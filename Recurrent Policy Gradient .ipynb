{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from machine import Machine\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "#Parameters\n",
    "lmd0 = 0.013364\n",
    "lmd1 = 0.333442\n",
    "lmdM = 1 - lmd0 - lmd1 #0.6531...\n",
    "mu0 = 0.125\n",
    "mu1 = 0.25\n",
    "muM = 0.5\n",
    "maintenance_cost = 500\n",
    "\n",
    "\n",
    "#transition matrices\n",
    "\n",
    "#transition matrix for a = 0 (no maintenance)\n",
    "a0_tm = np.array([[lmdM, lmd1, 0, 0, 0, 0, 0, 0, 0, lmd0], #current state 0 to next state\n",
    "                  [0, lmdM, lmd1, 0, 0, 0, 0, 0, 0, lmd0], #current state 1 to next state\n",
    "                  [0, 0, lmdM, lmd1, 0, 0, 0, 0, 0, lmd0], #current state 2 to next state\n",
    "                  [0, 0, 0, lmdM, 0, 0, 0, 0, lmd1, lmd0], #current state 3 to next state\n",
    "                  [muM, 0, 0, 0, 1-muM, 0, 0, 0, 0, 0], #current state 4 to next state\n",
    "                  [muM, 0, 0, 0, 0, 1-muM, 0, 0, 0, 0], #current state 5 to next state\n",
    "                  [0, muM, 0, 0, 0, 0, 1-muM, 0, 0, 0], #current state 6 to next state\n",
    "                  [0, 0, muM, 0, 0, 0, 0, 1-muM, 0, 0], #current state 7 to next state\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], #current state 8 to next state\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]) #current state 9 to next state\n",
    "\n",
    "\n",
    "#transition matrix for a = 1 (maintenance steps)\n",
    "a1_tm = np.array([[0, 0, 0, 0, 1-lmd0, 0, 0, 0, 0, lmd0], #current state 0 to next state\n",
    "                  [0, 0, 0, 0, 0, 1-lmd0, 0, 0, 0, lmd0], #current state 1 to next state\n",
    "                  [0, 0, 0, 0, 0, 0, 1-lmd0, 0, 0, lmd0], #current state 2 to next state\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 1-lmd0, 0, lmd0], #current state 3 to next state\n",
    "                  [muM, 0, 0, 0, 1-muM, 0, 0, 0, 0, 0], #current state 4 to next state\n",
    "                  [muM, 0, 0, 0, 0, 1-muM, 0, 0, 0, 0], #current state 5 to next state\n",
    "                  [0, muM, 0, 0, 0, 0, 1-muM, 0, 0, 0], #current state 6 to next state\n",
    "                  [0, 0, muM, 0, 0, 0, 0, 1-muM, 0, 0], #current state 7 to next state\n",
    "                  [mu1, 0, 0, 0, 0, 0, 0, 0, 1-mu1, 0], #current state 8 to next state\n",
    "                  [mu0, 0, 0, 0, 0, 0, 0, 0, 0, 1-mu0]]) #current state 9 to next state\n",
    "tm = [a0_tm,a1_tm]\n",
    "#r_func = {0:2000,1:1500,2:1000,3:500,4:-maintenance_cost,5:-maintenance_cost,6:-maintenance_cost,7:-maintenance_cost,8:-3000,9:-2000}\n",
    "r_func = {0:1000,1:900,2:800,3:500,4:-500,5:-500,6:-500,7:-500,8:-3000,9:-1000}\n",
    "\n",
    "class Machine_env():\n",
    "    '''\n",
    "    Description:\n",
    "    Code creates an environment for the policy to interact with the simulated machine.\n",
    "\n",
    "    States:\n",
    "    The simulated machine has 10 states\n",
    "    [0,1,2,3] are working states that degrades as the state number increases.\n",
    "    [4,5,6,7] are maintenance states that are transited from [0,1,2,3] respectively if the action deems it need transition\n",
    "    [8,9] are failure state, where 8 is sudden failure state that can occur from [0,1,2,3] while 9 is a degraded failure from 3\n",
    "\n",
    "    Actions:\n",
    "    Type: Discrete(2)\n",
    "    Num\n",
    "    0: No maintenance\n",
    "    1: Maintenance\n",
    "\n",
    "    Rewards:\n",
    "    reward_func = {0:1000,1:900,2:900,3:500,4:-500,5:-500,6:-500,7:-500,8:-3000,9:-1000}\n",
    "\n",
    "    Observations:\n",
    "    Produced using MachineSensor class that uses gmm from pickle file\n",
    "\n",
    "    Episode:\n",
    "    Since it is continous Markov model, we shall set 1 episode is 20 steps\n",
    "\n",
    "\n",
    "    Pseudo code\n",
    "\n",
    "    initialise class\n",
    "    Loop 20 times: #1 episode\n",
    "        sensor()\n",
    "        action()\n",
    "        step()\n",
    "\n",
    "    final otp: Class that contains rewards,actions, observations --> will be used to improve policy (ie. optimise theta)\n",
    "        \n",
    "''' \n",
    "\n",
    "    def __init__(self,tm,r_func):\n",
    "        self.action_space = [0,1]\n",
    "        self.state = 0 #Random initialise the start state, assumes uniform distribution for initial state,random.randrange(10)\n",
    "        self.state_seq = [] #initialise a list that records the actual states\n",
    "        self.reward_func = r_func\n",
    "        self.observation_space = 4\n",
    "        self.transition  = tm\n",
    "        self.simulator = Machine() #simulator to generate sensor readings\n",
    "        self.steps = 0\n",
    "    \n",
    "    def sensor(self,state): # generate observation at state\n",
    "        self.simulator.curr_state = state\n",
    "        sensor_reading = self.simulator.readSensors()\n",
    "        return sensor_reading\n",
    "    \n",
    "    def step(self,action): # simulate movement of states given an action\n",
    "        \n",
    "        self.state_seq.append(self.state) #record current state\n",
    "        \n",
    "        transition_mat_action = self.transition[action]\n",
    "        #print(f\"Transition Prob: {transition_mat_action[self.state]}\")\n",
    "        nxt_state = np.random.choice([i for i in range(10)],1,p=transition_mat_action[self.state])[0] #select nxt state based\n",
    "\n",
    "        \n",
    "        reward = self.reward_func[nxt_state] #reward for going to next state\n",
    "        self.steps += 1\n",
    "        self.state = nxt_state #update state\n",
    "\n",
    "        return reward\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = 0\n",
    "        self.done = False\n",
    "        self.steps = 0\n",
    "        self.state_seq = []\n",
    "        return \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class policy_estimator(nn.Module): #neural network\n",
    "    def __init__(self, env):\n",
    "        super(policy_estimator, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTMCell(env.observation_space,128)\n",
    "        self.layer1 = nn.Linear(128,128)\n",
    "        \n",
    "        self.layer2 = nn.Linear(128,len(env.action_space))\n",
    "       \n",
    "            \n",
    "    \n",
    "    def forward(self, x):#prediction is raw value\n",
    "        x = torch.FloatTensor(x)\n",
    "        output = []\n",
    "        hx = torch.zeros(1,128)\n",
    "        cx = torch.zeros(1,128)\n",
    "        \n",
    "        if(len(x.size()) == 1): #single tensor ie. [x1,x2,x3,x4]\n",
    "            x = x.unsqueeze(0)\n",
    "            #print(x)\n",
    "            hx, cx = self.lstm(x, (hx, cx))\n",
    "            output = hx\n",
    "            #print(output)\n",
    "\n",
    "        elif(len(x.size()) == 2): #2 dimension\n",
    "            x = x.unsqueeze(1) #dim = (timestep,batch,features), note batch = 1\n",
    "#             print(x.size())\n",
    "            for i in range(x.size()[0]): #loop to simulate recurrent network\n",
    "                #print(y)\n",
    "                hx, cx = self.lstm(x[i], (hx, cx))\n",
    "                output.append(hx)\n",
    "        \n",
    "            output = torch.stack(output, dim=0).squeeze(1) #convert to tensor\n",
    "        \n",
    "        x = F.leaky_relu(output)\n",
    "        x = self.layer1(x)\n",
    "        x  = F.relu(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        return F.softmax(x,dim = -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_discount_reward(rewards,gamma):\n",
    "    r = np.array([gamma**i * rewards[i] \n",
    "        for i in range(len(rewards))])\n",
    "    # Reverse the array direction for cumsum and then\n",
    "    # revert back to the original order\n",
    "    r = r[::-1].cumsum()[::-1]\n",
    "    r = np.array(r)\n",
    "    mean_rewards=np.mean(r)\n",
    "    std_rewards=np.std(r)\n",
    "    norm_discounted_rewards=(r-mean_rewards)/(std_rewards+1e-12)\n",
    "    return norm_discounted_rewards.tolist()\n",
    "\n",
    "class StateValueNetwork(nn.Module):\n",
    "    \n",
    "    #Takes in state\n",
    "    def __init__(self, observation_space):\n",
    "        super(StateValueNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.lstm = nn.LSTMCell(observation_space,128)\n",
    "        self.layer1 = nn.Linear(128, 128)\n",
    "        self.layer2 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #input layer\n",
    "        x = torch.FloatTensor(x)\n",
    "        output = []\n",
    "        hx = torch.zeros(1,128)\n",
    "        cx = torch.zeros(1,128)\n",
    "        \n",
    "        if(len(x.size()) == 1): #single tensor ie. [x1,x2,x3,x4]\n",
    "            x = x.unsqueeze(0)\n",
    "            #print(x)\n",
    "            hx, cx = self.lstm(x, (hx, cx))\n",
    "            output = hx\n",
    "            #print(output)\n",
    "\n",
    "        elif(len(x.size()) == 2): #2 dimension\n",
    "            x = x.unsqueeze(1) #dim = (timestep,batch,features), note batch = 1\n",
    "#             print(x.size())\n",
    "            for i in range(x.size()[0]): #loop to simulate recurrent network\n",
    "                #print(y)\n",
    "                hx, cx = self.lstm(x[i], (hx, cx))\n",
    "                output.append(hx)\n",
    "        \n",
    "            output = torch.stack(output, dim=0).squeeze(1) #convert to tensor\n",
    "        \n",
    "        x = F.leaky_relu(output)\n",
    "        x = self.layer1(x)\n",
    "        x  = F.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        state_value = x\n",
    "        \n",
    "        return state_value\n",
    "    \n",
    "def train_value(G, state_vals, optimizer):\n",
    "    ''' Update state-value network parameters\n",
    "    Args:\n",
    "    - G (Array): trajectory of cumulative discounted rewards \n",
    "    - state_vals (Array): trajectory of predicted state-value at each step\n",
    "    - optimizer (Pytorch optimizer): optimizer to update state-value network parameters\n",
    "    '''\n",
    "    \n",
    "    G = G.to(torch.float32)\n",
    "    state_vals = state_vals.to(torch.float32)\n",
    "    #calculate MSE loss\n",
    "    val_loss = F.mse_loss(state_vals, G)\n",
    "        \n",
    "    #Backpropagate\n",
    "    optimizer.zero_grad()\n",
    "    val_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "def stack_state_value(states,stateval_network): #input is a list of observations/states that will be used to train the nn for statevalue network\n",
    "    state_vals = []\n",
    "    for state in states:\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "        state_vals.append(stateval_network(state))\n",
    "    return torch.stack(state_vals).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paho.mqtt.client as mqtt\n",
    "def on_connect(self, client, userdata, flags, rc):\n",
    "    if rc == 0:\n",
    "        print('Connected OK')\n",
    "    else:\n",
    "        print('Bad connection Returned code = ' + str(rc))\n",
    "\n",
    "def on_disconnect(self, client, userdata, flags, rc = 0):\n",
    "    print('Disconnected result code: ' + str(rc))\n",
    "\n",
    "def on_message(self, client, userdata, message):\n",
    "    message_topic = message.topic\n",
    "    message_payload = message.payload.decode('utf-8')\n",
    "    print('Message topic: ' + message.topic)\n",
    "    print('Message received: ' + message_payload)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Improvement:\n",
    "- Recurrent implementation --> action taken by referencing 10 frames behind\n",
    "- Model does not learn about the maintenance readings = [-1,-1,-1,-1] default action for these states are no action, cost of maintenance is cumulative depending on how long it stays in the maintenance state\n",
    "- Add batch size which will determine the update frequency of the policy during simulation\n",
    "- longer episodic update of policy but more of batch update\n",
    "- Every batch update the input internal states to the next batch is updated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non Episodic/Batch update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurrent_pg_baseline(machine,baseline_net,policy_estimator,timesteps,lookback,gamma,lr): #Learning algo\n",
    "    # Set up lists to hold results\n",
    "    # Set up lists to hold results\n",
    "    total_rewards = [] #Total actual reward for each episode\n",
    "    batch_rewards = []  #Discounted expected future rewards for each batch\n",
    "    batch_actions = []\n",
    "    batch_observation = []\n",
    "    state_seq = []\n",
    "    counter = 0\n",
    "\n",
    "    \n",
    "    # Define optimizer\n",
    "    optimizer = torch.optim.Adam(policy_estimator.parameters(),lr=lr)\n",
    "    state_val_optimizer = torch.optim.Adam(baseline_net.parameters(),lr=0.001)\n",
    "    \n",
    "    action_space = machine.action_space\n",
    "    \n",
    "    machine.reset()\n",
    "    observation = []\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    batch_obs = []\n",
    "    t = 0\n",
    "    \n",
    "    for t in range(timesteps):\n",
    "        \n",
    "        obs = machine.sensor(machine.state).tolist() #observation\n",
    "        \n",
    "        batch_obs.append(obs)\n",
    "        \n",
    "        if len(observation) < lookback:\n",
    "            action_probs = policy_estimator(batch_obs).detach().numpy()[-1] #convert to numpy and get action prob for the latest\n",
    "        else:\n",
    "            print(action_probs)\n",
    "            action_probs = policy_estimator(batch_obs[-lookback:]).detach().numpy()[-1]\n",
    "        \n",
    "        try:\n",
    "            action = np.random.choice(action_space, p=action_probs) #select weighted actions based on NN output prob\n",
    "        except: #in the event converged\n",
    "            action_probs = np.nan_to_num(action_probs)\n",
    "            action_probs = np.round(action_probs)\n",
    "            action = np.random.choice(action_space, p=action_probs)\n",
    "            \n",
    "        print(f\"Sensor: {obs}, Action prob: {action_probs}, Action: {action}, state: {machine.state}\")\n",
    "        \n",
    "        r = machine.step(action) #receive reward and update machine to the next state after doing the sampled action\n",
    "        \n",
    "        rewards.append(r)\n",
    "        actions.append(action)\n",
    "        \n",
    "        while(r == -maintenance_cost): #cumulate maintenance\n",
    "            r = machine.step(0)\n",
    "            rewards[-1] += r \n",
    "            print(f\"Maintenance in progress, cumulative {rewards[-1]}\")\n",
    "        \n",
    "        counter+=1\n",
    "        \n",
    "\n",
    "        if(not counter%lookback): #batch update policy\n",
    "            observation.extend(batch_obs)\n",
    "            discount_r = normalized_discount_reward(rewards[-lookback:],gamma) #normalised future rewards\n",
    "\n",
    "            obs_tensor = torch.FloatTensor(observation[-lookback:])\n",
    "            action_tensor = torch.LongTensor(actions[-lookback:])\n",
    "            reward_tensor = torch.from_numpy(np.array(discount_r).copy()) #discounted reward G\n",
    "\n",
    "            #calculate state values \n",
    "            state_value_tensor = stack_state_value(np.array(observation[-lookback:]),baseline_net)\n",
    "\n",
    "            #train state value network\n",
    "#             print(rewards)\n",
    "#             print(reward_tensor,state_value_tensor)\n",
    "            train_value(reward_tensor,state_value_tensor,state_val_optimizer)\n",
    "\n",
    "            #calculate delta or advantage \n",
    "            deltas = [gt - val for gt, val in zip(reward_tensor, state_value_tensor)]\n",
    "            deltas = torch.tensor(deltas)\n",
    "\n",
    "\n",
    "\n",
    "            logprob = torch.log(policy_estimator(obs_tensor))\n",
    "\n",
    "            #print(logprob[np.arange(len(action_tensor)), action_tensor])\n",
    "            selected_logprobs = deltas * logprob[np.arange(len(action_tensor)), action_tensor]\n",
    "            print(selected_logprobs)\n",
    "\n",
    "\n",
    "            loss = -selected_logprobs.mean()\n",
    "            \n",
    "            if loss != 0:\n",
    "                optimizer.zero_grad()\n",
    "                # Calculate gradients\n",
    "                loss.backward()\n",
    "                # Apply gradients\n",
    "                optimizer.step()\n",
    "            \n",
    "            batch_obs = [] #reset batch\n",
    "            total_rewards.append(sum(rewards)) #Cumulative reward for this batch\n",
    "            print(f\"Reward for up to this timestep {t+1} is {total_rewards[-1]}, loss is {loss}\")\n",
    "            continue\n",
    "            \n",
    "        total_rewards.append(sum(rewards))\n",
    "        \n",
    "        \n",
    "        \n",
    "#         #Tensorboard params\n",
    "#         writer.add_scalar(\"Loss\", loss, ep)\n",
    "#         writer.add_scalar('Rewards',sum(rewards),ep)\n",
    "#         for name, weight in policy_estimator.network.named_parameters():\n",
    "#             try:\n",
    "#                 writer.add_histogram(name,weight, ep)\n",
    "#             except:\n",
    "#                 continue\n",
    "#             if weight.grad != None:\n",
    "#                 writer.add_histogram(f\"{name}.grad\",weight.grad, ep)\n",
    "    \n",
    "#     writer.add_graph(policy_estimator.network,torch.FloatTensor(machine.sensor(0))) #draw graph\n",
    "#     writer.flush()\n",
    "#     writer.close()\n",
    "    \n",
    "    return (total_rewards,batch_actions,state_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\overl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator GaussianMixture from version 0.20.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1000, 1: 900, 2: 800, 3: 500, 4: -500, 5: -500, 6: -500, 7: -500, 8: -3000, 9: -1000}\n",
      "Sensor: [0.337017098974057, 0.6858265145652863, 0.1640811890730791, 0.2644662983074236], Action prob: [0.49339536 0.5066047 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.37571670033791515, 0.668710069865872, 0.22827647210316343, 0.2782638038435191], Action prob: [0.49381194 0.50618804], Action: 0, state: 0\n",
      "Sensor: [0.4085559838771688, 0.6331438081732886, 0.21302601248983893, 0.28200092293748147], Action prob: [0.4939201 0.5060799], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.39874490435572785, 0.6413672670365032, 0.23766281705685044, 0.25207299972968383], Action prob: [0.49391305 0.50608695], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3809323423191324, 0.6556843543662995, 0.22049672991203564, 0.46154232712554455], Action prob: [0.49371082 0.50628924], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.33504070186776297, 0.672030861463656, 0.2183709942104962, 0.2530151121428409], Action prob: [0.4936739  0.50632614], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3506207429523578, 0.6961376450508633, 0.2286202661124814, 0.4331714543273174], Action prob: [0.49344027 0.5065597 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.426485789465523, 0.6526814755677459, 0.17682730203460367, 0.2168936607658377], Action prob: [0.4937841  0.50621593], Action: 0, state: 0\n",
      "tensor([-1.3787, -0.7940,  0.3399,  0.3399,  0.7875,  0.3846,  0.3842, -0.2782],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 8 is 1500, loss is 0.026867335243507887\n",
      "[0.4937841  0.50621593]\n",
      "Sensor: [0.3330989853704908, 0.6796466334680548, 0.2112221931955321, 0.21262585405960677], Action prob: [0.5157673  0.48423272], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5157673  0.48423272]\n",
      "Sensor: [0.31156050577909433, 0.6477715942612129, 0.19242938301843543, 0.4345856631272426], Action prob: [0.52260846 0.47739157], Action: 0, state: 0\n",
      "[0.52260846 0.47739157]\n",
      "Sensor: [0.3751251940184952, 0.6717062047925063, 0.389571421008173, 0.44983878713701464], Action prob: [0.52724314 0.47275686], Action: 0, state: 0\n",
      "[0.52724314 0.47275686]\n",
      "Sensor: [0.31446173244060244, 0.6160765324250733, 0.18887723726650485, 0.23785161776753333], Action prob: [0.5292891 0.4707109], Action: 0, state: 0\n",
      "[0.5292891 0.4707109]\n",
      "Sensor: [0.37263118587548666, 0.6512695828979925, 0.22144138276730585, 0.2580613732457109], Action prob: [0.53070104 0.469299  ], Action: 0, state: 0\n",
      "[0.53070104 0.469299  ]\n",
      "Sensor: [0.3129273680742692, 0.7096478379994627, 0.2263632173050809, 0.22166559843949565], Action prob: [0.5314178 0.4685822], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5314178 0.4685822]\n",
      "Sensor: [0.3177927239433599, 0.6241358270754842, 0.2642089648532, 0.25019071786055413], Action prob: [0.53180283 0.46819717], Action: 0, state: 0\n",
      "[0.53180283 0.46819717]\n",
      "Sensor: [0.42386598304512885, 0.6008212682528382, 0.21298838822981364, 0.22162912726363296], Action prob: [0.532176  0.4678239], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-0.8196, -0.9743, -0.5343, -0.1486,  0.1943,  0.6014,  0.6389,  1.0677],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 16 is 6500, loss is -0.0031890240082210197\n",
      "[0.532176  0.4678239]\n",
      "Sensor: [0.27900092911519037, 0.6411413458209481, 0.21446322242461913, 0.27893578100327393], Action prob: [0.54022634 0.4597737 ], Action: 0, state: 0\n",
      "[0.54022634 0.4597737 ]\n",
      "Sensor: [0.3834867196211855, 0.6383375811581218, 0.22429821508121925, 0.20850882261321388], Action prob: [0.55479205 0.44520792], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.55479205 0.44520792]\n",
      "Sensor: [0.3582875425773976, 0.6621222524058961, 0.23668541860207043, 0.2728516816108022], Action prob: [0.5649504 0.4350496], Action: 0, state: 0\n",
      "[0.5649504 0.4350496]\n",
      "Sensor: [0.3327850602238379, 0.6171770755134032, 0.23281213890214164, 0.2332259631420577], Action prob: [0.57148707 0.4285129 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.57148707 0.4285129 ]\n",
      "Sensor: [0.5438852233218453, 0.49459766834974345, 0.22546502341861446, 0.6750838764363548], Action prob: [0.5776003  0.42239967], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5776003  0.42239967]\n",
      "Sensor: [0.36255939352512173, 0.6366629048695591, 0.16565622976715288, 0.2388210008958679], Action prob: [0.5808068  0.41919315], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.5808068  0.41919315]\n",
      "Sensor: [0.34245299586043376, 0.645277701072003, 0.21301121477182208, 0.2719747264706555], Action prob: [0.58309656 0.41690347], Action: 0, state: 0\n",
      "[0.58309656 0.41690347]\n",
      "Sensor: [0.3198828762123499, 0.6305559008328053, 0.18812880906731388, 0.24569466033879603], Action prob: [0.5844961  0.41550392], Action: 0, state: 0\n",
      "tensor([-1.3290, -0.7047, -0.1296,  0.6913,  0.7025,  0.7095, -0.0156,  0.3928],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 24 is 9700, loss is -0.0396497450369236\n",
      "[0.5844961  0.41550392]\n",
      "Sensor: [0.3246399986024542, 0.660055037973896, 0.1650520679188957, 0.2339055653909823], Action prob: [0.5672672  0.43273282], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5672672  0.43273282]\n",
      "Sensor: [0.2885660713309822, 0.6404665846730653, 0.22319338966253105, 0.22961078299814328], Action prob: [0.5925377 0.4074624], Action: 0, state: 0\n",
      "[0.5925377 0.4074624]\n",
      "Sensor: [0.43031687242711897, 0.6594528843840756, 0.27490500667141043, 0.27385222522822095], Action prob: [0.61470836 0.38529158], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.61470836 0.38529158]\n",
      "Sensor: [0.3201773631391632, 0.6391304830805343, 0.2429869619666264, 0.24249001463056655], Action prob: [0.6322045  0.36779553], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6322045  0.36779553]\n",
      "Sensor: [0.3301451276706341, 0.6645064894765642, 0.2184259017109712, 0.3554859845865557], Action prob: [0.648192   0.35180798], Action: 0, state: 0\n",
      "[0.648192   0.35180798]\n",
      "Sensor: [0.3416966888821619, 0.5677211768331126, 0.2521668596534862, 0.21565615220056444], Action prob: [0.6607469 0.3392531], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6607469 0.3392531]\n",
      "Sensor: [0.3857764319667098, 0.6762333203909776, 0.22053549001618994, 0.2845258809870364], Action prob: [0.6731159 0.3268841], Action: 0, state: 0\n",
      "[0.6731159 0.3268841]\n",
      "Sensor: [0.36650233100451, 0.6279508513140561, 0.21797819456278392, 0.27299395945094557], Action prob: [0.6836326  0.31636748], Action: 0, state: 1\n",
      "tensor([-1.3611, -0.6226, -0.4617, -0.1311,  0.0809,  0.8191,  0.4020,  0.5447],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 32 is 15400, loss is 0.0912424305601448\n",
      "[0.6836326  0.31636748]\n",
      "Sensor: [0.3391922275674619, 0.6991873265455903, 0.22674347328705016, 0.2615405758929696], Action prob: [0.57711494 0.42288503], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.57711494 0.42288503]\n",
      "Sensor: [0.3680555240673811, 0.6865907662931008, 0.21606263915649124, 0.28958672662951623], Action prob: [0.6036954  0.39630458], Action: 0, state: 0\n",
      "[0.6036954  0.39630458]\n",
      "Sensor: [0.30573229948655395, 0.6841263402962591, 0.23103154383544616, 0.29158724209342424], Action prob: [0.62336147 0.37663853], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.62336147 0.37663853]\n",
      "Sensor: [0.33156147650313555, 0.6545998831829666, 0.16629745306742288, 0.24850120412619317], Action prob: [0.6373916 0.3626084], Action: 0, state: 0\n",
      "[0.6373916 0.3626084]\n",
      "Sensor: [0.37958091974072683, 0.6443340086752627, 0.22182444395006404, 0.23746391146197568], Action prob: [0.6485442  0.35145578], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6485442  0.35145578]\n",
      "Sensor: [0.38807215896839337, 0.6155936704943561, 0.23226296436590446, 0.24460753961623433], Action prob: [0.6569738 0.3430262], Action: 0, state: 0\n",
      "[0.6569738 0.3430262]\n",
      "Sensor: [0.3708265865914541, 0.5984368899414048, 0.19367545384203885, 0.22722325499253718], Action prob: [0.6629869 0.3370131], Action: 0, state: 0\n",
      "[0.6629869 0.3370131]\n",
      "Sensor: [0.35017223861971414, 0.6226043174115105, 0.21495852244835725, 0.2332186933215874], Action prob: [0.66788524 0.3321148 ], Action: 0, state: 0\n",
      "tensor([-1.0630, -0.6234, -0.2051, -0.3023,  0.0792,  0.1887,  0.4611,  0.6973],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 40 is 20300, loss is 0.09593968803843093\n",
      "[0.66788524 0.3321148 ]\n",
      "Sensor: [0.36832246755289144, 0.6552923726806728, 0.2031763984977466, 0.24487490529773837], Action prob: [0.5744934  0.42550656], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5744934  0.42550656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3231261707133339, 0.6492714509525741, 0.17973349606439631, 0.2553899419280064], Action prob: [0.59494317 0.4050569 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.59494317 0.4050569 ]\n",
      "Sensor: [0.3550194592336608, 0.6335230037711411, 0.19296378872827386, 0.2504408972924345], Action prob: [0.60776824 0.39223173], Action: 0, state: 0\n",
      "[0.60776824 0.39223173]\n",
      "Sensor: [0.3127083322403479, 0.56252862315046, 0.23109796653995518, 0.27722228447616076], Action prob: [0.6149891  0.38501093], Action: 0, state: 0\n",
      "[0.6149891  0.38501093]\n",
      "Sensor: [0.353332073420058, 0.6742890065427126, 0.229339424570223, 0.2640225494662667], Action prob: [0.6201771 0.379823 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.6201771 0.379823 ]\n",
      "Sensor: [0.43340594179709885, 0.6581177998043718, 0.4419282862856742, 0.2792990982082168], Action prob: [0.62409556 0.3759045 ], Action: 0, state: 0\n",
      "[0.62409556 0.3759045 ]\n",
      "Sensor: [0.35622771928271246, 0.6749720323080453, 0.18974913129907423, 0.2734089936943693], Action prob: [0.6254998  0.37450013], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6254998  0.37450013]\n",
      "Sensor: [0.3197685031014746, 0.5972197046910818, 0.1879074555468519, 0.3130382950419043], Action prob: [0.6256865  0.37431347], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "tensor([-0.5580, -1.1992, -0.6609, -0.1147,  0.7238,  0.1434,  1.0820,  1.4340],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 48 is 21800, loss is -0.10631467315476775\n",
      "[0.6256865  0.37431347]\n",
      "Sensor: [0.3721666451169783, 0.6472604402529275, 0.20699926697743487, 0.2685895309678063], Action prob: [0.581239   0.41876104], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.581239   0.41876104]\n",
      "Sensor: [0.31800217307445283, 0.6666839353615844, 0.22628041844419988, 0.22209842101001206], Action prob: [0.6033265  0.39667353], Action: 0, state: 0\n",
      "[0.6033265  0.39667353]\n",
      "Sensor: [0.31283727960779156, 0.5894017745340925, 0.17296196501245975, 0.2910982908784452], Action prob: [0.61671996 0.38328   ], Action: 0, state: 0\n",
      "[0.61671996 0.38328   ]\n",
      "Sensor: [0.45456305930988633, 0.6124363474247586, 0.19053597688467802, 0.25502922160651587], Action prob: [0.62542063 0.37457937], Action: 0, state: 1\n",
      "[0.62542063 0.37457937]\n",
      "Sensor: [0.40453297385897774, 0.556153861206011, 0.2166463249612584, 0.25698867494474675], Action prob: [0.62986296 0.3701371 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.62986296 0.3701371 ]\n",
      "Sensor: [0.34420477679521, 0.6240477666179427, 0.22154617323905962, 0.24876117354465796], Action prob: [0.6324523  0.36754778], Action: 0, state: 0\n",
      "[0.6324523  0.36754778]\n",
      "Sensor: [0.635791363688117, 0.6155105930808865, 0.1689150111733904, 0.21618465984654692], Action prob: [0.634893   0.36510703], Action: 1, state: 9\n",
      "[0.634893   0.36510703]\n",
      "Sensor: [0.34639161020405257, 0.620877248258714, 0.184353243016757, 0.26144714425621507], Action prob: [0.6351196  0.36488035], Action: 0, state: 0\n",
      "tensor([-1.3183, -0.7651, -0.2025,  0.2198,  1.2591,  0.3978,  0.1495,  0.3616],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 56 is 25100, loss is -0.012735064765024458\n",
      "[0.6351196  0.36488035]\n",
      "Sensor: [0.3542135554258137, 0.6049314629022831, 0.1797766963334561, 0.30405527790884584], Action prob: [0.58745426 0.4125458 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.58745426 0.4125458 ]\n",
      "Sensor: [0.42370963602525996, 0.6159675333075075, 0.23337903137315844, 0.2411535706839967], Action prob: [0.6124068 0.3875932], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6124068 0.3875932]\n",
      "Sensor: [0.30839153079897363, 0.6742074440393286, 0.20539456209186235, 0.19357442560691138], Action prob: [0.62718403 0.37281597], Action: 0, state: 0\n",
      "[0.62718403 0.37281597]\n",
      "Sensor: [0.4286214083311395, 0.6327941212058346, 0.2448523218455417, 0.30786221257324037], Action prob: [0.6373182  0.36268178], Action: 0, state: 1\n",
      "[0.6373182  0.36268178]\n",
      "Sensor: [0.347809364769205, 0.6433107933648938, 0.225149765058962, 0.19430744457457838], Action prob: [0.64174896 0.35825104], Action: 0, state: 1\n",
      "[0.64174896 0.35825104]\n",
      "Sensor: [0.3731972948170325, 0.654637265172527, 0.21000821587599652, 0.24049758673511182], Action prob: [0.6444232 0.3555768], Action: 0, state: 2\n",
      "[0.6444232 0.3555768]\n",
      "Sensor: [0.4105216967669605, 0.6363970969010765, 0.2463180961913835, 0.2756318324709019], Action prob: [0.64616823 0.35383168], Action: 0, state: 2\n",
      "[0.64616823 0.35383168]\n",
      "Sensor: [0.33330774037757566, 0.6401724413152494, 0.2009783325083135, 0.2598968062509571], Action prob: [0.6464166  0.35358334], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "tensor([-1.0907, -1.1680, -0.3985, -0.1106,  0.1350,  0.3268,  0.4971,  1.5543],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 64 is 29700, loss is 0.03182086876997814\n",
      "[0.6464166  0.35358334]\n",
      "Sensor: [0.3081664003134984, 0.614121081128626, 0.19927462997366596, 0.2675083546469171], Action prob: [0.5899642  0.41003573], Action: 0, state: 1\n",
      "[0.5899642  0.41003573]\n",
      "Sensor: [0.3587309118036636, 0.6485314857116541, 0.22428631460357315, 0.2162820570988887], Action prob: [0.61653715 0.38346288], Action: 0, state: 2\n",
      "[0.61653715 0.38346288]\n",
      "Sensor: [0.32553286706425616, 0.6308551094723268, 0.19498050283115087, 0.2356298822720385], Action prob: [0.6331398  0.36686024], Action: 0, state: 2\n",
      "[0.6331398  0.36686024]\n",
      "Sensor: [0.3755196622557867, 0.6258369872456713, 0.2322245267611241, 0.2821080887756958], Action prob: [0.6438717  0.35612825], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.6438717  0.35612825]\n",
      "Sensor: [0.37596028366748174, 0.6954833114718026, 0.21886121969316882, 0.2988202422513612], Action prob: [0.65090686 0.34909314], Action: 0, state: 2\n",
      "[0.65090686 0.34909314]\n",
      "Sensor: [0.40901284950292366, 0.6105642273582719, 0.19250138400032915, 0.2708330337908184], Action prob: [0.65381336 0.3461866 ], Action: 0, state: 2\n",
      "[0.65381336 0.3461866 ]\n",
      "Sensor: [0.3813908014645422, 0.6387282025772444, 0.24765202911036846, 0.25610708818284317], Action prob: [0.6553367  0.34466332], Action: 0, state: 2\n",
      "[0.6553367  0.34466332]\n",
      "Sensor: [0.36916387574540455, 0.6430879743172315, 0.22476186410865204, 0.3146720994843204], Action prob: [0.65639555 0.3436044 ], Action: 0, state: 2\n",
      "tensor([-0.9273, -0.5019, -0.1783, -0.0274,  0.0734,  0.2728,  0.4509,  0.6103],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 72 is 35300, loss is 0.028414747486256345\n",
      "[0.65639555 0.3436044 ]\n",
      "Sensor: [0.3751426714153971, 0.6415992557694487, 0.22156578047159867, 0.24453718531442073], Action prob: [0.5916975  0.40830255], Action: 0, state: 2\n",
      "[0.5916975  0.40830255]\n",
      "Sensor: [0.38828653001261093, 0.5899421884828497, 0.21131314973780047, 0.29405617404358225], Action prob: [0.61789435 0.38210562], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "[0.61789435 0.38210562]\n",
      "Sensor: [0.3542137434493185, 0.6446149050731697, 0.21599651162120945, 0.2589385930056781], Action prob: [0.6339212  0.36607876], Action: 0, state: 1\n",
      "[0.6339212  0.36607876]\n",
      "Sensor: [0.376151460253655, 0.6496335553680579, 0.24269612085457654, 0.26130129937367313], Action prob: [0.64330894 0.35669106], Action: 0, state: 1\n",
      "[0.64330894 0.35669106]\n",
      "Sensor: [0.38397728191711605, 0.6196338462407234, 0.21897454663720878, 0.23728234080682475], Action prob: [0.64788043 0.3521196 ], Action: 0, state: 1\n",
      "[0.64788043 0.3521196 ]\n",
      "Sensor: [0.3392372353690664, 0.6661045245795428, 0.217699294381047, 0.3078390553823715], Action prob: [0.6507036  0.34929642], Action: 0, state: 1\n",
      "[0.6507036  0.34929642]\n",
      "Sensor: [0.3972104669973144, 0.609630413498077, 0.23510434348157727, 0.24127551619703907], Action prob: [0.6514274 0.3485726], Action: 0, state: 1\n",
      "[0.6514274 0.3485726]\n",
      "Sensor: [0.4196502215528966, 0.6245454932754813, 0.18797512241241518, 0.2626514886012922], Action prob: [0.6518277  0.34817234], Action: 0, state: 1\n",
      "tensor([-0.7026, -0.5917, -0.5029, -0.1955,  0.0655,  0.2950,  0.5000,  0.6848],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for up to this timestep 80 is 40900, loss is 0.05591510853179378\n",
      "[0.6518277  0.34817234]\n",
      "Sensor: [0.34970567677438313, 0.636879111123194, 0.24394873208595522, 0.20393947680512922], Action prob: [0.5888871 0.411113 ], Action: 0, state: 1\n",
      "[0.5888871 0.411113 ]\n",
      "Sensor: [0.42108138844184295, 0.6349104922707628, 0.2112665564669464, 0.28078192401777247], Action prob: [0.6130815 0.3869185], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.6130815 0.3869185]\n",
      "Sensor: [0.3537789496461373, 0.6435495930783518, 0.2475214057447564, 0.24774586264071718], Action prob: [0.6262478  0.37375215], Action: 0, state: 0\n",
      "[0.6262478  0.37375215]\n",
      "Sensor: [0.41452505042849763, 0.6980432021208418, 0.18958780770948333, 0.23054669882933557], Action prob: [0.6330998 0.3669002], Action: 0, state: 1\n",
      "[0.6330998 0.3669002]\n",
      "Sensor: [0.39123801491372484, 0.6146592154275446, 0.2097862697847746, 0.26495912944932987], Action prob: [0.6358004  0.36419955], Action: 0, state: 2\n",
      "[0.6358004  0.36419955]\n",
      "Sensor: [0.37481907518591767, 0.6372523760455464, 0.19082380301850665, 0.19508302523309085], Action prob: [0.63620687 0.3637931 ], Action: 0, state: 3\n",
      "[0.63620687 0.3637931 ]\n",
      "Sensor: [0.3610767920287291, 0.3246842429063988, 0.22619899668495877, 0.2233794777468859], Action prob: [0.6337883  0.36621174], Action: 0, state: 8\n",
      "[0.6337883  0.36621174]\n",
      "Sensor: [0.390274325534752, 0.39398102549876196, 0.5018070154346453, 0.21054462837535196], Action prob: [0.633673   0.36632702], Action: 0, state: 8\n",
      "tensor([-0.3550,  0.2213, -0.1023,  0.2352,  0.4978,  0.6465, -0.1615, -0.8926],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 88 is 34500, loss is -0.011169892757320735\n",
      "[0.633673   0.36632702]\n",
      "Sensor: [0.572986890378762, 0.6512462229513143, 0.1948893283580098, 0.19319488676361082], Action prob: [0.58807635 0.41192365], Action: 0, state: 8\n",
      "[0.58807635 0.41192365]\n",
      "Sensor: [0.3583799887145964, 0.6413351873949227, 0.23454681728672386, 0.5470885562622376], Action prob: [0.61139596 0.38860402], Action: 0, state: 8\n",
      "[0.61139596 0.38860402]\n",
      "Sensor: [0.3200658377170695, 0.4175601090103942, 0.2540105529080533, 0.2176019881333401], Action prob: [0.61857146 0.3814285 ], Action: 0, state: 8\n",
      "[0.61857146 0.3814285 ]\n",
      "Sensor: [0.3685560471280369, 0.40473021861902314, 0.23546054113031725, 0.1750502957781787], Action prob: [0.6209429  0.37905708], Action: 1, state: 8\n",
      "[0.6209429  0.37905708]\n",
      "Sensor: [0.35285118084914446, 0.4503832301951523, 0.2611308562034512, 0.2550671276391611], Action prob: [0.62262 0.37738], Action: 1, state: 8\n",
      "[0.62262 0.37738]\n",
      "Sensor: [0.35894960787604613, 0.6647656919534248, 0.2520010031218236, 0.262287276252404], Action prob: [0.62478983 0.37521014], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.62478983 0.37521014]\n",
      "Sensor: [0.3676280928167581, 0.6414872246162379, 0.19775165573552922, 0.37845971204313267], Action prob: [0.62624294 0.37375703], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.62624294 0.37375703]\n",
      "Sensor: [0.3349894979677441, 0.6476731290509249, 0.2182075619952027, 0.25720828642415616], Action prob: [0.62600476 0.37399527], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([ 1.0524,  0.5622,  0.1850, -0.2869, -0.8848, -0.7075, -0.7920, -0.7177],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 96 is 24000, loss is 0.19866051575409338\n",
      "[0.62600476 0.37399527]\n",
      "Sensor: [0.35804417198564903, 0.6229233976814573, 0.18257936756969106, 0.2593411679323696], Action prob: [0.5771026  0.42289734], Action: 0, state: 0\n",
      "[0.5771026  0.42289734]\n",
      "Sensor: [0.3872741964314157, 0.6357923302404558, 0.1832457158311741, 0.27638100852585135], Action prob: [0.5929969  0.40700302], Action: 0, state: 0\n",
      "[0.5929969  0.40700302]\n",
      "Sensor: [0.38723243342552954, 0.6910889552577327, 0.22172279601815284, 0.2535682447873401], Action prob: [0.5997113 0.4002887], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5997113 0.4002887]\n",
      "Sensor: [0.3317740164276931, 0.6665239721741245, 0.20377236140439842, 0.2578219871674051], Action prob: [0.60168606 0.398314  ], Action: 0, state: 0\n",
      "[0.60168606 0.398314  ]\n",
      "Sensor: [0.38792915318870363, 0.6324122157560367, 0.2067559067631305, 0.2564566579877972], Action prob: [0.6018026  0.39819738], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6018026  0.39819738]\n",
      "Sensor: [0.31407831830366656, 0.6065921252097044, 0.17953579558699095, 0.25893579479213163], Action prob: [0.60090244 0.39909753], Action: 0, state: 0\n",
      "[0.60090244 0.39909753]\n",
      "Sensor: [0.3309619907982613, 0.6113776574700991, 0.20698527322962773, 0.2969366178094491], Action prob: [0.6005981 0.3994018], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6005981 0.3994018]\n",
      "Sensor: [0.33672572446688065, 0.6700083612778747, 0.2286161354330479, 0.2618520054415359], Action prob: [0.6006665  0.39933345], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "tensor([-1.0056, -0.5602, -0.3569, -0.0419,  0.3806,  0.3375,  0.9772,  1.1627],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 104 is 28800, loss is -0.11166678457751988\n",
      "[0.6006665  0.39933345]\n",
      "Sensor: [0.3848578329172495, 0.69049021498773, 0.34531765091185357, 0.2879735137187457], Action prob: [0.57502055 0.42497948], Action: 0, state: 0\n",
      "[0.57502055 0.42497948]\n",
      "Sensor: [0.3255050543690394, 0.6420575623569771, 0.27445333883180534, 0.22939952544987183], Action prob: [0.5876272  0.41237283], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5876272  0.41237283]\n",
      "Sensor: [0.3307588193738999, 0.6355113473151204, 0.2110217837104937, 0.28187441001684405], Action prob: [0.59189767 0.4081023 ], Action: 0, state: 0\n",
      "[0.59189767 0.4081023 ]\n",
      "Sensor: [0.36007990173487, 0.636399729356206, 0.2707737793036039, 0.5601971313274257], Action prob: [0.594681   0.40531898], Action: 0, state: 0\n",
      "[0.594681   0.40531898]\n",
      "Sensor: [0.3911987354826799, 0.6851715688048077, 0.2299697616961384, 0.30178783270407145], Action prob: [0.5940183  0.40598172], Action: 0, state: 0\n",
      "[0.5940183  0.40598172]\n",
      "Sensor: [0.37757148021827763, 0.6312697043318317, 0.20894258566616308, 0.2119337864063389], Action prob: [0.5924377 0.4075623], Action: 0, state: 1\n",
      "[0.5924377 0.4075623]\n",
      "Sensor: [0.3506262695353002, 0.5762584365889583, 0.21202006508411214, 0.25287690948955854], Action prob: [0.5913595  0.40864056], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5913595  0.40864056]\n",
      "Sensor: [0.40902533329056434, 0.626127301393668, 0.22703835711359593, 0.349544439466934], Action prob: [0.59180313 0.40819693], Action: 0, state: 0\n",
      "tensor([-0.8945, -0.7600, -0.4499, -0.1278,  0.1604,  0.3955,  1.0361,  0.7126],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 112 is 35100, loss is -0.009042346344972196\n",
      "[0.59180313 0.40819693]\n",
      "Sensor: [0.39927474448240946, 0.6296826365533507, 0.22601774550857764, 0.22413922634209377], Action prob: [0.57137245 0.42862758], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.57137245 0.42862758]\n",
      "Sensor: [0.3906174964422644, 0.7316382552384093, 0.22030123301278856, 0.2609009697174525], Action prob: [0.58309335 0.4169067 ], Action: 0, state: 0\n",
      "[0.58309335 0.4169067 ]\n",
      "Sensor: [0.3038924234202847, 0.5990298591995309, 0.21778185667216157, 0.2240909830053564], Action prob: [0.5855214  0.41447863], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5855214  0.41447863]\n",
      "Sensor: [0.3871849789032725, 0.6696190877151832, 0.2530720432304738, 0.6078116266591905], Action prob: [0.588076 0.411924], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.588076 0.411924]\n",
      "Sensor: [0.4063382997709932, 0.6509647684145552, 0.2095599124770732, 0.5884779477435392], Action prob: [0.58793765 0.41206235], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.58793765 0.41206235]\n",
      "Sensor: [0.3343785296874271, 0.6388824772735937, 0.21810798083484062, 0.25393032444415575], Action prob: [0.5858385 0.4141615], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5858385 0.4141615]\n",
      "Sensor: [0.37540257041189967, 0.6188913283057105, 0.20616928577756866, 0.34451517677663235], Action prob: [0.58509046 0.41490957], Action: 0, state: 0\n",
      "[0.58509046 0.41490957]\n",
      "Sensor: [0.36168968047205063, 0.5910673189679183, 0.21114419892452366, 0.27429693899470714], Action prob: [0.58443165 0.41556835], Action: 0, state: 1\n",
      "tensor([-1.5768, -0.6553, -0.0472,  0.4140, -0.0033,  0.3719,  0.4298,  0.7623],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 120 is 39300, loss is 0.03808442036712566\n",
      "[0.58443165 0.41556835]\n",
      "Sensor: [0.3713875340154243, 0.6707719347634626, 0.2462990656127276, 0.2623266316871458], Action prob: [0.56809586 0.43190414], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.56809586 0.43190414]\n",
      "Sensor: [0.34263360166982926, 0.6705803085621336, 0.24743353749720554, 0.257436810447893], Action prob: [0.57722646 0.42277357], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.57722646 0.42277357]\n",
      "Sensor: [0.36118891654594965, 0.6746298567183043, 0.24793001167083945, 0.224012908215069], Action prob: [0.5792247  0.42077532], Action: 0, state: 0\n",
      "[0.5792247  0.42077532]\n",
      "Sensor: [0.3510434672536392, 0.6912525228923418, 0.20891201847059046, 0.2618424549335182], Action prob: [0.5792373  0.42076266], Action: 0, state: 1\n",
      "[0.5792373  0.42076266]\n",
      "Sensor: [0.3197876749095738, 0.5626745337213863, 0.18435838291624082, 0.26948168732398686], Action prob: [0.5779117  0.42208824], Action: 0, state: 2\n",
      "[0.5779117  0.42208824]\n",
      "Sensor: [0.3746173739568806, 0.625892761463036, 0.2273060056416171, 0.27491110335386504], Action prob: [0.5775143  0.42248574], Action: 0, state: 2\n",
      "[0.5775143  0.42248574]\n",
      "Sensor: [0.40238533439439644, 0.6848881615987389, 0.2417247610261703, 0.2532224840812901], Action prob: [0.5775283  0.42247173], Action: 0, state: 3\n",
      "[0.5775283  0.42247173]\n",
      "Sensor: [0.7677211965913155, 0.6375723807906888, 0.1819911477657557, 0.2525479663982491], Action prob: [0.57770044 0.42229953], Action: 0, state: 8\n",
      "tensor([-1.1466, -0.7744, -0.4912, -0.0274,  0.3444,  0.6802,  0.8691, -0.1530],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 128 is 36700, loss is 0.08737066894383427\n",
      "[0.57770044 0.42229953]\n",
      "Sensor: [0.3860397351597426, 0.3600706137472293, 0.19811112616925222, 0.2859649651069718], Action prob: [0.55999225 0.44000775], Action: 0, state: 8\n",
      "[0.55999225 0.44000775]\n",
      "Sensor: [0.37343527875742816, 0.6074870843164075, 0.2131645903756971, 0.5709017822473268], Action prob: [0.56867576 0.43132424], Action: 0, state: 8\n",
      "[0.56867576 0.43132424]\n",
      "Sensor: [0.301274034715418, 0.6939109656216194, 0.20350553611787606, 0.5755423168551563], Action prob: [0.5700359 0.4299641], Action: 0, state: 8\n",
      "[0.5700359 0.4299641]\n",
      "Sensor: [0.36157400613254836, 0.40897757228693804, 0.24585158248771724, 0.25247794982385646], Action prob: [0.5669479 0.4330522], Action: 1, state: 8\n",
      "[0.5669479 0.4330522]\n",
      "Sensor: [0.34312883673431677, 0.6420777798147085, 0.24840418234977735, 0.24017140518152894], Action prob: [0.5659103  0.43408972], Action: 0, state: 0\n",
      "[0.5659103  0.43408972]\n",
      "Sensor: [0.41529047156562976, 0.594462158985333, 0.190968331165018, 0.23631918417277029], Action prob: [0.5653001  0.43469983], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5653001  0.43469983]\n",
      "Sensor: [0.331444180615181, 0.6811348240122119, 0.18792579091006734, 0.23429746900434403], Action prob: [0.56533164 0.43466836], Action: 0, state: 0\n",
      "[0.56533164 0.43466836]\n",
      "Sensor: [0.39548706613859796, 0.677595789752925, 0.19275005763065256, 0.28020063171322607], Action prob: [0.5656496 0.4343504], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([ 1.2604,  0.5668, -0.0265, -0.8346, -0.4043, -0.4009, -0.3389, -0.3410],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 136 is 30000, loss is 0.06488871630849821\n",
      "[0.5656496 0.4343504]\n",
      "Sensor: [0.3589232703019626, 0.6047153240474632, 0.20633671501829393, 0.24737933773735535], Action prob: [0.5530248  0.44697514], Action: 0, state: 0\n",
      "[0.5530248  0.44697514]\n",
      "Sensor: [0.3584026993649709, 0.6118632474029323, 0.19256489217045653, 0.2744032585904085], Action prob: [0.55714786 0.44285205], Action: 0, state: 1\n",
      "[0.55714786 0.44285205]\n",
      "Sensor: [0.27780927184763665, 0.634127238439007, 0.3058942187028167, 0.25203641683295225], Action prob: [0.5567842  0.44321585], Action: 0, state: 1\n",
      "[0.5567842  0.44321585]\n",
      "Sensor: [0.33216215076348965, 0.6238671025870066, 0.25707342023189056, 0.26103151127804647], Action prob: [0.55516016 0.44483984], Action: 0, state: 1\n",
      "[0.55516016 0.44483984]\n",
      "Sensor: [0.3577417114493776, 0.6312270755067365, 0.220218009882732, 0.19747779465018722], Action prob: [0.5537382  0.44626185], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.5537382  0.44626185]\n",
      "Sensor: [0.34344673972223794, 0.67795284006565, 0.22815061120433344, 0.18364896857167806], Action prob: [0.5531015 0.4468985], Action: 0, state: 1\n",
      "[0.5531015 0.4468985]\n",
      "Sensor: [0.38964851598108363, 0.5913141164111898, 0.20400865766077836, 0.23023350618571078], Action prob: [0.5527724 0.4472276], Action: 0, state: 2\n",
      "[0.5527724 0.4472276]\n",
      "Sensor: [0.3372440368895386, 0.6031082255212982, 0.2074495735066886, 0.23281986369602772], Action prob: [0.5526616  0.44733843], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1100\n",
      "tensor([-1.0999, -0.6608, -0.2776,  0.0670,  0.4722,  0.3157,  0.5411,  1.0113],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 144 is 33900, loss is -0.046104597774077646\n",
      "[0.5526616  0.44733843]\n",
      "Sensor: [0.32280111983389004, 0.6384728538879536, 0.2272071328029559, 0.25418186002970394], Action prob: [0.54875064 0.45124933], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.54875064 0.45124933]\n",
      "Sensor: [0.3274633343620043, 0.6456041121947546, 0.19483737416551847, 0.24879931521021525], Action prob: [0.55136675 0.44863322], Action: 0, state: 0\n",
      "[0.55136675 0.44863322]\n",
      "Sensor: [0.36931324454045117, 0.6540899142418611, 0.18802882910538712, 0.2668788356795886], Action prob: [0.5501494  0.44985065], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "[0.5501494  0.44985065]\n",
      "Sensor: [0.35412862042305776, 0.6464595404595884, 0.22181987071456566, 0.2824249302634862], Action prob: [0.5481758  0.45182416], Action: 0, state: 0\n",
      "[0.5481758  0.45182416]\n",
      "Sensor: [0.3776938977496373, 0.6635645844574364, 0.21242180985189363, 0.34435731749038206], Action prob: [0.5468532 0.4531468], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5468532 0.4531468]\n",
      "Sensor: [0.3439290901395354, 0.6660783638489848, 0.22288679331541278, 0.22791490117888258], Action prob: [0.545938   0.45406199], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.545938   0.45406199]\n",
      "Sensor: [0.3353985729292076, 0.6366789709892543, 0.19749100410007553, 0.2632658608993286], Action prob: [0.5456487 0.4543513], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5456487 0.4543513]\n",
      "Sensor: [0.3214746720665128, 0.6348726057502748, 0.20678306517202452, 0.2793282373071503], Action prob: [0.5456993 0.4543007], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.6467, -0.4838,  1.4181, -1.0336,  0.2982,  0.2986,  0.2980,  0.2981],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 152 is 34900, loss is -0.055849955514250205\n",
      "[0.5456993 0.4543007]\n",
      "Sensor: [0.3903329579166382, 0.6628455137115669, 0.19754482557930408, 0.21330988005033524], Action prob: [0.5476479 0.4523521], Action: 0, state: 0\n",
      "[0.5476479 0.4523521]\n",
      "Sensor: [0.43624873361893673, 0.647595562547387, 0.20030536961022058, 0.29324981083945456], Action prob: [0.5503663  0.44963375], Action: 0, state: 0\n",
      "[0.5503663  0.44963375]\n",
      "Sensor: [0.3429411303384428, 0.6618855544853274, 0.25820006513794, 0.255827450813459], Action prob: [0.5491878 0.4508122], Action: 0, state: 0\n",
      "[0.5491878 0.4508122]\n",
      "Sensor: [0.3515294286505745, 0.6037519304658523, 0.20715048045295825, 0.30957715510233347], Action prob: [0.54736763 0.45263234], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.54736763 0.45263234]\n",
      "Sensor: [0.36271772120369505, 0.6933799603555787, 0.19451653881563227, 0.26392628340787505], Action prob: [0.5463061  0.45369393], Action: 0, state: 0\n",
      "[0.5463061  0.45369393]\n",
      "Sensor: [0.3626050130236304, 0.6570970193864439, 0.22245011248906996, 0.2827935753190797], Action prob: [0.545787 0.454213], Action: 0, state: 0\n",
      "[0.545787 0.454213]\n",
      "Sensor: [0.39196222764981997, 0.6180438992877141, 0.20120074006189434, 0.3025560166248518], Action prob: [0.5455576  0.45444238], Action: 0, state: 1\n",
      "[0.5455576  0.45444238]\n",
      "Sensor: [0.38517001632216424, 0.6525875113181947, 0.20237123699247722, 0.27887359134815404], Action prob: [0.54551077 0.4544893 ], Action: 0, state: 1\n",
      "tensor([-1.0645, -0.6564, -0.2960, -0.0050,  0.1447,  0.4108,  0.6263,  0.8212],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 160 is 42000, loss is 0.002350889560169489\n",
      "[0.54551077 0.4544893 ]\n",
      "Sensor: [0.37620672144671086, 0.653633719514281, 0.2105163104786492, 0.19594204196967832], Action prob: [0.5468555  0.45314452], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5468555  0.45314452]\n",
      "Sensor: [0.3292538696195075, 0.6808031050603216, 0.20754052414983687, 0.2416932492904409], Action prob: [0.54924715 0.45075288], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.54924715 0.45075288]\n",
      "Sensor: [0.3769447037614355, 0.699667830295482, 0.2041519597282424, 0.2945507323660898], Action prob: [0.5481294  0.45187065], Action: 0, state: 0\n",
      "[0.5481294  0.45187065]\n",
      "Sensor: [0.31395858561771967, 0.6631471867311531, 0.2057873050043123, 0.2302453898898053], Action prob: [0.54614073 0.45385924], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.54614073 0.45385924]\n",
      "Sensor: [0.3306958457374186, 0.6484145834049307, 0.23288324931609267, 0.2386133640724631], Action prob: [0.5449481 0.4550519], Action: 0, state: 0\n",
      "[0.5449481 0.4550519]\n",
      "Sensor: [0.3754361325119979, 0.6016986193293932, 0.19303341976547972, 0.21738224427156563], Action prob: [0.54436684 0.4556332 ], Action: 0, state: 0\n",
      "[0.54436684 0.4556332 ]\n",
      "Sensor: [0.3687147575719854, 0.6685298124659006, 0.173038601123741, 0.23210544101113495], Action prob: [0.54436064 0.45563936], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.54436064 0.45563936]\n",
      "Sensor: [0.4150896117811683, 0.5856245039382115, 0.1977713596740983, 0.22100623536850406], Action prob: [0.54423064 0.4557694 ], Action: 0, state: 0\n",
      "tensor([-0.8604, -0.8655, -0.6537, -0.2377,  0.0314,  0.4175,  0.9903,  0.9220],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 168 is 47000, loss is 0.03200689355233195\n",
      "[0.54423064 0.4557694 ]\n",
      "Sensor: [0.3364591786533398, 0.6681337491132597, 0.2437608207960545, 0.2852636765689035], Action prob: [0.5451836 0.4548164], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5451836 0.4548164]\n",
      "Sensor: [0.3437074884557951, 0.6657610041203278, 0.2117795223580354, 0.25364577830873086], Action prob: [0.5468621  0.45313787], Action: 0, state: 0\n",
      "[0.5468621  0.45313787]\n",
      "Sensor: [0.346975207803303, 0.5881889232064065, 0.2701018317481477, 0.30741184790918397], Action prob: [0.5451952  0.45480475], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5451952  0.45480475]\n",
      "Sensor: [0.35363215566612877, 0.6160224612826095, 0.2008020225329908, 0.21707273375822383], Action prob: [0.5432046  0.45679536], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5432046  0.45679536]\n",
      "Sensor: [0.37041266661995886, 0.6528791038466868, 0.19460024419116093, 0.19663290607778042], Action prob: [0.54214615 0.45785388], Action: 0, state: 0\n",
      "[0.54214615 0.45785388]\n",
      "Sensor: [0.3315686640351372, 0.654409878483485, 0.16422361973998328, 0.2762586050641778], Action prob: [0.54184186 0.45815814], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -4500\n",
      "Maintenance in progress, cumulative -3500\n",
      "[0.54184186 0.45815814]\n",
      "Sensor: [0.3450644976319388, 0.6490908051344967, 0.24269458981816505, 0.2711346129863904], Action prob: [0.54173195 0.45826805], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.54173195 0.45826805]\n",
      "Sensor: [0.3692261406689567, 0.6419305594972159, 0.23601614389101172, 0.21331100689574495], Action prob: [0.54157996 0.45841998], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.0892, -0.4410,  0.3474,  0.3463,  0.5617,  1.3838, -0.7190, -0.4486],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 176 is 47500, loss is 0.007330831090879862\n",
      "[0.54157996 0.45841998]\n",
      "Sensor: [0.38629689580244525, 0.6536059638206745, 0.207864301591973, 0.21367719021128567], Action prob: [0.5429562  0.45704386], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5429562  0.45704386]\n",
      "Sensor: [0.34986263693679515, 0.639378921659831, 0.1911642940225966, 0.278064708895616], Action prob: [0.5446356  0.45536435], Action: 0, state: 0\n",
      "[0.5446356  0.45536435]\n",
      "Sensor: [0.40974167883871127, 0.6640778806937653, 0.23807485899666778, 0.2711269116272717], Action prob: [0.5429379  0.45706218], Action: 0, state: 0\n",
      "[0.5429379  0.45706218]\n",
      "Sensor: [0.3678047441746949, 0.6132369849227186, 0.24906581833565797, 0.24621152961070472], Action prob: [0.5407876 0.4592124], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5407876 0.4592124]\n",
      "Sensor: [0.3862561503785171, 0.5966542631434592, 0.22057153717613115, 0.24700048127828358], Action prob: [0.539543 0.460457], Action: 0, state: 0\n",
      "[0.539543 0.460457]\n",
      "Sensor: [0.38309541082007076, 0.6281195243469458, 0.1599408734794306, 0.2525554313856579], Action prob: [0.5391635 0.4608365], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5391635 0.4608365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.34914512928940294, 0.611004930613332, 0.18815037381250374, 0.26161133013901217], Action prob: [0.5390652  0.46093476], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5390652  0.46093476]\n",
      "Sensor: [0.39801692791541676, 0.6009537614289188, 0.20715637047116667, 0.25090965625909734], Action prob: [0.5390562 0.4609438], Action: 0, state: 0\n",
      "tensor([-1.4180, -0.7921, -0.2386,  0.2723,  0.2155,  0.7870,  0.7870,  0.4606],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 184 is 51300, loss is -0.009221491291166388\n",
      "[0.5390562 0.4609438]\n",
      "Sensor: [0.34511287928387563, 0.6863467611442825, 0.20892992445179534, 0.2481668786480508], Action prob: [0.5420007  0.45799932], Action: 0, state: 1\n",
      "[0.5420007  0.45799932]\n",
      "Sensor: [0.3505355631504929, 0.6464968452412087, 0.18659177819004366, 0.2674423918970162], Action prob: [0.5436087  0.45639122], Action: 0, state: 1\n",
      "[0.5436087  0.45639122]\n",
      "Sensor: [0.311158460215723, 0.6546758637848348, 0.20725734742889676, 0.2773214012187818], Action prob: [0.5420404  0.45795953], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5420404  0.45795953]\n",
      "Sensor: [0.38689050649685064, 0.6376766917497999, 0.2445087866646313, 0.3062009259455703], Action prob: [0.5401799  0.45982006], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5401799  0.45982006]\n",
      "Sensor: [0.35490575400846414, 0.6329087169168305, 0.20804588501662613, 0.2586768992273047], Action prob: [0.5389268  0.46107325], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5389268  0.46107325]\n",
      "Sensor: [0.32785137239185175, 0.6336795643491431, 0.22116321396183708, 0.21378735150918043], Action prob: [0.5384215 0.4615785], Action: 0, state: 0\n",
      "[0.5384215 0.4615785]\n",
      "Sensor: [0.35383935935348854, 0.660207024332654, 0.19665733984663375, 0.28823275122465397], Action prob: [0.53850925 0.46149078], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.53850925 0.46149078]\n",
      "Sensor: [0.35675047642682955, 0.5753958726910449, 0.20805459257530154, 0.2698476047973671], Action prob: [0.5383994 0.4616006], Action: 0, state: 0\n",
      "tensor([-1.1657, -0.5193,  0.0748, -0.2950,  0.0367,  0.2674,  0.8671,  0.8860],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 192 is 54100, loss is -0.019006934311666016\n",
      "[0.5383994 0.4616006]\n",
      "Sensor: [0.8034109337729372, 0.6574624270011185, 0.2314331840316768, 0.23649293947221608], Action prob: [0.5413811  0.45861894], Action: 0, state: 9\n",
      "[0.5413811  0.45861894]\n",
      "Sensor: [0.33059692419374875, 0.6147813696228354, 0.49366067299255495, 0.2112356052901122], Action prob: [0.5427756 0.4572244], Action: 1, state: 9\n",
      "[0.5427756 0.4572244]\n",
      "Sensor: [0.3972462269123765, 0.6443623848785739, 0.2161334446322516, 0.5792927251303158], Action prob: [0.5415462  0.45845377], Action: 0, state: 9\n",
      "[0.5415462  0.45845377]\n",
      "Sensor: [0.5210640073041367, 0.6520743310315491, 0.2425870455345774, 0.23091228401481179], Action prob: [0.53950024 0.46049976], Action: 0, state: 9\n",
      "[0.53950024 0.46049976]\n",
      "Sensor: [0.5810414725217348, 0.5711277109000819, 0.18897052678848641, 0.22718633045808784], Action prob: [0.5382243  0.46177563], Action: 1, state: 9\n",
      "[0.5382243  0.46177563]\n",
      "Sensor: [0.6255097304086553, 0.6135990084002904, 0.23243448940566316, 0.24598981552676555], Action prob: [0.53786707 0.46213293], Action: 0, state: 9\n",
      "[0.53786707 0.46213293]\n",
      "Sensor: [0.5901330608913967, 0.5799946652164262, 0.22591910742959098, 0.22475178559148157], Action prob: [0.5377063  0.46229365], Action: 1, state: 9\n",
      "[0.5377063  0.46229365]\n",
      "Sensor: [0.3884605769964371, 0.38173306249165073, 0.22484280537039106, 0.2474563572052437], Action prob: [0.5375237  0.46247628], Action: 0, state: 9\n",
      "tensor([ 1.0308,  0.8636,  0.3502,  0.0605, -0.2559, -0.4439, -0.8187, -0.8513],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 200 is 46100, loss is 0.008087343860751744\n",
      "[0.5375237  0.46247628]\n",
      "Sensor: [0.3871639538745424, 0.3534113277039699, 0.1804136549735963, 0.25073774932549725], Action prob: [0.5405861  0.45941386], Action: 0, state: 9\n",
      "[0.5405861  0.45941386]\n",
      "Sensor: [0.3423275008868421, 0.3866445635596606, 0.18121457926135615, 0.24713456444434223], Action prob: [0.54252356 0.4574765 ], Action: 0, state: 9\n",
      "[0.54252356 0.4574765 ]\n",
      "Sensor: [0.3343613561318911, 0.3923857187615492, 0.22018074217571848, 0.29017053715682734], Action prob: [0.54136133 0.45863864], Action: 1, state: 9\n",
      "[0.54136133 0.45863864]\n",
      "Sensor: [0.30645550820614564, 0.3817763412126642, 0.22497950278433934, 0.23676944839944794], Action prob: [0.53970313 0.46029693], Action: 0, state: 9\n",
      "[0.53970313 0.46029693]\n",
      "Sensor: [0.32639159923295935, 0.632050487592083, 0.22158359138210132, 0.5711150866046253], Action prob: [0.539389   0.46061093], Action: 0, state: 9\n",
      "[0.539389   0.46061093]\n",
      "Sensor: [0.5705124615121561, 0.6057282721015467, 0.17483345466504585, 0.2776697408147264], Action prob: [0.538462   0.46153802], Action: 1, state: 9\n",
      "[0.538462   0.46153802]\n",
      "Sensor: [0.3407497292856886, 0.38194791861134647, 0.17177982160755043, 0.19890959113474332], Action prob: [0.53756934 0.46243063], Action: 0, state: 9\n",
      "[0.53756934 0.46243063]\n",
      "Sensor: [0.35391029194466245, 0.4087448399034925, 0.18370383256225709, 0.29562015673912334], Action prob: [0.53782964 0.46217036], Action: 0, state: 9\n",
      "tensor([ 1.0365,  0.6731,  0.4471,  0.0618, -0.2020, -0.5518, -0.6561, -0.8492],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 208 is 38100, loss is 0.005083103882798562\n",
      "[0.53782964 0.46217036]\n",
      "Sensor: [0.564876445459969, 0.6386446793726326, 0.22716384441470713, 0.26547267530697494], Action prob: [0.54068565 0.45931438], Action: 1, state: 9\n",
      "[0.54068565 0.45931438]\n",
      "Sensor: [0.3530483934088235, 0.38594603293652463, 0.26688617514668295, 0.2785045301932604], Action prob: [0.5421226  0.45787743], Action: 1, state: 9\n",
      "[0.5421226  0.45787743]\n",
      "Sensor: [0.3765111375420987, 0.6206705025789103, 0.5010647841323831, 0.24469250790930977], Action prob: [0.5412549  0.45874518], Action: 1, state: 9\n",
      "[0.5412549  0.45874518]\n",
      "Sensor: [0.6026101818931664, 0.6474050637502754, 0.21242548406252057, 0.22635486991167314], Action prob: [0.5398367  0.46016324], Action: 1, state: 9\n",
      "[0.5398367  0.46016324]\n",
      "Sensor: [0.3639295386029489, 0.6245672821591703, 0.20149674694590397, 0.27929686137739845], Action prob: [0.5389167 0.4610833], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -2000\n",
      "[0.5389167 0.4610833]\n",
      "Sensor: [0.3802996930082365, 0.6121158790706214, 0.21390173675465388, 0.29513432545311], Action prob: [0.53868467 0.46131536], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -2000\n",
      "[0.53868467 0.46131536]\n",
      "Sensor: [0.3611742528241671, 0.62919324392988, 0.1802355613493737, 0.24363948728694806], Action prob: [0.53866976 0.46133032], Action: 0, state: 0\n",
      "[0.53866976 0.46133032]\n",
      "Sensor: [0.34970829065490466, 0.6445440036939218, 0.20119196098986428, 0.22513656544284127], Action prob: [0.5387565  0.46124348], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([ 1.3390,  0.7878,  0.2886, -0.1649,  0.2414, -0.4835, -0.9071, -0.8407],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 216 is 33600, loss is -0.03257455687684402\n",
      "[0.5387565  0.46124348]\n",
      "Sensor: [0.3611431353294431, 0.6156692270173659, 0.23132255668460644, 0.26356034083253277], Action prob: [0.54192346 0.4580765 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.54192346 0.4580765 ]\n",
      "Sensor: [0.3700613235480573, 0.6482958593766827, 0.2177526389831816, 0.2663210660040425], Action prob: [0.54416394 0.4558361 ], Action: 0, state: 0\n",
      "[0.54416394 0.4558361 ]\n",
      "Sensor: [0.4216965890232385, 0.6195204598955695, 0.21455549107988783, 0.32867488716206306], Action prob: [0.5431551  0.45684493], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -4500\n",
      "Maintenance in progress, cumulative -3500\n",
      "[0.5431551  0.45684493]\n",
      "Sensor: [0.31303741995192735, 0.632898425089655, 0.1826871909017711, 0.24827614867247946], Action prob: [0.54168516 0.45831487], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.54168516 0.45831487]\n",
      "Sensor: [0.3309520872500323, 0.6851836469557043, 0.19680528435775718, 0.2455062466316121], Action prob: [0.5410085  0.45899156], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5410085  0.45899156]\n",
      "Sensor: [0.3837875834572445, 0.6214762015179377, 0.3027108620706474, 0.24404677302755845], Action prob: [0.54070926 0.45929068], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.54070926 0.45929068]\n",
      "Sensor: [0.39924740554291543, 0.6521778535687819, 0.1811921059540531, 0.21372853163295644], Action prob: [0.54067415 0.45932588], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.54067415 0.45932588]\n",
      "Sensor: [0.3336510466754919, 0.4498487137466995, 0.22902607323274976, 0.2842893727923355], Action prob: [0.5405793 0.4594207], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([ 0.2955,  0.5841,  1.5697, -1.0049, -0.6727, -0.3771, -0.3768, -0.1384],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 224 is 33100, loss is 0.01506955431329831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5405793 0.4594207]\n",
      "Sensor: [0.3489919693817099, 0.6528504831435243, 0.22877261735325194, 0.5395211238894434], Action prob: [0.54248893 0.45751113], Action: 0, state: 0\n",
      "[0.54248893 0.45751113]\n",
      "Sensor: [0.3192999068328893, 0.43156347494144753, 0.2171497064078023, 0.2598180209078446], Action prob: [0.5436518 0.4563482], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5436518 0.4563482]\n",
      "Sensor: [0.35182449516183883, 0.6415180243864596, 0.2032665133054145, 0.20152262690490988], Action prob: [0.5429026  0.45709738], Action: 0, state: 0\n",
      "[0.5429026  0.45709738]\n",
      "Sensor: [0.3004879563655665, 0.620526326186586, 0.27887724993050106, 0.2426469281099668], Action prob: [0.54164255 0.45835742], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.54164255 0.45835742]\n",
      "Sensor: [0.37045076243312836, 0.6376983491248466, 0.21083567154101718, 0.27253973821749594], Action prob: [0.54102606 0.458974  ], Action: 0, state: 0\n",
      "[0.54102606 0.458974  ]\n",
      "Sensor: [0.36076691496930396, 0.6779547996694233, 0.2091657119021808, 0.608087099289482], Action prob: [0.54103    0.45897004], Action: 1, state: 9\n",
      "[0.54103    0.45897004]\n",
      "Sensor: [0.4274675720488262, 0.3851981144586421, 0.21151815836845675, 0.24512743306297768], Action prob: [0.54008853 0.4599115 ], Action: 0, state: 9\n",
      "[0.54008853 0.4599115 ]\n",
      "Sensor: [0.6196097397775993, 0.3932760773695734, 0.17140747179301952, 0.2226963624853445], Action prob: [0.5399555  0.46004456], Action: 1, state: 9\n",
      "tensor([-1.1150, -0.4353,  0.0117,  0.8163,  0.9256,  0.5228, -0.0485, -0.5872],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 232 is 32100, loss is -0.011297095913072527\n",
      "[0.5399555  0.46004456]\n",
      "Sensor: [0.33867118656526873, 0.3476693062973927, 0.20786639279514743, 0.16352331714603924], Action prob: [0.54158485 0.4584151 ], Action: 0, state: 9\n",
      "[0.54158485 0.4584151 ]\n",
      "Sensor: [0.4096385478202339, 0.3841471725904683, 0.24202565128992806, 0.23017087406663655], Action prob: [0.5440602  0.45593986], Action: 0, state: 9\n",
      "[0.5440602  0.45593986]\n",
      "Sensor: [0.3484198533244049, 0.5994292517508896, 0.20840897030094538, 0.5338652686276972], Action prob: [0.5438684  0.45613155], Action: 0, state: 9\n",
      "[0.5438684  0.45613155]\n",
      "Sensor: [0.5613561089960806, 0.6492806977302985, 0.19210759324408122, 0.22700795610473382], Action prob: [0.54191023 0.4580898 ], Action: 1, state: 9\n",
      "[0.54191023 0.4580898 ]\n",
      "Sensor: [0.3173765172097486, 0.3892997432698072, 0.2078068051299514, 0.28105550614167035], Action prob: [0.5406693  0.45933068], Action: 0, state: 9\n",
      "[0.5406693  0.45933068]\n",
      "Sensor: [0.3667247755650394, 0.35961842116716963, 0.18801451229288796, 0.28094430507788615], Action prob: [0.5405676  0.45943236], Action: 0, state: 9\n",
      "[0.5405676  0.45943236]\n",
      "Sensor: [0.3629422585575817, 0.38237498188431635, 0.19947851006122802, 0.2315454278047458], Action prob: [0.54072165 0.4592783 ], Action: 0, state: 9\n",
      "[0.54072165 0.4592783 ]\n",
      "Sensor: [0.31136738720619817, 0.6706193961489799, 0.5322288395545239, 0.27649127615380775], Action prob: [0.54102325 0.45897672], Action: 1, state: 9\n",
      "tensor([ 1.0368,  0.6716,  0.3516,  0.0801, -0.1989, -0.4363, -0.6481, -1.0585],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 240 is 24100, loss is 0.025215207264554118\n",
      "[0.54102325 0.45897672]\n",
      "Sensor: [0.3838300082420305, 0.603859803265673, 0.20122522379878457, 0.545663923852196], Action prob: [0.54188925 0.4581108 ], Action: 0, state: 9\n",
      "[0.54188925 0.4581108 ]\n",
      "Sensor: [0.6042857540479409, 0.6023365686658744, 0.24869917838619032, 0.26501116030268024], Action prob: [0.54292524 0.45707473], Action: 1, state: 9\n",
      "[0.54292524 0.45707473]\n",
      "Sensor: [0.6259116466369834, 0.6581653280554293, 0.22924672077027966, 0.2682500839458652], Action prob: [0.54137397 0.45862606], Action: 0, state: 9\n",
      "[0.54137397 0.45862606]\n",
      "Sensor: [0.30355672098892805, 0.31871222697677914, 0.19982812703913397, 0.2304659904681036], Action prob: [0.5397877  0.46021223], Action: 0, state: 9\n",
      "[0.5397877  0.46021223]\n",
      "Sensor: [0.3433504158018764, 0.3759616027392106, 0.48041106199442707, 0.2779447288155888], Action prob: [0.53949535 0.4605046 ], Action: 0, state: 9\n",
      "[0.53949535 0.4605046 ]\n",
      "Sensor: [0.5614881990144029, 0.3757416764926171, 0.18828375244208054, 0.2962579266878125], Action prob: [0.5395575  0.46044245], Action: 1, state: 9\n",
      "[0.5395575  0.46044245]\n",
      "Sensor: [0.3208412109989766, 0.39289222393641193, 0.5414314672108145, 0.30199684986389186], Action prob: [0.5395247 0.4604753], Action: 1, state: 9\n",
      "[0.5395247 0.4604753]\n",
      "Sensor: [0.6103734914165837, 0.6451034642430719, 0.24118083087643677, 0.2119704376185161], Action prob: [0.53945273 0.4605472 ], Action: 0, state: 9\n",
      "tensor([ 1.0348,  0.8625,  0.3528,  0.0636, -0.1996, -0.5536, -0.8164, -0.8435],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 248 is 16100, loss is 0.012404335181299492\n",
      "[0.53945273 0.4605472 ]\n",
      "Sensor: [0.5542869647297617, 0.3407550962412325, 0.20565728169233086, 0.31250766819840126], Action prob: [0.539361 0.460639], Action: 0, state: 9\n",
      "[0.539361 0.460639]\n",
      "Sensor: [0.5557243059866763, 0.6008311921919655, 0.23251013635564446, 0.24563811261659702], Action prob: [0.5414065 0.4585935], Action: 0, state: 9\n",
      "[0.5414065 0.4585935]\n",
      "Sensor: [0.5707899225464405, 0.5987591061351493, 0.19610500630000272, 0.23069120514337624], Action prob: [0.54003525 0.45996472], Action: 0, state: 9\n",
      "[0.54003525 0.45996472]\n",
      "Sensor: [0.3485691933925712, 0.6347326752014907, 0.4741614900245211, 0.24830697053701492], Action prob: [0.5383532  0.46164683], Action: 0, state: 9\n",
      "[0.5383532  0.46164683]\n",
      "Sensor: [0.5821681343261761, 0.621692389312924, 0.22418659414346706, 0.28970654629905707], Action prob: [0.5376086  0.46239144], Action: 0, state: 9\n",
      "[0.5376086  0.46239144]\n",
      "Sensor: [0.5753809020601349, 0.6250919429834341, 0.2075716857670086, 0.20435611739091286], Action prob: [0.5372324  0.46276754], Action: 0, state: 9\n",
      "[0.5372324  0.46276754]\n",
      "Sensor: [0.5602696417043882, 0.3529458482654409, 0.20986752171542533, 0.2285176364812849], Action prob: [0.5371922  0.46280777], Action: 0, state: 9\n",
      "[0.5371922  0.46280777]\n",
      "Sensor: [0.6000063504669602, 0.6317444938961078, 0.2113444498918556, 0.20042277477739923], Action prob: [0.53741413 0.46258593], Action: 0, state: 9\n",
      "tensor([ 1.0392,  0.6766,  0.3545,  0.0667, -0.2026, -0.4408, -0.6583, -0.8488],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 256 is 8100, loss is 0.001702049996416155\n",
      "[0.53741413 0.46258593]\n",
      "Sensor: [0.4029593186797683, 0.5920083066475887, 0.4777811733517747, 0.24414091118476988], Action prob: [0.5388612  0.46113873], Action: 1, state: 9\n",
      "[0.5388612  0.46113873]\n",
      "Sensor: [0.2927452067043951, 0.598602387896086, 0.2530716784070971, 0.287580128968582], Action prob: [0.5406985  0.45930153], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5406985  0.45930153]\n",
      "Sensor: [0.33125678475737075, 0.6465656926030859, 0.2276905614724832, 0.2681020269369851], Action prob: [0.53945893 0.46054104], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.53945893 0.46054104]\n",
      "Sensor: [0.39628959049941415, 0.6230942893472368, 0.19466013122351475, 0.2745009489038073], Action prob: [0.53802377 0.4619762 ], Action: 0, state: 0\n",
      "[0.53802377 0.4619762 ]\n",
      "Sensor: [0.32728201982196464, 0.6238567229274422, 0.21140609409393352, 0.2700286539976034], Action prob: [0.53725797 0.462742  ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.53725797 0.462742  ]\n",
      "Sensor: [0.36464013200097584, 0.647547878478797, 0.20718476167510955, 0.2639077203997898], Action prob: [0.5370438  0.46295622], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5370438  0.46295622]\n",
      "Sensor: [0.3487626021103996, 0.6161666805378827, 0.18572838672158848, 0.2764651337204054], Action prob: [0.53702193 0.4629781 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.53702193 0.4629781 ]\n",
      "Sensor: [0.35376836443151277, 0.6670942480419821, 0.2530189514997628, 0.27513202798894526], Action prob: [0.537006  0.4629939], Action: 0, state: 0\n",
      "tensor([-1.6281, -0.5996, -0.1330, -0.1077,  0.6153,  0.6146,  0.9169,  0.3010],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 264 is 11100, loss is 0.002571038745439666\n",
      "[0.537006  0.4629939]\n",
      "Sensor: [0.37669194149351576, 0.6991199831378536, 0.22785486130650384, 0.2847127750120306], Action prob: [0.53770626 0.46229377], Action: 0, state: 0\n",
      "[0.53770626 0.46229377]\n",
      "Sensor: [0.37953065449856166, 0.6655570282574669, 0.41555895886795907, 0.2589492791179601], Action prob: [0.53936654 0.46063346], Action: 0, state: 1\n",
      "[0.53936654 0.46063346]\n",
      "Sensor: [0.3749667579851505, 0.6754135593276506, 0.25710358605284583, 0.24283328732112236], Action prob: [0.53833634 0.4616637 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.53833634 0.4616637 ]\n",
      "Sensor: [0.35688459629204694, 0.6236791779652944, 0.2470902321847696, 0.4955950132499063], Action prob: [0.537399   0.46260104], Action: 0, state: 0\n",
      "[0.537399   0.46260104]\n",
      "Sensor: [0.33669543493153886, 0.6774700361733598, 0.2008378884013771, 0.2690018094895679], Action prob: [0.53674173 0.46325827], Action: 0, state: 1\n",
      "[0.53674173 0.46325827]\n",
      "Sensor: [0.37665674917348857, 0.6634747756205018, 0.23746846925700393, 0.2548924476734813], Action prob: [0.53657913 0.46342084], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.53657913 0.46342084]\n",
      "Sensor: [0.35739898824678673, 0.6273072200408691, 0.18692063471890466, 0.2886708941008427], Action prob: [0.53667545 0.46332452], Action: 0, state: 1\n",
      "[0.53667545 0.46332452]\n",
      "Sensor: [0.4575734348321565, 0.6523037563766444, 0.23833173875446925, 0.2594166518243056], Action prob: [0.53675985 0.46324015], Action: 0, state: 1\n",
      "tensor([-1.1322, -0.5566, -0.0550, -0.3049,  0.1163,  0.5568,  0.6008,  0.9047],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for up to this timestep 272 is 16300, loss is -0.016239095700458686\n",
      "[0.53675985 0.46324015]\n",
      "Sensor: [0.3479498782815484, 0.6389725484470499, 0.22984994375383921, 0.2501108224926389], Action prob: [0.536931 0.463069], Action: 0, state: 1\n",
      "[0.536931 0.463069]\n",
      "Sensor: [0.2961368541380089, 0.6218688114852473, 0.20863662211548242, 0.2099632233880842], Action prob: [0.5389411 0.4610589], Action: 0, state: 2\n",
      "[0.5389411 0.4610589]\n",
      "Sensor: [0.37151747957906955, 0.5474045266175748, 0.1982135801872625, 0.25352806652652543], Action prob: [0.5382565  0.46174347], Action: 0, state: 2\n",
      "[0.5382565  0.46174347]\n",
      "Sensor: [0.3071884222562707, 0.5940085459508179, 0.23403106276663324, 0.2334185711556715], Action prob: [0.5375123  0.46248767], Action: 0, state: 2\n",
      "[0.5375123  0.46248767]\n",
      "Sensor: [0.35846418638582, 0.658874827688315, 0.17769094066087765, 0.25010522703403704], Action prob: [0.53716874 0.46283123], Action: 0, state: 2\n",
      "[0.53716874 0.46283123]\n",
      "Sensor: [0.35537503807525755, 0.5818871843890632, 0.17514456832261505, 0.2147562088187114], Action prob: [0.53699315 0.46300682], Action: 0, state: 3\n",
      "[0.53699315 0.46300682]\n",
      "Sensor: [0.3730168743006605, 0.6419015146619433, 0.25825919347489473, 0.21772863015460986], Action prob: [0.537007   0.46299303], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.537007   0.46299303]\n",
      "Sensor: [0.4189613282331235, 0.6559024188292361, 0.18347608061732212, 0.22623732266056518], Action prob: [0.53706473 0.46293527], Action: 0, state: 2\n",
      "tensor([-1.1147, -0.6942, -0.3259,  0.0111,  0.3132,  0.4831,  0.7888,  0.7186],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 280 is 21300, loss is -0.022485039508742255\n",
      "[0.53706473 0.46293527]\n",
      "Sensor: [0.3735885114419579, 0.6467349285104924, 0.2642804578551506, 0.23649987638825873], Action prob: [0.5373015  0.46269846], Action: 0, state: 3\n",
      "[0.5373015  0.46269846]\n",
      "Sensor: [0.31158113239207375, 0.638639857974972, 0.480001862053158, 0.24743016432089818], Action prob: [0.5392779  0.46072203], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.5392779  0.46072203]\n",
      "Sensor: [0.316539595067486, 0.6530794938892317, 0.24666633943095972, 0.2170691468065431], Action prob: [0.5388268 0.4611732], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1100\n",
      "[0.5388268 0.4611732]\n",
      "Sensor: [0.3372382986376042, 0.6505178890852588, 0.23698292310860747, 0.2887610968837341], Action prob: [0.53817886 0.4618212 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.53817886 0.4618212 ]\n",
      "Sensor: [0.32312976231081925, 0.6886995824712708, 0.22595871860536773, 0.21233719929819822], Action prob: [0.5378172  0.46218276], Action: 0, state: 0\n",
      "[0.5378172  0.46218276]\n",
      "Sensor: [0.3223913205639744, 0.6214054871131309, 0.214002517731369, 0.29066346688389827], Action prob: [0.53772956 0.4622704 ], Action: 0, state: 0\n",
      "[0.53772956 0.4622704 ]\n",
      "Sensor: [0.33166266876374983, 0.6282555415097617, 0.21509140055908182, 0.24678166615635394], Action prob: [0.5377055  0.46229455], Action: 0, state: 0\n",
      "[0.5377055  0.46229455]\n",
      "Sensor: [0.3507230972389639, 0.6265611237437257, 0.21444504706517764, 0.23026803048995645], Action prob: [0.5377327  0.46226725], Action: 0, state: 1\n",
      "tensor([-0.6557, -0.2451,  0.0624, -0.9531, -0.4307,  0.1671,  0.7071,  1.1439],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 288 is 25300, loss is 0.025504581702658624\n",
      "[0.5377327  0.46226725]\n",
      "Sensor: [0.3843860592804567, 0.7011929584601554, 0.20439443381622968, 0.27641932425452737], Action prob: [0.53638667 0.4636133 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.53638667 0.4636133 ]\n",
      "Sensor: [0.45827106112490035, 0.5654280405986016, 0.18665069415026883, 0.16047449107887968], Action prob: [0.53781664 0.46218333], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.53781664 0.46218333]\n",
      "Sensor: [0.3233856509366599, 0.7013633751618482, 0.21693145570225478, 0.22098459867895526], Action prob: [0.5375103  0.46248972], Action: 0, state: 0\n",
      "[0.5375103  0.46248972]\n",
      "Sensor: [0.34750128360706073, 0.6448403958919737, 0.2763486463788108, 0.2707538825132444], Action prob: [0.5367048 0.4632952], Action: 0, state: 1\n",
      "[0.5367048 0.4632952]\n",
      "Sensor: [0.3508631918286168, 0.6377814399941596, 0.22129079438957597, 0.27498330390592], Action prob: [0.53629166 0.46370834], Action: 0, state: 1\n",
      "[0.53629166 0.46370834]\n",
      "Sensor: [0.40625931842710106, 0.6101662158746295, 0.20703519791212574, 0.2271146028585116], Action prob: [0.53613466 0.46386534], Action: 0, state: 2\n",
      "[0.53613466 0.46386534]\n",
      "Sensor: [0.34081200522607524, 0.5968877407153668, 0.2165345467748712, 0.2339344292490343], Action prob: [0.53616005 0.46384   ], Action: 0, state: 2\n",
      "[0.53616005 0.46384   ]\n",
      "Sensor: [0.40879769398834526, 0.6048485920297852, 0.2449309954803565, 0.23876450055516796], Action prob: [0.53622174 0.4637783 ], Action: 0, state: 2\n",
      "tensor([-0.9434, -0.5707, -0.7297, -0.2877,  0.1127,  0.4330,  0.7229,  0.9817],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 296 is 30300, loss is 0.035130891220467114\n",
      "[0.53622174 0.4637783 ]\n",
      "Sensor: [0.3747813831720943, 0.6647124087141794, 0.20826041807690418, 0.20141428321076593], Action prob: [0.5335922 0.4664078], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.5335922 0.4664078]\n",
      "Sensor: [0.3618604239521289, 0.6562399953273508, 0.21032794262202492, 0.270124111908301], Action prob: [0.535074   0.46492597], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.535074   0.46492597]\n",
      "Sensor: [0.30311680246234385, 0.6212374514970038, 0.18810811003684022, 0.26016049598431973], Action prob: [0.53416014 0.46583986], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.53416014 0.46583986]\n",
      "Sensor: [0.3446514582762153, 0.6602520271505581, 0.22148865069789486, 0.29797969788884165], Action prob: [0.53315043 0.4668496 ], Action: 0, state: 0\n",
      "[0.53315043 0.4668496 ]\n",
      "Sensor: [0.3585165893852013, 0.3201134908867118, 0.21160693507003075, 0.23046856545146482], Action prob: [0.5324113  0.46758878], Action: 0, state: 0\n",
      "[0.5324113  0.46758878]\n",
      "Sensor: [0.3133632857810344, 0.6144960762684161, 0.25800829259001173, 0.3108299918887225], Action prob: [0.53250575 0.46749422], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.53250575 0.46749422]\n",
      "Sensor: [0.36933979973672615, 0.6478503161476444, 0.19743332610014377, 0.2233216653548223], Action prob: [0.53255266 0.46744725], Action: 0, state: 0\n",
      "[0.53255266 0.46744725]\n",
      "Sensor: [0.3363969201690619, 0.6102183242492552, 0.19734403531550812, 0.27512751280105197], Action prob: [0.53257227 0.46742764], Action: 0, state: 0\n",
      "tensor([-0.9485, -0.5991, -0.5967, -0.4918,  0.0348,  0.5651,  0.6833,  1.0699],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 304 is 35100, loss is 0.03536876714994333\n",
      "[0.53257227 0.46742764]\n",
      "Sensor: [0.3795934356665235, 0.6983961833058686, 0.2326279100638069, 0.25422404376873264], Action prob: [0.5294902  0.47050986], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5294902  0.47050986]\n",
      "Sensor: [0.360330605447172, 0.6677593478483123, 0.2193152184408336, 0.1919465147695841], Action prob: [0.53019774 0.46980226], Action: 0, state: 0\n",
      "[0.53019774 0.46980226]\n",
      "Sensor: [0.37461377461155904, 0.615690714065155, 0.18533390395944213, 0.22418831331862313], Action prob: [0.5289323  0.47106773], Action: 0, state: 0\n",
      "[0.5289323  0.47106773]\n",
      "Sensor: [0.3037614611348525, 0.6486791153772544, 0.19572110945004573, 0.28291354540632824], Action prob: [0.5278609  0.47213915], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5278609  0.47213915]\n",
      "Sensor: [0.38143493397507583, 0.6102546463326308, 0.2053728038704694, 0.2927735487969989], Action prob: [0.5271602  0.47283983], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5271602  0.47283983]\n",
      "Sensor: [0.34228244665841834, 0.6385896816027868, 0.20097252100764926, 0.22702594079655153], Action prob: [0.5269138  0.47308618], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5269138  0.47308618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.304178010021325, 0.6770599837814617, 0.19936476194637784, 0.266527730692558], Action prob: [0.5269598  0.47304028], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5269598  0.47304028]\n",
      "Sensor: [0.36952268827241225, 0.6520850538233164, 0.21947728327584487, 0.2002713317097144], Action prob: [0.5269155  0.47308457], Action: 0, state: 0\n",
      "tensor([-1.1341, -0.9538, -0.3725,  0.1222,  0.3988,  0.6519,  0.6529,  0.7322],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 312 is 39500, loss is -0.0121955158544753\n",
      "[0.5269155  0.47308457]\n",
      "Sensor: [0.3734979985939492, 0.640922335667209, 0.237941523402767, 0.24583902124037185], Action prob: [0.5265405  0.47345942], Action: 0, state: 0\n",
      "[0.5265405  0.47345942]\n",
      "Sensor: [0.38636787705538933, 0.6974409766189084, 0.24599268884314596, 0.2783887899838496], Action prob: [0.5270465  0.47295353], Action: 0, state: 1\n",
      "[0.5270465  0.47295353]\n",
      "Sensor: [0.3146514296741266, 0.620282317204909, 0.21254685943969953, 0.2930913434365957], Action prob: [0.52551824 0.4744818 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.52551824 0.4744818 ]\n",
      "Sensor: [0.3521113607655672, 0.5784044406518765, 0.16092112355204524, 0.6396628431948621], Action prob: [0.524267   0.47573292], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.524267   0.47573292]\n",
      "Sensor: [0.34971664734358293, 0.6213456791757944, 0.19144564961124133, 0.1806874476350447], Action prob: [0.52322394 0.47677606], Action: 0, state: 0\n",
      "[0.52322394 0.47677606]\n",
      "Sensor: [0.3833836011436445, 0.60633321759117, 0.24803235365202042, 0.2894364190474372], Action prob: [0.52300465 0.4769953 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.52300465 0.4769953 ]\n",
      "Sensor: [0.3659443916223138, 0.6110395602136871, 0.21959346602116248, 0.23625786104322466], Action prob: [0.5230874  0.47691265], Action: 0, state: 0\n",
      "[0.5230874  0.47691265]\n",
      "Sensor: [0.3029015491092869, 0.6236270772289568, 0.20495583226584543, 0.2202323695469097], Action prob: [0.52332383 0.47667617], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.1887, -0.6891, -0.2807, -0.0268,  0.1870,  0.6310,  0.5532,  0.9742],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 320 is 44300, loss is -0.020015099606810624\n",
      "[0.52332383 0.47667617]\n",
      "Sensor: [0.29075605046954806, 0.5772239519860368, 0.18749800312458426, 0.29754214910849364], Action prob: [0.52554625 0.47445384], Action: 0, state: 0\n",
      "[0.52554625 0.47445384]\n",
      "Sensor: [0.3868054072283942, 0.6632398066805293, 0.15871823873492258, 0.2867128704298112], Action prob: [0.5260745  0.47392547], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5260745  0.47392547]\n",
      "Sensor: [0.37296898972173076, 0.6498197069217397, 0.18729096131317005, 0.5322956131784091], Action prob: [0.5244649  0.47553512], Action: 0, state: 0\n",
      "[0.5244649  0.47553512]\n",
      "Sensor: [0.2948210415836929, 0.6592378360535307, 0.22772949103197074, 0.24638077430020255], Action prob: [0.522824  0.4771761], Action: 0, state: 0\n",
      "[0.522824  0.4771761]\n",
      "Sensor: [0.3822217548003293, 0.6368285705586857, 0.18142148003182038, 0.21225748870798034], Action prob: [0.52215    0.47785002], Action: 0, state: 1\n",
      "[0.52215    0.47785002]\n",
      "Sensor: [0.3171384993869049, 0.6605826880817616, 0.1996279511585847, 0.2355640258691907], Action prob: [0.52212477 0.4778752 ], Action: 0, state: 1\n",
      "[0.52212477 0.4778752 ]\n",
      "Sensor: [0.34366882028594603, 0.6377393069864761, 0.3665071213153275, 0.2511730672806808], Action prob: [0.5219617  0.47803825], Action: 0, state: 1\n",
      "[0.5219617  0.47803825]\n",
      "Sensor: [0.4273209303491244, 0.6862120692687038, 0.24568187598066404, 0.23619309812507988], Action prob: [0.5219141  0.47808585], Action: 0, state: 2\n",
      "tensor([-1.0378, -0.6379, -0.5542, -0.1517,  0.1701,  0.4635,  0.7266,  0.9351],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 328 is 50300, loss is 0.010790697920487799\n",
      "[0.5219141  0.47808585]\n",
      "Sensor: [0.32762940289415704, 0.6520054805129771, 0.23827861043253126, 0.2013620441868341], Action prob: [0.5238618  0.47613811], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "[0.5238618  0.47613811]\n",
      "Sensor: [0.34193985960970824, 0.6571324704471803, 0.25798287753552607, 0.27282813659638816], Action prob: [0.5240891  0.47591093], Action: 0, state: 2\n",
      "[0.5240891  0.47591093]\n",
      "Sensor: [0.3783811289131661, 0.6080804569618082, 0.22764587879367898, 0.22080293312861965], Action prob: [0.5221654 0.4778346], Action: 0, state: 2\n",
      "[0.5221654 0.4778346]\n",
      "Sensor: [0.3861588078660308, 0.6531164248820023, 0.19162585375874772, 0.23270326407451852], Action prob: [0.520762   0.47923794], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.520762   0.47923794]\n",
      "Sensor: [0.36472167358644536, 0.5995017410309162, 0.23322417544662877, 0.23134337140378927], Action prob: [0.5199498  0.48005018], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -3000\n",
      "[0.5199498  0.48005018]\n",
      "Sensor: [0.33073701146739476, 0.6753077901501, 0.1921006764036359, 0.21590135821790096], Action prob: [0.51977926 0.48022076], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.51977926 0.48022076]\n",
      "Sensor: [0.3517839352849151, 0.6492882241399857, 0.19507735968219422, 0.2861894162941257], Action prob: [0.5197049  0.48029512], Action: 0, state: 0\n",
      "[0.5197049  0.48029512]\n",
      "Sensor: [0.3815047589301031, 0.6600973010707569, 0.22537559186527514, 0.27253195134264235], Action prob: [0.51951516 0.48048478], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.0869, -0.2322,  0.3287,  0.9459,  1.2014, -0.5354, -0.9446, -0.5891],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 336 is 49600, loss is -0.010972115777508784\n",
      "[0.51951516 0.48048478]\n",
      "Sensor: [0.3853979943508045, 0.6379262316930647, 0.25031744420569246, 0.2903475115356888], Action prob: [0.52331156 0.47668839], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.52331156 0.47668839]\n",
      "Sensor: [0.39299648937233456, 0.6236941645194443, 0.22833865703877132, 0.28679262752720763], Action prob: [0.52326125 0.47673872], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.52326125 0.47673872]\n",
      "Sensor: [0.3198326152583184, 0.6377412073834504, 0.24722162562152245, 0.2679015172931924], Action prob: [0.5214709 0.4785291], Action: 0, state: 0\n",
      "[0.5214709 0.4785291]\n",
      "Sensor: [0.3734840353089146, 0.6249138107998337, 0.18517786703408742, 0.25135879150182733], Action prob: [0.5200456 0.4799544], Action: 0, state: 0\n",
      "[0.5200456 0.4799544]\n",
      "Sensor: [0.39203581296557827, 0.6348471414280723, 0.1803214037530016, 0.27050644001618346], Action prob: [0.51929843 0.4807015 ], Action: 0, state: 1\n",
      "[0.51929843 0.4807015 ]\n",
      "Sensor: [0.3586568271470031, 0.6063219119578753, 0.19667946112429197, 0.2109099322226474], Action prob: [0.51897645 0.4810235 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.51897645 0.4810235 ]\n",
      "Sensor: [0.3757646483791034, 0.6150535107851536, 0.22183246636990805, 0.2628271543327459], Action prob: [0.518873   0.48112702], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.518873   0.48112702]\n",
      "Sensor: [0.39879438495204483, 0.5915736746862696, 0.2657231189731182, 0.2527122620406289], Action prob: [0.518716   0.48128405], Action: 0, state: 0\n",
      "tensor([-1.1199, -0.7449, -0.6526, -0.1201,  0.3149,  0.7423,  0.6975,  0.8023],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 344 is 54200, loss is 0.010055187829131132\n",
      "[0.518716   0.48128405]\n",
      "Sensor: [0.3735086812209369, 0.6579341443387718, 0.19969167828124443, 0.21217856174551497], Action prob: [0.522537   0.47746304], Action: 0, state: 0\n",
      "[0.522537   0.47746304]\n",
      "Sensor: [0.37320617150348323, 0.6595827825648093, 0.20569885324557677, 0.2415958857669431], Action prob: [0.5226441  0.47735593], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5226441  0.47735593]\n",
      "Sensor: [0.33750746243259333, 0.6406293586067104, 0.19611182324624288, 0.2185034225273658], Action prob: [0.52093863 0.47906137], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.52093863 0.47906137]\n",
      "Sensor: [0.3551293336397372, 0.653375422095349, 0.21501280289554167, 0.24319892568019907], Action prob: [0.51948065 0.48051932], Action: 0, state: 0\n",
      "[0.51948065 0.48051932]\n",
      "Sensor: [0.33239233401323737, 0.6797945278522408, 0.2202652659236042, 0.2941735144704912], Action prob: [0.5187109  0.48128912], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5187109  0.48128912]\n",
      "Sensor: [0.3060448939028534, 0.5004138972229527, 0.21525859710259684, 0.2662315881006818], Action prob: [0.51824534 0.48175472], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "[0.51824534 0.48175472]\n",
      "Sensor: [0.34054432672470103, 0.6987747660128208, 0.1964661187040383, 0.25927467622403066], Action prob: [0.51821154 0.48178855], Action: 0, state: 0\n",
      "[0.51821154 0.48178855]\n",
      "Sensor: [0.408556876252465, 0.6461689020010404, 0.20766730249711576, 0.2915658832487096], Action prob: [0.51800245 0.48199752], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.1686,  0.0346, -0.6446, -0.0295,  0.9524,  0.9492, -0.3389,  0.4172],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for up to this timestep 352 is 55500, loss is -0.02145991805107638\n",
      "[0.51800245 0.48199752]\n",
      "Sensor: [0.3783254525076366, 0.726149605845133, 0.22044448490160273, 0.29944572067074077], Action prob: [0.52362835 0.4763717 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.52362835 0.4763717 ]\n",
      "Sensor: [0.40911574576951526, 0.5974581885653486, 0.24243230016781395, 0.23700518417699257], Action prob: [0.523569   0.47643104], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -3000\n",
      "[0.523569   0.47643104]\n",
      "Sensor: [0.35573003240394174, 0.6618656988478464, 0.15005624781930027, 0.2656860094701952], Action prob: [0.52222383 0.47777617], Action: 0, state: 0\n",
      "[0.52222383 0.47777617]\n",
      "Sensor: [0.3921623367492459, 0.6147056972358548, 0.19871164010075354, 0.24048814567096433], Action prob: [0.520912   0.47908804], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.520912   0.47908804]\n",
      "Sensor: [0.38287436468025704, 0.5404259122211493, 0.22929325905159223, 0.26287477500483813], Action prob: [0.52013874 0.47986123], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.52013874 0.47986123]\n",
      "Sensor: [0.287268284527499, 0.378040976790498, 0.2291954092151255, 0.2745474203037963], Action prob: [0.5198825  0.48011747], Action: 0, state: 0\n",
      "[0.5198825  0.48011747]\n",
      "Sensor: [0.31363525909013135, 0.6405643501330814, 0.22201495668678906, 0.26877040329152035], Action prob: [0.5199944  0.48000562], Action: 0, state: 0\n",
      "[0.5199944  0.48000562]\n",
      "Sensor: [0.3345697533087434, 0.6312198876583385, 0.21966391156962606, 0.41672711047500444], Action prob: [0.5200227  0.47997734], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([ 1.1579,  1.1558, -0.8395, -0.3851, -0.3852, -0.5703, -0.1589,  0.2311],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 360 is 55400, loss is -0.025724634314149526\n",
      "[0.5200227  0.47997734]\n",
      "Sensor: [0.37464760351333626, 0.5907088786415836, 0.21125713909889124, 0.2766531321876702], Action prob: [0.52596915 0.47403082], Action: 0, state: 0\n",
      "[0.52596915 0.47403082]\n",
      "Sensor: [0.33695467266829676, 0.5686196403680697, 0.2017275809793013, 0.23950400422268678], Action prob: [0.52670443 0.4732956 ], Action: 0, state: 0\n",
      "[0.52670443 0.4732956 ]\n",
      "Sensor: [0.4008348167014131, 0.6653648380914635, 0.2609191682156075, 0.2203558978619165], Action prob: [0.5254901 0.4745099], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5254901 0.4745099]\n",
      "Sensor: [0.3717996906318, 0.6548827294555228, 0.21565168956144243, 0.2473570883570421], Action prob: [0.52444214 0.47555792], Action: 0, state: 0\n",
      "[0.52444214 0.47555792]\n",
      "Sensor: [0.36972781474063776, 0.6637369088701539, 0.21416317596555115, 0.27983188348773663], Action prob: [0.5238774 0.4761226], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "[0.5238774 0.4761226]\n",
      "Sensor: [0.36275878684725815, 0.6396351836959356, 0.22546215544535514, 0.2646034428448205], Action prob: [0.52355415 0.47644582], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.52355415 0.47644582]\n",
      "Sensor: [0.3495476796461949, 0.641944656389775, 0.22120480269227044, 0.25356319589690024], Action prob: [0.5234413 0.4765587], Action: 0, state: 0\n",
      "[0.5234413 0.4765587]\n",
      "Sensor: [0.3662881577166994, 0.6470664968062061, 0.20515102301211027, 0.28111992939105057], Action prob: [0.5234189 0.476581 ], Action: 0, state: 0\n",
      "tensor([-1.3746, -0.5579,  0.2027,  0.1753,  0.8872, -0.0386,  0.2090,  0.6445],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 368 is 59300, loss is -0.018447170798513164\n",
      "[0.5234189 0.476581 ]\n",
      "Sensor: [0.38449344591996315, 0.7019362932103825, 0.22491022581474535, 0.2699420680871118], Action prob: [0.52952725 0.4704727 ], Action: 0, state: 1\n",
      "[0.52952725 0.4704727 ]\n",
      "Sensor: [0.3590340936416977, 0.6045213746357258, 0.22466165535470775, 0.2660171023863513], Action prob: [0.5304473  0.46955267], Action: 0, state: 1\n",
      "[0.5304473  0.46955267]\n",
      "Sensor: [0.29975140900064423, 0.6333360749513107, 0.2480366713377396, 0.22928411751894115], Action prob: [0.52953845 0.47046155], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.52953845 0.47046155]\n",
      "Sensor: [0.35114506003424506, 0.6255190154854329, 0.17055469603249968, 0.2421896745371393], Action prob: [0.5286287 0.4713713], Action: 0, state: 1\n",
      "[0.5286287 0.4713713]\n",
      "Sensor: [0.3631874334643951, 0.6407741987763443, 0.19895707342044716, 0.20560023889944137], Action prob: [0.5280755 0.4719245], Action: 0, state: 2\n",
      "[0.5280755 0.4719245]\n",
      "Sensor: [0.3891373614701435, 0.354204916436264, 0.2151225413283197, 0.2972074967105614], Action prob: [0.5274693  0.47253066], Action: 0, state: 3\n",
      "[0.5274693  0.47253066]\n",
      "Sensor: [0.32309474300179464, 0.5603953439906304, 0.1846521611200243, 0.2687231872379088], Action prob: [0.5275961  0.47240394], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "[0.5275961  0.47240394]\n",
      "Sensor: [0.3184491303435383, 0.6457517883183559, 0.22567870547758684, 0.21303865884178974], Action prob: [0.52771753 0.47228256], Action: 0, state: 2\n",
      "tensor([-1.2588, -0.6110, -0.1099, -0.1533,  0.2681,  0.5004,  0.8421,  0.6432],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 376 is 63300, loss is -0.015084736102054686\n",
      "[0.52771753 0.47228256]\n",
      "Sensor: [0.34670813782791726, 0.5971945721519604, 0.19426751728751065, 0.23837160667220492], Action prob: [0.5330971  0.46690297], Action: 0, state: 2\n",
      "[0.5330971  0.46690297]\n",
      "Sensor: [0.40033956679786215, 0.6015382522103672, 0.1849874114528192, 0.2592605815449362], Action prob: [0.5345293  0.46547073], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.5345293  0.46547073]\n",
      "Sensor: [0.37121939331745607, 0.4593897258413203, 0.18456502104719585, 0.24142151419992827], Action prob: [0.53345937 0.4665406 ], Action: 0, state: 1\n",
      "[0.53345937 0.4665406 ]\n",
      "Sensor: [0.35377950530441915, 0.5712060831813853, 0.20533787506269877, 0.2452437053598542], Action prob: [0.53279847 0.4672016 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.53279847 0.4672016 ]\n",
      "Sensor: [0.37907913889198436, 0.5783592827780907, 0.2205000794488654, 0.2328454189231899], Action prob: [0.53231084 0.4676891 ], Action: 0, state: 0\n",
      "[0.53231084 0.4676891 ]\n",
      "Sensor: [0.2834672241051159, 0.5210794392517665, 0.1790777037511866, 0.23802513203253284], Action prob: [0.5321223 0.4678777], Action: 0, state: 0\n",
      "[0.5321223 0.4678777]\n",
      "Sensor: [0.34497594042128377, 0.6616214457372807, 0.1984152602350681, 0.2724172302639117], Action prob: [0.5322684  0.46773157], Action: 0, state: 1\n",
      "[0.5322684  0.46773157]\n",
      "Sensor: [0.33122000824410686, 0.6033628803024339, 0.2553422347232428, 0.3319134473179106], Action prob: [0.5322104  0.46778953], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.9869, -0.5724, -0.5297, -0.0685, -0.0569,  0.3696,  0.7146,  1.2336],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 384 is 68200, loss is -0.01293137946746964\n",
      "[0.5322104  0.46778953]\n",
      "Sensor: [0.36628663858105526, 0.6704167579782276, 0.24849886445402117, 0.2299065861868379], Action prob: [0.5372482  0.46275184], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5372482  0.46275184]\n",
      "Sensor: [0.34752967421234954, 0.6422130369322229, 0.24653258336015976, 0.21102275570740847], Action prob: [0.5390234  0.46097654], Action: 0, state: 0\n",
      "[0.5390234  0.46097654]\n",
      "Sensor: [0.3162390395937894, 0.6279420057607141, 0.2122045146907765, 0.25711811869083523], Action prob: [0.5385262 0.4614738], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5385262 0.4614738]\n",
      "Sensor: [0.32487624181563873, 0.6538934908255082, 0.2323983100141646, 0.30679403744500683], Action prob: [0.53782   0.4621801], Action: 0, state: 0\n",
      "[0.53782   0.4621801]\n",
      "Sensor: [0.38332670790699386, 0.6199408375612099, 0.19447611532113682, 0.26837177448715555], Action prob: [0.5371481  0.46285185], Action: 0, state: 1\n",
      "[0.5371481  0.46285185]\n",
      "Sensor: [0.35545142868806934, 0.677406882401867, 0.21328827968630154, 0.22101279838721563], Action prob: [0.5369071  0.46309295], Action: 0, state: 1\n",
      "[0.5369071  0.46309295]\n",
      "Sensor: [0.3914981262874136, 0.601869722529461, 0.1833409907109912, 0.25272706605744144], Action prob: [0.5367127  0.46328723], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5367127  0.46328723]\n",
      "Sensor: [0.4650740372683268, 0.626297908456814, 0.20165974108787338, 0.2213601257702007], Action prob: [0.536544   0.46345595], Action: 0, state: 1\n",
      "tensor([-0.9992, -0.8011, -0.4946, -0.1931,  0.1358,  0.4360,  0.7021,  0.9434],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 392 is 74000, loss is 0.03384132793314269\n",
      "[0.536544   0.46345595]\n",
      "Sensor: [0.35860251230097284, 0.6265992552323704, 0.19039658099443868, 0.28336296200159133], Action prob: [0.53922117 0.46077874], Action: 0, state: 2\n",
      "[0.53922117 0.46077874]\n",
      "Sensor: [0.34571405071782246, 0.6669628088018693, 0.2369640416821481, 0.23263658960124192], Action prob: [0.54118294 0.45881706], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.54118294 0.45881706]\n",
      "Sensor: [0.33494290315681247, 0.6050300157189987, 0.23884028459063852, 0.24324851064324832], Action prob: [0.5404849  0.45951504], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.5404849  0.45951504]\n",
      "Sensor: [0.35080156220597974, 0.6469904873698702, 0.19246999543952648, 0.24515926305320515], Action prob: [0.5396635  0.46033648], Action: 0, state: 1\n",
      "[0.5396635  0.46033648]\n",
      "Sensor: [0.36058440144966836, 0.6095926155953172, 0.2558035747521013, 0.19497346792163087], Action prob: [0.5390052 0.4609948], Action: 0, state: 2\n",
      "[0.5390052 0.4609948]\n",
      "Sensor: [0.4007501993425414, 0.6758099028820671, 0.2244533230607007, 0.23312107666198253], Action prob: [0.538858   0.46114206], Action: 0, state: 3\n",
      "[0.538858   0.46114206]\n",
      "Sensor: [0.6096930280586959, 0.6712445214824677, 0.2230762606076918, 0.20403041349218576], Action prob: [0.5384907  0.46150926], Action: 1, state: 8\n",
      "[0.5384907  0.46150926]\n",
      "Sensor: [0.336983998433299, 0.36407491280847387, 0.17777058018260175, 0.24790256442986125], Action prob: [0.53809994 0.46190012], Action: 1, state: 8\n",
      "tensor([-0.3846, -0.0872,  0.1252,  0.3022,  0.6692,  0.8749, -0.3025, -1.5523],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 400 is 67500, loss is 0.044391850735406\n",
      "[0.53809994 0.46190012]\n",
      "Sensor: [0.3933653733395027, 0.32923094975670936, 0.1869585367520999, 0.20642685309515277], Action prob: [0.5383395 0.4616606], Action: 1, state: 8\n",
      "[0.5383395 0.4616606]\n",
      "Sensor: [0.5548592022893637, 0.6519573584792758, 0.18835384086403567, 0.25721005502294914], Action prob: [0.5404934  0.45950654], Action: 1, state: 8\n",
      "[0.5404934  0.45950654]\n",
      "Sensor: [0.37919632036862894, 0.3200608885700924, 0.23388956529368846, 0.23357208091135973], Action prob: [0.5392206  0.46077943], Action: 0, state: 8\n",
      "[0.5392206  0.46077943]\n",
      "Sensor: [0.6580356578241799, 0.42597916908851025, 0.18516375456356712, 0.2269886485124581], Action prob: [0.5381204  0.46187964], Action: 1, state: 8\n",
      "[0.5381204  0.46187964]\n",
      "Sensor: [0.3312023696178069, 0.6425186555790054, 0.2552245276617199, 0.5703955925421088], Action prob: [0.5383135  0.46168646], Action: 1, state: 8\n",
      "[0.5383135  0.46168646]\n",
      "Sensor: [0.2900951660300948, 0.6279514208794178, 0.5329513571619322, 0.28151497775044293], Action prob: [0.5378034  0.46219653], Action: 0, state: 8\n",
      "[0.5378034  0.46219653]\n",
      "Sensor: [0.35394302252392973, 0.657447458277067, 0.5232187421080685, 0.2273102888344019], Action prob: [0.5374988  0.46250123], Action: 0, state: 8\n",
      "[0.5374988  0.46250123]\n",
      "Sensor: [0.3678814691805703, 0.45651846486792796, 0.2285512106251975, 0.21469366914471436], Action prob: [0.5371055  0.46289447], Action: 0, state: 8\n",
      "tensor([ 1.3002,  0.8532,  0.3521,  0.0683, -0.2536, -0.4355, -0.6510, -0.8509],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 408 is 43500, loss is -0.04784410023640259\n",
      "[0.5371055  0.46289447]\n",
      "Sensor: [0.39768427501149034, 0.3729461523567882, 0.22711454181174284, 0.25618588274448584], Action prob: [0.5403628  0.45963725], Action: 0, state: 8\n",
      "[0.5403628  0.45963725]\n",
      "Sensor: [0.3952968466439154, 0.7104806114650848, 0.24220995291362132, 0.5601885832872289], Action prob: [0.5429466  0.45705342], Action: 1, state: 8\n",
      "[0.5429466  0.45705342]\n",
      "Sensor: [0.5654190944245536, 0.6051071443565881, 0.20925955526606965, 0.23801994323802173], Action prob: [0.5414015  0.45859846], Action: 1, state: 8\n",
      "[0.5414015  0.45859846]\n",
      "Sensor: [0.37217095137315953, 0.6246794576088968, 0.23270672870298478, 0.22186384277676974], Action prob: [0.54011995 0.4598801 ], Action: 0, state: 0\n",
      "[0.54011995 0.4598801 ]\n",
      "Sensor: [0.3235033317515418, 0.6921136958865239, 0.23949611543038254, 0.24860935685328964], Action prob: [0.5397287  0.46027124], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5397287  0.46027124]\n",
      "Sensor: [0.3754834994020265, 0.6010946678841734, 0.20792934496961396, 0.22690740203558632], Action prob: [0.5393923  0.46060777], Action: 0, state: 0\n",
      "[0.5393923  0.46060777]\n",
      "Sensor: [0.3745809913195591, 0.6552089302197349, 0.19161029489766487, 0.24591382828667677], Action prob: [0.539384   0.46061602], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.539384   0.46061602]\n",
      "Sensor: [0.31243718113682545, 0.620361882792406, 0.20326310483140791, 0.2532769110969694], Action prob: [0.53937507 0.4606249 ], Action: 0, state: 0\n",
      "tensor([ 1.3807,  0.2678, -1.0713, -0.5249, -0.3000, -0.1127,  0.1495,  0.0159],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 416 is 41500, loss is 0.024377656955321333\n",
      "[0.53937507 0.4606249 ]\n",
      "Sensor: [0.38952624746943976, 0.6017349608786229, 0.2001827249504955, 0.2848383977539317], Action prob: [0.5415974  0.45840257], Action: 0, state: 0\n",
      "[0.5415974  0.45840257]\n",
      "Sensor: [0.37081059980679143, 0.6393070656776754, 0.22414600389337755, 0.3093182137279568], Action prob: [0.5433965  0.45660353], Action: 0, state: 1\n",
      "[0.5433965  0.45660353]\n",
      "Sensor: [0.34530478810848364, 0.6548997767772187, 0.28236915013483443, 0.2533367021353579], Action prob: [0.54236186 0.45763814], Action: 0, state: 2\n",
      "[0.54236186 0.45763814]\n",
      "Sensor: [0.44953721459844964, 0.6560445668285205, 0.24365415589656908, 0.2763202129832179], Action prob: [0.541106 0.458894], Action: 0, state: 2\n",
      "[0.541106 0.458894]\n",
      "Sensor: [0.5499316391587618, 0.629965630568565, 0.23640759031692335, 0.20639335928174346], Action prob: [0.540108 0.459892], Action: 0, state: 3\n",
      "[0.540108 0.459892]\n",
      "Sensor: [0.37749241515700976, 0.7023117508256596, 0.22972697139196266, 0.18817883861492035], Action prob: [0.53992474 0.4600752 ], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -700\n",
      "[0.53992474 0.4600752 ]\n",
      "Sensor: [0.3465430908172113, 0.6497198918384633, 0.2053710432485601, 0.2626324219151151], Action prob: [0.53994894 0.46005112], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.53994894 0.46005112]\n",
      "Sensor: [0.334492250847249, 0.6556765434683395, 0.19031239387777008, 0.23138763022997272], Action prob: [0.5399574  0.46004257], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.2321, -0.6618, -0.2104,  0.1938,  0.4226,  0.8002,  0.4698,  0.6398],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 424 is 44700, loss is -0.05271926907019809\n",
      "[0.5399574  0.46004257]\n",
      "Sensor: [0.3136443315075446, 0.627484734432904, 0.2377192585943288, 0.22701448750798656], Action prob: [0.544404   0.45559594], Action: 0, state: 0\n",
      "[0.544404   0.45559594]\n",
      "Sensor: [0.3303897548975504, 0.6412747779906258, 0.23559287698698778, 0.21834559774685355], Action prob: [0.5464458  0.45355424], Action: 0, state: 1\n",
      "[0.5464458  0.45355424]\n",
      "Sensor: [0.3580458926140925, 0.6048266994866006, 0.33340675806685194, 0.2733971887503194], Action prob: [0.54555756 0.45444247], Action: 0, state: 2\n",
      "[0.54555756 0.45444247]\n",
      "Sensor: [0.37285076687646745, 0.6169159227765515, 0.24041104744964067, 0.21558387679507268], Action prob: [0.5442489  0.45575112], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.5442489  0.45575112]\n",
      "Sensor: [0.30942160204978064, 0.5451788558458406, 0.31640097107346116, 0.4522550039945791], Action prob: [0.54372144 0.45627856], Action: 0, state: 1\n",
      "[0.54372144 0.45627856]\n",
      "Sensor: [0.3594160649696739, 0.6463445607050643, 0.240216240231877, 0.30492918406075], Action prob: [0.54325193 0.45674804], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.54325193 0.45674804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.4274309448363666, 0.6333084785171834, 0.19652382069538074, 0.2227204082565526], Action prob: [0.5428612 0.4571387], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5428612 0.4571387]\n",
      "Sensor: [0.32508523264067746, 0.6303843844427869, 0.1994158725010088, 0.2408603301916351], Action prob: [0.54287875 0.45712125], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.1234, -0.6527, -0.2833,  0.0664,  0.2016,  0.6554,  0.8501,  0.8530],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 432 is 49000, loss is -0.07087244844552072\n",
      "[0.54287875 0.45712125]\n",
      "Sensor: [0.3977741187815285, 0.5914951985308328, 0.24709764903977657, 0.5254123463302116], Action prob: [0.54969865 0.4503013 ], Action: 0, state: 0\n",
      "[0.54969865 0.4503013 ]\n",
      "Sensor: [0.3782606564609678, 0.5852236136917406, 0.19885212478997996, 0.28460712023117357], Action prob: [0.55166763 0.44833237], Action: 0, state: 1\n",
      "[0.55166763 0.44833237]\n",
      "Sensor: [0.3442911077099956, 0.6836954476307388, 0.22750861524646318, 0.23101157815147105], Action prob: [0.5511744  0.44882557], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "[0.5511744  0.44882557]\n",
      "Sensor: [0.297985761891894, 0.6232246995523623, 0.18914297780296713, 0.23026262117912233], Action prob: [0.5501912  0.44980884], Action: 0, state: 0\n",
      "[0.5501912  0.44980884]\n",
      "Sensor: [0.3835133833376471, 0.6634937828765975, 0.21156468670920112, 0.30656990433888587], Action prob: [0.5497845  0.45021552], Action: 0, state: 1\n",
      "[0.5497845  0.45021552]\n",
      "Sensor: [0.3422957655564446, 0.6379292639236359, 0.19732527625282023, 0.3013956565329129], Action prob: [0.5494697 0.4505303], Action: 0, state: 1\n",
      "[0.5494697 0.4505303]\n",
      "Sensor: [0.3671179238594173, 0.5916250331626666, 0.22877352823240787, 0.2641820095756882], Action prob: [0.5491883  0.45081165], Action: 0, state: 2\n",
      "[0.5491883  0.45081165]\n",
      "Sensor: [0.3675478851584696, 0.32167864593097095, 0.1969355508833373, 0.2662204097913446], Action prob: [0.54852384 0.45147613], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "tensor([-1.0038, -0.3248,  0.3795, -0.6264, -0.1376,  0.3056,  0.6599,  1.1345],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 440 is 52700, loss is -0.04836310994191699\n",
      "[0.54852384 0.45147613]\n",
      "Sensor: [0.3765024831007048, 0.6454002891921906, 0.25240762171847986, 0.20999396328250503], Action prob: [0.5559434  0.44405657], Action: 0, state: 2\n",
      "[0.5559434  0.44405657]\n",
      "Sensor: [0.3582816401332997, 0.6089847705946126, 0.1972503579027403, 0.26572090467438686], Action prob: [0.5593296  0.44067028], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.5593296  0.44067028]\n",
      "Sensor: [0.39655845797360223, 0.6531296748287766, 0.226797599396019, 0.2714611958091194], Action prob: [0.5592258  0.44077426], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.5592258  0.44077426]\n",
      "Sensor: [0.3911473264878854, 0.6760331102950063, 0.2693555475225417, 0.24786921141386054], Action prob: [0.55848324 0.44151676], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.55848324 0.44151676]\n",
      "Sensor: [0.3767540099254489, 0.6752794894180103, 0.20050048872163234, 0.30861306988983916], Action prob: [0.55794287 0.44205713], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.55794287 0.44205713]\n",
      "Sensor: [0.35072815022268333, 0.6184906084260644, 0.2293863141285821, 0.29725923498625734], Action prob: [0.5575834 0.4424166], Action: 0, state: 0\n",
      "[0.5575834 0.4424166]\n",
      "Sensor: [0.34913989927460753, 0.6352103580439245, 0.22664345989113588, 0.2615024959538999], Action prob: [0.5574475  0.44255257], Action: 0, state: 0\n",
      "[0.5574475  0.44255257]\n",
      "Sensor: [0.34061040389388403, 0.6765322564676199, 0.19809609859738722, 0.25708024494708515], Action prob: [0.5575012  0.44249874], Action: 0, state: 0\n",
      "tensor([-0.8506, -0.6520, -0.3620, -0.4465, -0.0572,  0.2103,  0.6632,  1.0706],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 448 is 57300, loss is 0.0530254888279047\n",
      "[0.5575012  0.44249874]\n",
      "Sensor: [0.34441612007045225, 0.6590031480238562, 0.2181825820612934, 0.20371881975730213], Action prob: [0.55988014 0.44011986], Action: 0, state: 1\n",
      "[0.55988014 0.44011986]\n",
      "Sensor: [0.3406111480153593, 0.642500654139657, 0.2070787145582366, 0.2807855969984178], Action prob: [0.5637356  0.43626434], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.5637356  0.43626434]\n",
      "Sensor: [0.30381709866695655, 0.6855993285100642, 0.17912699531446627, 0.27961257474709234], Action prob: [0.56362987 0.43637016], Action: 0, state: 0\n",
      "[0.56362987 0.43637016]\n",
      "Sensor: [0.36019211980494076, 0.6155576222253573, 0.2317330300630882, 0.24480524161131326], Action prob: [0.5625197  0.43748024], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -4500\n",
      "Maintenance in progress, cumulative -3500\n",
      "[0.5625197  0.43748024]\n",
      "Sensor: [0.38256820628137145, 0.6846297089249304, 0.18252775760167417, 0.259586999234913], Action prob: [0.5619883  0.43801168], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5619883  0.43801168]\n",
      "Sensor: [0.37335222001530294, 0.5957269711420292, 0.22540485442703959, 0.2262043529397863], Action prob: [0.5615053  0.43849465], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5615053  0.43849465]\n",
      "Sensor: [0.33759032537000233, 0.6255002132716079, 0.1830319393595494, 0.1987027893526488], Action prob: [0.56137145 0.4386286 ], Action: 0, state: 0\n",
      "[0.56137145 0.4386286 ]\n",
      "Sensor: [0.35739569554590006, 0.5880153471626028, 0.19050449635495606, 0.23653611966688054], Action prob: [0.5613437  0.43865636], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([ 0.2744,  1.1778,  0.2715,  1.0244, -1.1974, -0.9112, -0.4573, -0.1931],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 456 is 56600, loss is 0.0013706612745263344\n",
      "[0.5613437  0.43865636]\n",
      "Sensor: [0.37772792583385395, 0.7032323793820683, 0.18088657862367843, 0.2859940208008264], Action prob: [0.56364006 0.43635994], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -4500\n",
      "Maintenance in progress, cumulative -3500\n",
      "[0.56364006 0.43635994]\n",
      "Sensor: [0.3276274300549464, 0.6402913435839409, 0.20794895331632612, 0.28623691553764646], Action prob: [0.5675168  0.43248317], Action: 0, state: 0\n",
      "[0.5675168  0.43248317]\n",
      "Sensor: [0.33994007686696115, 0.6634393432854944, 0.20320869964075636, 0.2112062850874664], Action prob: [0.56707937 0.4329206 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.56707937 0.4329206 ]\n",
      "Sensor: [0.34504917514699984, 0.6233097129320722, 0.22555791084858023, 0.16924559217573432], Action prob: [0.56584096 0.43415907], Action: 0, state: 0\n",
      "[0.56584096 0.43415907]\n",
      "Sensor: [0.3407067085976417, 0.6605142903527956, 0.2591330723797196, 0.24397880395363686], Action prob: [0.56550103 0.434499  ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.56550103 0.434499  ]\n",
      "Sensor: [0.2969500069649254, 0.6564730761416657, 0.18072949763606444, 0.4673600667507113], Action prob: [0.56563944 0.43436056], Action: 0, state: 0\n",
      "[0.56563944 0.43436056]\n",
      "Sensor: [0.39628462507086065, 0.6298353822720715, 0.21734666465756575, 0.26261158254735256], Action prob: [0.5650572 0.4349428], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5650572 0.4349428]\n",
      "Sensor: [0.34295972108619355, 0.6268510557891891, 0.24270429105415917, 0.24011712717280134], Action prob: [0.5648263  0.43517366], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([ 1.5284, -0.9218, -0.6140, -0.4177, -0.0084, -0.0077,  0.4269,  0.6484],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 464 is 57000, loss is -0.07926582489278869\n",
      "[0.5648263  0.43517366]\n",
      "Sensor: [0.3345260896925226, 0.6558871651185354, 0.23704488583396308, 0.2246324762741686], Action prob: [0.5693944 0.4306056], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5693944 0.4306056]\n",
      "Sensor: [0.2919054671854266, 0.6328782716443162, 0.32503095497565554, 0.28139838676128126], Action prob: [0.57430196 0.42569807], Action: 0, state: 0\n",
      "[0.57430196 0.42569807]\n",
      "Sensor: [0.3815283056085615, 0.6505793114482861, 0.20830322178396163, 0.39148476199282267], Action prob: [0.5742608  0.42573932], Action: 0, state: 0\n",
      "[0.5742608  0.42573932]\n",
      "Sensor: [0.3628121900451836, 0.6652191727367857, 0.20071660524695945, 0.2562307769317328], Action prob: [0.57285523 0.42714474], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.57285523 0.42714474]\n",
      "Sensor: [0.37431876429453104, 0.6264466470665412, 0.20863693904165007, 0.25170914764387886], Action prob: [0.5718653 0.4281347], Action: 0, state: 0\n",
      "[0.5718653 0.4281347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3442641987255054, 0.6324171796962579, 0.19937953433898467, 0.22473724196193867], Action prob: [0.5714544  0.42854553], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5714544  0.42854553]\n",
      "Sensor: [0.3724505863405753, 0.6680234031166068, 0.20859313639084942, 0.22617469002077328], Action prob: [0.5715161  0.42848387], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.5715161  0.42848387]\n",
      "Sensor: [0.3284166545677976, 0.6429023447133648, 0.21492074779753628, 0.2757428516299399], Action prob: [0.5716151  0.42838493], Action: 0, state: 0\n",
      "tensor([-1.2827, -0.8433, -0.2396,  0.4745,  0.0629,  0.7739,  1.0787,  0.3501],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 472 is 58000, loss is -0.04680086818978426\n",
      "[0.5716151  0.42838493]\n",
      "Sensor: [0.37740850426357503, 0.3296363448447999, 0.24221683901222002, 0.2519723871245454], Action prob: [0.5752869  0.42471316], Action: 0, state: 9\n",
      "[0.5752869  0.42471316]\n",
      "Sensor: [0.362622962649397, 0.37994580908374326, 0.19387109355288717, 0.24088456573383454], Action prob: [0.5805374 0.4194627], Action: 1, state: 9\n",
      "[0.5805374 0.4194627]\n",
      "Sensor: [0.3509656554427522, 0.44529547194437735, 0.25064045492080744, 0.5863078629589308], Action prob: [0.5822424  0.41775757], Action: 1, state: 9\n",
      "[0.5822424  0.41775757]\n",
      "Sensor: [0.32099647860699887, 0.675453555375725, 0.19798368969929997, 0.2945213746520698], Action prob: [0.58171463 0.4182854 ], Action: 0, state: 0\n",
      "[0.58171463 0.4182854 ]\n",
      "Sensor: [0.35664315853381123, 0.634144628104337, 0.2383961483762771, 0.43342061802973286], Action prob: [0.58148295 0.41851708], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.58148295 0.41851708]\n",
      "Sensor: [0.3624740409568086, 0.643500724722808, 0.23451067375826498, 0.2612328595056648], Action prob: [0.5807923 0.4192077], Action: 0, state: 0\n",
      "[0.5807923 0.4192077]\n",
      "Sensor: [0.3556176479103063, 0.6997874512308053, 0.24040675837949715, 0.27964751144515126], Action prob: [0.58088297 0.41911694], Action: 0, state: 1\n",
      "[0.58088297 0.41911694]\n",
      "Sensor: [0.3911211315552765, 0.5864039863763156, 0.21281806587704008, 0.2531011906736394], Action prob: [0.5803947  0.41960528], Action: 0, state: 1\n",
      "tensor([ 2.2528e-01, -6.4196e-01, -1.5484e+00, -4.5125e-01, -5.7137e-04,\n",
      "         2.0577e-01,  5.3791e-01,  8.3477e-01], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 480 is 61200, loss is 0.10480397198181628\n",
      "[0.5803947  0.41960528]\n",
      "Sensor: [0.3737566960664081, 0.6305076547150781, 0.2316784219696414, 0.2347212237782956], Action prob: [0.5795408 0.4204593], Action: 0, state: 1\n",
      "[0.5795408 0.4204593]\n",
      "Sensor: [0.38785178438464135, 0.6346696442284494, 0.20444195241943636, 0.23014297240735676], Action prob: [0.5853871  0.41461286], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1100\n",
      "[0.5853871  0.41461286]\n",
      "Sensor: [0.43972038666553365, 0.6524699227104799, 0.23380112270855744, 0.26486083095757557], Action prob: [0.5859417  0.41405827], Action: 0, state: 1\n",
      "[0.5859417  0.41405827]\n",
      "Sensor: [0.4500086334341624, 0.6161655635621324, 0.22002749833066887, 0.24385850903110187], Action prob: [0.58475685 0.41524315], Action: 0, state: 1\n",
      "[0.58475685 0.41524315]\n",
      "Sensor: [0.37427704237949094, 0.6397851897985346, 0.20403257710366585, 0.32053910180694734], Action prob: [0.58426726 0.41573268], Action: 0, state: 1\n",
      "[0.58426726 0.41573268]\n",
      "Sensor: [0.38218039223553546, 0.620505718808946, 0.22773255976678963, 0.23870200583263146], Action prob: [0.58376294 0.41623706], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.58376294 0.41623706]\n",
      "Sensor: [0.3834300673584704, 0.6027249912632032, 0.2330926131284773, 0.22848946699514638], Action prob: [0.5835277  0.41647238], Action: 0, state: 1\n",
      "[0.5835277  0.41647238]\n",
      "Sensor: [0.35241355279683273, 0.615312771566459, 0.20136849137280213, 0.21884781580002505], Action prob: [0.58344394 0.4165561 ], Action: 0, state: 2\n",
      "tensor([-0.6610, -0.2563, -0.7662, -0.3192,  0.0878,  0.6740,  0.5607,  0.8254],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 488 is 65500, loss is -0.018145814748539282\n",
      "[0.58344394 0.4165561 ]\n",
      "Sensor: [0.3873564620487498, 0.6615558177796198, 0.20044326958834788, 0.2548691340829692], Action prob: [0.58315873 0.4168412 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.58315873 0.4168412 ]\n",
      "Sensor: [0.3765967515953709, 0.6518933340087537, 0.22637912002864333, 0.3022343961797158], Action prob: [0.58951634 0.41048366], Action: 0, state: 1\n",
      "[0.58951634 0.41048366]\n",
      "Sensor: [0.44136934876666994, 0.6817580462586859, 0.24159642879052537, 0.2924953158413526], Action prob: [0.5899379  0.41006202], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5899379  0.41006202]\n",
      "Sensor: [0.3966060091916166, 0.6103043299056972, 0.2164379085362197, 0.24853960242631187], Action prob: [0.5883555  0.41164446], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5883555  0.41164446]\n",
      "Sensor: [0.30832349464010694, 0.6760364536563002, 0.21040023970092214, 0.5195386140872715], Action prob: [0.5884594 0.4115407], Action: 0, state: 0\n",
      "[0.5884594 0.4115407]\n",
      "Sensor: [0.3273422874659296, 0.6251916735390007, 0.2394810901717253, 0.22183784609347712], Action prob: [0.58733964 0.4126604 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.58733964 0.4126604 ]\n",
      "Sensor: [0.39004636922942726, 0.608736426779048, 0.21517537394482927, 0.24059754472160766], Action prob: [0.5869067 0.4130933], Action: 0, state: 0\n",
      "[0.5869067 0.4130933]\n",
      "Sensor: [0.364248122217759, 0.692025804176418, 0.2731927690801962, 0.21929414885068355], Action prob: [0.5873238  0.41267624], Action: 0, state: 1\n",
      "tensor([-1.5198, -0.6276, -0.0689, -0.0685, -0.0401,  0.7328,  0.4390,  0.7905],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 496 is 69600, loss is 0.045324397542945025\n",
      "[0.5873238  0.41267624]\n",
      "Sensor: [0.3900427418467833, 0.6737770470822719, 0.25771698972952056, 0.20864282401118223], Action prob: [0.5849584 0.4150416], Action: 0, state: 1\n",
      "[0.5849584 0.4150416]\n",
      "Sensor: [0.3471914793232917, 0.5921919744892495, 0.21545648385399477, 0.23866104661598608], Action prob: [0.59082866 0.40917137], Action: 0, state: 2\n",
      "[0.59082866 0.40917137]\n",
      "Sensor: [0.3784044162958852, 0.5796789839362012, 0.22082297687822391, 0.2581311790131667], Action prob: [0.5908869 0.4091131], Action: 0, state: 2\n",
      "[0.5908869 0.4091131]\n",
      "Sensor: [0.42959944543294837, 0.6248730295545867, 0.23152000609994863, 0.25961196901115885], Action prob: [0.58984685 0.4101532 ], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.58984685 0.4101532 ]\n",
      "Sensor: [0.37205885916815673, 0.6175849534687561, 0.2424567896232877, 0.25800701509460994], Action prob: [0.5889565 0.4110435], Action: 0, state: 2\n",
      "[0.5889565 0.4110435]\n",
      "Sensor: [0.39036521551037134, 0.6709287770763698, 0.22637061281463003, 0.2760271626247409], Action prob: [0.58881664 0.41118342], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.58881664 0.41118342]\n",
      "Sensor: [0.38243827493964777, 0.5327532705730151, 0.17217315809176076, 0.29000486507603546], Action prob: [0.58793706 0.41206297], Action: 0, state: 1\n",
      "[0.58793706 0.41206297]\n",
      "Sensor: [0.3885779297833054, 0.6833953378669703, 0.2096221555472686, 0.26942969208921674], Action prob: [0.5883675 0.4116325], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.0211, -0.5683, -0.1781,  0.0702,  0.1626,  0.7547,  0.4161,  1.1381],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 504 is 74100, loss is -0.09676756878508921\n",
      "[0.5883675 0.4116325]\n",
      "Sensor: [0.3635965356655142, 0.5627682264115809, 0.24674006491931627, 0.29524777826406945], Action prob: [0.5895114  0.41048864], Action: 0, state: 0\n",
      "[0.5895114  0.41048864]\n",
      "Sensor: [0.3648317119739241, 0.6178190510134295, 0.23612675132141064, 0.25557264567971943], Action prob: [0.596442   0.40355796], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.596442   0.40355796]\n",
      "Sensor: [0.3750283053290541, 0.6492294004812634, 0.1953561565207384, 0.3114696075940484], Action prob: [0.5970793  0.40292072], Action: 0, state: 0\n",
      "[0.5970793  0.40292072]\n",
      "Sensor: [0.34414726738395635, 0.6338114845491751, 0.22728831151899925, 0.18205087000056194], Action prob: [0.59544814 0.4045519 ], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59544814 0.4045519 ]\n",
      "Sensor: [0.3178533710664275, 0.6060621955808168, 0.24777263566154226, 0.25439132653394037], Action prob: [0.5945572 0.4054427], Action: 0, state: 0\n",
      "[0.5945572 0.4054427]\n",
      "Sensor: [0.349471660517328, 0.5746771563993046, 0.2203957046660492, 0.21358286629376738], Action prob: [0.59375733 0.40624264], Action: 0, state: 0\n",
      "[0.59375733 0.40624264]\n",
      "Sensor: [0.3518126335395816, 0.6494970532239457, 0.19565688573566006, 0.2508347915391195], Action prob: [0.593922   0.40607798], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.593922   0.40607798]\n",
      "Sensor: [0.32789232128658863, 0.6897783956059418, 0.23354919160858417, 0.23512706269515218], Action prob: [0.5942609  0.40573916], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.8203, -0.8000, -0.4553, -0.1439,  0.1373,  0.3906,  1.0715,  1.2535],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 512 is 80000, loss is -0.07916921831438992\n",
      "[0.5942609  0.40573916]\n",
      "Sensor: [0.39063073964308703, 0.5921757415225553, 0.21360570294308825, 0.23947203941442413], Action prob: [0.59640914 0.4035908 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.59640914 0.4035908 ]\n",
      "Sensor: [0.35041198706786075, 0.62488864602022, 0.22233690493249303, 0.2102496462846966], Action prob: [0.604513 0.395487], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.604513 0.395487]\n",
      "Sensor: [0.3577014143374259, 0.6992057061631075, 0.22691510140339896, 0.2798484783761077], Action prob: [0.6062592  0.39374077], Action: 0, state: 0\n",
      "[0.6062592  0.39374077]\n",
      "Sensor: [0.35034283818941575, 0.5639141748967264, 0.22359308599689476, 0.22972307321299032], Action prob: [0.6044232  0.39557678], Action: 0, state: 0\n",
      "[0.6044232  0.39557678]\n",
      "Sensor: [0.3692952368940875, 0.6046160796917858, 0.20946980134954132, 0.22762590837812952], Action prob: [0.6033894  0.39661062], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6033894  0.39661062]\n",
      "Sensor: [0.35072464825868244, 0.6517594882083684, 0.21406647577208565, 0.24290738203805629], Action prob: [0.60326695 0.39673308], Action: 0, state: 0\n",
      "[0.60326695 0.39673308]\n",
      "Sensor: [0.37146762501395647, 0.6891108985591077, 0.19027821431294906, 0.1960607603347987], Action prob: [0.6031979 0.3968021], Action: 0, state: 0\n",
      "[0.6031979 0.3968021]\n",
      "Sensor: [0.3552308115090105, 0.6653883923130208, 0.2330200637074968, 0.2285718723640527], Action prob: [0.6033197  0.39668033], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.5438, -1.3873, -0.5454, -0.1833,  0.2696,  0.2974,  0.5660,  1.4337],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 520 is 84400, loss is 0.01165183653316526\n",
      "[0.6033197  0.39668033]\n",
      "Sensor: [0.32861656851491106, 0.6372643575386531, 0.2087303050539235, 0.21690787848309906], Action prob: [0.6028095  0.39719048], Action: 0, state: 0\n",
      "[0.6028095  0.39719048]\n",
      "Sensor: [0.35266120954211444, 0.6247720948334077, 0.2029639065102626, 0.2604909915611577], Action prob: [0.61225057 0.38774937], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.61225057 0.38774937]\n",
      "Sensor: [0.29920429892722195, 0.6118439233889839, 0.23322572991471038, 0.22661995281827704], Action prob: [0.61378914 0.38621083], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.61378914 0.38621083]\n",
      "Sensor: [0.34167246384197403, 0.6995341032571646, 0.35321920071293533, 0.26338218598203367], Action prob: [0.61431247 0.38568756], Action: 0, state: 0\n",
      "[0.61431247 0.38568756]\n",
      "Sensor: [0.3553836404495893, 0.6192796193931774, 0.22131667437267477, 0.26735677548722253], Action prob: [0.61299807 0.38700193], Action: 0, state: 1\n",
      "[0.61299807 0.38700193]\n",
      "Sensor: [0.2960458249611263, 0.6762780202707456, 0.2312267050451776, 0.24367848765366573], Action prob: [0.61258674 0.38741326], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "[0.61258674 0.38741326]\n",
      "Sensor: [0.3974717141549041, 0.6233557357852507, 0.20262662078704125, 0.23910579508983196], Action prob: [0.6120842  0.38791582], Action: 0, state: 1\n",
      "[0.6120842  0.38791582]\n",
      "Sensor: [0.3423024554121545, 0.6485670017748002, 0.22417612219215471, 0.2566550565155019], Action prob: [0.61214167 0.38785827], Action: 0, state: 2\n",
      "tensor([-1.0043, -0.7761, -0.2767, -0.1402,  0.2309,  1.0328,  0.3285,  0.5736],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 528 is 88300, loss is 0.003941733359414126\n",
      "[0.61214167 0.38785827]\n",
      "Sensor: [0.357573650301227, 0.6592807463739111, 0.18359282903883753, 0.260821337650472], Action prob: [0.6087618  0.39123824], Action: 0, state: 3\n",
      "[0.6087618  0.39123824]\n",
      "Sensor: [0.587907041171588, 0.6018730065578728, 0.2178781849124908, 0.20071507168330863], Action prob: [0.61880606 0.38119394], Action: 0, state: 8\n",
      "[0.61880606 0.38119394]\n",
      "Sensor: [0.45561047457817805, 0.6362821154877469, 0.7006400817203574, 0.19512540610855897], Action prob: [0.622494 0.377506], Action: 0, state: 8\n",
      "[0.622494 0.377506]\n",
      "Sensor: [0.5967224225901823, 0.3906031551945219, 0.21523458856436384, 0.23651634483894898], Action prob: [0.61955494 0.380445  ], Action: 0, state: 8\n",
      "[0.61955494 0.380445  ]\n",
      "Sensor: [0.34483497346551584, 0.579291228330153, 0.19800700365070764, 0.5495332773518823], Action prob: [0.62036127 0.37963876], Action: 0, state: 8\n",
      "[0.62036127 0.37963876]\n",
      "Sensor: [0.41252042498261654, 0.6742346276340789, 0.507766750610599, 0.2905557679994927], Action prob: [0.62170887 0.37829116], Action: 0, state: 8\n",
      "[0.62170887 0.37829116]\n",
      "Sensor: [0.37868544548891375, 0.35732568405743664, 0.20139353925349654, 0.2454018773719244], Action prob: [0.6183108 0.3816892], Action: 1, state: 8\n",
      "[0.6183108 0.3816892]\n",
      "Sensor: [0.34888018196195975, 0.6078169296164417, 0.237963060772321, 0.5917972153613088], Action prob: [0.62022144 0.37977853], Action: 0, state: 8\n",
      "tensor([ 0.8375,  0.5240,  0.2769,  0.0403, -0.1578, -0.3349, -1.0253, -0.6547],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 536 is 64300, loss is 0.061757680627605935\n",
      "[0.62022144 0.37977853]\n",
      "Sensor: [0.31184414673560346, 0.38315346153217394, 0.20488886351282876, 0.22804782145229577], Action prob: [0.6097579  0.39024207], Action: 1, state: 8\n",
      "[0.6097579  0.39024207]\n",
      "Sensor: [0.32998717599210003, 0.35043745263632703, 0.21257677049853652, 0.22826123334177034], Action prob: [0.6194412  0.38055882], Action: 0, state: 8\n",
      "[0.6194412  0.38055882]\n",
      "Sensor: [0.3708869575777038, 0.37943422063520843, 0.2222445622758305, 0.20087332064388697], Action prob: [0.6217979  0.37820208], Action: 1, state: 8\n",
      "[0.6217979  0.37820208]\n",
      "Sensor: [0.8739565297047283, 0.6782371042301032, 0.17822998298508777, 0.23062053065613378], Action prob: [0.62373775 0.37626228], Action: 1, state: 8\n",
      "[0.62373775 0.37626228]\n",
      "Sensor: [0.33170462076896945, 0.3709717639746659, 0.23027565955666168, 0.5856900829945039], Action prob: [0.62361497 0.376385  ], Action: 0, state: 8\n",
      "[0.62361497 0.376385  ]\n",
      "Sensor: [0.476000536089783, 0.40776293194055935, 0.20587679467393874, 0.2935559143690969], Action prob: [0.62217396 0.37782604], Action: 0, state: 8\n",
      "[0.62217396 0.37782604]\n",
      "Sensor: [0.3605335670889875, 0.6006557415135472, 0.5507762965569, 0.2811913710087656], Action prob: [0.6246369 0.3753631], Action: 0, state: 8\n",
      "[0.6246369 0.3753631]\n",
      "Sensor: [0.33164606374953554, 0.6335005084664769, 0.25238500764063165, 0.5429390117610753], Action prob: [0.62596846 0.37403157], Action: 1, state: 8\n",
      "tensor([ 1.5843,  0.5252,  0.5533,  0.0771, -0.1576, -0.3424, -0.4933, -1.3448],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 544 is 40300, loss is -0.05023232780006501\n",
      "[0.62596846 0.37403157]\n",
      "Sensor: [0.4579025201297227, 0.3809583954861722, 0.5323743796534863, 0.1893041017377372], Action prob: [0.616032 0.383968], Action: 0, state: 8\n",
      "[0.616032 0.383968]\n",
      "Sensor: [0.3507981997547522, 0.3995895729369349, 0.20282459912820464, 0.451348028400953], Action prob: [0.6267274  0.37327257], Action: 1, state: 8\n",
      "[0.6267274  0.37327257]\n",
      "Sensor: [0.6207136184177503, 0.6366405308589544, 0.2240067426465921, 0.2616326850989461], Action prob: [0.63056153 0.36943844], Action: 1, state: 8\n",
      "[0.63056153 0.36943844]\n",
      "Sensor: [0.47906336551103923, 0.4033607899291715, 0.20565951963113216, 0.23184285954035844], Action prob: [0.62886435 0.37113556], Action: 0, state: 8\n",
      "[0.62886435 0.37113556]\n",
      "Sensor: [0.5552443711171753, 0.583873607145151, 0.14559095527720434, 0.27199986599204146], Action prob: [0.6292842  0.37071574], Action: 1, state: 8\n",
      "[0.6292842  0.37071574]\n",
      "Sensor: [0.33080453572731056, 0.39051462945796617, 0.24178803341133007, 0.23324240987805947], Action prob: [0.6280767 0.3719233], Action: 0, state: 8\n",
      "[0.6280767 0.3719233]\n",
      "Sensor: [0.5818833751831615, 0.6192768071756711, 0.21111242488686616, 0.2142243613304169], Action prob: [0.629396   0.37060395], Action: 0, state: 8\n",
      "[0.629396   0.37060395]\n",
      "Sensor: [0.6229251176451969, 0.6833098320647892, 0.2028272189698728, 0.25388468710920886], Action prob: [0.63067186 0.3693281 ], Action: 1, state: 8\n",
      "tensor([ 0.8179,  1.0811,  0.5632,  0.0425, -0.3336, -0.3313, -0.4928, -1.3709],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for up to this timestep 552 is 16300, loss is 0.002985559552093009\n",
      "[0.63067186 0.3693281 ]\n",
      "Sensor: [0.34286291136934277, 0.3141029193378079, 0.18063410068107347, 0.24204095567070713], Action prob: [0.617845   0.38215503], Action: 1, state: 8\n",
      "[0.617845   0.38215503]\n",
      "Sensor: [0.42238386534959227, 0.7005827575726407, 0.18225767625033706, 0.5555371884056932], Action prob: [0.63392085 0.36607915], Action: 0, state: 8\n",
      "[0.63392085 0.36607915]\n",
      "Sensor: [0.5548901246152558, 0.6697132356038975, 0.2160336206922892, 0.22781739808088536], Action prob: [0.6368388 0.3631612], Action: 0, state: 8\n",
      "[0.6368388 0.3631612]\n",
      "Sensor: [0.33998131924316805, 0.4161566432524123, 0.23655000096382606, 0.23506478059046496], Action prob: [0.6348113 0.3651888], Action: 0, state: 8\n",
      "[0.6348113 0.3651888]\n",
      "Sensor: [0.34647333623039084, 0.3793556402113556, 0.23351607691582954, 0.23064417965510492], Action prob: [0.6334004  0.36659965], Action: 1, state: 8\n",
      "[0.6334004  0.36659965]\n",
      "Sensor: [0.32050413563370905, 0.6185323884437319, 0.19295044087132582, 0.26296476367945903], Action prob: [0.6348535  0.36514652], Action: 0, state: 0\n",
      "[0.6348535  0.36514652]\n",
      "Sensor: [0.40680526942769907, 0.6129091285905247, 0.25662900387001775, 0.2983635670325785], Action prob: [0.6361925  0.36380744], Action: 0, state: 1\n",
      "[0.6361925  0.36380744]\n",
      "Sensor: [0.36180554646944985, 0.6678198211493576, 0.2274125097324396, 0.22310602721024025], Action prob: [0.63647497 0.36352494], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "tensor([ 1.9216,  0.5118,  0.1476, -0.1735, -1.0278, -0.3753, -0.3042, -0.5356],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 560 is 6600, loss is -0.020592552374263634\n",
      "[0.63647497 0.36352494]\n",
      "Sensor: [0.36091202232010405, 0.6723077491649296, 0.21235034023009194, 0.26605802518246646], Action prob: [0.62548095 0.37451902], Action: 0, state: 0\n",
      "[0.62548095 0.37451902]\n",
      "Sensor: [0.3235379869870303, 0.662497486654077, 0.19959370258039272, 0.28505698907160854], Action prob: [0.6380829  0.36191705], Action: 0, state: 1\n",
      "[0.6380829  0.36191705]\n",
      "Sensor: [0.34525916218626884, 0.6205189959989814, 0.21604027810126772, 0.23708451475533765], Action prob: [0.6411406  0.35885936], Action: 0, state: 2\n",
      "[0.6411406  0.35885936]\n",
      "Sensor: [0.3670378294339716, 0.7352399919045879, 0.21521315973422497, 0.24950776793350873], Action prob: [0.6423264 0.3576736], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.6423264 0.3576736]\n",
      "Sensor: [0.27609787954467835, 0.6374761463328382, 0.21524750494916767, 0.29688206181461524], Action prob: [0.6418878  0.35811228], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6418878  0.35811228]\n",
      "Sensor: [0.37896085409811475, 0.638105892437765, 0.22516332976649453, 0.263901741407564], Action prob: [0.64156866 0.3584313 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.64156866 0.3584313 ]\n",
      "Sensor: [0.38156910567921315, 0.6160060762933854, 0.20232804754477154, 0.19184644819730834], Action prob: [0.64066744 0.35933256], Action: 0, state: 0\n",
      "[0.64066744 0.35933256]\n",
      "Sensor: [0.35184660646053934, 0.6405216328800171, 0.19080628195784802, 0.3118950811120149], Action prob: [0.6411938 0.3588062], Action: 0, state: 1\n",
      "tensor([-0.8688, -0.4792, -0.1959,  0.1295,  0.3914,  0.6800,  0.4092,  0.5941],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 568 is 12300, loss is -0.0825348622459716\n",
      "[0.6411938 0.3588062]\n",
      "Sensor: [0.35976180595956575, 0.6701149716768536, 0.17051432044812073, 0.2710200581450558], Action prob: [0.6322782  0.36772177], Action: 0, state: 1\n",
      "[0.6322782  0.36772177]\n",
      "Sensor: [0.35329738646392383, 0.603998197222518, 0.20176728520347914, 0.2805342180406966], Action prob: [0.6454218  0.35457823], Action: 0, state: 1\n",
      "[0.6454218  0.35457823]\n",
      "Sensor: [0.3712247869202433, 0.6252888122172693, 0.20691522460004547, 0.2998121380848496], Action prob: [0.64950585 0.35049412], Action: 0, state: 1\n",
      "[0.64950585 0.35049412]\n",
      "Sensor: [0.36467055865311415, 0.677168856590308, 0.1848309933916522, 0.23575211301311866], Action prob: [0.64985037 0.35014957], Action: 0, state: 1\n",
      "[0.64985037 0.35014957]\n",
      "Sensor: [0.33731392986440284, 0.615480243800585, 0.22519294243823829, 0.21062656155166956], Action prob: [0.6491081  0.35089186], Action: 0, state: 2\n",
      "[0.6491081  0.35089186]\n",
      "Sensor: [0.36485631480934577, 0.5965561740442311, 0.2055913048603276, 0.23274206437378475], Action prob: [0.6486423  0.35135776], Action: 0, state: 2\n",
      "[0.6486423  0.35135776]\n",
      "Sensor: [0.3780741476070088, 0.6329035461223368, 0.24415870787680122, 0.1958556095210514], Action prob: [0.64881444 0.3511856 ], Action: 0, state: 2\n",
      "[0.64881444 0.3511856 ]\n",
      "Sensor: [0.3890388401840774, 0.672483680536808, 0.24056032178385467, 0.2726135574371022], Action prob: [0.64978164 0.35021842], Action: 0, state: 2\n",
      "tensor([-0.7881, -0.4819, -0.2345, -0.0174,  0.1563,  0.3119,  0.4530,  0.5777],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 576 is 19000, loss is 0.0029000921030223337\n",
      "[0.64978164 0.35021842]\n",
      "Sensor: [0.4213415064554328, 0.6596350534520679, 0.23659943868647898, 0.1774327622533455], Action prob: [0.6381706  0.36182937], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.6381706  0.36182937]\n",
      "Sensor: [0.37034462507195326, 0.6589468199811366, 0.22171191583631608, 0.2837585701378259], Action prob: [0.65247566 0.34752434], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.65247566 0.34752434]\n",
      "Sensor: [0.34696030671008704, 0.618315360684149, 0.19145679560871942, 0.24654088997319173], Action prob: [0.6554367  0.34456325], Action: 0, state: 0\n",
      "[0.6554367  0.34456325]\n",
      "Sensor: [0.2974054161653051, 0.6457562515738325, 0.2067177165484472, 0.2603436029966254], Action prob: [0.6554495  0.34455046], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.6554495  0.34455046]\n",
      "Sensor: [0.3220103970728781, 0.6556950826762611, 0.20912616408130674, 0.21547237834206184], Action prob: [0.65480596 0.345194  ], Action: 0, state: 0\n",
      "[0.65480596 0.345194  ]\n",
      "Sensor: [0.37674730838590864, 0.6527920917937452, 0.18705726230082584, 0.5478514731632975], Action prob: [0.6565972 0.3434029], Action: 0, state: 1\n",
      "[0.6565972 0.3434029]\n",
      "Sensor: [0.3643417643910586, 0.5992872365405522, 0.187396384709174, 0.3056672595201675], Action prob: [0.6548848 0.3451152], Action: 0, state: 1\n",
      "[0.6548848 0.3451152]\n",
      "Sensor: [0.35887187847266444, 0.6513478142939408, 0.16426280201168972, 0.24941569596311622], Action prob: [0.65403885 0.3459612 ], Action: 0, state: 1\n",
      "tensor([-0.7958, -1.0040, -0.4017,  0.4460, -0.3436,  0.0759,  0.4555,  0.7999],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 584 is 22500, loss is 0.09596244365903626\n",
      "[0.65403885 0.3459612 ]\n",
      "Sensor: [0.3946723917138553, 0.6599566323384798, 0.2358169978451806, 0.18952763515872023], Action prob: [0.64001817 0.35998183], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.64001817 0.35998183]\n",
      "Sensor: [0.3292198068778576, 0.6225561942817921, 0.2567087762146927, 0.28131674073952173], Action prob: [0.6534631  0.34653693], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6534631  0.34653693]\n",
      "Sensor: [0.3382703093539922, 0.6647844257036195, 0.2150836516758577, 0.1739275107571401], Action prob: [0.65578854 0.3442115 ], Action: 0, state: 0\n",
      "[0.65578854 0.3442115 ]\n",
      "Sensor: [0.3936903069166101, 0.5979144093049421, 0.22137827771135585, 0.22910008838759097], Action prob: [0.65467453 0.3453254 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.65467453 0.3453254 ]\n",
      "Sensor: [0.36008250638144207, 0.5955390834380816, 0.15905595536021597, 0.26640182963495856], Action prob: [0.6534154 0.3465846], Action: 0, state: 0\n",
      "[0.6534154 0.3465846]\n",
      "Sensor: [0.3351845698658165, 0.6872339161499154, 0.24476974902239038, 0.22925291954990193], Action prob: [0.6538179  0.34618205], Action: 0, state: 0\n",
      "[0.6538179  0.34618205]\n",
      "Sensor: [0.3540758596098573, 0.6429315478461762, 0.19203152358278885, 0.22887821201927294], Action prob: [0.65324056 0.34675944], Action: 0, state: 0\n",
      "[0.65324056 0.34675944]\n",
      "Sensor: [0.30366720802813435, 0.5781612997165119, 0.23745573620344634, 0.30169533009520966], Action prob: [0.6530887  0.34691128], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9276, -1.4219, -0.4006, -0.2630,  0.0299,  0.2757,  0.4940,  0.6924],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 592 is 28000, loss is 0.19012450797486047\n",
      "[0.6530887  0.34691128]\n",
      "Sensor: [0.35238122620173273, 0.6454068217431543, 0.23285795824874367, 0.2903762193255415], Action prob: [0.635317 0.364683], Action: 0, state: 0\n",
      "[0.635317 0.364683]\n",
      "Sensor: [0.38932730535414295, 0.6184039781767225, 0.2184735253727079, 0.24943039124211502], Action prob: [0.6456071 0.3543929], Action: 0, state: 0\n",
      "[0.6456071 0.3543929]\n",
      "Sensor: [0.37985690654142085, 0.6850695100766199, 0.19593842291358377, 0.26344641881713765], Action prob: [0.6470208  0.35297918], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "[0.6470208  0.35297918]\n",
      "Sensor: [0.3252915550128483, 0.63902131039882, 0.21389059076535483, 0.23370322531750898], Action prob: [0.6449674  0.35503262], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.6449674  0.35503262]\n",
      "Sensor: [0.38377193310425106, 0.5679284696866491, 0.18852155354326428, 0.27645311390426125], Action prob: [0.64299953 0.3570004 ], Action: 0, state: 0\n",
      "[0.64299953 0.3570004 ]\n",
      "Sensor: [0.34202438840399385, 0.6660625784582913, 0.21393513043773738, 0.21486533383990433], Action prob: [0.64259547 0.35740462], Action: 0, state: 0\n",
      "[0.64259547 0.35740462]\n",
      "Sensor: [0.37567347050086314, 0.6260116250297089, 0.25075769347188903, 0.26932838223055033], Action prob: [0.6426268  0.35737312], Action: 0, state: 0\n",
      "[0.6426268  0.35737312]\n",
      "Sensor: [0.32402357613243854, 0.6340367283265653, 0.18178971725960882, 0.2577509168119493], Action prob: [0.64226544 0.35773465], Action: 0, state: 0\n",
      "tensor([-6.6778e-01,  6.5602e-04,  1.2488e+00, -6.1414e-01, -5.0204e-01,\n",
      "        -7.1825e-02,  3.1293e-01,  6.6098e-01], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 600 is 31900, loss is -0.04595138589012154\n",
      "[0.64226544 0.35773465]\n",
      "Sensor: [0.3640531317041471, 0.6260419682786209, 0.22581400787948888, 0.2905058529249659], Action prob: [0.6320197  0.36798027], Action: 0, state: 0\n",
      "[0.6320197  0.36798027]\n",
      "Sensor: [0.30423813455749615, 0.6044696187717434, 0.23700513731951214, 0.2276801426840765], Action prob: [0.6403945  0.35960546], Action: 0, state: 1\n",
      "[0.6403945  0.35960546]\n",
      "Sensor: [0.3423402730663012, 0.5818617896945796, 0.22409939521580713, 0.22262949247695724], Action prob: [0.639661 0.360339], Action: 0, state: 1\n",
      "[0.639661 0.360339]\n",
      "Sensor: [0.3683125657259344, 0.6539440487507999, 0.23893473200897733, 0.2540483338452511], Action prob: [0.63795906 0.36204097], Action: 0, state: 1\n",
      "[0.63795906 0.36204097]\n",
      "Sensor: [0.36681597462557197, 0.5946368444642633, 0.24497447139860803, 0.2545332556890459], Action prob: [0.6359073  0.36409274], Action: 0, state: 1\n",
      "[0.6359073  0.36409274]\n",
      "Sensor: [0.35753206579545527, 0.6047465952422371, 0.21592085484373416, 0.23639223486814884], Action prob: [0.634611   0.36538905], Action: 0, state: 1\n",
      "[0.634611   0.36538905]\n",
      "Sensor: [0.346420984308883, 0.6633091640703138, 0.21588662591271127, 0.18385859873639546], Action prob: [0.63424987 0.36575013], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.63424987 0.36575013]\n",
      "Sensor: [0.44924560969017713, 0.6279350385821031, 0.25126386496396647, 0.5185416526213132], Action prob: [0.6358937  0.36410633], Action: 0, state: 1\n",
      "tensor([-0.8011, -0.4979, -0.2486, -0.0214,  0.1844,  0.3720,  1.1559,  0.5014],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 608 is 37900, loss is -0.08059006037964056\n",
      "[0.6358937  0.36410633]\n",
      "Sensor: [0.30914379124131863, 0.6040747150072673, 0.24739792759655155, 0.23145258395740784], Action prob: [0.631624   0.36837605], Action: 0, state: 2\n",
      "[0.631624   0.36837605]\n",
      "Sensor: [0.3785527814950212, 0.5971392130208725, 0.1956916914256258, 0.27300955537645144], Action prob: [0.63931715 0.36068285], Action: 0, state: 3\n",
      "[0.63931715 0.36068285]\n",
      "Sensor: [0.3645824785868629, 0.4420780847884462, 0.18348040559542506, 0.2707209664414418], Action prob: [0.636457 0.363543], Action: 0, state: 3\n",
      "[0.636457 0.363543]\n",
      "Sensor: [0.5266399001998556, 0.6366426075374114, 0.22079098691596635, 0.5386432786474018], Action prob: [0.63574153 0.36425847], Action: 0, state: 3\n",
      "[0.63574153 0.36425847]\n",
      "Sensor: [0.6715710937283329, 0.6315949159937401, 0.21429325435538799, 0.27101472715302183], Action prob: [0.63227564 0.36772433], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.63227564 0.36772433]\n",
      "Sensor: [0.3795013188538211, 0.6648351500024772, 0.2022580618884014, 0.2544434714076492], Action prob: [0.6306215  0.36937845], Action: 0, state: 2\n",
      "[0.6306215  0.36937845]\n",
      "Sensor: [0.39478164224400947, 0.658339594463838, 0.2537570121949934, 0.20909507045331013], Action prob: [0.6300572  0.36994284], Action: 0, state: 2\n",
      "[0.6300572  0.36994284]\n",
      "Sensor: [0.32891023395714913, 0.6245764423284754, 0.22380200990647517, 0.23760246633030316], Action prob: [0.6299073  0.37009263], Action: 0, state: 2\n",
      "tensor([-0.7532, -0.4834, -0.2610, -0.0550,  0.2827,  0.2390,  0.4858,  0.7080],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 616 is 42600, loss is -0.020362495840098208\n",
      "[0.6299073  0.37009263]\n",
      "Sensor: [0.36731435587255773, 0.625997033604407, 0.18417588688543987, 0.2438455101242355], Action prob: [0.6322628 0.3677371], Action: 0, state: 2\n",
      "[0.6322628 0.3677371]\n",
      "Sensor: [0.45362896549293463, 0.5118732022277653, 0.3472223745920394, 0.3250543689001549], Action prob: [0.63862365 0.3613763 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.63862365 0.3613763 ]\n",
      "Sensor: [0.36532712679164997, 0.5751748211052884, 0.1934249598473127, 0.24470868840154925], Action prob: [0.63488734 0.36511263], Action: 0, state: 1\n",
      "[0.63488734 0.36511263]\n",
      "Sensor: [0.3548029868580975, 0.6294608568543918, 0.2695128797644517, 0.28471261498234485], Action prob: [0.63121843 0.3687816 ], Action: 0, state: 2\n",
      "[0.63121843 0.3687816 ]\n",
      "Sensor: [0.34712358273145144, 0.6284135050821973, 0.2285369972122164, 0.24452629909949775], Action prob: [0.6280212  0.37197882], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.6280212  0.37197882]\n",
      "Sensor: [0.3493397169502875, 0.6488484065639412, 0.18750227937735678, 0.24976670606263446], Action prob: [0.6263876 0.3736124], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.6263876 0.3736124]\n",
      "Sensor: [0.40153142941577175, 0.6699984545344815, 0.18988867320317704, 0.22977750625655904], Action prob: [0.6256901  0.37430987], Action: 0, state: 0\n",
      "[0.6256901  0.37430987]\n",
      "Sensor: [0.42931743337066425, 0.6308471607945224, 0.20815555174556333, 0.22704761339384205], Action prob: [0.6250784 0.3749216], Action: 0, state: 0\n",
      "tensor([-0.9036, -0.9830, -0.2320,  0.1427,  1.0325,  0.9459,  0.1009,  0.4148],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 624 is 46200, loss is -0.06475664928243437\n",
      "[0.6250784 0.3749216]\n",
      "Sensor: [0.38422363355117845, 0.5919751940611855, 0.20545757969810813, 0.2738415263921214], Action prob: [0.6352089  0.36479115], Action: 1, state: 1\n",
      "[0.6352089  0.36479115]\n",
      "Sensor: [0.33169428903555087, 0.4266855976563241, 0.20248516688926915, 0.2401422900685017], Action prob: [0.63927674 0.36072326], Action: 0, state: 9\n",
      "[0.63927674 0.36072326]\n",
      "Sensor: [0.37050792548169936, 0.6260659729916539, 0.22930077819070296, 0.571863508465126], Action prob: [0.6384753  0.36152464], Action: 0, state: 9\n",
      "[0.6384753  0.36152464]\n",
      "Sensor: [0.5767678702010367, 0.6250087698019516, 0.22532970992342455, 0.24638797425936898], Action prob: [0.6320483  0.36795166], Action: 0, state: 9\n",
      "[0.6320483  0.36795166]\n",
      "Sensor: [0.3866228492248394, 0.36906980315703797, 0.4895599515545675, 0.24896137120882528], Action prob: [0.62660986 0.37339017], Action: 0, state: 9\n",
      "[0.62660986 0.37339017]\n",
      "Sensor: [0.5818454300195768, 0.6210235705488099, 0.20547385560080964, 0.2363683394378902], Action prob: [0.6248548 0.3751452], Action: 0, state: 9\n",
      "[0.6248548 0.3751452]\n",
      "Sensor: [0.5679934347864206, 0.5764952081367907, 0.17406682199171777, 0.2740259948644301], Action prob: [0.6239213  0.37607875], Action: 0, state: 9\n",
      "[0.6239213  0.37607875]\n",
      "Sensor: [0.39361970062076934, 0.6079042788277973, 0.5386782935372498, 0.27452790112235304], Action prob: [0.625174   0.37482607], Action: 1, state: 9\n",
      "tensor([ 1.6941,  0.4884,  0.2556,  0.0393, -0.1555, -0.3415, -0.5065, -1.3396],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 632 is 38200, loss is -0.01678960659039594\n",
      "[0.625174   0.37482607]\n",
      "Sensor: [0.5302425340688303, 0.617282687983042, 0.5290483839807206, 0.27757435851951545], Action prob: [0.6397669  0.36023307], Action: 0, state: 9\n",
      "[0.6397669  0.36023307]\n",
      "Sensor: [0.3451066121018345, 0.6678811674271986, 0.23786365404939638, 0.5617519172507971], Action prob: [0.6452163  0.35478365], Action: 0, state: 9\n",
      "[0.6452163  0.35478365]\n",
      "Sensor: [0.4249036144341932, 0.355295997068704, 0.21994967227477963, 0.2769256148773942], Action prob: [0.63608927 0.36391076], Action: 0, state: 9\n",
      "[0.63608927 0.36391076]\n",
      "Sensor: [0.31729748588066364, 0.6536437950806809, 0.5215213664653547, 0.2846015008975406], Action prob: [0.63230705 0.36769292], Action: 1, state: 9\n",
      "[0.63230705 0.36769292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.600771897147124, 0.36602008406237774, 0.2259074183061433, 0.22893203428872455], Action prob: [0.6253538 0.3746462], Action: 0, state: 9\n",
      "[0.6253538 0.3746462]\n",
      "Sensor: [0.3690133405229088, 0.4346234464679703, 0.22315883454750088, 0.2240562785757302], Action prob: [0.6227868  0.37721324], Action: 1, state: 9\n",
      "[0.6227868  0.37721324]\n",
      "Sensor: [0.36483764056592594, 0.3602320500349822, 0.3713061785896342, 0.2308413463000288], Action prob: [0.6221947  0.37780523], Action: 0, state: 9\n",
      "[0.6221947  0.37780523]\n",
      "Sensor: [0.35633761778814266, 0.3482145146771758, 0.2421661151224898, 0.20763585371206533], Action prob: [0.62172264 0.3782773 ], Action: 0, state: 9\n",
      "tensor([ 0.7524,  0.4819,  0.2529,  0.1080, -0.1640, -0.7034, -0.5054, -0.6559],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 640 is 30200, loss is 0.054184311211989286\n",
      "[0.62172264 0.3782773 ]\n",
      "Sensor: [0.5784116117746699, 0.6467170789568362, 0.515703438082011, 0.25992103756456514], Action prob: [0.64095414 0.35904583], Action: 0, state: 9\n",
      "[0.64095414 0.35904583]\n",
      "Sensor: [0.519625080406423, 0.601629302487964, 0.23553121025793483, 0.49855985099461075], Action prob: [0.64424735 0.35575265], Action: 0, state: 9\n",
      "[0.64424735 0.35575265]\n",
      "Sensor: [0.38287307551615796, 0.5500315824272884, 0.22279199688807066, 0.5628093878924805], Action prob: [0.63843244 0.3615675 ], Action: 1, state: 9\n",
      "[0.63843244 0.3615675 ]\n",
      "Sensor: [0.37882621497890634, 0.5746114500688296, 0.4990488936453594, 0.30069512736402815], Action prob: [0.6315841 0.3684159], Action: 1, state: 9\n",
      "[0.6315841 0.3684159]\n",
      "Sensor: [0.5764035176859333, 0.6447757936624905, 0.23876565823516796, 0.2752315876769356], Action prob: [0.6265609  0.37343913], Action: 1, state: 9\n",
      "[0.6265609  0.37343913]\n",
      "Sensor: [0.34538544150920475, 0.37681556197117316, 0.22883560775836728, 0.2732767615790699], Action prob: [0.6223715 0.3776285], Action: 0, state: 9\n",
      "[0.6223715 0.3776285]\n",
      "Sensor: [0.34494237070580797, 0.5851390362395795, 0.4916268572318479, 0.24775180769151287], Action prob: [0.62335324 0.3766468 ], Action: 1, state: 9\n",
      "[0.62335324 0.3766468 ]\n",
      "Sensor: [0.36174651855011036, 0.5640607722290629, 0.5423650182131597, 0.4917846618912398], Action prob: [0.6250413  0.37495875], Action: 0, state: 9\n",
      "tensor([ 0.7488,  0.4793,  0.5773,  0.1024, -0.3340, -0.3421, -1.0280, -0.6408],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 648 is 22200, loss is 0.05463893443494615\n",
      "[0.6250413  0.37495875]\n",
      "Sensor: [0.5743503039257462, 0.5870401505712644, 0.24259661658570777, 0.294035569280553], Action prob: [0.63908833 0.36091173], Action: 0, state: 9\n",
      "[0.63908833 0.36091173]\n",
      "Sensor: [0.5951615020376367, 0.6031257355034949, 0.18486972656782025, 0.27440973737585184], Action prob: [0.64137495 0.35862514], Action: 0, state: 9\n",
      "[0.64137495 0.35862514]\n",
      "Sensor: [0.3134758109243784, 0.6198226503489224, 0.19838311422758376, 0.5415516907964583], Action prob: [0.63728434 0.36271563], Action: 0, state: 9\n",
      "[0.63728434 0.36271563]\n",
      "Sensor: [0.5636368095094624, 0.6863129467857778, 0.22361240312703257, 0.15838007681067875], Action prob: [0.62984914 0.37015086], Action: 1, state: 9\n",
      "[0.62984914 0.37015086]\n",
      "Sensor: [0.6407323285053564, 0.6142191827774409, 0.26077911399449893, 0.2255069961079761], Action prob: [0.6247606  0.37523934], Action: 0, state: 9\n",
      "[0.6247606  0.37523934]\n",
      "Sensor: [0.3396789097092468, 0.6668205938277139, 0.2319566505670126, 0.5600437713956669], Action prob: [0.62420744 0.3757926 ], Action: 0, state: 9\n",
      "[0.62420744 0.3757926 ]\n",
      "Sensor: [0.3536417451793297, 0.36013534282622467, 0.22405757849909666, 0.2277780146446975], Action prob: [0.620393   0.37960702], Action: 0, state: 9\n",
      "[0.620393   0.37960702]\n",
      "Sensor: [0.3357605084503762, 0.6249864912075911, 0.24510826891334125, 0.489893199814292], Action prob: [0.62220633 0.37779373], Action: 1, state: 9\n",
      "tensor([ 0.7494,  0.4824,  0.2579,  0.0892, -0.1607, -0.3354, -0.5094, -1.3329],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 656 is 16200, loss is 0.09494972544366959\n",
      "[0.62220633 0.37779373]\n",
      "Sensor: [0.36341043515207955, 0.6283381406958471, 0.24337760084121376, 0.563010241013353], Action prob: [0.63791966 0.36208028], Action: 0, state: 0\n",
      "[0.63791966 0.36208028]\n",
      "Sensor: [0.3078023012041065, 0.5832500617599798, 0.3979231703024708, 0.2803061303415341], Action prob: [0.63789123 0.36210877], Action: 0, state: 0\n",
      "[0.63789123 0.36210877]\n",
      "Sensor: [0.39643562268766247, 0.615072031724667, 0.23105400627814163, 0.27452446507376693], Action prob: [0.6313302  0.36866978], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6313302  0.36866978]\n",
      "Sensor: [0.31166168529469673, 0.6664890839545831, 0.20069875090937844, 0.2752149928915221], Action prob: [0.6253796 0.3746204], Action: 0, state: 0\n",
      "[0.6253796 0.3746204]\n",
      "Sensor: [0.2779729895392598, 0.6346554820850365, 0.20779184865344416, 0.2897787776732107], Action prob: [0.621402   0.37859797], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.621402   0.37859797]\n",
      "Sensor: [0.3776435816595898, 0.6779911878908692, 0.19141690054300883, 0.2510857777556271], Action prob: [0.61925703 0.38074297], Action: 0, state: 0\n",
      "[0.61925703 0.38074297]\n",
      "Sensor: [0.36746474412322194, 0.6352869024758357, 0.23144411898776063, 0.2212063648062097], Action prob: [0.61786824 0.38213181], Action: 0, state: 1\n",
      "[0.61786824 0.38213181]\n",
      "Sensor: [0.35030661094389043, 0.6611258535050787, 0.2107784067322422, 0.27109920918482466], Action prob: [0.617609   0.38239095], Action: 0, state: 1\n",
      "tensor([-0.8058, -0.4786, -0.4229, -0.0597,  0.3882,  0.3031,  0.4894,  0.6565],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 664 is 22900, loss is -0.008764273904283401\n",
      "[0.617609   0.38239095]\n",
      "Sensor: [0.4131449308961431, 0.5084388025325881, 0.2204710216870196, 0.3093611110733682], Action prob: [0.6323324  0.36766762], Action: 0, state: 1\n",
      "[0.6323324  0.36766762]\n",
      "Sensor: [0.36980801321759366, 0.6614603472172947, 0.21346971946256393, 0.27008795242849093], Action prob: [0.6328131  0.36718687], Action: 0, state: 1\n",
      "[0.6328131  0.36718687]\n",
      "Sensor: [0.31884009297172167, 0.6228892227840621, 0.24923666305034095, 0.24503851944111235], Action prob: [0.625644   0.37435588], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.625644   0.37435588]\n",
      "Sensor: [0.3186336233521696, 0.6158260336768557, 0.22331924658651342, 0.2764123615368369], Action prob: [0.618259   0.38174102], Action: 0, state: 1\n",
      "[0.618259   0.38174102]\n",
      "Sensor: [0.42546390002366513, 0.6181147833132684, 0.22523221534528673, 0.26232690070935233], Action prob: [0.6129954  0.38700458], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.6129954  0.38700458]\n",
      "Sensor: [0.34003264297392466, 0.6123386629866597, 0.2451884438105028, 0.2628159059249479], Action prob: [0.6101757  0.38982427], Action: 0, state: 1\n",
      "[0.6101757  0.38982427]\n",
      "Sensor: [0.36714414241361687, 0.6215322092917218, 0.2112724172911758, 0.2586660165171021], Action prob: [0.6087751  0.39122492], Action: 0, state: 1\n",
      "[0.6087751  0.39122492]\n",
      "Sensor: [0.30051752259588144, 0.6683342366512268, 0.23745709355046085, 0.22957136192299682], Action prob: [0.6084604  0.39153954], Action: 0, state: 2\n",
      "tensor([-0.8271, -0.4711, -0.4048, -0.0655,  0.3388,  0.2893,  0.5149,  0.6986],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 672 is 28700, loss is -0.009123014063408097\n",
      "[0.6084604  0.39153954]\n",
      "Sensor: [0.34083092743656407, 0.622736569683483, 0.22928092282069265, 0.20463072108068922], Action prob: [0.63009006 0.36990994], Action: 0, state: 2\n",
      "[0.63009006 0.36990994]\n",
      "Sensor: [0.5734293434395674, 0.6277276052642882, 0.18379679396039109, 0.28222775218921137], Action prob: [0.6265585  0.37344158], Action: 0, state: 3\n",
      "[0.6265585  0.37344158]\n",
      "Sensor: [0.4075931250671495, 0.62075297928397, 0.24620205191610373, 0.2396335799958843], Action prob: [0.61630845 0.38369158], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "[0.61630845 0.38369158]\n",
      "Sensor: [0.3697359181520942, 0.6740356676247256, 0.2160443852266986, 0.20464229849803026], Action prob: [0.6069501  0.39304993], Action: 0, state: 2\n",
      "[0.6069501  0.39304993]\n",
      "Sensor: [0.3801352293796289, 0.664909739548884, 0.22048880425479456, 0.2872641109186465], Action prob: [0.6005409 0.3994592], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.6005409 0.3994592]\n",
      "Sensor: [0.3696998169756304, 0.6179439465677111, 0.20225882660132272, 0.2689803838726408], Action prob: [0.59647936 0.40352064], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.59647936 0.40352064]\n",
      "Sensor: [0.37315345230797, 0.6128649624852209, 0.24196336323090328, 0.2507924821094676], Action prob: [0.594107   0.40589303], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.594107   0.40589303]\n",
      "Sensor: [0.3293264169588594, 0.6748175257130486, 0.16368820081668004, 0.28372291753517115], Action prob: [0.59306264 0.40693736], Action: 0, state: 0\n",
      "tensor([-0.7739, -0.4543, -0.3032, -0.2729,  0.2651,  0.6023,  0.9810,  0.7680],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 680 is 32600, loss is -0.10152958449916599\n",
      "[0.59306264 0.40693736]\n",
      "Sensor: [0.3558171288330013, 0.6068898451026712, 0.20271692289616952, 0.34289737864075476], Action prob: [0.63187987 0.36812016], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.63187987 0.36812016]\n",
      "Sensor: [0.3213148070457844, 0.6490013128703838, 0.21936487953150272, 0.25405328418548817], Action prob: [0.62801343 0.3719865 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.62801343 0.3719865 ]\n",
      "Sensor: [0.34361547827552197, 0.6541492112869278, 0.2021065080646354, 0.22679371642163487], Action prob: [0.6166025  0.38339755], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.6166025  0.38339755]\n",
      "Sensor: [0.3809902511707924, 0.6260980933003019, 0.22951456013679594, 0.2838787326927562], Action prob: [0.6056454  0.39435464], Action: 0, state: 0\n",
      "[0.6056454  0.39435464]\n",
      "Sensor: [0.34823548947604055, 0.6124787906038157, 0.1846665915704893, 0.29021378055977054], Action prob: [0.5977116  0.40228835], Action: 0, state: 0\n",
      "[0.5977116  0.40228835]\n",
      "Sensor: [0.31425530551848513, 0.6543748586774204, 0.21026179672533643, 0.23107034803985696], Action prob: [0.5930818  0.40691817], Action: 0, state: 0\n",
      "[0.5930818  0.40691817]\n",
      "Sensor: [0.3689216899422768, 0.6351589324924455, 0.2316835357276078, 0.2858996301090331], Action prob: [0.59011614 0.40988395], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.59011614 0.40988395]\n",
      "Sensor: [0.35839783589664115, 0.6108077885731645, 0.24049465694266509, 0.23159954230030882], Action prob: [0.58816344 0.41183653], Action: 0, state: 0\n",
      "tensor([-0.6993, -0.6887, -0.6692, -0.6528, -0.1123,  0.3976,  1.4598,  0.6591],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 688 is 35600, loss is 0.03822831387543149\n",
      "[0.58816344 0.41183653]\n",
      "Sensor: [0.40801859637754895, 0.6487703056210867, 0.25398918756328126, 0.2765731947563608], Action prob: [0.6310431  0.36895695], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6310431  0.36895695]\n",
      "Sensor: [0.3603049568978194, 0.6029879396491478, 0.2136865534052027, 0.25964928050445196], Action prob: [0.6258817 0.3741183], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.6258817 0.3741183]\n",
      "Sensor: [0.3089731893118337, 0.7043021863082559, 0.4080053331262635, 0.16556330433455357], Action prob: [0.61465657 0.38534337], Action: 0, state: 0\n",
      "[0.61465657 0.38534337]\n",
      "Sensor: [0.37439655655411636, 0.6683451891053583, 0.22999582444824718, 0.24248834981227377], Action prob: [0.6036568  0.39634314], Action: 0, state: 1\n",
      "[0.6036568  0.39634314]\n",
      "Sensor: [0.3173835064101861, 0.6615125033673415, 0.19891352405719578, 0.26085655002165514], Action prob: [0.59580904 0.404191  ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.59580904 0.404191  ]\n",
      "Sensor: [0.38133355976826183, 0.6325483414284374, 0.26279714921199443, 0.24431999212633657], Action prob: [0.59067756 0.40932238], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.59067756 0.40932238]\n",
      "Sensor: [0.5583167114593068, 0.69211656473222, 0.2354342471953635, 0.24668690578455243], Action prob: [0.58700466 0.41299534], Action: 0, state: 0\n",
      "[0.58700466 0.41299534]\n",
      "Sensor: [0.30910585564286386, 0.6233991629504143, 0.21189263378496132, 0.24037123388858628], Action prob: [0.5850642 0.4149358], Action: 0, state: 0\n",
      "tensor([-1.4706, -0.9400, -0.4595, -0.0999,  0.3706,  0.6073,  0.5210,  0.8252],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 696 is 40600, loss is 0.08072234246178299\n",
      "[0.5850642 0.4149358]\n",
      "Sensor: [0.3551766764688364, 0.6616542291768319, 0.2055285231291663, 0.2625980089115879], Action prob: [0.6273816  0.37261838], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.6273816  0.37261838]\n",
      "Sensor: [0.3507714719054847, 0.6417350569750707, 0.22581543205406251, 0.28438425842680226], Action prob: [0.62116784 0.37883216], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.62116784 0.37883216]\n",
      "Sensor: [0.37354764380354266, 0.6232111087876798, 0.19506208220942226, 0.2547825850968116], Action prob: [0.6081729  0.39182717], Action: 0, state: 0\n",
      "[0.6081729  0.39182717]\n",
      "Sensor: [0.3661481801439923, 0.6814066431763934, 0.22363321976152883, 0.26164537423352346], Action prob: [0.5964308 0.4035692], Action: 0, state: 1\n",
      "[0.5964308 0.4035692]\n",
      "Sensor: [0.35605754840307186, 0.5920402693927501, 0.26233195342036786, 0.24119285493471088], Action prob: [0.5871935 0.4128065], Action: 0, state: 1\n",
      "[0.5871935 0.4128065]\n",
      "Sensor: [0.3474090882883976, 0.6578839231273355, 0.20078525902669261, 0.25189150049834635], Action prob: [0.5813633  0.41863662], Action: 0, state: 2\n",
      "[0.5813633  0.41863662]\n",
      "Sensor: [0.349387779545167, 0.6992580620021986, 0.2501610335444795, 0.1989422474114242], Action prob: [0.57787865 0.42212138], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.57787865 0.42212138]\n",
      "Sensor: [0.45380175652662935, 0.6098993927606319, 0.2014487280600179, 0.24557237399204612], Action prob: [0.5747859 0.4252141], Action: 0, state: 1\n",
      "tensor([-0.5540, -1.4773, -0.5431, -0.2008,  0.1288,  0.4047,  1.0375,  0.7743],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 704 is 44800, loss is 0.05371826698227426\n",
      "[0.5747859 0.4252141]\n",
      "Sensor: [0.35673807101968597, 0.6247230212757632, 0.17988631006138317, 0.2463370420974178], Action prob: [0.6208101  0.37918994], Action: 0, state: 1\n",
      "[0.6208101  0.37918994]\n",
      "Sensor: [0.37816323152744147, 0.6034303756230357, 0.17587820362941997, 0.22997012647164597], Action prob: [0.61279756 0.38720247], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.61279756 0.38720247]\n",
      "Sensor: [0.3691061088435109, 0.6416199472960663, 0.27366152194012006, 0.263421953457992], Action prob: [0.59935653 0.40064353], Action: 0, state: 1\n",
      "[0.59935653 0.40064353]\n",
      "Sensor: [0.44564166645618464, 0.6340177978215563, 0.23594241400310617, 0.2618179797366187], Action prob: [0.5856993  0.41430065], Action: 0, state: 1\n",
      "[0.5856993  0.41430065]\n",
      "Sensor: [0.39713851477115286, 0.6063174081929733, 0.23085406783781154, 0.2956201517883606], Action prob: [0.5750018  0.42499822], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.5750018  0.42499822]\n",
      "Sensor: [0.32463620623627876, 0.659070390406401, 0.22457961257515202, 0.22919694808585217], Action prob: [0.5679686  0.43203142], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5679686  0.43203142]\n",
      "Sensor: [0.38436435987454176, 0.6424321768289892, 0.2324219897296148, 0.2667144933636137], Action prob: [0.56280756 0.4371925 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.56280756 0.4371925 ]\n",
      "Sensor: [0.33893354173649465, 0.6798389498716819, 0.2082974288474805, 0.2178715677072002], Action prob: [0.5593219  0.44067815], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "tensor([-0.9020, -0.7362, -0.4591,  0.0622,  0.7982,  0.7098,  0.6972,  0.6923],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 712 is 45600, loss is -0.10780096389159843\n",
      "[0.5593219  0.44067815]\n",
      "Sensor: [0.35238671718899206, 0.583947330457831, 0.1921291758989682, 0.25307977997946574], Action prob: [0.6201558  0.37984422], Action: 0, state: 0\n",
      "[0.6201558  0.37984422]\n",
      "Sensor: [0.41328568873341387, 0.6324008275432091, 0.19432561206520774, 0.3050852775709668], Action prob: [0.61324817 0.38675186], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.61324817 0.38675186]\n",
      "Sensor: [0.30580023087131236, 0.6702898674533875, 0.21947280233040017, 0.26701105910286266], Action prob: [0.60262644 0.39737356], Action: 0, state: 0\n",
      "[0.60262644 0.39737356]\n",
      "Sensor: [0.410948750975719, 0.6560339809016394, 0.18209207904327654, 0.21483236871260966], Action prob: [0.5916047  0.40839526], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5916047  0.40839526]\n",
      "Sensor: [0.33259690862192404, 0.6952967932832733, 0.22735601677901124, 0.28628652208779093], Action prob: [0.5834419 0.416558 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5834419 0.416558 ]\n",
      "Sensor: [0.3466721148688122, 0.552034189150107, 0.20076700217633806, 0.2872479266428861], Action prob: [0.5774872  0.42251283], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5774872  0.42251283]\n",
      "Sensor: [0.3594526577997847, 0.6528344482728466, 0.17813145773373407, 0.28917589590537623], Action prob: [0.57388526 0.4261148 ], Action: 0, state: 0\n",
      "[0.57388526 0.4261148 ]\n",
      "Sensor: [0.36222055155393346, 0.6425819555358736, 0.2049443925608808, 0.25346884444836637], Action prob: [0.571018   0.42898205], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.9972, -0.6135, -0.3234,  0.3640,  0.3618,  0.7599,  0.2534,  1.0359],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 720 is 49000, loss is -0.10509532253506684\n",
      "[0.571018   0.42898205]\n",
      "Sensor: [0.3355604247221449, 0.6340376589562058, 0.22321584321266597, 0.2925917982971636], Action prob: [0.6239075 0.3760925], Action: 0, state: 0\n",
      "[0.6239075 0.3760925]\n",
      "Sensor: [0.34068448286588077, 0.6325081873985839, 0.2384102753425666, 0.35421586983737974], Action prob: [0.61856174 0.38143826], Action: 0, state: 0\n",
      "[0.61856174 0.38143826]\n",
      "Sensor: [0.38364579966499945, 0.6451731103119465, 0.23952452476236, 0.31124444292315057], Action prob: [0.610332   0.38966802], Action: 0, state: 1\n",
      "[0.610332   0.38966802]\n",
      "Sensor: [0.32305774990101305, 0.6618093600785196, 0.2582270674118289, 0.2567583811756626], Action prob: [0.6028001 0.3971999], Action: 0, state: 1\n",
      "[0.6028001 0.3971999]\n",
      "Sensor: [0.3604280480300964, 0.6658694212543127, 0.20884555306701885, 0.23627435875713054], Action prob: [0.59695685 0.40304315], Action: 0, state: 2\n",
      "[0.59695685 0.40304315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3087368460402295, 0.6557255021149, 0.24518150855420048, 0.22867708799835676], Action prob: [0.59306633 0.40693372], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "[0.59306633 0.40693372]\n",
      "Sensor: [0.3333376715338464, 0.559655290513648, 0.2222221294937384, 0.2341924757438315], Action prob: [0.59002763 0.40997234], Action: 0, state: 2\n",
      "[0.59002763 0.40997234]\n",
      "Sensor: [0.3569865051914406, 0.6071433271872281, 0.16759231491466986, 0.22815167512603235], Action prob: [0.58844554 0.41155446], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "tensor([-0.9065, -0.5306, -0.2199,  0.0779,  0.3231,  0.8074,  0.4208,  0.8986],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 728 is 53700, loss is -0.10885624390096948\n",
      "[0.58844554 0.41155446]\n",
      "Sensor: [0.3951531595571332, 0.6351549095799872, 0.21116172314940243, 0.25743827498094024], Action prob: [0.6296851  0.37031496], Action: 0, state: 2\n",
      "[0.6296851  0.37031496]\n",
      "Sensor: [0.36766939444926716, 0.6704031239430003, 0.19673531607075728, 0.2466513771535643], Action prob: [0.62661153 0.3733885 ], Action: 0, state: 3\n",
      "[0.62661153 0.3733885 ]\n",
      "Sensor: [0.3784207600291062, 0.569744610107614, 0.22181602626506933, 0.2219272196293076], Action prob: [0.620618   0.37938195], Action: 0, state: 3\n",
      "[0.620618   0.37938195]\n",
      "Sensor: [0.635048195314058, 0.6359745934763236, 0.21009964909336903, 0.2194349751733241], Action prob: [0.6148015  0.38519853], Action: 0, state: 8\n",
      "[0.6148015  0.38519853]\n",
      "Sensor: [0.3475070718179839, 0.36872727290810076, 0.2086852727618012, 0.23416748035167625], Action prob: [0.61042356 0.38957644], Action: 0, state: 8\n",
      "[0.61042356 0.38957644]\n",
      "Sensor: [0.3855118059385597, 0.6861936037042563, 0.23190485825204607, 0.5809922159692535], Action prob: [0.60904175 0.39095825], Action: 0, state: 8\n",
      "[0.60904175 0.39095825]\n",
      "Sensor: [0.5682633927817928, 0.6441961313550004, 0.1910032570466858, 0.283171579993729], Action prob: [0.60660267 0.39339727], Action: 0, state: 8\n",
      "[0.60660267 0.39339727]\n",
      "Sensor: [0.6126473274316286, 0.6227762182999568, 0.19855239774606062, 0.208804824136661], Action prob: [0.6047392  0.39526075], Action: 1, state: 8\n",
      "tensor([ 0.4165,  0.4872,  0.5568,  0.2299, -0.0646, -0.3359, -0.5936, -1.5199],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 736 is 36700, loss is 0.10294274301208971\n",
      "[0.6047392  0.39526075]\n",
      "Sensor: [0.537301130952895, 0.33068811073854615, 0.12993666598815268, 0.26434258667391614], Action prob: [0.6293494 0.3706506], Action: 1, state: 8\n",
      "[0.6293494 0.3706506]\n",
      "Sensor: [0.33106096969322857, 0.638397760327874, 0.22393581249512842, 0.26578473951968806], Action prob: [0.62941784 0.3705821 ], Action: 0, state: 0\n",
      "[0.62941784 0.3705821 ]\n",
      "Sensor: [0.37033907985812914, 0.623572886555318, 0.2540771042079979, 0.5816411007180494], Action prob: [0.6260161  0.37398395], Action: 0, state: 0\n",
      "[0.6260161  0.37398395]\n",
      "Sensor: [0.3239414930765826, 0.4652142647215769, 0.24494964547939063, 0.2630756331219052], Action prob: [0.621037   0.37896296], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.621037   0.37896296]\n",
      "Sensor: [0.359375830984218, 0.6559176641387822, 0.21222850217195324, 0.23482939745238135], Action prob: [0.61840856 0.3815915 ], Action: 0, state: 0\n",
      "[0.61840856 0.3815915 ]\n",
      "Sensor: [0.3679671583918921, 0.666934300697684, 0.22163975602060396, 0.24271428222650748], Action prob: [0.61674875 0.38325128], Action: 0, state: 1\n",
      "[0.61674875 0.38325128]\n",
      "Sensor: [0.33343105725775174, 0.6043953017308501, 0.21425047632548658, 0.24822307551360076], Action prob: [0.6155096  0.38449034], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.6155096  0.38449034]\n",
      "Sensor: [0.36036076302585246, 0.6631104525280743, 0.1972990070602162, 0.23444764849815158], Action prob: [0.6148296  0.38517046], Action: 0, state: 0\n",
      "tensor([-1.8891, -0.5100, -0.1861,  0.2273,  0.1126,  0.3365,  1.0634,  0.5406],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 744 is 42500, loss is 0.03809833811475112\n",
      "[0.6148296  0.38517046]\n",
      "Sensor: [0.2864857177616033, 0.6541615518407133, 0.22194740859073706, 0.2529460790521808], Action prob: [0.6336101  0.36638984], Action: 0, state: 0\n",
      "[0.6336101  0.36638984]\n",
      "Sensor: [0.39893845987642085, 0.6459818343015016, 0.2168336125982183, 0.4942901008227146], Action prob: [0.6330129 0.3669871], Action: 0, state: 0\n",
      "[0.6330129 0.3669871]\n",
      "Sensor: [0.3046983327022355, 0.696120348530341, 0.2054257205143451, 0.3121099802658313], Action prob: [0.6291317  0.37086827], Action: 0, state: 0\n",
      "[0.6291317  0.37086827]\n",
      "Sensor: [0.3985820726748133, 0.6537536380086414, 0.4451490532771732, 0.29785071484341474], Action prob: [0.6251028  0.37489718], Action: 0, state: 1\n",
      "[0.6251028  0.37489718]\n",
      "Sensor: [0.3361305994541231, 0.6596558753161358, 0.21749491272856755, 0.2511238674689398], Action prob: [0.622935   0.37706503], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.622935   0.37706503]\n",
      "Sensor: [0.37256206692522303, 0.6919856004211878, 0.22418895553202453, 0.28735136601584305], Action prob: [0.62175363 0.37824634], Action: 0, state: 0\n",
      "[0.62175363 0.37824634]\n",
      "Sensor: [0.35042103519223244, 0.5978251674481425, 0.1935252566500474, 0.19970562856085886], Action prob: [0.6206219  0.37937808], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6206219  0.37937808]\n",
      "Sensor: [0.3755913997697345, 0.5958175509083373, 0.2330317437017071, 0.21703108141798302], Action prob: [0.6200258  0.37997413], Action: 0, state: 0\n",
      "tensor([-0.8736, -0.5108, -0.1811,  0.0932,  0.7007,  0.2159,  0.8976,  0.5447],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 752 is 48200, loss is -0.11083433940104548\n",
      "[0.6200258  0.37997413]\n",
      "Sensor: [0.3273309327333637, 0.5663687551696646, 0.2162198964236203, 0.24595579310981347], Action prob: [0.63710624 0.36289385], Action: 0, state: 1\n",
      "[0.63710624 0.36289385]\n",
      "Sensor: [0.3760288716675828, 0.596404340939362, 0.19359396589882238, 0.26365252282413304], Action prob: [0.6375914 0.3624086], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6375914 0.3624086]\n",
      "Sensor: [0.325410311591065, 0.6733025140359865, 0.25765708882558447, 0.25390209797248514], Action prob: [0.63562196 0.36437806], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.63562196 0.36437806]\n",
      "Sensor: [0.3517209300933916, 0.6260461116282062, 0.21587508025596586, 0.38693144745813285], Action prob: [0.6334079  0.36659208], Action: 0, state: 0\n",
      "[0.6334079  0.36659208]\n",
      "Sensor: [0.3445772716125645, 0.5624832296920843, 0.17097894040738454, 0.2862063824677685], Action prob: [0.6311771 0.3688228], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.6311771 0.3688228]\n",
      "Sensor: [0.366899978826992, 0.6098859952757872, 0.22750154674091563, 0.23143702735739774], Action prob: [0.6298293  0.37017068], Action: 0, state: 0\n",
      "[0.6298293  0.37017068]\n",
      "Sensor: [0.3373307780869832, 0.6343991989602964, 0.2490924288910031, 0.23454770997003482], Action prob: [0.6292584  0.37074158], Action: 0, state: 0\n",
      "[0.6292584  0.37074158]\n",
      "Sensor: [0.3580600526488342, 0.6012593559369728, 0.17897528469117646, 0.2829756358181603], Action prob: [0.6288317  0.37116832], Action: 0, state: 1\n",
      "tensor([-0.8058, -0.9636, -0.5278, -0.0673,  0.4616,  0.2146,  0.4719,  0.6780],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 760 is 53800, loss is 0.06729721662395223\n",
      "[0.6288317  0.37116832]\n",
      "Sensor: [0.36170562915339777, 0.6382720388019841, 0.20669481903461334, 0.2556968664116811], Action prob: [0.63885945 0.36114055], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.63885945 0.36114055]\n",
      "Sensor: [0.3870546273930224, 0.625479435298575, 0.2265424709807941, 0.2843523308496431], Action prob: [0.63962805 0.36037195], Action: 0, state: 0\n",
      "[0.63962805 0.36037195]\n",
      "Sensor: [0.36014855894960796, 0.702760284475486, 0.20290407097551721, 0.216815158706399], Action prob: [0.63729656 0.3627034 ], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63729656 0.3627034 ]\n",
      "Sensor: [0.2742150122139651, 0.4500061723759716, 0.21184415271236137, 0.21305753619892415], Action prob: [0.6344468 0.3655532], Action: 0, state: 2\n",
      "[0.6344468 0.3655532]\n",
      "Sensor: [0.444097824022098, 0.5807215804556973, 0.19722113496109792, 0.3817371226107325], Action prob: [0.63319594 0.36680397], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.63319594 0.36680397]\n",
      "Sensor: [0.36458917626182813, 0.6246931109404641, 0.24020088093142908, 0.30893764357207], Action prob: [0.63232464 0.36767545], Action: 0, state: 1\n",
      "[0.63232464 0.36767545]\n",
      "Sensor: [0.3729449545432062, 0.6427997916544654, 0.21838451282171098, 0.24048020958668312], Action prob: [0.631596   0.36840397], Action: 0, state: 1\n",
      "[0.631596   0.36840397]\n",
      "Sensor: [0.3475674163887271, 0.5714131369561861, 0.21247056639632203, 0.2537009997217373], Action prob: [0.63103485 0.36896518], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "tensor([-1.3974, -0.6133, -0.3029, -0.0508,  0.3870,  0.2833,  0.4941,  1.4382],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 768 is 58800, loss is -0.029788018429718705\n",
      "[0.63103485 0.36896518]\n",
      "Sensor: [0.3757103708320343, 0.6069284132597079, 0.24846707545447766, 0.3004635867012181], Action prob: [0.64112216 0.35887784], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.64112216 0.35887784]\n",
      "Sensor: [0.36323658037995116, 0.62168059921006, 0.24371182538061248, 0.21720949167555262], Action prob: [0.6426011  0.35739896], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6426011  0.35739896]\n",
      "Sensor: [0.3091959766479693, 0.6293939128798238, 0.21173727045235438, 0.3010558643689715], Action prob: [0.64130825 0.35869172], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.64130825 0.35869172]\n",
      "Sensor: [0.3635035889093032, 0.6285364723176811, 0.19079231852779957, 0.25683360448075343], Action prob: [0.6392349 0.3607651], Action: 0, state: 0\n",
      "[0.6392349 0.3607651]\n",
      "Sensor: [0.32694168055242506, 0.658708895644661, 0.24703046905036935, 0.22689964128143958], Action prob: [0.6380196 0.3619804], Action: 0, state: 1\n",
      "[0.6380196 0.3619804]\n",
      "Sensor: [0.3672764348210457, 0.6796711636613313, 0.17195660228369936, 0.2228452229186729], Action prob: [0.6372285  0.36277148], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6372285  0.36277148]\n",
      "Sensor: [0.3891201540786088, 0.5966039967288703, 0.2222490673070113, 0.2387223272123684], Action prob: [0.6362665 0.3637335], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6362665 0.3637335]\n",
      "Sensor: [0.34832830939110637, 0.6631865524755459, 0.2278838511012949, 0.2613926841925363], Action prob: [0.6362077  0.36379227], Action: 0, state: 0\n",
      "tensor([-1.5846, -1.1188, -0.6891, -0.1361,  0.1359,  0.8517,  1.1236,  0.6142],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 776 is 64100, loss is 0.10040188922190976\n",
      "[0.6362077  0.36379227]\n",
      "Sensor: [0.35497660704565354, 0.6704023673646282, 0.20800148454468773, 0.21959181893694468], Action prob: [0.63967144 0.3603285 ], Action: 0, state: 0\n",
      "[0.63967144 0.3603285 ]\n",
      "Sensor: [0.3759922696994783, 0.6212828765628932, 0.1988679993479583, 0.23052193046493594], Action prob: [0.64138454 0.35861552], Action: 0, state: 1\n",
      "[0.64138454 0.35861552]\n",
      "Sensor: [0.36558410412193626, 0.6479140636326322, 0.22172317012565443, 0.24897759404777164], Action prob: [0.640475   0.35952508], Action: 0, state: 2\n",
      "[0.640475   0.35952508]\n",
      "Sensor: [0.3466030762181949, 0.6768385247149618, 0.20742789006177093, 0.25625563054404665], Action prob: [0.63960737 0.36039263], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.63960737 0.36039263]\n",
      "Sensor: [0.2785013717643312, 0.665167302165027, 0.19540758923819926, 0.27045639098179913], Action prob: [0.638958   0.36104205], Action: 0, state: 1\n",
      "[0.638958   0.36104205]\n",
      "Sensor: [0.38919465497794065, 0.6148381914996477, 0.23642392335372983, 0.2350289010797692], Action prob: [0.6378643  0.36213568], Action: 0, state: 2\n",
      "[0.6378643  0.36213568]\n",
      "Sensor: [0.33554179279103635, 0.6542280306949667, 0.2298443427564883, 0.2753869664113345], Action prob: [0.6375937  0.36240628], Action: 0, state: 2\n",
      "[0.6375937  0.36240628]\n",
      "Sensor: [0.3787623402421665, 0.6232769755270138, 0.24038570921231522, 0.2760039301397751], Action prob: [0.6371733  0.36282676], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "tensor([-0.7941, -0.4739, -0.2208,  0.0181,  0.1125,  0.2976,  0.4675,  1.3921],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 784 is 69300, loss is -0.09987782316905344\n",
      "[0.6371733  0.36282676]\n",
      "Sensor: [0.3271465977188864, 0.6383701145917164, 0.18870989570499414, 0.22391179589811505], Action prob: [0.6420439  0.35795614], Action: 0, state: 1\n",
      "[0.6420439  0.35795614]\n",
      "Sensor: [0.3982406091822676, 0.6498935975446765, 0.21171760420475558, 0.27434111443363746], Action prob: [0.64451396 0.35548612], Action: 0, state: 2\n",
      "[0.64451396 0.35548612]\n",
      "Sensor: [0.31577231826443863, 0.6151187415873676, 0.21622449518721015, 0.24796192681378723], Action prob: [0.6441218  0.35587817], Action: 0, state: 2\n",
      "[0.6441218  0.35587817]\n",
      "Sensor: [0.33829671294246627, 0.6204186902510588, 0.19138945636763316, 0.2435299935311762], Action prob: [0.6434722 0.3565278], Action: 0, state: 2\n",
      "[0.6434722 0.3565278]\n",
      "Sensor: [0.4333794392358121, 0.6330241360137163, 0.2166371720624014, 0.27095670427738744], Action prob: [0.6426748  0.35732523], Action: 0, state: 3\n",
      "[0.6426748  0.35732523]\n",
      "Sensor: [0.4109940702061241, 0.34834400063711, 0.22531420233508084, 0.25563839670353133], Action prob: [0.64098775 0.35901228], Action: 0, state: 3\n",
      "[0.64098775 0.35901228]\n",
      "Sensor: [0.4118711056474485, 0.62479192123282, 0.5307779108813487, 0.24717753750894836], Action prob: [0.64138216 0.3586178 ], Action: 0, state: 8\n",
      "[0.64138216 0.3586178 ]\n",
      "Sensor: [0.33245796577933684, 0.6661953658510903, 0.23083481857340551, 0.5470003920165313], Action prob: [0.6425152  0.35748485], Action: 1, state: 8\n",
      "tensor([-0.5184, -0.2004,  0.0841,  0.3389,  0.4827,  0.6152, -0.0825, -1.6630],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 792 is 63700, loss is 0.11793137634955458\n",
      "[0.6425152  0.35748485]\n",
      "Sensor: [0.39562397626542695, 0.6767005123514609, 0.2137448809477093, 0.5773143201246502], Action prob: [0.6412072 0.3587928], Action: 0, state: 8\n",
      "[0.6412072 0.3587928]\n",
      "Sensor: [0.6097296436378029, 0.6493876949042748, 0.23924566031510222, 0.28010977791719804], Action prob: [0.64090186 0.35909814], Action: 1, state: 8\n",
      "[0.64090186 0.35909814]\n",
      "Sensor: [0.3544363412885718, 0.6260244719927777, 0.2057706817147246, 0.5723349898190252], Action prob: [0.6415126  0.35848743], Action: 0, state: 8\n",
      "[0.6415126  0.35848743]\n",
      "Sensor: [0.6137956588480046, 0.37134267079060307, 0.2209517954205267, 0.2882363613575464], Action prob: [0.6386643  0.36133564], Action: 1, state: 8\n",
      "[0.6386643  0.36133564]\n",
      "Sensor: [0.3709466074486347, 0.4192457006617383, 0.22518233301662155, 0.3288023857882345], Action prob: [0.63816077 0.36183918], Action: 0, state: 8\n",
      "[0.63816077 0.36183918]\n",
      "Sensor: [0.3693837211518308, 0.6968456024208336, 0.19742127066218418, 0.5222845872228739], Action prob: [0.6393308  0.36066929], Action: 0, state: 8\n",
      "[0.6393308  0.36066929]\n",
      "Sensor: [0.3825327362508046, 0.5986560391358646, 0.5418269605871404, 0.2560820462647502], Action prob: [0.63873774 0.36126223], Action: 0, state: 8\n",
      "[0.63873774 0.36126223]\n",
      "Sensor: [0.500293163717771, 0.6673451469109305, 0.2006724469819215, 0.26052510127146583], Action prob: [0.6383932  0.36160672], Action: 1, state: 8\n",
      "tensor([ 0.7510,  1.1177,  0.2566,  0.0878, -0.1475, -0.3168, -0.4682, -1.3982],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 800 is 39700, loss is 0.014694383562142255\n",
      "[0.6383932  0.36160672]\n",
      "Sensor: [0.39073565233222673, 0.3737600321686325, 0.18008652266127556, 0.22753073205382207], Action prob: [0.63609004 0.36390996], Action: 1, state: 8\n",
      "[0.63609004 0.36390996]\n",
      "Sensor: [0.3458448885761078, 0.6227958543573737, 0.25570431152021983, 0.2186066225261158], Action prob: [0.6387082  0.36129186], Action: 0, state: 0\n",
      "[0.6387082  0.36129186]\n",
      "Sensor: [0.3693960143929841, 0.6089094914711629, 0.22231987061557396, 0.4124422784739764], Action prob: [0.6387546 0.3612454], Action: 0, state: 0\n",
      "[0.6387546 0.3612454]\n",
      "Sensor: [0.300195703622598, 0.6423805474653146, 0.24197026932921273, 0.28835729837220403], Action prob: [0.63799655 0.3620035 ], Action: 0, state: 1\n",
      "[0.63799655 0.3620035 ]\n",
      "Sensor: [0.3233806424131024, 0.5944851287390677, 0.2579483465718995, 0.24419162754566484], Action prob: [0.6370542 0.3629458], Action: 0, state: 1\n",
      "[0.6370542 0.3629458]\n",
      "Sensor: [0.39978211124686097, 0.6995819457329062, 0.18324392636314235, 0.26812453144844384], Action prob: [0.6367359  0.36326408], Action: 0, state: 1\n",
      "[0.6367359  0.36326408]\n",
      "Sensor: [0.3795209997539918, 0.6870658697913675, 0.20304268157173447, 0.3045289889349829], Action prob: [0.6365628  0.36343718], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.6365628  0.36343718]\n",
      "Sensor: [0.3291603919025606, 0.6750324666534897, 0.177863448619606, 0.23902634764873282], Action prob: [0.63637537 0.3636246 ], Action: 0, state: 0\n",
      "tensor([-1.7983, -0.4983, -0.2322, -0.0153,  0.1791,  0.3529,  1.1482,  0.5129],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 808 is 46200, loss is 0.043886621532837164\n",
      "[0.63637537 0.3636246 ]\n",
      "Sensor: [0.3471299534755079, 0.6415966600211477, 0.19534242946767602, 0.2156764778737159], Action prob: [0.63404757 0.36595237], Action: 0, state: 1\n",
      "[0.63404757 0.36595237]\n",
      "Sensor: [0.3859642849864706, 0.6219766203790654, 0.22769434036054978, 0.27129682189045234], Action prob: [0.63572216 0.36427787], Action: 0, state: 2\n",
      "[0.63572216 0.36427787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.4103543872345816, 0.6302520751135758, 0.24345202340200178, 0.23969309319884968], Action prob: [0.6347586 0.3652414], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.6347586 0.3652414]\n",
      "Sensor: [0.3078908210863124, 0.5802874028086594, 0.22632713552843522, 0.28600406055510785], Action prob: [0.6340909 0.3659091], Action: 0, state: 1\n",
      "[0.6340909 0.3659091]\n",
      "Sensor: [0.3665183879793642, 0.5670878357687046, 0.2251780162045993, 0.2701606640492606], Action prob: [0.63329405 0.36670598], Action: 0, state: 1\n",
      "[0.63329405 0.36670598]\n",
      "Sensor: [0.3275799054316505, 0.6157232289545129, 0.27220828688752, 0.22947327827479186], Action prob: [0.6329352  0.36706477], Action: 0, state: 1\n",
      "[0.6329352  0.36706477]\n",
      "Sensor: [0.3855838069848314, 0.6727049377995441, 0.21023614132039997, 0.23408177584874565], Action prob: [0.63282233 0.36717772], Action: 0, state: 1\n",
      "[0.63282233 0.36717772]\n",
      "Sensor: [0.3626622484183592, 0.6514356224861241, 0.200840992737766, 0.24757055642687117], Action prob: [0.63272583 0.3672741 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "tensor([-0.7622, -0.4429, -0.3556, -0.1910,  0.0675,  0.3039,  0.5132,  1.4941],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 816 is 51600, loss is -0.07838642430072061\n",
      "[0.63272583 0.3672741 ]\n",
      "Sensor: [0.33370805360683525, 0.5662338678669906, 0.21204223663375257, 0.25981915584367077], Action prob: [0.63356274 0.36643723], Action: 0, state: 1\n",
      "[0.63356274 0.36643723]\n",
      "Sensor: [0.3767520490919346, 0.664603269993077, 0.22053022275655168, 0.2121983216556481], Action prob: [0.6353539  0.36464605], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.6353539  0.36464605]\n",
      "Sensor: [0.33196282761893914, 0.5957989329004203, 0.26551404731210365, 0.23984064330099272], Action prob: [0.63457173 0.36542827], Action: 0, state: 1\n",
      "[0.63457173 0.36542827]\n",
      "Sensor: [0.3943563470905707, 0.5824986709530677, 0.24805353357685683, 0.26319052427980316], Action prob: [0.63352144 0.36647853], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.63352144 0.36647853]\n",
      "Sensor: [0.3726416153585434, 0.6004000772822002, 0.22471787205869553, 0.23022581854209687], Action prob: [0.6328814  0.36711863], Action: 0, state: 1\n",
      "[0.6328814  0.36711863]\n",
      "Sensor: [0.39777909704478687, 0.6347578843233067, 0.23149665946246373, 0.24861021728321686], Action prob: [0.6325858  0.36741415], Action: 0, state: 1\n",
      "[0.6325858  0.36741415]\n",
      "Sensor: [0.37793226415854025, 0.6904178830977531, 0.22818996113819676, 0.1867024423507198], Action prob: [0.63249534 0.36750466], Action: 0, state: 2\n",
      "[0.63249534 0.36750466]\n",
      "Sensor: [0.4184236956805733, 0.6313765413163741, 0.23368089939294734, 0.31350227392253216], Action prob: [0.6323496  0.36765042], Action: 0, state: 2\n",
      "tensor([-0.7628, -0.9824, -0.2981, -0.0932,  0.0740,  0.3101,  0.4995,  0.6697],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 824 is 57300, loss is 0.07288518885289878\n",
      "[0.6323496  0.36765042]\n",
      "Sensor: [0.3419651835225307, 0.5998241072657197, 0.18484426516760838, 0.2783619431828018], Action prob: [0.6310882 0.3689118], Action: 0, state: 2\n",
      "[0.6310882 0.3689118]\n",
      "Sensor: [0.3783963332546142, 0.6139129369920053, 0.21805670680278177, 0.2655348165347103], Action prob: [0.63228285 0.36771715], Action: 0, state: 2\n",
      "[0.63228285 0.36771715]\n",
      "Sensor: [0.4233160794619132, 0.683785562281075, 0.2265788572990216, 0.27832995596372534], Action prob: [0.6313177 0.3686823], Action: 0, state: 3\n",
      "[0.6313177 0.3686823]\n",
      "Sensor: [0.3995540409441748, 0.6414751474846202, 0.2191811925828211, 0.2326705982955794], Action prob: [0.63025177 0.3697483 ], Action: 0, state: 3\n",
      "[0.63025177 0.3697483 ]\n",
      "Sensor: [0.37305558522357135, 0.6509844074632907, 0.23821564652410618, 0.21040232564950961], Action prob: [0.6296807 0.3703193], Action: 0, state: 3\n",
      "[0.6296807 0.3703193]\n",
      "Sensor: [0.35148365251116664, 0.6465891141702264, 0.22515615947303588, 0.5341709471167978], Action prob: [0.6297959  0.37020412], Action: 0, state: 8\n",
      "[0.6297959  0.37020412]\n",
      "Sensor: [0.4287114022284912, 0.5895817701988825, 0.2581356491578363, 0.5920793629482841], Action prob: [0.6294808  0.37051925], Action: 1, state: 8\n",
      "[0.6294808  0.37051925]\n",
      "Sensor: [0.3943318836312925, 0.6539525225094546, 0.21134448009896836, 0.3040518560706749], Action prob: [0.62892616 0.37107384], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-0.1331,  0.1623,  0.3288,  0.4803,  0.6177, -0.1121, -1.6571, -1.2350],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 832 is 54600, loss is 0.19352186122301143\n",
      "[0.62892616 0.37107384]\n",
      "Sensor: [0.3753492715859055, 0.598662033702262, 0.17444928997083006, 0.2860116272428833], Action prob: [0.62312156 0.37687838], Action: 0, state: 0\n",
      "[0.62312156 0.37687838]\n",
      "Sensor: [0.39621499231077556, 0.60370101804161, 0.17245365140001767, 0.25265940435670853], Action prob: [0.62329423 0.3767058 ], Action: 0, state: 1\n",
      "[0.62329423 0.3767058 ]\n",
      "Sensor: [0.5232922045341417, 0.6748269336130309, 0.1958811265152938, 0.23174081716490985], Action prob: [0.6215184  0.37848163], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1100\n",
      "[0.6215184  0.37848163]\n",
      "Sensor: [0.3377320378717177, 0.6157836507128249, 0.23177571250496226, 0.24293436786277253], Action prob: [0.62063867 0.3793613 ], Action: 0, state: 1\n",
      "[0.62063867 0.3793613 ]\n",
      "Sensor: [0.402220752822532, 0.6815626020772951, 0.23931267532510223, 0.23873680102290581], Action prob: [0.6201332  0.37986675], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.6201332  0.37986675]\n",
      "Sensor: [0.3273426450843087, 0.6277118308827209, 0.19956451693095556, 0.26399143393796815], Action prob: [0.6198783  0.38012168], Action: 0, state: 0\n",
      "[0.6198783  0.38012168]\n",
      "Sensor: [0.34658781162747165, 0.6427119737418391, 0.15831928641571502, 0.5138700465150403], Action prob: [0.6198434 0.3801566], Action: 0, state: 0\n",
      "[0.6198434 0.3801566]\n",
      "Sensor: [0.3503035596083178, 0.569046011146839, 0.1823574174324821, 0.23672531407714517], Action prob: [0.61942583 0.38057417], Action: 0, state: 0\n",
      "tensor([-0.8995, -0.2207,  0.6582, -0.3503,  0.3005, -0.1011,  0.3503,  0.7551],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 840 is 58600, loss is -0.06157001953156861\n",
      "[0.61942583 0.38057417]\n",
      "Sensor: [0.3331168059920256, 0.6667866568030165, 0.20342916359657737, 0.21958048253584023], Action prob: [0.61873806 0.38126191], Action: 0, state: 0\n",
      "[0.61873806 0.38126191]\n",
      "Sensor: [0.3540076590219943, 0.6192147887827407, 0.21436382595001538, 0.20159395755725504], Action prob: [0.61801565 0.38198438], Action: 0, state: 1\n",
      "[0.61801565 0.38198438]\n",
      "Sensor: [0.29016113942386457, 0.6432470811541087, 0.19870335945324125, 0.27095490471686334], Action prob: [0.61627495 0.38372505], Action: 0, state: 1\n",
      "[0.61627495 0.38372505]\n",
      "Sensor: [0.4007598733626803, 0.6147087652006764, 0.2258168231727144, 0.23848695158021108], Action prob: [0.6146311  0.38536888], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6146311  0.38536888]\n",
      "Sensor: [0.34907069921781725, 0.6646508615030395, 0.20382900645220745, 0.2552863047169494], Action prob: [0.61395 0.38605], Action: 0, state: 0\n",
      "[0.61395 0.38605]\n",
      "Sensor: [0.3310293891966424, 0.6600959516229656, 0.20728237509666858, 0.25787227248885053], Action prob: [0.6135291 0.3864709], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.6135291 0.3864709]\n",
      "Sensor: [0.3925954359803447, 0.6044162229481785, 0.2095540712067725, 0.2956509413246416], Action prob: [0.61304235 0.38695765], Action: 0, state: 0\n",
      "[0.61304235 0.38695765]\n",
      "Sensor: [0.3893738244557407, 0.6684163457636385, 0.21252717020521483, 0.2737970342551369], Action prob: [0.6128783  0.38712165], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-0.8698, -0.5379, -0.2363,  0.0669,  0.1726,  0.8193,  0.4204,  1.2053],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 848 is 63800, loss is -0.13004899261101183\n",
      "[0.6128783  0.38712165]\n",
      "Sensor: [0.3829818189302568, 0.6192629498703306, 0.22108910436445234, 0.2991161701023387], Action prob: [0.61787117 0.38212883], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.61787117 0.38212883]\n",
      "Sensor: [0.36406597087756576, 0.6635206620599964, 0.21342911301324463, 0.24763125410087056], Action prob: [0.6170913 0.3829087], Action: 0, state: 0\n",
      "[0.6170913 0.3829087]\n",
      "Sensor: [0.3568277000951562, 0.6129145691068218, 0.22537703652430047, 0.511006447099933], Action prob: [0.61499435 0.38500562], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.61499435 0.38500562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.29614058335077476, 0.6126910387451178, 0.23163442849221078, 0.26510635558335993], Action prob: [0.61321473 0.38678527], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.61321473 0.38678527]\n",
      "Sensor: [0.323290107078998, 0.6264563638109732, 0.19422275455567037, 0.28995168413871397], Action prob: [0.61249334 0.38750666], Action: 0, state: 0\n",
      "[0.61249334 0.38750666]\n",
      "Sensor: [0.3823071220323162, 0.6595220667932875, 0.19326201580429542, 0.24057911025241815], Action prob: [0.61203605 0.38796398], Action: 0, state: 0\n",
      "[0.61203605 0.38796398]\n",
      "Sensor: [0.3347540806404188, 0.6272887024681688, 0.4407942769504152, 0.5297024199640505], Action prob: [0.6115542  0.38844576], Action: 0, state: 1\n",
      "[0.6115542  0.38844576]\n",
      "Sensor: [0.38063044030813953, 0.6165349742020071, 0.2890583937065348, 0.297491343709653], Action prob: [0.61119336 0.3888066 ], Action: 0, state: 1\n",
      "tensor([-1.2415, -0.6230, -0.3716, -0.3708, -0.0148,  0.3041,  0.5743,  0.8026],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 856 is 69000, loss is 0.1175957276433674\n",
      "[0.61119336 0.3888066 ]\n",
      "Sensor: [0.4238788027447645, 0.6251716820225711, 0.22444289865561196, 0.23238733484427418], Action prob: [0.61378366 0.3862164 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.61378366 0.3862164 ]\n",
      "Sensor: [0.2895737927873676, 0.6623590584057961, 0.19335472993783098, 0.2909728961979939], Action prob: [0.61303276 0.3869672 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.61303276 0.3869672 ]\n",
      "Sensor: [0.3553360425979646, 0.6060490175428282, 0.3345441236654242, 0.2667667089756728], Action prob: [0.61003    0.38996994], Action: 0, state: 0\n",
      "[0.61003    0.38996994]\n",
      "Sensor: [0.34615726249532974, 0.6245483607803597, 0.2133285721725678, 0.241361207634952], Action prob: [0.6083486 0.3916514], Action: 0, state: 1\n",
      "[0.6083486 0.3916514]\n",
      "Sensor: [0.3864173836258231, 0.6155077814317421, 0.23575199989354206, 0.22977305001850373], Action prob: [0.60738117 0.39261883], Action: 0, state: 2\n",
      "[0.60738117 0.39261883]\n",
      "Sensor: [0.2882877335684153, 0.4205321181999395, 0.21249492488708022, 0.2908780635600609], Action prob: [0.60680544 0.39319462], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.60680544 0.39319462]\n",
      "Sensor: [0.3608599121473205, 0.7378249189293168, 0.22367895227871842, 0.30966591379451], Action prob: [0.6066979 0.3933021], Action: 0, state: 1\n",
      "[0.6066979 0.3933021]\n",
      "Sensor: [0.4732930129105316, 0.5155509378895051, 0.20392905302200817, 0.27494124946532006], Action prob: [0.6061283  0.39387175], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.0552, -1.0470, -0.5437, -0.1728,  0.1284,  0.7536,  0.5256,  1.4356],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 864 is 73300, loss is -0.003058551987206698\n",
      "[0.6061283  0.39387175]\n",
      "Sensor: [0.2786206501080979, 0.6565984517361908, 0.2130558896205631, 0.5184582425976585], Action prob: [0.6118251  0.38817486], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6118251  0.38817486]\n",
      "Sensor: [0.34340838921831557, 0.6330391918051085, 0.24111638505893956, 0.47950339538165543], Action prob: [0.6089281  0.39107195], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -2000\n",
      "[0.6089281  0.39107195]\n",
      "Sensor: [0.34827842300067535, 0.6090119338488889, 0.2226632829744914, 0.3091669341219504], Action prob: [0.60583097 0.3941691 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.60583097 0.3941691 ]\n",
      "Sensor: [0.35486862411253284, 0.6604829512341867, 0.1860760165076934, 0.20849762692753718], Action prob: [0.6043086  0.39569148], Action: 1, state: 0\n",
      "[0.6043086  0.39569148]\n",
      "Sensor: [0.3136508817001187, 0.4205250552786244, 0.2343434837777251, 0.2340004396577052], Action prob: [0.6034484 0.3965516], Action: 0, state: 9\n",
      "[0.6034484 0.3965516]\n",
      "Sensor: [0.3640389772193777, 0.4325344257576391, 0.1598665847676591, 0.26975606921125217], Action prob: [0.6030684  0.39693162], Action: 0, state: 9\n",
      "[0.6030684  0.39693162]\n",
      "Sensor: [0.3821398535141203, 0.6207475759178266, 0.25418269033342483, 0.5861328363598769], Action prob: [0.6024403 0.3975597], Action: 1, state: 9\n",
      "[0.6024403 0.3975597]\n",
      "Sensor: [0.4550728210956293, 0.6584029663691996, 0.22232629127974035, 0.5094214665321589], Action prob: [0.6019222 0.3980778], Action: 0, state: 9\n",
      "tensor([ 1.1682,  1.4879,  0.2879,  0.2835, -0.1037, -0.3409, -0.9972, -0.7426],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 872 is 66800, loss is -0.13038463016559404\n",
      "[0.6019222 0.3980778]\n",
      "Sensor: [0.38161374364617806, 0.37923989489874366, 0.18939663659183856, 0.2618332491901594], Action prob: [0.61105055 0.3889494 ], Action: 0, state: 9\n",
      "[0.61105055 0.3889494 ]\n",
      "Sensor: [0.827481411341144, 0.656699343276193, 0.19870552900671687, 0.23164413378381582], Action prob: [0.6082654 0.3917345], Action: 0, state: 9\n",
      "[0.6082654 0.3917345]\n",
      "Sensor: [0.3835501005280823, 0.39857864942159105, 0.20555393921911308, 0.26779258908358816], Action prob: [0.6062235 0.3937765], Action: 0, state: 9\n",
      "[0.6062235 0.3937765]\n",
      "Sensor: [0.35965436334517825, 0.6172650696926776, 0.5644162509889292, 0.24029330469197543], Action prob: [0.60498226 0.39501774], Action: 0, state: 9\n",
      "[0.60498226 0.39501774]\n",
      "Sensor: [0.3875652546656118, 0.5967692071757953, 0.5478962754351469, 0.22494502974318986], Action prob: [0.604196   0.39580402], Action: 0, state: 9\n",
      "[0.604196   0.39580402]\n",
      "Sensor: [0.35710729859822044, 0.6257281336826686, 0.5049265042215292, 0.29435985138981585], Action prob: [0.6038162 0.3961838], Action: 0, state: 9\n",
      "[0.6038162 0.3961838]\n",
      "Sensor: [0.40624178027867336, 0.37606903297467587, 0.17912971506210018, 0.29758840159389377], Action prob: [0.6033846  0.39661542], Action: 1, state: 9\n",
      "[0.6033846  0.39661542]\n",
      "Sensor: [0.39797208252638805, 0.30637059448115667, 0.2400395516940205, 0.24649337717658618], Action prob: [0.6032297  0.39677033], Action: 1, state: 9\n",
      "tensor([ 0.8286,  0.5346,  0.2855,  0.0576, -0.1586, -0.3522, -0.9828, -1.2682],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 880 is 58800, loss is 0.13194120260856723\n",
      "[0.6032297  0.39677033]\n",
      "Sensor: [0.5989013128095607, 0.6090893072569527, 0.24079895543284582, 0.2795225856399059], Action prob: [0.60748136 0.39251867], Action: 0, state: 9\n",
      "[0.60748136 0.39251867]\n",
      "Sensor: [0.43797479003399087, 0.3616388811461306, 0.4097991657586314, 0.2523127759305582], Action prob: [0.60535395 0.39464608], Action: 0, state: 9\n",
      "[0.60535395 0.39464608]\n",
      "Sensor: [0.49595912137519255, 0.38432671975612165, 0.20334203839519438, 0.21403765836910876], Action prob: [0.60300505 0.39699498], Action: 1, state: 9\n",
      "[0.60300505 0.39699498]\n",
      "Sensor: [0.38890295987664214, 0.6249016436008377, 0.5399976327793146, 0.31353899269353175], Action prob: [0.60185534 0.39814466], Action: 0, state: 9\n",
      "[0.60185534 0.39814466]\n",
      "Sensor: [0.34987185223875117, 0.3739764934011713, 0.21283303884883759, 0.22744994624216835], Action prob: [0.60101354 0.39898646], Action: 1, state: 9\n",
      "[0.60101354 0.39898646]\n",
      "Sensor: [0.36623346039652394, 0.34788565892134876, 0.2043594455207068, 0.20266044217968154], Action prob: [0.6005852  0.39941475], Action: 0, state: 9\n",
      "[0.6005852  0.39941475]\n",
      "Sensor: [0.5491360733991539, 0.3954741293813024, 0.20351851961857081, 0.24577836279293908], Action prob: [0.60006243 0.3999376 ], Action: 1, state: 9\n",
      "[0.60006243 0.3999376 ]\n",
      "Sensor: [0.3675926273751331, 0.39989512180351133, 0.21698390836862536, 0.599395926139797], Action prob: [0.5997095  0.40029055], Action: 0, state: 9\n",
      "tensor([ 0.8346,  0.5541,  0.5207,  0.0577, -0.3028, -0.3648, -0.9804, -0.6978],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 888 is 50800, loss is 0.047321159616314265\n",
      "[0.5997095  0.40029055]\n",
      "Sensor: [0.5468078230734442, 0.6185220878274542, 0.18109634683676576, 0.2941466398084056], Action prob: [0.60420513 0.39579478], Action: 0, state: 9\n",
      "[0.60420513 0.39579478]\n",
      "Sensor: [0.5852274306852502, 0.6409759228040048, 0.19732871958564116, 0.2902090286712462], Action prob: [0.60184014 0.39815986], Action: 0, state: 9\n",
      "[0.60184014 0.39815986]\n",
      "Sensor: [0.5704154750469794, 0.64119226442171, 0.2484730067022885, 0.2941679603199987], Action prob: [0.59903204 0.400968  ], Action: 1, state: 9\n",
      "[0.59903204 0.400968  ]\n",
      "Sensor: [0.3552954845915784, 0.4043665333018414, 0.21615931177515604, 0.24645651987023084], Action prob: [0.59759814 0.40240192], Action: 1, state: 9\n",
      "[0.59759814 0.40240192]\n",
      "Sensor: [0.5635302467913039, 0.6028280927944707, 0.2167100908051283, 0.30404673557675094], Action prob: [0.59657776 0.40342227], Action: 1, state: 9\n",
      "[0.59657776 0.40342227]\n",
      "Sensor: [0.6330259310546, 0.6596435253875771, 0.18606816371901488, 0.26483912079700017], Action prob: [0.5959469  0.40405306], Action: 1, state: 9\n",
      "[0.5959469  0.40405306]\n",
      "Sensor: [0.34314438625538557, 0.684552480197101, 0.24095813744112635, 0.5522697934397668], Action prob: [0.59567946 0.4043205 ], Action: 0, state: 9\n",
      "[0.59567946 0.4043205 ]\n",
      "Sensor: [0.31024842846802625, 0.39269111818379343, 0.2425584422370275, 0.35449726137846577], Action prob: [0.5954731 0.4045269], Action: 1, state: 9\n",
      "tensor([ 0.8436,  0.5522,  0.5153,  0.0892, -0.3072, -0.6601, -0.5442, -1.2349],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 896 is 42800, loss is 0.09326761662172774\n",
      "[0.5954731 0.4045269]\n",
      "Sensor: [0.37854772268831943, 0.6369482206790061, 0.5285326165578885, 0.29637498369963156], Action prob: [0.5995309 0.4004691], Action: 1, state: 9\n",
      "[0.5995309 0.4004691]\n",
      "Sensor: [0.3347436381738397, 0.6268084502927425, 0.2494120413069547, 0.2542209592574397], Action prob: [0.5970727  0.40292725], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5970727  0.40292725]\n",
      "Sensor: [0.33122032834315795, 0.7515449473602607, 0.23426150824441722, 0.24992570639062078], Action prob: [0.5945906 0.4054094], Action: 0, state: 0\n",
      "[0.5945906 0.4054094]\n",
      "Sensor: [0.3476666420245653, 0.665302585542866, 0.19307590065096414, 0.2646967062856274], Action prob: [0.59239924 0.4076007 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.59239924 0.4076007 ]\n",
      "Sensor: [0.36162909655716974, 0.6436662329823749, 0.23506567040069576, 0.22929083492228572], Action prob: [0.591069   0.40893108], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.591069   0.40893108]\n",
      "Sensor: [0.28010469108322655, 0.6479847795624807, 0.21219020449164952, 0.26067690534195054], Action prob: [0.5906209 0.4093791], Action: 0, state: 0\n",
      "[0.5906209 0.4093791]\n",
      "Sensor: [0.37322346815456586, 0.5823040441849187, 0.19958825766327368, 0.4147518460945452], Action prob: [0.58985484 0.4101452 ], Action: 0, state: 0\n",
      "[0.58985484 0.4101452 ]\n",
      "Sensor: [0.3680874070874936, 0.5774271182127939, 0.25548681447301747, 0.231365012936027], Action prob: [0.58956933 0.41043073], Action: 0, state: 0\n",
      "tensor([-1.7532, -0.8489, -0.2531,  0.2113,  0.5352,  0.1455,  0.4544,  0.7338],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 904 is 48200, loss is 0.09687460894157363\n",
      "[0.58956933 0.41043073]\n",
      "Sensor: [0.32936901722764445, 0.6744047222425786, 0.21677801644700445, 0.26624008207714145], Action prob: [0.592695 0.407305], Action: 0, state: 0\n",
      "[0.592695 0.407305]\n",
      "Sensor: [0.3696137897269912, 0.623944320076917, 0.17317476454546799, 0.2713860015003781], Action prob: [0.58905214 0.4109479 ], Action: 0, state: 0\n",
      "[0.58905214 0.4109479 ]\n",
      "Sensor: [0.37175085576833716, 0.6239782944280174, 0.23031099444344638, 0.6076939883404577], Action prob: [0.58571535 0.41428462], Action: 0, state: 0\n",
      "[0.58571535 0.41428462]\n",
      "Sensor: [0.3232433045190006, 0.616484528927304, 0.15619171074326524, 0.30716978784795546], Action prob: [0.5833864  0.41661355], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5833864  0.41661355]\n",
      "Sensor: [0.36872133533245044, 0.6078747792157909, 0.220357632902338, 0.2481762122527654], Action prob: [0.58194304 0.4180569 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.58194304 0.4180569 ]\n",
      "Sensor: [0.3395206571916428, 0.6702379096036897, 0.24602746192732683, 0.22771011622360574], Action prob: [0.58144194 0.4185581 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.58144194 0.4185581 ]\n",
      "Sensor: [0.35605591702652567, 0.6603238305170295, 0.2163225507732513, 0.24926259932323458], Action prob: [0.58111167 0.4188883 ], Action: 0, state: 0\n",
      "[0.58111167 0.4188883 ]\n",
      "Sensor: [0.3749051439297959, 0.6812053025143404, 0.5376069796597598, 0.5127569236943225], Action prob: [0.5803304 0.4196697], Action: 0, state: 0\n",
      "tensor([-1.0093, -0.5828, -0.1826,  0.2851,  0.2834,  0.5232,  0.4585,  0.7126],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 912 is 54200, loss is -0.06101720603355444\n",
      "[0.5803304 0.4196697]\n",
      "Sensor: [0.3477454037635251, 0.6075874035595143, 0.22372576270949443, 0.44901544453792025], Action prob: [0.5871099  0.41289002], Action: 0, state: 0\n",
      "[0.5871099  0.41289002]\n",
      "Sensor: [0.36754934110777787, 0.6561516170580441, 0.21962595932664106, 0.2252566689627331], Action prob: [0.5831675  0.41683245], Action: 0, state: 0\n",
      "[0.5831675  0.41683245]\n",
      "Sensor: [0.3778024200962353, 0.6602976757157386, 0.18015971264658726, 0.19446737437076736], Action prob: [0.57991254 0.42008746], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.57991254 0.42008746]\n",
      "Sensor: [0.3529295885266742, 0.6663560921605401, 0.21767781374685982, 0.2557325076757507], Action prob: [0.5776292 0.4223708], Action: 0, state: 0\n",
      "[0.5776292 0.4223708]\n",
      "Sensor: [0.3282051146316288, 0.6240396176464905, 0.21510984092528113, 0.246606952759027], Action prob: [0.5762209  0.42377913], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -2500\n",
      "[0.5762209  0.42377913]\n",
      "Sensor: [0.2786379209949011, 0.7125610957561225, 0.18052412235465942, 0.2430632235951686], Action prob: [0.5755775 0.4244225], Action: 0, state: 0\n",
      "[0.5755775 0.4244225]\n",
      "Sensor: [0.37499082395754124, 0.6566056983582583, 0.22482518632243786, 0.2817611193447729], Action prob: [0.57490015 0.4250999 ], Action: 0, state: 0\n",
      "[0.57490015 0.4250999 ]\n",
      "Sensor: [0.437988402029307, 0.6439626584760697, 0.2003398116223275, 0.3107872183504431], Action prob: [0.5744782  0.42552182], Action: 0, state: 1\n",
      "tensor([-1.0509, -0.4372,  0.1154,  0.3356,  1.2578, -0.2496,  0.1307,  0.4383],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 920 is 57800, loss is -0.06750262255358114\n",
      "[0.5744782  0.42552182]\n",
      "Sensor: [0.3577168002311086, 0.6389891039545676, 0.1846554305961555, 0.2717880428355553], Action prob: [0.58475775 0.4152423 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.58475775 0.4152423 ]\n",
      "Sensor: [0.35237603993417627, 0.6199702380957796, 0.2692549241582529, 0.19995039403678327], Action prob: [0.5807614  0.41923866], Action: 0, state: 1\n",
      "[0.5807614  0.41923866]\n",
      "Sensor: [0.32778278252468607, 0.5689617648928633, 0.21439014458381886, 0.2529428916183423], Action prob: [0.5772843  0.42271572], Action: 0, state: 1\n",
      "[0.5772843  0.42271572]\n",
      "Sensor: [0.35758035968391905, 0.6223341528728069, 0.21364413173641894, 0.27946684036439373], Action prob: [0.5747366  0.42526338], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.5747366  0.42526338]\n",
      "Sensor: [0.38883628337429266, 0.7083567857376353, 0.25134986432357026, 0.2631901519031333], Action prob: [0.5730309  0.42696908], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5730309  0.42696908]\n",
      "Sensor: [0.3970175840455352, 0.6254596916568019, 0.20012297680321556, 0.4484343262657384], Action prob: [0.57172424 0.4282758 ], Action: 0, state: 0\n",
      "[0.57172424 0.4282758 ]\n",
      "Sensor: [0.38545811572774774, 0.6433413639605731, 0.19661306161456857, 0.2588586786771924], Action prob: [0.5713925 0.4286075], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5713925 0.4286075]\n",
      "Sensor: [0.3720009192656745, 0.6594756998368354, 0.2500826114626692, 0.26199901378294416], Action prob: [0.571192   0.42880806], Action: 0, state: 0\n",
      "tensor([-1.4706, -0.6993, -0.2809,  0.0923,  0.3291,  0.3926,  1.0706,  0.5673],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 928 is 62200, loss is -0.0001281361526355579\n",
      "[0.571192   0.42880806]\n",
      "Sensor: [0.3218420946010547, 0.6890820584984425, 0.2004740339442646, 0.2139250612974919], Action prob: [0.58293957 0.41706035], Action: 0, state: 1\n",
      "[0.58293957 0.41706035]\n",
      "Sensor: [0.34382527537368934, 0.666720029018214, 0.19852830656741663, 0.2636339050501336], Action prob: [0.5791264  0.42087355], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5791264  0.42087355]\n",
      "Sensor: [0.32444229088225524, 0.6643162757264894, 0.204227754981676, 0.23637670467070612], Action prob: [0.57544315 0.42455685], Action: 0, state: 0\n",
      "[0.57544315 0.42455685]\n",
      "Sensor: [0.3851686968686662, 0.6336685401993181, 0.24499660419232483, 0.2661519643503279], Action prob: [0.57256556 0.42743447], Action: 0, state: 1\n",
      "[0.57256556 0.42743447]\n",
      "Sensor: [0.31124111610377775, 0.5836405667874118, 0.24587052813251067, 0.2439294145422562], Action prob: [0.5708799  0.42912012], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.5708799  0.42912012]\n",
      "Sensor: [0.38003388870801164, 0.6167117126268227, 0.19971293903157222, 0.26571789764487114], Action prob: [0.5699822  0.43001783], Action: 0, state: 1\n",
      "[0.5699822  0.43001783]\n",
      "Sensor: [0.4487024385215449, 0.6360191969966182, 0.2789749592847989, 0.2945981909908308], Action prob: [0.5692492 0.4307508], Action: 0, state: 1\n",
      "[0.5692492 0.4307508]\n",
      "Sensor: [0.2686357730737666, 0.6205535182304704, 0.20586691656877526, 0.30826458666839635], Action prob: [0.56913006 0.43086994], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.8903, -0.7242, -0.4620, -0.0994,  0.2988,  0.3281,  0.5997,  1.2668],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 936 is 67500, loss is -0.03969778651696526\n",
      "[0.56913006 0.43086994]\n",
      "Sensor: [0.31949871016878223, 0.6963477132415637, 0.20372841763759242, 0.2612025806615782], Action prob: [0.5821532 0.4178467], Action: 0, state: 0\n",
      "[0.5821532 0.4178467]\n",
      "Sensor: [0.3628219526839661, 0.6553371737818089, 0.23889994729590874, 0.2856922601373952], Action prob: [0.5782425  0.42175743], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5782425  0.42175743]\n",
      "Sensor: [0.3509256452917159, 0.6359045548073076, 0.23366577975868572, 0.24057165196508984], Action prob: [0.5747187  0.42528126], Action: 0, state: 0\n",
      "[0.5747187  0.42528126]\n",
      "Sensor: [0.3087587824979156, 0.5804351118955539, 0.22870677993901614, 0.2684739843893066], Action prob: [0.572268   0.42773202], Action: 0, state: 0\n",
      "[0.572268   0.42773202]\n",
      "Sensor: [0.550190000606707, 0.5688801161192728, 0.20299802807875114, 0.2622739095886436], Action prob: [0.57013136 0.4298687 ], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57013136 0.4298687 ]\n",
      "Sensor: [0.3286117231656497, 0.6435302655119842, 0.2113554333187416, 0.2519485421239435], Action prob: [0.56955117 0.4304488 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.56955117 0.4304488 ]\n",
      "Sensor: [0.3320023857833931, 0.6213643644163332, 0.20665683989588118, 0.27574986014875513], Action prob: [0.56917036 0.43082967], Action: 0, state: 0\n",
      "[0.56917036 0.43082967]\n",
      "Sensor: [0.30680829313213626, 0.6903988894192306, 0.2314377710701138, 0.2536251425479672], Action prob: [0.56898016 0.43101987], Action: 0, state: 0\n",
      "tensor([-0.8887, -0.7332, -0.4707, -0.1136,  0.1681,  0.6598,  0.5733,  0.8128],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 944 is 73700, loss is -0.0009800903925014093\n",
      "[0.56898016 0.43101987]\n",
      "Sensor: [0.31886494907663965, 0.6934870037204235, 0.21991721169643305, 0.2689337613315653], Action prob: [0.58132434 0.4186756 ], Action: 0, state: 1\n",
      "[0.58132434 0.4186756 ]\n",
      "Sensor: [0.29737737645242895, 0.5973657441939247, 0.5352956251216442, 0.2721753344837847], Action prob: [0.57716626 0.42283377], Action: 0, state: 2\n",
      "[0.57716626 0.42283377]\n",
      "Sensor: [0.3553941046989883, 0.6288867786445144, 0.22954786292799734, 0.29432168661649355], Action prob: [0.57376194 0.42623815], Action: 0, state: 2\n",
      "[0.57376194 0.42623815]\n",
      "Sensor: [0.34772373818778496, 0.562092457441032, 0.2159390515801845, 0.24882694343915643], Action prob: [0.5712369 0.4287631], Action: 0, state: 2\n",
      "[0.5712369 0.4287631]\n",
      "Sensor: [0.34000652140016996, 0.7042919299976581, 0.25153381266466496, 0.23737923555331533], Action prob: [0.5695761  0.43042392], Action: 0, state: 2\n",
      "[0.5695761  0.43042392]\n",
      "Sensor: [0.609304702900361, 0.6271915837787712, 0.18751941955081786, 0.2337486926326552], Action prob: [0.5682726  0.43172747], Action: 0, state: 9\n",
      "[0.5682726  0.43172747]\n",
      "Sensor: [0.38123360019219904, 0.40016082928521723, 0.22948976763815537, 0.26715430020812775], Action prob: [0.56777334 0.43222672], Action: 1, state: 9\n",
      "[0.56777334 0.43222672]\n",
      "Sensor: [0.3515681039833816, 0.6351443826541604, 0.8117959452014568, 0.17659532329917543], Action prob: [0.56693554 0.43306452], Action: 0, state: 9\n",
      "tensor([-0.9757, -0.4411,  0.0298,  0.4719,  0.8757,  0.4143,  0.0279, -0.3302],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 952 is 72900, loss is -0.009086703041178458\n",
      "[0.56693554 0.43306452]\n",
      "Sensor: [0.3788687468394384, 0.36489266062652376, 0.23148418088377792, 0.22959981482040423], Action prob: [0.57920325 0.42079675], Action: 1, state: 9\n",
      "[0.57920325 0.42079675]\n",
      "Sensor: [0.3624329252777213, 0.3632264501139913, 0.1963574237047683, 0.19951898765773018], Action prob: [0.5759288  0.42407116], Action: 0, state: 9\n",
      "[0.5759288  0.42407116]\n",
      "Sensor: [0.399274807931951, 0.6461299921344549, 0.17603098548945395, 0.6034499656036971], Action prob: [0.57255894 0.4274411 ], Action: 0, state: 9\n",
      "[0.57255894 0.4274411 ]\n",
      "Sensor: [0.3150646982641512, 0.5922543947531862, 0.2001812141914336, 0.576300205633981], Action prob: [0.56955516 0.43044487], Action: 0, state: 9\n",
      "[0.56955516 0.43044487]\n",
      "Sensor: [0.5890931443956438, 0.7058483863073067, 0.21983769023110833, 0.23195824790919684], Action prob: [0.567012   0.43298802], Action: 0, state: 9\n",
      "[0.567012   0.43298802]\n",
      "Sensor: [0.3190507877312316, 0.3459297027313164, 0.23074287206308336, 0.2768896019252572], Action prob: [0.56617904 0.433821  ], Action: 0, state: 9\n",
      "[0.56617904 0.433821  ]\n",
      "Sensor: [0.37462593948631795, 0.6421201414338762, 0.23524702890939303, 0.5384410857312923], Action prob: [0.5652972 0.4347028], Action: 0, state: 9\n",
      "[0.5652972 0.4347028]\n",
      "Sensor: [0.3809074259185272, 0.3418507224636799, 0.21880005512049372, 0.5767104852381092], Action prob: [0.56456333 0.43543664], Action: 1, state: 9\n",
      "tensor([ 1.4580,  0.6054,  0.3211,  0.0611, -0.1970, -0.4027, -0.5999, -1.1326],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 960 is 64900, loss is -0.014160740334531047\n",
      "[0.56456333 0.43543664]\n",
      "Sensor: [0.3994321990935121, 0.3744759648162806, 0.23416752015318704, 0.2844444113034219], Action prob: [0.57879555 0.4212044 ], Action: 1, state: 9\n",
      "[0.57879555 0.4212044 ]\n",
      "Sensor: [0.3808686980566091, 0.3797163137222158, 0.23502313234307262, 0.26048839016894043], Action prob: [0.57495576 0.42504427], Action: 0, state: 9\n",
      "[0.57495576 0.42504427]\n",
      "Sensor: [0.3745924293862561, 0.44328937077845626, 0.23619613904332143, 0.2787470467303699], Action prob: [0.571281   0.42871892], Action: 0, state: 9\n",
      "[0.571281   0.42871892]\n",
      "Sensor: [0.33605082240812295, 0.3642132815525964, 0.24756471578347022, 0.24912684393734105], Action prob: [0.56831527 0.4316847 ], Action: 1, state: 9\n",
      "[0.56831527 0.4316847 ]\n",
      "Sensor: [0.551645507691875, 0.5805100930783093, 0.21763994232126516, 0.27760744542702], Action prob: [0.5661171 0.4338829], Action: 1, state: 9\n",
      "[0.5661171 0.4338829]\n",
      "Sensor: [0.3437443336308269, 0.6128729108097584, 0.19435209947997767, 0.5561841985760263], Action prob: [0.56460744 0.43539247], Action: 0, state: 9\n",
      "[0.56460744 0.43539247]\n",
      "Sensor: [0.3703429475647479, 0.639562655306244, 0.48384148697471757, 0.24494407912168356], Action prob: [0.56371933 0.4362806 ], Action: 0, state: 9\n",
      "[0.56371933 0.4362806 ]\n",
      "Sensor: [0.3903111212120776, 0.39145263239324873, 0.23159715857265514, 0.2702420404693253], Action prob: [0.56332695 0.43667296], Action: 1, state: 9\n",
      "tensor([ 1.4560,  0.6083,  0.3207,  0.0854, -0.2871, -0.4034, -0.5985, -1.1360],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 968 is 56900, loss is -0.005684478949767646\n",
      "[0.56332695 0.43667296]\n",
      "Sensor: [0.3880406321039553, 0.60750967509633, 0.5107144281070034, 0.23284581358314346], Action prob: [0.57869935 0.4213007 ], Action: 0, state: 9\n",
      "[0.57869935 0.4213007 ]\n",
      "Sensor: [0.408482321696682, 0.39851596929668626, 0.23517129750684593, 0.18718242642659078], Action prob: [0.57391083 0.42608923], Action: 0, state: 9\n",
      "[0.57391083 0.42608923]\n",
      "Sensor: [0.38300633327352746, 0.6404077344334705, 0.22688950308169584, 0.5872371397937778], Action prob: [0.5697998 0.4302002], Action: 0, state: 9\n",
      "[0.5697998 0.4302002]\n",
      "Sensor: [0.34910685354354654, 0.5410919379190979, 0.5084811533109743, 0.23922695730772733], Action prob: [0.56581736 0.4341826 ], Action: 0, state: 9\n",
      "[0.56581736 0.4341826 ]\n",
      "Sensor: [0.49691377103590084, 0.6230794447496081, 0.24569701466646565, 0.30046354924272195], Action prob: [0.5634489  0.43655115], Action: 1, state: 9\n",
      "[0.5634489  0.43655115]\n",
      "Sensor: [0.38866421258466827, 0.6525538812128024, 0.20068354036977476, 0.22359809754240256], Action prob: [0.5625837  0.43741626], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -4500\n",
      "Maintenance in progress, cumulative -3500\n",
      "[0.5625837  0.43741626]\n",
      "Sensor: [0.32155950483510853, 0.6195945212961125, 0.2031777240552401, 0.567862322524298], Action prob: [0.56125975 0.43874022], Action: 0, state: 0\n",
      "[0.56125975 0.43874022]\n",
      "Sensor: [0.3555672555717628, 0.6891189808251136, 0.22308522612272577, 0.2216074789666887], Action prob: [0.5610647  0.43893522], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "tensor([ 0.9500,  0.5886,  0.2712, -0.0220, -0.4516, -0.0916, -0.8381, -0.9178],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 976 is 49900, loss is 0.06390824546003952\n",
      "[0.5610647  0.43893522]\n",
      "Sensor: [0.3621607105299521, 0.6453945236683553, 0.2213471379916972, 0.25543565528504164], Action prob: [0.5778557  0.42214426], Action: 0, state: 0\n",
      "[0.5778557  0.42214426]\n",
      "Sensor: [0.3204549339087149, 0.6326442767278252, 0.24854533877299123, 0.2958704649635459], Action prob: [0.5723131 0.427687 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5723131 0.427687 ]\n",
      "Sensor: [0.3563264148357383, 0.6148851129252111, 0.19914195122446626, 0.258838450401759], Action prob: [0.5666635  0.43333647], Action: 0, state: 0\n",
      "[0.5666635  0.43333647]\n",
      "Sensor: [0.3414082697729645, 0.5872659889861548, 0.18243735123478783, 0.2702409758931611], Action prob: [0.56244576 0.43755424], Action: 0, state: 1\n",
      "[0.56244576 0.43755424]\n",
      "Sensor: [0.3588426813980711, 0.6380035148877985, 0.22553685458010955, 0.22836914997108837], Action prob: [0.5599345  0.44006553], Action: 0, state: 1\n",
      "[0.5599345  0.44006553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3258518965544966, 0.6635893180576874, 0.20283321777969476, 0.23368990080568325], Action prob: [0.5583642  0.44163585], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5583642  0.44163585]\n",
      "Sensor: [0.4058814611533458, 0.6559454958075083, 0.1913123521276413, 0.19056658157595424], Action prob: [0.55717224 0.44282776], Action: 0, state: 0\n",
      "[0.55717224 0.44282776]\n",
      "Sensor: [0.3706098801988, 0.6422401583337548, 0.2072821726806383, 0.2694425961080531], Action prob: [0.55614257 0.44385734], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "tensor([-0.9736, -0.8429, -0.3695, -0.0485,  0.2464,  0.7229,  0.5122,  1.0517],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 984 is 54100, loss is -0.03731678940083959\n",
      "[0.55614257 0.44385734]\n",
      "Sensor: [0.3760411280235394, 0.6419355346836747, 0.20583936863695507, 0.17526270488548581], Action prob: [0.57719225 0.42280775], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.57719225 0.42280775]\n",
      "Sensor: [0.3239926152138934, 0.6476138594451558, 0.23609628814472738, 0.21336961119667547], Action prob: [0.5714075  0.42859253], Action: 0, state: 0\n",
      "[0.5714075  0.42859253]\n",
      "Sensor: [0.31752715379642726, 0.6516587331990182, 0.21000309014703486, 0.5728068371258265], Action prob: [0.5654104  0.43458965], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5654104  0.43458965]\n",
      "Sensor: [0.3594555280361153, 0.6700304992611625, 0.2331935027930157, 0.20912346273399723], Action prob: [0.56081086 0.4391891 ], Action: 0, state: 0\n",
      "[0.56081086 0.4391891 ]\n",
      "Sensor: [0.34932889864945854, 0.5811549985478, 0.22062145316955104, 0.2651179928559949], Action prob: [0.5581771  0.44182295], Action: 0, state: 0\n",
      "[0.5581771  0.44182295]\n",
      "Sensor: [0.3962155411542412, 0.606706941206657, 0.19973680106357317, 0.38377892311719697], Action prob: [0.5560481  0.44395196], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5560481  0.44395196]\n",
      "Sensor: [0.3678361507249633, 0.6523191102460992, 0.2002588980880926, 0.24830805019004876], Action prob: [0.5550094  0.44499055], Action: 0, state: 0\n",
      "[0.5550094  0.44499055]\n",
      "Sensor: [0.33809583392066495, 0.6882235724091568, 0.2192181624387295, 0.260117427844437], Action prob: [0.55425096 0.4457491 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.3636, -0.6729, -0.4316, -0.1332,  0.1848,  0.6545,  0.6031,  1.1200],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 992 is 60000, loss is 0.004864116357189224\n",
      "[0.55425096 0.4457491 ]\n",
      "Sensor: [0.3991031431871333, 0.6036099641189808, 0.21312048024005043, 0.24324548907162793], Action prob: [0.57624686 0.42375317], Action: 0, state: 0\n",
      "[0.57624686 0.42375317]\n",
      "Sensor: [0.37252839195809995, 0.6367703210979134, 0.21973501399530013, 0.259739186471206], Action prob: [0.57017785 0.42982215], Action: 0, state: 0\n",
      "[0.57017785 0.42982215]\n",
      "Sensor: [0.28389199396648557, 0.6035450005379024, 0.18523598832871413, 0.23900039465556489], Action prob: [0.5651355  0.43486452], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5651355  0.43486452]\n",
      "Sensor: [0.30984037431794104, 0.6402266478209165, 0.19050560801928018, 0.28223008200223304], Action prob: [0.56132746 0.43867248], Action: 0, state: 0\n",
      "[0.56132746 0.43867248]\n",
      "Sensor: [0.36244440160300745, 0.6804944502577941, 0.24249821522092896, 0.2728018638926053], Action prob: [0.55881625 0.4411837 ], Action: 0, state: 0\n",
      "[0.55881625 0.4411837 ]\n",
      "Sensor: [0.33552942957714277, 0.6530744316006432, 0.25899663445769194, 0.27916470120783354], Action prob: [0.5571063  0.44289365], Action: 0, state: 1\n",
      "[0.5571063  0.44289365]\n",
      "Sensor: [0.33504534212967735, 0.5984363278426573, 0.25829837442543746, 0.33323098116969285], Action prob: [0.55572283 0.4442772 ], Action: 0, state: 1\n",
      "[0.55572283 0.4442772 ]\n",
      "Sensor: [0.3385847735908585, 0.6065876031751102, 0.22284434348322443, 0.22124494063299013], Action prob: [0.55513614 0.4448638 ], Action: 0, state: 1\n",
      "tensor([-0.9600, -0.5987, -0.3794, -0.1061,  0.1775,  0.4130,  0.6259,  0.8122],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1000 is 67100, loss is 0.0019538713196453755\n",
      "[0.55513614 0.4448638 ]\n",
      "Sensor: [0.3968937347870665, 0.6532464882834902, 0.21444042187799806, 0.2553957320089411], Action prob: [0.57546264 0.42453736], Action: 0, state: 1\n",
      "[0.57546264 0.42453736]\n",
      "Sensor: [0.3996688166818791, 0.6554972951252163, 0.2059962487160725, 0.19585762670461132], Action prob: [0.56841624 0.43158385], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1100\n",
      "[0.56841624 0.43158385]\n",
      "Sensor: [0.3680852084808648, 0.6376581155623046, 0.22967213765517175, 0.26218370849414985], Action prob: [0.56248474 0.43751526], Action: 0, state: 1\n",
      "[0.56248474 0.43751526]\n",
      "Sensor: [0.36569646016321095, 0.6377196943442142, 0.24898562978207597, 0.25397733770085973], Action prob: [0.55822545 0.44177452], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.55822545 0.44177452]\n",
      "Sensor: [0.3778289949735514, 0.6594576317963475, 0.23839585773495858, 0.19104740008926585], Action prob: [0.55576086 0.4442391 ], Action: 0, state: 1\n",
      "[0.55576086 0.4442391 ]\n",
      "Sensor: [0.3769224713589758, 0.651507923492832, 0.22605885342521792, 0.2350629564336003], Action prob: [0.5538548 0.4461452], Action: 0, state: 2\n",
      "[0.5538548 0.4461452]\n",
      "Sensor: [0.35185289489899724, 0.6381908198757217, 0.24697311614381828, 0.25933846444550257], Action prob: [0.55243164 0.4475684 ], Action: 0, state: 3\n",
      "[0.55243164 0.4475684 ]\n",
      "Sensor: [0.5618482472421189, 0.6545388746737456, 0.1789609278064094, 0.26656112368217133], Action prob: [0.55094534 0.44905463], Action: 0, state: 8\n",
      "tensor([-0.4210,  0.6382, -0.6445,  0.0949, -0.0159,  0.5755,  0.9147, -0.9065],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1008 is 62800, loss is -0.029429004107792853\n",
      "[0.55094534 0.44905463]\n",
      "Sensor: [0.3297632784820262, 0.3906990989882518, 0.22647654843045006, 0.2870954296433484], Action prob: [0.5755209  0.42447916], Action: 1, state: 8\n",
      "[0.5755209  0.42447916]\n",
      "Sensor: [0.43270633660872637, 0.6675550778020928, 0.20287236930431002, 0.3258928661884578], Action prob: [0.56809586 0.43190414], Action: 0, state: 0\n",
      "[0.56809586 0.43190414]\n",
      "Sensor: [0.35646607046289425, 0.6636878368498619, 0.23636456309434686, 0.20360456311296765], Action prob: [0.56162894 0.43837106], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.56162894 0.43837106]\n",
      "Sensor: [0.39256598252753355, 0.6263945435566183, 0.2250792957824308, 0.20665575588217866], Action prob: [0.5570154  0.44298455], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5570154  0.44298455]\n",
      "Sensor: [0.3110631689349861, 0.7003618102868485, 0.20373097570541357, 0.22930050707359678], Action prob: [0.5543042  0.44569576], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5543042  0.44569576]\n",
      "Sensor: [0.2903522879620506, 0.5961834455529844, 0.2621482154806426, 0.20268737242627477], Action prob: [0.5522443 0.4477556], Action: 0, state: 0\n",
      "[0.5522443 0.4477556]\n",
      "Sensor: [0.3587489414128854, 0.6552674089850267, 0.15408958844364595, 0.24548967939142394], Action prob: [0.55068386 0.44931614], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.55068386 0.44931614]\n",
      "Sensor: [0.4175906401294343, 0.6864040232679631, 0.19825987116748134, 0.24340578562963117], Action prob: [0.54935014 0.45064986], Action: 0, state: 0\n",
      "tensor([-1.7444, -0.5910, -0.1159,  0.2121,  0.2162,  0.3565,  0.9431,  0.5455],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1016 is 67200, loss is 0.022216291324740706\n",
      "[0.54935014 0.45064986]\n",
      "Sensor: [0.39198162980227497, 0.5783591221791494, 0.25315625209541714, 0.2987510405011815], Action prob: [0.5748764 0.4251236], Action: 0, state: 1\n",
      "[0.5748764 0.4251236]\n",
      "Sensor: [0.32807378531490317, 0.632125573113378, 0.186952529380213, 0.23838360445910423], Action prob: [0.56784165 0.43215832], Action: 0, state: 1\n",
      "[0.56784165 0.43215832]\n",
      "Sensor: [0.3287078478231497, 0.6509714947943838, 0.23955672076779594, 0.27291344580135635], Action prob: [0.5607765  0.43922356], Action: 0, state: 1\n",
      "[0.5607765  0.43922356]\n",
      "Sensor: [0.39441638122414996, 0.6790460666081504, 0.23881221575582284, 0.24682213671957814], Action prob: [0.5556125  0.44438747], Action: 0, state: 1\n",
      "[0.5556125  0.44438747]\n",
      "Sensor: [0.31713395235312725, 0.6222445440555704, 0.24243892872865794, 0.18111286836836826], Action prob: [0.55259204 0.447408  ], Action: 0, state: 1\n",
      "[0.55259204 0.447408  ]\n",
      "Sensor: [0.3300662449371479, 0.6315938418040652, 0.19988637085631478, 0.1887842088306614], Action prob: [0.5504182  0.44958174], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.5504182  0.44958174]\n",
      "Sensor: [0.34060388307775114, 0.6728814335812665, 0.20496158577679188, 0.26426997548930575], Action prob: [0.5486038 0.4513963], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5486038 0.4513963]\n",
      "Sensor: [0.37714812079702914, 0.628147435564556, 0.2436205113585599, 0.24314664340227574], Action prob: [0.54714113 0.45285892], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "tensor([-1.0060, -0.6419, -0.2969,  0.0198,  0.3186,  0.7453,  0.7078,  0.8638],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1024 is 70500, loss is -0.08880268637631915\n",
      "[0.54714113 0.45285892]\n",
      "Sensor: [0.36091486925619376, 0.6884188520679834, 0.2128195897736425, 0.23901774232017578], Action prob: [0.57865983 0.42134023], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57865983 0.42134023]\n",
      "Sensor: [0.6037813352145659, 0.6558784793613415, 0.18511598299410534, 0.28042081600523444], Action prob: [0.56990296 0.430097  ], Action: 0, state: 9\n",
      "[0.56990296 0.430097  ]\n",
      "Sensor: [0.3022601287963747, 0.36834442699083586, 0.24562076514301662, 0.23167962789260613], Action prob: [0.5640073  0.43599266], Action: 1, state: 9\n",
      "[0.5640073  0.43599266]\n",
      "Sensor: [0.3541499866623433, 0.4048609824732674, 0.2541538469274459, 0.24994726381090038], Action prob: [0.55987924 0.4401208 ], Action: 0, state: 9\n",
      "[0.55987924 0.4401208 ]\n",
      "Sensor: [0.3831061541234708, 0.6458976043241451, 0.8404831283081027, 0.18650712488687013], Action prob: [0.5564213 0.4435787], Action: 0, state: 9\n",
      "[0.5564213 0.4435787]\n",
      "Sensor: [0.39124266936649105, 0.6649914841834849, 0.49669052644523803, 0.2127064230175439], Action prob: [0.5543666  0.44563332], Action: 0, state: 9\n",
      "[0.5543666  0.44563332]\n",
      "Sensor: [0.36667728521781945, 0.669007090886233, 0.2282784481700116, 0.5989422547966887], Action prob: [0.55242556 0.44757447], Action: 1, state: 9\n",
      "[0.55242556 0.44757447]\n",
      "Sensor: [0.3445569282555892, 0.38492049775307974, 0.22117960149105262, 0.23390092112770758], Action prob: [0.5517893  0.44821072], Action: 0, state: 9\n",
      "tensor([ 0.9232,  0.6068,  0.4836,  0.0608, -0.1656, -0.4089, -0.8356, -0.8118],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1032 is 62500, loss is 0.01844235077494931\n",
      "[0.5517893  0.44821072]\n",
      "Sensor: [0.4133324325690737, 0.3098563193645899, 0.2336456033803259, 0.46299301478309846], Action prob: [0.5786242 0.4213758], Action: 1, state: 9\n",
      "[0.5786242 0.4213758]\n",
      "Sensor: [0.6327456558770346, 0.4094728066194495, 0.25351309898766355, 0.24940598141726925], Action prob: [0.5708637  0.42913637], Action: 1, state: 9\n",
      "[0.5708637  0.42913637]\n",
      "Sensor: [0.5630155575962686, 0.6486478635495597, 0.20640517578972162, 0.2148604676639429], Action prob: [0.56640786 0.4335921 ], Action: 1, state: 9\n",
      "[0.56640786 0.4335921 ]\n",
      "Sensor: [0.3890901510041498, 0.6191429518553786, 0.17809367322523556, 0.5277195072465106], Action prob: [0.56290257 0.43709746], Action: 0, state: 9\n",
      "[0.56290257 0.43709746]\n",
      "Sensor: [0.3271881085918429, 0.5848531328001786, 0.24808019042958515, 0.6035089336056528], Action prob: [0.5604026  0.43959743], Action: 1, state: 9\n",
      "[0.5604026  0.43959743]\n",
      "Sensor: [0.5178235211040095, 0.5975092647220569, 0.17712025355198985, 0.5036198857422518], Action prob: [0.55840284 0.44159716], Action: 1, state: 9\n",
      "[0.55840284 0.44159716]\n",
      "Sensor: [0.3367270649882415, 0.3857868870882349, 0.20402107604849867, 0.26105181037826614], Action prob: [0.5580419  0.44195813], Action: 1, state: 9\n",
      "[0.5580419  0.44195813]\n",
      "Sensor: [0.3313737335878457, 0.5935804697914044, 0.5416145656427993, 0.24631019866676804], Action prob: [0.557504   0.44249603], Action: 0, state: 9\n",
      "tensor([ 1.4635,  0.9124,  0.4617,  0.0617, -0.2504, -0.5862, -0.8613, -0.7830],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1040 is 54500, loss is -0.052309441135965154\n",
      "[0.557504   0.44249603]\n",
      "Sensor: [0.5292991332492273, 0.6266929969262109, 0.21245575499731398, 0.23733285733578097], Action prob: [0.58193606 0.418064  ], Action: 0, state: 9\n",
      "[0.58193606 0.418064  ]\n",
      "Sensor: [0.3199779176689895, 0.6283491886919076, 0.21384872647171335, 0.5591926202082812], Action prob: [0.57808274 0.4219173 ], Action: 0, state: 9\n",
      "[0.57808274 0.4219173 ]\n",
      "Sensor: [0.5878802379062661, 0.6117165086113865, 0.2385061920089453, 0.19766029688109493], Action prob: [0.57125217 0.4287479 ], Action: 0, state: 9\n",
      "[0.57125217 0.4287479 ]\n",
      "Sensor: [0.5715325608461215, 0.6884656789509629, 0.1915753662265534, 0.5702314246205994], Action prob: [0.5673113 0.4326887], Action: 0, state: 9\n",
      "[0.5673113 0.4326887]\n",
      "Sensor: [0.6099041671318708, 0.6475605680102627, 0.15844249462886428, 0.23088283500603457], Action prob: [0.56541365 0.4345864 ], Action: 0, state: 9\n",
      "[0.56541365 0.4345864 ]\n",
      "Sensor: [0.5700289729390962, 0.6757156815561397, 0.2396961549877759, 0.22944518245324927], Action prob: [0.56422555 0.43577445], Action: 0, state: 9\n",
      "[0.56422555 0.43577445]\n",
      "Sensor: [0.5841170907599297, 0.6230689921324073, 0.23269718508040516, 0.2247945383541313], Action prob: [0.5633948  0.43660522], Action: 0, state: 9\n",
      "[0.5633948  0.43660522]\n",
      "Sensor: [0.5431267489044473, 0.6079057432416616, 0.19548494410556141, 0.2761049324442722], Action prob: [0.56285936 0.43714067], Action: 0, state: 9\n",
      "tensor([ 0.9029,  0.6136,  0.3076,  0.0520, -0.2045, -0.4193, -0.6200, -0.7977],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1048 is 46500, loss is 0.020682621323025063\n",
      "[0.56285936 0.43714067]\n",
      "Sensor: [0.5569450022286244, 0.687576388460245, 0.2468205692624518, 0.27419452740481126], Action prob: [0.5845472  0.41545278], Action: 0, state: 9\n",
      "[0.5845472  0.41545278]\n",
      "Sensor: [0.5738483674647206, 0.6289179165155463, 0.2021692106893922, 0.21784560377947987], Action prob: [0.5796911  0.42030892], Action: 0, state: 9\n",
      "[0.5796911  0.42030892]\n",
      "Sensor: [0.4495178925602822, 0.3320133130652638, 0.2309071926624469, 0.24912141130661006], Action prob: [0.5753617 0.4246383], Action: 1, state: 9\n",
      "[0.5753617 0.4246383]\n",
      "Sensor: [0.35488196257530746, 0.391610782367325, 0.2066315475151699, 0.23352297351589987], Action prob: [0.57314473 0.42685527], Action: 1, state: 9\n",
      "[0.57314473 0.42685527]\n",
      "Sensor: [0.3392400970239994, 0.38222794932979387, 0.18877197711496235, 0.25269851442162305], Action prob: [0.5719502 0.4280498], Action: 1, state: 9\n",
      "[0.5719502 0.4280498]\n",
      "Sensor: [0.34604758091342946, 0.39999389927644435, 0.21228263849277046, 0.2753775431975332], Action prob: [0.5710698 0.4289303], Action: 1, state: 9\n",
      "[0.5710698 0.4289303]\n",
      "Sensor: [0.36390205893275956, 0.3698382186293013, 0.19531760585998753, 0.24287648863239233], Action prob: [0.5705922  0.42940775], Action: 0, state: 9\n",
      "[0.5705922  0.42940775]\n",
      "Sensor: [0.5762958339471005, 0.6901190161286098, 0.22864878274811934, 0.2606748883238168], Action prob: [0.57007337 0.42992663], Action: 1, state: 9\n",
      "tensor([ 0.8975,  0.5877,  0.4865,  0.0854, -0.2761, -0.5987, -0.5936, -1.1714],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1056 is 40500, loss is 0.07284130551453047\n",
      "[0.57007337 0.42992663]\n",
      "Sensor: [0.3976155583040364, 0.6310137159377068, 0.19928699438881456, 0.25142609686637274], Action prob: [0.58615506 0.41384494], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.58615506 0.41384494]\n",
      "Sensor: [0.36347251305187783, 0.5876127680192015, 0.18591320065429653, 0.2259637055831124], Action prob: [0.5828266  0.41717345], Action: 0, state: 0\n",
      "[0.5828266  0.41717345]\n",
      "Sensor: [0.3440635013412757, 0.6729792029106602, 0.22575452283239547, 0.21557550067808173], Action prob: [0.57913256 0.42086744], Action: 0, state: 0\n",
      "[0.57913256 0.42086744]\n",
      "Sensor: [0.336731191837861, 0.6020851276375151, 0.20955015512500777, 0.24791435650049232], Action prob: [0.5764896 0.4235104], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5764896 0.4235104]\n",
      "Sensor: [0.39659607648179424, 0.5970769136514934, 0.24328134444085237, 0.18591547736657443], Action prob: [0.57465714 0.4253429 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.57465714 0.4253429 ]\n",
      "Sensor: [0.3802196223540737, 0.6227912355037167, 0.19755986039854362, 0.24036406542998265], Action prob: [0.5738718 0.4261282], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5738718 0.4261282]\n",
      "Sensor: [0.3722986385694802, 0.680115529826818, 0.24682359616529084, 0.25257281945681925], Action prob: [0.57338613 0.4266139 ], Action: 0, state: 0\n",
      "[0.57338613 0.4266139 ]\n",
      "Sensor: [0.3910600237895287, 0.6281449883083644, 0.23961851181285654, 0.2326630617204884], Action prob: [0.5730259  0.42697412], Action: 0, state: 1\n",
      "tensor([-1.5846, -0.7086, -0.2401,  0.2946,  0.5879,  0.5873,  0.3861,  0.6414],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1064 is 45300, loss is 0.004497263756794476\n",
      "[0.5730259  0.42697412]\n",
      "Sensor: [0.36327211997548703, 0.6202294792628862, 0.249268564279778, 0.262980099077649], Action prob: [0.5864617  0.41353825], Action: 0, state: 1\n",
      "[0.5864617  0.41353825]\n",
      "Sensor: [0.3730747609812461, 0.6889755003434275, 0.1983891137055994, 0.3041043548885916], Action prob: [0.58413684 0.41586313], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -2600\n",
      "[0.58413684 0.41586313]\n",
      "Sensor: [0.36718141072693417, 0.6088389643574544, 0.20291460135799647, 0.2582744508658198], Action prob: [0.58028406 0.4197159 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.58028406 0.4197159 ]\n",
      "Sensor: [0.3299579707323521, 0.6631893260883998, 0.21530714222314454, 0.2165246764262761], Action prob: [0.5782388  0.42176124], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5782388  0.42176124]\n",
      "Sensor: [0.3230521366079748, 0.6021302847362914, 0.22558441500331752, 0.22370229843119352], Action prob: [0.5767277  0.42327228], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -2000\n",
      "[0.5767277  0.42327228]\n",
      "Sensor: [0.3838615064561151, 0.6605060950105418, 0.22078409484500044, 0.2655635483245222], Action prob: [0.5758788 0.4241211], Action: 0, state: 0\n",
      "[0.5758788 0.4241211]\n",
      "Sensor: [0.31211207520966666, 0.6000354758186422, 0.22254854351107634, 0.2327129831413465], Action prob: [0.57555807 0.42444193], Action: 0, state: 0\n",
      "[0.57555807 0.42444193]\n",
      "Sensor: [0.3491976869458393, 0.673386284739588, 0.20994806028254703, 0.2053202716956598], Action prob: [0.57547617 0.4245238 ], Action: 0, state: 1\n",
      "tensor([ 0.6885,  1.6694,  0.0871, -0.4493, -0.2044, -0.6911, -0.4374, -0.2378],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for up to this timestep 1072 is 43800, loss is -0.05312158280083381\n",
      "[0.57547617 0.4245238 ]\n",
      "Sensor: [0.3670795980025261, 0.6415072723389321, 0.24153975376999587, 0.3429451933977197], Action prob: [0.58839995 0.41160005], Action: 0, state: 1\n",
      "[0.58839995 0.41160005]\n",
      "Sensor: [0.3408735235733773, 0.3915673011225008, 0.17904886666793082, 0.2282093516901938], Action prob: [0.58560354 0.4143965 ], Action: 0, state: 9\n",
      "[0.58560354 0.4143965 ]\n",
      "Sensor: [0.3476763999181266, 0.6399731442129918, 0.4846898356515293, 0.24444140948344534], Action prob: [0.5832787 0.4167213], Action: 0, state: 9\n",
      "[0.5832787 0.4167213]\n",
      "Sensor: [0.3795633898785877, 0.4053134850799558, 0.2533482203378642, 0.22274900716234378], Action prob: [0.58061963 0.41938043], Action: 0, state: 9\n",
      "[0.58061963 0.41938043]\n",
      "Sensor: [0.40586696488293883, 0.3982356520982336, 0.22178552600954154, 0.2529821241818097], Action prob: [0.5792681  0.42073196], Action: 0, state: 9\n",
      "[0.5792681  0.42073196]\n",
      "Sensor: [0.37221206431130227, 0.4034962937878788, 0.21616381080862224, 0.20158769085866818], Action prob: [0.5788613  0.42113864], Action: 0, state: 9\n",
      "[0.5788613  0.42113864]\n",
      "Sensor: [0.3555250754577268, 0.326648235532092, 0.2411613728294873, 0.24224139205070674], Action prob: [0.57850736 0.4214927 ], Action: 0, state: 9\n",
      "[0.57850736 0.4214927 ]\n",
      "Sensor: [0.35710696902810696, 0.6171100839576507, 0.1987802653847201, 0.5505612262683379], Action prob: [0.5782826 0.4217174], Action: 0, state: 9\n",
      "tensor([ 0.9019,  0.5921,  0.3276,  0.0582, -0.1768, -0.3869, -0.5730, -0.7369],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1080 is 35800, loss is -0.0007859012774337482\n",
      "[0.5782826 0.4217174]\n",
      "Sensor: [0.548556716247784, 0.6225938351735775, 0.22601374312445915, 0.2175883562266839], Action prob: [0.5880174 0.4119826], Action: 0, state: 9\n",
      "[0.5880174 0.4119826]\n",
      "Sensor: [0.2627016352648313, 0.3652929295075024, 0.1911554384688894, 0.2205225875968665], Action prob: [0.5873167  0.41268334], Action: 1, state: 9\n",
      "[0.5873167  0.41268334]\n",
      "Sensor: [0.3211018204930121, 0.35060626049807486, 0.2136209799804583, 0.20912942390818157], Action prob: [0.5853158  0.41468418], Action: 0, state: 9\n",
      "[0.5853158  0.41468418]\n",
      "Sensor: [0.3760524157266893, 0.6999595283409319, 0.5123457550249073, 0.261682708595393], Action prob: [0.58426416 0.41573584], Action: 0, state: 9\n",
      "[0.58426416 0.41573584]\n",
      "Sensor: [0.3997235692129788, 0.3723529928628417, 0.22732869038843376, 0.23447378315188916], Action prob: [0.5828662  0.41713375], Action: 1, state: 9\n",
      "[0.5828662  0.41713375]\n",
      "Sensor: [0.402358100478329, 0.3386671793188659, 0.19683993017917958, 0.27501977924421056], Action prob: [0.58220553 0.4177945 ], Action: 1, state: 9\n",
      "[0.58220553 0.4177945 ]\n",
      "Sensor: [0.3761214031890846, 0.37268101833483863, 0.21412290834059788, 0.290385519257016], Action prob: [0.5819646  0.41803536], Action: 0, state: 9\n",
      "[0.5819646  0.41803536]\n",
      "Sensor: [0.6003542978720388, 0.66832582333891, 0.19677292041078356, 0.2242660238156359], Action prob: [0.58200014 0.41799986], Action: 0, state: 9\n",
      "tensor([ 0.8860,  0.9852,  0.3113,  0.0705, -0.2852, -0.6205, -0.5693, -0.7550],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1088 is 27800, loss is -0.0028830449826536125\n",
      "[0.58200014 0.41799986]\n",
      "Sensor: [0.4298825959791703, 0.3680585927946439, 0.25184496545988133, 0.21198802414272555], Action prob: [0.58913827 0.41086176], Action: 1, state: 9\n",
      "[0.58913827 0.41086176]\n",
      "Sensor: [0.36896083280195013, 0.33701231818756916, 0.21769892148756576, 0.2880305930945782], Action prob: [0.58864105 0.411359  ], Action: 0, state: 9\n",
      "[0.58864105 0.411359  ]\n",
      "Sensor: [0.5383805611121654, 0.6051680645939277, 0.1849552288187389, 0.56414345249926], Action prob: [0.5874696  0.41253042], Action: 0, state: 9\n",
      "[0.5874696  0.41253042]\n",
      "Sensor: [0.6091484033314722, 0.3442505400394167, 0.22327994768138656, 0.2592417349433706], Action prob: [0.5856469  0.41435307], Action: 0, state: 9\n",
      "[0.5856469  0.41435307]\n",
      "Sensor: [0.37555251600008777, 0.6544175324557377, 0.2026118257469944, 0.5867299069505927], Action prob: [0.5856858  0.41431424], Action: 0, state: 9\n",
      "[0.5856858  0.41431424]\n",
      "Sensor: [0.3354813486856672, 0.35255861585435544, 0.23578854877220534, 0.26728981905347077], Action prob: [0.5854355 0.4145645], Action: 0, state: 9\n",
      "[0.5854355 0.4145645]\n",
      "Sensor: [0.34697584040580093, 0.6077001456871391, 0.5265330129746113, 0.263163808884567], Action prob: [0.58555466 0.41444534], Action: 0, state: 9\n",
      "[0.58555466 0.41444534]\n",
      "Sensor: [0.6038694670753342, 0.6557207456461658, 0.20222885277240607, 0.19411114376306565], Action prob: [0.5855929  0.41440704], Action: 0, state: 9\n",
      "tensor([ 1.4966,  0.5858,  0.3037,  0.0406, -0.1653, -0.3765, -0.5479, -0.7490],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1096 is 19800, loss is -0.07350806053863497\n",
      "[0.5855929  0.41440704]\n",
      "Sensor: [0.3394741991339429, 0.36075118751520957, 0.22453786608059007, 0.24453617620409235], Action prob: [0.59312874 0.40687126], Action: 0, state: 9\n",
      "[0.59312874 0.40687126]\n",
      "Sensor: [0.5945739136005277, 0.6626063211715725, 0.20317456751052362, 0.2771990011622237], Action prob: [0.59282696 0.40717304], Action: 0, state: 9\n",
      "[0.59282696 0.40717304]\n",
      "Sensor: [0.40628376017173856, 0.3527965559306621, 0.20209225380751328, 0.23769474146512284], Action prob: [0.59171885 0.40828118], Action: 1, state: 9\n",
      "[0.59171885 0.40828118]\n",
      "Sensor: [0.6267113938792563, 0.6121827873141368, 0.2004587298109904, 0.1884226170954375], Action prob: [0.59116435 0.40883568], Action: 0, state: 9\n",
      "[0.59116435 0.40883568]\n",
      "Sensor: [0.5715742234064791, 0.6550741283633367, 0.25696687631668486, 0.5055800052785425], Action prob: [0.5908903  0.40910977], Action: 0, state: 9\n",
      "[0.5908903  0.40910977]\n",
      "Sensor: [0.38609684462558086, 0.583658206129217, 0.2203990670013613, 0.5759869625868254], Action prob: [0.5910345  0.40896553], Action: 1, state: 9\n",
      "[0.5910345  0.40896553]\n",
      "Sensor: [0.6076361130199974, 0.6804334260672265, 0.24809970687390684, 0.23746271670112173], Action prob: [0.591017 0.408983], Action: 1, state: 9\n",
      "[0.591017 0.408983]\n",
      "Sensor: [0.6602476213390696, 0.5833050646914846, 0.2524026583944289, 0.27353249861247675], Action prob: [0.5908154  0.40918458], Action: 1, state: 9\n",
      "tensor([ 0.8830,  0.5616,  0.5088,  0.0335, -0.1751, -0.6210, -0.9694, -1.2494],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1104 is 11800, loss is 0.12849685610720474\n",
      "[0.5908154  0.40918458]\n",
      "Sensor: [0.3246491491294106, 0.37260471896349884, 0.19513463560249134, 0.25989210936753443], Action prob: [0.5928241  0.40717593], Action: 1, state: 9\n",
      "[0.5928241  0.40717593]\n",
      "Sensor: [0.6647622417238506, 0.6171900069674428, 0.26259525939812856, 0.2413918591868598], Action prob: [0.59192055 0.4080795 ], Action: 1, state: 9\n",
      "[0.59192055 0.4080795 ]\n",
      "Sensor: [0.3643097859684156, 0.6338223076454262, 0.22642578108142378, 0.5794287658815913], Action prob: [0.5925808  0.40741926], Action: 0, state: 9\n",
      "[0.5925808  0.40741926]\n",
      "Sensor: [0.3178986108862779, 0.6190940738966311, 0.1653241488953553, 0.5641460262254396], Action prob: [0.59253204 0.40746796], Action: 0, state: 9\n",
      "[0.59253204 0.40746796]\n",
      "Sensor: [0.36024280909621254, 0.6436949599126, 0.198202585493257, 0.5527870085134521], Action prob: [0.59203714 0.40796286], Action: 1, state: 9\n",
      "[0.59203714 0.40796286]\n",
      "Sensor: [0.39805087865762173, 0.41503494162552634, 0.17135992809828246, 0.25166223390735], Action prob: [0.5912856  0.40871438], Action: 0, state: 9\n",
      "[0.5912856  0.40871438]\n",
      "Sensor: [0.32250627749110106, 0.6546863304131882, 0.291699532966962, 0.5629697239096065], Action prob: [0.5915949  0.40840515], Action: 1, state: 9\n",
      "[0.5915949  0.40840515]\n",
      "Sensor: [0.5275689422531822, 0.6494208298832834, 0.5993080667617832, 0.24822401138586672], Action prob: [0.5912899  0.40871018], Action: 1, state: 9\n",
      "tensor([ 1.5212,  0.9616,  0.3128,  0.0638, -0.2756, -0.3762, -0.9165, -1.2055],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1112 is 3800, loss is -0.010690258971085026\n",
      "[0.5912899  0.40871018]\n",
      "Sensor: [0.37250515743860935, 0.32463204912725774, 0.24639032601713712, 0.28283093634672746], Action prob: [0.5918633 0.4081367], Action: 0, state: 9\n",
      "[0.5918633 0.4081367]\n",
      "Sensor: [0.5823217497382446, 0.6375541832762865, 0.1824220737954508, 0.23455143419691246], Action prob: [0.591713 0.408287], Action: 0, state: 9\n",
      "[0.591713 0.408287]\n",
      "Sensor: [0.3714620657514585, 0.393099567590746, 0.22839511019210695, 0.2608500868407823], Action prob: [0.5912816 0.4087184], Action: 0, state: 9\n",
      "[0.5912816 0.4087184]\n",
      "Sensor: [0.38704696837559616, 0.370503972570477, 0.2155933442883182, 0.21977610551117596], Action prob: [0.5907946  0.40920535], Action: 0, state: 9\n",
      "[0.5907946  0.40920535]\n",
      "Sensor: [0.35088765466326644, 0.5894312673152398, 0.4947505941749505, 0.2607868300130039], Action prob: [0.59084576 0.40915433], Action: 1, state: 9\n",
      "[0.59084576 0.40915433]\n",
      "Sensor: [0.35211408968211416, 0.6503896586190141, 0.49492484721598845, 0.20031539737767312], Action prob: [0.59109765 0.40890232], Action: 0, state: 9\n",
      "[0.59109765 0.40890232]\n",
      "Sensor: [0.37064139312801925, 0.3883709444902686, 0.24788321823059123, 0.22031289746068836], Action prob: [0.5908354 0.4091646], Action: 1, state: 9\n",
      "[0.5908354 0.4091646]\n",
      "Sensor: [0.3115609391540069, 0.4070041982040451, 0.1818617582750855, 0.19895884824495852], Action prob: [0.59096843 0.4090316 ], Action: 1, state: 9\n",
      "tensor([ 0.8890,  0.5643,  0.3043,  0.0523, -0.2619, -0.3582, -0.9408, -1.2202],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1120 is -4200, loss is 0.12140615922752508\n",
      "[0.59096843 0.4090316 ]\n",
      "Sensor: [0.3631947483354916, 0.40562129867934077, 0.19351024588840438, 0.296208538572404], Action prob: [0.5886525  0.41134754], Action: 0, state: 9\n",
      "[0.5886525  0.41134754]\n",
      "Sensor: [0.3657738490434195, 0.6147232276367731, 0.7872809641950318, 0.16011424777264854], Action prob: [0.58864224 0.41135776], Action: 0, state: 9\n",
      "[0.58864224 0.41135776]\n",
      "Sensor: [0.393074130702687, 0.3693174776457899, 0.26099634308111797, 0.2346636060019783], Action prob: [0.58718216 0.41281787], Action: 0, state: 9\n",
      "[0.58718216 0.41281787]\n",
      "Sensor: [0.3736887436525838, 0.40991000557285984, 0.20101417186598713, 0.25886288124810963], Action prob: [0.58663356 0.41336644], Action: 0, state: 9\n",
      "[0.58663356 0.41336644]\n",
      "Sensor: [0.367356764543747, 0.39382131486928484, 0.23386263118475567, 0.20573519146975788], Action prob: [0.586339   0.41366106], Action: 1, state: 9\n",
      "[0.586339   0.41366106]\n",
      "Sensor: [0.3547049157638504, 0.6255070673451935, 0.49700152829302674, 0.26789922539108496], Action prob: [0.5862978 0.4137022], Action: 0, state: 9\n",
      "[0.5862978 0.4137022]\n",
      "Sensor: [0.5460155332720742, 0.6382611549043139, 0.2413761659903345, 0.27199321337285903], Action prob: [0.58612007 0.41387987], Action: 1, state: 9\n",
      "[0.58612007 0.41387987]\n",
      "Sensor: [0.35883562857353263, 0.5983419828038095, 0.49739551846941565, 0.2652307733172366], Action prob: [0.586148   0.41385198], Action: 0, state: 9\n",
      "tensor([ 0.8961,  0.6144,  0.3075,  0.0539, -0.2871, -0.3608, -0.9450, -0.7123],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1128 is -12200, loss is 0.05416910409532859\n",
      "[0.586148   0.41385198]\n",
      "Sensor: [0.6179580021970567, 0.6365955271723214, 0.22374428477344913, 0.21475596735892302], Action prob: [0.58263737 0.41736263], Action: 0, state: 9\n",
      "[0.58263737 0.41736263]\n",
      "Sensor: [0.3675335813275037, 0.6346698587421449, 0.2182236959194953, 0.5303106962218365], Action prob: [0.58304614 0.41695383], Action: 0, state: 9\n",
      "[0.58304614 0.41695383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.4042690607856147, 0.3792383360273999, 0.22784422275292132, 0.26067746912844436], Action prob: [0.5814673  0.41853273], Action: 1, state: 9\n",
      "[0.5814673  0.41853273]\n",
      "Sensor: [0.33207813172370637, 0.4327200305556964, 0.24051911269896278, 0.2492676742591896], Action prob: [0.58107144 0.4189285 ], Action: 0, state: 9\n",
      "[0.58107144 0.4189285 ]\n",
      "Sensor: [0.354840930205264, 0.6093313835983147, 0.5285512094729635, 0.2606344687153874], Action prob: [0.58064663 0.41935337], Action: 1, state: 9\n",
      "[0.58064663 0.41935337]\n",
      "Sensor: [0.33149525644313765, 0.3666508032879031, 0.2251762336054048, 0.17645730515045882], Action prob: [0.58063745 0.41936255], Action: 0, state: 9\n",
      "[0.58063745 0.41936255]\n",
      "Sensor: [0.5476685392319012, 0.5990166046252147, 0.2297050877568667, 0.25949717368967495], Action prob: [0.5803695 0.4196306], Action: 1, state: 9\n",
      "[0.5803695 0.4196306]\n",
      "Sensor: [0.37210005078151653, 0.6085342019761997, 0.20133449400079045, 0.28074170604088167], Action prob: [0.58056146 0.41943854], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([ 0.9379,  0.6173,  0.4728,  0.0169, -0.3537, -0.4708, -1.0981, -0.7852],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1136 is -16700, loss is 0.08285878210295887\n",
      "[0.58056146 0.41943854]\n",
      "Sensor: [0.4018081331744212, 0.6235721623575256, 0.19866557770273469, 0.27018858778524624], Action prob: [0.5774323  0.42256778], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5774323  0.42256778]\n",
      "Sensor: [0.40483657101405324, 0.6437024935442401, 0.18351199679289332, 0.25331148283622285], Action prob: [0.57619035 0.4238097 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.57619035 0.4238097 ]\n",
      "Sensor: [0.3408507259658999, 0.7047821246409077, 0.2423175780973971, 0.25568678330680217], Action prob: [0.5751365  0.42486355], Action: 0, state: 0\n",
      "[0.5751365  0.42486355]\n",
      "Sensor: [0.3536334292465809, 0.6166657093275401, 0.19663139627468257, 0.33700554474479666], Action prob: [0.5742561  0.42574394], Action: 0, state: 0\n",
      "[0.5742561  0.42574394]\n",
      "Sensor: [0.3230627224734625, 0.6302618431187993, 0.16374348768579813, 0.25547674671639176], Action prob: [0.57394004 0.42605993], Action: 0, state: 0\n",
      "[0.57394004 0.42605993]\n",
      "Sensor: [0.41416511543326107, 0.5700268860242999, 0.21035069060129608, 0.27159134099705895], Action prob: [0.5733998  0.42660028], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5733998  0.42660028]\n",
      "Sensor: [0.41119029600601703, 0.6422954089969373, 0.21413127503953847, 0.25042644369703476], Action prob: [0.5732278  0.42677215], Action: 0, state: 0\n",
      "[0.5732278  0.42677215]\n",
      "Sensor: [0.3313375593275726, 0.6843432281202708, 0.19321592150233774, 0.20887881798320576], Action prob: [0.57348096 0.426519  ], Action: 0, state: 0\n",
      "tensor([-0.8459, -1.2708, -0.5640, -0.1216,  0.2759,  0.9174,  0.4363,  0.7312],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1144 is -12400, loss is 0.05520724053960356\n",
      "[0.57348096 0.426519  ]\n",
      "Sensor: [0.3577442300706708, 0.611157775721509, 0.1836579151915379, 0.1890302105391526], Action prob: [0.57058156 0.4294184 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.57058156 0.4294184 ]\n",
      "Sensor: [0.3156572171509525, 0.5817846287579678, 0.24302422775129368, 0.23953083648542636], Action prob: [0.56887996 0.43112004], Action: 0, state: 0\n",
      "[0.56887996 0.43112004]\n",
      "Sensor: [0.33320637812704046, 0.6100926941590411, 0.23203669183961997, 0.5530774312541394], Action prob: [0.5670462  0.43295377], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5670462  0.43295377]\n",
      "Sensor: [0.354530727494623, 0.6441889531472177, 0.17768883049535383, 0.24406022842535732], Action prob: [0.56612635 0.4338736 ], Action: 0, state: 0\n",
      "[0.56612635 0.4338736 ]\n",
      "Sensor: [0.35485847305161095, 0.6613014296669457, 0.2200943383779404, 0.2650813626007486], Action prob: [0.5655906  0.43440938], Action: 0, state: 0\n",
      "[0.5655906  0.43440938]\n",
      "Sensor: [0.32164484606637384, 0.6606433658337223, 0.1893977293645967, 0.230312217961968], Action prob: [0.56550246 0.43449748], Action: 0, state: 0\n",
      "[0.56550246 0.43449748]\n",
      "Sensor: [0.34101979447889424, 0.6213429835236889, 0.22033272536422818, 0.19438049002845753], Action prob: [0.5653994  0.43460065], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5653994  0.43460065]\n",
      "Sensor: [0.3885980837338229, 0.5563862124613246, 0.25256758867678275, 0.25801900818461504], Action prob: [0.5651133 0.4348867], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.3166, -0.6408, -0.3224, -0.2368,  0.1042,  0.4070,  0.9934,  1.1741],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1152 is -6900, loss is -0.020256323854925512\n",
      "[0.5651133 0.4348867]\n",
      "Sensor: [0.3936168735363134, 0.6802637579288258, 0.27161182923626764, 0.32870145928332734], Action prob: [0.5647978  0.43520215], Action: 0, state: 0\n",
      "[0.5647978  0.43520215]\n",
      "Sensor: [0.33030624276468046, 0.6688513037432624, 0.19342379002947113, 0.20455349991524566], Action prob: [0.5632547 0.4367452], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5632547 0.4367452]\n",
      "Sensor: [0.37817546516322076, 0.6043257762139014, 0.21034366968851353, 0.24980673913749096], Action prob: [0.5616107  0.43838927], Action: 0, state: 0\n",
      "[0.5616107  0.43838927]\n",
      "Sensor: [0.36031237397307425, 0.6461472672184134, 0.2096220957752174, 0.21085575221983385], Action prob: [0.5608075 0.4391925], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5608075 0.4391925]\n",
      "Sensor: [0.3574810917194625, 0.5926825129886337, 0.1784184632321778, 0.4291583952173906], Action prob: [0.5601001  0.43989986], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "[0.5601001  0.43989986]\n",
      "Sensor: [0.3792064499612942, 0.6343011045294847, 0.19870817125642698, 0.22906558378516145], Action prob: [0.55986834 0.44013163], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.55986834 0.44013163]\n",
      "Sensor: [0.3093113057596615, 0.6744294379151714, 0.2287561662359764, 0.32212610935707126], Action prob: [0.5597862  0.44021377], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5597862  0.44021377]\n",
      "Sensor: [0.3417122274186142, 0.5840116606900269, 0.2084354304476804, 0.24540989000166502], Action prob: [0.5597991  0.44020095], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.1372, -0.3609,  0.1545,  1.2636,  0.8023, -0.4747, -0.0792,  0.2514],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1160 is -5400, loss is -0.052485023707282134\n",
      "[0.5597991  0.44020095]\n",
      "Sensor: [0.34999638066253747, 0.6459858683287729, 0.2525266052830373, 0.2673072594311841], Action prob: [0.5621271  0.43787292], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5621271  0.43787292]\n",
      "Sensor: [0.36052744097869965, 0.6096856170324729, 0.21277894603846223, 0.5337367895199959], Action prob: [0.5601034  0.43989655], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -4500\n",
      "Maintenance in progress, cumulative -5000\n",
      "Maintenance in progress, cumulative -4000\n",
      "[0.5601034  0.43989655]\n",
      "Sensor: [0.36728121947940434, 0.6550470737947888, 0.21807858162264612, 0.23541946513695644], Action prob: [0.55875623 0.44124386], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.55875623 0.44124386]\n",
      "Sensor: [0.3489095430979823, 0.6360340996758391, 0.2208634496387158, 0.2816831785193679], Action prob: [0.5580615  0.44193852], Action: 0, state: 0\n",
      "[0.5580615  0.44193852]\n",
      "Sensor: [0.41367874929986687, 0.5931032828424638, 0.21941819449419378, 0.23816535994167543], Action prob: [0.55755025 0.44244978], Action: 0, state: 0\n",
      "[0.55755025 0.44244978]\n",
      "Sensor: [0.3433137680438215, 0.6750636599285931, 0.22587971869706294, 0.2486645601050058], Action prob: [0.55744916 0.44255078], Action: 0, state: 0\n",
      "[0.55744916 0.44255078]\n",
      "Sensor: [0.33600727422374427, 0.6152608021507032, 0.234663811095759, 0.25346656102306186], Action prob: [0.55740064 0.4425994 ], Action: 0, state: 0\n",
      "[0.55740064 0.4425994 ]\n",
      "Sensor: [0.34758649685172927, 0.6298941556409854, 0.19189417625294064, 0.23293584728797512], Action prob: [0.55742335 0.44257665], Action: 0, state: 1\n",
      "tensor([ 0.9377,  1.2652, -1.0663, -0.7567, -0.4312, -0.1241,  0.1474,  0.3617],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1168 is -4200, loss is -0.04172241986053912\n",
      "[0.55742335 0.44257665]\n",
      "Sensor: [0.37001349330276084, 0.6454155050679746, 0.22007124071911066, 0.28396159105690316], Action prob: [0.5606967  0.43930325], Action: 0, state: 2\n",
      "[0.5606967  0.43930325]\n",
      "Sensor: [0.3583328991934248, 0.6665887995309311, 0.24170047432094743, 0.22144176649991343], Action prob: [0.5591851  0.44081497], Action: 0, state: 2\n",
      "[0.5591851  0.44081497]\n",
      "Sensor: [0.44245575769813555, 0.6740857835500638, 0.26206585475609145, 0.23642026257310017], Action prob: [0.5577556 0.4422444], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.5577556 0.4422444]\n",
      "Sensor: [0.3826659638477353, 0.5834382614900382, 0.20761619781247467, 0.22594518021171411], Action prob: [0.5572139  0.44278613], Action: 0, state: 2\n",
      "[0.5572139  0.44278613]\n",
      "Sensor: [0.392263859223014, 0.6197062879032074, 0.18896273266640978, 0.19280389103552362], Action prob: [0.55692077 0.44307923], Action: 0, state: 3\n",
      "[0.55692077 0.44307923]\n",
      "Sensor: [0.32480591568506656, 0.6387195888119226, 0.5094164655823782, 0.26567139427525277], Action prob: [0.5564635  0.44353655], Action: 1, state: 8\n",
      "[0.5564635  0.44353655]\n",
      "Sensor: [0.5650351747425743, 0.6745560263731867, 0.20985733450157135, 0.20133192353775958], Action prob: [0.55611664 0.44388333], Action: 0, state: 8\n",
      "[0.55611664 0.44388333]\n",
      "Sensor: [0.6033815368690469, 0.33668515849822744, 0.2432473818795265, 0.2069216221671919], Action prob: [0.5559624  0.44403768], Action: 1, state: 8\n",
      "tensor([ 1.3442e-03,  2.7247e-01,  5.9098e-01,  5.0561e-01,  6.2726e-01,\n",
      "        -1.7599e-02, -6.6151e-01, -1.6731e+00], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for up to this timestep 1176 is -14100, loss is 0.044317466119565274\n",
      "[0.5559624  0.44403768]\n",
      "Sensor: [0.6040139183997807, 0.6849388876048157, 0.5514642388515556, 0.24522712494798082], Action prob: [0.55681485 0.44318524], Action: 1, state: 8\n",
      "[0.55681485 0.44318524]\n",
      "Sensor: [0.5864170528987465, 0.6401195347226533, 0.212996952748953, 0.2551629997930694], Action prob: [0.555609 0.444391], Action: 0, state: 8\n",
      "[0.555609 0.444391]\n",
      "Sensor: [0.39142389154284774, 0.6668141136688162, 0.2465875414825045, 0.5665602519648241], Action prob: [0.554846 0.445154], Action: 1, state: 8\n",
      "[0.554846 0.445154]\n",
      "Sensor: [0.32561375340771676, 0.37599175085167325, 0.2756038365571982, 0.22876026865578694], Action prob: [0.5545866  0.44541344], Action: 1, state: 8\n",
      "[0.5545866  0.44541344]\n",
      "Sensor: [0.3507785859551151, 0.36966585294475257, 0.20132254689698614, 0.2748561976058341], Action prob: [0.5544686 0.4455315], Action: 0, state: 8\n",
      "[0.5544686 0.4455315]\n",
      "Sensor: [0.34629428791015754, 0.35828369892513573, 0.2196294538542873, 0.24168927693950226], Action prob: [0.55445135 0.44554868], Action: 1, state: 8\n",
      "[0.55445135 0.44554868]\n",
      "Sensor: [0.3369823229682263, 0.6773260800002884, 0.20946467233002605, 0.5645931777874966], Action prob: [0.5541624  0.44583753], Action: 0, state: 8\n",
      "[0.5541624  0.44583753]\n",
      "Sensor: [0.38522872465147107, 0.352452001568404, 0.25220577915632636, 0.24098103822249242], Action prob: [0.5541309  0.44586903], Action: 0, state: 8\n",
      "tensor([ 1.3804,  0.6282,  0.4808,  0.0831, -0.1965, -0.5798, -0.6111, -0.8117],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1184 is -38100, loss is -0.04668390066127642\n",
      "[0.5541309  0.44586903]\n",
      "Sensor: [0.7226722424589845, 0.6665470769561298, 0.2038858906875787, 0.522032267853805], Action prob: [0.55631864 0.44368136], Action: 0, state: 8\n",
      "[0.55631864 0.44368136]\n",
      "Sensor: [0.5717834292103666, 0.673340946400014, 0.24165742376167135, 0.24251477249592865], Action prob: [0.5551163 0.4448837], Action: 0, state: 8\n",
      "[0.5551163 0.4448837]\n",
      "Sensor: [0.5755834283998451, 0.6409805901469118, 0.1876398458951133, 0.24813883256558278], Action prob: [0.5543416  0.44565836], Action: 0, state: 8\n",
      "[0.5543416  0.44565836]\n",
      "Sensor: [0.3670255742735386, 0.6787892061081903, 0.20289847194873556, 0.5536689038599809], Action prob: [0.55403894 0.44596112], Action: 0, state: 8\n",
      "[0.55403894 0.44596112]\n",
      "Sensor: [0.28781684564856275, 0.6312805475347901, 0.19879594299517894, 0.5730755080941312], Action prob: [0.5540009 0.4459991], Action: 0, state: 8\n",
      "[0.5540009 0.4459991]\n",
      "Sensor: [0.3083614944233912, 0.3591198373792249, 0.22921598597281817, 0.2247931998893245], Action prob: [0.5539784 0.4460216], Action: 0, state: 8\n",
      "[0.5539784 0.4460216]\n",
      "Sensor: [0.35131707672905077, 0.6539966261235919, 0.5559602851125892, 0.5730912712376416], Action prob: [0.55343777 0.44656223], Action: 0, state: 8\n",
      "[0.55343777 0.44656223]\n",
      "Sensor: [0.32328569904997523, 0.3809699854055869, 0.24290830236258557, 0.24084527050257293], Action prob: [0.5536732 0.4463268], Action: 1, state: 8\n",
      "tensor([ 0.9702,  0.6312,  0.3175,  0.0676, -0.1788, -0.4216, -0.5890, -1.1049],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1192 is -62100, loss is 0.03847340735557293\n",
      "[0.5536732 0.4463268]\n",
      "Sensor: [0.6035510800226567, 0.6836902484081722, 0.17591098828614518, 0.28220782465505395], Action prob: [0.5551857  0.44481435], Action: 0, state: 8\n",
      "[0.5551857  0.44481435]\n",
      "Sensor: [0.3535492054944722, 0.6391939425639126, 0.2536585418291781, 0.5845978121715235], Action prob: [0.5542159  0.44578406], Action: 0, state: 8\n",
      "[0.5542159  0.44578406]\n",
      "Sensor: [0.32392416737049196, 0.6821156240769369, 0.5248924189125811, 0.28094542895920854], Action prob: [0.5532095  0.44679052], Action: 0, state: 8\n",
      "[0.5532095  0.44679052]\n",
      "Sensor: [0.5560009947623311, 0.6247261005942669, 0.22048377917190012, 0.20633057787197145], Action prob: [0.5524739 0.4475261], Action: 0, state: 8\n",
      "[0.5524739 0.4475261]\n",
      "Sensor: [0.3620706275161399, 0.36970560534446417, 0.18032916740110388, 0.27614574813586634], Action prob: [0.5525216 0.4474784], Action: 1, state: 8\n",
      "[0.5525216 0.4474784]\n",
      "Sensor: [0.38335592223596093, 0.6304263381803716, 0.4940234969590923, 0.2784021469363373], Action prob: [0.5522193  0.44778073], Action: 0, state: 8\n",
      "[0.5522193  0.44778073]\n",
      "Sensor: [0.37284281779537226, 0.33142596323863, 0.22710072380373691, 0.19210569163343605], Action prob: [0.5523557  0.44764432], Action: 0, state: 8\n",
      "[0.5523557  0.44764432]\n",
      "Sensor: [0.3788526893348615, 0.6057471806973715, 0.19222204835644566, 0.4975533773682089], Action prob: [0.5522549  0.44774508], Action: 1, state: 8\n",
      "tensor([ 0.9678,  0.6630,  0.3631,  0.0377, -0.2741, -0.4064, -0.6367, -1.0962],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1200 is -82100, loss is 0.047740847658768876\n",
      "[0.5522549  0.44774508]\n",
      "Sensor: [0.40626374220166883, 0.6485138097806031, 0.1964307523124712, 0.3797449485590482], Action prob: [0.553014   0.44698602], Action: 0, state: 0\n",
      "[0.553014   0.44698602]\n",
      "Sensor: [0.2969989990291052, 0.6273733689434023, 0.22417881641640652, 0.2579696564375548], Action prob: [0.5520419 0.4479581], Action: 0, state: 0\n",
      "[0.5520419 0.4479581]\n",
      "Sensor: [0.29343867606638624, 0.635934504761229, 0.22478231167195029, 0.22517783652034928], Action prob: [0.5512744  0.44872555], Action: 0, state: 0\n",
      "[0.5512744  0.44872555]\n",
      "Sensor: [0.382722283642138, 0.6508349866299563, 0.24409877402614424, 0.25825418702657715], Action prob: [0.5505724 0.4494276], Action: 0, state: 1\n",
      "[0.5505724 0.4494276]\n",
      "Sensor: [0.337930994019624, 0.6136688707159792, 0.24620986535892894, 0.28520706993985157], Action prob: [0.5502492  0.44975072], Action: 0, state: 1\n",
      "[0.5502492  0.44975072]\n",
      "Sensor: [0.3741900567279153, 0.6092162137788643, 0.17986184731772267, 0.296180777099146], Action prob: [0.5500611  0.44993892], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.5500611  0.44993892]\n",
      "Sensor: [0.3713643414395221, 0.6007022056315229, 0.19342087024371968, 0.26283755999586267], Action prob: [0.5499731  0.45002702], Action: 0, state: 1\n",
      "[0.5499731  0.45002702]\n",
      "Sensor: [0.3765647981900847, 0.65645997383965, 0.1981451956810415, 0.22567873654774764], Action prob: [0.54994375 0.45005625], Action: 0, state: 1\n",
      "tensor([-1.0662, -0.6626, -0.3030, -0.0137,  0.2559,  0.6150,  0.5557,  0.7475],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1208 is -75400, loss is -0.016080744365041783\n",
      "[0.54994375 0.45005625]\n",
      "Sensor: [0.36293103235598156, 0.5829708439383927, 0.18679212966321113, 0.2204232366856128], Action prob: [0.5514407  0.44855928], Action: 0, state: 2\n",
      "[0.5514407  0.44855928]\n",
      "Sensor: [0.5903353203155963, 0.6641625636715823, 0.2186785852894677, 0.2677807127819467], Action prob: [0.5494706 0.4505295], Action: 1, state: 9\n",
      "[0.5494706 0.4505295]\n",
      "Sensor: [0.34382587051131486, 0.615551396788719, 0.1724157096137311, 0.2719627483564198], Action prob: [0.5490406  0.45095944], Action: 0, state: 0\n",
      "[0.5490406  0.45095944]\n",
      "Sensor: [0.3492592534745567, 0.6461297869166555, 0.21771416212001002, 0.23655051459571275], Action prob: [0.5486513 0.4513487], Action: 0, state: 1\n",
      "[0.5486513 0.4513487]\n",
      "Sensor: [0.415966115068932, 0.6239286836367203, 0.37375939755190707, 0.28619500339320164], Action prob: [0.5480495  0.45195052], Action: 0, state: 1\n",
      "[0.5480495  0.45195052]\n",
      "Sensor: [0.35823936046968025, 0.5859425792219826, 0.23894130228985316, 0.2561036469040082], Action prob: [0.5480126  0.45198736], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.5480126  0.45198736]\n",
      "Sensor: [0.35580791117604527, 0.6610162129943309, 0.21606148769501907, 0.21888369438742883], Action prob: [0.54805297 0.451947  ], Action: 0, state: 1\n",
      "[0.54805297 0.451947  ]\n",
      "Sensor: [0.3777273940308255, 0.6744247562532993, 0.19765274982015588, 0.2136773967125284], Action prob: [0.5480571  0.45194286], Action: 0, state: 2\n",
      "tensor([-0.4758, -1.4176, -0.5337, -0.1146,  0.2717,  0.7463,  0.5281,  0.7688],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1216 is -71300, loss is 0.028353733998207273\n",
      "[0.5480571  0.45194286]\n",
      "Sensor: [0.34148002114600634, 0.6789678110547724, 0.2381696416620682, 0.23545201149913206], Action prob: [0.54917496 0.45082507], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.54917496 0.45082507]\n",
      "Sensor: [0.32513085816002213, 0.620986438157211, 0.24853386879863523, 0.2599863026867992], Action prob: [0.5478533  0.45214674], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5478533  0.45214674]\n",
      "Sensor: [0.38937452014212875, 0.7274360617836535, 0.653408791028318, 0.6216408771941062], Action prob: [0.54615855 0.4538414 ], Action: 0, state: 0\n",
      "[0.54615855 0.4538414 ]\n",
      "Sensor: [0.34755143289141627, 0.6541750977263151, 0.22785613953596742, 0.478127543647817], Action prob: [0.54577696 0.4542231 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.54577696 0.4542231 ]\n",
      "Sensor: [0.35749516149311567, 0.6581828291920775, 0.20716407143332016, 0.3068994398223785], Action prob: [0.5456644 0.4543356], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5456644 0.4543356]\n",
      "Sensor: [0.3933875587606785, 0.6964292439891305, 0.23636198327285687, 0.19154323653686212], Action prob: [0.54556185 0.4544381 ], Action: 0, state: 0\n",
      "[0.54556185 0.4544381 ]\n",
      "Sensor: [0.38401838205499556, 0.6067130240671518, 0.22965354143482206, 0.26312654768944405], Action prob: [0.5455371 0.4544629], Action: 0, state: 0\n",
      "[0.5455371 0.4544629]\n",
      "Sensor: [0.39200226426078155, 0.6550308601315383, 0.21919293668851325, 0.23896614779696476], Action prob: [0.5455215  0.45447853], Action: 0, state: 1\n",
      "tensor([-0.7663, -0.9106, -0.6483,  0.3226,  0.3085, -0.1481,  0.5378,  1.0880],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1224 is -68100, loss is 0.027063548507141266\n",
      "[0.5455215  0.45447853]\n",
      "Sensor: [0.34076651583649736, 0.5772974296041287, 0.19055162487979369, 0.24377016952697925], Action prob: [0.5463373  0.45366272], Action: 0, state: 1\n",
      "[0.5463373  0.45366272]\n",
      "Sensor: [0.3789267138688929, 0.6483113558044002, 0.2547625405300717, 0.2746773075397785], Action prob: [0.5446335 0.4553664], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -2000\n",
      "[0.5446335 0.4553664]\n",
      "Sensor: [0.37918884357339466, 0.5930806146645607, 0.20899448042244964, 0.2317992056573386], Action prob: [0.54369956 0.4563005 ], Action: 0, state: 0\n",
      "[0.54369956 0.4563005 ]\n",
      "Sensor: [0.4035506742182112, 0.6723111992788037, 0.19089490264416303, 0.29528543512915484], Action prob: [0.5430371  0.45696285], Action: 0, state: 1\n",
      "[0.5430371  0.45696285]\n",
      "Sensor: [0.3776789624560622, 0.6606407486991402, 0.18062589120078876, 0.24988809710323356], Action prob: [0.54276025 0.45723972], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54276025 0.45723972]\n",
      "Sensor: [0.4467277988648417, 0.6700758045772192, 0.2090904374365037, 0.24964643715919663], Action prob: [0.54241604 0.45758402], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.54241604 0.45758402]\n",
      "Sensor: [0.3279982866704954, 0.6595369247177436, 0.1675143436038138, 0.24150961005933272], Action prob: [0.54256696 0.457433  ], Action: 0, state: 0\n",
      "[0.54256696 0.457433  ]\n",
      "Sensor: [0.38886692707906195, 0.6298847674274435, 0.185681933356162, 0.31446040872449743], Action prob: [0.54243493 0.457565  ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-0.2538,  0.9618, -1.2554, -0.4493,  0.2530,  0.1547,  0.1276,  0.9182],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1232 is -66600, loss is -0.057084987890664796\n",
      "[0.54243493 0.457565  ]\n",
      "Sensor: [0.36483705912222497, 0.6556389137348303, 0.22541253716727244, 0.26023259957361233], Action prob: [0.54557896 0.45442107], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.54557896 0.45442107]\n",
      "Sensor: [0.3580408428027736, 0.652247645947968, 0.18732919064966772, 0.26871784499832835], Action prob: [0.54424703 0.45575294], Action: 0, state: 0\n",
      "[0.54424703 0.45575294]\n",
      "Sensor: [0.3801990659055414, 0.6266961740038344, 0.1788367492875478, 0.27365891581679963], Action prob: [0.5433163 0.4566837], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5433163 0.4566837]\n",
      "Sensor: [0.3187281910398953, 0.6420932158099534, 0.19021753514339038, 0.29943746771433594], Action prob: [0.5428832  0.45711672], Action: 0, state: 0\n",
      "[0.5428832  0.45711672]\n",
      "Sensor: [0.39662457934041034, 0.4818173644513839, 0.2214934942515045, 0.2682187851065326], Action prob: [0.5424183 0.4575817], Action: 0, state: 1\n",
      "[0.5424183 0.4575817]\n",
      "Sensor: [0.3816777949478475, 0.5870784336941157, 0.20841795069466404, 0.20481201056630854], Action prob: [0.5422298  0.45777023], Action: 0, state: 2\n",
      "[0.5422298  0.45777023]\n",
      "Sensor: [0.4630479661184123, 0.6011335490715369, 0.4396615103274724, 0.1602416370487612], Action prob: [0.5418594  0.45814058], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.5418594  0.45814058]\n",
      "Sensor: [0.3539763799936172, 0.6266955635647905, 0.22876958080342874, 0.2145394123967537], Action prob: [0.541963   0.45803702], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "tensor([-1.0880, -0.8416, -0.4966, -0.1490,  0.2187,  0.5147,  0.8852,  0.9931],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1240 is -62300, loss is -0.004564795411235972\n",
      "[0.541963   0.45803702]\n",
      "Sensor: [0.3156197978196502, 0.6575180727571068, 0.21925603901087307, 0.14496274637747825], Action prob: [0.5456657 0.4543343], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5456657 0.4543343]\n",
      "Sensor: [0.33008559272508275, 0.6505885659719001, 0.16872950535797893, 0.22367028980431186], Action prob: [0.5444578  0.45554218], Action: 1, state: 0\n",
      "[0.5444578  0.45554218]\n",
      "Sensor: [0.5388573280648824, 0.5931887091297134, 0.1817192421680872, 0.237507193015108], Action prob: [0.5430763  0.45692375], Action: 1, state: 9\n",
      "[0.5430763  0.45692375]\n",
      "Sensor: [0.40799095880815245, 0.5890153016977727, 0.26383572765958285, 0.5418003020928458], Action prob: [0.54244024 0.45755982], Action: 1, state: 9\n",
      "[0.54244024 0.45755982]\n",
      "Sensor: [0.3772073829256024, 0.38948675670715144, 0.21510551451502197, 0.24068645975663666], Action prob: [0.54231435 0.45768568], Action: 1, state: 9\n",
      "[0.54231435 0.45768568]\n",
      "Sensor: [0.35849513923648946, 0.675958251391368, 0.19817399203037867, 0.5971222676112538], Action prob: [0.5421379  0.45786208], Action: 0, state: 9\n",
      "[0.5421379  0.45786208]\n",
      "Sensor: [0.5579177640442607, 0.6757139990565885, 0.21580691983748868, 0.1787567270401236], Action prob: [0.5417507  0.45824927], Action: 0, state: 9\n",
      "[0.5417507  0.45824927]\n",
      "Sensor: [0.386869374674215, 0.6402717430510603, 0.48161119639814043, 0.25497315705306484], Action prob: [0.5417601  0.45823985], Action: 0, state: 9\n",
      "tensor([ 1.0402,  1.0342,  0.5435,  0.1707, -0.2257, -0.4234, -0.7011, -0.8707],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1248 is -69300, loss is -0.07094886072260216\n",
      "[0.5417601  0.45823985]\n",
      "Sensor: [0.3832109931692945, 0.6375471660961225, 0.48764447750071416, 0.2503826879166433], Action prob: [0.54688287 0.4531171 ], Action: 0, state: 9\n",
      "[0.54688287 0.4531171 ]\n",
      "Sensor: [0.35967680496668514, 0.640614324509146, 0.22996497565466184, 0.5567568908392566], Action prob: [0.54589015 0.4541098 ], Action: 0, state: 9\n",
      "[0.54589015 0.4541098 ]\n",
      "Sensor: [0.30416926436731395, 0.4397311526026174, 0.188114265091734, 0.28549831317545976], Action prob: [0.5454645  0.45453554], Action: 0, state: 9\n",
      "[0.5454645  0.45453554]\n",
      "Sensor: [0.6746484717128688, 0.604932637657826, 0.16523232940941793, 0.24642356418562275], Action prob: [0.5444846  0.45551535], Action: 1, state: 9\n",
      "[0.5444846  0.45551535]\n",
      "Sensor: [0.35359394332923455, 0.6232819417381287, 0.21338074568732776, 0.3102973563051804], Action prob: [0.54456013 0.4554399 ], Action: 0, state: 0\n",
      "[0.54456013 0.4554399 ]\n",
      "Sensor: [0.33583101718182956, 0.6350138056332089, 0.23137024135464346, 0.2432593827222812], Action prob: [0.5446352  0.45536482], Action: 0, state: 0\n",
      "[0.5446352  0.45536482]\n",
      "Sensor: [0.3379578200025587, 0.6241403953960027, 0.25754797027271437, 0.2215898451017907], Action prob: [0.544644   0.45535603], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.544644   0.45535603]\n",
      "Sensor: [0.34732017226757916, 0.6156442368733841, 0.22959711722769266, 0.29953084906265753], Action prob: [0.5446235  0.45537648], Action: 0, state: 0\n",
      "tensor([ 1.0797,  0.3020, -0.4087, -1.3976, -0.4744,  0.0359,  0.6427,  0.0836],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1256 is -69300, loss is 0.01710438639719009\n",
      "[0.5446235  0.45537648]\n",
      "Sensor: [0.38452155862743753, 0.6550090555359906, 0.2213950766013602, 0.2820654425166052], Action prob: [0.5482383  0.45176166], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5482383  0.45176166]\n",
      "Sensor: [0.3506419215434081, 0.6261044759825178, 0.20445939498971524, 0.19814770317743774], Action prob: [0.54750824 0.45249176], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.54750824 0.45249176]\n",
      "Sensor: [0.2806118605603402, 0.5324241919123932, 0.2051993986489543, 0.28683313043138225], Action prob: [0.54704994 0.45295006], Action: 0, state: 0\n",
      "[0.54704994 0.45295006]\n",
      "Sensor: [0.35048924829749634, 0.6657337351247679, 0.2671416684128126, 0.18063056090599244], Action prob: [0.5466171 0.4533829], Action: 1, state: 0\n",
      "[0.5466171 0.4533829]\n",
      "Sensor: [0.6094350715102234, 0.5582125074008508, 0.22428942419558068, 0.24436618941283525], Action prob: [0.5458724  0.45412758], Action: 1, state: 9\n",
      "[0.5458724  0.45412758]\n",
      "Sensor: [0.5853492175391043, 0.6029245721827454, 0.23153603217404317, 0.26057188994013303], Action prob: [0.5456332  0.45436677], Action: 0, state: 9\n",
      "[0.5456332  0.45436677]\n",
      "Sensor: [0.5653709298129287, 0.6901539770466407, 0.19718954943500328, 0.1887100016775256], Action prob: [0.54558533 0.45441467], Action: 0, state: 9\n",
      "[0.54558533 0.45441467]\n",
      "Sensor: [0.3578780122316947, 0.6227666232747027, 0.22857554028187382, 0.48936771418300806], Action prob: [0.5457935  0.45420653], Action: 1, state: 9\n",
      "tensor([ 0.3425,  0.3383,  0.2690,  1.2055,  0.3969, -0.2265, -0.7133, -1.4424],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1264 is -73300, loss is -0.021232723876657755\n",
      "[0.5457935  0.45420653]\n",
      "Sensor: [0.4284298952975064, 0.19049156121321814, 0.19950351992316795, 0.25429551075661033], Action prob: [0.5497321 0.4502679], Action: 1, state: 9\n",
      "[0.5497321 0.4502679]\n",
      "Sensor: [0.3554192389980025, 0.3863964178531732, 0.25920465414209315, 0.26852230325914384], Action prob: [0.54898024 0.45101976], Action: 1, state: 9\n",
      "[0.54898024 0.45101976]\n",
      "Sensor: [0.3773311515973561, 0.44512178256678336, 0.4010769438353593, 0.2522291396014881], Action prob: [0.54845077 0.4515493 ], Action: 1, state: 9\n",
      "[0.54845077 0.4515493 ]\n",
      "Sensor: [0.3436067038544451, 0.36009287548766317, 0.19966356234569016, 0.23685985954439137], Action prob: [0.54827756 0.45172247], Action: 0, state: 9\n",
      "[0.54827756 0.45172247]\n",
      "Sensor: [0.35133122820442275, 0.4021171662396424, 0.18260804792124535, 0.2514735532244847], Action prob: [0.54818064 0.45181936], Action: 1, state: 9\n",
      "[0.54818064 0.45181936]\n",
      "Sensor: [0.49031819276089506, 0.34638615445006743, 0.2098114195544174, 0.6054393288055209], Action prob: [0.54781485 0.45218512], Action: 0, state: 9\n",
      "[0.54781485 0.45218512]\n",
      "Sensor: [0.5577997266332888, 0.6080570578766705, 0.5178868757310893, 0.2433829204842935], Action prob: [0.5475356 0.4524644], Action: 1, state: 9\n",
      "[0.5475356 0.4524644]\n",
      "Sensor: [0.40641119662345215, 0.6501741158342748, 0.49208887198185847, 0.2672119179047476], Action prob: [0.547621   0.45237902], Action: 1, state: 9\n",
      "tensor([ 1.3435,  0.8900,  0.4825,  0.0641, -0.2566, -0.4166, -0.8213, -1.0513],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1272 is -81300, loss is -0.029296964188450125\n",
      "[0.547621   0.45237902]\n",
      "Sensor: [0.3608066570986369, 0.3618850464259162, 0.17849770680947674, 0.18084398559687886], Action prob: [0.55195445 0.4480456 ], Action: 1, state: 9\n",
      "[0.55195445 0.4480456 ]\n",
      "Sensor: [0.6245565029233173, 0.636510479882096, 0.24099662225196689, 0.599181041233306], Action prob: [0.5505296  0.44947043], Action: 1, state: 9\n",
      "[0.5505296  0.44947043]\n",
      "Sensor: [0.3477346123104095, 0.4213462661047471, 0.19004258698561324, 0.3274471381505678], Action prob: [0.55047256 0.44952753], Action: 1, state: 9\n",
      "[0.55047256 0.44952753]\n",
      "Sensor: [0.3558289222673917, 0.6431604547443899, 0.2076582080605979, 0.23268794879698965], Action prob: [0.5504225  0.44957748], Action: 0, state: 0\n",
      "[0.5504225  0.44957748]\n",
      "Sensor: [0.3411801159845305, 0.6064832454137805, 0.2086744604849731, 0.241813567625956], Action prob: [0.55038565 0.44961432], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55038565 0.44961432]\n",
      "Sensor: [0.3753564260945261, 0.664022659826984, 0.23579665384886425, 0.2776602739055624], Action prob: [0.5502777  0.44972235], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5502777  0.44972235]\n",
      "Sensor: [0.3983068091439058, 0.6069764616770338, 0.21134409626287617, 0.2397745023952668], Action prob: [0.55019 0.44981], Action: 0, state: 0\n",
      "[0.55019 0.44981]\n",
      "Sensor: [0.40756499107661337, 0.5685629305734804, 0.20673041532595524, 0.22999881518136203], Action prob: [0.5501191  0.44988087], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([ 0.2875, -0.6015, -1.3960, -0.5081, -0.0202,  0.5012,  0.5654,  1.1802],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1280 is -78500, loss is -0.001068807944964556\n",
      "[0.5501191  0.44988087]\n",
      "Sensor: [0.3602377706327776, 0.6312991227030509, 0.21409959403856801, 0.24674916123070542], Action prob: [0.55365646 0.44634354], Action: 0, state: 0\n",
      "[0.55365646 0.44634354]\n",
      "Sensor: [0.3681257816601324, 0.5856447540516228, 0.19323681626738068, 0.25232858935879726], Action prob: [0.5531013 0.4468986], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5531013 0.4468986]\n",
      "Sensor: [0.327753404013771, 0.6047441225013132, 0.24829577022621374, 0.26856212550658726], Action prob: [0.55272114 0.4472788 ], Action: 0, state: 0\n",
      "[0.55272114 0.4472788 ]\n",
      "Sensor: [0.3426583822315674, 0.658717370969987, 0.14584072534083609, 0.22381437592175346], Action prob: [0.5525657  0.44743437], Action: 0, state: 1\n",
      "[0.5525657  0.44743437]\n",
      "Sensor: [0.29212284332670185, 0.5899884945082765, 0.22190406706173338, 0.23590732869404674], Action prob: [0.5524731  0.44752684], Action: 0, state: 1\n",
      "[0.5524731  0.44752684]\n",
      "Sensor: [0.40090882778853654, 0.7152653038339811, 0.18512578605629268, 0.24286753824242258], Action prob: [0.5522644 0.4477356], Action: 0, state: 1\n",
      "[0.5522644 0.4477356]\n",
      "Sensor: [0.3152492221110294, 0.6359582070225113, 0.18780291236597016, 0.258658525136225], Action prob: [0.5522958  0.44770423], Action: 0, state: 1\n",
      "[0.5522958  0.44770423]\n",
      "Sensor: [0.38399101213657205, 0.6679986073642252, 0.22805515642670673, 0.22417493746421574], Action prob: [0.55216646 0.4478335 ], Action: 0, state: 1\n",
      "tensor([-0.9456, -0.6674, -0.4818, -0.1607,  0.1532,  0.4114,  0.6649,  0.8804],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1288 is -72100, loss is 0.01819732364407868\n",
      "[0.55216646 0.4478335 ]\n",
      "Sensor: [0.3325486319344837, 0.7128893324884161, 0.23527941176901435, 0.2559815913989011], Action prob: [0.5547254 0.4452746], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5547254 0.4452746]\n",
      "Sensor: [0.3951430435112752, 0.6693489598235585, 0.21710866007932414, 0.2652638742150576], Action prob: [0.55407345 0.44592655], Action: 0, state: 0\n",
      "[0.55407345 0.44592655]\n",
      "Sensor: [0.39610590462080597, 0.6508691065493203, 0.5009210548697266, 0.25333751903763796], Action prob: [0.55342466 0.4465753 ], Action: 1, state: 9\n",
      "[0.55342466 0.4465753 ]\n",
      "Sensor: [0.3164881991383188, 0.6522157191692083, 0.47004959455068884, 0.2524196613315446], Action prob: [0.55317956 0.44682044], Action: 1, state: 9\n",
      "[0.55317956 0.44682044]\n",
      "Sensor: [0.2912718344858218, 0.6866546472186934, 0.22765634694000378, 0.26381379136490435], Action prob: [0.5533085  0.44669154], Action: 0, state: 0\n",
      "[0.5533085  0.44669154]\n",
      "Sensor: [0.323742784815673, 0.4785341155262376, 0.5243895373019893, 0.513959621361827], Action prob: [0.5529708  0.44702914], Action: 0, state: 1\n",
      "[0.5529708  0.44702914]\n",
      "Sensor: [0.3445988587422539, 0.6558781826786176, 0.22134228122195146, 0.21688984908140146], Action prob: [0.553022   0.44697797], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1100\n",
      "[0.553022   0.44697797]\n",
      "Sensor: [0.3436325475736434, 0.6297108272323679, 0.22516334009063604, 0.21786807079491627], Action prob: [0.553077   0.44692302], Action: 0, state: 1\n",
      "tensor([ 0.1783,  0.6676, -0.3900, -1.5870, -0.3908,  0.2948,  1.0348,  0.1235],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1296 is -71100, loss is 0.008608230918586122\n",
      "[0.553077   0.44692302]\n",
      "Sensor: [0.3454017660100606, 0.6319502981187091, 0.2129246595680375, 0.27188381635431286], Action prob: [0.55480987 0.4451901 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.55480987 0.4451901 ]\n",
      "Sensor: [0.3134353618437729, 0.5909272015821352, 0.21983526592480945, 0.23199110349679636], Action prob: [0.55429256 0.44570744], Action: 0, state: 0\n",
      "[0.55429256 0.44570744]\n",
      "Sensor: [0.2716587864594968, 0.6253146103252931, 0.20305278910094948, 0.22077787174143387], Action prob: [0.5539295 0.4460704], Action: 0, state: 0\n",
      "[0.5539295 0.4460704]\n",
      "Sensor: [0.3749920158000434, 0.6393399742530067, 0.19533428926557508, 0.19824216299074646], Action prob: [0.5535045  0.44649544], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5535045  0.44649544]\n",
      "Sensor: [0.3821374595461285, 0.6721617761661977, 0.25671240131812706, 0.18461145937551204], Action prob: [0.55320907 0.44679087], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.55320907 0.44679087]\n",
      "Sensor: [0.36122180451528735, 0.6179753649875758, 0.20710061442268035, 0.6600722681090584], Action prob: [0.5532135  0.44678658], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5532135  0.44678658]\n",
      "Sensor: [0.34798866003547196, 0.6220864183894115, 0.24077709493400334, 0.2378801810298363], Action prob: [0.55315745 0.44684252], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.55315745 0.44684252]\n",
      "Sensor: [0.3581833645214517, 0.6519905081928982, 0.23268016279630355, 0.24671554189544262], Action prob: [0.5531294  0.44687063], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-0.9093, -1.0842, -0.3230,  0.4785,  0.9042,  0.1855,  0.4949,  0.7996],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1304 is -69100, loss is -0.06829267655093915\n",
      "[0.5531294  0.44687063]\n",
      "Sensor: [0.3569901937330315, 0.6991069079232909, 0.18281393986677774, 0.28434871618948676], Action prob: [0.55659366 0.44340637], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.55659366 0.44340637]\n",
      "Sensor: [0.3814045254774524, 0.6052590033218122, 0.5184828441641096, 0.2110128581789292], Action prob: [0.555656   0.44434398], Action: 0, state: 0\n",
      "[0.555656   0.44434398]\n",
      "Sensor: [0.39744616989591025, 0.594158530806068, 0.181601754321161, 0.2585056541660574], Action prob: [0.55546653 0.4445334 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.55546653 0.4445334 ]\n",
      "Sensor: [0.36229402030657415, 0.6227267808045246, 0.23263607560563376, 0.28446247781669654], Action prob: [0.55531204 0.44468793], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.55531204 0.44468793]\n",
      "Sensor: [0.36136729535598044, 0.7033449298087096, 0.2395460252651202, 0.41916257047921707], Action prob: [0.5551804 0.4448196], Action: 0, state: 0\n",
      "[0.5551804 0.4448196]\n",
      "Sensor: [0.40966361625668024, 0.5865843199236792, 0.21320233608368971, 0.27015847213714234], Action prob: [0.55506414 0.4449359 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.55506414 0.4449359 ]\n",
      "Sensor: [0.36253367956353527, 0.6221385451233005, 0.23540456835762028, 0.21720253441448603], Action prob: [0.5550792 0.4449208], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5550792 0.4449208]\n",
      "Sensor: [0.3496905912356621, 0.6486526661224197, 0.18566685784904616, 0.25350447232938594], Action prob: [0.555154   0.44484597], Action: 0, state: 0\n",
      "tensor([-0.7337, -1.0732, -0.1094, -0.0962,  0.3555,  1.3938,  0.4705,  0.0373],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1312 is -67700, loss is -0.03057469425078107\n",
      "[0.555154   0.44484597]\n",
      "Sensor: [0.3054025577476888, 0.6455174373560254, 0.2676163541903289, 0.30424709775684966], Action prob: [0.5590749 0.4409251], Action: 0, state: 0\n",
      "[0.5590749 0.4409251]\n",
      "Sensor: [0.3805018311881287, 0.660089445529527, 0.1750833986854769, 0.25011588118727945], Action prob: [0.5586184  0.44138157], Action: 0, state: 0\n",
      "[0.5586184  0.44138157]\n",
      "Sensor: [0.41246440105024434, 0.6321625998658762, 0.23530305691035885, 0.27824314509722986], Action prob: [0.55812943 0.4418706 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.55812943 0.4418706 ]\n",
      "Sensor: [0.3880217751933088, 0.64943328256677, 0.22009890089639622, 0.252533439113389], Action prob: [0.55796045 0.44203958], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.55796045 0.44203958]\n",
      "Sensor: [0.3221041514771635, 0.6118256637428604, 0.261615406816646, 0.2626363369886948], Action prob: [0.5579136  0.44208637], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5579136  0.44208637]\n",
      "Sensor: [0.3687597668478995, 0.6167513329368194, 0.19765193023304733, 0.2521030872989722], Action prob: [0.5578356  0.44216445], Action: 0, state: 0\n",
      "[0.5578356  0.44216445]\n",
      "Sensor: [0.2994524250371588, 0.6160605056782125, 0.21764895489409913, 0.21311346701148948], Action prob: [0.55791306 0.44208696], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.55791306 0.44208696]\n",
      "Sensor: [0.3813087215410683, 0.6563407509561537, 0.2349629153435685, 0.22593685183262852], Action prob: [0.5578128  0.44218713], Action: 0, state: 0\n",
      "tensor([-1.1758, -0.5787, -0.0236, -0.0251,  0.3066,  0.2078,  0.8107,  0.7394],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1320 is -62700, loss is -0.03265639246501818\n",
      "[0.5578128  0.44218713]\n",
      "Sensor: [0.332686409242186, 0.6450904219904676, 0.2205302790481136, 0.1859851693668135], Action prob: [0.56229657 0.4377035 ], Action: 0, state: 0\n",
      "[0.56229657 0.4377035 ]\n",
      "Sensor: [0.40874459231576477, 0.6717325239667324, 0.23631350406633556, 0.2892344890475973], Action prob: [0.5618263  0.43817374], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5618263  0.43817374]\n",
      "Sensor: [0.35679285114817044, 0.6065375368368837, 0.22320263788091124, 0.28217328292889643], Action prob: [0.5615558  0.43844423], Action: 0, state: 0\n",
      "[0.5615558  0.43844423]\n",
      "Sensor: [0.4081348142163279, 0.6592313927060497, 0.19930487266025212, 0.21705504891638822], Action prob: [0.5613669  0.43863305], Action: 0, state: 0\n",
      "[0.5613669  0.43863305]\n",
      "Sensor: [0.3199432618209987, 0.6917267658174768, 0.18909503851535076, 0.25820393899175453], Action prob: [0.56140983 0.4385902 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.56140983 0.4385902 ]\n",
      "Sensor: [0.27813778165721864, 0.6331768600082915, 0.38380237043066656, 0.24113592514890908], Action prob: [0.56134075 0.43865928], Action: 0, state: 0\n",
      "[0.56134075 0.43865928]\n",
      "Sensor: [0.30356877990145364, 0.6304396387087625, 0.2423764804808033, 0.22502342752636476], Action prob: [0.56132543 0.4386746 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.56132543 0.4386746 ]\n",
      "Sensor: [0.5102446365588931, 0.6360206162876044, 0.16804584079443302, 0.2411387650840623], Action prob: [0.5609992 0.4390008], Action: 0, state: 0\n",
      "tensor([-1.0642, -0.8460, -0.3754, -0.0039,  0.5013,  0.3744,  0.9074,  0.6111],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1328 is -57300, loss is -0.013105307111082778\n",
      "[0.5609992 0.4390008]\n",
      "Sensor: [0.3566240329331115, 0.6009191796408567, 0.24035681703137748, 0.23764424223734762], Action prob: [0.56562895 0.43437096], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.56562895 0.43437096]\n",
      "Sensor: [0.3566208735805847, 0.6151120335291074, 0.2596841794296657, 0.2604136339018716], Action prob: [0.5654362  0.43456385], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5654362  0.43456385]\n",
      "Sensor: [0.318722341687696, 0.6248282229865957, 0.18034245401183524, 0.29512084255412924], Action prob: [0.56535184 0.43464822], Action: 0, state: 0\n",
      "[0.56535184 0.43464822]\n",
      "Sensor: [0.4036002240444678, 0.6976306882227126, 0.2666974090511545, 0.26380610762504403], Action prob: [0.5650442  0.43495584], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5650442  0.43495584]\n",
      "Sensor: [0.36279030123718065, 0.6346340917054513, 0.19926783003422724, 0.3001329624755939], Action prob: [0.56493175 0.43506828], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.56493175 0.43506828]\n",
      "Sensor: [0.3999473397579309, 0.6282335258616746, 0.22144180834724492, 0.1958150912323671], Action prob: [0.5648119  0.43518803], Action: 0, state: 0\n",
      "[0.5648119  0.43518803]\n",
      "Sensor: [0.3275998303294647, 0.6029632175315156, 0.20850204096675748, 0.27277983066622025], Action prob: [0.5648368  0.43516323], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5648368  0.43516323]\n",
      "Sensor: [0.3130092764370069, 0.6418126500331082, 0.19511027813460619, 0.25899707798285887], Action prob: [0.5649079  0.43509203], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.5274, -1.0895, -0.7480, -0.2671,  0.1456,  0.3466,  1.1233,  1.1218],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1336 is -54500, loss is -0.013142997439725496\n",
      "[0.5649079  0.43509203]\n",
      "Sensor: [0.31800294162851217, 0.6792416323352201, 0.23264524692319227, 0.25474222490960197], Action prob: [0.5695564  0.43044356], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5695564  0.43044356]\n",
      "Sensor: [0.3667672430756712, 0.6672518630872619, 0.15945344043810836, 0.2395629646126829], Action prob: [0.5695718  0.43042815], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.5695718  0.43042815]\n",
      "Sensor: [0.3606293820440621, 0.5550048658526099, 0.2188502153255539, 0.1894662349468235], Action prob: [0.56929314 0.43070686], Action: 0, state: 0\n",
      "[0.56929314 0.43070686]\n",
      "Sensor: [0.340225220568514, 0.7181678999562323, 0.1801965902240732, 0.23876998645941994], Action prob: [0.569267   0.43073303], Action: 0, state: 0\n",
      "[0.569267   0.43073303]\n",
      "Sensor: [0.3709529272362099, 0.6619928932080225, 0.2590894055692994, 0.24161167293484498], Action prob: [0.5690537 0.4309463], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5690537 0.4309463]\n",
      "Sensor: [0.34739368842819385, 0.6311223488337759, 0.23776806728611363, 0.2784988180601929], Action prob: [0.5689504  0.43104956], Action: 0, state: 0\n",
      "[0.5689504  0.43104956]\n",
      "Sensor: [0.3507189210863641, 0.6309745591804341, 0.2092686805981443, 0.25676148389985465], Action prob: [0.5689119  0.43108806], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5689119  0.43108806]\n",
      "Sensor: [0.3512560695640599, 0.624800027167608, 0.24575905263475933, 0.24715896155144532], Action prob: [0.56886876 0.43113124], Action: 0, state: 0\n",
      "tensor([-0.3908, -0.4111, -1.0743, -0.3506,  0.3604,  0.2442,  1.0656,  0.7176],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1344 is -51800, loss is -0.020129402459616058\n",
      "[0.56886876 0.43113124]\n",
      "Sensor: [0.4135610564389453, 0.624734607784105, 0.2615121253353719, 0.27949813276850677], Action prob: [0.57323635 0.42676368], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.57323635 0.42676368]\n",
      "Sensor: [0.3682892023747433, 0.5937596460260323, 0.21356134034125104, 0.2195846927574277], Action prob: [0.57365763 0.4263423 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.57365763 0.4263423 ]\n",
      "Sensor: [0.3629998774187913, 0.6419504940217995, 0.20967526372540157, 0.26666806915157265], Action prob: [0.5737204  0.42627957], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5737204  0.42627957]\n",
      "Sensor: [0.44909484262541066, 0.6327165469900623, 0.20282272822794165, 0.24645770799330735], Action prob: [0.5734713 0.4265287], Action: 0, state: 0\n",
      "[0.5734713 0.4265287]\n",
      "Sensor: [0.37202656431055786, 0.6128615221475148, 0.24139293798996553, 0.3978970109670185], Action prob: [0.5733768  0.42662323], Action: 0, state: 0\n",
      "[0.5733768  0.42662323]\n",
      "Sensor: [0.3699013263269573, 0.6499047691916456, 0.19091959093469604, 0.2687077933592613], Action prob: [0.57342726 0.42657277], Action: 0, state: 0\n",
      "[0.57342726 0.42657277]\n",
      "Sensor: [0.37231608210284345, 0.6299295085804147, 0.19197134236110142, 0.21603354778106487], Action prob: [0.5734495  0.42655054], Action: 0, state: 0\n",
      "[0.5734495  0.42655054]\n",
      "Sensor: [0.34766911924064714, 0.6527596302705732, 0.24388763972866953, 0.19528707249407035], Action prob: [0.57349384 0.4265062 ], Action: 0, state: 0\n",
      "tensor([-0.8391, -0.8482, -0.4281, -0.5331, -0.0718,  0.3079,  0.6592,  0.9851],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1352 is -46800, loss is 0.09599382446331017\n",
      "[0.57349384 0.4265062 ]\n",
      "Sensor: [0.357422245048813, 0.6726375011159336, 0.2013621268299617, 0.36045166295687564], Action prob: [0.5750428 0.4249572], Action: 0, state: 0\n",
      "[0.5750428 0.4249572]\n",
      "Sensor: [0.3836070052085665, 0.6472202738373957, 0.26187659929397816, 0.24523467612512267], Action prob: [0.5752671  0.42473286], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5752671  0.42473286]\n",
      "Sensor: [0.33653454550147777, 0.655831865510865, 0.19678255547431445, 0.26087365628376863], Action prob: [0.5753965  0.42460352], Action: 0, state: 0\n",
      "[0.5753965  0.42460352]\n",
      "Sensor: [0.3504265269767722, 0.6010360581916631, 0.22814095533435888, 0.20053927272957162], Action prob: [0.5752351 0.4247649], Action: 0, state: 0\n",
      "[0.5752351 0.4247649]\n",
      "Sensor: [0.3931822349314614, 0.6233026881458646, 0.22267899069932912, 0.22386759996397051], Action prob: [0.57506377 0.4249362 ], Action: 0, state: 1\n",
      "[0.57506377 0.4249362 ]\n",
      "Sensor: [0.3908676089160062, 0.6842455498866501, 0.21215437672928084, 0.24862525324215845], Action prob: [0.57504433 0.42495558], Action: 0, state: 2\n",
      "[0.57504433 0.42495558]\n",
      "Sensor: [0.2989701025375148, 0.3866066561251853, 0.2003047843866696, 0.2136534435564664], Action prob: [0.57490754 0.4250924 ], Action: 0, state: 3\n",
      "[0.57490754 0.4250924 ]\n",
      "Sensor: [0.3890515912687058, 0.6531933415197508, 0.191631154187853, 0.19165570390388842], Action prob: [0.5749535  0.42504656], Action: 0, state: 3\n",
      "tensor([-0.9440, -0.8824, -0.3822, -0.0443,  0.2285,  0.4498,  0.5806,  0.6795],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1360 is -41200, loss is 0.039330737726327225\n",
      "[0.5749535  0.42504656]\n",
      "Sensor: [0.38613739417542736, 0.6189378358014819, 0.22053026331418096, 0.25253224725503065], Action prob: [0.575329   0.42467102], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "[0.575329   0.42467102]\n",
      "Sensor: [0.5426523851880233, 0.6401694605809876, 0.23129950903872232, 0.23448737457258556], Action prob: [0.57522786 0.42477214], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.57522786 0.42477214]\n",
      "Sensor: [0.3096520771905555, 0.6686935674625788, 0.22761383885257921, 0.23165252219035218], Action prob: [0.5756067  0.42439333], Action: 0, state: 1\n",
      "[0.5756067  0.42439333]\n",
      "Sensor: [0.37303316318153673, 0.6264704642384669, 0.20789989192522518, 0.21837767232373514], Action prob: [0.57547814 0.42452183], Action: 0, state: 2\n",
      "[0.57547814 0.42452183]\n",
      "Sensor: [0.4009544640256965, 0.6676212285465648, 0.21933397414342604, 0.2612506303513678], Action prob: [0.57533276 0.4246672 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.57533276 0.4246672 ]\n",
      "Sensor: [0.39321123531382646, 0.670450584681892, 0.21583392439279592, 0.18871841151672603], Action prob: [0.5752974  0.42470267], Action: 0, state: 1\n",
      "[0.5752974  0.42470267]\n",
      "Sensor: [0.3083842412261196, 0.6461435616927736, 0.17752779175871808, 0.2627975149998648], Action prob: [0.57539624 0.42460376], Action: 0, state: 2\n",
      "[0.57539624 0.42460376]\n",
      "Sensor: [0.3627843412084111, 0.6946000724991337, 0.2320719835735394, 0.2649386756302711], Action prob: [0.5753427  0.42465734], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "tensor([-0.9610, -1.1899, -0.5074, -0.0866,  0.4687,  0.2536,  0.5767,  1.3327],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1368 is -38500, loss is 0.014146416620160918\n",
      "[0.5753427  0.42465734]\n",
      "Sensor: [0.34918528660019127, 0.6750348468625204, 0.23797699629548355, 0.26903708956257666], Action prob: [0.57555145 0.4244486 ], Action: 0, state: 1\n",
      "[0.57555145 0.4244486 ]\n",
      "Sensor: [0.3546329869707465, 0.6215468897246564, 0.20788773300495164, 0.24596005339765364], Action prob: [0.57574594 0.4242541 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.57574594 0.4242541 ]\n",
      "Sensor: [0.2945733476338729, 0.6216868193445104, 0.23297855021729363, 0.29525479375071534], Action prob: [0.5757418  0.42425817], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5757418  0.42425817]\n",
      "Sensor: [0.382983893247825, 0.6527240342988581, 0.22692441188423748, 0.3146182643607014], Action prob: [0.5754258  0.42457423], Action: 0, state: 0\n",
      "[0.5754258  0.42457423]\n",
      "Sensor: [0.4297282124484612, 0.5957870473196772, 0.24063366711579975, 0.2642928110350167], Action prob: [0.5751468 0.4248532], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5751468 0.4248532]\n",
      "Sensor: [0.351102422854861, 0.6414142189584434, 0.18687116231675555, 0.2137987798831999], Action prob: [0.5752148 0.4247852], Action: 0, state: 0\n",
      "[0.5752148 0.4247852]\n",
      "Sensor: [0.3289962532357414, 0.6228968950575721, 0.22802763465578108, 0.2547162265053504], Action prob: [0.57523996 0.42476   ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.57523996 0.42476   ]\n",
      "Sensor: [0.36355185497842146, 0.6072493020774513, 0.20182848114901714, 0.2298677590579801], Action prob: [0.57518756 0.42481247], Action: 0, state: 0\n",
      "tensor([-0.9159, -0.5889, -0.1909, -0.4051,  0.1276,  0.3020,  1.0416,  0.8448],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1376 is -33900, loss is -0.026888076310532374\n",
      "[0.57518756 0.42481247]\n",
      "Sensor: [0.3523510704034342, 0.6704707135283704, 0.23679791291164554, 0.2061868014884962], Action prob: [0.5759749  0.42402512], Action: 0, state: 0\n",
      "[0.5759749  0.42402512]\n",
      "Sensor: [0.38316437129688896, 0.6855580519354736, 0.2191745888114684, 0.39672420235317596], Action prob: [0.5760282  0.42397177], Action: 0, state: 0\n",
      "[0.5760282  0.42397177]\n",
      "Sensor: [0.36786416662301896, 0.6531609996479164, 0.20597696803106316, 0.2502195134640858], Action prob: [0.57596827 0.42403176], Action: 0, state: 0\n",
      "[0.57596827 0.42403176]\n",
      "Sensor: [0.30737680881364915, 0.6403353252032885, 0.224197109002019, 0.23073866858067882], Action prob: [0.57590705 0.42409298], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.57590705 0.42409298]\n",
      "Sensor: [0.3797317901555019, 0.6585758608759736, 0.23545763579000828, 0.24105269209478544], Action prob: [0.5756928  0.42430723], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5756928  0.42430723]\n",
      "Sensor: [0.31697592556688475, 0.6623767462513507, 0.21046437077995897, 0.5270137435265801], Action prob: [0.5756692  0.42433074], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5756692  0.42433074]\n",
      "Sensor: [0.35861984642803196, 0.6278289513495147, 0.22023252999199133, 0.290938128394017], Action prob: [0.57554924 0.42445084], Action: 0, state: 0\n",
      "[0.57554924 0.42445084]\n",
      "Sensor: [0.30385632928436124, 0.6738912816688937, 0.21495668186955105, 0.18605338063749083], Action prob: [0.57564205 0.42435798], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "tensor([-1.1431, -0.5600, -0.0575,  0.5688,  0.2372,  0.5705,  0.3452,  1.0013],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1384 is -30500, loss is -0.12030276566847917\n",
      "[0.57564205 0.42435798]\n",
      "Sensor: [0.2966106551208833, 0.46432017640835754, 0.2293552145634306, 0.21569630858495684], Action prob: [0.57877046 0.42122948], Action: 0, state: 0\n",
      "[0.57877046 0.42122948]\n",
      "Sensor: [0.3715169114349256, 0.6435923731952367, 0.22245749203876136, 0.2865457068979562], Action prob: [0.578812   0.42118803], Action: 0, state: 0\n",
      "[0.578812   0.42118803]\n",
      "Sensor: [0.3391702679239544, 0.6135451412904589, 0.2434649690822682, 0.17006844266597693], Action prob: [0.57879317 0.42120686], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.57879317 0.42120686]\n",
      "Sensor: [0.32631863414656836, 0.6472879078422837, 0.24237111392042945, 0.24895371267747282], Action prob: [0.57869184 0.42130822], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.57869184 0.42130822]\n",
      "Sensor: [0.31446255708908627, 0.6604963189625134, 0.2089939495121822, 0.27473951040989353], Action prob: [0.57865113 0.42134884], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.57865113 0.42134884]\n",
      "Sensor: [0.32058454373372836, 0.5894202325732403, 0.21106065499019971, 0.2594888572058079], Action prob: [0.57850903 0.42149097], Action: 0, state: 0\n",
      "[0.57850903 0.42149097]\n",
      "Sensor: [0.3414382458051016, 0.6604783156431139, 0.25214943839995224, 0.27431770644039505], Action prob: [0.5784326 0.4215674], Action: 0, state: 0\n",
      "[0.5784326 0.4215674]\n",
      "Sensor: [0.3635502891013516, 0.5963215892929271, 0.20415325559421588, 0.28405826294697395], Action prob: [0.57831955 0.42168042], Action: 0, state: 0\n",
      "tensor([-1.1195, -0.4817,  0.0519,  0.4737,  0.1037,  0.0643,  0.4467,  0.7810],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1392 is -25700, loss is -0.04000728974046746\n",
      "[0.57831955 0.42168042]\n",
      "Sensor: [0.34557560920313923, 0.6558533655646516, 0.2507279878170962, 0.2581012523728563], Action prob: [0.5818396 0.4181604], Action: 0, state: 1\n",
      "[0.5818396 0.4181604]\n",
      "Sensor: [0.3431533976700919, 0.5155289515935653, 0.18750687268865182, 0.2532325918306379], Action prob: [0.5820025  0.41799745], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.5820025  0.41799745]\n",
      "Sensor: [0.33641992634865936, 0.648081271135941, 0.16005536401937362, 0.20300459113128644], Action prob: [0.58206916 0.41793087], Action: 0, state: 0\n",
      "[0.58206916 0.41793087]\n",
      "Sensor: [0.34865531504318503, 0.6719413906535672, 0.21079212329102653, 0.20226219254651318], Action prob: [0.58193713 0.41806287], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.58193713 0.41806287]\n",
      "Sensor: [0.34042618641968253, 0.6689072476937331, 0.21746822287026482, 0.19883961617955234], Action prob: [0.5818168  0.41818318], Action: 0, state: 0\n",
      "[0.5818168  0.41818318]\n",
      "Sensor: [0.33936331045792156, 0.6354143050518956, 0.18997501369652894, 0.22249810606973172], Action prob: [0.5817065 0.4182935], Action: 0, state: 1\n",
      "[0.5817065 0.4182935]\n",
      "Sensor: [0.31699744469617774, 0.6409349560318288, 0.19097445649277367, 0.3078909558941031], Action prob: [0.5816715 0.4183285], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.5816715 0.4183285]\n",
      "Sensor: [0.3901330355890432, 0.6204257497479313, 0.23135067901910578, 0.215063738677994], Action prob: [0.5814459  0.41855413], Action: 0, state: 1\n",
      "tensor([-0.7294, -0.1989, -0.7433, -0.3908,  0.0068,  0.4081,  1.1892,  0.6939],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1400 is -21900, loss is -0.02944890259963681\n",
      "[0.5814459  0.41855413]\n",
      "Sensor: [0.345712992536253, 0.6495186019583932, 0.21821483363587035, 0.17318714166313273], Action prob: [0.58540535 0.4145947 ], Action: 0, state: 1\n",
      "[0.58540535 0.4145947 ]\n",
      "Sensor: [0.39512257317037447, 0.62633271905466, 0.22381853212825595, 0.28212304574388547], Action prob: [0.5855559  0.41444406], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5855559  0.41444406]\n",
      "Sensor: [0.35115437975906555, 0.6220835269425508, 0.23430685506458174, 0.27188242814123054], Action prob: [0.58548725 0.41451284], Action: 0, state: 0\n",
      "[0.58548725 0.41451284]\n",
      "Sensor: [0.28652431437860926, 0.670099804498124, 0.19354395891674236, 0.18770281472118877], Action prob: [0.5856152  0.41438475], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "[0.5856152  0.41438475]\n",
      "Sensor: [0.2828003044726037, 0.6322703627918812, 0.19943045970699574, 0.23791694312539252], Action prob: [0.58553743 0.4144626 ], Action: 0, state: 0\n",
      "[0.58553743 0.4144626 ]\n",
      "Sensor: [0.3237938667207746, 0.6679342614495136, 0.21737227963686442, 0.23344503578293552], Action prob: [0.5853765  0.41462353], Action: 0, state: 1\n",
      "[0.5853765  0.41462353]\n",
      "Sensor: [0.42243952409282315, 0.6651778254290389, 0.20650244141610116, 0.25205229668958473], Action prob: [0.58503383 0.4149662 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.58503383 0.4149662 ]\n",
      "Sensor: [0.3745520400849744, 0.6206984370921911, 0.23409911436417938, 0.2875293919828294], Action prob: [0.58491886 0.4150811 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.0399, -0.6630, -0.0828,  0.7886, -0.2824,  0.1296,  0.8110,  1.1348],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1408 is -18700, loss is -0.09947645159768095\n",
      "[0.58491886 0.4150811 ]\n",
      "Sensor: [0.33408778979665604, 0.6495210515751149, 0.18434883852385178, 0.3074832766646477], Action prob: [0.5910246  0.40897545], Action: 0, state: 0\n",
      "[0.5910246  0.40897545]\n",
      "Sensor: [0.342166559641644, 0.6884110410993562, 0.21162644406950212, 0.24663372016987772], Action prob: [0.59152836 0.4084716 ], Action: 0, state: 0\n",
      "[0.59152836 0.4084716 ]\n",
      "Sensor: [0.35172436496447995, 0.6304113238181805, 0.41291002181153935, 0.2699107917390618], Action prob: [0.59121    0.40879002], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.59121    0.40879002]\n",
      "Sensor: [0.3466082015213381, 0.62161381766657, 0.24264635462486445, 0.2710065773066775], Action prob: [0.59108984 0.40891019], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59108984 0.40891019]\n",
      "Sensor: [0.3214387714656569, 0.5910475742543976, 0.2101743117545593, 0.2679196279264502], Action prob: [0.59103066 0.4089693 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.59103066 0.4089693 ]\n",
      "Sensor: [0.4104136269898474, 0.5691456498803977, 0.2577846413821807, 0.3140742163475992], Action prob: [0.59066284 0.40933716], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.59066284 0.40933716]\n",
      "Sensor: [0.4052666823889581, 0.6163649155663378, 0.20974034236632022, 0.228683378913035], Action prob: [0.59059244 0.40940756], Action: 0, state: 0\n",
      "[0.59059244 0.40940756]\n",
      "Sensor: [0.4319022097979582, 0.6721963713416639, 0.20047193838308494, 0.35298049205031584], Action prob: [0.5905781  0.40942192], Action: 0, state: 1\n",
      "tensor([-1.0411, -0.5025, -0.0688, -0.1017,  0.2305,  0.5341,  0.4622,  0.7277],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1416 is -13500, loss is -0.0300463583799703\n",
      "[0.5905781  0.40942192]\n",
      "Sensor: [0.33329076491002196, 0.5973981340723016, 0.23024606638189993, 0.22715741208342774], Action prob: [0.5967684 0.4032317], Action: 0, state: 1\n",
      "[0.5967684 0.4032317]\n",
      "Sensor: [0.39574910979867656, 0.6616742561055, 0.18070868701613635, 0.22635750997380222], Action prob: [0.59741104 0.402589  ], Action: 0, state: 1\n",
      "[0.59741104 0.402589  ]\n",
      "Sensor: [0.3509585533399794, 0.5963074502187586, 0.17987284856029884, 0.288101381816757], Action prob: [0.5974507 0.4025493], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5974507 0.4025493]\n",
      "Sensor: [0.35147276019365575, 0.6210588799277091, 0.21395168872225784, 0.30225609768841705], Action prob: [0.59725755 0.40274248], Action: 0, state: 0\n",
      "[0.59725755 0.40274248]\n",
      "Sensor: [0.33264047850137224, 0.6327079297718342, 0.18754276426440392, 0.28207649644336413], Action prob: [0.59720546 0.4027946 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.59720546 0.4027946 ]\n",
      "Sensor: [0.4026722651453989, 0.6239725610276023, 0.26617578876083325, 0.3341291076728903], Action prob: [0.59684706 0.40315288], Action: 0, state: 0\n",
      "[0.59684706 0.40315288]\n",
      "Sensor: [0.3553034591096928, 0.6128299047155613, 0.20750372672203468, 0.2922920335970759], Action prob: [0.5968308 0.4031692], Action: 0, state: 0\n",
      "[0.5968308 0.4031692]\n",
      "Sensor: [0.33960430586327783, 0.6393593759020886, 0.216951412751094, 0.24658431863780453], Action prob: [0.5969015  0.40309852], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.8988, -0.5675, -0.4439, -0.0930,  0.3182,  0.3123,  0.5306,  1.2868],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1424 is -7200, loss is -0.05560286002949054\n",
      "[0.5969015  0.40309852]\n",
      "Sensor: [0.3818547987198763, 0.6333453631152464, 0.22669599036702437, 0.23046622908326694], Action prob: [0.60357785 0.3964222 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.60357785 0.3964222 ]\n",
      "Sensor: [0.34935322265784974, 0.6740522691949947, 0.18740505187467724, 0.22293616935623067], Action prob: [0.6048164  0.39518368], Action: 0, state: 0\n",
      "[0.6048164  0.39518368]\n",
      "Sensor: [0.38515555875508495, 0.4260850321552173, 0.20671408735548116, 0.2604837926359337], Action prob: [0.6044631  0.39553693], Action: 0, state: 1\n",
      "[0.6044631  0.39553693]\n",
      "Sensor: [0.35629457040175744, 0.624797898945483, 0.23287859334015049, 0.2643618138942519], Action prob: [0.60446525 0.39553478], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.60446525 0.39553478]\n",
      "Sensor: [0.37771936702483866, 0.7100223947831745, 0.21834031703786766, 0.2725770444146804], Action prob: [0.6044481  0.39555186], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -2500\n",
      "[0.6044481  0.39555186]\n",
      "Sensor: [0.359488422568481, 0.6566774054425464, 0.20319830513263368, 0.5520816624741665], Action prob: [0.604363 0.395637], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.604363 0.395637]\n",
      "Sensor: [0.3274430030837416, 0.611058219738312, 0.2172610988033837, 0.20388125416918676], Action prob: [0.60429037 0.3957097 ], Action: 0, state: 0\n",
      "[0.60429037 0.3957097 ]\n",
      "Sensor: [0.3846755793140691, 0.6276732857770015, 0.13849715949596736, 0.28493824614269836], Action prob: [0.60417813 0.39582187], Action: 0, state: 0\n",
      "tensor([-1.5200, -0.4916,  0.0579,  1.0205,  1.4673, -0.5293, -0.1115,  0.2397],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1432 is -4400, loss is -0.016634364518655187\n",
      "[0.60417813 0.39582187]\n",
      "Sensor: [0.34895069122262345, 0.6488467947660572, 0.21238705356843013, 0.26763988189528515], Action prob: [0.6110882  0.38891178], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6110882  0.38891178]\n",
      "Sensor: [0.3523324737436379, 0.6733280705055719, 0.24646984290488105, 0.15953649852418678], Action prob: [0.61256355 0.38743648], Action: 0, state: 0\n",
      "[0.61256355 0.38743648]\n",
      "Sensor: [0.33687827532171544, 0.683557243351335, 0.19659441870719502, 0.2797520387149041], Action prob: [0.6129857 0.3870143], Action: 0, state: 0\n",
      "[0.6129857 0.3870143]\n",
      "Sensor: [0.3987929190028767, 0.6440010533137187, 0.22184763361303816, 0.2789752506464154], Action prob: [0.61266303 0.387337  ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.61266303 0.387337  ]\n",
      "Sensor: [0.3514015794853761, 0.5844144667184279, 0.2255534763591219, 0.2823702110806658], Action prob: [0.6124893  0.38751066], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.6124893  0.38751066]\n",
      "Sensor: [0.3683362459303427, 0.6684774723426857, 0.23460982232576333, 0.21355655144178504], Action prob: [0.61244106 0.3875589 ], Action: 0, state: 0\n",
      "[0.61244106 0.3875589 ]\n",
      "Sensor: [0.3579755442206299, 0.6415571686278655, 0.23488854425224429, 0.30251901018891775], Action prob: [0.61240417 0.3875959 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.61240417 0.3875959 ]\n",
      "Sensor: [0.341413252538856, 0.6113888944944246, 0.22730672437875277, 0.4846137990809921], Action prob: [0.6123372  0.38766283], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.6928, -0.6414, -0.2004,  0.3660,  0.3756,  0.1880,  0.9317,  1.2091],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1440 is 100, loss is -0.06698246639110596\n",
      "[0.6123372  0.38766283]\n",
      "Sensor: [0.43114091460666665, 0.6899930605584353, 0.20040701073593747, 0.2382214018209323], Action prob: [0.619462 0.380538], Action: 0, state: 0\n",
      "[0.619462 0.380538]\n",
      "Sensor: [0.38578181955260255, 0.6011401925923948, 0.19747330745667044, 0.2356312324826236], Action prob: [0.6217792 0.3782208], Action: 0, state: 1\n",
      "[0.6217792 0.3782208]\n",
      "Sensor: [0.3531236503777273, 0.6796538753379991, 0.2699139579194576, 0.22433441371157897], Action prob: [0.6227641 0.3772358], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6227641 0.3772358]\n",
      "Sensor: [0.34382832585922557, 0.6303405858597481, 0.2331425220422479, 0.263490806756523], Action prob: [0.6230191  0.37698087], Action: 0, state: 0\n",
      "[0.6230191  0.37698087]\n",
      "Sensor: [0.36511079596331314, 0.5930730328556583, 0.21305475050645645, 0.2882952543716688], Action prob: [0.62292343 0.37707657], Action: 0, state: 1\n",
      "[0.62292343 0.37707657]\n",
      "Sensor: [0.35882542030911385, 0.6863790059649933, 0.1533862062859288, 0.20332300529897332], Action prob: [0.62306774 0.37693226], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.62306774 0.37693226]\n",
      "Sensor: [0.35821916866636827, 0.6816350492980412, 0.26778388592971053, 0.3317828239169885], Action prob: [0.6230878 0.3769122], Action: 0, state: 1\n",
      "[0.6230878 0.3769122]\n",
      "Sensor: [0.35918049490063086, 0.5821739478925392, 0.23475315993613294, 0.29618396585439377], Action prob: [0.62287337 0.3771266 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "tensor([-0.8677, -0.5254, -0.4463, -0.0680,  0.1710,  0.7240,  0.4595,  1.2971],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1448 is 4900, loss is -0.09301465189400919\n",
      "[0.62287337 0.3771266 ]\n",
      "Sensor: [0.38319485161749517, 0.6704686635587916, 0.23445611683806528, 0.2410099335596139], Action prob: [0.6305674  0.36943263], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6305674  0.36943263]\n",
      "Sensor: [0.3475859653282331, 0.6337914498840059, 0.2071071978178794, 0.2518605166781914], Action prob: [0.63428867 0.3657113 ], Action: 0, state: 0\n",
      "[0.63428867 0.3657113 ]\n",
      "Sensor: [0.32854765000159303, 0.7015440443918173, 0.26368274041129824, 0.29450138866609404], Action prob: [0.6360793  0.36392072], Action: 0, state: 0\n",
      "[0.6360793  0.36392072]\n",
      "Sensor: [0.30877552524740326, 0.5977563057564581, 0.19636129815540937, 0.24767785242543958], Action prob: [0.6365827 0.3634173], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.6365827 0.3634173]\n",
      "Sensor: [0.37932009619937107, 0.6651349499007382, 0.19499306957319162, 0.26315607568982324], Action prob: [0.63661927 0.36338073], Action: 0, state: 0\n",
      "[0.63661927 0.36338073]\n",
      "Sensor: [0.3853041948541115, 0.6893629604305157, 0.21351642438067886, 0.20779214153569922], Action prob: [0.63666415 0.3633358 ], Action: 0, state: 0\n",
      "[0.63666415 0.3633358 ]\n",
      "Sensor: [0.39048479564215033, 0.5871966039886889, 0.21647647028580902, 0.27976574328266895], Action prob: [0.636472   0.36352798], Action: 0, state: 1\n",
      "[0.636472   0.36352798]\n",
      "Sensor: [0.3355402535609045, 0.6245698860370736, 0.1898303797522427, 0.29120264377015687], Action prob: [0.63672817 0.3632718 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-0.8405, -0.4983, -0.1896,  0.1529,  0.0634,  0.2761,  0.4559,  1.3783],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1456 is 10700, loss is -0.09975407196041289\n",
      "[0.63672817 0.3632718 ]\n",
      "Sensor: [0.41736632422626246, 0.6519773335437036, 0.1816452052877439, 0.4721486711184393], Action prob: [0.6441843  0.35581565], Action: 0, state: 0\n",
      "[0.6441843  0.35581565]\n",
      "Sensor: [0.32912739143485326, 0.6544695237138795, 0.1866702019458311, 0.2475049186238529], Action prob: [0.64985156 0.35014847], Action: 0, state: 1\n",
      "[0.64985156 0.35014847]\n",
      "Sensor: [0.34595385524250305, 0.5941506758671167, 0.19949493658088568, 0.2524114708346001], Action prob: [0.6521317 0.3478683], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6521317 0.3478683]\n",
      "Sensor: [0.35970390139886127, 0.6267833719510908, 0.19996277948284633, 0.23347833341946345], Action prob: [0.6532435  0.34675655], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.6532435  0.34675655]\n",
      "Sensor: [0.3511455012903824, 0.6515821267795613, 0.18412009147305675, 0.25860204620853433], Action prob: [0.65403783 0.34596223], Action: 0, state: 0\n",
      "[0.65403783 0.34596223]\n",
      "Sensor: [0.3850425269557792, 0.634268886765414, 0.1988473705973885, 0.26771412070693523], Action prob: [0.65419096 0.34580904], Action: 0, state: 0\n",
      "[0.65419096 0.34580904]\n",
      "Sensor: [0.34699694703909056, 0.6523445422228907, 0.1861777834791793, 0.2743362022268747], Action prob: [0.65456575 0.34543425], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.65456575 0.34543425]\n",
      "Sensor: [0.33123264969658484, 0.6069716472211482, 0.23702610213319275, 0.4273518968369706], Action prob: [0.65478206 0.345218  ], Action: 0, state: 0\n",
      "tensor([-0.8134, -0.4508, -0.3227,  0.0622,  0.0255,  0.2792,  1.2767,  0.5244],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1464 is 15900, loss is -0.07264502823261\n",
      "[0.65478206 0.345218  ]\n",
      "Sensor: [0.2870774078825425, 0.5098240451315468, 0.24312107204286898, 0.183138039124262], Action prob: [0.6585345  0.34146544], Action: 0, state: 1\n",
      "[0.6585345  0.34146544]\n",
      "Sensor: [0.34416417363757246, 0.6391244423486321, 0.27100234971502146, 0.26210823249002224], Action prob: [0.6670869 0.3329131], Action: 0, state: 1\n",
      "[0.6670869 0.3329131]\n",
      "Sensor: [0.41780522152815247, 0.6569260509290928, 0.18752799958080446, 0.2768250324966226], Action prob: [0.67114806 0.3288519 ], Action: 0, state: 1\n",
      "[0.67114806 0.3288519 ]\n",
      "Sensor: [0.3542020694070887, 0.5894076838957882, 0.19776265593247797, 0.24119316248748676], Action prob: [0.6732357 0.3267643], Action: 0, state: 1\n",
      "[0.6732357 0.3267643]\n",
      "Sensor: [0.33012207010782496, 0.6331461156384092, 0.2067313016321315, 0.26509422284681367], Action prob: [0.6747147  0.32528532], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.6747147  0.32528532]\n",
      "Sensor: [0.38513549165641997, 0.6402925869084413, 0.19754099997091287, 0.246006304975429], Action prob: [0.67524517 0.3247548 ], Action: 0, state: 0\n",
      "[0.67524517 0.3247548 ]\n",
      "Sensor: [0.3551909249192413, 0.6633151140330241, 0.2636091626048737, 0.19690730775985657], Action prob: [0.6757245 0.3242755], Action: 0, state: 1\n",
      "[0.6757245 0.3242755]\n",
      "Sensor: [0.31001970412437835, 0.6394387596481783, 0.18910315892898605, 0.2656943965276811], Action prob: [0.67632735 0.32367262], Action: 0, state: 2\n",
      "tensor([-0.7766, -0.4452, -0.1803,  0.0653,  0.8112,  0.1705,  0.3491,  0.4876],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1472 is 21500, loss is -0.060200442446691003\n",
      "[0.67632735 0.32367262]\n",
      "Sensor: [0.3873045294504837, 0.633598692761427, 0.23946620887652476, 0.20716175660827268], Action prob: [0.6755477  0.32445228], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1100\n",
      "[0.6755477  0.32445228]\n",
      "Sensor: [0.38766029827596615, 0.6484698085579509, 0.20884282762876413, 0.24438792094969095], Action prob: [0.6869408  0.31305918], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6869408  0.31305918]\n",
      "Sensor: [0.35583191736420383, 0.6100740669706588, 0.19280214252538774, 0.2464225880208003], Action prob: [0.692629   0.30737105], Action: 0, state: 0\n",
      "[0.692629   0.30737105]\n",
      "Sensor: [0.39629827735734446, 0.6908553168213627, 0.1877367307856922, 0.2444910370479748], Action prob: [0.69580656 0.30419344], Action: 0, state: 1\n",
      "[0.69580656 0.30419344]\n",
      "Sensor: [0.3938149102143895, 0.6267699651575742, 0.24807505090624737, 0.5935601977740366], Action prob: [0.6980278 0.3019722], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.6980278 0.3019722]\n",
      "Sensor: [0.3878674468969891, 0.6509130830998022, 0.2177360840658419, 0.23542587736950338], Action prob: [0.6984065 0.3015935], Action: 0, state: 0\n",
      "[0.6984065 0.3015935]\n",
      "Sensor: [0.3778208620225779, 0.6385107212506141, 0.20442788272542836, 0.28859537651874473], Action prob: [0.69881517 0.3011848 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.69881517 0.3011848 ]\n",
      "Sensor: [0.3509346671658866, 0.6842464751252595, 0.19591545373168648, 0.25962372941228395], Action prob: [0.69947994 0.30052006], Action: 0, state: 0\n",
      "tensor([-0.4351, -1.9154, -0.4154, -0.1102,  0.6147,  0.1634,  1.3664,  0.5152],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1480 is 25100, loss is 0.027066429781401405\n",
      "[0.69947994 0.30052006]\n",
      "Sensor: [0.3796953333171046, 0.6994108969071936, 0.247288915076069, 0.2847372322512091], Action prob: [0.69197947 0.30802053], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.69197947 0.30802053]\n",
      "Sensor: [0.3947167919740412, 0.6390810670144222, 0.21066751270110656, 0.2502545075935482], Action prob: [0.70645136 0.2935487 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.70645136 0.2935487 ]\n",
      "Sensor: [0.38184544082954575, 0.5882120568023572, 0.22826643356309412, 0.19869425830786316], Action prob: [0.71375936 0.28624064], Action: 0, state: 0\n",
      "[0.71375936 0.28624064]\n",
      "Sensor: [0.3510736880150921, 0.5653789172405418, 0.18685167903360425, 0.2268292416250068], Action prob: [0.7178142  0.28218573], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.7178142  0.28218573]\n",
      "Sensor: [0.3653708605333206, 0.6760079451556273, 0.22592845564957825, 0.20098130797352573], Action prob: [0.72077733 0.27922264], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.72077733 0.27922264]\n",
      "Sensor: [0.3616495937014468, 0.5337881506144144, 0.21752035947202042, 0.20557349583205517], Action prob: [0.72135013 0.27864987], Action: 0, state: 0\n",
      "[0.72135013 0.27864987]\n",
      "Sensor: [0.3123133857903182, 0.590733918157308, 0.21943054785256935, 0.21251008576612243], Action prob: [0.7224099 0.2775901], Action: 0, state: 1\n",
      "[0.7224099 0.2775901]\n",
      "Sensor: [0.3420814041496126, 0.61046295901277, 0.2054760081493324, 0.2947312540133887], Action prob: [0.72316855 0.27683142], Action: 0, state: 2\n",
      "tensor([-1.0193, -0.0530, -0.5232, -0.4179, -0.4192,  0.0723,  0.3643,  0.5951],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1488 is 28500, loss is 0.17512858666811842\n",
      "[0.72316855 0.27683142]\n",
      "Sensor: [0.3555910195770552, 0.5818905947738949, 0.17790602520875515, 0.3071238081588853], Action prob: [0.6968551  0.30314493], Action: 0, state: 2\n",
      "[0.6968551  0.30314493]\n",
      "Sensor: [0.3939834659837365, 0.6503072537840358, 0.22387020938412144, 0.2465046978049129], Action prob: [0.7112226  0.28877744], Action: 0, state: 2\n",
      "[0.7112226  0.28877744]\n",
      "Sensor: [0.36769450753009064, 0.6421717487635069, 0.26617951673541873, 0.2007901722652633], Action prob: [0.7184317  0.28156826], Action: 0, state: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7184317  0.28156826]\n",
      "Sensor: [0.323534172190415, 0.4330927765024692, 0.1958458864573934, 0.23774027279506954], Action prob: [0.7207884 0.2792115], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.7207884 0.2792115]\n",
      "Sensor: [0.3582769721823194, 0.5951912538026022, 0.25785962116810734, 0.3849279780770883], Action prob: [0.7235581  0.27644187], Action: 0, state: 1\n",
      "[0.7235581  0.27644187]\n",
      "Sensor: [0.388291483446464, 0.679604167958046, 0.17395230776406484, 0.26648088107694723], Action prob: [0.72510344 0.27489656], Action: 0, state: 1\n",
      "[0.72510344 0.27489656]\n",
      "Sensor: [0.39015236994509306, 0.5995348090817867, 0.1678987997171255, 0.27354699640145785], Action prob: [0.7254065  0.27459353], Action: 0, state: 2\n",
      "[0.7254065  0.27459353]\n",
      "Sensor: [0.3993948297977854, 0.6525217889840343, 0.19360378342220674, 0.22759828685933586], Action prob: [0.72574574 0.2742543 ], Action: 0, state: 2\n",
      "tensor([-0.6188, -0.3705, -0.1692, -0.0022,  0.0824,  0.2187,  0.3381,  0.4443],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1496 is 34600, loss is 0.00964692753032307\n",
      "[0.72574574 0.2742543 ]\n",
      "Sensor: [0.3477789324853671, 0.6120891915152534, 0.2576748769431085, 0.24128430890107314], Action prob: [0.70121336 0.29878664], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.70121336 0.29878664]\n",
      "Sensor: [0.31543874276299877, 0.6344018362360047, 0.22546147224899754, 0.2275805844029943], Action prob: [0.71424973 0.28575027], Action: 0, state: 1\n",
      "[0.71424973 0.28575027]\n",
      "Sensor: [0.35080733228385835, 0.6708916311120517, 0.20355514969507793, 0.2623801183334705], Action prob: [0.72008103 0.27991894], Action: 0, state: 2\n",
      "[0.72008103 0.27991894]\n",
      "Sensor: [0.36391594894769896, 0.5859933639284384, 0.22347441544054716, 0.223925427698111], Action prob: [0.72171205 0.27828792], Action: 0, state: 2\n",
      "[0.72171205 0.27828792]\n",
      "Sensor: [0.3696566603680633, 0.6193811024437781, 0.21812447504376276, 0.24512645477090672], Action prob: [0.7226578 0.2773422], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "[0.7226578 0.2773422]\n",
      "Sensor: [0.3425872464129858, 0.5972191110003123, 0.2075508205676568, 0.23365815741322354], Action prob: [0.7230823  0.27691773], Action: 0, state: 2\n",
      "[0.7230823  0.27691773]\n",
      "Sensor: [0.3329987848375229, 0.670706768766562, 0.19393306720385856, 0.282931604873311], Action prob: [0.7240491 0.2759509], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1100\n",
      "[0.7240491 0.2759509]\n",
      "Sensor: [0.3725328232578058, 0.6148848296445001, 0.254162187657535, 0.26107608795773085], Action prob: [0.7237735 0.2762265], Action: 0, state: 1\n",
      "tensor([-1.7132, -0.5252, -0.1868,  0.1066,  1.0672,  0.2111,  1.6869,  0.1631],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1504 is 36900, loss is -0.10120473430784593\n",
      "[0.7237735 0.2762265]\n",
      "Sensor: [0.3693389057756594, 0.6834622594062868, 0.20121656431893742, 0.21450101877461952], Action prob: [0.7103207  0.28967923], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.7103207  0.28967923]\n",
      "Sensor: [0.47092559803463885, 0.6259244382118283, 0.2337451502535369, 0.23808292563568795], Action prob: [0.7236363 0.2763636], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7236363 0.2763636]\n",
      "Sensor: [0.31589085555856494, 0.6503983586229962, 0.2132039906878978, 0.2611442875720123], Action prob: [0.7306622 0.2693378], Action: 0, state: 0\n",
      "[0.7306622 0.2693378]\n",
      "Sensor: [0.3743574715754131, 0.6632843447791412, 0.19978361802710665, 0.2610042884229341], Action prob: [0.7333138  0.26668626], Action: 0, state: 1\n",
      "[0.7333138  0.26668626]\n",
      "Sensor: [0.3232330627446804, 0.6370552399382629, 0.23004329175547336, 0.2263751369321387], Action prob: [0.7342836 0.2657164], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7342836 0.2657164]\n",
      "Sensor: [0.38976670589964524, 0.6845381358578578, 0.21632944058639064, 0.2944849092735953], Action prob: [0.73488075 0.26511925], Action: 0, state: 0\n",
      "[0.73488075 0.26511925]\n",
      "Sensor: [0.3388687667332386, 0.6184119829748814, 0.19740860694768797, 0.2472142363603352], Action prob: [0.73477656 0.26522347], Action: 0, state: 0\n",
      "[0.73477656 0.26522347]\n",
      "Sensor: [0.3266635303188933, 0.6619553425999188, 0.20110016121968408, 0.26469400212042904], Action prob: [0.7350978  0.26490217], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "tensor([-1.4754, -1.6497, -0.2733, -0.0787,  0.4289,  0.1855,  0.3422,  2.0913],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1512 is 40600, loss is 0.05366287459853081\n",
      "[0.7350978  0.26490217]\n",
      "Sensor: [0.3452118057720189, 0.6253471221924036, 0.25516775696221106, 0.28998601684892034], Action prob: [0.7170501  0.28294998], Action: 0, state: 0\n",
      "[0.7170501  0.28294998]\n",
      "Sensor: [0.34443837329490556, 0.58750301994828, 0.17226442835245828, 0.22266132146660655], Action prob: [0.7323883  0.26761168], Action: 0, state: 1\n",
      "[0.7323883  0.26761168]\n",
      "Sensor: [0.38656758775252, 0.6687763266319855, 0.25508675107516654, 0.2310423463307899], Action prob: [0.7401306 0.2598693], Action: 0, state: 2\n",
      "[0.7401306 0.2598693]\n",
      "Sensor: [0.34082882527440816, 0.3471909411917543, 0.22962580541549588, 0.22631602028993633], Action prob: [0.7412238  0.25877616], Action: 0, state: 3\n",
      "[0.7412238  0.25877616]\n",
      "Sensor: [0.36672512687996434, 0.38361132737448106, 0.20062633313257028, 0.24363387026335087], Action prob: [0.7416449  0.25835508], Action: 0, state: 8\n",
      "[0.7416449  0.25835508]\n",
      "Sensor: [0.37380359867302704, 0.3363463132787275, 0.206805032501903, 0.22783487948441683], Action prob: [0.7413376 0.2586624], Action: 1, state: 8\n",
      "[0.7413376 0.2586624]\n",
      "Sensor: [0.39968075142538234, 0.41746275384400133, 0.1922106779521236, 0.2586898665070535], Action prob: [0.7417597  0.25824025], Action: 1, state: 8\n",
      "[0.7417597  0.25824025]\n",
      "Sensor: [0.37074614599894523, 0.6802049975552599, 0.20032792548509676, 0.2425536357818723], Action prob: [0.744183   0.25581694], Action: 0, state: 0\n",
      "tensor([ 0.1042,  0.2226,  0.3213,  0.3786,  0.0652, -0.9695, -2.1143, -0.3865],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1520 is 35700, loss is 0.2973128505434092\n",
      "[0.744183   0.25581694]\n",
      "Sensor: [0.3366417190891116, 0.6830100711831758, 0.25400349731672894, 0.22807565040171857], Action prob: [0.71285146 0.28714854], Action: 0, state: 1\n",
      "[0.71285146 0.28714854]\n",
      "Sensor: [0.37729968789139945, 0.60932556695011, 0.21874255537199655, 0.2804402602051415], Action prob: [0.72646856 0.27353144], Action: 0, state: 2\n",
      "[0.72646856 0.27353144]\n",
      "Sensor: [0.40647219792519684, 0.6250065489668181, 0.22726672561289196, 0.2509854543899573], Action prob: [0.73231626 0.2676837 ], Action: 0, state: 2\n",
      "[0.73231626 0.2676837 ]\n",
      "Sensor: [0.35546951798499216, 0.700243725411004, 0.19256766453481416, 0.24949952459236188], Action prob: [0.73566115 0.26433888], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.73566115 0.26433888]\n",
      "Sensor: [0.415907612218387, 0.5889206504690324, 0.25419849490123286, 0.26712192053941386], Action prob: [0.73600847 0.26399148], Action: 0, state: 1\n",
      "[0.73600847 0.26399148]\n",
      "Sensor: [0.3635245916507127, 0.6549543416431132, 0.20286231081005174, 0.2589112463941343], Action prob: [0.7368032 0.2631968], Action: 0, state: 2\n",
      "[0.7368032 0.2631968]\n",
      "Sensor: [0.6083215378842479, 0.6086485027474845, 0.2043319292345052, 0.2274406633718257], Action prob: [0.7353494  0.26465058], Action: 0, state: 3\n",
      "[0.7353494  0.26465058]\n",
      "Sensor: [0.36783525002816087, 0.6001614596473708, 0.25052973313978805, 0.2184590439551015], Action prob: [0.7360282  0.26397187], Action: 0, state: 3\n",
      "tensor([-0.6351, -0.3502, -0.1228,  0.3237,  0.0547,  0.2109,  0.2890,  0.3823],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1528 is 40300, loss is -0.019061303991834817\n",
      "[0.7360282  0.26397187]\n",
      "Sensor: [0.5065071484645487, 0.4954119329109504, 0.34199517571293825, 0.21876369828019043], Action prob: [0.707017 0.292983], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -700\n",
      "[0.707017 0.292983]\n",
      "Sensor: [0.43177121243706706, 0.5813826996988423, 0.20500799324971028, 0.22715272173153805], Action prob: [0.7192538  0.28074625], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.7192538  0.28074625]\n",
      "Sensor: [0.3285328730590423, 0.6284396869575526, 0.20225333180755364, 0.2551741717786779], Action prob: [0.7255952  0.27440482], Action: 0, state: 1\n",
      "[0.7255952  0.27440482]\n",
      "Sensor: [0.3808531690688229, 0.631134945912629, 0.19910142181811136, 0.21603865408704112], Action prob: [0.7275053 0.2724946], Action: 0, state: 1\n",
      "[0.7275053 0.2724946]\n",
      "Sensor: [0.32665757363400777, 0.6315534101767811, 0.23643198714262503, 0.24737181256661966], Action prob: [0.7285803 0.2714197], Action: 0, state: 1\n",
      "[0.7285803 0.2714197]\n",
      "Sensor: [0.3615488097728969, 0.6670642327276349, 0.19886720942203256, 0.2819836708676992], Action prob: [0.72910637 0.27089366], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.72910637 0.27089366]\n",
      "Sensor: [0.3521395155599626, 0.6275353126369367, 0.22735121993146049, 0.26656693371945916], Action prob: [0.72901386 0.27098614], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.72901386 0.27098614]\n",
      "Sensor: [0.3661499369705709, 0.6056702671688237, 0.18486823822350207, 0.26947700367979077], Action prob: [0.72869396 0.2713061 ], Action: 0, state: 0\n",
      "tensor([-0.9208, -1.9289, -0.3574, -0.1099,  0.1198,  1.2171,  1.5555,  0.3737],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1536 is 44000, loss is 0.006375050088473638\n",
      "[0.72869396 0.2713061 ]\n",
      "Sensor: [0.3067173861202412, 0.6604988332639515, 0.29290934040365335, 0.2843621032084481], Action prob: [0.70794594 0.29205406], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.70794594 0.29205406]\n",
      "Sensor: [0.41375144514122386, 0.6645114683390118, 0.23211950313649596, 0.2831209450109133], Action prob: [0.71856093 0.28143907], Action: 0, state: 0\n",
      "[0.71856093 0.28143907]\n",
      "Sensor: [0.5632457587889471, 0.6384325639665934, 0.20635916450904757, 0.23489463162999866], Action prob: [0.7214871  0.27851287], Action: 0, state: 0\n",
      "[0.7214871  0.27851287]\n",
      "Sensor: [0.34085033854447094, 0.6503210757700753, 0.1955354082318819, 0.2663355784229557], Action prob: [0.7241848  0.27581513], Action: 0, state: 1\n",
      "[0.7241848  0.27581513]\n",
      "Sensor: [0.4097396041204434, 0.6245656976318001, 0.2209054885507588, 0.2732685312226521], Action prob: [0.72455794 0.27544206], Action: 0, state: 1\n",
      "[0.72455794 0.27544206]\n",
      "Sensor: [0.34101114800957705, 0.6659447386587405, 0.22793433931179952, 0.26419176845044917], Action prob: [0.72526634 0.2747337 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -3000\n",
      "[0.72526634 0.2747337 ]\n",
      "Sensor: [0.34771817362008756, 0.6325408963479858, 0.2666258361851935, 0.2876248599726373], Action prob: [0.72532433 0.27467564], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.72532433 0.27467564]\n",
      "Sensor: [0.34172972115267747, 0.6845082913009853, 0.24609061683060057, 0.25375452563028555], Action prob: [0.7255757  0.27442434], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.9941, -0.3862, -0.1096,  0.1296,  0.3317,  2.0783, -0.1122,  0.0517],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1544 is 46700, loss is 0.0013630697305929782\n",
      "[0.7255757  0.27442434]\n",
      "Sensor: [0.37815743097013876, 0.7131603031498125, 0.2900274647757607, 0.25915022489094625], Action prob: [0.70632493 0.29367507], Action: 0, state: 0\n",
      "[0.70632493 0.29367507]\n",
      "Sensor: [0.3682693237293324, 0.6011237576467424, 0.18936964514611979, 0.2343070590691599], Action prob: [0.71663475 0.28336528], Action: 0, state: 0\n",
      "[0.71663475 0.28336528]\n",
      "Sensor: [0.36802304014367015, 0.6445497272570425, 0.26209636560712757, 0.2543566127595807], Action prob: [0.72129804 0.27870193], Action: 0, state: 0\n",
      "[0.72129804 0.27870193]\n",
      "Sensor: [0.4137943986464484, 0.6693414517461058, 0.21683564161236069, 0.2393986562106249], Action prob: [0.7230342 0.2769658], Action: 0, state: 1\n",
      "[0.7230342 0.2769658]\n",
      "Sensor: [0.404044595582493, 0.6366120064829252, 0.24047995590702886, 0.31900394296962886], Action prob: [0.7238613  0.27613872], Action: 0, state: 1\n",
      "[0.7238613  0.27613872]\n",
      "Sensor: [0.3369412118544908, 0.6819190678521687, 0.21017370814465655, 0.3009920801751887], Action prob: [0.7248127  0.27518728], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7248127  0.27518728]\n",
      "Sensor: [0.3357123104308843, 0.6570420507622414, 0.23157311540028477, 0.28720193301619834], Action prob: [0.7249317  0.27506828], Action: 0, state: 0\n",
      "[0.7249317  0.27506828]\n",
      "Sensor: [0.34600840003827876, 0.6242025861308395, 0.21640079742003862, 0.2835640544772919], Action prob: [0.724632   0.27536795], Action: 0, state: 1\n",
      "tensor([-0.6110, -0.3739, -0.1676, -0.0170,  0.1277,  1.0123,  0.3159,  0.4159],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1552 is 53700, loss is -0.08778782516141392\n",
      "[0.724632   0.27536795]\n",
      "Sensor: [0.3592586309733458, 0.6131513023187165, 0.2030839308018537, 0.2789147339505192], Action prob: [0.7073418  0.29265818], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.7073418  0.29265818]\n",
      "Sensor: [0.3521169448583901, 0.6297096464989872, 0.2593821772007794, 0.2755717657265673], Action prob: [0.7188393 0.2811607], Action: 0, state: 0\n",
      "[0.7188393 0.2811607]\n",
      "Sensor: [0.3513340612574355, 0.6453244220245303, 0.22234765113863345, 0.248176325248595], Action prob: [0.7237973  0.27620268], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.7237973  0.27620268]\n",
      "Sensor: [0.3947966243722809, 0.6166422679799367, 0.20137680576302974, 0.23830323294389177], Action prob: [0.72530526 0.2746947 ], Action: 0, state: 0\n",
      "[0.72530526 0.2746947 ]\n",
      "Sensor: [0.3696792920604891, 0.6216324891024015, 0.24631205644033227, 0.2352215152639286], Action prob: [0.72592765 0.27407238], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.72592765 0.27407238]\n",
      "Sensor: [0.3424727478170784, 0.6238470505701026, 0.2353481400653283, 0.22265359995314865], Action prob: [0.72624767 0.27375233], Action: 0, state: 0\n",
      "[0.72624767 0.27375233]\n",
      "Sensor: [0.34632872978892404, 0.6488013895967449, 0.22178139358766438, 0.23333326949215272], Action prob: [0.7265718 0.2734282], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7265718 0.2734282]\n",
      "Sensor: [0.3619994388030895, 0.6140182130742085, 0.18228620277334276, 0.27295402918896794], Action prob: [0.72657806 0.27342197], Action: 0, state: 0\n",
      "tensor([-1.6461, -0.4381, -0.5690, -0.1458,  0.3685,  0.1956,  1.5520,  0.4649],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1560 is 58600, loss is 0.027238063636731966\n",
      "[0.72657806 0.27342197]\n",
      "Sensor: [0.3701536631497663, 0.6677207516603929, 0.23143289787014773, 0.3028762766342167], Action prob: [0.70894665 0.29105338], Action: 0, state: 1\n",
      "[0.70894665 0.29105338]\n",
      "Sensor: [0.3918671963097107, 0.6483153469542496, 0.21090414222737974, 0.2556626241079963], Action prob: [0.72070795 0.2792921 ], Action: 0, state: 2\n",
      "[0.72070795 0.2792921 ]\n",
      "Sensor: [0.367750934324267, 0.6834906810398999, 0.19593950481357172, 0.23563040840449037], Action prob: [0.7263698 0.2736302], Action: 0, state: 2\n",
      "[0.7263698 0.2736302]\n",
      "Sensor: [0.431914463968117, 0.6979934645141058, 0.1916710622464317, 0.28225084222738583], Action prob: [0.72870004 0.27129996], Action: 0, state: 2\n",
      "[0.72870004 0.27129996]\n",
      "Sensor: [0.3264339840046598, 0.6900343790383575, 0.2528223374489373, 0.2183566098850322], Action prob: [0.7298859  0.27011415], Action: 0, state: 3\n",
      "[0.7298859  0.27011415]\n",
      "Sensor: [0.3506277214935824, 0.6212230537919731, 0.2070329646612918, 0.2044926579366516], Action prob: [0.7296184  0.27038157], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.7296184  0.27038157]\n",
      "Sensor: [0.3847005358052888, 0.638914550058519, 0.1945499855160759, 0.29964327653722234], Action prob: [0.72964406 0.27035594], Action: 0, state: 2\n",
      "[0.72964406 0.27035594]\n",
      "Sensor: [0.40443224165231084, 0.6478523419246367, 0.22139472987473482, 0.21483943297149238], Action prob: [0.7292288  0.27077124], Action: 0, state: 3\n",
      "tensor([-0.6385, -0.3716, -0.1522,  0.0359,  0.1480,  0.9899,  0.2907,  0.3661],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1568 is 63300, loss is -0.08353476058551537\n",
      "[0.7292288  0.27077124]\n",
      "Sensor: [0.3994464058834325, 0.6674071255760404, 0.20670156582670848, 0.25372946532080837], Action prob: [0.7120403  0.28795967], Action: 0, state: 3\n",
      "[0.7120403  0.28795967]\n",
      "Sensor: [0.3263148668383629, 0.625640885398818, 0.2438402756613179, 0.20947873745999393], Action prob: [0.7250996  0.27490038], Action: 0, state: 3\n",
      "[0.7250996  0.27490038]\n",
      "Sensor: [0.3383959275292176, 0.604009768075136, 0.23158188257650628, 0.18244979534684558], Action prob: [0.7306829  0.26931706], Action: 0, state: 3\n",
      "[0.7306829  0.26931706]\n",
      "Sensor: [0.3137908098504289, 0.6325684654874388, 0.2421933982613582, 0.25210402276811483], Action prob: [0.7337253  0.26627466], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "[0.7337253  0.26627466]\n",
      "Sensor: [0.38175946743444367, 0.6296213559579397, 0.22784857640136522, 0.26596042961394345], Action prob: [0.73449594 0.2655041 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "[0.73449594 0.2655041 ]\n",
      "Sensor: [0.43692517518036644, 0.6012323623260288, 0.2739345847655401, 0.2179541037325114], Action prob: [0.7339179 0.2660821], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7339179 0.2660821]\n",
      "Sensor: [0.33731916060728284, 0.6271465653402222, 0.18557410571913102, 0.29025404460192616], Action prob: [0.7348728  0.26512712], Action: 0, state: 0\n",
      "[0.7348728  0.26512712]\n",
      "Sensor: [0.37350559560858715, 0.6672309921903048, 0.18988611513439643, 0.27502687390902025], Action prob: [0.73529094 0.264709  ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-6.7037e-01, -2.9648e-01,  1.2125e-03,  1.1347e+00,  7.2059e-01,\n",
      "        -3.6597e-01,  1.0454e-01,  1.9075e+00], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1576 is 66000, loss is -0.31697555262739596\n",
      "[0.73529094 0.264709  ]\n",
      "Sensor: [0.37295529251534987, 0.6398759757250104, 0.22089576915559964, 0.2791159636977814], Action prob: [0.7242523 0.2757477], Action: 0, state: 0\n",
      "[0.7242523 0.2757477]\n",
      "Sensor: [0.3588660859156368, 0.6481072444845325, 0.20881184789060264, 0.2942881958120828], Action prob: [0.74108225 0.25891772], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.74108225 0.25891772]\n",
      "Sensor: [0.3275745745850001, 0.6849806817860087, 0.2238739104451808, 0.18180366521804406], Action prob: [0.74877906 0.25122094], Action: 0, state: 0\n",
      "[0.74877906 0.25122094]\n",
      "Sensor: [0.36073210968559805, 0.6141809164732086, 0.24139634815520042, 0.27799512572161855], Action prob: [0.7519125  0.24808753], Action: 0, state: 0\n",
      "[0.7519125  0.24808753]\n",
      "Sensor: [0.30739289962533756, 0.6532110220615853, 0.22965773936731235, 0.21142692837596805], Action prob: [0.75327635 0.24672365], Action: 0, state: 0\n",
      "[0.75327635 0.24672365]\n",
      "Sensor: [0.348133789203196, 0.7037720085738218, 0.2173317197018111, 0.2655753104726703], Action prob: [0.7542371  0.24576288], Action: 0, state: 0\n",
      "[0.7542371  0.24576288]\n",
      "Sensor: [0.36655452310485054, 0.6603087670571481, 0.2473491015757273, 0.2840049310656165], Action prob: [0.7543601  0.24563992], Action: 0, state: 1\n",
      "[0.7543601  0.24563992]\n",
      "Sensor: [0.3706521173286957, 0.623498325087405, 0.18778370366182404, 0.25402823201009184], Action prob: [0.7538704  0.24612957], Action: 0, state: 2\n",
      "tensor([-0.5216, -1.3711, -0.2081, -0.0479,  0.0896,  0.2119,  0.3136,  0.3898],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1584 is 72900, loss is 0.14295361399848136\n",
      "[0.7538704  0.24612957]\n",
      "Sensor: [0.3463997934400288, 0.5823424743741477, 0.19363104845161352, 0.4198036559720146], Action prob: [0.73196167 0.26803833], Action: 0, state: 2\n",
      "[0.73196167 0.26803833]\n",
      "Sensor: [0.27293480875941933, 0.33110022936717154, 0.19217816092264173, 0.22502034110052996], Action prob: [0.746557 0.253443], Action: 0, state: 3\n",
      "[0.746557 0.253443]\n",
      "Sensor: [0.5995557414935816, 0.644050209215021, 0.20910998567605008, 0.25290142189022324], Action prob: [0.7543275  0.24567254], Action: 0, state: 3\n",
      "[0.7543275  0.24567254]\n",
      "Sensor: [0.3464289044283912, 0.6422798921104433, 0.2012127146870308, 0.4837545404426966], Action prob: [0.7611377  0.23886226], Action: 0, state: 8\n",
      "[0.7611377  0.23886226]\n",
      "Sensor: [0.5781672793036167, 0.7238000262008223, 0.2345096813948902, 0.21767470834401423], Action prob: [0.76175725 0.23824278], Action: 0, state: 8\n",
      "[0.76175725 0.23824278]\n",
      "Sensor: [0.6288818579062833, 0.6399116030659054, 0.2617328420276103, 0.28129854820155176], Action prob: [0.7613952  0.23860477], Action: 0, state: 8\n",
      "[0.7613952  0.23860477]\n",
      "Sensor: [0.3017988670513941, 0.34264752158744843, 0.1789322564825905, 0.2609180614286807], Action prob: [0.7606174  0.23938264], Action: 1, state: 8\n",
      "[0.7606174  0.23938264]\n",
      "Sensor: [0.28972643284859345, 0.6682006865066161, 0.4885413753000953, 0.21308327897698665], Action prob: [0.7622572  0.23774275], Action: 1, state: 8\n",
      "tensor([ 0.2877,  0.3080,  0.3202,  0.1407, -0.0424, -0.1913, -1.6698, -2.2312],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1592 is 55900, loss is 0.3847477089960162\n",
      "[0.7622572  0.23774275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.5828438115802423, 0.6174869530199079, 0.25783144812814723, 0.2329867609846727], Action prob: [0.7248048  0.27519524], Action: 0, state: 8\n",
      "[0.7248048  0.27519524]\n",
      "Sensor: [0.35742588742660303, 0.40711307532426516, 0.2214507833022775, 0.27562423490581106], Action prob: [0.7395628  0.26043725], Action: 0, state: 8\n",
      "[0.7395628  0.26043725]\n",
      "Sensor: [0.5571113166592344, 0.6381185210462582, 0.26401933285074003, 0.27384005862442995], Action prob: [0.7466664 0.2533336], Action: 0, state: 8\n",
      "[0.7466664 0.2533336]\n",
      "Sensor: [0.35245981550683314, 0.363025584573432, 0.21775294803307396, 0.2214775477122716], Action prob: [0.74828225 0.2517177 ], Action: 0, state: 8\n",
      "[0.74828225 0.2517177 ]\n",
      "Sensor: [0.5659140690329165, 0.4041269013463531, 0.21949109969873035, 0.2854684784753457], Action prob: [0.74758834 0.25241163], Action: 1, state: 8\n",
      "[0.74758834 0.25241163]\n",
      "Sensor: [0.40883568529368397, 0.6292394914576976, 0.23722405451183598, 0.32499902888565496], Action prob: [0.75032735 0.24967267], Action: 0, state: 0\n",
      "[0.75032735 0.24967267]\n",
      "Sensor: [0.3489410082996915, 0.6113748450791197, 0.17896585496003586, 0.21690007801321773], Action prob: [0.7514106  0.24858938], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "[0.7514106  0.24858938]\n",
      "Sensor: [0.41129160472833887, 0.5654373256533813, 0.15860359074360345, 0.23592332843777364], Action prob: [0.75107473 0.24892527], Action: 0, state: 0\n",
      "tensor([ 0.6315,  0.3438,  0.1016, -0.0950, -1.3420, -0.2180, -0.8451, -0.2419],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1600 is 45300, loss is 0.20814831432314657\n",
      "[0.75107473 0.24892527]\n",
      "Sensor: [0.34705121932508204, 0.5822808247407696, 0.19664734203664974, 0.22787119355509622], Action prob: [0.7169894  0.28301057], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.7169894  0.28301057]\n",
      "Sensor: [0.37117654964061786, 0.6754091630915084, 0.20845426247627094, 0.3220434635293761], Action prob: [0.7304358  0.26956418], Action: 0, state: 0\n",
      "[0.7304358  0.26956418]\n",
      "Sensor: [0.3418038109184307, 0.6481726786594675, 0.2451185708941008, 0.25840068318146336], Action prob: [0.7352326  0.26476744], Action: 0, state: 1\n",
      "[0.7352326  0.26476744]\n",
      "Sensor: [0.35320489935485777, 0.3742938587218123, 0.20202797881158674, 0.2303737759982007], Action prob: [0.7344598  0.26554015], Action: 0, state: 2\n",
      "[0.7344598  0.26554015]\n",
      "Sensor: [0.348986560347795, 0.6139632835151267, 0.1462150855478061, 0.2537957566248857], Action prob: [0.7353338 0.2646662], Action: 0, state: 2\n",
      "[0.7353338 0.2646662]\n",
      "Sensor: [0.40000086955012487, 0.6116554350175558, 0.5403071161277953, 0.2717751951174118], Action prob: [0.7350195 0.2649805], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.7350195 0.2649805]\n",
      "Sensor: [0.35703290222690276, 0.6415911004020337, 0.24255801242673652, 0.22568928870162838], Action prob: [0.7356398  0.26436022], Action: 0, state: 1\n",
      "[0.7356398  0.26436022]\n",
      "Sensor: [0.3488364366184888, 0.5183080566579097, 0.23563354246911658, 0.29513650067141023], Action prob: [0.7354362  0.26456383], Action: 0, state: 2\n",
      "tensor([-1.7405, -0.4303, -0.2069, -0.0405,  0.1088,  1.1795,  0.3135,  0.4278],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1608 is 50300, loss is 0.048574999159270445\n",
      "[0.7354362  0.26456383]\n",
      "Sensor: [0.41997593218235296, 0.6467488155617499, 0.22221632801866184, 0.2667609672921566], Action prob: [0.7082981  0.29170188], Action: 0, state: 3\n",
      "[0.7082981  0.29170188]\n",
      "Sensor: [0.3215961127746698, 0.5955961389869701, 0.22586685957760566, 0.5704566965873362], Action prob: [0.72005737 0.27994257], Action: 0, state: 8\n",
      "[0.72005737 0.27994257]\n",
      "Sensor: [0.30824646763981123, 0.6644846857016701, 0.486671085768699, 0.2671157942887554], Action prob: [0.7226299 0.2773701], Action: 0, state: 8\n",
      "[0.7226299 0.2773701]\n",
      "Sensor: [0.36570164514795395, 0.5998897203368814, 0.5364145808867827, 0.26902397037777437], Action prob: [0.7220341  0.27796596], Action: 0, state: 8\n",
      "[0.7220341  0.27796596]\n",
      "Sensor: [0.3969469165897585, 0.35203207183602875, 0.25993144998620143, 0.24691630240669435], Action prob: [0.71988004 0.28011996], Action: 0, state: 8\n",
      "[0.71988004 0.28011996]\n",
      "Sensor: [0.41940367379220767, 0.372327058114955, 0.23306447460490679, 0.25331973721169593], Action prob: [0.7186247 0.2813753], Action: 0, state: 8\n",
      "[0.7186247 0.2813753]\n",
      "Sensor: [0.4089929555617079, 0.3463978983574523, 0.23831635076972882, 0.6083299510412505], Action prob: [0.7192564  0.28074363], Action: 0, state: 8\n",
      "[0.7192564  0.28074363]\n",
      "Sensor: [0.7246600793511039, 0.6217747929272577, 0.27878827281795115, 0.1957387937129407], Action prob: [0.7176876  0.28231242], Action: 1, state: 8\n",
      "tensor([ 0.5800,  0.3763,  0.2104,  0.0576, -0.1050, -0.2354, -0.3353, -1.7884],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1616 is 26300, loss is 0.1549909851584645\n",
      "[0.7176876  0.28231242]\n",
      "Sensor: [0.35536274992770567, 0.5602504101768038, 0.19136319416987957, 0.5475960421372643], Action prob: [0.6979835 0.3020165], Action: 1, state: 8\n",
      "[0.6979835 0.3020165]\n",
      "Sensor: [0.5845149107431353, 0.6629729424369735, 0.20346832815064372, 0.24673558070786883], Action prob: [0.7027138 0.2972862], Action: 1, state: 8\n",
      "[0.7027138 0.2972862]\n",
      "Sensor: [0.3295878930507139, 0.6991082268097517, 0.5031037058413911, 0.23971474995994543], Action prob: [0.7048073  0.29519266], Action: 1, state: 8\n",
      "[0.7048073  0.29519266]\n",
      "Sensor: [0.37104510351539216, 0.6401121640545, 0.5414018087745295, 0.25390606022130696], Action prob: [0.70439357 0.29560643], Action: 0, state: 8\n",
      "[0.70439357 0.29560643]\n",
      "Sensor: [0.39605479434023494, 0.4024055626797562, 0.1755498834030139, 0.24144358096127358], Action prob: [0.70310974 0.29689032], Action: 1, state: 8\n",
      "[0.70310974 0.29689032]\n",
      "Sensor: [0.34974673505594583, 0.6936268382849831, 0.2209268262272947, 0.2645452713830765], Action prob: [0.7039808  0.29601914], Action: 0, state: 0\n",
      "[0.7039808  0.29601914]\n",
      "Sensor: [0.3192249606156065, 0.6249556710318048, 0.2115907091402629, 0.2327489094925356], Action prob: [0.704281  0.2957191], Action: 0, state: 0\n",
      "[0.704281  0.2957191]\n",
      "Sensor: [0.32076472843994386, 0.6854916711333588, 0.21728705758697825, 0.22611430413436398], Action prob: [0.70457226 0.29542768], Action: 0, state: 0\n",
      "tensor([ 2.4218,  1.3047,  0.4726, -0.1132, -1.2789, -0.2963, -0.2352, -0.1802],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1624 is 18200, loss is -0.26191415097995385\n",
      "[0.70457226 0.29542768]\n",
      "Sensor: [0.3508201438608124, 0.6759480052911097, 0.229577885723428, 0.22737587379378094], Action prob: [0.69287807 0.30712193], Action: 0, state: 1\n",
      "[0.69287807 0.30712193]\n",
      "Sensor: [0.3500678818099807, 0.48041757574902877, 0.1914569959807894, 0.21824039690248576], Action prob: [0.6976528  0.30234724], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.6976528  0.30234724]\n",
      "Sensor: [0.34598236544994787, 0.6442067135923158, 0.18504900542916491, 0.25040428532971964], Action prob: [0.6991103  0.30088967], Action: 0, state: 1\n",
      "[0.6991103  0.30088967]\n",
      "Sensor: [0.3879193886025122, 0.6796039574968189, 0.20888666742974724, 0.2818720369566542], Action prob: [0.69886947 0.3011305 ], Action: 0, state: 1\n",
      "[0.69886947 0.3011305 ]\n",
      "Sensor: [0.33194502826562866, 0.6351913004969257, 0.17492674377714212, 0.23249307504440048], Action prob: [0.69840455 0.30159545], Action: 0, state: 1\n",
      "[0.69840455 0.30159545]\n",
      "Sensor: [0.3950598493151149, 0.6685084997811771, 0.24173335952120795, 0.3053895866245916], Action prob: [0.69770515 0.30229488], Action: 0, state: 1\n",
      "[0.69770515 0.30229488]\n",
      "Sensor: [0.39326841395277906, 0.6563088546196337, 0.22405214128629078, 0.2849950471379061], Action prob: [0.69728255 0.30271748], Action: 0, state: 1\n",
      "[0.69728255 0.30271748]\n",
      "Sensor: [0.37369984501497133, 0.7164026430011516, 0.20782931687085351, 0.28458924239265776], Action prob: [0.697547   0.30245295], Action: 0, state: 1\n",
      "tensor([-0.5879, -1.2236, -0.2717, -0.0798,  0.0911,  0.2519,  0.3906,  0.5159],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1632 is 24800, loss is 0.1142028798450261\n",
      "[0.697547   0.30245295]\n",
      "Sensor: [0.35048727395196005, 0.6714129771657641, 0.19494772706888297, 0.2646127075535485], Action prob: [0.6871811 0.3128189], Action: 0, state: 1\n",
      "[0.6871811 0.3128189]\n",
      "Sensor: [0.4087497857541421, 0.6266123494431444, 0.21243229538405936, 0.2670469104117422], Action prob: [0.69036555 0.30963442], Action: 0, state: 1\n",
      "[0.69036555 0.30963442]\n",
      "Sensor: [0.4069363636387164, 0.6209396066137163, 0.24173509724514602, 0.2565704090056734], Action prob: [0.6897929 0.3102072], Action: 0, state: 1\n",
      "[0.6897929 0.3102072]\n",
      "Sensor: [0.3540448012128189, 0.660487011080137, 0.22415502916850416, 0.25723847232706226], Action prob: [0.68915045 0.31084955], Action: 0, state: 1\n",
      "[0.68915045 0.31084955]\n",
      "Sensor: [0.330021067118997, 0.6427104313147362, 0.1764158695513348, 0.17005558946430355], Action prob: [0.6884204  0.31157959], Action: 0, state: 1\n",
      "[0.6884204  0.31157959]\n",
      "Sensor: [0.403062228371402, 0.6729707738146481, 0.2527483273786395, 0.28292896616256474], Action prob: [0.6875631  0.31243685], Action: 0, state: 1\n",
      "[0.6875631  0.31243685]\n",
      "Sensor: [0.44099502414925457, 0.6365758807309093, 0.19467923968810255, 0.2865505985615509], Action prob: [0.68684095 0.3131591 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.68684095 0.3131591 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3910754424239109, 0.611461525580338, 0.18877370263797244, 0.2136617148789238], Action prob: [0.686579   0.31342098], Action: 0, state: 1\n",
      "tensor([-0.6557, -0.4230, -0.2180, -0.0335,  0.1266,  0.2834,  1.2292,  0.4520],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1640 is 31400, loss is -0.09512743990563227\n",
      "[0.686579   0.31342098]\n",
      "Sensor: [0.3228386592081656, 0.6388085988392092, 0.22101391534609904, 0.24907573767328908], Action prob: [0.6843871 0.3156129], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6843871 0.3156129]\n",
      "Sensor: [0.3750811008813502, 0.6235839622603014, 0.1961944762061148, 0.26383629609209636], Action prob: [0.6866601  0.31333986], Action: 0, state: 0\n",
      "[0.6866601  0.31333986]\n",
      "Sensor: [0.3403151277576863, 0.6017564578549398, 0.20617357465517602, 0.29325629720984725], Action prob: [0.6858371  0.31416285], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "[0.6858371  0.31416285]\n",
      "Sensor: [0.32276087784285845, 0.6330122276376149, 0.21304385111836946, 0.39471829681333176], Action prob: [0.6848244 0.3151756], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.6848244 0.3151756]\n",
      "Sensor: [0.3341736558275995, 0.6399362975688269, 0.21049497916912863, 0.23066595757698252], Action prob: [0.6834308 0.3165692], Action: 0, state: 0\n",
      "[0.6834308 0.3165692]\n",
      "Sensor: [0.3491429803519301, 0.6479501179209762, 0.1988070081270088, 0.2556297879954007], Action prob: [0.68258744 0.3174125 ], Action: 0, state: 1\n",
      "[0.68258744 0.3174125 ]\n",
      "Sensor: [0.3922630169837036, 0.6212680447956801, 0.23331714735660214, 0.19101166345873494], Action prob: [0.68156976 0.31843024], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1600\n",
      "[0.68156976 0.31843024]\n",
      "Sensor: [0.372192863937035, 0.6890058873741687, 0.181488605071321, 0.24006293998840006], Action prob: [0.68174386 0.31825617], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.3023, -0.0253,  1.9476, -1.0544, -0.3544,  0.1276,  1.5383, -0.5568],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1648 is 31900, loss is -0.04004361234675917\n",
      "[0.68174386 0.31825617]\n",
      "Sensor: [0.3796253947983551, 0.6170739993291479, 0.1836378316382774, 0.3013022767056894], Action prob: [0.68319297 0.316807  ], Action: 0, state: 0\n",
      "[0.68319297 0.316807  ]\n",
      "Sensor: [0.36457443371557496, 0.5972257980977577, 0.22016554345433714, 0.21447338838674723], Action prob: [0.6849452 0.3150547], Action: 0, state: 0\n",
      "[0.6849452 0.3150547]\n",
      "Sensor: [0.3818459434452093, 0.6154438204903987, 0.2593841965797168, 0.22858816689076367], Action prob: [0.68373924 0.3162608 ], Action: 0, state: 1\n",
      "[0.68373924 0.3162608 ]\n",
      "Sensor: [0.38720220611766554, 0.7044100599191516, 0.22133703898965976, 0.26695743932978777], Action prob: [0.68263686 0.31736317], Action: 0, state: 1\n",
      "[0.68263686 0.31736317]\n",
      "Sensor: [0.3060116209742168, 0.6380853947158048, 0.24906563367553264, 0.2752534121902717], Action prob: [0.6818641 0.318136 ], Action: 0, state: 1\n",
      "[0.6818641 0.318136 ]\n",
      "Sensor: [0.40639575776570336, 0.7015121832535351, 0.2450257237438784, 0.2336798210003976], Action prob: [0.6808021  0.31919792], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6808021  0.31919792]\n",
      "Sensor: [0.37830519889876135, 0.6377435267479589, 0.23717270857148418, 0.27636438455122125], Action prob: [0.68026805 0.31973195], Action: 0, state: 0\n",
      "[0.68026805 0.31973195]\n",
      "Sensor: [0.3521224174513413, 0.6103001243060248, 0.17717133202441515, 0.4839610068861749], Action prob: [0.6805682  0.31943175], Action: 0, state: 0\n",
      "tensor([-0.6773, -0.4191, -0.2126, -0.0303,  0.1447,  0.8592,  0.3685,  0.5085],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1656 is 38900, loss is -0.06770359585978253\n",
      "[0.6805682  0.31943175]\n",
      "Sensor: [0.3526506475439208, 0.7107453992015998, 0.25133043680021416, 0.27989228777627534], Action prob: [0.68421024 0.3157897 ], Action: 0, state: 1\n",
      "[0.68421024 0.3157897 ]\n",
      "Sensor: [0.3760889036204039, 0.5673197168873363, 0.18164646302996296, 0.20777397076492177], Action prob: [0.6855453  0.31445467], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "[0.6855453  0.31445467]\n",
      "Sensor: [0.3957899475640808, 0.633276182170447, 0.2150336229273129, 0.29372611905376983], Action prob: [0.6844437 0.3155563], Action: 0, state: 1\n",
      "[0.6844437 0.3155563]\n",
      "Sensor: [0.3594847019524852, 0.6196791523495452, 0.19661317109938084, 0.24037002925411777], Action prob: [0.6829609  0.31703913], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6829609  0.31703913]\n",
      "Sensor: [0.33949846008480067, 0.6450333408875488, 0.2280435232955907, 0.26135060820573935], Action prob: [0.6819522  0.31804782], Action: 0, state: 0\n",
      "[0.6819522  0.31804782]\n",
      "Sensor: [0.40023074124209235, 0.6346157609429601, 0.22029418222918265, 0.26120472226490377], Action prob: [0.68087804 0.319122  ], Action: 0, state: 0\n",
      "[0.68087804 0.319122  ]\n",
      "Sensor: [0.38399397336257074, 0.6391288941575902, 0.2353280287711999, 0.36066643992278313], Action prob: [0.680577 0.319423], Action: 0, state: 0\n",
      "[0.680577 0.319423]\n",
      "Sensor: [0.3621074843522241, 0.6443928259946113, 0.2406975540330393, 0.23353038818044353], Action prob: [0.68030846 0.31969154], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.5108, -0.6906, -0.4198, -0.4680, -0.0171,  0.2222,  0.4471,  1.9014],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1664 is 44000, loss is -0.05803657353142566\n",
      "[0.68030846 0.31969154]\n",
      "Sensor: [0.33096799106862085, 0.6334305360827981, 0.19513317910455844, 0.3851307094087704], Action prob: [0.6865239  0.31347615], Action: 0, state: 0\n",
      "[0.6865239  0.31347615]\n",
      "Sensor: [0.3918119812022694, 0.6321491176474189, 0.23289378550486436, 0.5210418897752512], Action prob: [0.68874025 0.31125972], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.68874025 0.31125972]\n",
      "Sensor: [0.35115873796801456, 0.6289640248105522, 0.1994853877832459, 0.2442109283890147], Action prob: [0.68714017 0.3128598 ], Action: 0, state: 0\n",
      "[0.68714017 0.3128598 ]\n",
      "Sensor: [0.36330102326533126, 0.6501583125648187, 0.26426237509111455, 0.24523610220159295], Action prob: [0.6852286  0.31477147], Action: 0, state: 0\n",
      "[0.6852286  0.31477147]\n",
      "Sensor: [0.40513814469819004, 0.6566181149058823, 0.22343360899389608, 0.2631923878739516], Action prob: [0.683793 0.316207], Action: 0, state: 0\n",
      "[0.683793 0.316207]\n",
      "Sensor: [0.357276427744061, 0.6210573327189434, 0.1988595543334433, 0.2606274675721797], Action prob: [0.6832948  0.31670517], Action: 0, state: 1\n",
      "[0.6832948  0.31670517]\n",
      "Sensor: [0.33987133501794764, 0.6185146039262053, 0.42947838229149427, 0.28530508764916646], Action prob: [0.6824154 0.3175846], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.6824154 0.3175846]\n",
      "Sensor: [0.3616593069100091, 0.6227684856127537, 0.2268181012553586, 0.24878458875813403], Action prob: [0.6823972  0.31760284], Action: 0, state: 1\n",
      "tensor([-0.6478, -1.1624, -0.2626, -0.0411,  0.1516,  0.3133,  1.3942,  0.4305],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1672 is 50000, loss is -0.021962399561927713\n",
      "[0.6823972  0.31760284]\n",
      "Sensor: [0.35948447581383525, 0.6596338454092301, 0.1922687188521795, 0.34212700129987805], Action prob: [0.6884307  0.31156933], Action: 0, state: 1\n",
      "[0.6884307  0.31156933]\n",
      "Sensor: [0.3476924144692083, 0.6311556091467374, 0.2190385673031599, 0.2377403482713899], Action prob: [0.69050944 0.30949053], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.69050944 0.30949053]\n",
      "Sensor: [0.3641691704835486, 0.6595748975006286, 0.22960865831626698, 0.2758186888941239], Action prob: [0.68952954 0.31047052], Action: 0, state: 0\n",
      "[0.68952954 0.31047052]\n",
      "Sensor: [0.3670815790504468, 0.6761428566172785, 0.2136723015683655, 0.2702090537794168], Action prob: [0.6881113 0.3118887], Action: 0, state: 0\n",
      "[0.6881113 0.3118887]\n",
      "Sensor: [0.4073585496551112, 0.6844789188369851, 0.18816511440382003, 0.4155535503911701], Action prob: [0.6871499  0.31285018], Action: 0, state: 0\n",
      "[0.6871499  0.31285018]\n",
      "Sensor: [0.4228102195166124, 0.6458390105643033, 0.23291680905926496, 0.1739116262332898], Action prob: [0.6855987 0.3144014], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6855987 0.3144014]\n",
      "Sensor: [0.35753226409287076, 0.6783475870960551, 0.23588332211624988, 0.23374957577479788], Action prob: [0.6855603  0.31443974], Action: 0, state: 0\n",
      "[0.6855603  0.31443974]\n",
      "Sensor: [0.4018449507315662, 0.6362547854695302, 0.20444894857707605, 0.2291735246089042], Action prob: [0.6851736  0.31482646], Action: 0, state: 0\n",
      "tensor([-0.6204, -1.2057, -0.2631, -0.0528,  0.1403,  0.9007,  0.3778,  0.5153],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1680 is 56800, loss is 0.02599019324092869\n",
      "[0.6851736  0.31482646]\n",
      "Sensor: [0.3569250229227467, 0.6195075043674289, 0.19920685428374746, 0.23506207267294793], Action prob: [0.68914115 0.31085885], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68914115 0.31085885]\n",
      "Sensor: [0.40069954425394133, 0.6886013434702176, 0.22357660059822845, 0.24293834393857208], Action prob: [0.69148093 0.30851912], Action: 0, state: 0\n",
      "[0.69148093 0.30851912]\n",
      "Sensor: [0.2929463502965022, 0.626652872661695, 0.2097166248172379, 0.26894614048733606], Action prob: [0.69099927 0.30900076], Action: 0, state: 1\n",
      "[0.69099927 0.30900076]\n",
      "Sensor: [0.3996712755495509, 0.6306093259976688, 0.1829402373868199, 0.2717559257922286], Action prob: [0.6891078  0.31089222], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6891078  0.31089222]\n",
      "Sensor: [0.4207695869254353, 0.6047461560615268, 0.20329261170353297, 0.6002828400111356], Action prob: [0.6880884  0.31191155], Action: 0, state: 0\n",
      "[0.6880884  0.31191155]\n",
      "Sensor: [0.3867021213597458, 0.6388887574218924, 0.2237667696151664, 0.2853946628116499], Action prob: [0.6870844  0.31291556], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6870844  0.31291556]\n",
      "Sensor: [0.32155977130860264, 0.6409723723356473, 0.2069743141787052, 0.21122131733422086], Action prob: [0.68684834 0.31315163], Action: 0, state: 0\n",
      "[0.68684834 0.31315163]\n",
      "Sensor: [0.35835448260284647, 0.6596945100783896, 0.21605767668016343, 0.21134919449679385], Action prob: [0.6866536  0.31334642], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.6673, -0.3980, -0.1792,  0.0190,  0.1144,  0.8796,  0.3634,  1.5594],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1688 is 63100, loss is -0.21141137849212488\n",
      "[0.6866536  0.31334642]\n",
      "Sensor: [0.4303988325394448, 0.6220918506095026, 0.22367429689976404, 0.22665371335746176], Action prob: [0.69393224 0.3060678 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.69393224 0.3060678 ]\n",
      "Sensor: [0.3557920434501142, 0.6105654233134515, 0.2151790369874778, 0.28731457554437345], Action prob: [0.6972212  0.30277875], Action: 0, state: 0\n",
      "[0.6972212  0.30277875]\n",
      "Sensor: [0.3666114296379834, 0.580149861787226, 0.38943761578888036, 0.26394661881843107], Action prob: [0.69614244 0.30385762], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.69614244 0.30385762]\n",
      "Sensor: [0.3531926647846458, 0.6198946869158942, 0.17799580893973668, 0.2197391850800018], Action prob: [0.69510555 0.30489448], Action: 0, state: 0\n",
      "[0.69510555 0.30489448]\n",
      "Sensor: [0.39314260207023133, 0.6023801658479829, 0.21134010677957868, 0.26225826977583294], Action prob: [0.6940374 0.3059626], Action: 0, state: 0\n",
      "[0.6940374 0.3059626]\n",
      "Sensor: [0.3632218638784265, 0.6578388668635822, 0.2607752582537546, 0.20427881654708221], Action prob: [0.6936204  0.30637965], Action: 0, state: 1\n",
      "[0.6936204  0.30637965]\n",
      "Sensor: [0.34324411363475194, 0.6348321287261591, 0.22537096012801014, 0.2620734009216483], Action prob: [0.69356376 0.30643624], Action: 0, state: 1\n",
      "[0.69356376 0.30643624]\n",
      "Sensor: [0.40149093081178333, 0.6104461869715434, 0.21206236301578216, 0.2548257778930747], Action prob: [0.6930893 0.3069107], Action: 0, state: 2\n",
      "tensor([-1.5695, -0.4733, -0.6880, -0.1125,  0.0963,  0.2677,  0.4193,  0.5375],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1696 is 69000, loss is 0.19029990252205098\n",
      "[0.6930893 0.3069107]\n",
      "Sensor: [0.31135624421046515, 0.6421216243309739, 0.1998592935406627, 0.2681446874440997], Action prob: [0.69595766 0.3040423 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.69595766 0.3040423 ]\n",
      "Sensor: [0.346908339650019, 0.6349926214396401, 0.22238668052362695, 0.22480226395725222], Action prob: [0.6985983  0.30140167], Action: 0, state: 1\n",
      "[0.6985983  0.30140167]\n",
      "Sensor: [0.3428992883851517, 0.6516368182408283, 0.23065822691963814, 0.2943347941804293], Action prob: [0.6980227  0.30197734], Action: 0, state: 1\n",
      "[0.6980227  0.30197734]\n",
      "Sensor: [0.3352323454749722, 0.6122438955854925, 0.22568458448275144, 0.2377301771760432], Action prob: [0.6964227  0.30357724], Action: 0, state: 1\n",
      "[0.6964227  0.30357724]\n",
      "Sensor: [0.37375603964350923, 0.6399451900160662, 0.2255578430155461, 0.19574028109607416], Action prob: [0.6950354 0.3049646], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.6950354 0.3049646]\n",
      "Sensor: [0.39210419818701303, 0.6342563297879026, 0.20226137514960135, 0.18538696995876341], Action prob: [0.6941773 0.3058227], Action: 0, state: 1\n",
      "[0.6941773 0.3058227]\n",
      "Sensor: [0.3462025337355621, 0.6662576999920754, 0.2715773061358667, 0.22016544093063245], Action prob: [0.6942137 0.3057863], Action: 0, state: 1\n",
      "[0.6942137 0.3057863]\n",
      "Sensor: [0.35569284679703667, 0.6265010487572521, 0.23749787380307216, 0.24454371733942631], Action prob: [0.69407624 0.30592382], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.5483, -0.4979, -0.2508, -0.0314,  0.4703,  0.2224,  0.3943,  1.7503],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1704 is 74200, loss is -0.06362476419041355\n",
      "[0.69407624 0.30592382]\n",
      "Sensor: [0.397406498048795, 0.6485329391792015, 0.20775153313042646, 0.23570747312295173], Action prob: [0.6970901  0.30290988], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.6970901  0.30290988]\n",
      "Sensor: [0.3137445647104845, 0.6665835724752005, 0.21150055223249162, 0.24331531984987503], Action prob: [0.7008046 0.2991954], Action: 0, state: 0\n",
      "[0.7008046 0.2991954]\n",
      "Sensor: [0.4090517893288104, 0.6302621355958906, 0.2020838108746503, 0.2609610436798124], Action prob: [0.6998286  0.30017135], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -3000\n",
      "[0.6998286  0.30017135]\n",
      "Sensor: [0.28257710819648174, 0.6380483720724638, 0.1718788124477174, 0.28509881511833907], Action prob: [0.69922704 0.30077294], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.69922704 0.30077294]\n",
      "Sensor: [0.3589631415315247, 0.6543781016353315, 0.1932166752617191, 0.29476428439955427], Action prob: [0.69824094 0.301759  ], Action: 0, state: 0\n",
      "[0.69824094 0.301759  ]\n",
      "Sensor: [0.33647875743896555, 0.5918183622689067, 0.18220278914954663, 0.20423921807934675], Action prob: [0.69729406 0.30270594], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.69729406 0.30270594]\n",
      "Sensor: [0.35635129700006046, 0.5991246020006107, 0.2251064238628178, 0.20722721948357156], Action prob: [0.69673204 0.30326793], Action: 0, state: 0\n",
      "[0.69673204 0.30326793]\n",
      "Sensor: [0.34602363731316166, 0.6458319811910421, 0.23729614353233427, 0.22298924318166582], Action prob: [0.69680834 0.3031917 ], Action: 0, state: 0\n",
      "tensor([ 0.9275,  0.2804,  2.1474, -1.4748, -0.4429, -0.6012, -0.1796,  0.0609],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1712 is 75000, loss is -0.08971996761269727\n",
      "[0.69680834 0.3031917 ]\n",
      "Sensor: [0.3729075453653174, 0.634119447389285, 0.23635578183389302, 0.20893886862292904], Action prob: [0.7005417  0.29945832], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.7005417  0.29945832]\n",
      "Sensor: [0.3540238574939828, 0.6528745858403376, 0.2038887434899121, 0.2950352145239831], Action prob: [0.7046122 0.2953879], Action: 0, state: 0\n",
      "[0.7046122 0.2953879]\n",
      "Sensor: [0.35799439094783336, 0.6044628354191213, 0.1732330160728743, 0.2609801881356257], Action prob: [0.7041313  0.29586866], Action: 0, state: 0\n",
      "[0.7041313  0.29586866]\n",
      "Sensor: [0.347995475231919, 0.6370813830843871, 0.1972352076472247, 0.24390096226631994], Action prob: [0.70308435 0.2969157 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.70308435 0.2969157 ]\n",
      "Sensor: [0.3399336864997148, 0.6998771570681805, 0.26023491555938566, 0.31448640857348775], Action prob: [0.70265657 0.29734343], Action: 0, state: 0\n",
      "[0.70265657 0.29734343]\n",
      "Sensor: [0.35217207752707164, 0.6868110355258985, 0.20934230421107558, 0.3043339988601401], Action prob: [0.7021702  0.29782987], Action: 0, state: 0\n",
      "[0.7021702  0.29782987]\n",
      "Sensor: [0.3871249324692778, 0.42206445928880776, 0.24152136349239264, 0.256544544253563], Action prob: [0.700308 0.299692], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.700308 0.299692]\n",
      "Sensor: [0.42313149023270286, 0.6511315259286546, 0.18884477353694162, 0.26996450796751315], Action prob: [0.7004789  0.29952112], Action: 0, state: 0\n",
      "tensor([-8.5758e-01, -5.9084e-01, -2.8593e-01, -2.2088e-02,  1.2928e-04,\n",
      "         2.2261e-01,  1.4595e+00,  5.1685e-01], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1720 is 79500, loss is -0.055331051878284174\n",
      "[0.7004789  0.29952112]\n",
      "Sensor: [0.415610740527985, 0.7003880044891415, 0.13753304718832682, 0.3465893960307387], Action prob: [0.70564353 0.29435644], Action: 0, state: 0\n",
      "[0.70564353 0.29435644]\n",
      "Sensor: [0.33193764602972364, 0.6540963916229293, 0.2053164760219538, 0.2189562290011878], Action prob: [0.7099817  0.29001838], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7099817  0.29001838]\n",
      "Sensor: [0.4068481732699838, 0.6638624931795757, 0.2146328892327018, 0.2957094485252772], Action prob: [0.7097734  0.29022655], Action: 0, state: 0\n",
      "[0.7097734  0.29022655]\n",
      "Sensor: [0.32913097398746705, 0.667791859094122, 0.23042756665337805, 0.44493214268856873], Action prob: [0.7095158 0.2904842], Action: 0, state: 0\n",
      "[0.7095158 0.2904842]\n",
      "Sensor: [0.4103600874089167, 0.6605736340554703, 0.19985368345685045, 0.2852357237448841], Action prob: [0.7080035  0.29199645], Action: 0, state: 0\n",
      "[0.7080035  0.29199645]\n",
      "Sensor: [0.3259518590643452, 0.6011589229813354, 0.20370323221205267, 0.20484792338539415], Action prob: [0.7070837  0.29291627], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -4500\n",
      "Maintenance in progress, cumulative -5000\n",
      "Maintenance in progress, cumulative -5500\n",
      "Maintenance in progress, cumulative -6000\n",
      "Maintenance in progress, cumulative -5000\n",
      "[0.7070837  0.29291627]\n",
      "Sensor: [0.3857739489064075, 0.6315945245159182, 0.20233670474973572, 0.4293095323540387], Action prob: [0.70710313 0.29289687], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.70710313 0.29289687]\n",
      "Sensor: [0.3330807034252124, 0.6473223467848437, 0.18475793876294958, 0.23371195239265588], Action prob: [0.70704573 0.2929542 ], Action: 0, state: 0\n",
      "tensor([-0.4746, -0.6160, -0.0407,  0.2037,  0.4080,  2.1425, -0.9197, -0.2638],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1728 is 79900, loss is -0.05492740948109251\n",
      "[0.70704573 0.2929542 ]\n",
      "Sensor: [0.3364348533341399, 0.6118827729852393, 0.18953891541594978, 0.20615056056486067], Action prob: [0.7098684 0.2901317], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7098684 0.2901317]\n",
      "Sensor: [0.3086347624982876, 0.589429797262949, 0.2249337535711934, 0.240497986617824], Action prob: [0.7152287  0.28477138], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.7152287  0.28477138]\n",
      "Sensor: [0.3386558900539484, 0.6181924461040491, 0.23426605758023322, 0.22025418068168007], Action prob: [0.71562576 0.28437427], Action: 0, state: 0\n",
      "[0.71562576 0.28437427]\n",
      "Sensor: [0.3476742840364583, 0.6919654590979983, 0.1638461855565149, 0.256973472747023], Action prob: [0.7153297  0.28467026], Action: 0, state: 0\n",
      "[0.7153297  0.28467026]\n",
      "Sensor: [0.3477002915608543, 0.6903247669821888, 0.19384450644180864, 0.24305796733485013], Action prob: [0.7147463 0.2852537], Action: 0, state: 1\n",
      "[0.7147463 0.2852537]\n",
      "Sensor: [0.35850874705628033, 0.6180748758844781, 0.19115626193953264, 0.27402320434894056], Action prob: [0.7139416  0.28605843], Action: 0, state: 1\n",
      "[0.7139416  0.28605843]\n",
      "Sensor: [0.3787592162610261, 0.6426039126783586, 0.23400749488663503, 0.21050829529928197], Action prob: [0.7133329 0.2866671], Action: 0, state: 2\n",
      "[0.7133329 0.2866671]\n",
      "Sensor: [0.3743690727171036, 0.5583356624957269, 0.1794797178422726, 0.2763258308263482], Action prob: [0.7128207  0.28717932], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "tensor([-1.7171, -1.2030, -0.3219, -0.1013,  0.0834,  0.2499,  0.3834,  1.8532],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1736 is 84700, loss is 0.09665579153646256\n",
      "[0.7128207  0.28717932]\n",
      "Sensor: [0.37628007029268495, 0.6301816223607858, 0.2077429485653798, 0.28342241643649746], Action prob: [0.7125843 0.2874157], Action: 0, state: 1\n",
      "[0.7125843 0.2874157]\n",
      "Sensor: [0.40005764039415087, 0.6073185684801702, 0.22255615736579037, 0.2572345760438053], Action prob: [0.71804065 0.2819594 ], Action: 0, state: 1\n",
      "[0.71804065 0.2819594 ]\n",
      "Sensor: [0.4336625161027097, 0.4837786415266699, 0.5734764901731839, 0.40095849527471084], Action prob: [0.71803224 0.28196773], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.71803224 0.28196773]\n",
      "Sensor: [0.34732050977366347, 0.5865299105630669, 0.1829815977498674, 0.3005691496203981], Action prob: [0.7180113  0.28198868], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.7180113  0.28198868]\n",
      "Sensor: [0.34862730275044007, 0.6473189309766758, 0.15412842514995945, 0.46956255417435544], Action prob: [0.71868753 0.28131247], Action: 0, state: 0\n",
      "[0.71868753 0.28131247]\n",
      "Sensor: [0.37040412838412057, 0.6659180567250884, 0.20517789143497583, 0.2185353726451164], Action prob: [0.71823794 0.28176212], Action: 0, state: 0\n",
      "[0.71823794 0.28176212]\n",
      "Sensor: [0.4237045894381536, 0.6192101045643973, 0.21996294474200992, 0.267311822145462], Action prob: [0.7174972  0.28250277], Action: 0, state: 1\n",
      "[0.7174972  0.28250277]\n",
      "Sensor: [0.41225293318300443, 0.710679649697164, 0.44888606820170135, 0.22973444373146149], Action prob: [0.71755296 0.28244704], Action: 0, state: 1\n",
      "tensor([-0.6381, -0.2092,  0.5701,  0.3310, -0.2469,  0.0506,  0.2966,  0.5319],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1744 is 88900, loss is -0.08576034484707239\n",
      "[0.71755296 0.28244704]\n",
      "Sensor: [0.395426802286821, 0.6251652459203754, 0.20488271296805077, 0.2657503884763538], Action prob: [0.7162744  0.28372565], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "[0.7162744  0.28372565]\n",
      "Sensor: [0.3785164801431944, 0.684166566667269, 0.20322098527158763, 0.23344817777670054], Action prob: [0.7232494  0.27675062], Action: 0, state: 1\n",
      "[0.7232494  0.27675062]\n",
      "Sensor: [0.3814762165919301, 0.6574885845117551, 0.1981136543494071, 0.23891363553591957], Action prob: [0.72466683 0.27533314], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1100\n",
      "[0.72466683 0.27533314]\n",
      "Sensor: [0.3031888661977484, 0.6167390679020232, 0.1803615194474048, 0.2385300763367968], Action prob: [0.7246062  0.27539378], Action: 0, state: 1\n",
      "[0.7246062  0.27539378]\n",
      "Sensor: [0.3252942484433839, 0.6627231620124296, 0.1889285504617193, 0.2553848160520141], Action prob: [0.7244254  0.27557468], Action: 0, state: 1\n",
      "[0.7244254  0.27557468]\n",
      "Sensor: [0.35946250805418334, 0.6115214916115639, 0.21898868271566918, 0.2690381911348259], Action prob: [0.72379506 0.27620494], Action: 0, state: 2\n",
      "[0.72379506 0.27620494]\n",
      "Sensor: [0.33291269900284237, 0.629846105396402, 0.20791437691775788, 0.20879232307165457], Action prob: [0.7234993  0.27650076], Action: 0, state: 3\n",
      "[0.7234993  0.27650076]\n",
      "Sensor: [0.37057385562127576, 0.6107557884535674, 0.2030094788406087, 0.30672266109236057], Action prob: [0.723376   0.27662396], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "tensor([-0.2152, -0.4019,  0.0524, -0.4951, -0.1194,  0.1833,  0.3525,  2.0098],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1752 is 91000, loss is -0.1707948694124365\n",
      "[0.723376   0.27662396]\n",
      "Sensor: [0.3137544761939649, 0.6603235456536519, 0.22185828029062213, 0.24931804701529892], Action prob: [0.7244945 0.2755055], Action: 0, state: 2\n",
      "[0.7244945 0.2755055]\n",
      "Sensor: [0.4054246033588471, 0.6734522615536391, 0.25944079224968963, 0.27732741145574114], Action prob: [0.73281896 0.26718107], Action: 0, state: 2\n",
      "[0.73281896 0.26718107]\n",
      "Sensor: [0.3496904731916996, 0.62450578112185, 0.23340398860068276, 0.24473840912220607], Action prob: [0.73490936 0.26509067], Action: 0, state: 2\n",
      "[0.73490936 0.26509067]\n",
      "Sensor: [0.3306197097630664, 0.6706359676764301, 0.228760850443436, 0.24786615648294047], Action prob: [0.7355212  0.26447886], Action: 0, state: 2\n",
      "[0.7355212  0.26447886]\n",
      "Sensor: [0.42531080048985126, 0.6550144952411586, 0.22843484716906085, 0.25320419498415675], Action prob: [0.7349297  0.26507032], Action: 0, state: 3\n",
      "[0.7349297  0.26507032]\n",
      "Sensor: [0.3613719399903892, 0.6626833230910729, 0.24480774488249263, 0.2231466727070002], Action prob: [0.73485273 0.26514724], Action: 0, state: 3\n",
      "[0.73485273 0.26514724]\n",
      "Sensor: [0.30859737628816714, 0.5848275234290781, 0.18561472167788526, 0.2424116161010529], Action prob: [0.7346839  0.26531616], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "[0.7346839  0.26531616]\n",
      "Sensor: [0.3516646732217415, 0.6676121793785481, 0.19559720787772605, 0.2482050851961246], Action prob: [0.73492694 0.26507306], Action: 0, state: 2\n",
      "tensor([-0.6060, -0.3532, -0.1423,  0.0444,  0.1456,  0.2430,  1.4118,  0.2955],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1760 is 95500, loss is -0.12985881023770518\n",
      "[0.73492694 0.26507306]\n",
      "Sensor: [0.41213825997665404, 0.6412580689728621, 0.2156336883881028, 0.2665410568931172], Action prob: [0.7338439  0.26615605], Action: 0, state: 2\n",
      "[0.7338439  0.26615605]\n",
      "Sensor: [0.3201314849278377, 0.609949680393209, 0.22954673552904567, 0.2540147005043034], Action prob: [0.7447537  0.25524622], Action: 0, state: 3\n",
      "[0.7447537  0.25524622]\n",
      "Sensor: [0.3587936323304421, 0.5919848421428672, 0.21288536067652208, 0.5614776907313537], Action prob: [0.7492895  0.25071046], Action: 0, state: 8\n",
      "[0.7492895  0.25071046]\n",
      "Sensor: [0.350113566618823, 0.6626055329402504, 0.20212649625757007, 0.5588025774438876], Action prob: [0.7510582  0.24894187], Action: 0, state: 8\n",
      "[0.7510582  0.24894187]\n",
      "Sensor: [0.3707561730030164, 0.35162431447541465, 0.22160054074094915, 0.23657692070148095], Action prob: [0.74811035 0.2518896 ], Action: 1, state: 8\n",
      "[0.74811035 0.2518896 ]\n",
      "Sensor: [0.38386618676217793, 0.3919558273156325, 0.22370116307272103, 0.19597581860194577], Action prob: [0.7463598  0.25364023], Action: 0, state: 8\n",
      "[0.7463598  0.25364023]\n",
      "Sensor: [0.3865178457682321, 0.43987878187223783, 0.23390728068676536, 0.2726448988285092], Action prob: [0.74631494 0.25368506], Action: 0, state: 8\n",
      "[0.74631494 0.25368506]\n",
      "Sensor: [0.3796078855561459, 0.6225050446959566, 0.574009356335351, 0.1814897346404591], Action prob: [0.7479395  0.25206047], Action: 0, state: 8\n",
      "tensor([ 0.3811,  0.4003,  0.2224,  0.0645, -0.3882, -0.2126, -0.3266, -0.4119],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1768 is 75000, loss is 0.03387988386136952\n",
      "[0.7479395  0.25206047]\n",
      "Sensor: [0.5281382492917992, 0.5936618262583538, 0.6299559981580182, 0.21422567715765947], Action prob: [0.7420326  0.25796738], Action: 1, state: 8\n",
      "[0.7420326  0.25796738]\n",
      "Sensor: [0.3832647794069777, 0.6262666182685837, 0.22185487396895348, 0.5788664321443477], Action prob: [0.7565535  0.24344657], Action: 0, state: 8\n",
      "[0.7565535  0.24344657]\n",
      "Sensor: [0.5989458052218657, 0.6200989982649302, 0.21687685433713202, 0.2573719150124191], Action prob: [0.76024723 0.2397528 ], Action: 0, state: 8\n",
      "[0.76024723 0.2397528 ]\n",
      "Sensor: [0.5987410477036266, 0.6378154167517031, 0.20678148072214864, 0.23733886405691168], Action prob: [0.7615082  0.23849176], Action: 0, state: 8\n",
      "[0.7615082  0.23849176]\n",
      "Sensor: [0.566086035606429, 0.7336057336105573, 0.22202726966097788, 0.25308160215805425], Action prob: [0.7630191  0.23698092], Action: 0, state: 8\n",
      "[0.7630191  0.23698092]\n",
      "Sensor: [0.391505862584542, 0.42062960898896595, 0.20154450396453483, 0.2600722406861052], Action prob: [0.7623276  0.23767239], Action: 0, state: 8\n",
      "[0.7623276  0.23767239]\n",
      "Sensor: [0.36910207298533354, 0.6120394030389409, 0.549934868066314, 0.23734928191881458], Action prob: [0.76381636 0.23618361], Action: 0, state: 8\n",
      "[0.76381636 0.23618361]\n",
      "Sensor: [0.6892596728163052, 0.7146758919112446, 0.2777918513940495, 0.2755106389104518], Action prob: [0.76360637 0.23639357], Action: 0, state: 8\n",
      "tensor([ 2.3403,  0.3104,  0.1453,  0.0142, -0.0996, -0.1967, -0.2716, -0.3815],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for up to this timestep 1776 is 51000, loss is -0.232603824173125\n",
      "[0.76360637 0.23639357]\n",
      "Sensor: [0.610771202028456, 0.6774458686088076, 0.260067310876711, 0.2913998743969604], Action prob: [0.7556703  0.24432968], Action: 0, state: 8\n",
      "[0.7556703  0.24432968]\n",
      "Sensor: [0.3637702064089109, 0.7036052477613931, 0.21023534495394722, 0.4882411762863755], Action prob: [0.7746159  0.22538419], Action: 0, state: 8\n",
      "[0.7746159  0.22538419]\n",
      "Sensor: [0.560495503312912, 0.6304839027598076, 0.1753070907691808, 0.2767275936358516], Action prob: [0.78077984 0.21922016], Action: 0, state: 8\n",
      "[0.78077984 0.21922016]\n",
      "Sensor: [0.6368507914718173, 0.6046180379840302, 0.21924319847876841, 0.19815602433280288], Action prob: [0.7830048  0.21699513], Action: 0, state: 8\n",
      "[0.7830048  0.21699513]\n",
      "Sensor: [0.4076272490809628, 0.4312113810042075, 0.24281580037604783, 0.2692887484964364], Action prob: [0.7839104  0.21608959], Action: 1, state: 8\n",
      "[0.7839104  0.21608959]\n",
      "Sensor: [0.2924914052244277, 0.5924186852729274, 0.30610003500944677, 0.22315626488908208], Action prob: [0.7863068  0.21369322], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7863068  0.21369322]\n",
      "Sensor: [0.3854763475503988, 0.6700282311723388, 0.20362811946971537, 0.2723305577252174], Action prob: [0.7879545  0.21204545], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7879545  0.21204545]\n",
      "Sensor: [0.3536564174263592, 0.5960787242215859, 0.21518494637037014, 0.23716915949030035], Action prob: [0.78837895 0.2116211 ], Action: 0, state: 0\n",
      "tensor([ 0.5483,  0.2887,  0.0750, -0.0994, -1.5208, -1.2076, -1.1272, -0.1533],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1784 is 42000, loss is 0.399531017275511\n",
      "[0.78837895 0.2116211 ]\n",
      "Sensor: [0.3269397305842305, 0.599156846424807, 0.24979907189507009, 0.28794539313733014], Action prob: [0.75721323 0.2427868 ], Action: 0, state: 0\n",
      "[0.75721323 0.2427868 ]\n",
      "Sensor: [0.33923208222244644, 0.6938956140008885, 0.20604788186314574, 0.20708294642546402], Action prob: [0.7738269 0.2261731], Action: 0, state: 0\n",
      "[0.7738269 0.2261731]\n",
      "Sensor: [0.33250476361163495, 0.6402506051834521, 0.1880567942959946, 0.22353830696264493], Action prob: [0.7807406  0.21925943], Action: 0, state: 0\n",
      "[0.7807406  0.21925943]\n",
      "Sensor: [0.35808993146360435, 0.6100461657303511, 0.1856375183832605, 0.2493035723209037], Action prob: [0.7835775  0.21642242], Action: 0, state: 1\n",
      "[0.7835775  0.21642242]\n",
      "Sensor: [0.3750649692447014, 0.6575613118092917, 0.21144347795604201, 0.25980281849242187], Action prob: [0.7853141  0.21468592], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7853141  0.21468592]\n",
      "Sensor: [0.34505428266282, 0.6546163947191674, 0.19990168738362005, 0.2586294598566378], Action prob: [0.7863847  0.21361525], Action: 0, state: 0\n",
      "[0.7863847  0.21361525]\n",
      "Sensor: [0.3811637975863073, 0.6124223754316138, 0.23727996590832914, 0.27508939734986965], Action prob: [0.7866737  0.21332625], Action: 0, state: 0\n",
      "[0.7866737  0.21332625]\n",
      "Sensor: [0.35443151094705067, 0.6248468816402806, 0.17785443495617712, 0.2679100753312576], Action prob: [0.7868653  0.21313469], Action: 0, state: 0\n",
      "tensor([-0.4891, -0.2863, -0.1295, -0.0107,  0.6012,  0.1464,  0.2405,  0.3224],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1792 is 49200, loss is -0.049347497133666166\n",
      "[0.7868653  0.21313469]\n",
      "Sensor: [0.40015488167622026, 0.6121451568276178, 0.2565331286903764, 0.27762762909989364], Action prob: [0.7593379  0.24066205], Action: 0, state: 1\n",
      "[0.7593379  0.24066205]\n",
      "Sensor: [0.36348500819115453, 0.6272426804497643, 0.21649875245848502, 0.23437964036766923], Action prob: [0.774606   0.22539401], Action: 0, state: 1\n",
      "[0.774606   0.22539401]\n",
      "Sensor: [0.3303824242759025, 0.6244634462657592, 0.20910271626669744, 0.2837690197506465], Action prob: [0.7812625  0.21873742], Action: 0, state: 2\n",
      "[0.7812625  0.21873742]\n",
      "Sensor: [0.3560210300708871, 0.6379291868909673, 0.21682946145217086, 0.25292782689077387], Action prob: [0.7841053 0.2158947], Action: 0, state: 2\n",
      "[0.7841053 0.2158947]\n",
      "Sensor: [0.3920684658943654, 0.6733453137818872, 0.24495389855116184, 0.2997972319672998], Action prob: [0.7856447  0.21435528], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.7856447  0.21435528]\n",
      "Sensor: [0.4041190266004011, 0.6143323569720113, 0.17242617064170224, 0.28141590234595615], Action prob: [0.7856391  0.21436086], Action: 0, state: 1\n",
      "[0.7856391  0.21436086]\n",
      "Sensor: [0.47932867007109575, 0.6055663793151228, 0.2023802612058656, 0.2295807274768827], Action prob: [0.7851993  0.21480075], Action: 0, state: 2\n",
      "[0.7851993  0.21480075]\n",
      "Sensor: [0.5875609993262314, 0.6340238051573169, 0.249597918854663, 0.27859445653694737], Action prob: [0.78505135 0.21494865], Action: 0, state: 3\n",
      "tensor([-0.4975, -0.2807, -0.1288, -0.0031,  0.6961,  0.1557,  0.2445,  0.2947],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1800 is 54700, loss is -0.060087202921638654\n",
      "[0.78505135 0.21494865]\n",
      "Sensor: [0.3606691041984565, 0.6517620819118136, 0.2319780194531384, 0.21792339616635548], Action prob: [0.76323956 0.23676042], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.76323956 0.23676042]\n",
      "Sensor: [0.4265714013734857, 0.6377293304993545, 0.22469498869779955, 0.24909088899349463], Action prob: [0.7779355  0.22206445], Action: 0, state: 2\n",
      "[0.7779355  0.22206445]\n",
      "Sensor: [0.37996636199072936, 0.5948186352085745, 0.22231796669316492, 0.24397863836326825], Action prob: [0.7832622  0.21673776], Action: 0, state: 2\n",
      "[0.7832622  0.21673776]\n",
      "Sensor: [0.31662995465214183, 0.6308096439549142, 0.21208475211059155, 0.22474859451190946], Action prob: [0.7857386 0.2142614], Action: 0, state: 2\n",
      "[0.7857386 0.2142614]\n",
      "Sensor: [0.3177051421198098, 0.3775851182742564, 0.20378941534886513, 0.3029610900399223], Action prob: [0.7847583 0.2152417], Action: 0, state: 3\n",
      "[0.7847583 0.2152417]\n",
      "Sensor: [0.33226569046447174, 0.3311785906988652, 0.25562874507711664, 0.28142983718820663], Action prob: [0.78370595 0.21629412], Action: 0, state: 8\n",
      "[0.78370595 0.21629412]\n",
      "Sensor: [0.40266591861888645, 0.6085801476547102, 0.5361895419103287, 0.23769019643426845], Action prob: [0.78608394 0.21391612], Action: 0, state: 8\n",
      "[0.78608394 0.21391612]\n",
      "Sensor: [0.4311997913487643, 0.6634558810435809, 0.2292905085812374, 0.5872251084347726], Action prob: [0.7876616 0.2123384], Action: 0, state: 8\n",
      "tensor([-0.0150,  0.0409,  0.1478,  0.2417,  0.2986,  0.0117, -0.2386, -0.4756],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1808 is 45100, loss is -0.00143623655151226\n",
      "[0.7876616 0.2123384]\n",
      "Sensor: [0.554767626213551, 0.5810829239005828, 0.23667933863753643, 0.23985007713960982], Action prob: [0.7649313  0.23506868], Action: 0, state: 8\n",
      "[0.7649313  0.23506868]\n",
      "Sensor: [0.5731596982092765, 0.6323403869587223, 0.22960243841956574, 0.29934168744268747], Action prob: [0.7792316 0.2207684], Action: 0, state: 8\n",
      "[0.7792316 0.2207684]\n",
      "Sensor: [0.3591969777782678, 0.35331000741899915, 0.22901318368559276, 0.27336438832305243], Action prob: [0.78285676 0.21714325], Action: 0, state: 8\n",
      "[0.78285676 0.21714325]\n",
      "Sensor: [0.5905295640020944, 0.6619168684380522, 0.22553661090477095, 0.2773226878434314], Action prob: [0.7854924  0.21450765], Action: 1, state: 8\n",
      "[0.7854924  0.21450765]\n",
      "Sensor: [0.38043153603540647, 0.44255712068486514, 0.20168556264215554, 0.2341204615036929], Action prob: [0.78556657 0.2144334 ], Action: 0, state: 8\n",
      "[0.78556657 0.2144334 ]\n",
      "Sensor: [0.4006862800896418, 0.6162732629883384, 0.49346138610679335, 0.22696217392965812], Action prob: [0.7879966  0.21200348], Action: 0, state: 8\n",
      "[0.7879966  0.21200348]\n",
      "Sensor: [0.4752025355607513, 0.6300067518570063, 0.1561302606152707, 0.26681590367303476], Action prob: [0.7877819 0.2122181], Action: 0, state: 8\n",
      "[0.7877819 0.2122181]\n",
      "Sensor: [0.32448333710062016, 0.6150321740610032, 0.4841209663295421, 0.5015889675179347], Action prob: [0.79029584 0.20970412], Action: 1, state: 8\n",
      "tensor([ 0.4454,  0.2683,  0.1430,  0.1056, -0.0796, -0.1591, -0.2586, -2.0238],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1816 is 21100, loss is 0.19485652829287092\n",
      "[0.79029584 0.20970412]\n",
      "Sensor: [0.6229927256356954, 0.6235874318057913, 0.20508633922844152, 0.270924003875188], Action prob: [0.7635089  0.23649113], Action: 0, state: 8\n",
      "[0.7635089  0.23649113]\n",
      "Sensor: [0.362626718849859, 0.37744965324305474, 0.21995732426539744, 0.25345538970868153], Action prob: [0.7745631  0.22543687], Action: 0, state: 8\n",
      "[0.7745631  0.22543687]\n",
      "Sensor: [0.399115097330525, 0.4396137940871982, 0.2184775654368576, 0.296175153967621], Action prob: [0.77877814 0.22122185], Action: 0, state: 8\n",
      "[0.77877814 0.22122185]\n",
      "Sensor: [0.400105139108837, 0.6577900576791665, 0.6615657540058332, 0.2534071620438231], Action prob: [0.78356755 0.21643247], Action: 0, state: 8\n",
      "[0.78356755 0.21643247]\n",
      "Sensor: [0.3548626185454827, 0.6394798645877673, 0.2295343781730363, 0.5725736177837767], Action prob: [0.7845769  0.21542312], Action: 1, state: 8\n",
      "[0.7845769  0.21542312]\n",
      "Sensor: [0.5671799755442788, 0.6656840326525433, 0.16778381173386298, 0.269012962028488], Action prob: [0.78322977 0.21677019], Action: 0, state: 8\n",
      "[0.78322977 0.21677019]\n",
      "Sensor: [0.43522321645742623, 0.6640288815921701, 0.205494792519549, 0.583397885018248], Action prob: [0.78395927 0.21604076], Action: 0, state: 8\n",
      "[0.78395927 0.21604076]\n",
      "Sensor: [0.38888705376045435, 0.4206053492087271, 0.20133102627163668, 0.31745716434262233], Action prob: [0.78200465 0.21799532], Action: 0, state: 8\n",
      "tensor([ 0.4451,  0.2837,  0.1449,  0.0444, -0.4564, -0.1828, -0.2541, -0.3351],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1824 is -2900, loss is 0.03878640153137832\n",
      "[0.78200465 0.21799532]\n",
      "Sensor: [0.5592386375115377, 0.6711567628631238, 0.21871697978229873, 0.2569963714111128], Action prob: [0.76201534 0.23798458], Action: 0, state: 8\n",
      "[0.76201534 0.23798458]\n",
      "Sensor: [0.2867573700103456, 0.6180277381814916, 0.4699054411739327, 0.22982652751499028], Action prob: [0.7754866  0.22451344], Action: 0, state: 8\n",
      "[0.7754866  0.22451344]\n",
      "Sensor: [0.3759527258168118, 0.6485403053000846, 0.23214127835327608, 0.5361279656143034], Action prob: [0.7791926  0.22080733], Action: 1, state: 8\n",
      "[0.7791926  0.22080733]\n",
      "Sensor: [0.3038109647291536, 0.3662744841430136, 0.2299021089289999, 0.22516155770309781], Action prob: [0.777365   0.22263497], Action: 0, state: 8\n",
      "[0.777365   0.22263497]\n",
      "Sensor: [0.3906039010968865, 0.4101414917409962, 0.2108547594845777, 0.17591663480385208], Action prob: [0.7758096  0.22419038], Action: 1, state: 8\n",
      "[0.7758096  0.22419038]\n",
      "Sensor: [0.37879590724100987, 0.7188907221576135, 0.19604909152457559, 0.5890065697932937], Action prob: [0.778412   0.22158806], Action: 0, state: 8\n",
      "[0.778412   0.22158806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.37888815513848734, 0.4224088225060485, 0.2674003602759931, 0.32756506533648044], Action prob: [0.77739495 0.22260502], Action: 1, state: 8\n",
      "[0.77739495 0.22260502]\n",
      "Sensor: [0.39821501149779226, 0.6392916467625148, 0.2307032902062717, 0.5982885403473468], Action prob: [0.7784864 0.2215136], Action: 0, state: 8\n",
      "tensor([ 0.4514,  0.2966,  0.9087,  0.0304, -0.4903, -0.1725, -1.5537, -0.3355],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1832 is -26900, loss is 0.10810680242406137\n",
      "[0.7784864 0.2215136]\n",
      "Sensor: [0.3535945689164202, 0.6399354176186473, 0.5143173726213693, 0.21620320300376844], Action prob: [0.75974315 0.24025694], Action: 0, state: 8\n",
      "[0.75974315 0.24025694]\n",
      "Sensor: [0.3148578538490342, 0.5987764494561185, 0.5321476267362546, 0.2305603955802173], Action prob: [0.7701534  0.22984657], Action: 0, state: 8\n",
      "[0.7701534  0.22984657]\n",
      "Sensor: [0.379983421754257, 0.627931019773964, 0.4790970830574209, 0.2326339078287497], Action prob: [0.7726367  0.22736326], Action: 1, state: 8\n",
      "[0.7726367  0.22736326]\n",
      "Sensor: [0.3824918676189256, 0.6238005033508821, 0.5206619119924006, 0.17563581906568485], Action prob: [0.7729104  0.22708952], Action: 1, state: 8\n",
      "[0.7729104  0.22708952]\n",
      "Sensor: [0.5859636647686409, 0.6008731788934144, 0.25936667633172206, 0.22956952123124086], Action prob: [0.770685   0.22931498], Action: 0, state: 8\n",
      "[0.770685   0.22931498]\n",
      "Sensor: [0.3763694676892844, 0.3403751124425075, 0.21558468490601168, 0.23289097730889083], Action prob: [0.7685035  0.23149654], Action: 0, state: 8\n",
      "[0.7685035  0.23149654]\n",
      "Sensor: [0.3931096935317954, 0.38650415541241817, 0.25714164327501193, 0.25091938734661356], Action prob: [0.7680136 0.2319864], Action: 0, state: 8\n",
      "[0.7680136 0.2319864]\n",
      "Sensor: [0.349259190541269, 0.3429264305404426, 0.21931968063017843, 0.24631991583708196], Action prob: [0.76763874 0.23236124], Action: 1, state: 8\n",
      "tensor([ 0.4806,  0.3070,  0.9278,  0.2305, -0.0917, -0.1855, -0.2757, -1.9781],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1840 is -46900, loss is 0.07313565871345659\n",
      "[0.76763874 0.23236124]\n",
      "Sensor: [0.38864963559983734, 0.661198009933465, 0.2524448475040212, 0.2107294549157197], Action prob: [0.75246614 0.24753381], Action: 0, state: 0\n",
      "[0.75246614 0.24753381]\n",
      "Sensor: [0.3140279961274525, 0.6662091783576211, 0.20707051393547812, 0.2664871025126393], Action prob: [0.7619162  0.23808372], Action: 0, state: 1\n",
      "[0.7619162  0.23808372]\n",
      "Sensor: [0.333886089886098, 0.6198828651777532, 0.23986633456937265, 0.2564571964952822], Action prob: [0.76368654 0.2363134 ], Action: 0, state: 1\n",
      "[0.76368654 0.2363134 ]\n",
      "Sensor: [0.3056723453638104, 0.6529926850559905, 0.20603136167103014, 0.2595915978015898], Action prob: [0.7637754  0.23622459], Action: 0, state: 1\n",
      "[0.7637754  0.23622459]\n",
      "Sensor: [0.40096470038458915, 0.6402583527400634, 0.22075930723031356, 0.2858098071065247], Action prob: [0.7629624  0.23703769], Action: 0, state: 2\n",
      "[0.7629624  0.23703769]\n",
      "Sensor: [0.3378998190957856, 0.6377804845296325, 0.22098790874255084, 0.28841623256102034], Action prob: [0.76272804 0.23727201], Action: 0, state: 2\n",
      "[0.76272804 0.23727201]\n",
      "Sensor: [0.35966348982781404, 0.6256328702773827, 0.20796778902355986, 0.25891147821914096], Action prob: [0.7624113  0.23758867], Action: 0, state: 2\n",
      "[0.7624113  0.23758867]\n",
      "Sensor: [0.37515704343390993, 0.7059632001735052, 0.22295290355527875, 0.29014114792301526], Action prob: [0.7628655  0.23713449], Action: 0, state: 2\n",
      "tensor([-0.4926, -0.3004, -0.1467, -0.0121,  0.0936,  0.1944,  0.2806,  0.3595],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1848 is -40500, loss is 0.0029687587527050183\n",
      "[0.7628655  0.23713449]\n",
      "Sensor: [0.3641739776487676, 0.6258872561976478, 0.2080233481642204, 0.24882958259112872], Action prob: [0.74683034 0.2531697 ], Action: 0, state: 3\n",
      "[0.74683034 0.2531697 ]\n",
      "Sensor: [0.3643421718114576, 0.5887073276885526, 0.2168605917728607, 0.576330125032743], Action prob: [0.7540275  0.24597251], Action: 0, state: 9\n",
      "[0.7540275  0.24597251]\n",
      "Sensor: [0.3328758737891513, 0.6404570497208827, 0.5107305689044369, 0.21503281191561727], Action prob: [0.7560011  0.24399889], Action: 1, state: 9\n",
      "[0.7560011  0.24399889]\n",
      "Sensor: [0.5399523231180098, 0.6294886580809749, 0.21048834120903812, 0.28294196251296777], Action prob: [0.75360554 0.24639449], Action: 0, state: 9\n",
      "[0.75360554 0.24639449]\n",
      "Sensor: [0.6878571938555471, 0.35178786091157715, 0.2056711600784728, 0.29000226347636526], Action prob: [0.74962616 0.25037387], Action: 0, state: 9\n",
      "[0.74962616 0.25037387]\n",
      "Sensor: [0.3892921392394226, 0.3452851597924476, 0.23401039035473867, 0.3144667627505994], Action prob: [0.7490959  0.25090408], Action: 1, state: 9\n",
      "[0.7490959  0.25090408]\n",
      "Sensor: [0.5677008756005647, 0.672597082068009, 0.24624235069961523, 0.25427320216967253], Action prob: [0.750792   0.24920797], Action: 0, state: 9\n",
      "[0.750792   0.24920797]\n",
      "Sensor: [0.40165681164912387, 0.3719222498889596, 0.22133892156840812, 0.26964142977420125], Action prob: [0.75010693 0.2498931 ], Action: 0, state: 9\n",
      "tensor([ 0.4889,  0.3161,  0.8798,  0.0173, -0.1105, -0.9809, -0.3144, -0.3955],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1856 is -48500, loss is 0.012397397114334407\n",
      "[0.75010693 0.2498931 ]\n",
      "Sensor: [0.25566813763084417, 0.4557037620441508, 0.22750994865754484, 0.5113963146285844], Action prob: [0.7419906  0.25800937], Action: 0, state: 9\n",
      "[0.7419906  0.25800937]\n",
      "Sensor: [0.4132708499000106, 0.7007316504111811, 0.46974489291253374, 0.3108781288547614], Action prob: [0.7488272  0.25117275], Action: 1, state: 9\n",
      "[0.7488272  0.25117275]\n",
      "Sensor: [0.5785138207049273, 0.614482116818834, 0.18671084203053528, 0.21315212972232475], Action prob: [0.74704987 0.2529502 ], Action: 0, state: 9\n",
      "[0.74704987 0.2529502 ]\n",
      "Sensor: [0.34061028470520677, 0.4115770708506412, 0.19267322384956395, 0.24218027596067743], Action prob: [0.74519396 0.25480607], Action: 0, state: 9\n",
      "[0.74519396 0.25480607]\n",
      "Sensor: [0.4139153197632717, 0.3671327628450265, 0.22031310973935614, 0.2468552038048778], Action prob: [0.7436057 0.2563944], Action: 1, state: 9\n",
      "[0.7436057 0.2563944]\n",
      "Sensor: [0.31704049318484206, 0.6453815065712804, 0.23756102563988524, 0.541590984896296], Action prob: [0.74534744 0.2546526 ], Action: 0, state: 9\n",
      "[0.74534744 0.2546526 ]\n",
      "Sensor: [0.33357308615546705, 0.41737676902303844, 0.21558108109253613, 0.200620515883745], Action prob: [0.7444791 0.2555209], Action: 0, state: 9\n",
      "[0.7444791 0.2555209]\n",
      "Sensor: [0.37137549854343427, 0.5894371214743978, 0.49398382697007104, 0.2602107298226318], Action prob: [0.7456712 0.2543288], Action: 0, state: 9\n",
      "tensor([ 0.5130,  1.5610,  0.1499,  0.0264, -0.4663, -0.2028, -0.3144, -0.3901],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1864 is -56500, loss is -0.10958075454944087\n",
      "[0.7456712 0.2543288]\n",
      "Sensor: [0.3343021660328279, 0.5582202120549655, 0.505155237272624, 0.23499622199529172], Action prob: [0.74150753 0.2584925 ], Action: 0, state: 9\n",
      "[0.74150753 0.2584925 ]\n",
      "Sensor: [0.31106713297725325, 0.3568355295314391, 0.21732354022968745, 0.22135185924130954], Action prob: [0.7449817 0.2550183], Action: 1, state: 9\n",
      "[0.7449817 0.2550183]\n",
      "Sensor: [0.35232000201162367, 0.660486210685397, 0.5094640918946859, 0.5414805526427029], Action prob: [0.7477183  0.25228176], Action: 0, state: 9\n",
      "[0.7477183  0.25228176]\n",
      "Sensor: [0.3872731720176818, 0.35412783359777406, 0.21163369460667, 0.28343394965917734], Action prob: [0.74415725 0.25584275], Action: 0, state: 9\n",
      "[0.74415725 0.25584275]\n",
      "Sensor: [0.31852081931595816, 0.35938655110278894, 0.2251309267971453, 0.26192022003478377], Action prob: [0.7426148 0.2573852], Action: 0, state: 9\n",
      "[0.7426148 0.2573852]\n",
      "Sensor: [0.4328312363763055, 0.37835876048917727, 0.23629890511967747, 0.29147828274159043], Action prob: [0.7415258 0.2584742], Action: 1, state: 9\n",
      "[0.7415258 0.2584742]\n",
      "Sensor: [0.3829017484237435, 0.41762818368962695, 0.21578112088123336, 0.26050134312414674], Action prob: [0.741568   0.25843197], Action: 0, state: 9\n",
      "[0.741568   0.25843197]\n",
      "Sensor: [0.6564661105207097, 0.6917202089392169, 0.5572918385850298, 0.21715834658162542], Action prob: [0.7432169 0.2567831], Action: 0, state: 9\n",
      "tensor([ 0.5166,  1.4977,  0.1851,  0.0255, -0.0978, -0.9850, -0.3209, -0.4090],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1872 is -64500, loss is -0.05150089793728582\n",
      "[0.7432169 0.2567831]\n",
      "Sensor: [0.5858727340717476, 0.6606587091672156, 0.22522333428152666, 0.2602685347305569], Action prob: [0.7395065  0.26049352], Action: 0, state: 9\n",
      "[0.7395065  0.26049352]\n",
      "Sensor: [0.5723951607194856, 0.6487046383253472, 0.22996940206046612, 0.2522958065650219], Action prob: [0.7450646  0.25493535], Action: 0, state: 9\n",
      "[0.7450646  0.25493535]\n",
      "Sensor: [0.34724058795852053, 0.43438407520369304, 0.21634421226792758, 0.25372756357353526], Action prob: [0.7451664  0.25483358], Action: 0, state: 9\n",
      "[0.7451664  0.25483358]\n",
      "Sensor: [0.3524494567406817, 0.3740512483838649, 0.25159248056965633, 0.21805661280527086], Action prob: [0.7439703 0.2560297], Action: 1, state: 9\n",
      "[0.7439703 0.2560297]\n",
      "Sensor: [0.34048075562723235, 0.6291006773494552, 0.5571207344667523, 0.26369179359478456], Action prob: [0.746036   0.25396398], Action: 0, state: 9\n",
      "[0.746036   0.25396398]\n",
      "Sensor: [0.5977655261163609, 0.6186145074976207, 0.2226930099577414, 0.24942674338885526], Action prob: [0.74424106 0.25575897], Action: 0, state: 9\n",
      "[0.74424106 0.25575897]\n",
      "Sensor: [0.34063645770060863, 0.39366043554178026, 0.24077659694505704, 0.280286090066078], Action prob: [0.743027   0.25697303], Action: 1, state: 9\n",
      "[0.743027   0.25697303]\n",
      "Sensor: [0.565936471385654, 0.6502697728137249, 0.21362241239978252, 0.2571635789281882], Action prob: [0.74330443 0.25669563], Action: 0, state: 9\n",
      "tensor([ 0.4907,  0.3070,  0.1643,  0.1215, -0.0831, -0.2286, -1.4448, -0.4236],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1880 is -72500, loss is 0.13707417957854245\n",
      "[0.74330443 0.25669563]\n",
      "Sensor: [0.33801840737951006, 0.3874916487283229, 0.20290550683538344, 0.2591101966302294], Action prob: [0.7363113  0.26368862], Action: 0, state: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7363113  0.26368862]\n",
      "Sensor: [0.4755025962685318, 0.40310453706733224, 0.562282632263491, 0.22532252988619728], Action prob: [0.7422771  0.25772288], Action: 1, state: 9\n",
      "[0.7422771  0.25772288]\n",
      "Sensor: [0.3765031908112527, 0.3336662806213828, 0.20404860236464106, 0.24046124310722086], Action prob: [0.74127907 0.25872096], Action: 0, state: 9\n",
      "[0.74127907 0.25872096]\n",
      "Sensor: [0.6238310645177679, 0.6196809367998981, 0.2052302688679162, 0.4795637794429334], Action prob: [0.7409829  0.25901708], Action: 1, state: 9\n",
      "[0.7409829  0.25901708]\n",
      "Sensor: [0.5691130659971182, 0.6206571125482725, 0.21736373481283092, 0.20595092311923732], Action prob: [0.7407497  0.25925037], Action: 0, state: 9\n",
      "[0.7407497  0.25925037]\n",
      "Sensor: [0.395907204415576, 0.42929973478413674, 0.22127830737464146, 0.5382395069852587], Action prob: [0.73998356 0.26001647], Action: 0, state: 9\n",
      "[0.73998356 0.26001647]\n",
      "Sensor: [0.5535800679241504, 0.653540869155709, 0.217797876323046, 0.2629675213127822], Action prob: [0.74052644 0.25947353], Action: 1, state: 9\n",
      "[0.74052644 0.25947353]\n",
      "Sensor: [0.29819568726239004, 0.6200479808403753, 0.23913988952988846, 0.6212636118147925], Action prob: [0.7420513  0.25794867], Action: 0, state: 9\n",
      "tensor([ 0.5120,  1.5278,  0.1660,  0.0666, -0.1168, -0.2137, -1.5018, -0.4019],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1888 is -80500, loss is -0.004764235761139317\n",
      "[0.7420513  0.25794867]\n",
      "Sensor: [0.37011431324069965, 0.42359183907220604, 0.19895076601482245, 0.2718685146352867], Action prob: [0.73446757 0.26553246], Action: 0, state: 9\n",
      "[0.73446757 0.26553246]\n",
      "Sensor: [0.3668846036653184, 0.39875081984829375, 0.2015968146082586, 0.22862298885721832], Action prob: [0.7397198  0.26028025], Action: 0, state: 9\n",
      "[0.7397198  0.26028025]\n",
      "Sensor: [0.3453776256930382, 0.662926625049307, 0.5195432558074462, 0.24283082040083342], Action prob: [0.7433305  0.25666955], Action: 0, state: 9\n",
      "[0.7433305  0.25666955]\n",
      "Sensor: [0.5897858109377049, 0.6345590237041748, 0.23844278913571765, 0.29587680907200453], Action prob: [0.7408518 0.2591482], Action: 0, state: 9\n",
      "[0.7408518 0.2591482]\n",
      "Sensor: [0.3636755511049673, 0.617870038482373, 0.21298826068334173, 0.5418685600472454], Action prob: [0.7406742 0.2593258], Action: 1, state: 9\n",
      "[0.7406742 0.2593258]\n",
      "Sensor: [0.37221103031807534, 0.38942221982183495, 0.20965778449503578, 0.21715163262519324], Action prob: [0.7385591  0.26144084], Action: 0, state: 9\n",
      "[0.7385591  0.26144084]\n",
      "Sensor: [0.3390773819898315, 0.42149367346802574, 0.24307332959555483, 0.16921586251386464], Action prob: [0.7379947 0.2620054], Action: 0, state: 9\n",
      "[0.7379947 0.2620054]\n",
      "Sensor: [0.606186391241723, 0.33038025581470976, 0.20741144315081772, 0.25668445768393994], Action prob: [0.7355642  0.26443583], Action: 0, state: 9\n",
      "tensor([ 0.5156,  0.3266,  0.1804,  0.0149, -0.4374, -0.2210, -0.3248, -0.4356],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1896 is -88500, loss is 0.04766117191950182\n",
      "[0.7355642  0.26443583]\n",
      "Sensor: [0.37905700239939233, 0.27536707472682787, 0.3640356693804403, 0.21474041860746662], Action prob: [0.7316093  0.26839072], Action: 0, state: 9\n",
      "[0.7316093  0.26839072]\n",
      "Sensor: [0.4074892547847102, 0.41543159956869447, 0.22334071263733263, 0.2583508188735816], Action prob: [0.73701596 0.262984  ], Action: 1, state: 9\n",
      "[0.73701596 0.262984  ]\n",
      "Sensor: [0.5578004542049608, 0.636264787629692, 0.24229822126866926, 0.2730060828269116], Action prob: [0.73833126 0.2616688 ], Action: 1, state: 9\n",
      "[0.73833126 0.2616688 ]\n",
      "Sensor: [0.30860721419812015, 0.6368730747135418, 0.18930177998934772, 0.2303211574000985], Action prob: [0.73906255 0.26093748], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.73906255 0.26093748]\n",
      "Sensor: [0.39002731681650815, 0.6504942200614635, 0.24843369262868076, 0.29335803259725485], Action prob: [0.73895067 0.2610493 ], Action: 0, state: 0\n",
      "[0.73895067 0.2610493 ]\n",
      "Sensor: [0.3719971719699742, 0.6375694538859117, 0.28331946374315736, 0.2665756509972522], Action prob: [0.73879826 0.2612017 ], Action: 0, state: 0\n",
      "[0.73879826 0.2612017 ]\n",
      "Sensor: [0.3682570722097263, 0.6748617526010798, 0.2094571472518369, 0.28875527872117435], Action prob: [0.738626   0.26137397], Action: 0, state: 1\n",
      "[0.738626   0.26137397]\n",
      "Sensor: [0.3743912748985767, 0.6665156851507084, 0.22196343138685587, 0.2792922688052587], Action prob: [0.73853445 0.26146558], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "tensor([ 0.1622, -0.9082, -2.3586, -1.0562, -0.1082,  0.1261,  0.3108,  2.0438],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1904 is -86400, loss is 0.22353667144649686\n",
      "[0.73853445 0.26146558]\n",
      "Sensor: [0.3776226731883435, 0.6215854559209057, 0.2677710879592514, 0.2949493947740542], Action prob: [0.7269601  0.27303985], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.7269601  0.27303985]\n",
      "Sensor: [0.3553191412883678, 0.6417029881544831, 0.17940689459385245, 0.5683428287768565], Action prob: [0.73233145 0.2676685 ], Action: 0, state: 0\n",
      "[0.73233145 0.2676685 ]\n",
      "Sensor: [0.34824358988558823, 0.6040469236408441, 0.23374624307767883, 0.29534762430523126], Action prob: [0.73291564 0.2670844 ], Action: 0, state: 1\n",
      "[0.73291564 0.2670844 ]\n",
      "Sensor: [0.3169370231469031, 0.6252435381347813, 0.22564545408821762, 0.27585834991257707], Action prob: [0.73225194 0.2677481 ], Action: 0, state: 2\n",
      "[0.73225194 0.2677481 ]\n",
      "Sensor: [0.3586451353950045, 0.675233468255618, 0.24935650966248069, 0.2598584059722629], Action prob: [0.73180956 0.2681904 ], Action: 0, state: 2\n",
      "[0.73180956 0.2681904 ]\n",
      "Sensor: [0.42609681935694166, 0.6421503194476184, 0.18811485796208657, 0.2557276562443265], Action prob: [0.7306069 0.2693931], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "[0.7306069 0.2693931]\n",
      "Sensor: [0.3545421568186606, 0.6063797857271985, 0.1870406960320241, 0.2504310867442635], Action prob: [0.7302518  0.26974827], Action: 0, state: 2\n",
      "[0.7302518  0.26974827]\n",
      "Sensor: [0.3531306167546733, 0.609522345000007, 0.2104315856789045, 0.21766100414506023], Action prob: [0.73030376 0.26969624], Action: 0, state: 2\n",
      "tensor([-0.8663, -0.5664, -0.2761, -0.0421,  0.1677,  1.1783,  0.2429,  0.3985],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1912 is -83000, loss is -0.029563339779335045\n",
      "[0.73030376 0.26969624]\n",
      "Sensor: [0.34249727094378435, 0.6015014254449916, 0.47288319805646584, 0.2501757080784928], Action prob: [0.723017   0.27698296], Action: 0, state: 2\n",
      "[0.723017   0.27698296]\n",
      "Sensor: [0.37323940128097416, 0.33703637878301795, 0.2166780520398038, 0.2701528096511883], Action prob: [0.7252023 0.2747977], Action: 0, state: 3\n",
      "[0.7252023 0.2747977]\n",
      "Sensor: [0.6374278407563196, 0.611857072264417, 0.1892611637349941, 0.32462126733278174], Action prob: [0.72458    0.27542004], Action: 1, state: 8\n",
      "[0.72458    0.27542004]\n",
      "Sensor: [0.3335578394743223, 0.5973103732779513, 0.5235643127470266, 0.24758464568304483], Action prob: [0.726659   0.27334103], Action: 1, state: 8\n",
      "[0.726659   0.27334103]\n",
      "Sensor: [0.44156555022841315, 0.6141199336307797, 0.79357725729527, 0.30367058295288457], Action prob: [0.72802347 0.27197653], Action: 0, state: 8\n",
      "[0.72802347 0.27197653]\n",
      "Sensor: [0.34053706813129697, 0.6888028923574517, 0.23590992374128872, 0.5652874999055201], Action prob: [0.72687835 0.27312163], Action: 0, state: 8\n",
      "[0.72687835 0.27312163]\n",
      "Sensor: [0.377517850199848, 0.3672153860997848, 0.21785984153765778, 0.2212652145909779], Action prob: [0.7243443 0.2756557], Action: 0, state: 8\n",
      "[0.7243443 0.2756557]\n",
      "Sensor: [0.3394640126897117, 0.5913068508135182, 0.208225083125686, 0.5530606340757739], Action prob: [0.7247263  0.27527365], Action: 1, state: 8\n",
      "tensor([ 0.4188,  0.4394,  0.9220,  0.3454, -0.0601, -0.2191, -0.3577, -1.8592],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1920 is -99500, loss is 0.046313439315452565\n",
      "[0.7247263  0.27527365]\n",
      "Sensor: [0.3415712635841632, 0.5837126720372094, 0.22438131776929446, 0.24388294227755047], Action prob: [0.71548027 0.28451976], Action: 0, state: 0\n",
      "[0.71548027 0.28451976]\n",
      "Sensor: [0.31803727602894855, 0.5947096042648693, 0.21113105747018063, 0.25044407849514133], Action prob: [0.7200577  0.27994227], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.7200577  0.27994227]\n",
      "Sensor: [0.38527420140670215, 0.6597837795513606, 0.16373357158465485, 0.26790192575787997], Action prob: [0.7204635 0.2795365], Action: 0, state: 0\n",
      "[0.7204635 0.2795365]\n",
      "Sensor: [0.3732630920508546, 0.5853430904562409, 0.2119199575961027, 0.256638779568651], Action prob: [0.7197449  0.28025508], Action: 0, state: 1\n",
      "[0.7197449  0.28025508]\n",
      "Sensor: [0.36469931189901256, 0.6085060071237249, 0.23037792329245443, 0.27646152026435517], Action prob: [0.71923864 0.28076136], Action: 0, state: 2\n",
      "[0.71923864 0.28076136]\n",
      "Sensor: [0.37315934765753456, 0.5600130847762874, 0.20034909664700618, 0.26480271980100933], Action prob: [0.7184993  0.28150073], Action: 0, state: 2\n",
      "[0.7184993  0.28150073]\n",
      "Sensor: [0.447820579092619, 0.6374784536694779, 0.22560067268260045, 0.21217895959510577], Action prob: [0.7183383  0.28166175], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "[0.7183383  0.28166175]\n",
      "Sensor: [0.33169384437596944, 0.6103562775350027, 0.22049466006613594, 0.24210478394018398], Action prob: [0.71866256 0.28133744], Action: 0, state: 1\n",
      "tensor([-0.5814, -1.0397, -0.2737, -0.0507,  0.1275,  0.2855,  1.6259,  0.3336],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1928 is -95000, loss is -0.05336167834992048\n",
      "[0.71866256 0.28133744]\n",
      "Sensor: [0.3832711255699501, 0.6114004362159601, 0.2083969554644864, 0.2822799826046394], Action prob: [0.711064   0.28893602], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1600\n",
      "[0.711064   0.28893602]\n",
      "Sensor: [0.3446758286116498, 0.6248431813354529, 0.21472440210368193, 0.24690228836936257], Action prob: [0.71538407 0.28461596], Action: 0, state: 1\n",
      "[0.71538407 0.28461596]\n",
      "Sensor: [0.3797642930759996, 0.6535311872863302, 0.18837530274556802, 0.2806964345005765], Action prob: [0.7160198  0.28398022], Action: 0, state: 1\n",
      "[0.7160198  0.28398022]\n",
      "Sensor: [0.384095073697714, 0.5938809956603113, 0.219100144058603, 0.25034110891636], Action prob: [0.71542656 0.28457344], Action: 0, state: 1\n",
      "[0.71542656 0.28457344]\n",
      "Sensor: [0.34231055045848074, 0.5998037865471543, 0.207022280732394, 0.3118723554766005], Action prob: [0.7150319  0.28496805], Action: 0, state: 2\n",
      "[0.7150319  0.28496805]\n",
      "Sensor: [0.4657112295545813, 0.6241628790758562, 0.2364355809696863, 0.22928647517230463], Action prob: [0.7144549  0.28554505], Action: 0, state: 3\n",
      "[0.7144549  0.28554505]\n",
      "Sensor: [0.5493796524091843, 0.37776022012719657, 0.22004610110192305, 0.3381626066723902], Action prob: [0.71215045 0.2878496 ], Action: 0, state: 8\n",
      "[0.71215045 0.2878496 ]\n",
      "Sensor: [0.33956804741841046, 0.6031463302293658, 0.4711372739175199, 0.5251504714682955], Action prob: [0.71440524 0.28559476], Action: 0, state: 8\n",
      "tensor([ 0.6705, -0.3288, -0.0725,  0.1612,  0.3510,  0.4498, -0.1174, -0.6009],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1936 is -102500, loss is -0.06409934783547615\n",
      "[0.71440524 0.28559476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.37302240935654757, 0.618465971672076, 0.7842447189622159, 0.1942018755986905], Action prob: [0.7120969  0.28790304], Action: 0, state: 8\n",
      "[0.7120969  0.28790304]\n",
      "Sensor: [0.43936792799613694, 0.32785758293878225, 0.1895708155134349, 0.52731598874914], Action prob: [0.7116957  0.28830436], Action: 1, state: 8\n",
      "[0.7116957  0.28830436]\n",
      "Sensor: [0.4138948298793803, 0.61924232159534, 0.22169709799004417, 0.4517306679745785], Action prob: [0.71279585 0.28720412], Action: 0, state: 8\n",
      "[0.71279585 0.28720412]\n",
      "Sensor: [0.35700098466663727, 0.38476467090357586, 0.22875253091950687, 0.3006232396135342], Action prob: [0.71178925 0.28821072], Action: 0, state: 8\n",
      "[0.71178925 0.28821072]\n",
      "Sensor: [0.5685732234227179, 0.6240491415740236, 0.1941851810875591, 0.5130548635105012], Action prob: [0.7110043  0.28899568], Action: 0, state: 8\n",
      "[0.7110043  0.28899568]\n",
      "Sensor: [0.3408676293723816, 0.5888637639255117, 0.5185205234687071, 0.2539811885042304], Action prob: [0.7130901  0.28690988], Action: 1, state: 8\n",
      "[0.7130901  0.28690988]\n",
      "Sensor: [0.6034247459766768, 0.6820454917892538, 0.2502450242851715, 0.30209997812376593], Action prob: [0.7118482  0.28815177], Action: 1, state: 8\n",
      "[0.7118482  0.28815177]\n",
      "Sensor: [0.5437009108442952, 0.4203605664447292, 0.21545664784794458, 0.2404216882008409], Action prob: [0.7100466 0.2899534], Action: 0, state: 8\n",
      "tensor([ 0.6026,  1.4017,  0.2001,  0.0409, -0.1130, -0.8168, -1.3432, -0.4737],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1944 is -126500, loss is 0.06267706171696205\n",
      "[0.7100466 0.2899534]\n",
      "Sensor: [0.3391948627491593, 0.3520958001801015, 0.21683047509064754, 0.25916445965679985], Action prob: [0.7038852  0.29611486], Action: 0, state: 8\n",
      "[0.7038852  0.29611486]\n",
      "Sensor: [0.5283923812696297, 0.6473942554126528, 0.21856762357352433, 0.23869324556298713], Action prob: [0.70708334 0.2929166 ], Action: 0, state: 8\n",
      "[0.70708334 0.2929166 ]\n",
      "Sensor: [0.35121424468420176, 0.6490037001657954, 0.2729074390977807, 0.5913506865799694], Action prob: [0.7087608  0.29123917], Action: 1, state: 8\n",
      "[0.7087608  0.29123917]\n",
      "Sensor: [0.6525314682292889, 0.3629533038540084, 0.23265165480971675, 0.2858896176189844], Action prob: [0.70638996 0.29361004], Action: 1, state: 8\n",
      "[0.70638996 0.29361004]\n",
      "Sensor: [0.3625497014219492, 0.6209961828168371, 0.2138932657692846, 0.3068098746551139], Action prob: [0.7068029 0.2931971], Action: 0, state: 0\n",
      "[0.7068029 0.2931971]\n",
      "Sensor: [0.3977322470174268, 0.5818608105386311, 0.24392420741547868, 0.21691974519041074], Action prob: [0.7071698  0.29283026], Action: 0, state: 0\n",
      "[0.7071698  0.29283026]\n",
      "Sensor: [0.3789575315313601, 0.6757869609250687, 0.2639518347066756, 0.18766192598988282], Action prob: [0.7077751  0.29222488], Action: 0, state: 0\n",
      "[0.7077751  0.29222488]\n",
      "Sensor: [0.31941855856304446, 0.6630549395588088, 0.22264514743345998, 0.5758726710460024], Action prob: [0.7081954  0.29180458], Action: 0, state: 0\n",
      "tensor([ 0.7652,  0.3210, -0.1221, -1.4086, -0.2861, -0.1962, -0.1133, -0.0253],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1952 is -130500, loss is 0.133177895459213\n",
      "[0.7081954  0.29180458]\n",
      "Sensor: [0.4004994029836667, 0.5472632858033808, 0.22160567461458594, 0.6520341358617352], Action prob: [0.69808835 0.30191168], Action: 0, state: 0\n",
      "[0.69808835 0.30191168]\n",
      "Sensor: [0.35220318299107173, 0.6097600512037015, 0.20901663664233733, 0.2867078882339689], Action prob: [0.70106316 0.2989368 ], Action: 0, state: 1\n",
      "[0.70106316 0.2989368 ]\n",
      "Sensor: [0.3585997737232239, 0.6450922571227059, 0.23683901313431566, 0.21621880891237097], Action prob: [0.7016667  0.29833332], Action: 0, state: 1\n",
      "[0.7016667  0.29833332]\n",
      "Sensor: [0.30153656940821977, 0.6589607814044947, 0.19201636300833222, 0.2583216517008694], Action prob: [0.701408   0.29859194], Action: 0, state: 2\n",
      "[0.701408   0.29859194]\n",
      "Sensor: [0.32947930141402126, 0.6604104652480259, 0.23423203532195538, 0.20857606920730504], Action prob: [0.70123965 0.29876032], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "[0.70123965 0.29876032]\n",
      "Sensor: [0.3243288630496694, 0.6453267889245238, 0.2165957155429975, 0.18836945122711093], Action prob: [0.7008999 0.2991001], Action: 0, state: 2\n",
      "[0.7008999 0.2991001]\n",
      "Sensor: [0.33481054591790077, 0.5601875072341369, 0.1738033507519403, 0.24764789134592577], Action prob: [0.70015377 0.29984623], Action: 0, state: 2\n",
      "[0.70015377 0.29984623]\n",
      "Sensor: [0.3029786597138894, 0.6710551715364137, 0.23649286789435564, 0.22914754655495895], Action prob: [0.70067275 0.2993273 ], Action: 0, state: 2\n",
      "tensor([-0.6782, -0.3894, -0.1276,  0.0842,  0.6870,  0.1582,  0.3131,  0.4537],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1960 is -125200, loss is -0.0626269745333415\n",
      "[0.70067275 0.2993273 ]\n",
      "Sensor: [0.36599774566028487, 0.6669382717827843, 0.21831821359783427, 0.20314708589039684], Action prob: [0.6941459  0.30585414], Action: 0, state: 2\n",
      "[0.6941459  0.30585414]\n",
      "Sensor: [0.3545793333713035, 0.6752398264222654, 0.21723921648740657, 0.21715748474427418], Action prob: [0.69632334 0.30367666], Action: 0, state: 3\n",
      "[0.69632334 0.30367666]\n",
      "Sensor: [0.5955554208012707, 0.618092961186694, 0.22824341294353243, 0.2217853375010086], Action prob: [0.69506437 0.3049356 ], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -2200\n",
      "[0.69506437 0.3049356 ]\n",
      "Sensor: [0.377139207122065, 0.6601827345270542, 0.22355283336133727, 0.24879520581026568], Action prob: [0.69481426 0.3051857 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "[0.69481426 0.3051857 ]\n",
      "Sensor: [0.38665421892544716, 0.6926472380683291, 0.21589077504355922, 0.2194341185235808], Action prob: [0.69481677 0.30518326], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.69481677 0.30518326]\n",
      "Sensor: [0.30921859578320793, 0.6049743934113778, 0.19050171121571396, 0.28603035151051054], Action prob: [0.69471693 0.30528316], Action: 0, state: 0\n",
      "[0.69471693 0.30528316]\n",
      "Sensor: [0.35187036778908104, 0.6689230482753215, 0.18597346987847543, 0.19473483506210215], Action prob: [0.6947869  0.30521306], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.6947869  0.30521306]\n",
      "Sensor: [0.33313811245129715, 0.6754770960879087, 0.2226269131338308, 0.20521193490885858], Action prob: [0.6949668  0.30503315], Action: 0, state: 0\n",
      "tensor([ 0.1936,  0.4303,  2.0798, -0.6615, -1.3505, -0.4085, -0.4324, -0.1294],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1968 is -125000, loss is 0.034803676813835234\n",
      "[0.6949668  0.30503315]\n",
      "Sensor: [0.4032948853266398, 0.6472935899518485, 0.22247195934359013, 0.2928455915193571], Action prob: [0.6891409  0.31085908], Action: 0, state: 0\n",
      "[0.6891409  0.31085908]\n",
      "Sensor: [0.40014145012936325, 0.613210351780287, 0.18969967479381503, 0.24512911315398103], Action prob: [0.69014484 0.30985516], Action: 0, state: 1\n",
      "[0.69014484 0.30985516]\n",
      "Sensor: [0.38670041278432427, 0.6279053404699996, 0.272404088781872, 0.24462685991296315], Action prob: [0.69014806 0.30985197], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.69014806 0.30985197]\n",
      "Sensor: [0.36338707380237345, 0.6230684457928654, 0.2310623698174093, 0.2421407835504309], Action prob: [0.68950135 0.31049863], Action: 0, state: 1\n",
      "[0.68950135 0.31049863]\n",
      "Sensor: [0.3141072038629214, 0.6443880600672102, 0.24563421579701344, 0.2830574574811557], Action prob: [0.68936104 0.31063893], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "[0.68936104 0.31063893]\n",
      "Sensor: [0.3837673640643017, 0.6313430170715597, 0.21537843467886195, 0.21259223574237784], Action prob: [0.68883765 0.31116232], Action: 0, state: 1\n",
      "[0.68883765 0.31116232]\n",
      "Sensor: [0.39380941952101856, 0.6855169015522887, 0.18076831734135188, 0.3086675919036566], Action prob: [0.6883538  0.31164628], Action: 0, state: 1\n",
      "[0.6883538  0.31164628]\n",
      "Sensor: [0.36287630978978413, 0.6435412149676899, 0.17021974476416393, 0.2288631184769071], Action prob: [0.68821985 0.31178015], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "tensor([-0.7612, -0.3372,  0.0222, -0.0323,  0.7788,  0.0542,  0.3070,  1.5829],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1976 is -121100, loss is -0.2017847940106576\n",
      "[0.68821985 0.31178015]\n",
      "Sensor: [0.37140335350299003, 0.6590613874036313, 0.24350142382814963, 0.18472843573540493], Action prob: [0.69033337 0.30966663], Action: 0, state: 1\n",
      "[0.69033337 0.30966663]\n",
      "Sensor: [0.39202857725692886, 0.6611867015967015, 0.21652833851538636, 0.17021521063943135], Action prob: [0.6919903  0.30800974], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6919903  0.30800974]\n",
      "Sensor: [0.4205110966946144, 0.6601936673528395, 0.22692193867933735, 0.2826601057539815], Action prob: [0.6916353  0.30836475], Action: 0, state: 0\n",
      "[0.6916353  0.30836475]\n",
      "Sensor: [0.3799189855587202, 0.6690937291042042, 0.20450382900377198, 0.2723946722428855], Action prob: [0.6911075  0.30889246], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6911075  0.30889246]\n",
      "Sensor: [0.33676257891754036, 0.6516126934638169, 0.22280830099743726, 0.273399874609805], Action prob: [0.6909286  0.30907145], Action: 0, state: 0\n",
      "[0.6909286  0.30907145]\n",
      "Sensor: [0.38655717204212453, 0.613221364323719, 0.18605871845564867, 0.2682142804543431], Action prob: [0.69031906 0.3096809 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.69031906 0.3096809 ]\n",
      "Sensor: [0.3487584193771006, 0.6053472000623381, 0.21134366634828428, 0.30700542294111544], Action prob: [0.69021505 0.30978498], Action: 0, state: 0\n",
      "[0.69021505 0.30978498]\n",
      "Sensor: [0.3489909754075624, 0.6256124007650075, 0.20358182387600102, 0.24028609217546607], Action prob: [0.69026154 0.30973843], Action: 0, state: 0\n",
      "tensor([-0.6372, -1.2100, -0.2462, -0.0433,  0.0946,  0.8854,  0.3701,  0.5200],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1984 is -114800, loss is 0.03334108913158301\n",
      "[0.69026154 0.30973843]\n",
      "Sensor: [0.3293673018431431, 0.6860247363241198, 0.2155569718291179, 0.22004311172636354], Action prob: [0.6905822  0.30941778], Action: 0, state: 1\n",
      "[0.6905822  0.30941778]\n",
      "Sensor: [0.3795984022445747, 0.674005341730359, 0.2164915888226524, 0.2506703468388628], Action prob: [0.69232666 0.30767336], Action: 0, state: 1\n",
      "[0.69232666 0.30767336]\n",
      "Sensor: [0.3554069658958777, 0.6093171503672336, 0.24290665106351006, 0.2339486755993962], Action prob: [0.6921563  0.30784366], Action: 0, state: 2\n",
      "[0.6921563  0.30784366]\n",
      "Sensor: [0.41055868288964587, 0.611726754706347, 0.2275063948220788, 0.2016316411351372], Action prob: [0.6912245 0.3087755], Action: 0, state: 3\n",
      "[0.6912245 0.3087755]\n",
      "Sensor: [0.36886530385445665, 0.5087860753492028, 0.19946850250491605, 0.25198539282089355], Action prob: [0.69026446 0.30973554], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.69026446 0.30973554]\n",
      "Sensor: [0.36211415819864057, 0.657156103748708, 0.22171499587643315, 0.23141993195145763], Action prob: [0.6903965 0.3096035], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.6903965 0.3096035]\n",
      "Sensor: [0.34952195567111866, 0.6528242852619451, 0.23702934739100262, 0.24806803747827036], Action prob: [0.6906127  0.30938727], Action: 0, state: 1\n",
      "[0.6906127  0.30938727]\n",
      "Sensor: [0.33447286307559726, 0.6048581864988047, 0.2429046772263743, 0.2849099411933243], Action prob: [0.69069284 0.30930716], Action: 0, state: 1\n",
      "tensor([-0.7162, -0.3856, -0.1214,  0.0211,  0.5013,  0.7250,  0.3174,  0.4953],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 1992 is -109600, loss is -0.10459561259588318\n",
      "[0.69069284 0.30930716]\n",
      "Sensor: [0.38630207359690644, 0.6309251732226813, 0.1881543296897869, 0.26507674994844194], Action prob: [0.69228864 0.30771136], Action: 0, state: 1\n",
      "[0.69228864 0.30771136]\n",
      "Sensor: [0.35986282256965785, 0.6275942110297714, 0.24287998203051778, 0.23259292710184074], Action prob: [0.6946601  0.30533987], Action: 0, state: 2\n",
      "[0.6946601  0.30533987]\n",
      "Sensor: [0.3383767507181239, 0.5301563702295615, 0.2188516844066364, 0.30490721462873926], Action prob: [0.69444346 0.30555657], Action: 0, state: 3\n",
      "[0.69444346 0.30555657]\n",
      "Sensor: [0.40936774787914465, 0.659101084476419, 0.27838051931817415, 0.22824418903465607], Action prob: [0.6941578  0.30584225], Action: 0, state: 3\n",
      "[0.6941578  0.30584225]\n",
      "Sensor: [0.41083888739885777, 0.6702027689658681, 0.2354008297874559, 0.2634563212918304], Action prob: [0.693559   0.30644098], Action: 0, state: 3\n",
      "[0.693559   0.30644098]\n",
      "Sensor: [0.41656735475626283, 0.6148224569747059, 0.25646020767003314, 0.19252417801443025], Action prob: [0.6931295  0.30687046], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1200\n",
      "[0.6931295  0.30687046]\n",
      "Sensor: [0.3556881747144624, 0.6408821741373635, 0.2281019023728637, 0.24334341704666793], Action prob: [0.69314754 0.3068525 ], Action: 0, state: 2\n",
      "[0.69314754 0.3068525 ]\n",
      "Sensor: [0.38051014525846594, 0.6434680228769746, 0.21642177495253997, 0.22371065755696284], Action prob: [0.6931181  0.30688193], Action: 0, state: 2\n",
      "tensor([-0.7546, -0.3398, -0.1082,  0.0920,  0.2764,  1.4267,  0.0849,  0.2988],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2000 is -106400, loss is -0.12201995771707722\n",
      "[0.6931181  0.30688193]\n",
      "Sensor: [0.35093775484849343, 0.7009196001305765, 0.22582543452259377, 0.24744508144544036], Action prob: [0.69756866 0.30243126], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.69756866 0.30243126]\n",
      "Sensor: [0.3783289022125696, 0.5925232208673471, 0.23764864618359713, 0.2321198276560489], Action prob: [0.6997991  0.30020094], Action: 0, state: 1\n",
      "[0.6997991  0.30020094]\n",
      "Sensor: [0.3992452272833303, 0.6389664836229533, 0.2152687041348423, 0.21682863616085415], Action prob: [0.69970006 0.30029994], Action: 0, state: 2\n",
      "[0.69970006 0.30029994]\n",
      "Sensor: [0.3749320623053375, 0.6156732203335488, 0.21392974260050804, 0.26198198631743636], Action prob: [0.6990053  0.30099472], Action: 0, state: 3\n",
      "[0.6990053  0.30099472]\n",
      "Sensor: [0.3415087055927174, 0.6710798382560808, 0.420615201590281, 0.25204258130754387], Action prob: [0.69965386 0.30034614], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.69965386 0.30034614]\n",
      "Sensor: [0.46464696491694013, 0.7114947093167046, 0.5490253762250564, 0.25907035248793137], Action prob: [0.69991124 0.30008876], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.69991124 0.30008876]\n",
      "Sensor: [0.4238493522034761, 0.6367631493374983, 0.1912751534527074, 0.21089005745524475], Action prob: [0.6984894 0.3015106], Action: 0, state: 1\n",
      "[0.6984894 0.3015106]\n",
      "Sensor: [0.35540064846883007, 0.645157263520694, 0.19138774710142914, 0.2991909448220853], Action prob: [0.6983602  0.30163974], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "tensor([-2.1226, -0.4572, -0.1434,  0.0382,  0.7062,  1.0013,  0.2550,  1.5023],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2008 is -102800, loss is -0.09747292593968407\n",
      "[0.6983602  0.30163974]\n",
      "Sensor: [0.3422302964169123, 0.6336750900317707, 0.18586351207639457, 0.23434208824827787], Action prob: [0.70308477 0.2969152 ], Action: 0, state: 1\n",
      "[0.70308477 0.2969152 ]\n",
      "Sensor: [0.3625838763860856, 0.6992334672225355, 0.20584176506481666, 0.24653210837711484], Action prob: [0.707112   0.29288793], Action: 0, state: 1\n",
      "[0.707112   0.29288793]\n",
      "Sensor: [0.35289754016522146, 0.6464024715356487, 0.22642454308810026, 0.34265894590034834], Action prob: [0.7077348  0.29226515], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.7077348  0.29226515]\n",
      "Sensor: [0.24878922590282493, 0.6322797874229938, 0.2496714059442289, 0.2674909251984551], Action prob: [0.7078298 0.2921702], Action: 0, state: 1\n",
      "[0.7078298 0.2921702]\n",
      "Sensor: [0.32247151110891964, 0.6001184272727915, 0.23666790094964366, 0.2925514739271915], Action prob: [0.7070718  0.29292822], Action: 0, state: 2\n",
      "[0.7070718  0.29292822]\n",
      "Sensor: [0.36608208867934494, 0.6565644301773372, 0.23151396136755303, 0.2835770209510817], Action prob: [0.7066612  0.29333878], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.7066612  0.29333878]\n",
      "Sensor: [0.3837866048742512, 0.726618045351805, 0.23154485392090857, 0.2457343215820978], Action prob: [0.7067238  0.29327625], Action: 0, state: 1\n",
      "[0.7067238  0.29327625]\n",
      "Sensor: [0.34724573497631156, 0.6369313910032504, 0.228515779524044, 0.22289538975435655], Action prob: [0.7064916  0.29350838], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "tensor([-0.6331, -0.3615, -0.5197, -0.0491,  0.1178,  0.9453,  0.3332,  1.6745],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2016 is -98300, loss is -0.18842189596143769\n",
      "[0.7064916  0.29350838]\n",
      "Sensor: [0.32855577218101517, 0.647257152362551, 0.1950587617607585, 0.3240644654373658], Action prob: [0.7124226  0.28757745], Action: 0, state: 0\n",
      "[0.7124226  0.28757745]\n",
      "Sensor: [0.37103816188490724, 0.641422219023485, 0.19172383555368683, 0.23765403090360157], Action prob: [0.71707577 0.28292423], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.71707577 0.28292423]\n",
      "Sensor: [0.3408174228807715, 0.6248506508408485, 0.22728746607978376, 0.23964996716129847], Action prob: [0.71803784 0.28196213], Action: 0, state: 0\n",
      "[0.71803784 0.28196213]\n",
      "Sensor: [0.31291618300773233, 0.6463803064771956, 0.20473398926317124, 0.22892277422627272], Action prob: [0.71798056 0.28201944], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.71798056 0.28201944]\n",
      "Sensor: [0.3570058177783861, 0.6442884810947251, 0.19694998101592542, 0.2555016787735454], Action prob: [0.7175264  0.28247368], Action: 0, state: 0\n",
      "[0.7175264  0.28247368]\n",
      "Sensor: [0.3076386084051657, 0.6250251309598404, 0.24358985463254823, 0.25808690059775163], Action prob: [0.7175599  0.28244016], Action: 0, state: 0\n",
      "[0.7175599  0.28244016]\n",
      "Sensor: [0.37831789103611024, 0.6225017880619412, 0.24072531257278282, 0.2477007566299419], Action prob: [0.71722454 0.28277543], Action: 0, state: 0\n",
      "[0.71722454 0.28277543]\n",
      "Sensor: [0.3703511182862151, 0.6660471830096966, 0.2324879844240854, 0.2454877117803549], Action prob: [0.7172817 0.2827183], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "tensor([-0.5879, -0.8358, -0.2161,  0.1753, -0.0868,  0.1545,  0.3646,  2.0403],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2024 is -94500, loss is -0.1260188260168459\n",
      "[0.7172817 0.2827183]\n",
      "Sensor: [0.34871106053917217, 0.6502709399220493, 0.24436651837102688, 0.2240000346822134], Action prob: [0.7225084  0.27749163], Action: 0, state: 0\n",
      "[0.7225084  0.27749163]\n",
      "Sensor: [0.40119535906552445, 0.5885047867268781, 0.21533573135333617, 0.2402641698025988], Action prob: [0.72811574 0.27188435], Action: 0, state: 1\n",
      "[0.72811574 0.27188435]\n",
      "Sensor: [0.39286888903904643, 0.6592997827109983, 0.23366569453205097, 0.24036994263105937], Action prob: [0.7298561 0.270144 ], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7298561 0.270144 ]\n",
      "Sensor: [0.3889851524216644, 0.5907284239697819, 0.23176528599735013, 0.26343377154900705], Action prob: [0.72961587 0.2703841 ], Action: 0, state: 1\n",
      "[0.72961587 0.2703841 ]\n",
      "Sensor: [0.34997285798661104, 0.6850258814966192, 0.1732742859279302, 0.2747600638457133], Action prob: [0.7298895  0.27011043], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.7298895  0.27011043]\n",
      "Sensor: [0.3901772074456537, 0.6215573073226973, 0.20744352506885022, 0.25514906729422576], Action prob: [0.7295298  0.27047023], Action: 0, state: 0\n",
      "[0.7295298  0.27047023]\n",
      "Sensor: [0.3640393974285827, 0.6548000042990962, 0.239442734327339, 0.4079350106693541], Action prob: [0.7299754  0.27002463], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.7299754  0.27002463]\n",
      "Sensor: [0.3647156283603229, 0.6877013890946858, 0.22384978117844861, 0.23188327957798024], Action prob: [0.7302147  0.26978528], Action: 0, state: 0\n",
      "tensor([-0.6472, -0.3515, -0.0964,  0.1324,  1.3919,  0.1307,  1.3378,  0.1488],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2032 is -91000, loss is -0.2558158063565722\n",
      "[0.7302147  0.26978528]\n",
      "Sensor: [0.3789511254242986, 0.6284114020099321, 0.2480875307962134, 0.2671234435079354], Action prob: [0.7365466 0.2634534], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7365466 0.2634534]\n",
      "Sensor: [0.35323582808524157, 0.6595674201719683, 0.24179875890999836, 0.2455627418873095], Action prob: [0.7450231 0.2549769], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.7450231 0.2549769]\n",
      "Sensor: [0.38515864176344383, 0.7076376276029488, 0.24474864256240506, 0.2650097452613568], Action prob: [0.7477675  0.25223246], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.7477675  0.25223246]\n",
      "Sensor: [0.4009755885575155, 0.6267300734722816, 0.24686749602185268, 0.21956112558613272], Action prob: [0.74742687 0.25257313], Action: 0, state: 0\n",
      "[0.74742687 0.25257313]\n",
      "Sensor: [0.3258250896425962, 0.652234997643081, 0.21140750097481828, 0.21139605741427647], Action prob: [0.7473872  0.25261283], Action: 0, state: 1\n",
      "[0.7473872  0.25261283]\n",
      "Sensor: [0.3725321573447856, 0.6366191347456318, 0.21176887898136693, 0.2728386135456265], Action prob: [0.7471807  0.25281933], Action: 0, state: 1\n",
      "[0.7471807  0.25281933]\n",
      "Sensor: [0.376918710635649, 0.6721156842843027, 0.23122918178108492, 0.22805182508478594], Action prob: [0.7473238  0.25267616], Action: 0, state: 1\n",
      "[0.7473238  0.25267616]\n",
      "Sensor: [0.36594411835956253, 0.6105720237581653, 0.2409335730409706, 0.31786193454522277], Action prob: [0.7472281  0.25277194], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "tensor([-1.7170, -1.0099, -1.0222, -0.2172, -0.0065,  0.1831,  0.3518,  2.3241],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2040 is -86600, loss is 0.1392194928962761\n",
      "[0.7472281  0.25277194]\n",
      "Sensor: [0.41520365195085246, 0.6614281016447539, 0.2401923181860105, 0.2518563327674476], Action prob: [0.7467659  0.25323412], Action: 0, state: 1\n",
      "[0.7467659  0.25323412]\n",
      "Sensor: [0.37182103014994017, 0.6659343742378709, 0.1744768329024864, 0.23211545723602556], Action prob: [0.75654846 0.24345157], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.75654846 0.24345157]\n",
      "Sensor: [0.3339056927221818, 0.6278148441226713, 0.23150956888854918, 0.27360932106258995], Action prob: [0.76008415 0.23991589], Action: 0, state: 0\n",
      "[0.76008415 0.23991589]\n",
      "Sensor: [0.3199625519984923, 0.6530003128311045, 0.2034649746668223, 0.2715858299939385], Action prob: [0.7611949  0.23880509], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7611949  0.23880509]\n",
      "Sensor: [0.3927190252445891, 0.5864442088209351, 0.18454601404115561, 0.6205959536478176], Action prob: [0.76143223 0.23856783], Action: 0, state: 0\n",
      "[0.76143223 0.23856783]\n",
      "Sensor: [0.5694039077269328, 0.6540312757009374, 0.25248889006602226, 0.32877543499802175], Action prob: [0.7604987  0.23950131], Action: 0, state: 9\n",
      "[0.7604987  0.23950131]\n",
      "Sensor: [0.43363543078399336, 0.4323112301865804, 0.14526205679393478, 0.23624358757930683], Action prob: [0.75798106 0.24201897], Action: 0, state: 9\n",
      "[0.75798106 0.24201897]\n",
      "Sensor: [0.5708184518844884, 0.7115389561552148, 0.23391859911682128, 0.2398552567939155], Action prob: [0.75874513 0.24125487], Action: 0, state: 9\n",
      "tensor([-0.4586, -0.2697, -0.0474,  1.5337,  0.4530,  0.1654, -0.0844, -0.3141],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2048 is -88200, loss is -0.12223751996111698\n",
      "[0.75874513 0.24125487]\n",
      "Sensor: [0.3211148169207925, 0.6273491397132125, 0.5477503668013507, 0.2596979249656096], Action prob: [0.76092094 0.23907901], Action: 1, state: 9\n",
      "[0.76092094 0.23907901]\n",
      "Sensor: [0.37779666949062357, 0.6611560178193847, 0.4927081478055705, 0.24006633508668687], Action prob: [0.7734034  0.22659661], Action: 1, state: 9\n",
      "[0.7734034  0.22659661]\n",
      "Sensor: [0.5962374102161171, 0.6432569210285178, 0.20304805387223412, 0.22814491488652575], Action prob: [0.7750332  0.22496681], Action: 0, state: 9\n",
      "[0.7750332  0.22496681]\n",
      "Sensor: [0.6184255916486324, 0.6215717321916474, 0.23484985986925944, 0.24522487920498953], Action prob: [0.7750567  0.22494327], Action: 0, state: 9\n",
      "[0.7750567  0.22494327]\n",
      "Sensor: [0.27528381778286803, 0.625331055551211, 0.49618455336196743, 0.30626179058783015], Action prob: [0.77829033 0.22170968], Action: 0, state: 9\n",
      "[0.77829033 0.22170968]\n",
      "Sensor: [0.32928608376520085, 0.5839957142755221, 0.17578828730863816, 0.5359693922011315], Action prob: [0.7788672 0.2211328], Action: 0, state: 9\n",
      "[0.7788672 0.2211328]\n",
      "Sensor: [0.2649432964352774, 0.42876795234678494, 0.4552281296967149, 0.2539772088997408], Action prob: [0.77835506 0.22164492], Action: 0, state: 9\n",
      "[0.77835506 0.22164492]\n",
      "Sensor: [0.5851259527248512, 0.5640125363209139, 0.23059553897220417, 0.22766905344031285], Action prob: [0.77578056 0.22421943], Action: 1, state: 9\n",
      "tensor([ 2.4796,  1.6781,  0.1374,  0.0176, -0.0694, -0.1703, -0.2532, -2.0864],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2056 is -96200, loss is -0.21669105796117621\n",
      "[0.77578056 0.22421943]\n",
      "Sensor: [0.3438353756097188, 0.3990862400089873, 0.18881814451349646, 0.5655025652696231], Action prob: [0.77319884 0.2268012 ], Action: 1, state: 9\n",
      "[0.77319884 0.2268012 ]\n",
      "Sensor: [0.28770800673347485, 0.39271308557309953, 0.22924093884146168, 0.22098537312870192], Action prob: [0.78560174 0.2143983 ], Action: 1, state: 9\n",
      "[0.78560174 0.2143983 ]\n",
      "Sensor: [0.32045597573025963, 0.4195160165724741, 0.21884813542815512, 0.2656761522480803], Action prob: [0.79045635 0.20954369], Action: 1, state: 9\n",
      "[0.79045635 0.20954369]\n",
      "Sensor: [0.3732401717965293, 0.641626561684484, 0.5067195108150815, 0.30393104107108954], Action prob: [0.7962328  0.20376723], Action: 0, state: 9\n",
      "[0.7962328  0.20376723]\n",
      "Sensor: [0.32817248551899375, 0.6310037448181626, 0.7727616374290418, 0.1933219921338699], Action prob: [0.8003709  0.19962913], Action: 0, state: 9\n",
      "[0.8003709  0.19962913]\n",
      "Sensor: [0.5282412582327073, 0.5677107834209558, 0.1951146817605044, 0.24264306508034522], Action prob: [0.7970683  0.20293175], Action: 1, state: 9\n",
      "[0.7970683  0.20293175]\n",
      "Sensor: [0.6087784910459995, 0.5965169021508765, 0.19452811523511845, 0.20227852268437813], Action prob: [0.7950631  0.20493692], Action: 0, state: 9\n",
      "[0.7950631  0.20493692]\n",
      "Sensor: [0.3482214971127158, 0.6097927878900338, 0.2547259346580411, 0.5507708333318049], Action prob: [0.7978935  0.20210646], Action: 1, state: 9\n",
      "tensor([ 2.5575,  1.7139,  0.9138,  0.0311, -0.0589, -1.1729, -0.2514, -2.1299],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2064 is -104200, loss is -0.2004035371338207\n",
      "[0.7978935  0.20210646]\n",
      "Sensor: [0.5387219045542538, 0.6429802718083957, 0.22665753113328377, 0.24668672606066708], Action prob: [0.7907864  0.20921366], Action: 0, state: 9\n",
      "[0.7907864  0.20921366]\n",
      "Sensor: [0.5443229773469311, 0.3912332589737119, 0.20617306163617793, 0.24047148825362638], Action prob: [0.8028467  0.19715326], Action: 0, state: 9\n",
      "[0.8028467  0.19715326]\n",
      "Sensor: [0.3422501193737681, 0.689300536082892, 0.5137056824183691, 0.5559990625527351], Action prob: [0.8162622  0.18373786], Action: 0, state: 9\n",
      "[0.8162622  0.18373786]\n",
      "Sensor: [0.3643946747184121, 0.39859239665860074, 0.21965700401039537, 0.25557078591731325], Action prob: [0.8147215  0.18527853], Action: 0, state: 9\n",
      "[0.8147215  0.18527853]\n",
      "Sensor: [0.3866196845357225, 0.6439838651836151, 0.22017223961181331, 0.5416819428031597], Action prob: [0.8173607 0.1826393], Action: 1, state: 9\n",
      "[0.8173607 0.1826393]\n",
      "Sensor: [0.37801926080694054, 0.3687173561724638, 0.26158461323221444, 0.1711122645435496], Action prob: [0.8139273 0.1860727], Action: 0, state: 9\n",
      "[0.8139273 0.1860727]\n",
      "Sensor: [0.3624082736427319, 0.3587831448675275, 0.21844051564871148, 0.2880353576088051], Action prob: [0.8117837  0.18821628], Action: 1, state: 9\n",
      "[0.8117837  0.18821628]\n",
      "Sensor: [0.3585891103676711, 0.39421299096846085, 0.22713209306072218, 0.2950842126359891], Action prob: [0.81154644 0.18845363], Action: 0, state: 9\n",
      "tensor([ 0.3900,  0.2373,  0.1292,  0.0210, -0.5178, -0.1468, -1.7530, -0.2839],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2072 is -112200, loss is 0.24049102859955002\n",
      "[0.81154644 0.18845363]\n",
      "Sensor: [0.35632430712749025, 0.7108017319934506, 0.23519433891822047, 0.5825538413969216], Action prob: [0.80544496 0.19455498], Action: 1, state: 9\n",
      "[0.80544496 0.19455498]\n",
      "Sensor: [0.612184668038414, 0.7109461148263783, 0.2268361733312757, 0.26119506205961346], Action prob: [0.81808525 0.18191475], Action: 0, state: 9\n",
      "[0.81808525 0.18191475]\n",
      "Sensor: [0.3507274156443288, 0.37394590050701004, 0.23919054016455366, 0.22419371298636392], Action prob: [0.818575   0.18142492], Action: 0, state: 9\n",
      "[0.818575   0.18142492]\n",
      "Sensor: [0.3849850012348305, 0.3702315749411498, 0.2790894421748045, 0.23016955175675088], Action prob: [0.8174076  0.18259239], Action: 0, state: 9\n",
      "[0.8174076  0.18259239]\n",
      "Sensor: [0.3652444784124344, 0.5835933553343821, 0.4759181227758296, 0.30594842999031635], Action prob: [0.82132995 0.17867008], Action: 0, state: 9\n",
      "[0.82132995 0.17867008]\n",
      "Sensor: [0.3644386292461807, 0.5806090450839848, 0.49317638073084025, 0.2668361899268682], Action prob: [0.8233118  0.17668816], Action: 1, state: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8233118  0.17668816]\n",
      "Sensor: [0.38041041862344965, 0.6445577549088508, 0.21561244538158444, 0.24115000323333302], Action prob: [0.8226097  0.17739028], Action: 0, state: 0\n",
      "[0.8226097  0.17739028]\n",
      "Sensor: [0.3327955163061249, 0.6291373273272932, 0.2162326059939933, 0.30449991999826875], Action prob: [0.82303643 0.1769636 ], Action: 0, state: 0\n",
      "tensor([ 3.1280,  0.2167,  0.0851, -0.0394, -0.1436, -2.1422, -0.1603, -0.0779],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2080 is -114200, loss is -0.10829081981807487\n",
      "[0.82303643 0.1769636 ]\n",
      "Sensor: [0.2828455843379616, 0.5100533088522546, 0.20553264822316267, 0.2528468472832661], Action prob: [0.80921537 0.1907847 ], Action: 0, state: 0\n",
      "[0.80921537 0.1907847 ]\n",
      "Sensor: [0.38894507047172183, 0.6317954338500757, 0.2362782168324813, 0.2654619521957623], Action prob: [0.8247282  0.17527187], Action: 0, state: 0\n",
      "[0.8247282  0.17527187]\n",
      "Sensor: [0.3015531267264148, 0.6400935994276828, 0.22494749744108095, 0.1987646902139904], Action prob: [0.82872313 0.1712769 ], Action: 0, state: 0\n",
      "[0.82872313 0.1712769 ]\n",
      "Sensor: [0.32504629583683287, 0.6700891258698742, 0.20926176690464612, 0.2828160067014156], Action prob: [0.82966995 0.17033   ], Action: 0, state: 1\n",
      "[0.82966995 0.17033   ]\n",
      "Sensor: [0.33269833158508055, 0.6534239982077267, 0.18896349320536746, 0.31347050546342353], Action prob: [0.82941294 0.17058702], Action: 0, state: 1\n",
      "[0.82941294 0.17058702]\n",
      "Sensor: [0.3569895905277286, 0.6648788917010846, 0.2210470633935888, 0.25821945483390396], Action prob: [0.82890064 0.17109932], Action: 0, state: 1\n",
      "[0.82890064 0.17109932]\n",
      "Sensor: [0.3790632326707489, 0.6706382398163337, 0.20726259316043374, 0.3314542548375441], Action prob: [0.8289349  0.17106514], Action: 0, state: 1\n",
      "[0.8289349  0.17106514]\n",
      "Sensor: [0.3535579285734326, 0.644472665842749, 0.21700695400653597, 0.27262370610065056], Action prob: [0.8285782 0.1714219], Action: 0, state: 1\n",
      "tensor([-0.3661, -0.2141, -0.1022, -0.0153,  0.0619,  0.1309,  0.1942,  0.2510],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2088 is -106800, loss is 0.0074745994237273156\n",
      "[0.8285782 0.1714219]\n",
      "Sensor: [0.31089864189403615, 0.6583709290085126, 0.19886484857821687, 0.19017268913819116], Action prob: [0.8196227  0.18037732], Action: 0, state: 1\n",
      "[0.8196227  0.18037732]\n",
      "Sensor: [0.4007734389350969, 0.5727410173170712, 0.1942107165848374, 0.2617034599260443], Action prob: [0.8313054  0.16869459], Action: 0, state: 2\n",
      "[0.8313054  0.16869459]\n",
      "Sensor: [0.36931636081641167, 0.6244082186454578, 0.20566883611293144, 0.27318330132610086], Action prob: [0.8336266  0.16637339], Action: 0, state: 2\n",
      "[0.8336266  0.16637339]\n",
      "Sensor: [0.3708830009944447, 0.6484023770632162, 0.19968466030476315, 0.2311818009582946], Action prob: [0.83294946 0.16705057], Action: 0, state: 2\n",
      "[0.83294946 0.16705057]\n",
      "Sensor: [0.35715572658318284, 0.6303018158161128, 0.19084422966374323, 0.23710600233425572], Action prob: [0.83198786 0.16801216], Action: 0, state: 2\n",
      "[0.83198786 0.16801216]\n",
      "Sensor: [0.35809834784583006, 0.5840641898176305, 0.2022200438453722, 0.2736524993960634], Action prob: [0.8311863  0.16881369], Action: 0, state: 3\n",
      "[0.8311863  0.16881369]\n",
      "Sensor: [0.3824970165678251, 0.39492889584291907, 0.21678951755529022, 0.23809669462316996], Action prob: [0.8279282  0.17207178], Action: 0, state: 3\n",
      "[0.8279282  0.17207178]\n",
      "Sensor: [0.7843673027220534, 0.6348904991863105, 0.22717163713616131, 0.2451269156609606], Action prob: [0.82688636 0.17311372], Action: 1, state: 8\n",
      "tensor([-0.3600, -0.1976, -0.0725,  0.0358,  0.1356,  0.1937,  0.2497, -0.3585],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2096 is -108600, loss is 0.0467175624961834\n",
      "[0.82688636 0.17311372]\n",
      "Sensor: [0.5598562131368828, 0.6345906006679798, 0.19688936461972603, 0.22778000076040428], Action prob: [0.8239097  0.17609024], Action: 0, state: 8\n",
      "[0.8239097  0.17609024]\n",
      "Sensor: [0.3193958955487493, 0.6589163373961462, 0.47242886687522245, 0.24642796318677784], Action prob: [0.8391623  0.16083771], Action: 0, state: 8\n",
      "[0.8391623  0.16083771]\n",
      "Sensor: [0.6515448169901763, 0.6447735134247028, 0.2192348832937994, 0.23917024894258887], Action prob: [0.83580923 0.16419074], Action: 0, state: 8\n",
      "[0.83580923 0.16419074]\n",
      "Sensor: [0.34250352697729414, 0.3460053471925652, 0.18884148867207937, 0.31567806076776117], Action prob: [0.8314983  0.16850172], Action: 0, state: 8\n",
      "[0.8314983  0.16850172]\n",
      "Sensor: [0.396261655039367, 0.3916071699702248, 0.24891237008818587, 0.1937247701796196], Action prob: [0.82872826 0.1712717 ], Action: 0, state: 8\n",
      "[0.82872826 0.1712717 ]\n",
      "Sensor: [0.37831352454020134, 0.624956616521138, 0.21811677320488695, 0.5633311258301335], Action prob: [0.83368653 0.16631347], Action: 0, state: 8\n",
      "[0.83368653 0.16631347]\n",
      "Sensor: [0.6094913041655666, 0.40623683383790377, 0.1911355537938635, 0.28383578222485994], Action prob: [0.82918584 0.17081416], Action: 0, state: 8\n",
      "[0.82918584 0.17081416]\n",
      "Sensor: [0.5526825017974316, 0.6649706687613584, 0.24900573674887416, 0.23266837191566017], Action prob: [0.83072853 0.16927145], Action: 0, state: 8\n",
      "tensor([ 0.3187,  0.1960,  0.0943,  0.0183, -0.0639, -0.1269, -0.2044, -0.2603],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2104 is -132600, loss is 0.003521910426628593\n",
      "[0.83072853 0.16927145]\n",
      "Sensor: [0.32099705962978625, 0.5355527574986215, 0.46053473433926534, 0.4787601888890086], Action prob: [0.83644664 0.1635533 ], Action: 1, state: 8\n",
      "[0.83644664 0.1635533 ]\n",
      "Sensor: [0.6101363040451284, 0.6355967175885849, 0.20566838110519883, 0.23070016853282677], Action prob: [0.839971   0.16002905], Action: 0, state: 8\n",
      "[0.839971   0.16002905]\n",
      "Sensor: [0.44593306103064545, 0.37028811670385287, 0.17831144358000728, 0.1944576899539275], Action prob: [0.83492607 0.16507393], Action: 0, state: 8\n",
      "[0.83492607 0.16507393]\n",
      "Sensor: [0.5935409020827724, 0.5906934959987413, 0.22119447691757768, 0.49949798955298924], Action prob: [0.83616775 0.16383223], Action: 1, state: 8\n",
      "[0.83616775 0.16383223]\n",
      "Sensor: [0.3805705326657005, 0.6421611439574689, 0.2497719863279154, 0.5511193920643567], Action prob: [0.8394066  0.16059345], Action: 0, state: 8\n",
      "[0.8394066  0.16059345]\n",
      "Sensor: [0.3492487503325009, 0.3838605921355794, 0.19499512295915108, 0.2611858524567928], Action prob: [0.83435655 0.16564348], Action: 0, state: 8\n",
      "[0.83435655 0.16564348]\n",
      "Sensor: [0.6370155442430049, 0.6144294117262861, 0.17646128522691218, 0.2620464591417331], Action prob: [0.8329072  0.16709282], Action: 0, state: 8\n",
      "[0.8329072  0.16709282]\n",
      "Sensor: [0.3414573646505896, 0.654270423426671, 0.20092229550151033, 0.5368640006008689], Action prob: [0.8379667  0.16203332], Action: 0, state: 8\n",
      "tensor([ 3.1301,  0.1844,  0.0994,  0.1571, -0.0544, -0.1298, -0.2017, -0.2395],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2112 is -156600, loss is -0.3682130767699848\n",
      "[0.8379667  0.16203332]\n",
      "Sensor: [0.37767157940127544, 0.6884389527152865, 0.4922954722864111, 0.24504146809828203], Action prob: [0.8491286  0.15087132], Action: 0, state: 8\n",
      "[0.8491286  0.15087132]\n",
      "Sensor: [0.38124096005264385, 0.6716300127445521, 0.25570339862114405, 0.5405530233264636], Action prob: [0.85906446 0.14093551], Action: 0, state: 8\n",
      "[0.85906446 0.14093551]\n",
      "Sensor: [0.34759732288504, 0.39415028891545945, 0.25964281971243736, 0.2516019462524176], Action prob: [0.8503175 0.1496825], Action: 0, state: 8\n",
      "[0.8503175 0.1496825]\n",
      "Sensor: [0.38851997547563677, 0.37763269632064544, 0.23313891130091646, 0.2820303749459628], Action prob: [0.84482193 0.15517807], Action: 0, state: 8\n",
      "[0.84482193 0.15517807]\n",
      "Sensor: [0.3559462494369448, 0.3284110819681315, 0.20867708946596494, 0.4669430557418193], Action prob: [0.84355634 0.15644364], Action: 0, state: 8\n",
      "[0.84355634 0.15644364]\n",
      "Sensor: [0.3181384732125237, 0.3763079629561056, 0.2272217977697179, 0.2629506429156546], Action prob: [0.8424542  0.15754585], Action: 0, state: 8\n",
      "[0.8424542  0.15754585]\n",
      "Sensor: [0.368669328761322, 0.6273930264987005, 0.2451038661704135, 0.5796775973440946], Action prob: [0.8487085  0.15129143], Action: 0, state: 8\n",
      "[0.8487085  0.15129143]\n",
      "Sensor: [0.4130639015048343, 0.2179163112619027, 0.21574377080737758, 0.21607101810800894], Action prob: [0.84120744 0.15879261], Action: 1, state: 8\n",
      "tensor([ 0.2783,  0.1699,  0.0936,  0.0167, -0.0525, -0.1212, -0.1697, -2.5296],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2120 is -180600, loss is 0.2893378147972701\n",
      "[0.84120744 0.15879261]\n",
      "Sensor: [0.3891317437241746, 0.3707763100232268, 0.20257200778630174, 0.25423994699233776], Action prob: [0.8464168  0.15358321], Action: 0, state: 8\n",
      "[0.8464168  0.15358321]\n",
      "Sensor: [0.33865989065230223, 0.398666306613028, 0.21546849063581666, 0.2037591794851989], Action prob: [0.8529351  0.14706486], Action: 0, state: 8\n",
      "[0.8529351  0.14706486]\n",
      "Sensor: [0.2818070892497171, 0.34744688194750684, 0.2352247595397772, 0.4766237098234989], Action prob: [0.85311276 0.14688727], Action: 0, state: 8\n",
      "[0.85311276 0.14688727]\n",
      "Sensor: [0.3625906377982468, 0.3841482382792608, 0.237643062480611, 0.25404329939323345], Action prob: [0.84832436 0.15167561], Action: 0, state: 8\n",
      "[0.84832436 0.15167561]\n",
      "Sensor: [0.6210765709648124, 0.3744126763758633, 0.19908817475197557, 0.3185020528605248], Action prob: [0.84409934 0.15590063], Action: 0, state: 8\n",
      "[0.84409934 0.15590063]\n",
      "Sensor: [0.3716035308026444, 0.37955778500184306, 0.5597051119597619, 0.24805521591471044], Action prob: [0.84686357 0.1531364 ], Action: 1, state: 8\n",
      "[0.84686357 0.1531364 ]\n",
      "Sensor: [0.3211876667424902, 0.3365051054574893, 0.2513190210700831, 0.29005214288609427], Action prob: [0.84508586 0.15491417], Action: 0, state: 8\n",
      "[0.84508586 0.15491417]\n",
      "Sensor: [0.5682445205801765, 0.3819384109318485, 0.197241278642813, 0.20881987422565673], Action prob: [0.84242535 0.15757464], Action: 0, state: 8\n",
      "tensor([ 0.2803,  0.1745,  0.0959,  0.0165, -0.0595, -1.2747, -0.1761, -0.2396],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2128 is -204600, loss is 0.14784608498935736\n",
      "[0.84242535 0.15757464]\n",
      "Sensor: [0.39500196352575456, 0.6356080358909134, 0.21241065572493473, 0.6033974812469883], Action prob: [0.8602242 0.1397758], Action: 0, state: 8\n",
      "[0.8602242 0.1397758]\n",
      "Sensor: [0.3863712293294076, 0.65367999703154, 0.5273196373849713, 0.28741974839158896], Action prob: [0.8636418  0.13635826], Action: 0, state: 8\n",
      "[0.8636418  0.13635826]\n",
      "Sensor: [0.38923906778789996, 0.31970692776028636, 0.5004059491710932, 0.23919024511430698], Action prob: [0.85282385 0.1471762 ], Action: 0, state: 8\n",
      "[0.85282385 0.1471762 ]\n",
      "Sensor: [0.43681798751334827, 0.6367677422010054, 0.5373134081188151, 0.26365235330551134], Action prob: [0.8521771  0.14782289], Action: 0, state: 8\n",
      "[0.8521771  0.14782289]\n",
      "Sensor: [0.566086551303133, 0.6143332087883293, 0.20888578425051174, 0.22680690219438454], Action prob: [0.84786737 0.15213262], Action: 0, state: 8\n",
      "[0.84786737 0.15213262]\n",
      "Sensor: [0.3850740299689731, 0.39574687081585835, 0.2249157182734316, 0.2508097870372506], Action prob: [0.8451484  0.15485163], Action: 0, state: 8\n",
      "[0.8451484  0.15485163]\n",
      "Sensor: [0.3836429134882039, 0.6307114272619436, 0.24205399082768708, 0.5220783975030531], Action prob: [0.8509052 0.1490948], Action: 0, state: 8\n",
      "[0.8509052 0.1490948]\n",
      "Sensor: [0.3792086993108455, 0.3693727577255536, 0.20642698057621858, 0.22177564679723616], Action prob: [0.84593827 0.15406175], Action: 0, state: 8\n",
      "tensor([ 0.2567,  0.1647,  0.0954,  0.0186, -0.0594, -0.1202, -0.1682, -0.2299],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2136 is -228600, loss is 0.005279791178605473\n",
      "[0.84593827 0.15406175]\n",
      "Sensor: [0.33921782639016573, 0.3670963047567992, 0.20081908621011285, 0.24363891869064408], Action prob: [0.85184634 0.14815362], Action: 0, state: 8\n",
      "[0.85184634 0.14815362]\n",
      "Sensor: [0.7781511852427119, 0.611113894080817, 0.2634194991407511, 0.23535692668288824], Action prob: [0.85464627 0.1453537 ], Action: 0, state: 8\n",
      "[0.85464627 0.1453537 ]\n",
      "Sensor: [0.5736791393892144, 0.5993283551957297, 0.2839451015450386, 0.2199682056101436], Action prob: [0.852584 0.147416], Action: 0, state: 8\n",
      "[0.852584 0.147416]\n",
      "Sensor: [0.39036132809644847, 0.6748832751729874, 0.18098735154791606, 0.5363006677332138], Action prob: [0.85478634 0.14521363], Action: 0, state: 8\n",
      "[0.85478634 0.14521363]\n",
      "Sensor: [0.3383390603424859, 0.3727373438223772, 0.2045047475144899, 0.27022842235726124], Action prob: [0.8483671  0.15163295], Action: 0, state: 8\n",
      "[0.8483671  0.15163295]\n",
      "Sensor: [0.34887159111503874, 0.3255723788812129, 0.21907599240970832, 0.24636657084834973], Action prob: [0.84469897 0.15530103], Action: 1, state: 8\n",
      "[0.84469897 0.15530103]\n",
      "Sensor: [0.5812769973800019, 0.6156556125729629, 0.21169351108338888, 0.21883604921798425], Action prob: [0.84629476 0.15370527], Action: 0, state: 8\n",
      "[0.84629476 0.15370527]\n",
      "Sensor: [0.35700072009110817, 0.39026233079240513, 0.20787840389800635, 0.2576989155375041], Action prob: [0.84589016 0.15410984], Action: 0, state: 8\n",
      "tensor([ 0.2704,  0.1656,  0.0875,  0.0168, -0.0535, -1.3215, -0.1821, -0.2292],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2144 is -252600, loss is 0.1557617629902383\n",
      "[0.84589016 0.15410984]\n",
      "Sensor: [0.33984785353634533, 0.3894381773223267, 0.2048079693991598, 0.20906987122220144], Action prob: [0.8511606  0.14883947], Action: 0, state: 8\n",
      "[0.8511606  0.14883947]\n",
      "Sensor: [0.3730737275898587, 0.34949014159431324, 0.2213675171963767, 0.23225138007501225], Action prob: [0.85179186 0.14820819], Action: 0, state: 8\n",
      "[0.85179186 0.14820819]\n",
      "Sensor: [0.34828551468711255, 0.6473909039035654, 0.5074681358852385, 0.2829674945094879], Action prob: [0.85506576 0.14493427], Action: 0, state: 8\n",
      "[0.85506576 0.14493427]\n",
      "Sensor: [0.5665300704040128, 0.4092404921989513, 0.20934619708225946, 0.22492908050727772], Action prob: [0.8455768  0.15442319], Action: 0, state: 8\n",
      "[0.8455768  0.15442319]\n",
      "Sensor: [0.6724337828759992, 0.5721061219434358, 0.2788997049399169, 0.23290019720146132], Action prob: [0.8441472  0.15585282], Action: 0, state: 8\n",
      "[0.8441472  0.15585282]\n",
      "Sensor: [0.36959022534807084, 0.3293182377589973, 0.21274895981745157, 0.25089871506476624], Action prob: [0.84217924 0.15782076], Action: 0, state: 8\n",
      "[0.84217924 0.15782076]\n",
      "Sensor: [0.5332665807219181, 0.43530094944007464, 0.22829537687539, 0.22901955185827422], Action prob: [0.8420776  0.15792237], Action: 0, state: 8\n",
      "[0.8420776  0.15792237]\n",
      "Sensor: [0.44861918622406854, 0.655858967615613, 0.7497386927943664, 0.23934348331138267], Action prob: [0.85034823 0.14965175], Action: 0, state: 8\n",
      "tensor([ 0.2713,  0.1764,  0.0933,  0.0127, -0.0610, -0.1221, -0.1850, -0.2168],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2152 is -276600, loss is 0.003904385910707641\n",
      "[0.85034823 0.14965175]\n",
      "Sensor: [0.3325469775731263, 0.34232312373105656, 0.19762608634927697, 0.19800915059878552], Action prob: [0.84930825 0.15069176], Action: 0, state: 8\n",
      "[0.84930825 0.15069176]\n",
      "Sensor: [0.6011778733792789, 0.47544096173713946, 0.19042424075136852, 0.27564014347840915], Action prob: [0.8504685  0.14953153], Action: 0, state: 8\n",
      "[0.8504685  0.14953153]\n",
      "Sensor: [0.32949233894314245, 0.646540344254141, 0.1780468386950748, 0.5729215810515862], Action prob: [0.8543793  0.14562067], Action: 0, state: 8\n",
      "[0.8543793  0.14562067]\n",
      "Sensor: [0.37918281812527943, 0.3604406031882396, 0.24766525363107114, 0.2766421811221509], Action prob: [0.8461398  0.15386021], Action: 0, state: 8\n",
      "[0.8461398  0.15386021]\n",
      "Sensor: [0.5496942753013023, 0.5954976600382602, 0.20770813790490392, 0.24136257819756587], Action prob: [0.84419316 0.15580688], Action: 0, state: 8\n",
      "[0.84419316 0.15580688]\n",
      "Sensor: [0.5896560849289165, 0.6224446190219477, 0.2139739294061733, 0.2627016809643568], Action prob: [0.84447265 0.15552735], Action: 1, state: 8\n",
      "[0.84447265 0.15552735]\n",
      "Sensor: [0.38295869101588115, 0.7201729763435317, 0.2092981453048225, 0.5066674671674474], Action prob: [0.85022396 0.14977604], Action: 0, state: 8\n",
      "[0.85022396 0.14977604]\n",
      "Sensor: [0.5869273442322157, 0.6503792016131884, 0.20479620949935198, 0.26836231284700524], Action prob: [0.84679127 0.15320875], Action: 0, state: 8\n",
      "tensor([ 0.2753,  0.1743,  0.0932,  0.0175, -0.0597, -1.3756, -0.1702, -0.2324],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2160 is -300600, loss is 0.15969956039242358\n",
      "[0.84679127 0.15320875]\n",
      "Sensor: [0.35725038455113806, 0.6097600681349054, 0.1846766071541427, 0.606601554037603], Action prob: [0.85784155 0.14215843], Action: 0, state: 8\n",
      "[0.85784155 0.14215843]\n",
      "Sensor: [0.5608343456899206, 0.6419145099969057, 0.22821419329347428, 0.2863245195070899], Action prob: [0.8511323 0.1488677], Action: 0, state: 8\n",
      "[0.8511323 0.1488677]\n",
      "Sensor: [0.3918436582364335, 0.4047334220524534, 0.19818280785860334, 0.23072061344033004], Action prob: [0.8431654  0.15683462], Action: 0, state: 8\n",
      "[0.8431654  0.15683462]\n",
      "Sensor: [0.32335261909103197, 0.40567803826114684, 0.20859088540753015, 0.23940159421902285], Action prob: [0.8401495  0.15985054], Action: 0, state: 8\n",
      "[0.8401495  0.15985054]\n",
      "Sensor: [0.5732594894735707, 0.4328207006543695, 0.18940355747765586, 0.29032813031868465], Action prob: [0.838131   0.16186893], Action: 0, state: 8\n",
      "[0.838131   0.16186893]\n",
      "Sensor: [0.33424728273464044, 0.6097986131347856, 0.19004431340201233, 0.519290523372301], Action prob: [0.84462667 0.15537336], Action: 0, state: 8\n",
      "[0.84462667 0.15537336]\n",
      "Sensor: [0.4022227720447651, 0.4110454811592369, 0.24015421778211452, 0.22932371635836518], Action prob: [0.8402969  0.15970306], Action: 0, state: 8\n",
      "[0.8402969  0.15970306]\n",
      "Sensor: [0.3707364629664795, 0.6312723596739019, 0.23216646666564789, 0.5471336471703008], Action prob: [0.84542245 0.15457758], Action: 0, state: 8\n",
      "tensor([ 0.2621,  0.1745,  0.0975,  0.0182, -0.0606, -0.1171, -0.1840, -0.2264],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2168 is -324600, loss is 0.004481716038619223\n",
      "[0.84542245 0.15457758]\n",
      "Sensor: [0.5734670025405307, 0.4077105413681522, 0.21848447591502254, 0.2722450073720722], Action prob: [0.84167    0.15833005], Action: 0, state: 8\n",
      "[0.84167    0.15833005]\n",
      "Sensor: [0.44530698358668014, 0.34906407457426236, 0.48800716233278835, 0.2188673385488853], Action prob: [0.8435911  0.15640892], Action: 1, state: 8\n",
      "[0.8435911  0.15640892]\n",
      "Sensor: [0.5886442654631118, 0.35721912872989275, 0.17094444853503632, 0.25869765480690243], Action prob: [0.8369763  0.16302371], Action: 0, state: 8\n",
      "[0.8369763  0.16302371]\n",
      "Sensor: [0.28402247763897587, 0.6889367691162827, 0.48775889822006924, 0.23600362337703912], Action prob: [0.8433859  0.15661407], Action: 0, state: 8\n",
      "[0.8433859  0.15661407]\n",
      "Sensor: [0.3947417605788564, 0.36001009860406036, 0.19815816935507205, 0.27408935224458103], Action prob: [0.83758056 0.16241944], Action: 0, state: 8\n",
      "[0.83758056 0.16241944]\n",
      "Sensor: [0.5651057447389625, 0.6608890991233599, 0.227214628985357, 0.2426184993854422], Action prob: [0.8385865  0.16141352], Action: 0, state: 8\n",
      "[0.8385865  0.16141352]\n",
      "Sensor: [0.5923834105514048, 0.6805944746456887, 0.2015094126283546, 0.27529689837263793], Action prob: [0.8395     0.16049998], Action: 0, state: 8\n",
      "[0.8395     0.16049998]\n",
      "Sensor: [0.3614778185704953, 0.5774495380097815, 0.2058241318701052, 0.5112948859120579], Action prob: [0.84252775 0.15747224], Action: 0, state: 8\n",
      "tensor([ 0.2888,  2.0818,  0.0993,  0.0213, -0.0573, -0.1289, -0.1891, -0.2312],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2176 is -348600, loss is -0.23559671806342253\n",
      "[0.84252775 0.15747224]\n",
      "Sensor: [0.5572738382896292, 0.6290923914474166, 0.20058983913103826, 0.21520231731207973], Action prob: [0.8462452 0.1537548], Action: 0, state: 8\n",
      "[0.8462452 0.1537548]\n",
      "Sensor: [0.38600418878561066, 0.30744506131326604, 0.17961355736848317, 0.26302649027855374], Action prob: [0.84454083 0.15545914], Action: 0, state: 8\n",
      "[0.84454083 0.15545914]\n",
      "Sensor: [0.39542872696011455, 0.38942299222222804, 0.25310359786204006, 0.2523346026958486], Action prob: [0.84198636 0.15801364], Action: 0, state: 8\n",
      "[0.84198636 0.15801364]\n",
      "Sensor: [0.3331682993191103, 0.34255460229192763, 0.172581599345411, 0.22733421137278487], Action prob: [0.83915955 0.16084047], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83915955 0.16084047]\n",
      "Sensor: [0.38988914745134684, 0.639101532470794, 0.5059580237471216, 0.24416080901460707], Action prob: [0.84455276 0.15544727], Action: 0, state: 8\n",
      "[0.84455276 0.15544727]\n",
      "Sensor: [0.3358353979323873, 0.3833019205728415, 0.2332449475769998, 0.20096191962511573], Action prob: [0.84035265 0.15964733], Action: 0, state: 8\n",
      "[0.84035265 0.15964733]\n",
      "Sensor: [0.6231665770426932, 0.6572831470615174, 0.23601243079992898, 0.28138107384194583], Action prob: [0.8414369  0.15856308], Action: 0, state: 8\n",
      "[0.8414369  0.15856308]\n",
      "Sensor: [0.37811306119180366, 0.6160073536316647, 0.21526204068514393, 0.5460687787716172], Action prob: [0.8459334  0.15406664], Action: 0, state: 8\n",
      "tensor([ 0.2781,  0.1871,  0.1002,  0.0186, -0.0516, -0.1224, -0.1858, -0.2252],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2184 is -372600, loss is 0.00011617194829129443\n",
      "[0.8459334  0.15406664]\n",
      "Sensor: [0.3197527038481056, 0.6180898533536457, 0.48968623897300234, 0.4335255064701436], Action prob: [0.8560999  0.14390004], Action: 0, state: 8\n",
      "[0.8560999  0.14390004]\n",
      "Sensor: [0.61602879772275, 0.667903101632283, 0.22667113715263407, 0.2290808680811893], Action prob: [0.8499398  0.15006018], Action: 0, state: 8\n",
      "[0.8499398  0.15006018]\n",
      "Sensor: [0.34165744578994994, 0.6093614306650057, 0.19616625696216586, 0.5666763876808767], Action prob: [0.8509063 0.1490937], Action: 1, state: 8\n",
      "[0.8509063 0.1490937]\n",
      "Sensor: [0.3798113705959526, 0.617533337302958, 0.20283717666406964, 0.22361409927906906], Action prob: [0.8466838 0.1533162], Action: 0, state: 0\n",
      "[0.8466838 0.1533162]\n",
      "Sensor: [0.30144238714134997, 0.6664272488534434, 0.23920695048125878, 0.2854150775882616], Action prob: [0.8479075  0.15209256], Action: 0, state: 0\n",
      "[0.8479075  0.15209256]\n",
      "Sensor: [0.29173478645680295, 0.6249160020890292, 0.19101983012871881, 0.23712827518423596], Action prob: [0.8472923  0.15270773], Action: 0, state: 0\n",
      "[0.8472923  0.15270773]\n",
      "Sensor: [0.4152515614154352, 0.40980770272667755, 0.24006474826674018, 0.23187364219476184], Action prob: [0.84353095 0.15646908], Action: 1, state: 9\n",
      "[0.84353095 0.15646908]\n",
      "Sensor: [0.622874474920089, 0.6962119959557249, 0.22024654447953115, 0.2497080894985064], Action prob: [0.8447881  0.15521187], Action: 0, state: 9\n",
      "tensor([ 0.3675,  0.0718, -2.2504, -0.1182, -0.0405,  0.0257, -0.3909, -0.0956],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2192 is -378600, loss is 0.30383064678772637\n",
      "[0.8447881  0.15521187]\n",
      "Sensor: [0.6080252652876336, 0.6678401999986411, 0.21219971021811354, 0.2683874345336279], Action prob: [0.8439903  0.15600972], Action: 0, state: 9\n",
      "[0.8439903  0.15600972]\n",
      "Sensor: [0.4159000578050642, 0.6763618254409296, 0.5265116117453057, 0.2505781528619937], Action prob: [0.8495314  0.15046859], Action: 0, state: 9\n",
      "[0.8495314  0.15046859]\n",
      "Sensor: [0.33260012547098156, 0.36990699460414833, 0.24891203538419432, 0.2304459367379012], Action prob: [0.8422635  0.15773645], Action: 0, state: 9\n",
      "[0.8422635  0.15773645]\n",
      "Sensor: [0.5967002290855454, 0.5930221220689751, 0.2299348896996911, 0.23846061438815871], Action prob: [0.8405636  0.15943639], Action: 1, state: 9\n",
      "[0.8405636  0.15943639]\n",
      "Sensor: [0.3348702217962789, 0.6799097328959752, 0.21687467922265408, 0.2366855039638153], Action prob: [0.8438471  0.15615286], Action: 0, state: 0\n",
      "[0.8438471  0.15615286]\n",
      "Sensor: [0.3224317171753402, 0.6643344415225353, 0.23954812803939726, 0.275665540792171], Action prob: [0.84537256 0.15462743], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.84537256 0.15462743]\n",
      "Sensor: [0.3433989012188483, 0.7037345532644698, 0.2103549641835783, 0.30009489505248754], Action prob: [0.84603775 0.15396222], Action: 0, state: 0\n",
      "[0.84603775 0.15396222]\n",
      "Sensor: [0.37356203744156297, 0.6288617971538506, 0.19950344181962743, 0.2910443176476597], Action prob: [0.8447378  0.15526216], Action: 0, state: 0\n",
      "tensor([ 0.2991,  0.0836, -0.1129, -3.1818, -0.1314,  0.1488,  0.0128,  0.1283],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2200 is -377600, loss is 0.3441650826199825\n",
      "[0.8447378  0.15526216]\n",
      "Sensor: [0.1710498642060922, 0.6404050580700106, 0.2412453782537249, 0.22844083937581672], Action prob: [0.84153974 0.15846029], Action: 0, state: 0\n",
      "[0.84153974 0.15846029]\n",
      "Sensor: [0.3690284776474978, 0.6126091022535826, 0.27226499969247686, 0.27825837949896554], Action prob: [0.8397505  0.16024952], Action: 0, state: 0\n",
      "[0.8397505  0.16024952]\n",
      "Sensor: [0.3688338994381592, 0.6530198184212246, 0.20972457053596144, 0.2786874455757783], Action prob: [0.8365545  0.16344553], Action: 0, state: 0\n",
      "[0.8365545  0.16344553]\n",
      "Sensor: [0.3685111586124618, 0.6910117262756824, 0.19291619218760825, 0.2712442891285331], Action prob: [0.8355573 0.1644427], Action: 0, state: 0\n",
      "[0.8355573 0.1644427]\n",
      "Sensor: [0.3643258041504449, 0.6949667012193245, 0.23207542510775694, 0.22829203470784737], Action prob: [0.8354973  0.16450267], Action: 0, state: 0\n",
      "[0.8354973  0.16450267]\n",
      "Sensor: [0.2816435575451085, 0.6159651155059488, 0.2133621122826023, 0.28232290788766756], Action prob: [0.8357847  0.16421528], Action: 0, state: 0\n",
      "[0.8357847  0.16421528]\n",
      "Sensor: [0.3504321525276961, 0.6798868400678615, 0.17147950381351973, 0.285756523981498], Action prob: [0.83594304 0.16405702], Action: 0, state: 0\n",
      "[0.83594304 0.16405702]\n",
      "Sensor: [0.3637061481015282, 0.6599251691918467, 0.19915018387662242, 0.17926961109168743], Action prob: [0.8350684  0.16493157], Action: 0, state: 0\n",
      "tensor([-0.2877, -0.1905, -0.1017, -0.0177,  0.0590,  0.1299,  0.1898,  0.2459],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2208 is -369700, loss is -0.0033738011984867818\n",
      "[0.8350684  0.16493157]\n",
      "Sensor: [0.3655239674689385, 0.6166697500386497, 0.1965587009053158, 0.2386340402224125], Action prob: [0.8300524  0.16994764], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.8300524  0.16994764]\n",
      "Sensor: [0.3301830058694684, 0.6051841536902595, 0.24470963278636604, 0.2649458018969322], Action prob: [0.8307133  0.16928676], Action: 0, state: 0\n",
      "[0.8307133  0.16928676]\n",
      "Sensor: [0.3342999358616756, 0.6294495636775466, 0.218645535372445, 0.340549066290876], Action prob: [0.8284543 0.1715457], Action: 0, state: 0\n",
      "[0.8284543 0.1715457]\n",
      "Sensor: [0.3554035180815769, 0.6179555202945702, 0.24271096392261035, 0.21533170848319633], Action prob: [0.82604903 0.17395096], Action: 0, state: 1\n",
      "[0.82604903 0.17395096]\n",
      "Sensor: [0.35900689075630027, 0.6505670077457294, 0.2223471274139675, 0.22031954277971144], Action prob: [0.82596564 0.17403437], Action: 0, state: 1\n",
      "[0.82596564 0.17403437]\n",
      "Sensor: [0.3713767230996261, 0.6397235318541982, 0.24356767508578037, 0.25830576447861164], Action prob: [0.82648116 0.1735188 ], Action: 0, state: 2\n",
      "[0.82648116 0.1735188 ]\n",
      "Sensor: [0.3372563841036756, 0.6885267512022468, 0.22956519887645677, 0.22586283727350495], Action prob: [0.82729554 0.17270443], Action: 0, state: 2\n",
      "[0.82729554 0.17270443]\n",
      "Sensor: [0.3718256666363226, 0.6457703132604319, 0.2419432300936379, 0.2754554250953702], Action prob: [0.82717854 0.17282143], Action: 0, state: 2\n",
      "tensor([-1.3963, -0.2983, -0.1617, -0.0503,  0.0532,  0.1368,  0.2099,  0.2776],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2216 is -364700, loss is 0.15364519904620932\n",
      "[0.82717854 0.17282143]\n",
      "Sensor: [0.32673919672418383, 0.6407307862336791, 0.24128364462163981, 0.2804217585290332], Action prob: [0.8224985  0.17750148], Action: 0, state: 2\n",
      "[0.8224985  0.17750148]\n",
      "Sensor: [0.3776580695403593, 0.5669113708853214, 0.21684956230875221, 0.27417945157247425], Action prob: [0.8197644  0.18023564], Action: 0, state: 2\n",
      "[0.8197644  0.18023564]\n",
      "Sensor: [0.46504816800070803, 0.6299889237237575, 0.23383829178500687, 0.22459885464467413], Action prob: [0.8159427  0.18405734], Action: 0, state: 3\n",
      "[0.8159427  0.18405734]\n",
      "Sensor: [0.318898840175044, 0.6077947890320349, 0.18577268020067145, 0.20668287889676296], Action prob: [0.8153077  0.18469234], Action: 0, state: 3\n",
      "[0.8153077  0.18469234]\n",
      "Sensor: [0.5452440311022667, 0.6668611426499517, 0.21033218249854382, 0.19663033378451372], Action prob: [0.8142381  0.18576191], Action: 0, state: 8\n",
      "[0.8142381  0.18576191]\n",
      "Sensor: [0.36869920441011783, 0.3404155220513291, 0.23998048521757176, 0.22126932439219335], Action prob: [0.81242764 0.18757237], Action: 0, state: 8\n",
      "[0.81242764 0.18757237]\n",
      "Sensor: [0.30639161689056826, 0.684551478094941, 0.2030522898747251, 0.5235263565484948], Action prob: [0.81812686 0.18187317], Action: 0, state: 8\n",
      "[0.81812686 0.18187317]\n",
      "Sensor: [0.41746848663086367, 0.6223933908690404, 0.22550434621109827, 0.7843743114418696], Action prob: [0.819325   0.18067506], Action: 0, state: 8\n",
      "tensor([ 0.0918,  0.1543,  0.1913,  0.2256,  0.0485, -0.1042, -0.2359, -0.3548],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2224 is -377900, loss is -0.0020933429822944175\n",
      "[0.819325   0.18067506]\n",
      "Sensor: [0.4015831278647465, 0.3403456925028379, 0.1931138821728099, 0.2869160250477496], Action prob: [0.8090532  0.19094686], Action: 0, state: 8\n",
      "[0.8090532  0.19094686]\n",
      "Sensor: [0.3990733158158818, 0.3310597954057688, 0.244134212146155, 0.24324121503614865], Action prob: [0.80726457 0.19273548], Action: 0, state: 8\n",
      "[0.80726457 0.19273548]\n",
      "Sensor: [0.5262372164974125, 0.6336482267747501, 0.23710468026597675, 0.21843693319060223], Action prob: [0.80591136 0.19408864], Action: 0, state: 8\n",
      "[0.80591136 0.19408864]\n",
      "Sensor: [0.3742602949654305, 0.6414707581399096, 0.14196227191150884, 0.533054485742638], Action prob: [0.80791545 0.19208455], Action: 0, state: 8\n",
      "[0.80791545 0.19208455]\n",
      "Sensor: [0.3868623715304257, 0.4115926230222159, 0.2133002611343525, 0.30685703935879893], Action prob: [0.8046346  0.19536541], Action: 0, state: 8\n",
      "[0.8046346  0.19536541]\n",
      "Sensor: [0.6505168847206307, 0.3947306822890247, 0.2130611932762898, 0.2810566196398206], Action prob: [0.8014442  0.19855584], Action: 0, state: 8\n",
      "[0.8014442  0.19855584]\n",
      "Sensor: [0.3743575350745372, 0.34108573644099927, 0.16753726490750598, 0.23222763978579217], Action prob: [0.80237335 0.1976266 ], Action: 0, state: 8\n",
      "[0.80237335 0.1976266 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.5357326966822546, 0.6362501707098019, 0.2439543179780853, 0.2491805487533771], Action prob: [0.805138   0.19486201], Action: 0, state: 8\n",
      "tensor([ 0.3592,  0.2378,  0.1214,  0.0250, -0.0688, -0.1601, -0.2318, -0.2986],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2232 is -401900, loss is 0.0019852359237844397\n",
      "[0.805138   0.19486201]\n",
      "Sensor: [0.3698120369442773, 0.37479571457762545, 0.17828832282401713, 0.22023464801249396], Action prob: [0.80223095 0.19776903], Action: 0, state: 8\n",
      "[0.80223095 0.19776903]\n",
      "Sensor: [0.5511364705390639, 0.6247186404107345, 0.2367060740772663, 0.27122439377565966], Action prob: [0.80157596 0.19842407], Action: 0, state: 8\n",
      "[0.80157596 0.19842407]\n",
      "Sensor: [0.362926828489484, 0.6395192335922572, 0.22369077090955042, 0.5380043513505951], Action prob: [0.8016661  0.19833392], Action: 1, state: 8\n",
      "[0.8016661  0.19833392]\n",
      "Sensor: [0.3714892143760482, 0.3398826918597266, 0.1973978340411848, 0.25466362060136066], Action prob: [0.79636884 0.20363115], Action: 0, state: 8\n",
      "[0.79636884 0.20363115]\n",
      "Sensor: [0.39536216091870147, 0.14344314372959296, 0.2062090814041769, 0.1806186979897042], Action prob: [0.7932431  0.20675689], Action: 0, state: 8\n",
      "[0.7932431  0.20675689]\n",
      "Sensor: [0.36853197494030066, 0.3578265517103506, 0.24566029023768907, 0.22145448099940454], Action prob: [0.7959132  0.20408674], Action: 0, state: 8\n",
      "[0.7959132  0.20408674]\n",
      "Sensor: [0.45175403247185797, 0.37328936019035214, 0.2143862183859127, 0.23753375390802445], Action prob: [0.7963054  0.20369458], Action: 0, state: 8\n",
      "[0.7963054  0.20369458]\n",
      "Sensor: [0.3769471862259948, 0.4243639038140852, 0.25215663461132043, 0.27462872460556365], Action prob: [0.7977559  0.20224416], Action: 0, state: 8\n",
      "tensor([ 0.3724,  0.2413,  0.9685,  0.0245, -0.0743, -0.1604, -0.2406, -0.3067],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2240 is -425900, loss is -0.10309078862935939\n",
      "[0.7977559  0.20224416]\n",
      "Sensor: [0.5538295837123397, 0.7104152523340009, 0.22716614279639954, 0.2576348038026656], Action prob: [0.7993988  0.20060118], Action: 0, state: 8\n",
      "[0.7993988  0.20060118]\n",
      "Sensor: [0.3150024574211868, 0.38351314807391135, 0.2467233289714979, 0.24417843740005404], Action prob: [0.7964949  0.20350505], Action: 0, state: 8\n",
      "[0.7964949  0.20350505]\n",
      "Sensor: [0.40661065824612036, 0.3816634021375783, 0.2190454544877494, 0.2917216226550299], Action prob: [0.793138   0.20686196], Action: 0, state: 8\n",
      "[0.793138   0.20686196]\n",
      "Sensor: [0.5585346552028579, 0.6343335240173599, 0.23915506173406215, 0.22236323665358684], Action prob: [0.79290414 0.20709586], Action: 0, state: 8\n",
      "[0.79290414 0.20709586]\n",
      "Sensor: [0.5061006759498305, 0.3777594865358669, 0.21672093689901814, 0.23940900387195824], Action prob: [0.79153043 0.20846951], Action: 0, state: 8\n",
      "[0.79153043 0.20846951]\n",
      "Sensor: [0.5915453573488544, 0.5530430247469718, 0.1970651540500288, 0.23741795800540472], Action prob: [0.7921976  0.20780243], Action: 0, state: 8\n",
      "[0.7921976  0.20780243]\n",
      "Sensor: [0.39827053256335565, 0.37253903845810754, 0.18339022206729014, 0.27606494817195093], Action prob: [0.7928997  0.20710032], Action: 0, state: 8\n",
      "[0.7928997  0.20710032]\n",
      "Sensor: [0.35764601092047427, 0.3935960328798369, 0.20575972075180352, 0.2484271083739115], Action prob: [0.7936508  0.20634918], Action: 0, state: 8\n",
      "tensor([ 0.3740,  0.2535,  0.1347,  0.0194, -0.0777, -0.1700, -0.2444, -0.3148],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2248 is -449900, loss is 0.003152270825077831\n",
      "[0.7936508  0.20634918]\n",
      "Sensor: [0.32115485991411724, 0.3789999469220554, 0.2153921820800848, 0.2513492572715766], Action prob: [0.7941725  0.20582746], Action: 0, state: 8\n",
      "[0.7941725  0.20582746]\n",
      "Sensor: [0.31587743872386287, 0.4035543866793737, 0.5233698290863504, 0.1898334529495118], Action prob: [0.79368174 0.20631821], Action: 0, state: 8\n",
      "[0.79368174 0.20631821]\n",
      "Sensor: [0.6001172167146834, 0.628512886422223, 0.43730032505127214, 0.2418013372962452], Action prob: [0.7904616  0.20953833], Action: 0, state: 8\n",
      "[0.7904616  0.20953833]\n",
      "Sensor: [0.3399215600564891, 0.36114530701148173, 0.17705102026930605, 0.2642588533117869], Action prob: [0.78919554 0.21080443], Action: 0, state: 8\n",
      "[0.78919554 0.21080443]\n",
      "Sensor: [0.5904144035314366, 0.612102286937032, 0.21713421619254078, 0.23332011647301248], Action prob: [0.78961736 0.21038269], Action: 1, state: 8\n",
      "[0.78961736 0.21038269]\n",
      "Sensor: [0.4148466493817477, 0.6174258522684893, 0.26080876629810407, 0.27224744590835465], Action prob: [0.7920001  0.20799989], Action: 0, state: 0\n",
      "[0.7920001  0.20799989]\n",
      "Sensor: [0.36258931337961564, 0.5953245586182816, 0.2486894254398398, 0.2763692989142187], Action prob: [0.7927364  0.20726357], Action: 0, state: 0\n",
      "[0.7927364  0.20726357]\n",
      "Sensor: [0.39118629005725514, 0.6833585981068291, 0.24883311532862226, 0.222394145013697], Action prob: [0.7930167  0.20698328], Action: 0, state: 0\n",
      "tensor([ 0.4634,  0.2649,  0.0752, -0.0910, -1.6445, -0.1962, -0.1540, -0.1197],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2256 is -457900, loss is 0.17524211131080017\n",
      "[0.7930167  0.20698328]\n",
      "Sensor: [0.34641491043825373, 0.6163642410823992, 0.22240549725348388, 0.23691687831166341], Action prob: [0.78958225 0.21041776], Action: 0, state: 0\n",
      "[0.78958225 0.21041776]\n",
      "Sensor: [0.3970228944678004, 0.6469295324214784, 0.21507131248834516, 0.2432673960117525], Action prob: [0.7876451  0.21235487], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7876451  0.21235487]\n",
      "Sensor: [0.3610492098031169, 0.6485972979050016, 0.1954146162016894, 0.24391719290270547], Action prob: [0.7860928  0.21390717], Action: 0, state: 0\n",
      "[0.7860928  0.21390717]\n",
      "Sensor: [0.37933971984388964, 0.66131129066251, 0.1867218696230362, 0.2308678690031576], Action prob: [0.78595364 0.21404636], Action: 0, state: 0\n",
      "[0.78595364 0.21404636]\n",
      "Sensor: [0.4175740501538149, 0.6045536985275997, 0.18948054007552434, 0.24577842343760628], Action prob: [0.7857611  0.21423887], Action: 0, state: 0\n",
      "[0.7857611  0.21423887]\n",
      "Sensor: [0.3573641989777944, 0.6156806239829693, 0.23122656561228108, 0.5953654736405174], Action prob: [0.78801036 0.21198963], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.78801036 0.21198963]\n",
      "Sensor: [0.3682940232019875, 0.614199347928565, 0.18515787115797167, 0.24002151123534468], Action prob: [0.78650826 0.21349168], Action: 0, state: 0\n",
      "[0.78650826 0.21349168]\n",
      "Sensor: [0.45735660861798744, 0.6405006816422135, 0.203839578089198, 0.32472620822555076], Action prob: [0.78627056 0.21372944], Action: 0, state: 0\n",
      "tensor([-0.3900, -1.6002, -0.1732, -0.0391,  0.0826,  1.2920,  0.2412,  0.3301],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2264 is -451000, loss is 0.032084468610614446\n",
      "[0.78627056 0.21372944]\n",
      "Sensor: [0.35937629914386343, 0.6616437743225096, 0.23241486626629862, 0.3040393157283113], Action prob: [0.78364426 0.21635568], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.78364426 0.21635568]\n",
      "Sensor: [0.3881363559297124, 0.6449049674181713, 0.21486111392996976, 0.25520632448053393], Action prob: [0.7810039  0.21899608], Action: 0, state: 0\n",
      "[0.7810039  0.21899608]\n",
      "Sensor: [0.2802518381903846, 0.675880221925111, 0.2086056888365041, 0.24315040622910647], Action prob: [0.78074557 0.21925445], Action: 0, state: 0\n",
      "[0.78074557 0.21925445]\n",
      "Sensor: [0.3602279775151877, 0.6917028654419244, 0.19234666717275947, 0.2176546821343133], Action prob: [0.7804591 0.2195409], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.7804591 0.2195409]\n",
      "Sensor: [0.3306914591377392, 0.6308415735403646, 0.21343191563854425, 0.3057503354349206], Action prob: [0.781211   0.21878903], Action: 0, state: 0\n",
      "[0.781211   0.21878903]\n",
      "Sensor: [0.37972636528228515, 0.6593717470180264, 0.2221669594646136, 0.2759303835063937], Action prob: [0.78121585 0.21878423], Action: 0, state: 0\n",
      "[0.78121585 0.21878423]\n",
      "Sensor: [0.3428511468115123, 0.6425060704600484, 0.22434667599563288, 0.3376777372084026], Action prob: [0.7817696  0.21823043], Action: 0, state: 0\n",
      "[0.7817696  0.21823043]\n",
      "Sensor: [0.3828915268697054, 0.6469937886940254, 0.19425991589341823, 0.2757850717289727], Action prob: [0.7812522 0.2187478], Action: 0, state: 0\n",
      "tensor([-2.0832, -0.3381, -0.1521,  0.0722,  0.0149,  0.1478,  0.2701,  0.3771],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2272 is -445000, loss is 0.21140564850170426\n",
      "[0.7812522 0.2187478]\n",
      "Sensor: [0.35687458032458697, 0.6800462322049045, 0.2240165979642722, 0.2490545058317511], Action prob: [0.7743837  0.22561629], Action: 0, state: 0\n",
      "[0.7743837  0.22561629]\n",
      "Sensor: [0.3558201774867358, 0.6472175983477217, 0.2340223823238734, 0.29137006622582085], Action prob: [0.77214676 0.2278532 ], Action: 0, state: 0\n",
      "[0.77214676 0.2278532 ]\n",
      "Sensor: [0.37347583384851313, 0.6182205175447371, 0.21100353148166637, 0.26542406153587406], Action prob: [0.7704477  0.22955228], Action: 0, state: 0\n",
      "[0.7704477  0.22955228]\n",
      "Sensor: [0.36449869782511224, 0.6508967245408759, 0.19241778818722505, 0.2721154981343942], Action prob: [0.7710647  0.22893532], Action: 0, state: 0\n",
      "[0.7710647  0.22893532]\n",
      "Sensor: [0.34586389704462833, 0.6132674543787292, 0.20625040083318874, 0.29043604624975317], Action prob: [0.77187854 0.22812143], Action: 0, state: 0\n",
      "[0.77187854 0.22812143]\n",
      "Sensor: [0.3459283233741473, 0.695043315744863, 0.21564781344003714, 0.22481243284913002], Action prob: [0.7726407  0.22735928], Action: 0, state: 1\n",
      "[0.7726407  0.22735928]\n",
      "Sensor: [0.36536463862248336, 0.645587518535101, 0.22353518211252346, 0.31608074894136867], Action prob: [0.77274644 0.22725348], Action: 0, state: 1\n",
      "[0.77274644 0.22725348]\n",
      "Sensor: [0.3758081882693084, 0.6551166520045715, 0.19789503440672704, 0.20702768361101623], Action prob: [0.7723009  0.22769913], Action: 0, state: 2\n",
      "tensor([-0.4403, -0.2869, -0.1480, -0.0199,  0.0961,  0.1865,  0.2716,  0.3358],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2280 is -437600, loss is 0.000655564183944933\n",
      "[0.7723009  0.22769913]\n",
      "Sensor: [0.4115666931321953, 0.6327772212120933, 0.21039781348157652, 0.2640000783506387], Action prob: [0.76524574 0.23475425], Action: 0, state: 2\n",
      "[0.76524574 0.23475425]\n",
      "Sensor: [0.3608216775874153, 0.6526688557022985, 0.2288614646840272, 0.25728615794106235], Action prob: [0.76328546 0.23671448], Action: 0, state: 2\n",
      "[0.76328546 0.23671448]\n",
      "Sensor: [0.422838428647133, 0.6833415275801018, 0.1947712628898799, 0.20731975736308222], Action prob: [0.76173055 0.23826942], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.76173055 0.23826942]\n",
      "Sensor: [0.37249895588532, 0.6601937775072916, 0.2564086496549328, 0.2876270292037676], Action prob: [0.7627143  0.23728573], Action: 1, state: 2\n",
      "[0.7627143  0.23728573]\n",
      "Sensor: [0.5783561363336157, 0.6508384405019245, 0.2059736547397402, 0.24767342831254996], Action prob: [0.7612724  0.23872763], Action: 0, state: 9\n",
      "[0.7612724  0.23872763]\n",
      "Sensor: [0.43703291445329295, 0.35489665074794213, 0.22870339909848078, 0.19834560548565086], Action prob: [0.7611462  0.23885383], Action: 0, state: 9\n",
      "[0.7611462  0.23885383]\n",
      "Sensor: [0.5735906448923918, 0.6057224656669201, 0.21112947709508273, 0.20697951793234165], Action prob: [0.7616996  0.23830034], Action: 0, state: 9\n",
      "[0.7616996  0.23830034]\n",
      "Sensor: [0.5771514950281713, 0.67896037416374, 0.2325123698419376, 0.2778219570665233], Action prob: [0.7623947 0.2376053], Action: 0, state: 9\n",
      "tensor([-0.1228,  0.1446,  1.5488,  2.0083,  0.1285, -0.0884, -0.2921, -0.4682],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2288 is -441000, loss is -0.35732846999437\n",
      "[0.7623947 0.2376053]\n",
      "Sensor: [0.5986745616617505, 0.6334893154867548, 0.22694420894501216, 0.2645234985005544], Action prob: [0.7623274  0.23767264], Action: 0, state: 9\n",
      "[0.7623274  0.23767264]\n",
      "Sensor: [0.3291157854785579, 0.4609010121180628, 0.24809417800890154, 0.22348759985458316], Action prob: [0.76199895 0.23800106], Action: 1, state: 9\n",
      "[0.76199895 0.23800106]\n",
      "Sensor: [0.5126974554891762, 0.37797416071491347, 0.1907344360249698, 0.5613853010367649], Action prob: [0.7606547  0.23934534], Action: 0, state: 9\n",
      "[0.7606547  0.23934534]\n",
      "Sensor: [0.5819366179478791, 0.6434061719398735, 0.23831471439715257, 0.25474436976384224], Action prob: [0.7606801  0.23931995], Action: 1, state: 9\n",
      "[0.7606801  0.23931995]\n",
      "Sensor: [0.347302420826553, 0.42967144129376794, 0.21367587163877116, 0.268023289595817], Action prob: [0.7625756  0.23742439], Action: 1, state: 9\n",
      "[0.7625756  0.23742439]\n",
      "Sensor: [0.33955498423463604, 0.658745407616743, 0.20492768728350255, 0.5331901434157098], Action prob: [0.76524156 0.23475839], Action: 1, state: 9\n",
      "[0.76524156 0.23475839]\n",
      "Sensor: [0.3907640059900041, 0.6132208098751172, 0.21723384377431687, 0.5646438468830821], Action prob: [0.76472837 0.23527166], Action: 0, state: 9\n",
      "[0.76472837 0.23527166]\n",
      "Sensor: [0.3554837240711672, 0.625576895786941, 0.49109820280035466, 0.2643255436949794], Action prob: [0.7641507  0.23584934], Action: 0, state: 9\n",
      "tensor([ 0.4523,  1.5864,  0.1611,  0.1156, -0.4638, -1.0029, -0.2782, -0.3632],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2296 is -449000, loss is -0.02593043556414465\n",
      "[0.7641507  0.23584934]\n",
      "Sensor: [0.42557417564869376, 0.6112021471955956, 0.2101576237492036, 0.5612038827474595], Action prob: [0.7642878  0.23571216], Action: 0, state: 9\n",
      "[0.7642878  0.23571216]\n",
      "Sensor: [0.32297732861295897, 0.5998475559768359, 0.5373631596945017, 0.5078185856411279], Action prob: [0.76379037 0.23620966], Action: 0, state: 9\n",
      "[0.76379037 0.23620966]\n",
      "Sensor: [0.38019846965538406, 0.6386081149618354, 0.49720740306326444, 0.23419439714652263], Action prob: [0.76241845 0.23758154], Action: 0, state: 9\n",
      "[0.76241845 0.23758154]\n",
      "Sensor: [0.35537026076207084, 0.3746356053931063, 0.22649015724773075, 0.2269116099241472], Action prob: [0.7619289  0.23807107], Action: 0, state: 9\n",
      "[0.7619289  0.23807107]\n",
      "Sensor: [0.32875334417975377, 0.3962704797853114, 0.1990517205209482, 0.23229269957119902], Action prob: [0.7635637  0.23643629], Action: 0, state: 9\n",
      "[0.7635637  0.23643629]\n",
      "Sensor: [0.33533623484834263, 0.6150582340572415, 0.5099518316311631, 0.24153915221808966], Action prob: [0.7658705  0.23412952], Action: 0, state: 9\n",
      "[0.7658705  0.23412952]\n",
      "Sensor: [0.6021441706238106, 0.65715954627214, 0.21599058794096382, 0.2490630397145123], Action prob: [0.7633385 0.2366615], Action: 1, state: 9\n",
      "[0.7633385 0.2366615]\n",
      "Sensor: [0.3855593486711886, 0.6379963062899953, 0.5047488928863643, 0.21953171396480545], Action prob: [0.7650699  0.23493011], Action: 0, state: 9\n",
      "tensor([ 0.4581,  0.3089,  0.1597,  0.0281, -0.0873, -0.1844, -1.5559, -0.3628],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2304 is -457000, loss is 0.15445750924117746\n",
      "[0.7650699  0.23493011]\n",
      "Sensor: [0.3792554277362185, 0.6415000611762544, 0.4794933458347056, 0.2420953274795131], Action prob: [0.7612605  0.23873955], Action: 0, state: 9\n",
      "[0.7612605  0.23873955]\n",
      "Sensor: [0.3769971535994328, 0.4433844088592147, 0.16568860545528485, 0.29800571542975957], Action prob: [0.75928336 0.24071664], Action: 1, state: 9\n",
      "[0.75928336 0.24071664]\n",
      "Sensor: [0.34339351584199196, 0.6673697426037317, 0.5203003425547389, 0.21209259793647572], Action prob: [0.76106465 0.23893537], Action: 0, state: 9\n",
      "[0.76106465 0.23893537]\n",
      "Sensor: [0.30854241003191674, 0.3670733594633223, 0.21761007256395942, 0.2521675170108241], Action prob: [0.7606192  0.23938073], Action: 0, state: 9\n",
      "[0.7606192  0.23938073]\n",
      "Sensor: [0.31443253065995475, 0.39160806405191134, 0.5130298322584907, 0.23572887691719638], Action prob: [0.76197755 0.2380224 ], Action: 0, state: 9\n",
      "[0.76197755 0.2380224 ]\n",
      "Sensor: [0.578164786419057, 0.6345486288777373, 0.22520314068870848, 0.2843273192895538], Action prob: [0.76090497 0.23909503], Action: 0, state: 9\n",
      "[0.76090497 0.23909503]\n",
      "Sensor: [0.3685289323325378, 0.37947482487631085, 0.21359456548450334, 0.24837803430995625], Action prob: [0.7615328  0.23846726], Action: 1, state: 9\n",
      "[0.7615328  0.23846726]\n",
      "Sensor: [0.3994143093775867, 0.341787701111189, 0.36625830633528456, 0.2816747845543753], Action prob: [0.76179904 0.23820092], Action: 0, state: 9\n",
      "tensor([ 0.4637,  1.5689,  0.1610,  0.0295, -0.0817, -0.1990, -1.5120, -0.3683],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2312 is -465000, loss is -0.007744298930874215\n",
      "[0.76179904 0.23820092]\n",
      "Sensor: [0.3189421858713046, 0.43220520767439874, 0.20555244583731305, 0.269120509939485], Action prob: [0.75811505 0.24188498], Action: 1, state: 9\n",
      "[0.75811505 0.24188498]\n",
      "Sensor: [0.5363884909473904, 0.652486571052705, 0.5123403045908865, 0.1939339753916085], Action prob: [0.75703937 0.24296057], Action: 0, state: 9\n",
      "[0.75703937 0.24296057]\n",
      "Sensor: [0.37370386048146287, 0.3359254650453098, 0.21041122696181866, 0.24408004245074383], Action prob: [0.75688344 0.24311657], Action: 1, state: 9\n",
      "[0.75688344 0.24311657]\n",
      "Sensor: [0.3704806249383963, 0.38495862501386147, 0.16000832635367937, 0.2568675376652277], Action prob: [0.7583223  0.24167776], Action: 0, state: 9\n",
      "[0.7583223  0.24167776]\n",
      "Sensor: [0.5501252131444947, 0.5754522979850533, 0.23871353365761852, 0.2561272602808095], Action prob: [0.7588488  0.24115123], Action: 1, state: 9\n",
      "[0.7588488  0.24115123]\n",
      "Sensor: [0.3314737889010931, 0.6808384500050128, 0.2186727443774757, 0.5059966735674176], Action prob: [0.7617007  0.23829935], Action: 1, state: 9\n",
      "[0.7617007  0.23829935]\n",
      "Sensor: [0.36451393655503067, 0.6305188355830597, 0.22989947038080535, 0.20331639080120062], Action prob: [0.76067716 0.23932277], Action: 0, state: 0\n",
      "[0.76067716 0.23932277]\n",
      "Sensor: [0.3616552312806508, 0.70383506937453, 0.20448799609889212, 0.2587572927487358], Action prob: [0.76112694 0.2388731 ], Action: 0, state: 0\n",
      "tensor([ 2.6809,  0.3100,  0.6019, -0.0555, -1.1011, -1.7875, -0.2234, -0.1112],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2320 is -467100, loss is -0.039251845831633554\n",
      "[0.76112694 0.2388731 ]\n",
      "Sensor: [0.3291805682932618, 0.6800582297492468, 0.2287278832292262, 0.2152068969446741], Action prob: [0.75735486 0.24264516], Action: 0, state: 1\n",
      "[0.75735486 0.24264516]\n",
      "Sensor: [0.36011629619459984, 0.6567058822846863, 0.2362309750251662, 0.2699974404808742], Action prob: [0.7569092  0.24309078], Action: 0, state: 1\n",
      "[0.7569092  0.24309078]\n",
      "Sensor: [0.5765866132102697, 0.38520031607450933, 0.22507281954246372, 0.2504065732441531], Action prob: [0.7542995 0.2457005], Action: 1, state: 9\n",
      "[0.7542995 0.2457005]\n",
      "Sensor: [0.5987425220760081, 0.597878607602841, 0.2205775763457482, 0.6199586018286094], Action prob: [0.7561239  0.24387607], Action: 0, state: 9\n",
      "[0.7561239  0.24387607]\n",
      "Sensor: [0.6351476744952993, 0.6042889940118356, 0.20772690575511416, 0.49593210170078933], Action prob: [0.7561802  0.24381985], Action: 1, state: 9\n",
      "[0.7561802  0.24381985]\n",
      "Sensor: [0.3292545631765157, 0.659314220655437, 0.24808911548159826, 0.5392468481424996], Action prob: [0.75925076 0.24074927], Action: 1, state: 9\n",
      "[0.75925076 0.24074927]\n",
      "Sensor: [0.35643565527019244, 0.3550863134437901, 0.2358928602743207, 0.2039174812554746], Action prob: [0.75763667 0.24236327], Action: 0, state: 9\n",
      "[0.75763667 0.24236327]\n",
      "Sensor: [0.33431800249227767, 0.5974453519738563, 0.5290674970693835, 0.27992795777085566], Action prob: [0.75941354 0.2405865 ], Action: 0, state: 9\n",
      "tensor([ 0.2410,  0.4222,  1.2055,  0.0836, -0.3354, -0.9693, -0.3123, -0.4087],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for up to this timestep 2328 is -473200, loss is 0.009176753439658555\n",
      "[0.75941354 0.2405865 ]\n",
      "Sensor: [0.32563081665135457, 0.41104212687166586, 0.22517919852260207, 0.2192499565240703], Action prob: [0.75441736 0.24558268], Action: 1, state: 9\n",
      "[0.75441736 0.24558268]\n",
      "Sensor: [0.2889219976245987, 0.37597114232336204, 0.19316732323485314, 0.2439000366642631], Action prob: [0.7546962  0.24530382], Action: 0, state: 9\n",
      "[0.7546962  0.24530382]\n",
      "Sensor: [0.36257091119967505, 0.3355430721408293, 0.2266150756572661, 0.23879679124659905], Action prob: [0.7543515 0.2456485], Action: 0, state: 9\n",
      "[0.7543515 0.2456485]\n",
      "Sensor: [0.3622919928799598, 0.3866106632028495, 0.17795172553667912, 0.2578392835093948], Action prob: [0.75519866 0.24480128], Action: 0, state: 9\n",
      "[0.75519866 0.24480128]\n",
      "Sensor: [0.3174161999664158, 0.351378529112541, 0.14084656726799372, 0.21714141381242738], Action prob: [0.7560616  0.24393836], Action: 1, state: 9\n",
      "[0.7560616  0.24393836]\n",
      "Sensor: [0.5512497731220563, 0.6233270065249525, 0.22114975216754412, 0.25958120190141415], Action prob: [0.755883   0.24411705], Action: 0, state: 9\n",
      "[0.755883   0.24411705]\n",
      "Sensor: [0.4579863638852112, 0.6132466992397909, 0.4177254476807175, 0.21451137694739184], Action prob: [0.7563936  0.24360642], Action: 0, state: 9\n",
      "[0.7563936  0.24360642]\n",
      "Sensor: [0.5710233056780819, 0.6478999239364163, 0.23349505105524537, 0.25312184197306514], Action prob: [0.7554994  0.24450053], Action: 1, state: 9\n",
      "tensor([ 2.3680,  0.3108,  0.1620,  0.0273, -0.4672, -0.2047, -0.2959, -1.9582],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2336 is -479200, loss is 0.0072485757331458844\n",
      "[0.7554994  0.24450053]\n",
      "Sensor: [0.34714097589453846, 0.6418721628358087, 0.21663282046755192, 0.2842128887015044], Action prob: [0.7534898  0.24651024], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "[0.7534898  0.24651024]\n",
      "Sensor: [0.3775383608080429, 0.7166188379022816, 0.18389110143824, 0.27314671337363583], Action prob: [0.753211   0.24678904], Action: 0, state: 0\n",
      "[0.753211   0.24678904]\n",
      "Sensor: [0.40396385406158597, 0.6219536907458283, 0.23961369676000482, 0.27500665072875485], Action prob: [0.75298154 0.24701849], Action: 0, state: 0\n",
      "[0.75298154 0.24701849]\n",
      "Sensor: [0.3834444301474929, 0.6589586835871853, 0.22017686411392184, 0.28588509076019347], Action prob: [0.7538598  0.24614026], Action: 0, state: 0\n",
      "[0.7538598  0.24614026]\n",
      "Sensor: [0.43780244045812977, 0.6132134062910809, 0.23464875875215885, 0.40522654322406], Action prob: [0.7541335  0.24586646], Action: 0, state: 0\n",
      "[0.7541335  0.24586646]\n",
      "Sensor: [0.2949067110683414, 0.6452200505244426, 0.19056346311843197, 0.2416702503990918], Action prob: [0.7552027  0.24479729], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.7552027  0.24479729]\n",
      "Sensor: [0.3529637092568319, 0.6774467166180013, 0.24805256085456845, 0.2146102179473955], Action prob: [0.7553224  0.24467762], Action: 0, state: 0\n",
      "[0.7553224  0.24467762]\n",
      "Sensor: [0.3783793222153504, 0.6126797964170128, 0.2034496870550283, 0.34748988250448454], Action prob: [0.7551156  0.24488442], Action: 0, state: 1\n",
      "tensor([-0.6127, -0.5225, -0.2837, -0.0691,  0.1250,  1.4758,  0.2161,  0.3435],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2344 is -475500, loss is -0.08406339882704483\n",
      "[0.7551156  0.24488442]\n",
      "Sensor: [0.39304804251226333, 0.6445742410974031, 0.21614873614988475, 0.2678993336586955], Action prob: [0.75293684 0.24706319], Action: 0, state: 2\n",
      "[0.75293684 0.24706319]\n",
      "Sensor: [0.3985988730062778, 0.6710501076742957, 0.18800119475488655, 0.2163007214822301], Action prob: [0.7527051  0.24729487], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.7527051  0.24729487]\n",
      "Sensor: [0.3361923097082532, 0.6213320868439692, 0.23412742716896404, 0.2864363693699542], Action prob: [0.75346065 0.24653937], Action: 0, state: 1\n",
      "[0.75346065 0.24653937]\n",
      "Sensor: [0.314912623429551, 0.6347399498549563, 0.23803202446337987, 0.21099508842641929], Action prob: [0.75418484 0.24581516], Action: 0, state: 2\n",
      "[0.75418484 0.24581516]\n",
      "Sensor: [0.35491723974692313, 0.47051571281970006, 0.2290646307437526, 0.27625509299515544], Action prob: [0.7539906  0.24600947], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.7539906  0.24600947]\n",
      "Sensor: [0.3485686188560654, 0.6403345202424292, 0.2077308638203538, 0.23357916537531115], Action prob: [0.754726   0.24527399], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.754726   0.24527399]\n",
      "Sensor: [0.3749379936846437, 0.6530722509034816, 0.22966297353148268, 0.2610253959628673], Action prob: [0.75487465 0.24512532], Action: 0, state: 0\n",
      "[0.75487465 0.24512532]\n",
      "Sensor: [0.28895563798784113, 0.6261382977808215, 0.19602220494626424, 0.2725331273066033], Action prob: [0.75541955 0.24458046], Action: 0, state: 0\n",
      "tensor([-0.4655, -1.1376, -0.2530, -0.0629,  0.5468,  0.9200,  0.2709,  0.4270],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2352 is -470400, loss is -0.030725069360589635\n",
      "[0.75541955 0.24458046]\n",
      "Sensor: [0.3594145608811057, 0.48490653826657354, 0.23263176310488795, 0.30897336809495374], Action prob: [0.7530415  0.24695855], Action: 0, state: 1\n",
      "[0.7530415  0.24695855]\n",
      "Sensor: [0.32798794105962226, 0.6099169443830724, 0.2201309143058742, 0.23732894242212316], Action prob: [0.7534866  0.24651341], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7534866  0.24651341]\n",
      "Sensor: [0.3474593392841504, 0.6699809333810638, 0.2004267420562354, 0.22756360403382703], Action prob: [0.7538327  0.24616726], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7538327  0.24616726]\n",
      "Sensor: [0.3653277531340368, 0.581926167447407, 0.2155881721072099, 0.2791484016614678], Action prob: [0.75413305 0.24586692], Action: 0, state: 0\n",
      "[0.75413305 0.24586692]\n",
      "Sensor: [0.3463957769509542, 0.6653779926318891, 0.2432774513142292, 0.23895075906291197], Action prob: [0.75488937 0.24511062], Action: 0, state: 0\n",
      "[0.75488937 0.24511062]\n",
      "Sensor: [0.3222733177225975, 0.6234429084302926, 0.15303770789200422, 0.25789301775475276], Action prob: [0.7552135 0.2447865], Action: 0, state: 0\n",
      "[0.7552135 0.2447865]\n",
      "Sensor: [0.37948914070995465, 0.6299576285011972, 0.17085583514945807, 0.2302184535666713], Action prob: [0.75498235 0.24501766], Action: 0, state: 1\n",
      "[0.75498235 0.24501766]\n",
      "Sensor: [0.3886418743454717, 0.668373002177823, 0.2184196617770552, 0.3118947251207036], Action prob: [0.75518626 0.24481378], Action: 0, state: 1\n",
      "tensor([-0.4603, -1.3428, -0.8805, -0.0904,  0.0623,  0.1991,  0.3093,  0.4113],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2360 is -463800, loss is 0.22400359416913146\n",
      "[0.75518626 0.24481378]\n",
      "Sensor: [0.36414541772048303, 0.6696294187722129, 0.2155588993371828, 0.2542853260019245], Action prob: [0.7505514  0.24944858], Action: 0, state: 1\n",
      "[0.7505514  0.24944858]\n",
      "Sensor: [0.3344016119903732, 0.621047244427976, 0.2391036302600973, 0.2881785416955463], Action prob: [0.7502089  0.24979107], Action: 0, state: 2\n",
      "[0.7502089  0.24979107]\n",
      "Sensor: [0.3919133034113525, 0.631691723629167, 0.209002340834143, 0.26312725900737144], Action prob: [0.7498112 0.2501888], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.7498112 0.2501888]\n",
      "Sensor: [0.3156731468825306, 0.6688788936715369, 0.27051315582226526, 0.228173162066318], Action prob: [0.7509743 0.2490257], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.7509743 0.2490257]\n",
      "Sensor: [0.3643111301618753, 0.6377243815547522, 0.21090015421919195, 0.3067912498633471], Action prob: [0.75112027 0.24887976], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.75112027 0.24887976]\n",
      "Sensor: [0.40147397743225977, 0.694901207082675, 0.2343734647644151, 0.21495223276283232], Action prob: [0.75104934 0.24895068], Action: 0, state: 0\n",
      "[0.75104934 0.24895068]\n",
      "Sensor: [0.3464722032914593, 0.6072848716280848, 0.3418548364167363, 0.27269291239045473], Action prob: [0.7514582  0.24854171], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7514582  0.24854171]\n",
      "Sensor: [0.35254906349579423, 0.6562891439594596, 0.18758155867449122, 0.21382312917204827], Action prob: [0.7513596  0.24864043], Action: 0, state: 0\n",
      "tensor([-0.5213, -0.2635, -0.5864, -0.2034,  0.2478,  0.1531,  1.5941,  0.4073],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2368 is -458900, loss is -0.10346264538449487\n",
      "[0.7513596  0.24864043]\n",
      "Sensor: [0.3869353032755184, 0.656787185824312, 0.20369190106797233, 0.19754670155428727], Action prob: [0.749204   0.25079596], Action: 0, state: 0\n",
      "[0.749204   0.25079596]\n",
      "Sensor: [0.39624137911479085, 0.6019446816287667, 0.2538260811098245, 0.27935931444834095], Action prob: [0.7483803 0.2516197], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7483803 0.2516197]\n",
      "Sensor: [0.3696613499417504, 0.6302062714353217, 0.17171053719928808, 0.23597157239997144], Action prob: [0.7484779  0.25152203], Action: 0, state: 2\n",
      "[0.7484779  0.25152203]\n",
      "Sensor: [0.40602697058800596, 0.6380930712015567, 0.22798499895407828, 0.26748838370676375], Action prob: [0.7488521  0.25114796], Action: 0, state: 3\n",
      "[0.7488521  0.25114796]\n",
      "Sensor: [0.3596064617755013, 0.5947616207374605, 0.17540027061187807, 0.23677435978517355], Action prob: [0.7493356  0.25066438], Action: 0, state: 3\n",
      "[0.7493356  0.25066438]\n",
      "Sensor: [0.6229645917764514, 0.563886366504993, 0.18637381920615595, 0.5131365940912332], Action prob: [0.7478332  0.25216684], Action: 0, state: 8\n",
      "[0.7478332  0.25216684]\n",
      "Sensor: [0.5704221477989899, 0.6382132663255221, 0.20623466918715685, 0.21709143819724486], Action prob: [0.7477655  0.25223458], Action: 0, state: 8\n",
      "[0.7477655  0.25223458]\n",
      "Sensor: [0.3968986001260463, 0.40159551774685454, 0.21435006184028818, 0.24482732849654862], Action prob: [0.7486331 0.2513669], Action: 0, state: 8\n",
      "tensor([-0.0684,  0.0890,  0.2104,  0.2805,  0.3418,  0.0063, -0.3048, -0.5714],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2376 is -468200, loss is 0.0020711008933092523\n",
      "[0.7486331 0.2513669]\n",
      "Sensor: [0.3798877320372064, 0.6218784609080725, 0.5344649873605046, 0.2766952502230998], Action prob: [0.7479926  0.25200748], Action: 1, state: 8\n",
      "[0.7479926  0.25200748]\n",
      "Sensor: [0.3459589819544512, 0.6336974667835995, 0.5537393261552799, 0.28135057315856316], Action prob: [0.7473377 0.2526623], Action: 1, state: 8\n",
      "[0.7473377 0.2526623]\n",
      "Sensor: [0.2867754215732652, 0.69643817558909, 0.2451117606460224, 0.5119837877319129], Action prob: [0.74786294 0.25213706], Action: 0, state: 8\n",
      "[0.74786294 0.25213706]\n",
      "Sensor: [0.3546327748575015, 0.368421291909276, 0.16199871059565238, 0.25707290291591545], Action prob: [0.74682456 0.25317553], Action: 0, state: 8\n",
      "[0.74682456 0.25317553]\n",
      "Sensor: [0.30663336316988554, 0.6712150951201155, 0.20039913890843453, 0.6245808945298781], Action prob: [0.74893844 0.2510615 ], Action: 0, state: 8\n",
      "[0.74893844 0.2510615 ]\n",
      "Sensor: [0.30128229861656064, 0.622347443977078, 0.46554340778763936, 0.22655477306288963], Action prob: [0.7486406  0.25135934], Action: 1, state: 8\n",
      "[0.7486406  0.25135934]\n",
      "Sensor: [0.5973467238885035, 0.6552354729282582, 0.24258375429053464, 0.3043845894487074], Action prob: [0.7465795 0.2534204], Action: 1, state: 8\n",
      "[0.7465795 0.2534204]\n",
      "Sensor: [0.3008728240231556, 0.3042261438252171, 0.1982136563204087, 0.2893231966394418], Action prob: [0.7475607  0.25243932], Action: 0, state: 8\n",
      "tensor([ 2.3545,  1.5496,  0.1739,  0.0298, -0.0861, -0.9571, -1.4674, -0.3945],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2384 is -492200, loss is -0.1503312838262999\n",
      "[0.7475607  0.25243932]\n",
      "Sensor: [0.36464525265532605, 0.6774941893681997, 0.23610068310545676, 0.5235119478268268], Action prob: [0.7497594  0.25024062], Action: 0, state: 8\n",
      "[0.7497594  0.25024062]\n",
      "Sensor: [0.4351198745978731, 0.6560606229660284, 0.2179232507972637, 0.5585480228000375], Action prob: [0.7480363  0.25196365], Action: 0, state: 8\n",
      "[0.7480363  0.25196365]\n",
      "Sensor: [0.5289191903229912, 0.6017616148155642, 0.19093645854675506, 0.21976198525068638], Action prob: [0.74656695 0.25343302], Action: 0, state: 8\n",
      "[0.74656695 0.25343302]\n",
      "Sensor: [0.5877190055991435, 0.5983478839884367, 0.22012639285930813, 0.19892166741625622], Action prob: [0.7467801  0.25321984], Action: 0, state: 8\n",
      "[0.7467801  0.25321984]\n",
      "Sensor: [0.38418273354973503, 0.35280671981593575, 0.21491070879783106, 0.27417115857569224], Action prob: [0.74800736 0.25199264], Action: 0, state: 8\n",
      "[0.74800736 0.25199264]\n",
      "Sensor: [0.4069334110183418, 0.6653453000834371, 0.2254794106179882, 0.8862589777062335], Action prob: [0.74961305 0.25038695], Action: 0, state: 8\n",
      "[0.74961305 0.25038695]\n",
      "Sensor: [0.5226932446941622, 0.6794633892047771, 0.21364216225219215, 0.24135950107906343], Action prob: [0.747664   0.25233603], Action: 0, state: 8\n",
      "[0.747664   0.25233603]\n",
      "Sensor: [0.35351408961376274, 0.6358044432542985, 0.4891558522082398, 0.2729879556070275], Action prob: [0.7489955  0.25100452], Action: 0, state: 8\n",
      "tensor([ 0.4913,  0.3245,  0.1632,  0.0235, -0.0934, -0.1924, -0.3115, -0.3900],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2392 is -516200, loss is -0.0019129074190503623\n",
      "[0.7489955  0.25100452]\n",
      "Sensor: [0.3594375548329885, 0.5767901593686855, 0.1914835129972917, 0.5536353063040609], Action prob: [0.7507411  0.24925889], Action: 1, state: 8\n",
      "[0.7507411  0.24925889]\n",
      "Sensor: [0.31250861326566115, 0.6006891135742491, 0.21541602881007568, 0.23765168649527477], Action prob: [0.74970764 0.25029233], Action: 0, state: 0\n",
      "[0.74970764 0.25029233]\n",
      "Sensor: [0.3030902667960419, 0.6151099612943173, 0.22221728582433503, 0.21775642238490028], Action prob: [0.7495835  0.25041658], Action: 0, state: 1\n",
      "[0.7495835  0.25041658]\n",
      "Sensor: [0.3713735590875306, 0.6397988577659509, 0.2288620762850082, 0.2657911375992742], Action prob: [0.7496227 0.2503773], Action: 0, state: 1\n",
      "[0.7496227 0.2503773]\n",
      "Sensor: [0.3623517223969184, 0.7073993636858503, 0.20344224051503992, 0.20937000559918278], Action prob: [0.7500233  0.24997671], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.7500233  0.24997671]\n",
      "Sensor: [0.354823878670298, 0.6384288429502952, 0.22803958617375594, 0.209594306985068], Action prob: [0.7501695  0.24983044], Action: 0, state: 1\n",
      "[0.7501695  0.24983044]\n",
      "Sensor: [0.3404355511215775, 0.6494084309084366, 0.23656901519065143, 0.26458850269316125], Action prob: [0.7504363 0.2495637], Action: 0, state: 1\n",
      "[0.7504363 0.2495637]\n",
      "Sensor: [0.4058197791560161, 0.6372715362700617, 0.21641134562420816, 0.2660468280469429], Action prob: [0.749889   0.25011095], Action: 0, state: 1\n",
      "tensor([-2.4692, -0.3122, -0.1462,  0.0034,  0.5830,  0.1758,  0.2858,  0.3833],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2400 is -509500, loss is 0.18704749615177776\n",
      "[0.749889   0.25011095]\n",
      "Sensor: [0.3573818975410008, 0.6207928698595677, 0.1859503388472407, 0.2607869488504778], Action prob: [0.749036   0.25096396], Action: 0, state: 1\n",
      "[0.749036   0.25096396]\n",
      "Sensor: [0.37820930421533133, 0.5995381170947714, 0.18110070052791438, 0.22650840739420286], Action prob: [0.7476156  0.25238442], Action: 0, state: 1\n",
      "[0.7476156  0.25238442]\n",
      "Sensor: [0.3219003316763425, 0.6212686100513541, 0.17919579688378545, 0.23864348590175244], Action prob: [0.74756634 0.25243366], Action: 0, state: 1\n",
      "[0.74756634 0.25243366]\n",
      "Sensor: [0.3826392164841376, 0.5842862837110899, 0.19363050497033596, 0.2292811867310901], Action prob: [0.7473599 0.2526401], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.7473599 0.2526401]\n",
      "Sensor: [0.3673957808576652, 0.6761638724880711, 0.23897597865830777, 0.24039042554999224], Action prob: [0.74791586 0.25208414], Action: 0, state: 1\n",
      "[0.74791586 0.25208414]\n",
      "Sensor: [0.3382727860751888, 0.6019105153915387, 0.26702168288759276, 0.22023269892397418], Action prob: [0.74809676 0.2519032 ], Action: 0, state: 2\n",
      "[0.74809676 0.2519032 ]\n",
      "Sensor: [0.30636285611526193, 0.6824405648273689, 0.2461623940404117, 0.19861043741290346], Action prob: [0.7485097  0.25149027], Action: 0, state: 2\n",
      "[0.7485097  0.25149027]\n",
      "Sensor: [0.3542577467400016, 0.5870124886010126, 0.2286862334498832, 0.22467754008441979], Action prob: [0.74806076 0.25193933], Action: 0, state: 3\n",
      "tensor([-0.5442, -0.3158, -0.1051,  0.2928,  0.0437,  0.1804,  0.3010,  0.3703],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2408 is -504400, loss is -0.027876984779484366\n",
      "[0.74806076 0.25193933]\n",
      "Sensor: [0.5936688807127911, 0.527731801038954, 0.22053621687576752, 0.21481356357931447], Action prob: [0.7456416  0.25435844], Action: 0, state: 3\n",
      "[0.7456416  0.25435844]\n",
      "Sensor: [0.35554806568853786, 0.6890177975900287, 0.20546372042336203, 0.25866805728943415], Action prob: [0.7463902  0.25360978], Action: 0, state: 3\n",
      "[0.7463902  0.25360978]\n",
      "Sensor: [0.291904320289902, 0.5806950937504005, 0.20401082186719033, 0.27125382318158925], Action prob: [0.74636114 0.2536389 ], Action: 0, state: 3\n",
      "[0.74636114 0.2536389 ]\n",
      "Sensor: [0.3835259237581078, 0.5673628814048193, 0.5229206556899443, 0.21157564414334518], Action prob: [0.74632615 0.25367388], Action: 0, state: 3\n",
      "[0.74632615 0.25367388]\n",
      "Sensor: [0.40887029377563505, 0.5356179594553745, 0.20654036901209688, 0.22138458851798204], Action prob: [0.7455308 0.2544692], Action: 0, state: 3\n",
      "[0.7455308 0.2544692]\n",
      "Sensor: [0.35641303440877536, 0.40666827012551787, 0.22471919184130776, 0.21356638370648448], Action prob: [0.7458668 0.2541332], Action: 0, state: 3\n",
      "[0.7458668 0.2541332]\n",
      "Sensor: [0.41819126738895207, 0.5221565684947153, 0.42897244567598214, 0.5305342956242949], Action prob: [0.74623716 0.2537628 ], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.74623716 0.2537628 ]\n",
      "Sensor: [0.2961630160406069, 0.4555371232853504, 0.19800941843470005, 0.1995934791953834], Action prob: [0.7460221  0.25397798], Action: 0, state: 2\n",
      "tensor([-0.5062, -0.3257, -0.1661, -0.0212,  0.1007,  0.2176,  1.5435,  0.3767],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2416 is -500300, loss is -0.1524207832397627\n",
      "[0.7460221  0.25397798]\n",
      "Sensor: [0.36916932275049813, 0.618080902990549, 0.19804635664738252, 0.21145626793462552], Action prob: [0.7490922  0.25090778], Action: 0, state: 2\n",
      "[0.7490922  0.25090778]\n",
      "Sensor: [0.38442869262795903, 0.6298287245424807, 0.2575081259754789, 0.24718934003039875], Action prob: [0.74772334 0.25227663], Action: 0, state: 2\n",
      "[0.74772334 0.25227663]\n",
      "Sensor: [0.376032217313797, 0.610248865669896, 0.22169183602316347, 0.2497631296361709], Action prob: [0.7469719  0.25302806], Action: 0, state: 3\n",
      "[0.7469719  0.25302806]\n",
      "Sensor: [0.35789922119996453, 0.65433600209126, 0.19320558652004016, 0.19639165106741405], Action prob: [0.7471928  0.25280726], Action: 0, state: 3\n",
      "[0.7471928  0.25280726]\n",
      "Sensor: [0.34453031101810844, 0.6570077789951967, 0.33008807853905064, 0.2246695944945521], Action prob: [0.74782616 0.2521739 ], Action: 0, state: 3\n",
      "[0.74782616 0.2521739 ]\n",
      "Sensor: [0.36049580243155704, 0.6426005850846516, 0.25464917276097043, 0.24194029460575325], Action prob: [0.7476095 0.2523904], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.7476095 0.2523904]\n",
      "Sensor: [0.4079316609016627, 0.684461000506909, 0.17944460998822906, 0.2889890974510538], Action prob: [0.74728465 0.2527153 ], Action: 0, state: 2\n",
      "[0.74728465 0.2527153 ]\n",
      "Sensor: [0.3777855817188325, 0.6021113730561081, 0.18289202885414424, 0.28447403861114573], Action prob: [0.74726933 0.2527307 ], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "tensor([-0.5475, -0.2872, -0.1405, -0.0089,  0.1140,  1.0436,  0.2775,  1.7276],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2424 is -496400, loss is -0.2723247542944835\n",
      "[0.74726933 0.2527307 ]\n",
      "Sensor: [0.37732933543719643, 0.6304822993087007, 0.20665748847668153, 0.31312236476351807], Action prob: [0.7543467  0.24565327], Action: 0, state: 2\n",
      "[0.7543467  0.24565327]\n",
      "Sensor: [0.6201876145116099, 0.605916453251696, 0.19741197066207136, 0.2709909310179746], Action prob: [0.75152224 0.24847773], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1200\n",
      "[0.75152224 0.24847773]\n",
      "Sensor: [0.3047713618421975, 0.5899090017495988, 0.25184888232845226, 0.2613518408018982], Action prob: [0.7527955  0.24720447], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.7527955  0.24720447]\n",
      "Sensor: [0.3723962592327165, 0.6429542571907765, 0.22829766530356418, 0.24172093811938117], Action prob: [0.75288    0.24712005], Action: 0, state: 1\n",
      "[0.75288    0.24712005]\n",
      "Sensor: [0.2787498328071793, 0.6528315084189272, 0.2045104706617012, 0.19604003824342214], Action prob: [0.7535575  0.24644254], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7535575  0.24644254]\n",
      "Sensor: [0.43899231398521626, 0.7131117077583558, 0.21961212090214682, 0.2691107047574983], Action prob: [0.75302964 0.24697033], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75302964 0.24697033]\n",
      "Sensor: [0.37456900714132324, 0.6020833811368189, 0.20512734482951403, 0.2811665249548303], Action prob: [0.7529682  0.24703178], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -4500\n",
      "Maintenance in progress, cumulative -5000\n",
      "Maintenance in progress, cumulative -4000\n",
      "[0.7529682  0.24703178]\n",
      "Sensor: [0.310285320542352, 0.6743550936965385, 0.22692861394029054, 0.22742108698142127], Action prob: [0.75353944 0.24646057], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.0695,  0.6818, -1.5605, -0.1806,  0.4948,  0.2391,  2.4326, -2.0524],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2432 is -497800, loss is 0.0018434087362174667\n",
      "[0.75353944 0.24646057]\n",
      "Sensor: [0.40380875402243716, 0.5894338285026703, 0.22652017158805351, 0.3071143584627947], Action prob: [0.75882584 0.24117418], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.75882584 0.24117418]\n",
      "Sensor: [0.3120785118979012, 0.6312362652336894, 0.18570446483904188, 0.22196259629509463], Action prob: [0.7585417  0.24145834], Action: 0, state: 0\n",
      "[0.7585417  0.24145834]\n",
      "Sensor: [0.3588121593563526, 0.6714277119886773, 0.23461357204004685, 0.2558671179481888], Action prob: [0.7579905  0.24200955], Action: 0, state: 1\n",
      "[0.7579905  0.24200955]\n",
      "Sensor: [0.3931601165332799, 0.46338900646193193, 0.21905247819765356, 0.25783679325199366], Action prob: [0.75724643 0.24275355], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.75724643 0.24275355]\n",
      "Sensor: [0.33948161264531745, 0.6192882825577475, 0.21270297662303642, 0.17428927104957853], Action prob: [0.7579417  0.24205822], Action: 0, state: 0\n",
      "[0.7579417  0.24205822]\n",
      "Sensor: [0.3730228129295368, 0.5867080792245809, 0.19121134168951545, 0.22741462381322036], Action prob: [0.75801677 0.24198322], Action: 0, state: 0\n",
      "[0.75801677 0.24198322]\n",
      "Sensor: [0.3603666090579659, 0.641766688076194, 0.2646501455264183, 0.22280097954428182], Action prob: [0.75839335 0.24160662], Action: 0, state: 0\n",
      "[0.75839335 0.24160662]\n",
      "Sensor: [0.34837448369607793, 0.6463572723581178, 0.2112374848241552, 0.22864494033840554], Action prob: [0.75834846 0.24165158], Action: 0, state: 0\n",
      "tensor([-2.3207, -0.3254, -0.1199,  0.3374, -0.0286,  0.1385,  0.2891,  0.4233],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2440 is -492100, loss is 0.2007745479649308\n",
      "[0.75834846 0.24165158]\n",
      "Sensor: [0.3909754592047333, 0.6530702528902605, 0.2282740542088854, 0.27931011759194513], Action prob: [0.76052415 0.23947585], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.76052415 0.23947585]\n",
      "Sensor: [0.40108208592046973, 0.6404283344746408, 0.2000494619056261, 0.28298227613014176], Action prob: [0.7596014  0.24039862], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.7596014  0.24039862]\n",
      "Sensor: [0.31260953880783143, 0.6376667390070481, 0.24542321451445323, 0.481310739791395], Action prob: [0.75984496 0.24015504], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.75984496 0.24015504]\n",
      "Sensor: [0.35022816960130954, 0.6048260370003004, 0.22625302140473383, 0.30387264353684124], Action prob: [0.759257   0.24074295], Action: 0, state: 0\n",
      "[0.759257   0.24074295]\n",
      "Sensor: [0.3066985169545662, 0.6409340057631133, 0.21987995242036293, 0.24629968982755698], Action prob: [0.75965375 0.24034627], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.75965375 0.24034627]\n",
      "Sensor: [0.34995822190173376, 0.5959497487713105, 0.24399393212480205, 0.3196235829462603], Action prob: [0.75971794 0.24028206], Action: 0, state: 0\n",
      "[0.75971794 0.24028206]\n",
      "Sensor: [0.39531650192093143, 0.6576119149386681, 0.23455029698287183, 0.2864010677304817], Action prob: [0.75953007 0.24046989], Action: 0, state: 0\n",
      "[0.75953007 0.24046989]\n",
      "Sensor: [0.4169535755422006, 0.6770795357672511, 0.2540680543435205, 0.25163195198046456], Action prob: [0.75945795 0.24054207], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "tensor([-1.6730, -0.8767, -1.5606, -0.1813,  0.2156,  0.1435,  0.3227,  2.4266],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2448 is -488700, loss is 0.1479045064728316\n",
      "[0.75945795 0.24054207]\n",
      "Sensor: [0.38778958514968803, 0.6223100518898246, 0.2737628227548852, 0.28213616131395625], Action prob: [0.75961477 0.2403852 ], Action: 0, state: 0\n",
      "[0.75961477 0.2403852 ]\n",
      "Sensor: [0.31969109297865594, 0.6644025643085146, 0.24480699516276586, 0.20631897406191707], Action prob: [0.7593527  0.24064732], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7593527  0.24064732]\n",
      "Sensor: [0.29421969825281646, 0.6612045098775079, 0.21884569828575398, 0.26624788595791626], Action prob: [0.7590826 0.2409174], Action: 0, state: 0\n",
      "[0.7590826 0.2409174]\n",
      "Sensor: [0.38122756657440976, 0.6594539407591414, 0.24032518223715396, 0.2636629625346203], Action prob: [0.75870967 0.24129036], Action: 0, state: 0\n",
      "[0.75870967 0.24129036]\n",
      "Sensor: [0.41694487166898175, 0.6445011327365995, 0.22106358093292805, 0.2328768565261478], Action prob: [0.7584618  0.24153821], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7584618  0.24153821]\n",
      "Sensor: [0.30784668619841765, 0.6484368198123917, 0.232554139377251, 0.25639177197500956], Action prob: [0.75926816 0.24073184], Action: 0, state: 0\n",
      "[0.75926816 0.24073184]\n",
      "Sensor: [0.367243749193787, 0.6799939673020747, 0.21926860318208494, 0.23062958472469547], Action prob: [0.75911826 0.24088179], Action: 0, state: 1\n",
      "[0.75911826 0.24088179]\n",
      "Sensor: [0.3853699021078426, 0.6110346373893297, 0.2297340569583678, 0.26193149717347947], Action prob: [0.7588779  0.24112211], Action: 0, state: 1\n",
      "tensor([-0.4748, -1.4238, -0.1836, -0.0213,  0.5654,  0.1781,  0.2835,  0.3814],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2456 is -482100, loss is 0.08690205342759968\n",
      "[0.7588779  0.24112211]\n",
      "Sensor: [0.38510279762622357, 0.642199327132089, 0.2044949440757811, 0.2397683875425389], Action prob: [0.75755894 0.24244104], Action: 0, state: 1\n",
      "[0.75755894 0.24244104]\n",
      "Sensor: [0.3107497142297102, 0.5981085733106566, 0.24732495083951794, 0.3045166161606795], Action prob: [0.75732183 0.24267815], Action: 0, state: 1\n",
      "[0.75732183 0.24267815]\n",
      "Sensor: [0.4099804338476121, 0.6159849775847296, 0.28762861949437696, 0.213323366684428], Action prob: [0.7563032  0.24369685], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.7563032  0.24369685]\n",
      "Sensor: [0.4099252528210637, 0.6381702387881061, 0.1958826485910435, 0.24841646351127958], Action prob: [0.7561802  0.24381976], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.7561802  0.24381976]\n",
      "Sensor: [0.36757335457692875, 0.675217693424321, 0.22600655004839618, 0.2373027052533903], Action prob: [0.7568027 0.2431974], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7568027 0.2431974]\n",
      "Sensor: [0.3587548746423004, 0.5763758631337892, 0.21433055320662303, 0.23662788859929193], Action prob: [0.7567853  0.24321474], Action: 0, state: 0\n",
      "[0.7567853  0.24321474]\n",
      "Sensor: [0.33608583859363167, 0.6637902440715112, 0.20016706399883788, 0.20352082343737393], Action prob: [0.75708294 0.24291705], Action: 0, state: 0\n",
      "[0.75708294 0.24291705]\n",
      "Sensor: [0.2969630923005454, 0.5679793713096193, 0.3430369091707457, 0.2236380885409529], Action prob: [0.7575466  0.24245344], Action: 0, state: 0\n",
      "tensor([-0.5205, -0.2670, -0.3533,  0.0995,  0.1033,  0.1125,  0.2757,  0.4270],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2464 is -476500, loss is 0.015354667783770572\n",
      "[0.7575466  0.24245344]\n",
      "Sensor: [0.3542012367126576, 0.6215719794750099, 0.2382079972931453, 0.23449269068108566], Action prob: [0.7557353  0.24426469], Action: 0, state: 0\n",
      "[0.7557353  0.24426469]\n",
      "Sensor: [0.39428809499200856, 0.6023541501223683, 0.2439842303534339, 0.21752609693438102], Action prob: [0.75464666 0.24535333], Action: 0, state: 0\n",
      "[0.75464666 0.24535333]\n",
      "Sensor: [0.34874917653788096, 0.6210197652528264, 0.1881138024750439, 0.27099801713299987], Action prob: [0.7542778  0.24572216], Action: 0, state: 0\n",
      "[0.7542778  0.24572216]\n",
      "Sensor: [0.3931012151537799, 0.6337998199892548, 0.20924508261116118, 0.23445771075698607], Action prob: [0.7541645  0.24583545], Action: 0, state: 0\n",
      "[0.7541645  0.24583545]\n",
      "Sensor: [0.37339957600968643, 0.6267907103173816, 0.19468374504023922, 0.24785503582223453], Action prob: [0.75436026 0.2456398 ], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75436026 0.2456398 ]\n",
      "Sensor: [0.3959515515299292, 0.6359536545005786, 0.22892673993371707, 0.23709172862543199], Action prob: [0.75444347 0.24555652], Action: 0, state: 0\n",
      "[0.75444347 0.24555652]\n",
      "Sensor: [0.37838234368828755, 0.6675102353378408, 0.22531024355361265, 0.28959534498571526], Action prob: [0.7546431  0.24535693], Action: 0, state: 0\n",
      "[0.7546431  0.24535693]\n",
      "Sensor: [0.33992074605510836, 0.6692795765006412, 0.23065422997390125, 0.21719814230106071], Action prob: [0.7548157  0.24518426], Action: 0, state: 1\n",
      "tensor([-0.4740, -0.3115, -0.1619, -0.0287,  0.0928,  0.2015,  0.3002,  0.3784],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2472 is -468700, loss is 0.00040863379088191404\n",
      "[0.7548157  0.24518426]\n",
      "Sensor: [0.3430741040833463, 0.6618191764727116, 0.19336069331354971, 0.26920929892872864], Action prob: [0.75401044 0.24598958], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.75401044 0.24598958]\n",
      "Sensor: [0.35704352118145966, 0.6733154741591509, 0.16874934044978868, 0.2465807933411609], Action prob: [0.75286835 0.24713166], Action: 0, state: 0\n",
      "[0.75286835 0.24713166]\n",
      "Sensor: [0.3612169192670922, 0.6648249991275171, 0.17531197674330717, 0.3424443234350848], Action prob: [0.7521504  0.24784955], Action: 0, state: 1\n",
      "[0.7521504  0.24784955]\n",
      "Sensor: [0.4126697573407646, 0.6267567182119524, 0.17148293664347208, 0.3057799550044769], Action prob: [0.75163543 0.2483645 ], Action: 0, state: 2\n",
      "[0.75163543 0.2483645 ]\n",
      "Sensor: [0.45910223130784017, 0.6250038190564831, 0.20076777232327908, 0.2325519033469333], Action prob: [0.75150764 0.24849232], Action: 0, state: 2\n",
      "[0.75150764 0.24849232]\n",
      "Sensor: [0.3527530501844045, 0.6579316521871249, 0.23862261142127145, 0.24744333008047675], Action prob: [0.7523766  0.24762343], Action: 0, state: 2\n",
      "[0.7523766  0.24762343]\n",
      "Sensor: [0.30814904666159104, 0.6602728400359724, 0.23229720357887274, 0.25505642163018444], Action prob: [0.75276846 0.2472315 ], Action: 0, state: 2\n",
      "[0.75276846 0.2472315 ]\n",
      "Sensor: [0.4936681523918444, 0.6431410382310322, 0.23927258132377918, 0.2530643371530066], Action prob: [0.75178593 0.24821404], Action: 0, state: 2\n",
      "tensor([-2.2145, -0.3432, -0.1696, -0.0329,  0.0899,  0.2038,  0.3046,  0.3938],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2480 is -462500, loss is 0.22101822230857882\n",
      "[0.75178593 0.24821404]\n",
      "Sensor: [0.3525143428292595, 0.6394441890309369, 0.20586803662583586, 0.26500357543776654], Action prob: [0.7491051 0.2508948], Action: 0, state: 2\n",
      "[0.7491051 0.2508948]\n",
      "Sensor: [0.3563828799047022, 0.6289210499256904, 0.2189229047448543, 0.26801132190714816], Action prob: [0.74772745 0.25227255], Action: 0, state: 2\n",
      "[0.74772745 0.25227255]\n",
      "Sensor: [0.4239896157593418, 0.6167972814233488, 0.2143812298886908, 0.23088653751780153], Action prob: [0.7464444  0.25355563], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.7464444  0.25355563]\n",
      "Sensor: [0.40703724107337114, 0.3633211637929206, 0.2173513737561139, 0.2286147852245342], Action prob: [0.7458817  0.25411835], Action: 0, state: 1\n",
      "[0.7458817  0.25411835]\n",
      "Sensor: [0.3669283759430782, 0.6288028847793716, 0.2433009831507828, 0.2212399604944447], Action prob: [0.74675584 0.25324416], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.74675584 0.25324416]\n",
      "Sensor: [0.3310198594046347, 0.47532900761277735, 0.22352789422784813, 0.27571433238124343], Action prob: [0.74677026 0.25322968], Action: 0, state: 1\n",
      "[0.74677026 0.25322968]\n",
      "Sensor: [0.3017118168277346, 0.6411045971724147, 0.23688573108552025, 0.2375592043986332], Action prob: [0.74718547 0.25281447], Action: 0, state: 1\n",
      "[0.74718547 0.25281447]\n",
      "Sensor: [0.3622261468449935, 0.6279507663798455, 0.22456565499434578, 0.18350059933810842], Action prob: [0.7468854  0.25311452], Action: 0, state: 2\n",
      "tensor([-0.5074, -0.3078, -0.6017, -0.0436,  0.4882,  0.1732,  0.3063,  0.4125],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2488 is -456800, loss is 0.010035717844596927\n",
      "[0.7468854  0.25311452]\n",
      "Sensor: [0.3578197551982991, 0.6426808839546733, 0.20537010402795014, 0.2146757300161715], Action prob: [0.7446297  0.25537026], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "[0.7446297  0.25537026]\n",
      "Sensor: [0.3718435494822748, 0.627579430085905, 0.21783510695245828, 0.24354009853398031], Action prob: [0.7425857  0.25741425], Action: 0, state: 1\n",
      "[0.7425857  0.25741425]\n",
      "Sensor: [0.3835453344127691, 0.6542323993852974, 0.19212792692118147, 0.26154167869945016], Action prob: [0.74123263 0.2587674 ], Action: 0, state: 2\n",
      "[0.74123263 0.2587674 ]\n",
      "Sensor: [0.39446024954145625, 0.6976567721012774, 0.2063894080655913, 0.2775346158631748], Action prob: [0.74087393 0.25912607], Action: 0, state: 2\n",
      "[0.74087393 0.25912607]\n",
      "Sensor: [0.30687226525890654, 0.62614147930546, 0.21148941373592411, 0.23168136110204937], Action prob: [0.7411108  0.25888917], Action: 0, state: 2\n",
      "[0.7411108  0.25888917]\n",
      "Sensor: [0.36745760439572045, 0.6920651168510024, 0.18834499807923083, 0.26118428865605076], Action prob: [0.7409536  0.25904638], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.7409536  0.25904638]\n",
      "Sensor: [0.3598361251541457, 0.6410710137371662, 0.23760224493226179, 0.2558391981469269], Action prob: [0.74092567 0.25907433], Action: 0, state: 1\n",
      "[0.74092567 0.25907433]\n",
      "Sensor: [0.34622479317946475, 0.5933162274720732, 0.23683993876864212, 0.24419841775221873], Action prob: [0.74086237 0.2591377 ], Action: 0, state: 1\n",
      "tensor([-1.3220, -0.4555, -0.2559, -0.0734,  0.0922,  1.0766,  0.3069,  0.4423],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2496 is -452000, loss is 0.023612965921599574\n",
      "[0.74086237 0.2591377 ]\n",
      "Sensor: [0.3578021722454874, 0.5938579297084308, 0.20598101549209186, 0.2199372595292842], Action prob: [0.74013895 0.25986108], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.74013895 0.25986108]\n",
      "Sensor: [0.3370945519995799, 0.6001516166025096, 0.20355786393709013, 0.2121323639765366], Action prob: [0.73791933 0.26208067], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.73791933 0.26208067]\n",
      "Sensor: [0.39165433954908285, 0.6003828982420593, 0.2327653657375334, 0.5304135635113588], Action prob: [0.7357829  0.26421714], Action: 0, state: 0\n",
      "[0.7357829  0.26421714]\n",
      "Sensor: [0.37224635596555683, 0.6445729281995072, 0.20381421570133168, 0.2679918680879458], Action prob: [0.7351257  0.26487425], Action: 0, state: 0\n",
      "[0.7351257  0.26487425]\n",
      "Sensor: [0.38445627830566076, 0.6375104547617164, 0.22230691740001177, 0.19471448565808494], Action prob: [0.7352326  0.26476744], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7352326  0.26476744]\n",
      "Sensor: [0.32021599155357483, 0.6441096756325401, 0.2199806936327824, 0.22545996981132108], Action prob: [0.7357265  0.26427358], Action: 0, state: 0\n",
      "[0.7357265  0.26427358]\n",
      "Sensor: [0.39673408697759216, 0.6361116223229966, 0.22017168877433688, 0.29132215620462554], Action prob: [0.73534817 0.26465183], Action: 0, state: 0\n",
      "[0.73534817 0.26465183]\n",
      "Sensor: [0.37664453829385147, 0.6431539616602001, 0.19490222113410352, 0.23844866654737548], Action prob: [0.73529774 0.2647023 ], Action: 0, state: 0\n",
      "tensor([-1.4691, -1.4594, -0.3274, -0.1100,  0.3929,  0.1834,  0.3479,  0.4941],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2504 is -446600, loss is 0.24345915823234338\n",
      "[0.73529774 0.2647023 ]\n",
      "Sensor: [0.3204141916524475, 0.6352601762689895, 0.20835126210795746, 0.3071977556485206], Action prob: [0.7321202  0.26787975], Action: 0, state: 1\n",
      "[0.7321202  0.26787975]\n",
      "Sensor: [0.36766005516667977, 0.6818319669108732, 0.2459207529483443, 0.2316073573215534], Action prob: [0.7287175  0.27128255], Action: 0, state: 2\n",
      "[0.7287175  0.27128255]\n",
      "Sensor: [0.3582646170839342, 0.6170327267043885, 0.2478455450831054, 0.2932586692380303], Action prob: [0.72658056 0.27341947], Action: 0, state: 2\n",
      "[0.72658056 0.27341947]\n",
      "Sensor: [0.4018806895543245, 0.6487503907761333, 0.29039972724355, 0.23379780849105603], Action prob: [0.7257361  0.27426386], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "[0.7257361  0.27426386]\n",
      "Sensor: [0.3242659557711718, 0.6442807252067808, 0.2115590961079298, 0.2181545454444841], Action prob: [0.7257629 0.2742371], Action: 0, state: 2\n",
      "[0.7257629 0.2742371]\n",
      "Sensor: [0.3806619120364757, 0.6368273256359565, 0.24376573358827178, 0.23115668127323993], Action prob: [0.7255586  0.27444145], Action: 0, state: 2\n",
      "[0.7255586  0.27444145]\n",
      "Sensor: [0.3881208759540264, 0.5786514648136545, 0.22633502540709685, 0.21720768096788998], Action prob: [0.7253507 0.2746493], Action: 0, state: 3\n",
      "[0.7253507 0.2746493]\n",
      "Sensor: [0.4100037433102707, 0.6327558338727081, 0.1851783648542105, 0.5443092285899699], Action prob: [0.7246573  0.27534273], Action: 0, state: 8\n",
      "tensor([-0.5799, -0.2738,  0.0140,  0.7058,  0.1160,  0.3269,  0.4457, -0.1897],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2512 is -449400, loss is -0.07062716031601414\n",
      "[0.7246573  0.27534273]\n",
      "Sensor: [0.5836650264173737, 0.6520893250185545, 0.22774661240766347, 0.2318697685220616], Action prob: [0.7243794  0.27562052], Action: 0, state: 8\n",
      "[0.7243794  0.27562052]\n",
      "Sensor: [0.33021272070334673, 0.38446272268900467, 0.19085412833624668, 0.24484980115412108], Action prob: [0.72132427 0.27867576], Action: 0, state: 8\n",
      "[0.72132427 0.27867576]\n",
      "Sensor: [0.5144685706145611, 0.6032536354080837, 0.20081088811316564, 0.1893740558820486], Action prob: [0.7186792 0.2813208], Action: 1, state: 8\n",
      "[0.7186792 0.2813208]\n",
      "Sensor: [0.32858133131619344, 0.6378320875919062, 0.1827192677220798, 0.4045623448941048], Action prob: [0.7177738  0.28222623], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.7177738  0.28222623]\n",
      "Sensor: [0.35655691887149554, 0.6140071903562982, 0.22154342813056105, 0.2790764674954626], Action prob: [0.7171101  0.28288993], Action: 0, state: 0\n",
      "[0.7171101  0.28288993]\n",
      "Sensor: [0.34415732329144777, 0.6366255915086737, 0.22073035211460887, 0.279230257871858], Action prob: [0.7168774 0.2831227], Action: 0, state: 0\n",
      "[0.7168774 0.2831227]\n",
      "Sensor: [0.40221763573465585, 0.6293461448853419, 0.22594511322862257, 0.24505027540839625], Action prob: [0.71662277 0.28337723], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.71662277 0.28337723]\n",
      "Sensor: [0.38773100547655587, 0.6721654710454822, 0.19676484915454667, 0.24688772205656423], Action prob: [0.7166815  0.28331852], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([ 0.7375,  0.1532, -1.5304, -0.8657, -0.2304, -0.0967,  0.0830,  0.0807],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2520 is -452400, loss is 0.20858130688704182\n",
      "[0.7166815  0.28331852]\n",
      "Sensor: [0.33910825492348523, 0.634825141801741, 0.25806608012120297, 0.24001052352695407], Action prob: [0.71643025 0.28356978], Action: 0, state: 0\n",
      "[0.71643025 0.28356978]\n",
      "Sensor: [0.3374429070366513, 0.6228058868124529, 0.23338307097215452, 0.3100329617264339], Action prob: [0.7102795  0.28972048], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7102795  0.28972048]\n",
      "Sensor: [0.3338982868043228, 0.6128157275523192, 0.16418998056720005, 0.24304836151162273], Action prob: [0.7067669  0.29323313], Action: 0, state: 0\n",
      "[0.7067669  0.29323313]\n",
      "Sensor: [0.3552839322460893, 0.6190013755465196, 0.19541999108407004, 0.22627334874880364], Action prob: [0.7052191 0.2947809], Action: 0, state: 1\n",
      "[0.7052191 0.2947809]\n",
      "Sensor: [0.39278092058821096, 0.5721986519273338, 0.2020657893162971, 0.3254284572683948], Action prob: [0.70401627 0.29598376], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.70401627 0.29598376]\n",
      "Sensor: [0.3651219259221051, 0.6392130169507223, 0.2295066287900375, 0.2365189212815848], Action prob: [0.7037894 0.2962106], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.7037894 0.2962106]\n",
      "Sensor: [0.3609556434777722, 0.6764873566668158, 0.20738332869848064, 0.24481236399425255], Action prob: [0.70366156 0.29633844], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.70366156 0.29633844]\n",
      "Sensor: [0.3605695540311718, 0.5819059794373929, 0.21843315015920733, 0.3142913587858844], Action prob: [0.70331025 0.29668972], Action: 0, state: 0\n",
      "tensor([-0.6516, -1.2033, -0.1874,  0.0600,  0.9992,  0.9916,  1.3408,  0.2082],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2528 is -448700, loss is -0.19467760432993003\n",
      "[0.70331025 0.29668972]\n",
      "Sensor: [0.3391886150035927, 0.5924798132296881, 0.20498903625963277, 0.23541569862417502], Action prob: [0.7121506  0.28784946], Action: 0, state: 1\n",
      "[0.7121506  0.28784946]\n",
      "Sensor: [0.3237660362548289, 0.6464196755834131, 0.2639908748373078, 0.20798800421447536], Action prob: [0.7066477 0.2933523], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.7066477 0.2933523]\n",
      "Sensor: [0.3417755230199421, 0.6224611301125375, 0.23852217509893262, 0.24950168781383722], Action prob: [0.7031221 0.2968779], Action: 0, state: 1\n",
      "[0.7031221 0.2968779]\n",
      "Sensor: [0.3313454005110323, 0.6151423555060797, 0.24045052875960443, 0.2558324193777943], Action prob: [0.7015177  0.29848227], Action: 0, state: 1\n",
      "[0.7015177  0.29848227]\n",
      "Sensor: [0.3492700451955096, 0.6374758048874797, 0.20917674204670553, 0.21288920166646458], Action prob: [0.70082235 0.29917765], Action: 0, state: 1\n",
      "[0.70082235 0.29917765]\n",
      "Sensor: [0.35446690658959995, 0.6003646048558485, 0.49565673789503123, 0.2883031967469445], Action prob: [0.70049447 0.2995056 ], Action: 0, state: 1\n",
      "[0.70049447 0.2995056 ]\n",
      "Sensor: [0.37776851445373266, 0.6458681964760785, 0.20648802130885957, 0.23692842459829527], Action prob: [0.69976455 0.30023545], Action: 0, state: 1\n",
      "[0.69976455 0.30023545]\n",
      "Sensor: [0.36291609810776826, 0.6342043982549878, 0.19677507245093528, 0.3220912412445146], Action prob: [0.6996379  0.30036214], Action: 0, state: 1\n",
      "tensor([-0.5382, -1.2249, -0.2584, -0.0702,  0.0981,  0.2605,  0.3919,  0.5200],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2536 is -442100, loss is 0.10264700235596237\n",
      "[0.6996379  0.30036214]\n",
      "Sensor: [0.28443732614224554, 0.652281875988159, 0.24392366833888898, 0.21387163136633658], Action prob: [0.7063215  0.29367855], Action: 0, state: 1\n",
      "[0.7063215  0.29367855]\n",
      "Sensor: [0.33042022180483144, 0.6345951958549364, 0.24266886576252314, 0.21351342497520087], Action prob: [0.69958186 0.30041808], Action: 0, state: 2\n",
      "[0.69958186 0.30041808]\n",
      "Sensor: [0.3215337973408668, 0.6098896638874711, 0.24759374008184018, 0.24190557071769117], Action prob: [0.69594675 0.30405325], Action: 0, state: 2\n",
      "[0.69594675 0.30405325]\n",
      "Sensor: [0.366882079765305, 0.6474379827304442, 0.2150513118621482, 0.2968984987833256], Action prob: [0.6938655  0.30613455], Action: 0, state: 2\n",
      "[0.6938655  0.30613455]\n",
      "Sensor: [0.3985523918780868, 0.5885631849683185, 0.2553385522607122, 0.2758002923396944], Action prob: [0.6928925  0.30710757], Action: 0, state: 2\n",
      "[0.6928925  0.30710757]\n",
      "Sensor: [0.38396892793967025, 0.6001450404662128, 0.2403593316543783, 0.24697344405161126], Action prob: [0.6925918  0.30740824], Action: 0, state: 2\n",
      "[0.6925918  0.30740824]\n",
      "Sensor: [0.35702565114045726, 0.6212090043902952, 0.48727832351677813, 0.26693145302170873], Action prob: [0.69261926 0.3073808 ], Action: 0, state: 3\n",
      "[0.69261926 0.3073808 ]\n",
      "Sensor: [0.4164846454215701, 0.6352339991957857, 0.47445151973625627, 0.21582820729221824], Action prob: [0.69217676 0.3078232 ], Action: 0, state: 8\n",
      "tensor([-0.6121, -0.3787, -0.1535,  0.0530,  0.2413,  0.4100,  0.5114, -0.0065],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2544 is -443600, loss is -0.00811559671411528\n",
      "[0.69217676 0.3078232 ]\n",
      "Sensor: [0.38718802173402933, 0.6158960075919347, 0.486454783494439, 0.2747808082904621], Action prob: [0.6989043 0.3010957], Action: 0, state: 8\n",
      "[0.6989043 0.3010957]\n",
      "Sensor: [0.35610552654592265, 0.619920497177363, 0.47565818276895755, 0.24159183393972167], Action prob: [0.6914801  0.30851993], Action: 0, state: 8\n",
      "[0.6914801  0.30851993]\n",
      "Sensor: [0.5139161966885392, 0.6432793811527047, 0.19820652035488937, 0.5995663191061523], Action prob: [0.68544906 0.31455097], Action: 0, state: 8\n",
      "[0.68544906 0.31455097]\n",
      "Sensor: [0.3344259526870934, 0.6424914507637695, 0.48106520783428386, 0.2565749598644439], Action prob: [0.68467295 0.3153271 ], Action: 1, state: 8\n",
      "[0.68467295 0.3153271 ]\n",
      "Sensor: [0.36497675122642587, 0.669667453788554, 0.1957346044158546, 0.5649417860994683], Action prob: [0.6829413  0.31705868], Action: 0, state: 8\n",
      "[0.6829413  0.31705868]\n",
      "Sensor: [0.35534171807768533, 0.6057508185939082, 0.520622572973843, 0.20174196891652496], Action prob: [0.6834307 0.3165693], Action: 0, state: 8\n",
      "[0.6834307 0.3165693]\n",
      "Sensor: [0.5677913856843632, 0.6647720029127384, 0.19145106029406989, 0.27298901233366213], Action prob: [0.6825365  0.31746352], Action: 1, state: 8\n",
      "[0.6825365  0.31746352]\n",
      "Sensor: [0.5854066864183752, 0.6630074195957096, 0.18447788576878965, 0.2732789056921377], Action prob: [0.68263257 0.3173674 ], Action: 1, state: 8\n",
      "tensor([ 0.6100,  0.4116,  0.2237,  0.1345, -0.1157, -0.2654, -1.2282, -1.5874],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2552 is -467600, loss is 0.22711687443395784\n",
      "[0.68263257 0.3173674 ]\n",
      "Sensor: [0.636786975393276, 0.6559639935767122, 0.1916702415966188, 0.2200862727549629], Action prob: [0.6876167 0.3123833], Action: 0, state: 8\n",
      "[0.6876167 0.3123833]\n",
      "Sensor: [0.32151908730575773, 0.3934101310740684, 0.22323566451736074, 0.2795758871165977], Action prob: [0.6797442  0.32025582], Action: 0, state: 8\n",
      "[0.6797442  0.32025582]\n",
      "Sensor: [0.6268992951080458, 0.4102614404982497, 0.22543358878541023, 0.2611553261001324], Action prob: [0.6734112 0.3265888], Action: 0, state: 8\n",
      "[0.6734112 0.3265888]\n",
      "Sensor: [0.36020514240745144, 0.4106682930824084, 0.23990424306038058, 0.21835225461485816], Action prob: [0.6717042  0.32829583], Action: 1, state: 8\n",
      "[0.6717042  0.32829583]\n",
      "Sensor: [0.26844083414084974, 0.4382920169918925, 0.6303746919309947, 0.23665724080447428], Action prob: [0.6706137  0.32938632], Action: 1, state: 8\n",
      "[0.6706137  0.32938632]\n",
      "Sensor: [0.40550106339224457, 0.6652237781331456, 0.22356868548701586, 0.21480040254599395], Action prob: [0.6685259 0.3314741], Action: 0, state: 0\n",
      "[0.6685259 0.3314741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3847303971668469, 0.6169183005197143, 0.2264303609067897, 0.23712967523515613], Action prob: [0.668217 0.331783], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.668217 0.331783]\n",
      "Sensor: [0.41284686040687313, 0.6697605270711147, 0.20859589199046255, 0.2986633194551894], Action prob: [0.6676357 0.3323643], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "tensor([ 0.7403,  0.4369,  0.1269, -0.4196, -1.0987, -0.3365, -0.7263, -0.6385],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2560 is -477600, loss is 0.23943407755394241\n",
      "[0.6676357 0.3323643]\n",
      "Sensor: [0.3159410317809058, 0.6569983236623137, 0.18161359590973797, 0.24894950581995426], Action prob: [0.675491   0.32450902], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.675491   0.32450902]\n",
      "Sensor: [0.3517156643703836, 0.6678759769888312, 0.19890844921976525, 0.22659125447438833], Action prob: [0.6612958  0.33870426], Action: 0, state: 0\n",
      "[0.6612958  0.33870426]\n",
      "Sensor: [0.3669655555206688, 0.657963573789429, 0.21746173010146466, 0.2912906063024279], Action prob: [0.65236485 0.34763515], Action: 0, state: 0\n",
      "[0.65236485 0.34763515]\n",
      "Sensor: [0.41780627985588104, 0.6573676911670587, 0.22694604293385046, 0.24888522869574034], Action prob: [0.64748144 0.35251856], Action: 0, state: 0\n",
      "[0.64748144 0.35251856]\n",
      "Sensor: [0.40692606699626716, 0.5881772707007719, 0.23140977064410728, 0.2652168375285502], Action prob: [0.6452239  0.35477602], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.6452239  0.35477602]\n",
      "Sensor: [0.34852266124364145, 0.626044126260318, 0.23352060216237364, 0.2697322253159082], Action prob: [0.64388376 0.3561162 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.64388376 0.3561162 ]\n",
      "Sensor: [0.3427766308270009, 0.6461371481615543, 0.2481873042945318, 0.25231805640394117], Action prob: [0.64309007 0.35691002], Action: 0, state: 0\n",
      "[0.64309007 0.35691002]\n",
      "Sensor: [0.39062076357477077, 0.6122147387362414, 0.23991940001310444, 0.2597176620468026], Action prob: [0.642605   0.35739505], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.6656, -0.6135, -0.2779,  0.0382,  0.7897,  0.7900,  0.3374,  1.2368],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2568 is -473700, loss is -0.07939670940917609\n",
      "[0.642605   0.35739505]\n",
      "Sensor: [0.287340725488034, 0.651916810482922, 0.39561652159781896, 0.2468028950515259], Action prob: [0.6648111  0.33518893], Action: 0, state: 0\n",
      "[0.6648111  0.33518893]\n",
      "Sensor: [0.37447834678860764, 0.6686495597295776, 0.22392971606524342, 0.29909883591125525], Action prob: [0.6482631 0.3517369], Action: 0, state: 0\n",
      "[0.6482631 0.3517369]\n",
      "Sensor: [0.3052667587765036, 0.6741835132009532, 0.22380075674614386, 0.25615127273535176], Action prob: [0.6396461 0.3603539], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6396461 0.3603539]\n",
      "Sensor: [0.3241246048520338, 0.6519359170433423, 0.18801311626179054, 0.25583524103438265], Action prob: [0.6352497  0.36475036], Action: 0, state: 0\n",
      "[0.6352497  0.36475036]\n",
      "Sensor: [0.34222388308415364, 0.6347410432347727, 0.21498553616035987, 0.2817677813741784], Action prob: [0.63262224 0.36737767], Action: 0, state: 1\n",
      "[0.63262224 0.36737767]\n",
      "Sensor: [0.3754672542249221, 0.6014220743076341, 0.4948167776924942, 0.24746324575817996], Action prob: [0.6305962  0.36940375], Action: 0, state: 9\n",
      "[0.6305962  0.36940375]\n",
      "Sensor: [0.3047823928413484, 0.4134308071775139, 0.23859958495154499, 0.2177787204334839], Action prob: [0.63112617 0.36887392], Action: 1, state: 9\n",
      "[0.63112617 0.36887392]\n",
      "Sensor: [0.3276625770702527, 0.36235859640246243, 0.22988645341461808, 0.23206394882883585], Action prob: [0.6317784  0.36822158], Action: 1, state: 9\n",
      "tensor([-0.7844, -0.3372,  0.2672,  0.3298,  0.6809,  0.3414,  0.0522, -0.5601],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2576 is -474300, loss is 0.0012691122132714033\n",
      "[0.6317784  0.36822158]\n",
      "Sensor: [0.3697697648664915, 0.16135477247285604, 0.20127737291895462, 0.2449495986308374], Action prob: [0.6578186  0.34218144], Action: 0, state: 9\n",
      "[0.6578186  0.34218144]\n",
      "Sensor: [0.2790766345422981, 0.38924537190832204, 0.206826945930201, 0.2149463373472418], Action prob: [0.64102334 0.35897675], Action: 0, state: 9\n",
      "[0.64102334 0.35897675]\n",
      "Sensor: [0.38032772072897547, 0.6201665330678436, 0.22329462772887368, 0.8770523140265754], Action prob: [0.6237576  0.37624237], Action: 0, state: 9\n",
      "[0.6237576  0.37624237]\n",
      "Sensor: [0.3395923328409377, 0.7546632457469684, 0.5998135694378258, 0.6262705153426507], Action prob: [0.6146683  0.38533172], Action: 1, state: 9\n",
      "[0.6146683  0.38533172]\n",
      "Sensor: [0.3661058858119582, 0.3729654164216527, 0.20255192195080865, 0.24680446546855297], Action prob: [0.61462015 0.38537985], Action: 1, state: 9\n",
      "[0.61462015 0.38537985]\n",
      "Sensor: [0.3515345249415687, 0.32797419685496176, 0.17052679685908723, 0.2514923410482145], Action prob: [0.61566967 0.38433036], Action: 0, state: 9\n",
      "[0.61566967 0.38433036]\n",
      "Sensor: [0.3517227745256237, 0.6507442848502443, 0.21978544065260056, 0.5369469272131401], Action prob: [0.6122438  0.38775617], Action: 0, state: 9\n",
      "[0.6122438  0.38775617]\n",
      "Sensor: [0.371356395216891, 0.37171472409652373, 0.20115695053936075, 0.2216916541809685], Action prob: [0.61384535 0.38615462], Action: 0, state: 9\n",
      "tensor([ 0.7080,  0.4903,  0.2921,  0.1363, -0.3131, -0.3452, -0.5102, -0.6696],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2584 is -482300, loss is 0.0264229350747726\n",
      "[0.61384535 0.38615462]\n",
      "Sensor: [0.5917836883528224, 0.5966932447822866, 0.20457232591180832, 0.27447536470821865], Action prob: [0.64375955 0.3562404 ], Action: 1, state: 9\n",
      "[0.64375955 0.3562404 ]\n",
      "Sensor: [0.39074377292630347, 0.43668792777993876, 0.5413029147792539, 0.26426109405759624], Action prob: [0.6246248  0.37537518], Action: 0, state: 9\n",
      "[0.6246248  0.37537518]\n",
      "Sensor: [0.35819019166333776, 0.6474520922526864, 0.21071733961156372, 0.540254534702805], Action prob: [0.61134595 0.38865402], Action: 1, state: 9\n",
      "[0.61134595 0.38865402]\n",
      "Sensor: [0.34248359620789537, 0.6521434118729811, 0.5241487404699933, 0.243056356322552], Action prob: [0.605569   0.39443097], Action: 1, state: 9\n",
      "[0.605569   0.39443097]\n",
      "Sensor: [0.3627262647712241, 0.3379358761843258, 0.24221277223515494, 0.2638106155222467], Action prob: [0.6047227  0.39527738], Action: 0, state: 9\n",
      "[0.6047227  0.39527738]\n",
      "Sensor: [0.5165168194450167, 0.5704669098773132, 0.2304179221226857, 0.20432280787321605], Action prob: [0.6029484  0.39705154], Action: 1, state: 9\n",
      "[0.6029484  0.39705154]\n",
      "Sensor: [0.3520344750720764, 0.41910286405842306, 0.20783740863654745, 0.23354557605824558], Action prob: [0.6035447 0.3964552], Action: 0, state: 9\n",
      "[0.6035447 0.3964552]\n",
      "Sensor: [0.3768185749288569, 0.5788592142559092, 0.21368876561393907, 0.604786308719282], Action prob: [0.60014147 0.3998586 ], Action: 0, state: 9\n",
      "tensor([ 1.7187,  0.5240,  0.5563,  0.0996, -0.1640, -0.6758, -0.5360, -0.6881],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2592 is -490300, loss is -0.10433456657650443\n",
      "[0.60014147 0.3998586 ]\n",
      "Sensor: [0.4415853879828486, 0.6493492494723726, 0.19054181482812643, 0.5624473646722763], Action prob: [0.63796985 0.36203012], Action: 0, state: 9\n",
      "[0.63796985 0.36203012]\n",
      "Sensor: [0.6216264870599342, 0.6082062650697112, 0.4493098190845052, 0.2843302213282862], Action prob: [0.6182468 0.3817532], Action: 0, state: 9\n",
      "[0.6182468 0.3817532]\n",
      "Sensor: [0.31136716341280746, 0.4076517961804982, 0.510955320227711, 0.26907053153203714], Action prob: [0.610442   0.38955805], Action: 1, state: 9\n",
      "[0.610442   0.38955805]\n",
      "Sensor: [0.6588360959444821, 0.6209392815920015, 0.21768899037023434, 0.1981315530332044], Action prob: [0.6048865  0.39511353], Action: 0, state: 9\n",
      "[0.6048865  0.39511353]\n",
      "Sensor: [0.35762128576016017, 0.687201376693952, 0.20229803287239, 0.5590699246643257], Action prob: [0.6010184  0.39898157], Action: 0, state: 9\n",
      "[0.6010184  0.39898157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.42674138161410097, 0.36780313237667933, 0.22608004741765175, 0.2479286573665402], Action prob: [0.6020116  0.39798838], Action: 0, state: 9\n",
      "[0.6020116  0.39798838]\n",
      "Sensor: [0.3375326930226764, 0.6411980367529448, 0.21231890841835277, 0.5731309208561297], Action prob: [0.5996135  0.40038654], Action: 1, state: 9\n",
      "[0.5996135  0.40038654]\n",
      "Sensor: [0.3164636040835397, 0.6485665035590081, 0.2096564361749249, 0.5927442074153441], Action prob: [0.59833676 0.4016633 ], Action: 1, state: 9\n",
      "tensor([ 0.7616,  0.5234,  0.5552,  0.0328, -0.1601, -0.3651, -0.9521, -1.2302],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2600 is -498300, loss is 0.10430447680517059\n",
      "[0.59833676 0.4016633 ]\n",
      "Sensor: [0.34777236136092193, 0.6254621875287935, 0.17874272220604193, 0.5731491022229753], Action prob: [0.63163394 0.36836606], Action: 1, state: 9\n",
      "[0.63163394 0.36836606]\n",
      "Sensor: [0.3936216206398839, 0.39117617374353353, 0.4217978892153855, 0.23123181715193297], Action prob: [0.61326665 0.38673335], Action: 0, state: 9\n",
      "[0.61326665 0.38673335]\n",
      "Sensor: [0.37408707955966936, 0.6609750157192664, 0.18529337738637988, 0.5225243895824887], Action prob: [0.60086393 0.39913607], Action: 0, state: 9\n",
      "[0.60086393 0.39913607]\n",
      "Sensor: [0.2986535584208028, 0.39629030977211566, 0.18426206405673434, 0.24252336784083187], Action prob: [0.5987156  0.40128443], Action: 1, state: 9\n",
      "[0.5987156  0.40128443]\n",
      "Sensor: [0.36354407734192823, 0.5894546971311194, 0.21736143878315609, 0.2766496173133851], Action prob: [0.5955811 0.4044189], Action: 0, state: 0\n",
      "[0.5955811 0.4044189]\n",
      "Sensor: [0.3238180612021879, 0.6218821695651441, 0.17044812251406527, 0.2668437987788309], Action prob: [0.5941621 0.4058378], Action: 0, state: 0\n",
      "[0.5941621 0.4058378]\n",
      "Sensor: [0.33174860828863634, 0.6151286765440626, 0.2391741100544488, 0.30652056713177794], Action prob: [0.5928945  0.40710548], Action: 0, state: 0\n",
      "[0.5928945  0.40710548]\n",
      "Sensor: [0.38699292904928745, 0.6433510694834526, 0.20980193851109974, 0.32144468990531516], Action prob: [0.59178126 0.4082188 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([ 1.4443,  0.1347, -0.3869, -1.5600, -0.4506, -0.0580,  0.3023,  1.0100],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2608 is -496900, loss is -0.05446194955289871\n",
      "[0.59178126 0.4082188 ]\n",
      "Sensor: [0.3717924230306742, 0.6364736204845955, 0.2319075206107913, 0.2564952810074729], Action prob: [0.6300593  0.36994073], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6300593  0.36994073]\n",
      "Sensor: [0.38594111812514437, 0.6725178055869347, 0.18353830101973992, 0.27250953410709283], Action prob: [0.6089107  0.39108935], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6089107  0.39108935]\n",
      "Sensor: [0.36382046273778057, 0.6547066752102528, 0.20862488694830697, 0.20106822266359997], Action prob: [0.59871614 0.40128383], Action: 0, state: 0\n",
      "[0.59871614 0.40128383]\n",
      "Sensor: [0.36673349214426515, 0.6479288037628808, 0.2330365019814338, 0.23430624047376025], Action prob: [0.59300286 0.40699708], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.59300286 0.40699708]\n",
      "Sensor: [0.3588578817769289, 0.6270117579251085, 0.2563102618510012, 0.22790822727158022], Action prob: [0.5900555  0.40994453], Action: 0, state: 0\n",
      "[0.5900555  0.40994453]\n",
      "Sensor: [0.31447214672111734, 0.648991447728443, 0.19674128895279042, 0.29387140968490755], Action prob: [0.5882578  0.41174215], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "[0.5882578  0.41174215]\n",
      "Sensor: [0.3164364066567198, 0.6296326283538646, 0.16369955877217104, 0.27075490536689034], Action prob: [0.58776015 0.41223982], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.58776015 0.41223982]\n",
      "Sensor: [0.33123793154623177, 0.6244512195550957, 0.2059876484109802, 0.27802291552935515], Action prob: [0.58731556 0.41268438], Action: 0, state: 0\n",
      "tensor([-1.7127, -1.0688, -0.3144,  0.3072,  0.4069,  1.3723,  0.4463,  0.1030],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2616 is -494400, loss is 0.05752471186856995\n",
      "[0.58731556 0.41268438]\n",
      "Sensor: [0.34578989149590117, 0.5754509424578123, 0.25278920073718514, 0.2515016105168771], Action prob: [0.6258276  0.37417245], Action: 0, state: 0\n",
      "[0.6258276  0.37417245]\n",
      "Sensor: [0.3575588128125008, 0.6284981686643629, 0.2369220290922327, 0.42574199198855944], Action prob: [0.60338587 0.39661407], Action: 0, state: 0\n",
      "[0.60338587 0.39661407]\n",
      "Sensor: [0.3651038007878576, 0.6364636359176385, 0.21431779391517874, 0.2646327527393922], Action prob: [0.59377885 0.40622112], Action: 0, state: 0\n",
      "[0.59377885 0.40622112]\n",
      "Sensor: [0.3532494529513186, 0.6571572996566742, 0.22475638845715884, 0.2529697421305437], Action prob: [0.58926654 0.41073346], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.58926654 0.41073346]\n",
      "Sensor: [0.34561355614851513, 0.6191281223923878, 0.24731728243312467, 0.25220651086505413], Action prob: [0.58699965 0.4130004 ], Action: 0, state: 0\n",
      "[0.58699965 0.4130004 ]\n",
      "Sensor: [0.3295868699977515, 0.6734421155812692, 0.19816932256217212, 0.23087182863624184], Action prob: [0.58587795 0.41412196], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.58587795 0.41412196]\n",
      "Sensor: [0.3036945537915202, 0.5806632307984702, 0.26954516094310854, 0.25776970333434823], Action prob: [0.5854522 0.4145478], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5854522 0.4145478]\n",
      "Sensor: [0.3927437533397026, 0.6500519952560825, 0.2648210582359704, 0.3299660270936322], Action prob: [0.58383834 0.4161617 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "tensor([-0.9390, -0.5476, -0.1469,  0.4037,  0.0667,  0.6318,  0.8759,  0.8700],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2624 is -490900, loss is -0.15183208384446578\n",
      "[0.58383834 0.4161617 ]\n",
      "Sensor: [0.32147386706374936, 0.6810355074035919, 0.23817938325190469, 0.2599665463207792], Action prob: [0.62698376 0.37301624], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "[0.62698376 0.37301624]\n",
      "Sensor: [0.29622797465410894, 0.6112251267087855, 0.20930727976330019, 0.623008530498657], Action prob: [0.6067754  0.39322463], Action: 0, state: 0\n",
      "[0.6067754  0.39322463]\n",
      "Sensor: [0.3211625242471072, 0.6480508948159367, 0.22152379045691425, 0.21928075146342083], Action prob: [0.600317   0.39968303], Action: 0, state: 1\n",
      "[0.600317   0.39968303]\n",
      "Sensor: [0.3182913256784637, 0.6196435132427578, 0.2507307787537492, 0.2328752804541449], Action prob: [0.5976412  0.40235874], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.5976412  0.40235874]\n",
      "Sensor: [0.390080960520969, 0.5717377172110644, 0.22031923840755574, 0.23870577751402722], Action prob: [0.59618294 0.40381697], Action: 0, state: 1\n",
      "[0.59618294 0.40381697]\n",
      "Sensor: [0.35832904509611085, 0.641658250400016, 0.22146484711955522, 0.28918527498847], Action prob: [0.5949344  0.40506557], Action: 0, state: 1\n",
      "[0.5949344  0.40506557]\n",
      "Sensor: [0.37382158233900276, 0.5976404846250962, 0.22500253092235237, 0.24181917896841107], Action prob: [0.5947135  0.40528652], Action: 0, state: 2\n",
      "[0.5947135  0.40528652]\n",
      "Sensor: [0.39066649123423847, 0.6820091947925151, 0.21716408240235752, 0.2359624725198956], Action prob: [0.59426165 0.4057384 ], Action: 0, state: 2\n",
      "tensor([-0.0771, -0.9086, -0.4578, -0.1163, -0.1131,  0.2513,  0.5397,  0.7998],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2632 is -487500, loss is 0.010244976708857712\n",
      "[0.59426165 0.4057384 ]\n",
      "Sensor: [0.3329848770824756, 0.5805039668738002, 0.22726847926020755, 0.27273263279621773], Action prob: [0.6283225 0.3716775], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.6283225 0.3716775]\n",
      "Sensor: [0.40883071705561685, 0.6117656220553259, 0.2108111566864142, 0.24274731098357633], Action prob: [0.6123893  0.38761067], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6123893  0.38761067]\n",
      "Sensor: [0.35785468522279607, 0.595100404953689, 0.2461153076821337, 0.2703458752217162], Action prob: [0.6056617  0.39433834], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6056617  0.39433834]\n",
      "Sensor: [0.3701401861573746, 0.6232348163057281, 0.264360208910084, 0.28724471781203753], Action prob: [0.6021703  0.39782974], Action: 0, state: 0\n",
      "[0.6021703  0.39782974]\n",
      "Sensor: [0.38269785221080904, 0.6907097413221817, 0.2589186450975175, 0.4005434749429253], Action prob: [0.5995925 0.4004075], Action: 0, state: 0\n",
      "[0.5995925 0.4004075]\n",
      "Sensor: [0.3972542945644141, 0.5980967723466539, 0.222272428954911, 0.2791602956985596], Action prob: [0.5995371  0.40046284], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5995371  0.40046284]\n",
      "Sensor: [0.3765058920020578, 0.6201169264852481, 0.23526392399245388, 0.2087879511073074], Action prob: [0.60004514 0.3999549 ], Action: 0, state: 0\n",
      "[0.60004514 0.3999549 ]\n",
      "Sensor: [0.36239456100189726, 0.6089836735394851, 0.22926047912773012, 0.25047584014606594], Action prob: [0.60012996 0.39986998], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.4347, -1.0586, -0.6735, -0.1910,  0.1299,  0.7364,  0.5378,  1.3444],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2640 is -482700, loss is 0.07617232711360791\n",
      "[0.60012996 0.39986998]\n",
      "Sensor: [0.375307402594015, 0.6569457638477035, 0.21239529063788867, 0.25146935349435884], Action prob: [0.62702084 0.3729792 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.62702084 0.3729792 ]\n",
      "Sensor: [0.3072603336301353, 0.5678078475345985, 0.1805756284300909, 0.22442178342386332], Action prob: [0.61410844 0.38589156], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.61410844 0.38589156]\n",
      "Sensor: [0.3842389568533453, 0.6219645467506681, 0.2282312684914034, 0.21604987093590577], Action prob: [0.60817635 0.39182365], Action: 0, state: 0\n",
      "[0.60817635 0.39182365]\n",
      "Sensor: [0.34686607328075514, 0.6539450150386457, 0.2423939770018878, 0.2730815163607463], Action prob: [0.6052973  0.39470267], Action: 0, state: 0\n",
      "[0.6052973  0.39470267]\n",
      "Sensor: [0.35820616199696803, 0.6813825242220739, 0.20643477047980843, 0.16777392595431914], Action prob: [0.60462147 0.39537853], Action: 0, state: 1\n",
      "[0.60462147 0.39537853]\n",
      "Sensor: [0.3231111767686519, 0.6336120464420529, 0.20214630563193686, 0.27521359102843873], Action prob: [0.60412353 0.39587644], Action: 0, state: 1\n",
      "[0.60412353 0.39587644]\n",
      "Sensor: [0.41560660273699934, 0.6689000460290019, 0.22462147498779608, 0.2151652436896276], Action prob: [0.6035356  0.39646435], Action: 0, state: 2\n",
      "[0.6035356  0.39646435]\n",
      "Sensor: [0.35545339872644643, 0.6355000147799452, 0.17885213901205552, 0.2630934021712164], Action prob: [0.60362947 0.39637053], Action: 0, state: 2\n",
      "tensor([-0.9492, -1.3140, -0.5006, -0.1591,  0.1123,  0.3696,  0.5652,  0.7494],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2648 is -477500, loss is 0.1408148753886595\n",
      "[0.60362947 0.39637053]\n",
      "Sensor: [0.36627042876913846, 0.614880494062982, 0.20700802818798125, 0.18613190694243528], Action prob: [0.6236186  0.37638143], Action: 0, state: 2\n",
      "[0.6236186  0.37638143]\n",
      "Sensor: [0.34707708004323623, 0.4658545872538646, 0.2211523078334164, 0.28782456655429145], Action prob: [0.6100997  0.38990036], Action: 0, state: 3\n",
      "[0.6100997  0.38990036]\n",
      "Sensor: [0.2998773451563274, 0.35242687319332167, 0.17048436770240438, 0.4686343218241472], Action prob: [0.6046289  0.39537105], Action: 0, state: 8\n",
      "[0.6046289  0.39537105]\n",
      "Sensor: [0.36874688870811767, 0.6473950611465138, 0.48139508799815056, 0.26360628825147225], Action prob: [0.60076314 0.39923683], Action: 0, state: 8\n",
      "[0.60076314 0.39923683]\n",
      "Sensor: [0.3881947639005587, 0.6212666349359413, 0.21551736717561287, 0.5649997754336702], Action prob: [0.59837854 0.40162143], Action: 1, state: 8\n",
      "[0.59837854 0.40162143]\n",
      "Sensor: [0.354875525968223, 0.6045427597215647, 0.17856489313692286, 0.5646083294382976], Action prob: [0.59781176 0.40218824], Action: 1, state: 8\n",
      "[0.59781176 0.40218824]\n",
      "Sensor: [0.4036231528723697, 0.42094971184165053, 0.21371906269663174, 0.5453676783713112], Action prob: [0.5982097  0.40179038], Action: 0, state: 8\n",
      "[0.5982097  0.40179038]\n",
      "Sensor: [0.35704238655442666, 0.3805948911466661, 0.24212407083314652, 0.3026151475848071], Action prob: [0.5999838  0.40001622], Action: 1, state: 8\n",
      "tensor([ 0.5819,  0.6716,  0.3902,  0.1102, -0.2364, -0.6356, -0.5615, -1.3418],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2656 is -498000, loss is 0.1276535835016469\n",
      "[0.5999838  0.40001622]\n",
      "Sensor: [0.36552854019658026, 0.34666590692680466, 0.19635998875178537, 0.284376986932211], Action prob: [0.6168142 0.3831858], Action: 0, state: 8\n",
      "[0.6168142 0.3831858]\n",
      "Sensor: [0.41002694269367457, 0.38076075912450386, 0.22928048287696606, 0.22624818273677377], Action prob: [0.6028577  0.39714226], Action: 0, state: 8\n",
      "[0.6028577  0.39714226]\n",
      "Sensor: [0.36230811235684096, 0.6115530486715303, 0.20725878598481434, 0.6372421483245819], Action prob: [0.5937269  0.40627307], Action: 0, state: 8\n",
      "[0.5937269  0.40627307]\n",
      "Sensor: [0.5906687095814046, 0.6531106630699179, 0.18300040587778754, 0.18401197750916254], Action prob: [0.59178257 0.40821737], Action: 0, state: 8\n",
      "[0.59178257 0.40821737]\n",
      "Sensor: [0.5569214847454894, 0.6297279363653551, 0.18683708064722773, 0.29547479423785944], Action prob: [0.5910322  0.40896782], Action: 0, state: 8\n",
      "[0.5910322  0.40896782]\n",
      "Sensor: [0.4543002800275137, 0.34436478313056473, 0.23824020453657022, 0.2585231855158583], Action prob: [0.59217024 0.40782982], Action: 1, state: 8\n",
      "[0.59217024 0.40782982]\n",
      "Sensor: [0.43555080822265546, 0.3804680422116069, 0.2022748953758182, 0.25918232770310984], Action prob: [0.59258986 0.40741023], Action: 0, state: 8\n",
      "[0.59258986 0.40741023]\n",
      "Sensor: [0.626480208824078, 0.6497010168136061, 0.19326130782385617, 0.22100156834141732], Action prob: [0.59103763 0.40896237], Action: 0, state: 8\n",
      "tensor([ 0.8166,  0.5549,  0.3144,  0.0354, -0.1819, -0.6415, -0.5558, -0.7360],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2664 is -522000, loss is 0.049232629812341264\n",
      "[0.59103763 0.40896237]\n",
      "Sensor: [0.5441163254917786, 0.6147481877145498, 0.22088045573342932, 0.23389214188828103], Action prob: [0.6062344 0.3937656], Action: 0, state: 8\n",
      "[0.6062344 0.3937656]\n",
      "Sensor: [0.6009041678553841, 0.6290490465708459, 0.20354212266892424, 0.289818551914218], Action prob: [0.59079665 0.4092033 ], Action: 0, state: 8\n",
      "[0.59079665 0.4092033 ]\n",
      "Sensor: [0.3598734090344355, 0.6600915603916848, 0.48690942895147227, 0.24798949969190412], Action prob: [0.5853183  0.41468164], Action: 0, state: 8\n",
      "[0.5853183  0.41468164]\n",
      "Sensor: [0.36832715008771716, 0.40194292549309796, 0.2170173573585077, 0.2289241986701941], Action prob: [0.58525014 0.41474983], Action: 1, state: 8\n",
      "[0.58525014 0.41474983]\n",
      "Sensor: [0.4084730659164145, 0.4007522193117237, 0.19794587652271448, 0.2742243352013448], Action prob: [0.58512795 0.41487202], Action: 0, state: 8\n",
      "[0.58512795 0.41487202]\n",
      "Sensor: [0.36511913969708154, 0.6289211181428656, 0.20526821129857045, 0.5214956293074382], Action prob: [0.5825148  0.41748527], Action: 0, state: 8\n",
      "[0.5825148  0.41748527]\n",
      "Sensor: [0.5566978722720325, 0.6674484645522187, 0.16532581813325342, 0.27174361440861755], Action prob: [0.5820511  0.41794893], Action: 1, state: 8\n",
      "[0.5820511  0.41794893]\n",
      "Sensor: [0.3905599719569815, 0.3971027956607602, 0.2051066850022515, 0.26146002650016387], Action prob: [0.5841571  0.41584295], Action: 0, state: 8\n",
      "tensor([ 0.8350,  0.5695,  0.3120,  0.0882, -0.1750, -0.3732, -0.9397, -0.7349],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2672 is -546000, loss is 0.052244784518491544\n",
      "[0.5841571  0.41584295]\n",
      "Sensor: [0.5649224398409188, 0.6280027552514601, 0.1785578819170207, 0.28590927475979155], Action prob: [0.59748644 0.40251353], Action: 0, state: 8\n",
      "[0.59748644 0.40251353]\n",
      "Sensor: [0.6174135154796097, 0.6505029893220882, 0.2678427452009927, 0.24989116139906334], Action prob: [0.58165675 0.41834328], Action: 0, state: 8\n",
      "[0.58165675 0.41834328]\n",
      "Sensor: [0.5971204969586811, 0.6415114453828913, 0.21755154464280416, 0.30329397096342847], Action prob: [0.57621205 0.42378795], Action: 0, state: 8\n",
      "[0.57621205 0.42378795]\n",
      "Sensor: [0.37414318080244435, 0.6586533766224949, 0.5360391491885164, 0.2802831189392059], Action prob: [0.5737218  0.42627814], Action: 0, state: 8\n",
      "[0.5737218  0.42627814]\n",
      "Sensor: [0.5563761977308754, 0.599348173908925, 0.23374228084496354, 0.2599976405650959], Action prob: [0.5732839 0.4267161], Action: 0, state: 8\n",
      "[0.5732839 0.4267161]\n",
      "Sensor: [0.349695784069358, 0.6616885147037835, 0.2654268054017012, 0.5554654476614785], Action prob: [0.57214224 0.42785776], Action: 1, state: 8\n",
      "[0.57214224 0.42785776]\n",
      "Sensor: [0.3501840852374169, 0.5818154530518628, 0.23124611077414528, 0.5784571105344892], Action prob: [0.5717749  0.42822513], Action: 0, state: 8\n",
      "[0.5717749  0.42822513]\n",
      "Sensor: [0.33437007146808395, 0.6066367615617323, 0.21627847558702393, 0.5712680875171827], Action prob: [0.5718604 0.4281396], Action: 1, state: 8\n",
      "tensor([ 0.8610,  0.5864,  0.3085,  0.0640, -0.1894, -0.5782, -0.5726, -1.1336],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2680 is -570000, loss is 0.08174706023597633\n",
      "[0.5718604 0.4281396]\n",
      "Sensor: [0.3366672495161097, 0.3839259618505767, 0.2391535735486275, 0.224611803558935], Action prob: [0.59192437 0.40807557], Action: 0, state: 8\n",
      "[0.59192437 0.40807557]\n",
      "Sensor: [0.3589893548163754, 0.6286771506589158, 0.20146695995621772, 0.5411481776169309], Action prob: [0.5705219  0.42947814], Action: 1, state: 8\n",
      "[0.5705219  0.42947814]\n",
      "Sensor: [0.5547167616274054, 0.6271766805643784, 0.18076383387952802, 0.24999119470646092], Action prob: [0.56468874 0.43531132], Action: 0, state: 8\n",
      "[0.56468874 0.43531132]\n",
      "Sensor: [0.3624681156753998, 0.6720276362647757, 0.21582320236763758, 0.5222368709137059], Action prob: [0.56172997 0.43827006], Action: 1, state: 8\n",
      "[0.56172997 0.43827006]\n",
      "Sensor: [0.3732925326680164, 0.30322531961569366, 0.23342374729212734, 0.2695267945478568], Action prob: [0.56390184 0.4360982 ], Action: 0, state: 8\n",
      "[0.56390184 0.4360982 ]\n",
      "Sensor: [0.5352283421629683, 0.6240538836337842, 0.20156452172634037, 0.2119636073931766], Action prob: [0.5628403  0.43715963], Action: 1, state: 8\n",
      "[0.5628403  0.43715963]\n",
      "Sensor: [0.36346521905997464, 0.5987552260960343, 0.20080106522429858, 0.6247844003874506], Action prob: [0.5605047 0.4394953], Action: 1, state: 8\n",
      "[0.5605047 0.4394953]\n",
      "Sensor: [0.20534962323615658, 0.4719091356337916, 0.1849125407998141, 0.8287944119701128], Action prob: [0.5595215  0.44047847], Action: 0, state: 8\n",
      "tensor([ 0.8891,  0.9552,  0.3188,  0.1040, -0.1804, -0.6029, -0.8383, -0.7538],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2688 is -594000, loss is 0.01354890177581558\n",
      "[0.5595215  0.44047847]\n",
      "Sensor: [0.41428267056480883, 0.6042423882847172, 0.5041255099771602, 0.22760727514880047], Action prob: [0.576402   0.42359802], Action: 1, state: 8\n",
      "[0.576402   0.42359802]\n",
      "Sensor: [0.504398530324188, 0.6611117507802863, 0.23205898187029014, 0.5303116440134217], Action prob: [0.55566806 0.44433194], Action: 0, state: 8\n",
      "[0.55566806 0.44433194]\n",
      "Sensor: [0.4173481602763719, 0.4572309125912894, 0.21363882701171097, 0.25541625560780484], Action prob: [0.55341506 0.44658497], Action: 0, state: 8\n",
      "[0.55341506 0.44658497]\n",
      "Sensor: [0.34496883708185877, 0.6618411920133297, 0.2355535108117011, 0.6017198167938873], Action prob: [0.5495441 0.4504559], Action: 0, state: 8\n",
      "[0.5495441 0.4504559]\n",
      "Sensor: [0.5848111755167946, 0.6609051453935433, 0.20833431417026077, 0.29262941727106473], Action prob: [0.54869276 0.45130724], Action: 1, state: 8\n",
      "[0.54869276 0.45130724]\n",
      "Sensor: [0.33575049045780125, 0.3304565801875604, 0.20954379102812642, 0.28067959027071016], Action prob: [0.55194175 0.4480583 ], Action: 0, state: 8\n",
      "[0.55194175 0.4480583 ]\n",
      "Sensor: [0.4414796011507482, 0.6491556446057625, 0.23923104072872758, 0.8345806342182451], Action prob: [0.5471543 0.4528457], Action: 0, state: 8\n",
      "[0.5471543 0.4528457]\n",
      "Sensor: [0.3261953533842834, 0.5956218798555166, 0.5109743731727534, 0.26273832275149817], Action prob: [0.5480105  0.45198944], Action: 0, state: 8\n",
      "tensor([ 1.4560,  0.6569,  0.3406,  0.0824, -0.2726, -0.4142, -0.6049, -0.8110],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2696 is -618000, loss is -0.05414012287901987\n",
      "[0.5480105  0.45198944]\n",
      "Sensor: [0.5761406307158576, 0.5955437697835071, 0.18183592648939462, 0.23488630705435187], Action prob: [0.57053995 0.42946002], Action: 1, state: 8\n",
      "[0.57053995 0.42946002]\n",
      "Sensor: [0.39291215522075273, 0.6485611198095607, 0.19292058219051678, 0.5768175323932364], Action prob: [0.5501978  0.44980222], Action: 0, state: 8\n",
      "[0.5501978  0.44980222]\n",
      "Sensor: [0.34368816215595316, 0.3817853324873532, 0.19274722371901792, 0.1622984950089192], Action prob: [0.54903 0.45097], Action: 0, state: 8\n",
      "[0.54903 0.45097]\n",
      "Sensor: [0.34883950627561, 0.6502540329519105, 0.5321416834478848, 0.20594869482996084], Action prob: [0.5453709 0.4546291], Action: 1, state: 8\n",
      "[0.5453709 0.4546291]\n",
      "Sensor: [0.5680430720975793, 0.6308264209252056, 0.229467759714157, 0.22695763182097645], Action prob: [0.543822 0.456178], Action: 1, state: 8\n",
      "[0.543822 0.456178]\n",
      "Sensor: [0.6185090245707069, 0.6182910922657715, 0.2412128795086785, 0.22010693835190978], Action prob: [0.5433605  0.45663956], Action: 0, state: 8\n",
      "[0.5433605  0.45663956]\n",
      "Sensor: [0.35722207802174505, 0.661841505379828, 0.5232164480882913, 0.29442696883329617], Action prob: [0.54248106 0.45751897], Action: 1, state: 8\n",
      "[0.54248106 0.45751897]\n",
      "Sensor: [0.43038904144862616, 0.6258827949952693, 0.504761057931207, 0.28177420662257147], Action prob: [0.541896   0.45810407], Action: 0, state: 8\n",
      "tensor([ 1.4063,  0.6751,  0.3427,  0.0859, -0.2740, -0.4499, -0.8132, -0.8325],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2704 is -642000, loss is -0.017551915120499487\n",
      "[0.541896   0.45810407]\n",
      "Sensor: [0.3676619769579408, 0.40870790433685766, 0.20206461747210738, 0.3262198741342236], Action prob: [0.56841767 0.43158227], Action: 1, state: 8\n",
      "[0.56841767 0.43158227]\n",
      "Sensor: [0.46789310382988053, 0.309199713981288, 0.46674544485300545, 0.2311016331564536], Action prob: [0.5484032  0.45159683], Action: 1, state: 8\n",
      "[0.5484032  0.45159683]\n",
      "Sensor: [0.38533324680701897, 0.3579084988721153, 0.17470906029919353, 0.2753074133534741], Action prob: [0.54453766 0.45546234], Action: 0, state: 8\n",
      "[0.54453766 0.45546234]\n",
      "Sensor: [0.3614993823430397, 0.393239689395448, 0.18792518634944305, 0.2547186275751834], Action prob: [0.5433771  0.45662284], Action: 1, state: 8\n",
      "[0.5433771  0.45662284]\n",
      "Sensor: [0.3828218478230397, 0.6400750905510997, 0.8394424251981393, 0.13392346549890394], Action prob: [0.53923374 0.4607663 ], Action: 0, state: 8\n",
      "[0.53923374 0.4607663 ]\n",
      "Sensor: [0.5462132283308067, 0.6807780537422685, 0.20825668002752876, 0.5257505656605166], Action prob: [0.5372534 0.4627466], Action: 1, state: 8\n",
      "[0.5372534 0.4627466]\n",
      "Sensor: [0.3332265398516559, 0.6268924802821033, 0.1860871489597741, 0.21596264027924478], Action prob: [0.5396298  0.46037018], Action: 0, state: 0\n",
      "[0.5396298  0.46037018]\n",
      "Sensor: [0.33381511012164744, 0.6642646792812077, 0.2132816862921629, 0.22514224398299879], Action prob: [0.5404096  0.45959032], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([ 1.5657,  0.9113,  0.3040, -0.0616, -0.3637, -0.8189, -0.5775, -0.6287],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2712 is -654500, loss is -0.04132052681664326\n",
      "[0.5404096  0.45959032]\n",
      "Sensor: [0.3252755938441172, 0.6587296616452654, 0.24536643633320238, 0.2500812335276351], Action prob: [0.5643403  0.43565974], Action: 0, state: 0\n",
      "[0.5643403  0.43565974]\n",
      "Sensor: [0.6048633842029655, 0.6826806736306511, 0.22253561806504546, 0.32380386117785953], Action prob: [0.5425903  0.45740965], Action: 1, state: 9\n",
      "[0.5425903  0.45740965]\n",
      "Sensor: [0.32291390992875973, 0.42445177524347255, 0.2006473012796465, 0.46561172130491457], Action prob: [0.5398167 0.4601833], Action: 0, state: 9\n",
      "[0.5398167 0.4601833]\n",
      "Sensor: [0.39732266589647136, 0.27933857076859037, 0.1887723779659431, 0.24231669882659038], Action prob: [0.54044586 0.4595542 ], Action: 1, state: 9\n",
      "[0.54044586 0.4595542 ]\n",
      "Sensor: [0.39020810672266204, 0.6873617568543388, 0.49962928676277224, 0.24113565669064702], Action prob: [0.5376186  0.46238145], Action: 1, state: 9\n",
      "[0.5376186  0.46238145]\n",
      "Sensor: [0.3543542396668724, 0.6582097855855901, 0.541141077632237, 0.26058642475120386], Action prob: [0.5363076  0.46369237], Action: 1, state: 9\n",
      "[0.5363076  0.46369237]\n",
      "Sensor: [0.3323139117792164, 0.3716375244408063, 0.22735916085592686, 0.32543420786848715], Action prob: [0.5381889  0.46181116], Action: 1, state: 9\n",
      "[0.5381889  0.46181116]\n",
      "Sensor: [0.5689257289760424, 0.5824448243954037, 0.18268427933893114, 0.22587110042886077], Action prob: [0.53772295 0.46227705], Action: 1, state: 9\n",
      "tensor([ 0.9644,  0.8445,  0.3721,  0.0784, -0.2494, -0.5370, -0.8047, -1.0772],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2720 is -662500, loss is 0.05113653398377513\n",
      "[0.53772295 0.46227705]\n",
      "Sensor: [0.5862436895815281, 0.6300684962069805, 0.17302126134131884, 0.25892205811585584], Action prob: [0.5558399  0.44416016], Action: 1, state: 9\n",
      "[0.5558399  0.44416016]\n",
      "Sensor: [0.37356951686243733, 0.3963693604496067, 0.22154176317154903, 0.2844246322882178], Action prob: [0.5397093  0.46029064], Action: 0, state: 9\n",
      "[0.5397093  0.46029064]\n",
      "Sensor: [0.5574371121033583, 0.6353223561233096, 0.17528744238362823, 0.20745700012868556], Action prob: [0.53356606 0.466434  ], Action: 1, state: 9\n",
      "[0.53356606 0.466434  ]\n",
      "Sensor: [0.32401798042546, 0.3610843132752544, 0.2287407348519884, 0.2719157641091517], Action prob: [0.5335993 0.4664007], Action: 1, state: 9\n",
      "[0.5335993 0.4664007]\n",
      "Sensor: [0.3939939215585185, 0.6269198340300547, 0.22967068517147454, 0.541180407506044], Action prob: [0.5305346  0.46946532], Action: 0, state: 9\n",
      "[0.5305346  0.46946532]\n",
      "Sensor: [0.37946507939338264, 0.3865494450014128, 0.21214217261322105, 0.21381945634925215], Action prob: [0.5320777 0.4679222], Action: 1, state: 9\n",
      "[0.5320777 0.4679222]\n",
      "Sensor: [0.34277175893553713, 0.6816195577758674, 0.22521601904089766, 0.5134062398812904], Action prob: [0.53037643 0.4696235 ], Action: 1, state: 9\n",
      "[0.53037643 0.4696235 ]\n",
      "Sensor: [0.611292622286311, 0.6824064911509573, 0.23299893920174275, 0.24534348025842215], Action prob: [0.5297806 0.4702194], Action: 1, state: 9\n",
      "tensor([ 1.3444,  0.6817,  0.4123,  0.0831, -0.1912, -0.5438, -0.7800, -1.0574],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2728 is -670500, loss is 0.006362761221769042\n",
      "[0.5297806 0.4702194]\n",
      "Sensor: [0.30523004204670046, 0.6455625208149408, 0.20228557299761551, 0.6032705040185673], Action prob: [0.548903   0.45109698], Action: 0, state: 9\n",
      "[0.548903   0.45109698]\n",
      "Sensor: [0.5862873963481772, 0.6281712192246541, 0.21127093225235655, 0.22972028972373743], Action prob: [0.52960336 0.4703966 ], Action: 1, state: 9\n",
      "[0.52960336 0.4703966 ]\n",
      "Sensor: [0.3060507802324929, 0.6423320072263523, 0.5428225631095943, 0.2885370402863795], Action prob: [0.52541316 0.47458684], Action: 0, state: 9\n",
      "[0.52541316 0.47458684]\n",
      "Sensor: [0.29501100711238937, 0.7054883701729292, 0.5431046045077845, 0.2580209517250501], Action prob: [0.5241754 0.4758246], Action: 0, state: 9\n",
      "[0.5241754 0.4758246]\n",
      "Sensor: [0.3267169011675183, 0.6283997152751379, 0.5123042657889486, 0.2564093047222478], Action prob: [0.5240061  0.47599384], Action: 1, state: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5240061  0.47599384]\n",
      "Sensor: [0.5555346366672802, 0.6199714859114447, 0.22428522006433993, 0.2365507992782806], Action prob: [0.5239915 0.4760084], Action: 1, state: 9\n",
      "[0.5239915 0.4760084]\n",
      "Sensor: [0.5753642984275955, 0.6219510756016213, 0.36407142759327527, 0.2763220813657694], Action prob: [0.52386063 0.47613928], Action: 1, state: 9\n",
      "[0.52386063 0.47613928]\n",
      "Sensor: [0.3943448621007123, 0.37975269284187674, 0.21469769753903986, 0.23914697913664698], Action prob: [0.52463657 0.4753634 ], Action: 0, state: 9\n",
      "tensor([ 1.0360,  0.8054,  0.3826,  0.0746, -0.2331, -0.5490, -0.7977, -0.8850],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2736 is -678500, loss is 0.02076470323552944\n",
      "[0.52463657 0.4753634 ]\n",
      "Sensor: [0.6014709840995974, 0.6110635163035597, 0.18731252669177872, 0.2756422520995506], Action prob: [0.54316306 0.45683697], Action: 1, state: 9\n",
      "[0.54316306 0.45683697]\n",
      "Sensor: [0.4008765592327434, 0.6177112092687281, 0.26690374017064844, 0.5578659130691404], Action prob: [0.52295834 0.4770417 ], Action: 0, state: 9\n",
      "[0.52295834 0.4770417 ]\n",
      "Sensor: [0.35729097842851903, 0.5949247530391231, 0.5550985021155481, 0.23462208761111858], Action prob: [0.52106726 0.47893268], Action: 1, state: 9\n",
      "[0.52106726 0.47893268]\n",
      "Sensor: [0.3500347795808029, 0.6778673241415653, 0.20492312309967253, 0.5062560277739999], Action prob: [0.52066255 0.47933748], Action: 0, state: 9\n",
      "[0.52066255 0.47933748]\n",
      "Sensor: [0.29868181216747924, 0.6390593408567884, 0.2531165138521228, 0.5990407244043094], Action prob: [0.52053416 0.4794658 ], Action: 1, state: 9\n",
      "[0.52053416 0.4794658 ]\n",
      "Sensor: [0.40509754042626434, 0.6523511535991403, 0.5057616527960862, 0.2215531152637888], Action prob: [0.5204176  0.47958237], Action: 0, state: 9\n",
      "[0.5204176  0.47958237]\n",
      "Sensor: [0.33734366782938946, -0.0003994348325455366, 0.2695410890967005, 0.252713063200182], Action prob: [0.52131623 0.4786838 ], Action: 0, state: 9\n",
      "[0.52131623 0.4786838 ]\n",
      "Sensor: [0.6702485519430529, 0.5986087261979577, 0.41682926092477074, 0.18179967656225848], Action prob: [0.5207029 0.4792971], Action: 0, state: 9\n",
      "tensor([ 1.2967,  0.7325,  0.4300,  0.0795, -0.2088, -0.4655, -0.6773, -0.9157],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2744 is -686500, loss is -0.03392027588866342\n",
      "[0.5207029 0.4792971]\n",
      "Sensor: [0.3440650526338776, 0.3621980302364181, 0.21549785979143826, 0.25522297320122556], Action prob: [0.5468987  0.45310134], Action: 1, state: 9\n",
      "[0.5468987  0.45310134]\n",
      "Sensor: [0.5525494778773199, 0.6252098635423335, 0.20800395342522326, 0.238816232228129], Action prob: [0.5222482  0.47775182], Action: 1, state: 9\n",
      "[0.5222482  0.47775182]\n",
      "Sensor: [0.37143278278917263, 0.5461945061183684, 0.498705988563384, 0.6528314225077432], Action prob: [0.52047986 0.4795202 ], Action: 0, state: 9\n",
      "[0.52047986 0.4795202 ]\n",
      "Sensor: [0.2994535375790363, 0.19478814812149403, 0.26692232348014056, 0.21835580208061203], Action prob: [0.5206709  0.47932917], Action: 1, state: 9\n",
      "[0.5206709  0.47932917]\n",
      "Sensor: [0.5765499179372742, 0.6702616099229607, 0.1855885302103873, 0.27443122699768374], Action prob: [0.52017164 0.47982842], Action: 1, state: 9\n",
      "[0.52017164 0.47982842]\n",
      "Sensor: [0.3967031159895114, 0.40000817858874693, 0.21025095441670139, 0.24009458049202737], Action prob: [0.5203917  0.47960833], Action: 1, state: 9\n",
      "[0.5203917  0.47960833]\n",
      "Sensor: [0.4909469567158077, 0.36376438691299373, 0.46611819679334743, 0.22538883554739725], Action prob: [0.52026814 0.4797319 ], Action: 1, state: 9\n",
      "[0.52026814 0.4797319 ]\n",
      "Sensor: [0.6187368544314185, 0.6759288266533845, 0.21475656543558622, 0.18799696335375887], Action prob: [0.5199785  0.48002142], Action: 0, state: 9\n",
      "tensor([ 1.3356,  0.7887,  0.4125,  0.0800, -0.2655, -0.5290, -0.7796, -0.9255],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2752 is -694500, loss is -0.014644689522527635\n",
      "[0.5199785  0.48002142]\n",
      "Sensor: [0.4387644982387159, 0.3443145689168819, 0.1970757970833816, 0.23520340406294674], Action prob: [0.5445202 0.4554798], Action: 1, state: 9\n",
      "[0.5445202 0.4554798]\n",
      "Sensor: [0.362702190461871, 0.4108445161653749, 0.2219779775573043, 0.24966154020207104], Action prob: [0.5222196  0.47778043], Action: 0, state: 9\n",
      "[0.5222196  0.47778043]\n",
      "Sensor: [0.3268153245018027, 0.6061279127101931, 0.5100671039583763, 0.2559475017691374], Action prob: [0.52030563 0.4796944 ], Action: 0, state: 9\n",
      "[0.52030563 0.4796944 ]\n",
      "Sensor: [0.5624457715074587, 0.6327121711588086, 0.21347994927505498, 0.2401794300459605], Action prob: [0.5196439 0.4803561], Action: 1, state: 9\n",
      "[0.5196439 0.4803561]\n",
      "Sensor: [0.38578478741551314, 0.6128386990511356, 0.17751346716154076, 0.570338643823321], Action prob: [0.51948786 0.48051217], Action: 1, state: 9\n",
      "[0.51948786 0.48051217]\n",
      "Sensor: [0.37941187870305004, 0.6421080469511187, 0.21963630021106317, 0.20817459975000385], Action prob: [0.51948667 0.48051333], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.51948667 0.48051333]\n",
      "Sensor: [0.33471222834678505, 0.6511246572559968, 0.24012318853576078, 0.25142514507025615], Action prob: [0.51950186 0.4804981 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.51950186 0.4804981 ]\n",
      "Sensor: [0.3503633825645722, 0.623439360003385, 0.2508816560562843, 0.23176950864397625], Action prob: [0.51951635 0.48048356], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([ 1.5711,  0.6715,  0.1125, -0.4844, -0.9617, -0.5254, -0.3068, -0.1191],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2760 is -696000, loss is 0.00528052713743276\n",
      "[0.51951635 0.48048356]\n",
      "Sensor: [0.35986902336350424, 0.5642728045463946, 0.18400180576078803, 0.23448081179087518], Action prob: [0.54193264 0.45806736], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.54193264 0.45806736]\n",
      "Sensor: [0.3489916860675127, 0.5883194637789175, 0.2186413596756228, 0.24376693438310718], Action prob: [0.52015257 0.4798474 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.52015257 0.4798474 ]\n",
      "Sensor: [0.3668645235681214, 0.6196937802264392, 0.23372755729989173, 0.23120462799630648], Action prob: [0.51852685 0.4814732 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.51852685 0.4814732 ]\n",
      "Sensor: [0.35162812668001214, 0.6378882192489853, 0.22426548431751545, 0.26867641265299913], Action prob: [0.51788205 0.48211795], Action: 0, state: 0\n",
      "[0.51788205 0.48211795]\n",
      "Sensor: [0.3701128951965178, 0.6275736433133641, 0.18299597960407984, 0.20160396866376565], Action prob: [0.5178275  0.48217246], Action: 0, state: 0\n",
      "[0.5178275  0.48217246]\n",
      "Sensor: [0.3340143103825272, 0.6425822311654358, 0.15667671794845872, 0.2779333401686516], Action prob: [0.51780367 0.48219633], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.51780367 0.48219633]\n",
      "Sensor: [0.3728488759412617, 0.527570811154705, 0.20083335559406604, 0.19512573827919918], Action prob: [0.517867   0.48213294], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.517867   0.48213294]\n",
      "Sensor: [0.3214539225888317, 0.5727838247542959, 0.21073916133744558, 0.2809665172501204], Action prob: [0.5178485 0.4821515], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "tensor([-1.0282, -0.9645, -0.5937, -0.2322,  0.2980,  0.8754,  0.6283,  0.8567],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2768 is -694000, loss is 0.020010714378476957\n",
      "[0.5178485 0.4821515]\n",
      "Sensor: [0.33330566198313943, 0.600681748386283, 0.17754710766069776, 0.23383392745274478], Action prob: [0.5400088  0.45999122], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5400088  0.45999122]\n",
      "Sensor: [0.3804909098167371, 0.6508019087726136, 0.21516908015091143, 0.21136019570022568], Action prob: [0.5188026  0.48119748], Action: 0, state: 0\n",
      "[0.5188026  0.48119748]\n",
      "Sensor: [0.3864705947941938, 0.6372972840391601, 0.1874676912387884, 0.26661274719717887], Action prob: [0.51704866 0.48295128], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "[0.51704866 0.48295128]\n",
      "Sensor: [0.3506325665594783, 0.6358727389773882, 0.20928296092009108, 0.30566398112271076], Action prob: [0.5167293  0.48327076], Action: 0, state: 0\n",
      "[0.5167293  0.48327076]\n",
      "Sensor: [0.3760759018298239, 0.6548836981489333, 0.624290929404874, 0.5971600767009277], Action prob: [0.5163585 0.4836415], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5163585 0.4836415]\n",
      "Sensor: [0.33955604019918234, 0.6235490304193803, 0.2201649351615065, 0.24504406411734225], Action prob: [0.516409   0.48359105], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.516409   0.48359105]\n",
      "Sensor: [0.3890000915220372, 0.6703008639195259, 0.2382164496462016, 0.22818189984012857], Action prob: [0.5164616  0.48353833], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5164616  0.48353833]\n",
      "Sensor: [0.31256841589353307, 0.6184380326606713, 0.25128691477812404, 0.31775346964769347], Action prob: [0.51651233 0.4834876 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.1573, -0.7265,  0.3737, -1.0948, -0.2109,  0.1704,  0.5004,  1.2593],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2776 is -691500, loss is -0.014288876974728748\n",
      "[0.51651233 0.4834876 ]\n",
      "Sensor: [0.36211698575807955, 0.5979463785380815, 0.2069329405051589, 0.2918987943565457], Action prob: [0.5374382  0.46256176], Action: 0, state: 0\n",
      "[0.5374382  0.46256176]\n",
      "Sensor: [0.3740586755491547, 0.631083663034344, 0.24033395947610403, 0.24870436736434676], Action prob: [0.51895845 0.48104164], Action: 0, state: 0\n",
      "[0.51895845 0.48104164]\n",
      "Sensor: [0.3620585327818591, 0.6559283682313412, 0.2104667384841963, 0.23567192778576604], Action prob: [0.5177148  0.48228526], Action: 0, state: 0\n",
      "[0.5177148  0.48228526]\n",
      "Sensor: [0.3446459593547358, 0.6328189344387757, 0.22400159526620844, 0.26589936176424184], Action prob: [0.5174774  0.48252264], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5174774  0.48252264]\n",
      "Sensor: [0.3577673971153079, 0.6583040439986586, 0.252713924678745, 0.32618408067874755], Action prob: [0.51734155 0.48265854], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.51734155 0.48265854]\n",
      "Sensor: [0.33570990085068897, 0.6794542290777418, 0.21721822877379207, 0.3031567696208182], Action prob: [0.51729465 0.48270535], Action: 0, state: 0\n",
      "[0.51729465 0.48270535]\n",
      "Sensor: [0.3751541334880386, 0.6525251011645424, 0.2282819374747277, 0.2487282352349365], Action prob: [0.51730555 0.4826945 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.51730555 0.4826945 ]\n",
      "Sensor: [0.33968841430267005, 0.6406721492109828, 0.24000958445601267, 0.301984913734141], Action prob: [0.5173177  0.48268226], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "tensor([-1.2316, -0.7258, -0.2079,  0.2434,  0.2484,  0.4132,  0.8296,  0.6668],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2784 is -688100, loss is -0.029509072162907657\n",
      "[0.5173177  0.48268226]\n",
      "Sensor: [0.37542570719741014, 0.6764809680032242, 0.20519203158722735, 0.29065421777437317], Action prob: [0.5379038  0.46209624], Action: 0, state: 0\n",
      "[0.5379038  0.46209624]\n",
      "Sensor: [0.32123417319362957, 0.6934820213266686, 0.2209606670321445, 0.20877006528827635], Action prob: [0.5207891  0.47921088], Action: 0, state: 1\n",
      "[0.5207891  0.47921088]\n",
      "Sensor: [0.33058737526048965, 0.591120584116102, 0.22160928760313134, 0.42054886257602875], Action prob: [0.51996094 0.480039  ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.51996094 0.480039  ]\n",
      "Sensor: [0.30286698084130026, 0.6961853808279344, 0.2514792731365851, 0.24104991104009846], Action prob: [0.5198671  0.48013294], Action: 0, state: 0\n",
      "[0.5198671  0.48013294]\n",
      "Sensor: [0.33413151415941106, 0.6514824852086335, 0.17531070843659285, 0.24144596341864238], Action prob: [0.5199017  0.48009828], Action: 0, state: 0\n",
      "[0.5199017  0.48009828]\n",
      "Sensor: [0.39467346620592136, 0.6804450709001312, 0.21859302064469668, 0.28286590461659444], Action prob: [0.51989096 0.48010904], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.51989096 0.48010904]\n",
      "Sensor: [0.389640259400136, 0.6928285914571457, 0.20738484042605324, 0.21943858574597633], Action prob: [0.51989686 0.4801031 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.51989686 0.4801031 ]\n",
      "Sensor: [0.33991577174672605, 0.6499756985943919, 0.2475528746290149, 0.3114869363507592], Action prob: [0.5199167  0.48008332], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.1512, -0.7239, -0.2982, -0.0582,  0.3351,  0.7779,  0.5916,  0.7682],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2792 is -683300, loss is -0.03017835785119166\n",
      "[0.5199167  0.48008332]\n",
      "Sensor: [0.3346502108534542, 0.6507828529244819, 0.20058831400820276, 0.27480252228362817], Action prob: [0.5426536  0.45734632], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5426536  0.45734632]\n",
      "Sensor: [0.43350196506891214, 0.6250254112859528, 0.19891236968492665, 0.25135604972551007], Action prob: [0.52395165 0.47604835], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.52395165 0.47604835]\n",
      "Sensor: [0.3875962593874494, 0.5924651458342796, 0.26827224016120654, 0.2327541467832335], Action prob: [0.5234337  0.47656637], Action: 0, state: 0\n",
      "[0.5234337  0.47656637]\n",
      "Sensor: [0.41965342523676175, 0.6618537481112977, 0.24350417277650682, 0.29776699042619087], Action prob: [0.5235435  0.47645658], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5235435  0.47645658]\n",
      "Sensor: [0.358497754790651, 0.6668379157127949, 0.2152413401210971, 0.2458545367062749], Action prob: [0.52364314 0.47635686], Action: 0, state: 0\n",
      "[0.52364314 0.47635686]\n",
      "Sensor: [0.33809601285811636, 0.7095606012497072, 0.25010005156211057, 0.27550771410681163], Action prob: [0.52370054 0.47629946], Action: 0, state: 0\n",
      "[0.52370054 0.47629946]\n",
      "Sensor: [0.3850047210568783, 0.6475646596596873, 0.22704893106717616, 0.25975956249444265], Action prob: [0.5237412 0.4762588], Action: 0, state: 0\n",
      "[0.5237412 0.4762588]\n",
      "Sensor: [0.3565957904890814, 0.6344538253694336, 0.2586710649893303, 0.2633717307502331], Action prob: [0.52377015 0.47622985], Action: 0, state: 0\n",
      "tensor([-0.3794, -0.3684, -0.9818, -0.5066, -0.1740,  0.3150,  0.7475,  1.1438],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2800 is -679000, loss is 0.025491604924423955\n",
      "[0.52377015 0.47622985]\n",
      "Sensor: [0.32998977773753, 0.6412987225457812, 0.21168316535138648, 0.30053483187768204], Action prob: [0.5437085 0.4562915], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5437085 0.4562915]\n",
      "Sensor: [0.37223391616524265, 0.646563603303759, 0.21142740701385918, 0.22437396079178817], Action prob: [0.52516025 0.47483975], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -2000\n",
      "[0.52516025 0.47483975]\n",
      "Sensor: [0.3816219074200628, 0.6102386878224758, 0.2229053330991773, 0.24462577744247754], Action prob: [0.5247146 0.4752854], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5247146 0.4752854]\n",
      "Sensor: [0.3477163464688206, 0.6543799999535246, 0.2313633253180143, 0.28144831380860075], Action prob: [0.52488256 0.47511742], Action: 0, state: 0\n",
      "[0.52488256 0.47511742]\n",
      "Sensor: [0.3611726647064484, 0.6068727929293439, 0.22646913718924877, 0.29416163010463137], Action prob: [0.52501154 0.47498843], Action: 0, state: 0\n",
      "[0.52501154 0.47498843]\n",
      "Sensor: [0.3339609403953834, 0.6532338271700184, 0.2569744380012616, 0.23480756106222594], Action prob: [0.5250754  0.47492465], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5250754  0.47492465]\n",
      "Sensor: [0.3447853651956655, 0.6687574527915181, 0.2398274586304196, 0.3207390629112855], Action prob: [0.5251304  0.47486967], Action: 0, state: 0\n",
      "[0.5251304  0.47486967]\n",
      "Sensor: [0.36701030028503906, 0.6681478478736617, 0.23033014010411065, 0.21094048225291706], Action prob: [0.5251369  0.47486305], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-0.0840,  0.3687, -1.2755, -0.7801, -0.2015,  0.3653,  0.5543,  1.1163],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2808 is -676500, loss is -0.007935488660408607\n",
      "[0.5251369  0.47486305]\n",
      "Sensor: [0.35434711309113226, 0.6865737331110738, 0.20868465951458462, 0.27271488877935446], Action prob: [0.54478526 0.45521474], Action: 0, state: 0\n",
      "[0.54478526 0.45521474]\n",
      "Sensor: [0.36662853543872065, 0.6732147308321254, 0.21696559405397833, 0.23668970798614047], Action prob: [0.52657765 0.4734224 ], Action: 0, state: 0\n",
      "[0.52657765 0.4734224 ]\n",
      "Sensor: [0.3202081008876794, 0.6559567360454429, 0.21853588130868126, 0.228487826054578], Action prob: [0.52630293 0.473697  ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.52630293 0.473697  ]\n",
      "Sensor: [0.3094854686856864, 0.7034360539521278, 0.18248338163259278, 0.5807605652548252], Action prob: [0.5266279  0.47337207], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5266279  0.47337207]\n",
      "Sensor: [0.3561557904470839, 0.6100844898848533, 0.22187819288140034, 0.25331593162859184], Action prob: [0.5267336 0.4732664], Action: 0, state: 0\n",
      "[0.5267336 0.4732664]\n",
      "Sensor: [0.3401361663379816, 0.679595852554224, 0.20793015275374682, 0.28263863426349567], Action prob: [0.52683246 0.4731676 ], Action: 0, state: 0\n",
      "[0.52683246 0.4731676 ]\n",
      "Sensor: [0.3628564832965415, 0.6414992534690115, 0.17497238015856403, 0.2658758337843062], Action prob: [0.52688324 0.47311676], Action: 0, state: 0\n",
      "[0.52688324 0.47311676]\n",
      "Sensor: [0.36777259318683775, 0.6450845702132947, 0.22659213943227352, 0.25318006051290504], Action prob: [0.5269071 0.4730929], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.0823, -0.6241, -0.1771, -0.1477,  0.0387,  0.3818,  0.6861,  1.1260],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2816 is -670500, loss is -0.025184381091290536\n",
      "[0.5269071 0.4730929]\n",
      "Sensor: [0.3768415759748248, 0.663979353731712, 0.20469254784642582, 0.2767354727582399], Action prob: [0.54737985 0.4526202 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.54737985 0.4526202 ]\n",
      "Sensor: [0.37588982025379897, 0.6394199823293216, 0.19871416518283827, 0.23769512238505028], Action prob: [0.5281676  0.47183236], Action: 0, state: 0\n",
      "[0.5281676  0.47183236]\n",
      "Sensor: [0.36540258670960785, 0.5677006914053143, 0.19496393338644485, 0.27518429835620645], Action prob: [0.5279873  0.47201267], Action: 0, state: 0\n",
      "[0.5279873  0.47201267]\n",
      "Sensor: [0.39835434843872686, 0.7076860590603515, 0.22927766510921777, 0.26157182235472054], Action prob: [0.5283516  0.47164837], Action: 0, state: 0\n",
      "[0.5283516  0.47164837]\n",
      "Sensor: [0.3621324024559198, 0.6401345559024683, 0.20149052498245493, 0.2114118464775468], Action prob: [0.5285189  0.47148106], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5285189  0.47148106]\n",
      "Sensor: [0.33415153453337904, 0.6717661262800937, 0.17279838289994212, 0.2156292145110245], Action prob: [0.52860874 0.47139126], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.52860874 0.47139126]\n",
      "Sensor: [0.41377344388592474, 0.6339587318085197, 0.20064054731167602, 0.283456461028177], Action prob: [0.5286704 0.4713297], Action: 0, state: 0\n",
      "[0.5286704 0.4713297]\n",
      "Sensor: [0.38470663928770343, 0.6509495655820576, 0.2200639163290013, 0.23667244380560667], Action prob: [0.52869946 0.47130048], Action: 0, state: 0\n",
      "tensor([-0.8801, -0.9526, -0.5139, -0.1267,  0.2236,  0.5997,  0.6525,  0.9075],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2824 is -664600, loss is 0.011251419709907534\n",
      "[0.52869946 0.47130048]\n",
      "Sensor: [0.3452605249892495, 0.6145424446995567, 0.1933968528254988, 0.22433241409995605], Action prob: [0.55098    0.44902006], Action: 0, state: 0\n",
      "[0.55098    0.44902006]\n",
      "Sensor: [0.35726410979398887, 0.6308647998161294, 0.20295159970743903, 0.23470438109710057], Action prob: [0.5297329  0.47026712], Action: 0, state: 1\n",
      "[0.5297329  0.47026712]\n",
      "Sensor: [0.32411741388925386, 0.6141587810999931, 0.2216190746186217, 0.19403596163184605], Action prob: [0.5289846 0.4710154], Action: 0, state: 1\n",
      "[0.5289846 0.4710154]\n",
      "Sensor: [0.3664139615641951, 0.5692609989609732, 0.20896192796704993, 0.30258129178428517], Action prob: [0.529351   0.47064906], Action: 0, state: 2\n",
      "[0.529351   0.47064906]\n",
      "Sensor: [0.3199328727199979, 0.6461194549632238, 0.18484114776954313, 0.24885780744224767], Action prob: [0.5295677  0.47043225], Action: 0, state: 3\n",
      "[0.5295677  0.47043225]\n",
      "Sensor: [0.38484171813866025, 0.5632976535486431, 0.21778344646601433, 0.21901514183818882], Action prob: [0.5296477  0.47035226], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1200\n",
      "[0.5296477  0.47035226]\n",
      "Sensor: [0.39796977604365164, 0.6434031064319081, 0.1749578205875301, 0.30286388046109936], Action prob: [0.52975404 0.47024593], Action: 0, state: 2\n",
      "[0.52975404 0.47024593]\n",
      "Sensor: [0.345572396872903, 0.6016272933337109, 0.19048894010331488, 0.2435582497619784], Action prob: [0.5297695  0.47023055], Action: 0, state: 2\n",
      "tensor([-1.1993, -0.6973, -0.1746,  0.2499,  0.4815,  0.8192,  0.2344,  0.5092],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2832 is -660600, loss is -0.02787741426019203\n",
      "[0.5297695  0.47023055]\n",
      "Sensor: [0.37365038591186495, 0.6050404431478988, 0.24446190379242527, 0.2727611829965951], Action prob: [0.5524947  0.44750527], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.5524947  0.44750527]\n",
      "Sensor: [0.30043727298228, 0.6086969480298114, 0.2549857615153035, 0.2485438090773035], Action prob: [0.53178084 0.46821916], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.53178084 0.46821916]\n",
      "Sensor: [0.33385066705924726, 0.6828962627896602, 0.19759767648328547, 0.28636160529976534], Action prob: [0.53058815 0.46941185], Action: 0, state: 0\n",
      "[0.53058815 0.46941185]\n",
      "Sensor: [0.3029351665920697, 0.6329304606497912, 0.24015311316058854, 0.2532003268777421], Action prob: [0.5309524  0.46904764], Action: 0, state: 0\n",
      "[0.5309524  0.46904764]\n",
      "Sensor: [0.34066664251234197, 0.6648410473669703, 0.2046286699736366, 0.1908807547686922], Action prob: [0.53114265 0.4688574 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.53114265 0.4688574 ]\n",
      "Sensor: [0.3368378898453381, 0.5296048592864497, 0.2478305471847685, 0.27787624611866374], Action prob: [0.5312424  0.46875757], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5312424  0.46875757]\n",
      "Sensor: [0.3628985400800573, 0.621212623230977, 0.2230351700483746, 0.37318199175410055], Action prob: [0.53137237 0.4686276 ], Action: 0, state: 0\n",
      "[0.53137237 0.4686276 ]\n",
      "Sensor: [0.35860686341576586, 0.614676563378219, 0.2296789586995528, 0.26766467479264394], Action prob: [0.53139293 0.4686071 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.1806, -0.7750, -0.6505, -0.0808,  0.5029,  0.7908,  0.4561,  0.9837],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2840 is -656700, loss is -0.005811633170934791\n",
      "[0.53139293 0.4686071 ]\n",
      "Sensor: [0.3562818739545089, 0.6176121222210177, 0.23922069850957406, 0.2843578745426004], Action prob: [0.5547723  0.44522768], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5547723  0.44522768]\n",
      "Sensor: [0.35082204250826016, 0.6830800902489915, 0.17163143221235555, 0.20610984041293728], Action prob: [0.53416485 0.46583512], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.53416485 0.46583512]\n",
      "Sensor: [0.3533482047837821, 0.6459233365084639, 0.20392895177966872, 0.2518410963479378], Action prob: [0.5329568  0.46704322], Action: 0, state: 0\n",
      "[0.5329568  0.46704322]\n",
      "Sensor: [0.3039588968718707, 0.6017786571077762, 0.22574454530248936, 0.2584078784155707], Action prob: [0.533444   0.46655604], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.533444   0.46655604]\n",
      "Sensor: [0.3767603291545773, 0.5847774327193772, 0.2359229011876567, 0.24471327133764276], Action prob: [0.53372055 0.46627936], Action: 0, state: 0\n",
      "[0.53372055 0.46627936]\n",
      "Sensor: [0.3532549337718442, 0.6433335112008722, 0.2259274553037617, 0.20854481878847642], Action prob: [0.53388816 0.4661118 ], Action: 0, state: 1\n",
      "[0.53388816 0.4661118 ]\n",
      "Sensor: [0.3149385863157115, 0.6794524832142451, 0.20988052423714124, 0.2371439492849262], Action prob: [0.53399915 0.46600085], Action: 0, state: 2\n",
      "[0.53399915 0.46600085]\n",
      "Sensor: [0.3381174156805061, 0.6052369317906213, 0.16765044657138117, 0.2040929900446307], Action prob: [0.5339846  0.46601543], Action: 0, state: 3\n",
      "tensor([-0.7481, -1.0894, -0.6167, -0.1398,  0.1031,  0.4610,  0.7522,  0.9103],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2848 is -652500, loss is 0.0459194583549791\n",
      "[0.5339846  0.46601543]\n",
      "Sensor: [0.544053025161368, 0.5818879020628999, 0.20668056554338338, 0.2863158321288176], Action prob: [0.55278575 0.44721425], Action: 0, state: 3\n",
      "[0.55278575 0.44721425]\n",
      "Sensor: [0.4230190845888655, 0.6097209245968763, 0.5409128876921225, 0.25883726172950755], Action prob: [0.5333377 0.4666622], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.5333377 0.4666622]\n",
      "Sensor: [0.42223752618981936, 0.6669406292807475, 0.20844676207243026, 0.21841061145554141], Action prob: [0.5325549  0.46744505], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -3100\n",
      "[0.5325549  0.46744505]\n",
      "Sensor: [0.3571214145557065, 0.5826708464587184, 0.22436901664851913, 0.21890290778591148], Action prob: [0.5329482  0.46705174], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5329482  0.46705174]\n",
      "Sensor: [0.35946364018268906, 0.6138714603818997, 0.2147575667638179, 0.25161660520736495], Action prob: [0.5331888  0.46681118], Action: 0, state: 0\n",
      "[0.5331888  0.46681118]\n",
      "Sensor: [0.28454054797970607, 0.5199389270852071, 0.2167918851492088, 0.32703092039471243], Action prob: [0.5333069 0.4666931], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5333069 0.4666931]\n",
      "Sensor: [0.29880877629363656, 0.6209083246744933, 0.23476186455159587, 0.260792129165255], Action prob: [0.5333644  0.46663558], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5333644  0.46663558]\n",
      "Sensor: [0.34197476827305967, 0.6219490567070637, 0.2433871357846115, 0.24498698796868582], Action prob: [0.53338945 0.4666106 ], Action: 0, state: 0\n",
      "tensor([ 0.4114,  0.9928,  1.2049, -0.9932, -0.5546, -0.0808, -0.3486, -0.4836],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2856 is -653300, loss is -0.018526624139045454\n",
      "[0.53338945 0.4666106 ]\n",
      "Sensor: [0.4425400199878447, 0.6656358700555336, 0.18950280047483198, 0.6293775728589697], Action prob: [0.5489589 0.4510411], Action: 0, state: 0\n",
      "[0.5489589 0.4510411]\n",
      "Sensor: [0.37220323931174837, 0.6299451130637469, 0.20130755802985156, 0.29807337008828966], Action prob: [0.5337365 0.4662634], Action: 0, state: 0\n",
      "[0.5337365 0.4662634]\n",
      "Sensor: [0.35776042379804407, 0.6397908750279487, 0.24597048745281913, 0.25343749870543014], Action prob: [0.53293264 0.46706736], Action: 0, state: 1\n",
      "[0.53293264 0.46706736]\n",
      "Sensor: [0.3648458478050298, 0.6404316617849835, 0.17315187175123653, 0.2522522359279161], Action prob: [0.5333401  0.46665993], Action: 0, state: 2\n",
      "[0.5333401  0.46665993]\n",
      "Sensor: [0.39569576383668187, 0.6210497759613374, 0.22386267273651317, 0.24704916354928003], Action prob: [0.5335645 0.4664355], Action: 0, state: 3\n",
      "[0.5335645 0.4664355]\n",
      "Sensor: [0.39852283215758333, 0.7074214374032213, 0.22115057679616695, 0.2674522684641583], Action prob: [0.5337399  0.46626014], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "[0.5337399  0.46626014]\n",
      "Sensor: [0.31616972843677243, 0.6443945958083785, 0.2121651945033454, 0.25926475842951624], Action prob: [0.5337925  0.46620744], Action: 0, state: 2\n",
      "[0.5337925  0.46620744]\n",
      "Sensor: [0.35767422676128025, 0.6204743055229082, 0.2378564332497063, 0.27232233752036256], Action prob: [0.53380793 0.4661921 ], Action: 0, state: 2\n",
      "tensor([-1.1283, -0.6743, -0.2496,  0.0881,  0.2802,  0.5494,  0.5502,  0.7737],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2864 is -647700, loss is -0.023682795650071697\n",
      "[0.53380793 0.4661921 ]\n",
      "Sensor: [0.40152367618349194, 0.5894033408477379, 0.19774555643536826, 0.21276471660658158], Action prob: [0.5569316 0.4430683], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.5569316 0.4430683]\n",
      "Sensor: [0.3599214453326292, 0.5805352195250326, 0.21822721455717553, 0.252698474922463], Action prob: [0.53530616 0.4646938 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.53530616 0.4646938 ]\n",
      "Sensor: [0.35262196355526343, 0.6607683741717417, 0.206752747020332, 0.280137171813496], Action prob: [0.53383243 0.46616754], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.53383243 0.46616754]\n",
      "Sensor: [0.31136111758998314, 0.6980195935378781, 0.21342379048809165, 0.29858876157879194], Action prob: [0.5338458 0.4661542], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5338458 0.4661542]\n",
      "Sensor: [0.34263396170190524, 0.6373201360986936, 0.15331308484475664, 0.2015442120671567], Action prob: [0.5340252 0.4659748], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.5340252 0.4659748]\n",
      "Sensor: [0.4063348051744082, 0.6059202384694365, 0.19158980890303154, 0.23931709376788668], Action prob: [0.5341358  0.46586415], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.5341358  0.46586415]\n",
      "Sensor: [0.3539760928164508, 0.6806672990383255, 0.1801396765998603, 0.26229682074260713], Action prob: [0.53424597 0.465754  ], Action: 0, state: 0\n",
      "[0.53424597 0.465754  ]\n",
      "Sensor: [0.3306472207835032, 0.6389439010215802, 0.399016495709404, 0.27934234192889523], Action prob: [0.5343182 0.4656818], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "tensor([ 0.2180,  0.9517,  0.9483,  0.2077,  0.1952, -0.4071, -1.2230, -0.5943],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2872 is -649400, loss is -0.03706460008904251\n",
      "[0.5343182 0.4656818]\n",
      "Sensor: [0.3473793294447257, 0.6628116038255322, 0.23639528099151405, 0.2643199582137699], Action prob: [0.558339   0.44166103], Action: 0, state: 0\n",
      "[0.558339   0.44166103]\n",
      "Sensor: [0.2861674611038406, 0.629036098520172, 0.17632170660163263, 0.2435230891577965], Action prob: [0.5378     0.46219993], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5378     0.46219993]\n",
      "Sensor: [0.33542280286548853, 0.6861120184039812, 0.18199906484142972, 0.2338261228178548], Action prob: [0.5363109  0.46368915], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5363109  0.46368915]\n",
      "Sensor: [0.3127152030454247, 0.690635900782807, 0.21503668404722628, 0.23702157037944402], Action prob: [0.5359802  0.46401975], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5359802  0.46401975]\n",
      "Sensor: [0.2961873258231985, 0.6437938004248515, 0.223378843723313, 0.20614815592757127], Action prob: [0.5360053  0.46399468], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5360053  0.46399468]\n",
      "Sensor: [0.39531074851626635, 0.7081274605961012, 0.20201368713436332, 0.2848846287453146], Action prob: [0.53614354 0.46385643], Action: 0, state: 0\n",
      "[0.53614354 0.46385643]\n",
      "Sensor: [0.34866089694622787, 0.6994009386651759, 0.20823684659919864, 0.2591893505792356], Action prob: [0.5362464  0.46375358], Action: 0, state: 1\n",
      "[0.5362464  0.46375358]\n",
      "Sensor: [0.40410770473753865, 0.6300494996029049, 0.21012719410541222, 0.25597408001933164], Action prob: [0.536256   0.46374398], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1600\n",
      "tensor([-1.0427, -0.7146, -0.3855, -0.0833,  0.1850,  0.3439,  0.6627,  1.1278],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2880 is -646400, loss is -0.011651297345037837\n",
      "[0.536256   0.46374398]\n",
      "Sensor: [0.3302180974936591, 0.6938130028225943, 0.2158896740598869, 0.24011311323659423], Action prob: [0.56165314 0.43834686], Action: 0, state: 1\n",
      "[0.56165314 0.43834686]\n",
      "Sensor: [0.3537256017927087, 0.6064310308594103, 0.23303174032192958, 0.19738949669034178], Action prob: [0.540153   0.45984694], Action: 0, state: 1\n",
      "[0.540153   0.45984694]\n",
      "Sensor: [0.3718304217788166, 0.6587739032470545, 0.2215470352471859, 0.24439966690501042], Action prob: [0.53862745 0.46137255], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.53862745 0.46137255]\n",
      "Sensor: [0.3330760807299178, 0.6317964318912876, 0.21743744182552394, 0.26504723311627604], Action prob: [0.5382792  0.46172088], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5382792  0.46172088]\n",
      "Sensor: [0.3078583003721767, 0.6644459754624803, 0.2417033307955235, 0.25937561814721277], Action prob: [0.53817695 0.4618231 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.53817695 0.4618231 ]\n",
      "Sensor: [0.40022352220176216, 0.6546909062921906, 0.23723810239769427, 0.22496899492463776], Action prob: [0.5381635  0.46183652], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.5381635  0.46183652]\n",
      "Sensor: [0.3693540973665426, 0.6324706263600116, 0.26787403856518754, 0.30427647366838617], Action prob: [0.5382631 0.461737 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5382631 0.461737 ]\n",
      "Sensor: [0.40754518109003274, 0.6496413294849572, 0.2611924036121562, 0.22496226453881865], Action prob: [0.5382748  0.46172518], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.3220, -0.5092,  0.3837,  0.3885,  0.3904,  0.7937,  0.0613,  0.3854],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2888 is -644600, loss is -0.07147920361848101\n",
      "[0.5382748  0.46172518]\n",
      "Sensor: [0.2762185018550224, 0.6532045751128287, 0.42625593052375976, 0.2514452064247124], Action prob: [0.56610376 0.4338963 ], Action: 0, state: 0\n",
      "[0.56610376 0.4338963 ]\n",
      "Sensor: [0.3115826791257878, 0.6508758260296256, 0.2138398124588232, 0.27265286802648897], Action prob: [0.544603 0.455397], Action: 0, state: 0\n",
      "[0.544603 0.455397]\n",
      "Sensor: [0.34053837370199846, 0.5849796505982398, 0.23048181138930932, 0.28449865106916244], Action prob: [0.5433388 0.4566613], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.5433388 0.4566613]\n",
      "Sensor: [0.30428651604027257, 0.59068511301628, 0.2115523426539529, 0.2140860543981293], Action prob: [0.5431749 0.4568251], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5431749 0.4568251]\n",
      "Sensor: [0.33877029021933386, 0.6655902898897856, 0.28214434300572944, 0.24091330631481772], Action prob: [0.5430781  0.45692194], Action: 0, state: 0\n",
      "[0.5430781  0.45692194]\n",
      "Sensor: [0.33484405903827624, 0.6481073044559972, 0.22922237368006063, 0.21164332095060814], Action prob: [0.5430595  0.45694044], Action: 0, state: 0\n",
      "[0.5430595  0.45694044]\n",
      "Sensor: [0.2679973699852064, 0.6243921511196837, 0.17193303593331427, 0.2780646899263473], Action prob: [0.54313725 0.45686275], Action: 0, state: 1\n",
      "[0.54313725 0.45686275]\n",
      "Sensor: [0.35666706092501194, 0.6213913278433162, 0.2013410319384159, 0.28514197993264645], Action prob: [0.54308724 0.45691282], Action: 0, state: 1\n",
      "tensor([-1.0073, -0.4321,  0.2027, -0.4848, -0.1369,  0.2901,  0.6457,  0.9563],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2896 is -639400, loss is -0.004206885960140586\n",
      "[0.54308724 0.45691282]\n",
      "Sensor: [0.33908170361863693, 0.6707535958226838, 0.2530382352678765, 0.22019612171115158], Action prob: [0.571749  0.4282511], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "[0.571749  0.4282511]\n",
      "Sensor: [0.34820660730596437, 0.6672238739723392, 0.2171151969242565, 0.23972980851161196], Action prob: [0.5490797  0.45092034], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5490797  0.45092034]\n",
      "Sensor: [0.3187352257924947, 0.5156804805603907, 0.2453996978713662, 0.4757644333326997], Action prob: [0.54681087 0.4531891 ], Action: 0, state: 0\n",
      "[0.54681087 0.4531891 ]\n",
      "Sensor: [0.4090281410089694, 0.6212510915316887, 0.22309329725762267, 0.2543829654946715], Action prob: [0.5464974 0.4535026], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5464974 0.4535026]\n",
      "Sensor: [0.3046129731246147, 0.626021584608676, 0.21834513843363232, 0.21237685675781995], Action prob: [0.5466129  0.45338714], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "[0.5466129  0.45338714]\n",
      "Sensor: [0.3514116069383434, 0.6644173734698192, 0.20825453874441616, 0.20135707547580858], Action prob: [0.54660946 0.4533905 ], Action: 0, state: 0\n",
      "[0.54660946 0.4533905 ]\n",
      "Sensor: [0.4281018049572756, 0.603176108455446, 0.18411963345105678, 0.28931822242740135], Action prob: [0.546584 0.453416], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.546584 0.453416]\n",
      "Sensor: [0.3564654152187251, 0.6382610628260993, 0.21102167733776322, 0.2848365885996186], Action prob: [0.54661745 0.45338252], Action: 0, state: 0\n",
      "tensor([ 0.5289, -1.3559, -0.3722,  0.8194,  0.8235, -0.7580,  0.0957,  0.4508],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2904 is -638100, loss is -0.02901847657273789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54661745 0.45338252]\n",
      "Sensor: [0.42717027062820684, 0.6070301383414354, 0.23931804335435317, 0.25332391114169367], Action prob: [0.5762836  0.42371643], Action: 0, state: 1\n",
      "[0.5762836  0.42371643]\n",
      "Sensor: [0.40199079435152135, 0.6544947905265778, 0.22798240917568055, 0.28085045097987366], Action prob: [0.5538374 0.4461625], Action: 0, state: 1\n",
      "[0.5538374 0.4461625]\n",
      "Sensor: [0.3481424268339582, 0.6350937840363433, 0.2054239277247812, 0.31333907949813333], Action prob: [0.55152994 0.44847006], Action: 0, state: 1\n",
      "[0.55152994 0.44847006]\n",
      "Sensor: [0.37331141096952664, 0.6363313734994848, 0.25258237562991304, 0.24589898451384398], Action prob: [0.55157673 0.4484233 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.55157673 0.4484233 ]\n",
      "Sensor: [0.3239758581741536, 0.626386823071645, 0.20023164106967228, 0.24964460587485982], Action prob: [0.5517438 0.4482562], Action: 0, state: 1\n",
      "[0.5517438 0.4482562]\n",
      "Sensor: [0.4063405611238438, 0.6486985807027158, 0.2077243313402418, 0.224794922548276], Action prob: [0.55174255 0.44825742], Action: 0, state: 2\n",
      "[0.55174255 0.44825742]\n",
      "Sensor: [0.37559320371112453, 0.6425419090978085, 0.21987693791622132, 0.2701255430924785], Action prob: [0.55182445 0.44817552], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "[0.55182445 0.44817552]\n",
      "Sensor: [0.4029229651823297, 0.6616351650695442, 0.20960683806143576, 0.20732387347769923], Action prob: [0.55180043 0.44819957], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "tensor([-1.0347, -0.6599, -0.2542,  0.0886,  0.2126,  0.4683,  0.9587,  0.7340],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2912 is -634600, loss is -0.06416956971991614\n",
      "[0.55180043 0.44819957]\n",
      "Sensor: [0.3727852914211927, 0.5439438632319841, 0.21036728507925928, 0.5771249008571483], Action prob: [0.5818084 0.4181916], Action: 0, state: 0\n",
      "[0.5818084 0.4181916]\n",
      "Sensor: [0.3596706527230847, 0.6548364304921613, 0.2334217485089884, 0.622068385683556], Action prob: [0.55994105 0.44005895], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.55994105 0.44005895]\n",
      "Sensor: [0.32414496030458556, 0.6526711552199993, 0.23249958248057942, 0.5958460453780066], Action prob: [0.55857223 0.44142768], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.55857223 0.44142768]\n",
      "Sensor: [0.35615592922807243, 0.6451873277546449, 0.2696994863815888, 0.20903045634649198], Action prob: [0.5588449 0.4411551], Action: 0, state: 0\n",
      "[0.5588449 0.4411551]\n",
      "Sensor: [0.4220594671993841, 0.642977738812686, 0.19068525345102616, 0.24727459455902334], Action prob: [0.5591362 0.4408637], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5591362 0.4408637]\n",
      "Sensor: [0.3735548909024005, 0.6587251527336818, 0.24643546973625424, 0.23652328492301491], Action prob: [0.5593719  0.44062817], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5593719  0.44062817]\n",
      "Sensor: [0.42207253644456405, 0.6644736075292622, 0.20834486336822522, 0.20964125962783872], Action prob: [0.5594163 0.4405837], Action: 0, state: 0\n",
      "[0.5594163 0.4405837]\n",
      "Sensor: [0.29005248161239094, 0.6461702246282975, 0.21904519559591032, 0.27592678835872053], Action prob: [0.5596406  0.44035944], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.0395, -0.7233, -0.3404, -0.0290,  0.5692,  0.5755,  0.4014,  1.0356],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2920 is -630100, loss is -0.056180123598531514\n",
      "[0.5596406  0.44035944]\n",
      "Sensor: [0.32842120501446725, 0.6708405988652617, 0.2649042372554038, 0.2752096837847209], Action prob: [0.5922204  0.40777957], Action: 0, state: 0\n",
      "[0.5922204  0.40777957]\n",
      "Sensor: [0.27859975805442777, 0.5752544636854996, 0.21238055807155368, 0.2570893510855433], Action prob: [0.5731504 0.4268496], Action: 0, state: 0\n",
      "[0.5731504 0.4268496]\n",
      "Sensor: [0.6439476651466658, 0.6506310228792636, 0.19039841130801646, 0.24118906977239593], Action prob: [0.56692857 0.43307152], Action: 0, state: 0\n",
      "[0.56692857 0.43307152]\n",
      "Sensor: [0.3951848347433202, 0.6450405721186299, 0.1725114268424276, 0.2482620013777922], Action prob: [0.5676264 0.4323736], Action: 0, state: 0\n",
      "[0.5676264 0.4323736]\n",
      "Sensor: [0.4102665314783122, 0.6406358903762791, 0.2411577068316382, 0.5452340526300152], Action prob: [0.56855243 0.4314476 ], Action: 0, state: 0\n",
      "[0.56855243 0.4314476 ]\n",
      "Sensor: [0.34628667814478176, 0.6541842197036132, 0.20675365251450156, 0.2370497862221504], Action prob: [0.56878877 0.4312113 ], Action: 0, state: 1\n",
      "[0.56878877 0.4312113 ]\n",
      "Sensor: [0.3444308190084965, 0.636111876316777, 0.2554058759518405, 0.23044214895787457], Action prob: [0.56891793 0.43108213], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "[0.56891793 0.43108213]\n",
      "Sensor: [0.366562960952668, 0.5968622382911398, 0.20836808342898788, 0.22266686325814825], Action prob: [0.56893384 0.43106616], Action: 0, state: 1\n",
      "tensor([-0.9248, -0.6242, -0.3337, -0.0240,  0.2653,  0.4574,  0.9403,  0.6078],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2928 is -623700, loss is -0.045508985353664475\n",
      "[0.56893384 0.43106616]\n",
      "Sensor: [0.39507097725916607, 0.6360649352468352, 0.22257344555543765, 0.26154322813905123], Action prob: [0.60137963 0.39862034], Action: 0, state: 2\n",
      "[0.60137963 0.39862034]\n",
      "Sensor: [0.37488706811614164, 0.7224120260977885, 0.20089435817081247, 0.20622125727608792], Action prob: [0.58404607 0.415954  ], Action: 0, state: 2\n",
      "[0.58404607 0.415954  ]\n",
      "Sensor: [0.37334625839932156, 0.6293077358552601, 0.25950948323643863, 0.2217640280189785], Action prob: [0.577403   0.42259696], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1600\n",
      "[0.577403   0.42259696]\n",
      "Sensor: [0.3137790245890751, 0.5558688832951276, 0.17254400553246946, 0.27725725068665685], Action prob: [0.57793635 0.42206365], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -4500\n",
      "Maintenance in progress, cumulative -3500\n",
      "[0.57793635 0.42206365]\n",
      "Sensor: [0.3492765712263446, 0.6776565753198253, 0.20480028685819035, 0.2717508834517304], Action prob: [0.57858217 0.4214179 ], Action: 0, state: 0\n",
      "[0.57858217 0.4214179 ]\n",
      "Sensor: [0.3585023442620202, 0.6261902296491723, 0.20468362799528594, 0.2470409846811502], Action prob: [0.5790478  0.42095223], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5790478  0.42095223]\n",
      "Sensor: [0.38460907529419897, 0.6350090929343093, 0.18614817256666918, 0.31292494237169116], Action prob: [0.57937735 0.42062262], Action: 0, state: 0\n",
      "[0.57937735 0.42062262]\n",
      "Sensor: [0.3491534090514935, 0.6584170615633477, 0.20915275395167993, 0.266657170304055], Action prob: [0.57960457 0.42039546], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -2500\n",
      "tensor([ 0.1877,  0.5420,  1.3794,  0.4836, -0.8286, -0.8522, -0.4046, -0.3076],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2936 is -627300, loss is -0.024974661555054116\n",
      "[0.57960457 0.42039546]\n",
      "Sensor: [0.40061794366335507, 0.6409531852870654, 0.2338331516357848, 0.26566837598909543], Action prob: [0.61096364 0.38903642], Action: 0, state: 0\n",
      "[0.61096364 0.38903642]\n",
      "Sensor: [0.3782444435008726, 0.6327019213976357, 0.1972919318944109, 0.27222963029660474], Action prob: [0.5960116  0.40398836], Action: 1, state: 0\n",
      "[0.5960116  0.40398836]\n",
      "Sensor: [0.5779408313051688, 0.6711825461383347, 0.2197948384715814, 0.2854154092790197], Action prob: [0.58917063 0.41082934], Action: 1, state: 9\n",
      "[0.58917063 0.41082934]\n",
      "Sensor: [0.5524238114213768, 0.5836062796309919, 0.24059289537424414, 0.1807371769993141], Action prob: [0.5902235 0.4097765], Action: 1, state: 9\n",
      "[0.5902235 0.4097765]\n",
      "Sensor: [0.39098306945914363, 0.6510580368931883, 0.22168367693959146, 0.2694836905331263], Action prob: [0.5915739 0.4084261], Action: 0, state: 0\n",
      "[0.5915739 0.4084261]\n",
      "Sensor: [0.36290417178387985, 0.6688720206656638, 0.17678644375612598, 0.26102533667344174], Action prob: [0.59239316 0.4076068 ], Action: 0, state: 1\n",
      "[0.59239316 0.4076068 ]\n",
      "Sensor: [0.39567849341663064, 0.5521468243390528, 0.20770878471830356, 0.23634054477815436], Action prob: [0.5926086  0.40739137], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.5926086  0.40739137]\n",
      "Sensor: [0.32427193939671356, 0.6273076664110988, 0.1943102508684473, 0.3333141482400802], Action prob: [0.5930293  0.40697068], Action: 0, state: 1\n",
      "tensor([-0.3296,  0.8074, -0.4729, -1.6070, -0.3354,  0.1462,  0.9117,  0.7133],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2944 is -624300, loss is 0.0207741514776872\n",
      "[0.5930293  0.40697068]\n",
      "Sensor: [0.4095330834689555, 0.6532220738133049, 0.20880530115647286, 0.20458199817364478], Action prob: [0.6195093  0.38049066], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6195093  0.38049066]\n",
      "Sensor: [0.3612243546296591, 0.6383266116927172, 0.25164338284006366, 0.22775137310093274], Action prob: [0.6065703  0.39342967], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.6065703  0.39342967]\n",
      "Sensor: [0.39918253226589473, 0.6631867378524209, 0.2319718629469749, 0.2527625814440704], Action prob: [0.60030216 0.39969784], Action: 0, state: 0\n",
      "[0.60030216 0.39969784]\n",
      "Sensor: [0.3657761414209042, 0.678423770518676, 0.22411068202482076, 0.25677993763016616], Action prob: [0.60017186 0.3998281 ], Action: 0, state: 1\n",
      "[0.60017186 0.3998281 ]\n",
      "Sensor: [0.35366825168961136, 0.579709265283672, 0.21938890328891475, 0.2756840826447444], Action prob: [0.60133815 0.39866185], Action: 0, state: 2\n",
      "[0.60133815 0.39866185]\n",
      "Sensor: [0.3722831439780344, 0.6064842937238264, 0.2370320061533617, 0.22585283556278654], Action prob: [0.602036   0.39796403], Action: 0, state: 2\n",
      "[0.602036   0.39796403]\n",
      "Sensor: [0.3685140414252529, 0.6292942006318235, 0.23697429491450908, 0.3007266825194575], Action prob: [0.60262096 0.39737907], Action: 0, state: 2\n",
      "[0.60262096 0.39737907]\n",
      "Sensor: [0.3488871400346232, 0.5816677843580786, 0.2020540995734155, 0.20923206968182334], Action prob: [0.6028031 0.3971969], Action: 0, state: 3\n",
      "tensor([-1.3894, -0.8974, -0.4925, -0.1461,  0.1330,  0.3753,  0.6014,  0.7198],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2952 is -619500, loss is 0.13699597847285402\n",
      "[0.6028031 0.3971969]\n",
      "Sensor: [0.42944565716626615, 0.6236368018179104, 0.21262112790409599, 0.2743090531844767], Action prob: [0.6217054  0.37829462], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "[0.6217054  0.37829462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.36115708012600584, 0.6522336208872709, 0.24486608323985448, 0.2156627583318713], Action prob: [0.60939014 0.39060986], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.60939014 0.39060986]\n",
      "Sensor: [0.3531620707141372, 0.7080972099829275, 0.2154132355327418, 0.277499807818245], Action prob: [0.60343236 0.39656755], Action: 0, state: 1\n",
      "[0.60343236 0.39656755]\n",
      "Sensor: [0.38310961173191277, 0.6621630414596182, 0.21118426114122968, 0.27410376620745824], Action prob: [0.6015799  0.39842016], Action: 0, state: 1\n",
      "[0.6015799  0.39842016]\n",
      "Sensor: [0.40694422459304125, 0.4838541458245891, 0.23185729528680843, 0.220302685144428], Action prob: [0.6020576  0.39794242], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6020576  0.39794242]\n",
      "Sensor: [0.3982268847923472, 0.6055289441082082, 0.23301617271607528, 0.2833192327819134], Action prob: [0.60276246 0.3972376 ], Action: 0, state: 0\n",
      "[0.60276246 0.3972376 ]\n",
      "Sensor: [0.3284308118948008, 0.6779342210957462, 0.1812729568094039, 0.24431938665840236], Action prob: [0.60334456 0.39665553], Action: 0, state: 0\n",
      "[0.60334456 0.39665553]\n",
      "Sensor: [0.3208341898779522, 0.6381001140982507, 0.19410899167488874, 0.2382532208663169], Action prob: [0.6035714 0.3964286], Action: 0, state: 1\n",
      "tensor([-1.0679, -1.2020, -0.4788, -0.1479,  0.2765,  0.3050,  0.5718,  0.7910],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2960 is -614200, loss is 0.11903432309797761\n",
      "[0.6035714 0.3964286]\n",
      "Sensor: [0.3727812554672015, 0.6673511416186486, 0.24631791138778406, 0.25355380358127516], Action prob: [0.62126017 0.37873974], Action: 0, state: 1\n",
      "[0.62126017 0.37873974]\n",
      "Sensor: [0.3670501752571297, 0.6919191389612673, 0.19072714776136357, 0.2728773389380199], Action prob: [0.6079375  0.39206252], Action: 0, state: 1\n",
      "[0.6079375  0.39206252]\n",
      "Sensor: [0.3276372202698259, 0.6144348509552726, 0.31333103327349715, 0.23188815081296843], Action prob: [0.6018855  0.39811456], Action: 0, state: 1\n",
      "[0.6018855  0.39811456]\n",
      "Sensor: [0.3654722395744276, 0.6485211367937406, 0.20486220944109645, 0.24672631343407936], Action prob: [0.5992525  0.40074745], Action: 0, state: 1\n",
      "[0.5992525  0.40074745]\n",
      "Sensor: [0.3786721046520295, 0.6308158780565325, 0.19729868392108366, 0.25878297988943305], Action prob: [0.59852636 0.4014736 ], Action: 0, state: 1\n",
      "[0.59852636 0.4014736 ]\n",
      "Sensor: [0.3415150165083193, 0.6842679595069247, 0.38290059036689383, 0.23818787596691754], Action prob: [0.59848005 0.40151998], Action: 0, state: 1\n",
      "[0.59848005 0.40151998]\n",
      "Sensor: [0.3012109103370339, 0.6440309773749935, 0.22509467695454316, 0.2477972574080321], Action prob: [0.5986736  0.40132642], Action: 0, state: 1\n",
      "[0.5986736  0.40132642]\n",
      "Sensor: [0.3387790525253092, 0.6407668275875611, 0.19848289032687377, 0.2816953464872472], Action prob: [0.59877187 0.4012282 ], Action: 0, state: 1\n",
      "tensor([-0.8018, -0.5479, -0.2857, -0.0515,  0.1677,  0.3724,  0.5466,  0.7055],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2968 is -607000, loss is -0.013156897564531256\n",
      "[0.59877187 0.4012282 ]\n",
      "Sensor: [0.37019451826625, 0.6988415491362228, 0.24824950082042704, 0.25745180886141467], Action prob: [0.6205497  0.37945032], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.6205497  0.37945032]\n",
      "Sensor: [0.42708121911525837, 0.6560816592958055, 0.2505699739567826, 0.25091051036349515], Action prob: [0.60653234 0.3934676 ], Action: 0, state: 0\n",
      "[0.60653234 0.3934676 ]\n",
      "Sensor: [0.3783065509961411, 0.6571521874997448, 0.2249374006228083, 0.2834077752976572], Action prob: [0.5999887  0.40001133], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5999887  0.40001133]\n",
      "Sensor: [0.3045387127190669, 0.6831316947343637, 0.20641883946010262, 0.2801957718602852], Action prob: [0.59726036 0.40273967], Action: 0, state: 0\n",
      "[0.59726036 0.40273967]\n",
      "Sensor: [0.31078595793691194, 0.6304810827933747, 0.2277138725754265, 0.23439790592497411], Action prob: [0.596222  0.4037781], Action: 0, state: 1\n",
      "[0.596222  0.4037781]\n",
      "Sensor: [0.39295442609939146, 0.6379563154807988, 0.21960857891616156, 0.26763948587547504], Action prob: [0.59563345 0.40436655], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "[0.59563345 0.40436655]\n",
      "Sensor: [0.4871097244021442, 0.6948015448512525, 0.14765929922109317, 0.20654500520580954], Action prob: [0.5952262  0.40477374], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5952262  0.40477374]\n",
      "Sensor: [0.357523049866376, 0.6441360871559967, 0.2073879133032671, 0.2992414177941578], Action prob: [0.5953604  0.40463957], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.5953, -0.6176, -0.4381, -0.0699,  0.2103,  0.7595,  0.9123,  1.1436],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2976 is -601900, loss is -0.03808529565831066\n",
      "[0.5953604  0.40463957]\n",
      "Sensor: [0.3180106133352619, 0.6735747765418201, 0.23684068972616232, 0.3167092293276629], Action prob: [0.62181854 0.37818152], Action: 0, state: 0\n",
      "[0.62181854 0.37818152]\n",
      "Sensor: [0.379034127174933, 0.6357434329162179, 0.20607575117148194, 0.27504860597971825], Action prob: [0.6083669  0.39163315], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "[0.6083669  0.39163315]\n",
      "Sensor: [0.3228688643269974, 0.6671084560554884, 0.25020028726176646, 0.2938385035368616], Action prob: [0.60234505 0.39765498], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.60234505 0.39765498]\n",
      "Sensor: [0.4086887825417739, 0.6698926102273273, 0.19615296800798704, 0.22976708631985338], Action prob: [0.5995174 0.4004826], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "[0.5995174 0.4004826]\n",
      "Sensor: [0.30978187885226766, 0.6881630503221793, 0.41838448443452214, 0.21969124252082792], Action prob: [0.59852153 0.40147844], Action: 0, state: 0\n",
      "[0.59852153 0.40147844]\n",
      "Sensor: [0.35807394685660515, 0.6165699078187447, 0.2126058264008488, 0.2657020848532392], Action prob: [0.5978633 0.4021367], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "[0.5978633 0.4021367]\n",
      "Sensor: [0.3778765658654085, 0.633403133832004, 0.2117452860205706, 0.25283270803485447], Action prob: [0.59771836 0.40228158], Action: 0, state: 0\n",
      "[0.59771836 0.40228158]\n",
      "Sensor: [0.4078634642496011, 0.6111084928080999, 0.3221678659109462, 0.2679122888534493], Action prob: [0.5975943  0.40240577], Action: 0, state: 0\n",
      "tensor([-0.7760, -0.3378, -0.8559, -0.3935,  0.0340,  0.8174,  0.4594,  0.8164],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2984 is -597500, loss is 0.029521229820387615\n",
      "[0.5975943  0.40240577]\n",
      "Sensor: [0.35260415087294905, 0.6987031366132535, 0.21541397179204966, 0.2727300460050974], Action prob: [0.62110823 0.37889174], Action: 0, state: 1\n",
      "[0.62110823 0.37889174]\n",
      "Sensor: [0.2904739143616784, 0.630401057331534, 0.24181624427121937, 0.20900798676465931], Action prob: [0.6084178 0.3915822], Action: 0, state: 2\n",
      "[0.6084178 0.3915822]\n",
      "Sensor: [0.4035725318646888, 0.6298173148590499, 0.21422476683468492, 0.21247465295388135], Action prob: [0.60213053 0.3978695 ], Action: 0, state: 3\n",
      "[0.60213053 0.3978695 ]\n",
      "Sensor: [0.5802093696163435, 0.6075727922789754, 0.21144340458855257, 0.24530804175706236], Action prob: [0.5988298 0.4011702], Action: 0, state: 8\n",
      "[0.5988298 0.4011702]\n",
      "Sensor: [0.314034433849957, 0.382407994228394, 0.23331089102971467, 0.23277417496076458], Action prob: [0.5983008  0.40169913], Action: 1, state: 8\n",
      "[0.5983008  0.40169913]\n",
      "Sensor: [0.2858214822664985, 0.3924237550719759, 0.17638758860944428, 0.22426679286934967], Action prob: [0.5983412 0.4016588], Action: 0, state: 8\n",
      "[0.5983412 0.4016588]\n",
      "Sensor: [0.34218031115231623, 0.3648862159692889, 0.20423825344396787, 0.2662533942455637], Action prob: [0.59843194 0.40156806], Action: 0, state: 8\n",
      "[0.59843194 0.40156806]\n",
      "Sensor: [0.5723365808129601, 0.6278247111096857, 0.17648996755652246, 0.22916818496528943], Action prob: [0.5975942 0.4024058], Action: 1, state: 8\n",
      "tensor([ 0.4025,  0.5334,  0.6022,  0.2490, -0.0894, -0.3382, -0.5939, -1.5016],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 2992 is -614200, loss is 0.09198624035938816\n",
      "[0.5975942 0.4024058]\n",
      "Sensor: [0.3635172515689517, 0.609842777007607, 0.522771849239233, 0.23041072923652195], Action prob: [0.61788845 0.38211155], Action: 0, state: 8\n",
      "[0.61788845 0.38211155]\n",
      "Sensor: [0.40129604719847084, 0.6689779161053211, 0.4783493175502353, 0.291814629730401], Action prob: [0.60332555 0.39667448], Action: 0, state: 8\n",
      "[0.60332555 0.39667448]\n",
      "Sensor: [0.655126046966748, 0.7141632181996824, 0.2697497558434989, 0.2309308097352393], Action prob: [0.59625304 0.40374696], Action: 1, state: 8\n",
      "[0.59625304 0.40374696]\n",
      "Sensor: [0.4104915635743273, 0.6445650871060006, 0.2297123083216605, 0.5507934241878365], Action prob: [0.5934483  0.40655172], Action: 0, state: 8\n",
      "[0.5934483  0.40655172]\n",
      "Sensor: [0.369951826805032, 0.35491215084095784, 0.23553271566626433, 0.26904340641552954], Action prob: [0.59318215 0.40681785], Action: 1, state: 8\n",
      "[0.59318215 0.40681785]\n",
      "Sensor: [0.37889287491126006, 0.3450966233059246, 0.22653263496044573, 0.27521023848865567], Action prob: [0.5934972 0.4065028], Action: 1, state: 8\n",
      "[0.5934972 0.4065028]\n",
      "Sensor: [0.3223826644824147, 0.37336053973822314, 0.23771869242355648, 0.30371278893934306], Action prob: [0.593859   0.40614095], Action: 0, state: 8\n",
      "[0.593859   0.40614095]\n",
      "Sensor: [0.3535423729838757, 0.6041441098599052, 0.5464676633329412, 0.26271585467001685], Action prob: [0.5935154 0.4064846], Action: 0, state: 8\n",
      "tensor([ 0.8265,  0.5713,  0.4970,  0.0782, -0.2770, -0.6234, -0.5353, -0.6940],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this timestep 3000 is -638200, loss is 0.01958815849788488\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "machine1 = Machine_env(tm,r_func)\n",
    "print(r_func)\n",
    "baseline = StateValueNetwork(machine1.observation_space)\n",
    "pol = policy_estimator(machine1)\n",
    "\n",
    "#Hyper Parameters\n",
    "timestep = 3000\n",
    "gamma = 0.9\n",
    "lr= 0.005\n",
    "lookback = 8\n",
    "\n",
    "results = recurrent_pg_baseline(machine1,baseline,pol,timestep,lookback,gamma,lr)\n",
    "rewards = results[0]\n",
    "actions = np.array(results[1])\n",
    "states = results[2]\n",
    "\n",
    "episode = [i for i in range(len(rewards))]\n",
    "\n",
    "#Moving average we will use a window size of 50\n",
    "\n",
    "moving_averages = []\n",
    "window_size = 10\n",
    "\n",
    "df = pd.DataFrame(rewards,columns = ['r'])\n",
    "moving_ave = df.r.rolling(window_size,min_periods=1).mean().values\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.plot(episode,rewards,label = 'Cumulative Reward')\n",
    "plt.plot(episode,moving_ave,label = f'Moving Average Window {window_size}')\n",
    "plt.title(f'Lookback {lookback}')\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Rewards')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# machine1 = Machine_env()\n",
    "# pol = policy_estimator(machine1)\n",
    "# x = [machine1.sensor(9),machine1.sensor(9)]\n",
    "# #x = [machine1.sensor(9)]\n",
    "# x = torch.FloatTensor(x)\n",
    "# pol(x).detach().numpy()[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Episodic/Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine_env2():\n",
    "\n",
    "    def __init__(self,tm,r_func):\n",
    "        self.action_space = [0,1]\n",
    "        self.state = 0 #Random initialise the start state, assumes uniform distribution for initial state,random.randrange(10)\n",
    "        self.state_seq = [] #initialise a list that records the actual states\n",
    "        self.reward_func = r_func\n",
    "        self.observation_space = 4\n",
    "        self.transition  = tm\n",
    "        self.simulator = Machine() #simulator to generate sensor readings\n",
    "        self.done = False\n",
    "        self.steps = 0\n",
    "    \n",
    "    def sensor(self,state): # generate observation at state\n",
    "        self.simulator.curr_state = state\n",
    "        sensor_reading = self.simulator.readSensors()\n",
    "        return sensor_reading\n",
    "    \n",
    "    def step(self,action): # simulate movement of states given an action\n",
    "        self.state_seq.append(self.state) #record current state\n",
    "        \n",
    "        transition_mat_action = self.transition[action]\n",
    "        #print(f\"Transition Prob: {transition_mat_action[self.state]}\")\n",
    "        nxt_state = np.random.choice([i for i in range(10)],1,p=transition_mat_action[self.state])[0] #select nxt state based\n",
    "        reward = self.reward_func[nxt_state] #reward for going to next state\n",
    "        self.state = nxt_state #update state\n",
    "        \n",
    "        self.steps += 1\n",
    "        \n",
    "        #if(((nxt_state == 0) and (self.steps > 20)) or (self.steps >= 30)):#condition for end of episode\n",
    "        if self.steps >= 30:   \n",
    "            self.done = True\n",
    "\n",
    "\n",
    "        return reward\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = 0\n",
    "        self.done = False\n",
    "        self.steps = 0\n",
    "        self.state_seq = []\n",
    "        return \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurrent_pg_baseline_montecarlo(machine,baseline_net,policy_estimator,episodes,gamma,lr): #Learning algo\n",
    "    # Set up lists to hold results\n",
    "    # Set up lists to hold results\n",
    "    total_rewards = [] #Total actual reward for each episode\n",
    "    batch_rewards = []  #Discounted expected future rewards for each batch\n",
    "    batch_actions = []\n",
    "    batch_observation = []\n",
    "    state_seq = []\n",
    "\n",
    "    \n",
    "    # Define optimizer\n",
    "    optimizer = torch.optim.Adam(policy_estimator.parameters(),lr=lr)\n",
    "    state_val_optimizer = torch.optim.Adam(baseline_net.parameters(),lr=0.001)\n",
    "    \n",
    "    action_space = machine.action_space\n",
    "    \n",
    "    machine.reset()\n",
    "    observation = []\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    t = 0\n",
    "    \n",
    "    for ep in range(episodes):\n",
    "        machine.reset()\n",
    "        observation = []\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        \n",
    "        while(not machine.done):\n",
    "            obs = machine.sensor(machine.state).tolist() #observation\n",
    "\n",
    "            observation.append(obs)\n",
    "\n",
    "            \n",
    "            action_probs = policy_estimator(observation).detach().numpy()[-1] #convert to numpy and get action prob for the latest\n",
    "\n",
    "            try:\n",
    "                action = np.random.choice(action_space, p=action_probs) #select weighted actions based on NN output prob\n",
    "            except: #in the event converged\n",
    "                action_probs = np.nan_to_num(action_probs)\n",
    "                action_probs = np.round(action_probs)\n",
    "                action = np.random.choice(action_space, p=action_probs)\n",
    "\n",
    "            print(f\"Sensor: {obs}, Action prob: {action_probs}, Action: {action}, state: {machine.state}\")\n",
    "\n",
    "            r = machine.step(action) #receive reward and update machine to the next state after doing the sampled action\n",
    "\n",
    "            rewards.append(r)\n",
    "            actions.append(action)\n",
    "\n",
    "            while(r == -maintenance_cost): #cumulate maintenance\n",
    "                r = machine.step(0)\n",
    "                rewards[-1] += r \n",
    "                print(f\"Maintenance in progress, cumulative {rewards[-1]}\")\n",
    "            \n",
    "    \n",
    "        discount_r = normalized_discount_reward(rewards,gamma) #normalised future rewards\n",
    "\n",
    "        obs_tensor = torch.FloatTensor(observation)\n",
    "        action_tensor = torch.LongTensor(actions)\n",
    "        reward_tensor = torch.from_numpy(np.array(discount_r).copy()) #discounted reward G\n",
    "\n",
    "        #calculate state values \n",
    "        state_value_tensor = stack_state_value(np.array(observation),baseline_net)\n",
    "\n",
    "        #train state value network\n",
    "#             print(rewards)\n",
    "#             print(reward_tensor,state_value_tensor)\n",
    "        train_value(reward_tensor,state_value_tensor,state_val_optimizer)\n",
    "\n",
    "        #calculate delta or advantage \n",
    "        deltas = [gt - val for gt, val in zip(reward_tensor, state_value_tensor)]\n",
    "        deltas = torch.tensor(deltas)\n",
    "\n",
    "\n",
    "\n",
    "        logprob = torch.log(policy_estimator(obs_tensor))\n",
    "\n",
    "        #print(logprob[np.arange(len(action_tensor)), action_tensor])\n",
    "        selected_logprobs = deltas * logprob[np.arange(len(action_tensor)), action_tensor]\n",
    "        print(selected_logprobs)\n",
    "\n",
    "\n",
    "        loss = -selected_logprobs.mean()\n",
    "\n",
    "        if loss != 0:\n",
    "            optimizer.zero_grad()\n",
    "            # Calculate gradients\n",
    "            loss.backward()\n",
    "            # Apply gradients\n",
    "            optimizer.step()\n",
    "\n",
    "        total_rewards.append(sum(rewards)) #Cumulative reward for this batch\n",
    "        print(f\"Reward for up to this episode {ep} is {total_rewards[-1]}, loss is {loss}\")\n",
    "        continue\n",
    "            \n",
    "        total_rewards.append(sum(rewards))\n",
    "        \n",
    "        \n",
    "        \n",
    "#         #Tensorboard params\n",
    "#         writer.add_scalar(\"Loss\", loss, ep)\n",
    "#         writer.add_scalar('Rewards',sum(rewards),ep)\n",
    "#         for name, weight in policy_estimator.network.named_parameters():\n",
    "#             try:\n",
    "#                 writer.add_histogram(name,weight, ep)\n",
    "#             except:\n",
    "#                 continue\n",
    "#             if weight.grad != None:\n",
    "#                 writer.add_histogram(f\"{name}.grad\",weight.grad, ep)\n",
    "    \n",
    "#     writer.add_graph(policy_estimator.network,torch.FloatTensor(machine.sensor(0))) #draw graph\n",
    "#     writer.flush()\n",
    "#     writer.close()\n",
    "    \n",
    "    return (total_rewards,batch_actions,state_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\overl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator GaussianMixture from version 0.20.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1000, 1: 900, 2: 800, 3: 500, 4: -500, 5: -500, 6: -500, 7: -500, 8: -3000, 9: -1000}\n",
      "Sensor: [0.3807507762454214, 0.6361738006384455, 0.23620420574119588, 0.24661291254615758], Action prob: [0.50629276 0.49370724], Action: 0, state: 0\n",
      "Sensor: [0.32693456590855147, 0.584582397752011, 0.22895891251197156, 0.3115032267603916], Action prob: [0.50738144 0.49261862], Action: 0, state: 1\n",
      "Sensor: [0.3425466971943434, 0.6491868988073065, 0.2233219306026904, 0.2548158056844297], Action prob: [0.5079862  0.49201375], Action: 0, state: 1\n",
      "Sensor: [0.35519110517563685, 0.6301193747618096, 0.21780008347461696, 0.32515100329823626], Action prob: [0.50839037 0.49160966], Action: 0, state: 1\n",
      "Sensor: [0.3851757862306747, 0.6720971267367457, 0.17417835183964436, 0.3585998474681449], Action prob: [0.5086722  0.49132782], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.33074796324258576, 0.6746131291027251, 0.21121481641485515, 0.2338107580761701], Action prob: [0.50855947 0.49144053], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.38103489192465984, 0.6312963621788364, 0.2255727870723088, 0.5455431150719356], Action prob: [0.5089343 0.4910656], Action: 0, state: 0\n",
      "Sensor: [0.31169393010075314, 0.6455289721255132, 0.20816094466155366, 0.20487757356015535], Action prob: [0.50860953 0.49139044], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.34904056319965227, 0.6449232207764921, 0.190927834767545, 0.2529771075590116], Action prob: [0.50851583 0.4914842 ], Action: 0, state: 0\n",
      "Sensor: [0.39831915975861754, 0.5867445425336777, 0.20524449380067558, 0.2378927610575761], Action prob: [0.50843155 0.4915685 ], Action: 0, state: 1\n",
      "Sensor: [0.38367165553311744, 0.6073260300055894, 0.19847065958346027, 0.26998150730820913], Action prob: [0.50845706 0.4915429 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.2955683391180465, 0.6317492019119298, 0.22196159046537425, 0.23474636160492235], Action prob: [0.5083835  0.49161646], Action: 0, state: 0\n",
      "Sensor: [0.3949021018662898, 0.6656136748098862, 0.22968421764635621, 0.2728982833377152], Action prob: [0.50846076 0.49153927], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "Sensor: [0.3144780322827195, 0.6812410507756165, 0.17519541635922914, 0.24219579922003734], Action prob: [0.50844204 0.49155802], Action: 0, state: 0\n",
      "Sensor: [0.351577217635754, 0.6058926280850312, 0.2564525119093276, 0.24076547366870754], Action prob: [0.50835896 0.491641  ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.37440356435340655, 0.6429174454072846, 0.24532641926767915, 0.2737367936886092], Action prob: [0.5084142 0.4915858], Action: 0, state: 0\n",
      "Sensor: [0.3339933525180818, 0.6731960609364468, 0.21669085149266015, 0.2864135462401243], Action prob: [0.5084719  0.49152806], Action: 0, state: 0\n",
      "Sensor: [0.33719992257253895, 0.6894379017395189, 0.21275238583703046, 0.21646714144385554], Action prob: [0.5084107  0.49158922], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.5207, -1.1436, -0.8071, -0.5055, -0.2466, -0.1045, -0.0994,  0.1256,\n",
      "         0.2182,  0.3779,  0.5478,  0.5937,  0.7456,  0.5355,  0.6719,  0.6874,\n",
      "         0.7722,  0.8910], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 0 is 11300, loss is -0.09664238270084018\n",
      "Sensor: [0.3848890469392853, 0.6483231861991626, 0.2622049776467288, 0.2660137433595797], Action prob: [0.5544343  0.44556567], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3810817090178286, 0.5885961296553166, 0.21972757182253563, 0.274348698755976], Action prob: [0.56618035 0.43381968], Action: 0, state: 0\n",
      "Sensor: [0.385783135424916, 0.6588652315639353, 0.24480836206781809, 0.381177142457125], Action prob: [0.5736567  0.42634335], Action: 0, state: 0\n",
      "Sensor: [0.3159532060707505, 0.6397197320564639, 0.18810988498231668, 0.2648150369156397], Action prob: [0.5771433 0.4228567], Action: 0, state: 0\n",
      "Sensor: [0.309498781581775, 0.6128154705637429, 0.22379755651334954, 0.29416399836013923], Action prob: [0.57891375 0.42108625], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.31979327125089224, 0.7007594943170533, 0.18181172695940534, 0.27531865528231864], Action prob: [0.5801317  0.41986826], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.38926228053997125, 0.48226827571771386, 0.26053703682676593, 0.3312789168221833], Action prob: [0.5802576  0.41974244], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3295068980038246, 0.633742800666822, 0.20665314000241575, 0.2566943170588791], Action prob: [0.58043575 0.41956425], Action: 0, state: 0\n",
      "Sensor: [0.38834745872332976, 0.6624040296704791, 0.19657522564287602, 0.5914245731551121], Action prob: [0.5818606 0.4181394], Action: 0, state: 0\n",
      "Sensor: [0.4126798335149911, 0.6208934003478944, 0.2315200202209, 0.25194676392897536], Action prob: [0.58161414 0.4183859 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3365670636023657, 0.6669045463658418, 0.241236074006609, 0.25105746055501577], Action prob: [0.58136517 0.41863483], Action: 0, state: 0\n",
      "Sensor: [0.357847900759507, 0.6903747620988345, 0.21454759412454488, 0.2907863321548627], Action prob: [0.58141285 0.41858718], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3403317004681452, 0.684474231745759, 0.17387373496140332, 0.24901037749904045], Action prob: [0.58103573 0.41896424], Action: 0, state: 0\n",
      "Sensor: [0.36353294173623035, 0.6148147551040354, 0.23960833757196565, 0.2514189428749195], Action prob: [0.58075744 0.4192426 ], Action: 0, state: 0\n",
      "Sensor: [0.328581440876152, 0.6861088032262704, 0.22245286683405704, 0.28474310442530854], Action prob: [0.58087754 0.41912246], Action: 0, state: 0\n",
      "Sensor: [0.31846923458324433, 0.6684013563247782, 0.250669939691384, 0.2917931820844187], Action prob: [0.5809326 0.4190674], Action: 0, state: 0\n",
      "Sensor: [0.2871711600127076, 0.6400795343354431, 0.20739487720602187, 0.2217618013230862], Action prob: [0.58029777 0.4197023 ], Action: 0, state: 0\n",
      "Sensor: [0.3569759156657681, 0.6728858701662702, 0.21587753459750858, 0.2679298206979648], Action prob: [0.5805597  0.41944027], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3921340549544863, 0.6228352497820392, 0.2139416741617152, 0.247148392738993], Action prob: [0.58053046 0.4194695 ], Action: 0, state: 0\n",
      "Sensor: [0.38413375916604775, 0.652742361177029, 0.2092655477672501, 0.24937003737148145], Action prob: [0.5806392 0.4193608], Action: 0, state: 0\n",
      "Sensor: [0.3152603314985201, 0.6387853310895796, 0.21132306475997426, 0.28047367648842175], Action prob: [0.58046156 0.41953835], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "tensor([-1.7149, -1.0568, -0.7692, -0.5263, -0.4962, -0.3479, -0.2131, -0.0574,\n",
      "         0.0792,  0.3248,  0.1468,  0.3957,  0.2916,  0.3726,  0.4452,  0.5104,\n",
      "         0.5706,  0.9956,  0.6471,  0.6898,  1.1578], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 1 is 14900, loss is -0.06883676582354883\n",
      "Sensor: [0.34465156415535225, 0.716059127848666, 0.2309253264692516, 0.31965107942798693], Action prob: [0.5623699 0.4376302], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.339656866764904, 0.6337398028513942, 0.21160770297537052, 0.2770259352626168], Action prob: [0.5684817  0.43151838], Action: 0, state: 0\n",
      "Sensor: [0.33160420214809244, 0.6733501332066817, 0.22266569152997262, 0.2677380701927195], Action prob: [0.567962   0.43203798], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.2584195973444341, 0.6173219881510592, 0.2287884701120162, 0.536533215191078], Action prob: [0.5654804  0.43451956], Action: 0, state: 0\n",
      "Sensor: [0.3730893435814779, 0.7013922952773072, 0.19993724352025308, 0.2727656731823018], Action prob: [0.5616264 0.4383736], Action: 0, state: 1\n",
      "Sensor: [0.35878176849379717, 0.5962707175345271, 0.2343922547450457, 0.20855387001279505], Action prob: [0.5577228  0.44227728], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.37827521907582007, 0.6914724285266801, 0.20258193358499857, 0.2657964745211796], Action prob: [0.55548817 0.44451183], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.28348369236406634, 0.7026274122954107, 0.23209713123959505, 0.302951237925657], Action prob: [0.5538984  0.44610167], Action: 0, state: 0\n",
      "Sensor: [0.32693521815998333, 0.6658074590684777, 0.21468429100026276, 0.26734460848854563], Action prob: [0.5527869 0.4472131], Action: 0, state: 0\n",
      "Sensor: [0.4132220738423086, 0.6958555814032734, 0.16467114527018178, 0.2779459860344658], Action prob: [0.55242425 0.44757572], Action: 0, state: 0\n",
      "Sensor: [0.380235162606283, 0.6553894631554177, 0.18010321944865215, 0.1942554540522551], Action prob: [0.55193067 0.44806936], Action: 0, state: 0\n",
      "Sensor: [0.3844997960970857, 0.687540035998063, 0.24102616217942277, 0.22202575877774738], Action prob: [0.5522201  0.44777986], Action: 0, state: 0\n",
      "Sensor: [0.43727915898733816, 0.6167589280387453, 0.22690959837336877, 0.25975848129190765], Action prob: [0.55235946 0.44764057], Action: 0, state: 1\n",
      "Sensor: [0.3592729073305093, 0.6695066021801093, 0.23104757149234975, 0.25043248236921073], Action prob: [0.55243576 0.4475642 ], Action: 0, state: 1\n",
      "Sensor: [0.38097154218949436, 0.5943671713261433, 0.2082155307281952, 0.282493368378614], Action prob: [0.5522756  0.44772437], Action: 0, state: 2\n",
      "Sensor: [0.3538679150888901, 0.6060176514582052, 0.18850855324746577, 0.25709271503677045], Action prob: [0.5521263  0.44787374], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1100\n",
      "tensor([-0.9373, -0.8484, -0.7044, -0.6485, -0.3774, -0.1786, -0.3541, -0.1425,\n",
      "         0.0661,  0.2545,  0.4246,  0.5765,  0.7000,  0.8108,  0.9004,  1.3264],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 2 is 8100, loss is -0.0542454862375448\n",
      "Sensor: [0.3452387281838727, 0.627809438915626, 0.1948915773651922, 0.2457523916418793], Action prob: [0.5474032 0.4525968], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3681730124223227, 0.6698405535290869, 0.24243650277973958, 0.2517951676554442], Action prob: [0.5439785  0.45602146], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.4143199968316947, 0.6378643148188968, 0.23246818178442533, 0.27597823619356576], Action prob: [0.5314832  0.46851686], Action: 0, state: 0\n",
      "Sensor: [0.3468937225333734, 0.5946620221608515, 0.20501278854769298, 0.3005072072462023], Action prob: [0.5175985  0.48240146], Action: 0, state: 1\n",
      "Sensor: [0.4060190615615732, 0.6674612430892846, 0.2274383467572485, 0.24180418323013306], Action prob: [0.5077171  0.49228293], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "Sensor: [0.36562575129030167, 0.6328459053230385, 0.2224506825882798, 0.23306430111823728], Action prob: [0.50096774 0.49903226], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3009224501566571, 0.5912012538222713, 0.21351918336272876, 0.2424913485423944], Action prob: [0.49676666 0.50323343], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3590982537111696, 0.6703716905448572, 0.17792623091450183, 0.20729973684040823], Action prob: [0.49481362 0.5051863 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.38470836849707807, 0.6194562713215082, 0.21948257331548818, 0.2580073668726946], Action prob: [0.49393675 0.5060632 ], Action: 0, state: 0\n",
      "Sensor: [0.31439453413017293, 0.6555571534866667, 0.21483901383119833, 0.22318079627347212], Action prob: [0.49355143 0.5064486 ], Action: 0, state: 0\n",
      "Sensor: [0.3171549938354938, 0.6153893959949139, 0.17735226885917182, 0.19740358233208008], Action prob: [0.49349514 0.5065049 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.42445265097263946, 0.6905405911319519, 0.21388373238271344, 0.2416941130530656], Action prob: [0.49377027 0.5062297 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "tensor([-1.6809, -0.9891, -0.4619, -0.0046,  0.4051,  0.3521,  0.5492,  0.5461,\n",
      "         0.2292,  0.5310,  0.7734,  0.5381], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 3 is 2100, loss is -0.06565980265614484\n",
      "Sensor: [0.33521236391515835, 0.6169549709921249, 0.2290311980397802, 0.3875807854790783], Action prob: [0.54729265 0.45270744], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3588197515607228, 0.6282369143634525, 0.2198558210519436, 0.26140695319522583], Action prob: [0.54592246 0.45407754], Action: 0, state: 0\n",
      "Sensor: [0.3970595941916223, 0.6294818907744985, 0.2375531066491915, 0.25991247445872856], Action prob: [0.5397047 0.4602953], Action: 0, state: 0\n",
      "Sensor: [0.3046965918921274, 0.629934313209604, 0.2362688385171051, 0.19405538086405297], Action prob: [0.5323862  0.46761388], Action: 0, state: 0\n",
      "Sensor: [0.33398479986490787, 0.6164479854195088, 0.20146189249910024, 0.26696320321160055], Action prob: [0.528421   0.47157905], Action: 0, state: 0\n",
      "Sensor: [0.39745220869887554, 0.6667154902303993, 0.18938369801471788, 0.22768364884576392], Action prob: [0.52641857 0.47358146], Action: 0, state: 0\n",
      "Sensor: [0.3837063188107911, 0.6491071905054779, 0.2261782511955369, 0.262632712363068], Action prob: [0.5255492  0.47445083], Action: 0, state: 0\n",
      "Sensor: [0.42445657035710116, 0.587942154099043, 0.2434548585354399, 0.20840693306571192], Action prob: [0.5255061  0.47449398], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35677904590950377, 0.6089585312289455, 0.26463194681686725, 0.28542874543599145], Action prob: [0.52574617 0.4742538 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35568508463552045, 0.6500877325605352, 0.25604486616959804, 0.21792258949354393], Action prob: [0.5261273  0.47387275], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3137507198241427, 0.6716629017809355, 0.20878543746830308, 0.29514863819121756], Action prob: [0.52624017 0.4737598 ], Action: 0, state: 0\n",
      "Sensor: [0.41170297111459514, 0.7034780797500277, 0.23740696426090147, 0.5901920929034882], Action prob: [0.5261921  0.47380778], Action: 0, state: 0\n",
      "Sensor: [0.3501236338776034, 0.6734486557076462, 0.2060896568876868, 0.25207089100971836], Action prob: [0.52610934 0.47389066], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.34803023803902405, 0.6217728278530213, 0.25263547924430574, 0.2233930536509372], Action prob: [0.5261915  0.47380844], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.32134594067195454, 0.5799673840462662, 0.20108176144305892, 0.25536908900213146], Action prob: [0.5262365 0.4737635], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.31136256406041596, 0.6248507635232075, 0.22059492634428776, 0.5082455445713022], Action prob: [0.5262526  0.47374743], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "tensor([-1.5580, -1.0348, -0.7700, -0.5256, -0.2933, -0.0794,  0.1149,  0.3365,\n",
      "         0.4278,  0.5105,  0.5026,  0.6174,  0.8262,  0.7723,  0.7242,  0.7677],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 4 is 8400, loss is -0.08368534354101709\n",
      "Sensor: [0.3165586758807595, 0.6513424033266841, 0.26255570929092115, 0.24869853337483333], Action prob: [0.55659515 0.44340482], Action: 0, state: 0\n",
      "Sensor: [0.3289268009370194, 0.5919468023717939, 0.17981930612906244, 0.2959404949050772], Action prob: [0.5598911  0.44010893], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35482289586417604, 0.6513803380579765, 0.1786542732388527, 0.2769410892787365], Action prob: [0.5599697  0.44003028], Action: 0, state: 0\n",
      "Sensor: [0.36569560273204793, 0.69134103095798, 0.2192977646926089, 0.29274438980066775], Action prob: [0.5590973 0.4409027], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3544798917540089, 0.6478481225818027, 0.5435800893962875, 0.30762380609243495], Action prob: [0.5591791  0.44082093], Action: 0, state: 0\n",
      "Sensor: [0.37164441672895904, 0.6145272257816099, 0.1877271981700671, 0.2607894727995983], Action prob: [0.5588499 0.4411502], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3559761156911117, 0.6510431781327375, 0.2131432315595336, 0.24969701588934287], Action prob: [0.5589703  0.44102967], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3422820852234168, 0.6651957239202018, 0.22960589351275232, 0.26917393274364787], Action prob: [0.5592245 0.4407755], Action: 0, state: 0\n",
      "Sensor: [0.355757664285821, 0.682846454120297, 0.19035209591254038, 0.22009743685158187], Action prob: [0.5594072  0.44059289], Action: 0, state: 1\n",
      "Sensor: [0.4040917955359155, 0.6370585803544965, 0.21596473245798362, 0.2729532132744593], Action prob: [0.559649   0.44035107], Action: 0, state: 1\n",
      "Sensor: [0.3532614884020281, 0.6361991234420054, 0.22911972385726362, 0.2504923613130456], Action prob: [0.55969524 0.44030476], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3672312974302493, 0.6547407413511113, 0.18876639261749695, 0.31032394742190633], Action prob: [0.5597557  0.44024432], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3575629822341862, 0.7020421290938638, 0.2240292638313506, 0.26487267192564745], Action prob: [0.55981684 0.4401831 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35050143625163355, 0.6487794546669565, 0.1769599689833453, 0.23987904839744034], Action prob: [0.55966324 0.44033676], Action: 0, state: 0\n",
      "Sensor: [0.419896979933074, 0.634017519150796, 0.16279098171150788, 0.31289391285184226], Action prob: [0.55972254 0.44027743], Action: 0, state: 0\n",
      "Sensor: [0.3967536877807594, 0.6287594947934089, 0.20234127890383571, 0.33903190609921263], Action prob: [0.55978525 0.44021478], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-1.2699, -1.1794, -0.6221, -0.3416, -0.4154, -0.1473, -0.1478,  0.0200,\n",
      "         0.2227,  0.4049,  0.8038,  0.8041,  0.6994,  0.5615,  0.6812,  1.1150],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 5 is 8600, loss is -0.07431208171772548\n",
      "Sensor: [0.4096902318346158, 0.6127364696795713, 0.19837070746572413, 0.2617068230804714], Action prob: [0.5710887 0.4289114], Action: 0, state: 0\n",
      "Sensor: [0.3372980632514725, 0.6547580360147108, 0.5026822464968301, 0.6144593572160866], Action prob: [0.57918936 0.42081067], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3669930547601485, 0.6371775727358575, 0.1758260739819787, 0.2498644562520688], Action prob: [0.5827357 0.4172643], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.361068043575506, 0.6637880061778788, 0.21419805417946025, 0.22848497812078628], Action prob: [0.58532375 0.4146763 ], Action: 0, state: 0\n",
      "Sensor: [0.3283787165658377, 0.6228029780071611, 0.20875322694612716, 0.3004171334527166], Action prob: [0.58716786 0.41283217], Action: 0, state: 0\n",
      "Sensor: [0.40528486569541644, 0.6403306581315333, 0.22846980235133724, 0.22855784334470908], Action prob: [0.58829284 0.4117072 ], Action: 0, state: 1\n",
      "Sensor: [0.3449087456963966, 0.6662026836768481, 0.22571590522806056, 0.26462837594483474], Action prob: [0.58887196 0.41112807], Action: 0, state: 1\n",
      "Sensor: [0.3509077269277913, 0.6749025205873893, 0.19764861766416453, 0.24225448010165296], Action prob: [0.5891842  0.41081578], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.3069627183961136, 0.6468919911482154, 0.20974193240166927, 0.26467358392187973], Action prob: [0.5893003  0.41069978], Action: 0, state: 1\n",
      "Sensor: [0.4117553640301475, 0.6720274584491166, 0.23512132152798323, 0.3245958627497052], Action prob: [0.58980155 0.4101985 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3575330414586573, 0.6176031452649353, 0.16561209373818458, 0.24481600514778723], Action prob: [0.58970547 0.41029453], Action: 0, state: 0\n",
      "Sensor: [0.30417658960224564, 0.6107038834742106, 0.2340437160985772, 0.2631449790060798], Action prob: [0.5895673  0.41043267], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3414357769039602, 0.6494255621840228, 0.21329378491909384, 0.27074640152734225], Action prob: [0.58961165 0.41038832], Action: 0, state: 0\n",
      "Sensor: [0.3864694132410596, 0.641324688814948, 0.22341986132482455, 0.19426534214871835], Action prob: [0.58961827 0.41038176], Action: 0, state: 1\n",
      "Sensor: [0.363355368508101, 0.6334993609557853, 0.17714097376713434, 0.2393606061118124], Action prob: [0.58959085 0.4104091 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.38319892818850637, 0.614687188972862, 0.2052985477692116, 0.503117819858405], Action prob: [0.5901678 0.4098321], Action: 0, state: 0\n",
      "Sensor: [0.3608491245717551, 0.6359766493096854, 0.22354015220929274, 0.24173185673974626], Action prob: [0.58999693 0.4100031 ], Action: 0, state: 0\n",
      "Sensor: [0.32166124793822415, 0.6506856782041835, 0.21292425340409452, 0.2203141055051764], Action prob: [0.5897347  0.41026533], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3384272869759003, 0.7075183212548803, 0.2119891975055282, 0.23827882496646122], Action prob: [0.5897478  0.41025224], Action: 0, state: 0\n",
      "Sensor: [0.38742622377177893, 0.6711788498355453, 0.21393924360806857, 0.24553275285844645], Action prob: [0.58989173 0.41010824], Action: 0, state: 0\n",
      "Sensor: [0.4191792699909152, 0.647858177070332, 0.21832047414778583, 0.2737050010764185], Action prob: [0.5900725  0.40992743], Action: 0, state: 0\n",
      "tensor([-1.1522, -1.3195, -1.3300, -0.6992, -0.4871, -0.3177, -0.1667, -0.0774,\n",
      "         0.0081,  0.1985,  0.1728,  0.4404,  0.3056,  0.3776,  0.7459,  0.4741,\n",
      "         0.5322,  0.9868,  0.5846,  0.6270,  0.6650], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 6 is 15500, loss is -0.02709431543871615\n",
      "Sensor: [0.39371766602035857, 0.6121861746595452, 0.19815457470027734, 0.22149785397911284], Action prob: [0.5782631  0.42173696], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3392140687285006, 0.6384685278138683, 0.20189464026856316, 0.2489599313873942], Action prob: [0.58514994 0.4148501 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3714039256342619, 0.6885986370425078, 0.14699766177427043, 0.27594131085061313], Action prob: [0.5900021  0.40999788], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.2959592515780852, 0.658981821563557, 0.23191309452732828, 0.25453724029564045], Action prob: [0.5928993 0.4071007], Action: 0, state: 0\n",
      "Sensor: [0.376940177335825, 0.6139451866516773, 0.17353853199991454, 0.25481472151761214], Action prob: [0.5946445  0.40535548], Action: 0, state: 0\n",
      "Sensor: [0.3510655728343311, 0.5604902653279471, 0.16453169329888642, 0.20922916732317365], Action prob: [0.59524477 0.40475526], Action: 0, state: 0\n",
      "Sensor: [0.3394061553451931, 0.6335980839761409, 0.2054226245153998, 0.26629769204179193], Action prob: [0.5956603  0.40433973], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3137526541959478, 0.6302777121495522, 0.22976658954789037, 0.22463995930523217], Action prob: [0.59575474 0.40424526], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.40818910210948167, 0.6834834440561524, 0.2226560644951142, 0.29196394539782694], Action prob: [0.5963282 0.4036719], Action: 0, state: 0\n",
      "Sensor: [0.36226049068283195, 0.6432136931727878, 0.2219179397720937, 0.2813840450061223], Action prob: [0.5965306 0.4034694], Action: 0, state: 0\n",
      "Sensor: [0.3853489145033908, 0.6409588553282793, 0.22145856445352766, 0.2749625249996977], Action prob: [0.5967068  0.40329322], Action: 0, state: 1\n",
      "Sensor: [0.34336968866310585, 0.4961261708458789, 0.1980928689050635, 0.1999737798902981], Action prob: [0.59624815 0.40375182], Action: 0, state: 2\n",
      "Sensor: [0.34252703118283534, 0.6885090835135537, 0.23550366287251537, 0.2540316053553983], Action prob: [0.59636724 0.40363273], Action: 0, state: 2\n",
      "Sensor: [0.3666473130910742, 0.613911003052326, 0.2671346222327385, 0.2789642557786186], Action prob: [0.59652585 0.40347418], Action: 0, state: 2\n",
      "Sensor: [0.33576475349227286, 0.6014134624479789, 0.21557551782341872, 0.25964206697744524], Action prob: [0.5964379  0.40356207], Action: 0, state: 2\n",
      "Sensor: [0.32480525325041115, 0.6280169259381247, 0.21495745492748702, 0.21630095499487886], Action prob: [0.59632444 0.40367553], Action: 0, state: 2\n",
      "Sensor: [0.5640538699533518, 0.6143212535432688, 0.21624680357236986, 0.2645687633385756], Action prob: [0.5969591  0.40304092], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.32649404329190096, 0.6601439098493201, 0.2600848054914518, 0.2239598198236582], Action prob: [0.5967152  0.40328485], Action: 0, state: 2\n",
      "Sensor: [0.5513105515684877, 0.5670269392269062, 0.44827240233448956, 0.24905847006112256], Action prob: [0.59709126 0.40290874], Action: 0, state: 3\n",
      "Sensor: [0.3503734536828573, 0.6260949560815675, 0.23878467408332682, 0.21914253174581863], Action prob: [0.5967283  0.40327168], Action: 0, state: 3\n",
      "Sensor: [0.3924505636526203, 0.6869283893237741, 0.5001701779900701, 0.2709012622725635], Action prob: [0.5969247  0.40307528], Action: 0, state: 3\n",
      "Sensor: [0.3948695094361923, 0.5718045652308085, 0.22038897758354714, 0.22283015444922902], Action prob: [0.59680265 0.40319738], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -2200\n",
      "tensor([-1.6826, -1.4796, -1.2845, -0.7534, -0.5456, -0.3620, -0.3466, -0.2180,\n",
      "        -0.0583,  0.0610,  0.1574,  0.2356,  0.3039,  0.3665,  0.4231,  0.4738,\n",
      "         0.8840,  0.5167,  0.5393,  0.5608,  0.5777,  1.0498],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 7 is 11500, loss is 0.026415150501201145\n",
      "Sensor: [0.2995672820030884, 0.6372801308550832, 0.21036307749325417, 0.312834924878954], Action prob: [0.5719568  0.42804316], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.34757579025726054, 0.608858747437403, 0.24223226638526824, 0.23485020701857204], Action prob: [0.5754294  0.42457062], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3378197125266209, 0.6727595693905207, 0.23810839970984266, 0.292792514088326], Action prob: [0.577439   0.42256102], Action: 0, state: 0\n",
      "Sensor: [0.34843370275995056, 0.614883789396552, 0.21302506887686812, 0.21521299182455048], Action prob: [0.57822204 0.42177802], Action: 0, state: 1\n",
      "Sensor: [0.353277871462614, 0.42454553243093446, 0.23971967538140637, 0.2423075191499875], Action prob: [0.5780862  0.42191383], Action: 0, state: 2\n",
      "Sensor: [0.3730725405985294, 0.6411138491804967, 0.21824800449124687, 0.19292788770698494], Action prob: [0.57792574 0.4220743 ], Action: 0, state: 3\n",
      "Sensor: [0.37827340367772044, 0.6369115391747517, 0.19585820150625544, 0.23807592408922174], Action prob: [0.5779039 0.4220961], Action: 0, state: 3\n",
      "Sensor: [0.3440673568175439, 0.6804799968778654, 0.22168263255508713, 0.22585547235410308], Action prob: [0.5778212  0.42217886], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.44542351806087055, 0.6758460557942513, 0.18912403313374881, 0.27522966810466437], Action prob: [0.57808095 0.42191902], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "Sensor: [0.3436089257341381, 0.634986831342602, 0.22477842977334025, 0.26438530231837426], Action prob: [0.577958   0.42204198], Action: 0, state: 1\n",
      "Sensor: [0.3412660487294627, 0.6124492521434751, 0.20954423279231954, 0.21503955254575416], Action prob: [0.5777871 0.4222129], Action: 0, state: 2\n",
      "Sensor: [0.3750512750185657, 0.6387908185920961, 0.17818483656334688, 0.2600183406633304], Action prob: [0.57789546 0.42210457], Action: 0, state: 2\n",
      "Sensor: [0.34268756100149705, 0.6656197958535717, 0.21713286189889774, 0.24969811638561984], Action prob: [0.5778757  0.42212433], Action: 0, state: 2\n",
      "Sensor: [0.3680732135920626, 0.6369957509430844, 0.22069585402531952, 0.280795164130737], Action prob: [0.5779287 0.4220713], Action: 0, state: 2\n",
      "Sensor: [0.44165746530070105, 0.6127556597804018, 0.2311435897513445, 0.16557841907812154], Action prob: [0.5777921  0.42220783], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.32215830478893714, 0.6305752132418926, 0.22416402747727937, 0.2627298653095417], Action prob: [0.5777251  0.42227492], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "Sensor: [0.3664885531365649, 0.6265494993157549, 0.18836747441875526, 0.22777252939046866], Action prob: [0.5777647  0.42223534], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3918228377027075, 0.6322534527005036, 0.2463910791121607, 0.311976113282131], Action prob: [0.5779107 0.4220893], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.8541, -1.5415, -0.7981, -0.4878, -0.2405, -0.1033,  0.0216,  0.2099,\n",
      "         0.3062,  0.0852,  0.2165,  0.3344,  0.4401,  0.5357,  0.9275,  0.9723,\n",
      "         0.8908,  0.8907], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 8 is 7300, loss is -0.044753893792334604\n",
      "Sensor: [0.37561709527745024, 0.6232262149996265, 0.22306379730640957, 0.23356436309078976], Action prob: [0.56944907 0.43055093], Action: 0, state: 0\n",
      "Sensor: [0.3223378802779794, 0.6149722031372946, 0.21256177761846146, 0.300222667020801], Action prob: [0.57231504 0.42768496], Action: 0, state: 0\n",
      "Sensor: [0.2945837921983167, 0.6118223689164662, 0.21829417862194453, 0.21560155537792852], Action prob: [0.5738529  0.42614707], Action: 0, state: 0\n",
      "Sensor: [0.3447641174785382, 0.680002200202769, 0.20287169897470197, 0.26047740009405074], Action prob: [0.57483983 0.4251602 ], Action: 0, state: 0\n",
      "Sensor: [0.3664710059023331, 0.6444537602073331, 0.21538372864817032, 0.2885589314069923], Action prob: [0.5751658  0.42483416], Action: 0, state: 0\n",
      "Sensor: [0.3655821275076928, 0.5815747525792863, 0.23228269485836206, 0.21539502777755146], Action prob: [0.5750083 0.4249917], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.35884522818183, 0.6524835485584748, 0.19678357901070961, 0.2179061556541342], Action prob: [0.5748368 0.4251632], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "Sensor: [0.3697725777280721, 0.663717296113249, 0.1919421378329026, 0.1981223019205183], Action prob: [0.5747917 0.4252083], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.331380267254862, 0.6663301196812089, 0.2515567648545769, 0.23365343382545778], Action prob: [0.57471085 0.42528915], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3318102832103055, 0.635250665399439, 0.24061190689039857, 0.26405194533276655], Action prob: [0.5746855 0.4253145], Action: 1, state: 0\n",
      "Sensor: [0.3726291804016618, 0.6238793238216654, 0.5383574109385958, 0.2395129710817715], Action prob: [0.5742025  0.42579758], Action: 0, state: 9\n",
      "Sensor: [0.3756330531678888, 0.6626212757190003, 0.23527882290493057, 0.5452268369916426], Action prob: [0.5746979  0.42530212], Action: 0, state: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.29076997472177846, 0.617589148875139, 0.5314019059289486, 0.2548338947571642], Action prob: [0.5740596  0.42594033], Action: 0, state: 9\n",
      "Sensor: [0.3324398994716298, 0.39456197334504034, 0.2512250274184526, 0.2643206116506308], Action prob: [0.5739033  0.42609668], Action: 0, state: 9\n",
      "Sensor: [0.33820632071407764, 0.6368974043012928, 0.5192123134825947, 0.27481102620879244], Action prob: [0.57378143 0.42621854], Action: 1, state: 9\n",
      "Sensor: [0.34202013820331134, 0.663358210978005, 0.22266971996360613, 0.3323758441093241], Action prob: [0.5743027 0.4256974], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.2378, -0.6882, -0.2025,  0.2306,  0.6197,  1.5011,  1.2563,  0.5982,\n",
      "         0.4000,  0.5780,  0.1663, -0.0191, -0.1886, -0.3370, -0.7314, -0.5419],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 9 is -1000, loss is -0.0877314081971096\n",
      "Sensor: [0.3691273354962358, 0.6651912686242352, 0.20031081615762505, 0.27109318316509], Action prob: [0.5761111 0.4238889], Action: 0, state: 0\n",
      "Sensor: [0.4026952104991753, 0.6621062375708988, 0.19352656464933474, 0.2530229522671644], Action prob: [0.58073294 0.41926706], Action: 0, state: 1\n",
      "Sensor: [0.43216127031782736, 0.6113256801755367, 0.20893790618103528, 0.22589712065965173], Action prob: [0.58367217 0.4163278 ], Action: 0, state: 1\n",
      "Sensor: [0.34382100202101534, 0.6053742621126664, 0.2276073969000818, 0.2382919355709971], Action prob: [0.5850995 0.4149005], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.34834565264832834, 0.6594605054958551, 0.11903110596693434, 0.2193290568268355], Action prob: [0.5859763  0.41402373], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3707828724441443, 0.6486120127969327, 0.1733168658263516, 0.2532875849636071], Action prob: [0.5864452 0.4135548], Action: 0, state: 0\n",
      "Sensor: [0.3407342035180657, 0.682155182747557, 0.22358820746606614, 0.24824933775324], Action prob: [0.5865641  0.41343597], Action: 0, state: 0\n",
      "Sensor: [0.39713579840781893, 0.641351510518819, 0.2307363397559435, 0.2503668047715546], Action prob: [0.5866326  0.41336745], Action: 0, state: 0\n",
      "Sensor: [0.42445669252118434, 0.6314660317771742, 0.22935663800621375, 0.2412122536014684], Action prob: [0.5866351  0.41336492], Action: 0, state: 0\n",
      "Sensor: [0.32509780378151587, 0.6242662360733077, 0.2140404146296762, 0.3122035545839647], Action prob: [0.5865424 0.4134575], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.359025803823138, 0.6621277295779496, 0.19290427036291108, 0.2635187885078037], Action prob: [0.5865842  0.41341585], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.40436827845715073, 0.6362125400879006, 0.21111422919975556, 0.25768478110263376], Action prob: [0.58667874 0.41332123], Action: 0, state: 0\n",
      "Sensor: [0.3509573245287914, 0.6603488915667229, 0.21882163294154172, 0.28625833498446723], Action prob: [0.5866886 0.4133114], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.4117888577833932, 0.6343123637732392, 0.2180688291828982, 0.281207812151035], Action prob: [0.58676845 0.41323152], Action: 0, state: 0\n",
      "Sensor: [0.3525805692872221, 0.6864759734099849, 0.2303658321306128, 0.23084432443069308], Action prob: [0.58665055 0.41334942], Action: 0, state: 0\n",
      "tensor([-1.2496, -0.7587, -0.3298,  0.0803, -0.5403, -0.4964, -0.1923,  0.0820,\n",
      "         0.3287,  0.9114,  0.5807,  0.4406,  0.9706,  0.5132,  0.6439],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 10 is 7100, loss is -0.06562028959262185\n",
      "Sensor: [0.3913355485092808, 0.6788076715188709, 0.23716066376519168, 0.22644059892805538], Action prob: [0.58774525 0.4122548 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3610067865215123, 0.616918481629364, 0.19218481590791617, 0.27284071497353096], Action prob: [0.59481996 0.40518007], Action: 0, state: 0\n",
      "Sensor: [0.33476340264844856, 0.6684954277513991, 0.18397939124675097, 0.23320222581319727], Action prob: [0.59944814 0.40055192], Action: 0, state: 0\n",
      "Sensor: [0.3868224940499639, 0.6894863005349425, 0.2250023397533421, 0.22990582529875775], Action prob: [0.6024835 0.3975165], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3663414771238907, 0.7285718952093932, 0.21901075610481935, 0.2867456773590798], Action prob: [0.6043367  0.39566332], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -2000\n",
      "Sensor: [0.34102077783905343, 0.6264384883014877, 0.2313648718607249, 0.5882686250607508], Action prob: [0.6055648 0.3944352], Action: 0, state: 0\n",
      "Sensor: [0.3166141417884015, 0.6279629266011205, 0.20823771583204573, 0.23394454979065257], Action prob: [0.60534245 0.39465758], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.37484918553962454, 0.5908406263574518, 0.20948755613793732, 0.23383373460010953], Action prob: [0.6051983  0.39480165], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3253816813830912, 0.5842515992709529, 0.19494113239432026, 0.29895375859859935], Action prob: [0.60507697 0.39492306], Action: 0, state: 0\n",
      "Sensor: [0.34163486062429155, 0.6478941786777047, 0.175710759503425, 0.263633661749228], Action prob: [0.60519975 0.39480022], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3121440068449632, 0.653236461335309, 0.18958981728466195, 0.280268454535622], Action prob: [0.60527945 0.39472055], Action: 0, state: 0\n",
      "Sensor: [0.3591094454713459, 0.6266796224898518, 0.24292199438307904, 0.25615443409053423], Action prob: [0.60528153 0.39471844], Action: 0, state: 1\n",
      "Sensor: [0.363170313184651, 0.6665045879216375, 0.23263462348746777, 0.20058450706724132], Action prob: [0.60524404 0.39475596], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.9037, -0.6961,  0.0575,  1.3097,  1.3157, -0.3504,  0.2372, -0.1608,\n",
      "        -0.2810,  0.1256,  0.0677,  0.3221,  1.0198], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 11 is 3300, loss is -0.0818016878725362\n",
      "Sensor: [0.4103362475182317, 0.6275971662434707, 0.19615513740642532, 0.2756053997466716], Action prob: [0.60576016 0.39423978], Action: 0, state: 0\n",
      "Sensor: [0.3423816211826762, 0.6454313561527036, 0.2277993697568408, 0.28564249908553807], Action prob: [0.61872876 0.3812713 ], Action: 0, state: 1\n",
      "Sensor: [0.3900619618996361, 0.6451961554765392, 0.1823994502047653, 0.27873469497596653], Action prob: [0.6282924  0.37170765], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.32727365381759954, 0.6500798284158776, 0.18868528761400893, 0.26479742511645177], Action prob: [0.63424087 0.36575913], Action: 0, state: 0\n",
      "Sensor: [0.3516142049412764, 0.6083698447205228, 0.18665402292353198, 0.265745031279919], Action prob: [0.63780373 0.36219624], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.36840799319188294, 0.6568450317659356, 0.18560163266441712, 0.2559620792520618], Action prob: [0.6400807 0.3599193], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3201005754708686, 0.6278839440838043, 0.23093046240745999, 0.2712972808950241], Action prob: [0.64107364 0.3589263 ], Action: 0, state: 0\n",
      "Sensor: [0.3890684258796975, 0.6562291438629317, 0.2307154243817177, 0.5703564663073305], Action prob: [0.64282775 0.35717222], Action: 0, state: 0\n",
      "Sensor: [0.38138940626160217, 0.6854072402596456, 0.1981484554397679, 0.2764695268089799], Action prob: [0.6432462  0.35675383], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.34660690043934883, 0.6382751733046927, 0.2454665046192649, 0.28988702394169236], Action prob: [0.64310926 0.35689068], Action: 0, state: 0\n",
      "Sensor: [0.38022256364332113, 0.6768074188128735, 0.19090161909919684, 0.3099840903559902], Action prob: [0.64336574 0.35663423], Action: 0, state: 0\n",
      "Sensor: [0.3666913766776337, 0.6749608233555988, 0.17942257261637687, 0.2664237621833359], Action prob: [0.64336985 0.35663015], Action: 0, state: 0\n",
      "Sensor: [0.3839414414600527, 0.5935419140971417, 0.26845585352077367, 0.23704711236002574], Action prob: [0.64288294 0.35711706], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.3835847398143699, 0.6688938878810025, 0.18780315888930948, 0.21353286552554676], Action prob: [0.64279866 0.35720134], Action: 0, state: 0\n",
      "Sensor: [0.35150611123887127, 0.6437815447541229, 0.21350467756309385, 0.5362574292959171], Action prob: [0.64350736 0.35649267], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3654657226208531, 0.6425921634605964, 0.20447924151407307, 0.4502555822627996], Action prob: [0.6438082 0.3561918], Action: 0, state: 0\n",
      "Sensor: [0.35049714861922454, 0.6354717091956364, 0.18332467765517346, 0.23503847888430163], Action prob: [0.64329135 0.35670865], Action: 0, state: 0\n",
      "Sensor: [0.300667994824638, 0.646043653330271, 0.22546088129418596, 0.22587294263668625], Action prob: [0.64262944 0.35737053], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.1129, -0.8155, -1.2152, -0.4522, -0.5782, -0.3879, -0.1689, -0.0317,\n",
      "         0.2122,  0.1461,  0.2451,  0.3344,  0.9688,  0.3432,  0.9529,  0.4362,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0.4899,  1.2525], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 12 is 11800, loss is -0.03438448407320771\n",
      "Sensor: [0.3736894515206817, 0.5815209009434833, 0.17650797131517731, 0.26666892744190607], Action prob: [0.62644047 0.37355953], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.341313537109762, 0.6293313073829944, 0.19118824737926443, 0.2690044283995581], Action prob: [0.64709556 0.3529044 ], Action: 0, state: 0\n",
      "Sensor: [0.3249083659234877, 0.6355872104611238, 0.21006032766197424, 0.3108605114029881], Action prob: [0.66304016 0.3369598 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3614910022913233, 0.6820621066895192, 0.2382936131033507, 0.21697178795034328], Action prob: [0.674343   0.32565704], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.4161950200631137, 0.6412703794563245, 0.21336295435997715, 0.2344895561155416], Action prob: [0.6820878  0.31791222], Action: 0, state: 0\n",
      "Sensor: [0.3736543593675016, 0.6423037431451109, 0.23322081583254187, 0.22345201352918237], Action prob: [0.6867066  0.31329343], Action: 0, state: 1\n",
      "Sensor: [0.3670650553941937, 0.653750750814685, 0.2139947427779618, 0.3062565882657577], Action prob: [0.6898464 0.3101536], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3475394188532616, 0.6193026201134757, 0.26748171671739895, 0.2811056553189805], Action prob: [0.69135725 0.30864275], Action: 0, state: 0\n",
      "Sensor: [0.3872023839103382, 0.6860726104048351, 0.22964192557126206, 0.2515551570843392], Action prob: [0.6926084  0.30739158], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3008606212890247, 0.5619394914995989, 0.2082180021533331, 0.275191185209615], Action prob: [0.6924563 0.3075437], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.34435326754510165, 0.6773814120725038, 0.20752412548213858, 0.24282472622785656], Action prob: [0.6927676  0.30723238], Action: 0, state: 0\n",
      "Sensor: [0.3725949460758824, 0.6410180218469665, 0.18428491670306862, 0.2146662103343876], Action prob: [0.6928919 0.3071081], Action: 0, state: 0\n",
      "Sensor: [0.32699134685571635, 0.6818459943264629, 0.21461036782107823, 0.28135976551896597], Action prob: [0.69318235 0.30681762], Action: 0, state: 1\n",
      "Sensor: [0.3440733895152321, 0.6318377523788421, 0.23998797572843208, 0.2749840446030977], Action prob: [0.69330126 0.3066988 ], Action: 0, state: 2\n",
      "Sensor: [0.37906424687393236, 0.6995496571015994, 0.18149128631122483, 0.269693137967302], Action prob: [0.6937787 0.3062213], Action: 0, state: 2\n",
      "Sensor: [0.40542681073577735, 0.6407691403218636, 0.227779840838155, 0.2870486547157082], Action prob: [0.69414836 0.30585164], Action: 0, state: 2\n",
      "Sensor: [0.3870395103973546, 0.653513282055525, 0.1718619642030424, 0.26275715815281747], Action prob: [0.6941463  0.30585372], Action: 0, state: 3\n",
      "Sensor: [0.5526430597799362, 0.3816340060180103, 0.23649720874409463, 0.2926952095481872], Action prob: [0.69370866 0.30629137], Action: 0, state: 8\n",
      "Sensor: [0.40107051497602564, 0.38981923169168153, 0.23093222233606794, 0.28196152823940596], Action prob: [0.69208914 0.3079109 ], Action: 0, state: 8\n",
      "tensor([-1.8601, -0.8227, -1.3039, -0.9963, -0.4466, -0.2682, -0.3573, -0.0373,\n",
      "         0.3141,  0.5112,  0.1039,  0.2025,  0.2814,  0.3451,  0.4015,  0.4525,\n",
      "         0.4815,  0.3277,  0.1879], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 13 is 100, loss is 0.130699862451052\n",
      "Sensor: [0.3854662660878494, 0.6131041854477243, 0.19312657596957772, 0.2787643466943178], Action prob: [0.6310595  0.36894047], Action: 0, state: 0\n",
      "Sensor: [0.38622286931171435, 0.6883529410383519, 0.26216811171812526, 0.2711369041940173], Action prob: [0.65120053 0.3487995 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3690572497984585, 0.6170022193094602, 0.19802896987684684, 0.49109505256292685], Action prob: [0.6656013  0.33439872], Action: 0, state: 0\n",
      "Sensor: [0.39980393474379256, 0.6664999164033015, 0.250726233719511, 0.2751989912819107], Action prob: [0.67454755 0.32545245], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.38975140894158516, 0.6101863980317155, 0.22544765728814922, 0.2640273334442238], Action prob: [0.6791972 0.3208028], Action: 0, state: 0\n",
      "Sensor: [0.3244229433419644, 0.6375900214702167, 0.22198259036850918, 0.2526722054641144], Action prob: [0.6811772  0.31882277], Action: 0, state: 0\n",
      "Sensor: [0.355306110904734, 0.6038789458180736, 0.22200324079552877, 0.4400889519451799], Action prob: [0.68303883 0.31696123], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.5222728043968844, 0.5878037086408652, 0.2145978439719572, 0.8355241184421982], Action prob: [0.68626654 0.31373346], Action: 0, state: 0\n",
      "Sensor: [0.3727638891676015, 0.6582424514454327, 0.17801011097993136, 0.5779675010826912], Action prob: [0.68693566 0.31306437], Action: 0, state: 0\n",
      "Sensor: [0.32336218239870496, 0.5609464750323022, 0.1808031178581194, 0.27614837401931175], Action prob: [0.68543893 0.31456107], Action: 0, state: 0\n",
      "Sensor: [0.3112102939884048, 0.6596247365693553, 0.23578732370435107, 0.5529294858138791], Action prob: [0.68571275 0.31428722], Action: 0, state: 0\n",
      "Sensor: [0.29722553241260125, 0.5978572403351883, 0.20827676887650357, 0.2627170924259038], Action prob: [0.68444777 0.3155523 ], Action: 0, state: 1\n",
      "Sensor: [0.357599540778105, 0.6374488302654691, 0.23993696215627325, 0.240756108325583], Action prob: [0.68381524 0.3161847 ], Action: 0, state: 1\n",
      "Sensor: [0.3374757394930466, 0.5870702667708113, 0.2473596685978414, 0.2724682804446343], Action prob: [0.6832023 0.3167977], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.40082391515545024, 0.6591789763991882, 0.22728661839799, 0.2208042077631437], Action prob: [0.68318826 0.31681165], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.37487482881340456, 0.6428526380759322, 0.2470295088551233, 0.19925791833123513], Action prob: [0.6829454  0.31705463], Action: 0, state: 0\n",
      "Sensor: [0.33981102009805736, 0.63188389880463, 0.22658751294092327, 0.2366781804148208], Action prob: [0.6827042  0.31729576], Action: 0, state: 1\n",
      "Sensor: [0.3715114637352643, 0.6408932934308059, 0.26034455222114616, 0.27024240979020864], Action prob: [0.6829779  0.31702203], Action: 0, state: 1\n",
      "Sensor: [0.4305573089749305, 0.5884727228135869, 0.18151959761505873, 0.24138329462102306], Action prob: [0.6830498  0.31695023], Action: 0, state: 1\n",
      "Sensor: [0.3763653218007562, 0.5505219429290998, 0.1997031070815351, 0.23172791125481568], Action prob: [0.6824275  0.31757247], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "tensor([-1.0105, -1.8276, -0.6117, -1.2212, -0.3480, -0.2163, -0.2987, -0.0979,\n",
      "        -0.0057,  0.0785,  0.1524,  0.2149,  0.2703,  0.9681,  0.8923,  0.3184,\n",
      "         0.3551,  0.3872,  0.4172,  1.3265], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 14 is 14000, loss is 0.012830753770697756\n",
      "Sensor: [0.3497309247838881, 0.6319869266171451, 0.20634240078062677, 0.3627570880487003], Action prob: [0.63393754 0.36606243], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3539779360873445, 0.6544632003460721, 0.20664882193764453, 0.24013442245610964], Action prob: [0.6513068  0.34869316], Action: 0, state: 0\n",
      "Sensor: [0.3324571010374385, 0.6551940623425327, 0.1871254970819656, 0.27329796042112464], Action prob: [0.66247123 0.33752882], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.37231479613163193, 0.6688815827547956, 0.17083098638394756, 0.2324741100617121], Action prob: [0.6690063 0.3309937], Action: 0, state: 0\n",
      "Sensor: [0.328778291496017, 0.6772285864812732, 0.20141246596831713, 0.22764665825857638], Action prob: [0.67210484 0.32789513], Action: 0, state: 0\n",
      "Sensor: [0.37994623615121914, 0.6543144391583475, 0.23108231459969694, 0.46829714228900754], Action prob: [0.6747158 0.3252842], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3479539789938214, 0.6119666830497987, 0.20094241419077227, 0.2410460852414162], Action prob: [0.67453814 0.3254619 ], Action: 0, state: 0\n",
      "Sensor: [0.35633750996953156, 0.6557618868698079, 0.193844495997964, 0.2478095252549309], Action prob: [0.6743205  0.32567948], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.34817353590401656, 0.583227943427688, 0.17442906584320872, 0.4015476262296075], Action prob: [0.6743994  0.32560056], Action: 0, state: 0\n",
      "Sensor: [0.30350709306969, 0.7003061983446048, 0.24729010040971103, 0.27939847196297884], Action prob: [0.6742914 0.3257086], Action: 0, state: 0\n",
      "Sensor: [0.3630055549769004, 0.619403343961613, 0.2133610259911412, 0.23132674303703646], Action prob: [0.67400897 0.32599103], Action: 0, state: 1\n",
      "Sensor: [0.3438390316294223, 0.646850990811171, 0.19707390329389132, 0.23078985311410774], Action prob: [0.67372525 0.32627478], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.34445512685970764, 0.6620692817517989, 0.1930075581630323, 0.23831905257012703], Action prob: [0.67366654 0.32633346], Action: 0, state: 0\n",
      "Sensor: [0.3187015851239607, 0.6445418354393738, 0.22828554615159155, 0.23676119045122432], Action prob: [0.67345697 0.32654303], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.32859979553637597, 0.6347347934712051, 0.23531189665140473, 0.31655513592200746], Action prob: [0.6736631  0.32633698], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3002964861362819, 0.579655603001774, 0.251413659464678, 0.2214060867621785], Action prob: [0.67297965 0.32702035], Action: 0, state: 0\n",
      "Sensor: [0.3542903766257285, 0.6466239706782102, 0.2296442668227243, 0.2448141339698174], Action prob: [0.6731693  0.32683066], Action: 0, state: 0\n",
      "tensor([-2.1282, -0.7796, -1.3888, -0.4164, -0.2383, -0.2321, -0.0808,  0.1263,\n",
      "         0.1013,  0.2019,  0.2854,  1.0204,  0.3226,  1.1033,  1.0186,  0.3606,\n",
      "         0.4089], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 15 is 10300, loss is 0.01851512512441681\n",
      "Sensor: [0.3396192590653112, 0.6690849747821599, 0.21614634612472255, 0.2144055614718612], Action prob: [0.6350559 0.3649441], Action: 0, state: 0\n",
      "Sensor: [0.34712353184164907, 0.6505938743221189, 0.23847719899145797, 0.247807676234631], Action prob: [0.6517344  0.34826553], Action: 0, state: 1\n",
      "Sensor: [0.3529641568953096, 0.6726212170162067, 0.2033603019575147, 0.24432453377812624], Action prob: [0.6623072  0.33769277], Action: 0, state: 2\n",
      "Sensor: [0.32253622801220466, 0.6204838142406655, 0.19391281642874852, 0.2560634874502825], Action prob: [0.66782886 0.3321711 ], Action: 0, state: 2\n",
      "Sensor: [0.38274433630404076, 0.4909146175715103, 0.19489838660976122, 0.2519552707043967], Action prob: [0.670027 0.329973], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "Sensor: [0.3359641027736081, 0.6622408389159079, 0.23189476245146787, 0.2364540908244016], Action prob: [0.67121303 0.328787  ], Action: 0, state: 1\n",
      "Sensor: [0.38967929725896705, 0.6470968829057197, 0.4286938687251693, 0.2446329323010538], Action prob: [0.67217726 0.32782274], Action: 0, state: 2\n",
      "Sensor: [0.35546609866569956, 0.6175864348096258, 0.2408213487738113, 0.22573738953175074], Action prob: [0.6720515 0.3279485], Action: 0, state: 2\n",
      "Sensor: [0.6137399535415408, 0.6247291044781547, 0.21625135867133052, 0.2582340629743755], Action prob: [0.6731124  0.32688758], Action: 0, state: 3\n",
      "Sensor: [0.5431796107637011, 0.5898152116015211, 0.21205608840298165, 0.23992391288803422], Action prob: [0.67315626 0.32684374], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.4188840399354158, 0.6488152776855707, 0.22647682425438348, 0.2844461725798249], Action prob: [0.67296726 0.32703272], Action: 0, state: 2\n",
      "Sensor: [0.3752847227206757, 0.62399990880837, 0.21925471014981418, 0.1968708292480108], Action prob: [0.67231125 0.3276888 ], Action: 0, state: 2\n",
      "Sensor: [0.554495127661393, 0.5764485685199358, 0.2070065764840641, 0.3325535109145725], Action prob: [0.6729267  0.32707325], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.38124378658177605, 0.6365666917376193, 0.20177755602425734, 0.2261626086346832], Action prob: [0.6723384  0.32766157], Action: 0, state: 1\n",
      "Sensor: [0.3763464871456042, 0.6475186388685313, 0.18910074676534072, 0.22112239788932722], Action prob: [0.6720333 0.3279667], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.36466487258091773, 0.5799778496038902, 0.20334657940395054, 0.2440240657125326], Action prob: [0.6715948 0.3284052], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.36765534203821126, 0.6642788717610617, 0.14556230787791846, 0.22344748487229762], Action prob: [0.6715575 0.3284425], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.29101059292357007, 0.6468643170760845, 0.2025439886537576, 0.5361845579651053], Action prob: [0.6723377  0.32766232], Action: 0, state: 0\n",
      "Sensor: [0.3914459156211895, 0.6783547527962592, 0.23035523689876014, 0.3422656728455744], Action prob: [0.6728576 0.3271424], Action: 0, state: 0\n",
      "Sensor: [0.36620009251588903, 0.6330990193095606, 0.22523441877531097, 0.19157275864778228], Action prob: [0.672239   0.32776096], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.1066, -0.7958, -0.5753, -0.3952, -0.6668, -0.2581, -0.1374, -0.0278,\n",
      "         0.0337,  0.2503,  0.1175,  0.1891,  0.7144,  0.2820,  0.9556,  0.8738,\n",
      "         0.3384,  0.3842,  0.4259,  1.2970], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 16 is 11900, loss is -0.09494185601641521\n",
      "Sensor: [0.2713729126959296, 0.6465099122391287, 0.19223658610713606, 0.2595097497678045], Action prob: [0.6456086  0.35439146], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.34464841490821285, 0.5854014159237163, 0.22150995115093394, 0.22849556552397343], Action prob: [0.66532093 0.33467904], Action: 0, state: 0\n",
      "Sensor: [0.4055205554101175, 0.6341288690805363, 0.1803736284233362, 0.266502083770348], Action prob: [0.6784862  0.32151386], Action: 0, state: 1\n",
      "Sensor: [0.35969337297250165, 0.6973986799844654, 0.18545358602855203, 0.2403006367611857], Action prob: [0.68608135 0.3139187 ], Action: 0, state: 1\n",
      "Sensor: [0.29631333620539074, 0.6185121919625008, 0.2247342187286428, 0.27056076211629143], Action prob: [0.6892481  0.31075191], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3010394291489262, 0.6237976324973062, 0.21887317126129066, 0.23241110076590668], Action prob: [0.6905325 0.3094675], Action: 0, state: 0\n",
      "Sensor: [0.3666679341710845, 0.6191935821239581, 0.17621132306667803, 0.1842795408752272], Action prob: [0.69106925 0.30893078], Action: 0, state: 0\n",
      "Sensor: [0.3666065136304934, 0.6438354778429853, 0.22851966892175776, 0.25530625693394593], Action prob: [0.69157416 0.3084258 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3557424487269858, 0.6570157754047904, 0.20074852456938805, 0.2498423448461007], Action prob: [0.69179004 0.30820996], Action: 0, state: 0\n",
      "Sensor: [0.2990938093609622, 0.6088912349454322, 0.16355090861532054, 0.2532920429696278], Action prob: [0.69121426 0.30878574], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.39839226260310895, 0.6208592175756698, 0.20931862975545906, 0.2380500671964271], Action prob: [0.6914592 0.3085408], Action: 0, state: 0\n",
      "Sensor: [0.36407357598088286, 0.6562678256201759, 0.1971725306377216, 0.24544646679570437], Action prob: [0.69164205 0.30835792], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.34766749379367523, 0.6254768358181413, 0.18515550857192478, 0.2855835739700549], Action prob: [0.691675 0.308325], Action: 0, state: 0\n",
      "Sensor: [0.3354138455092247, 0.6701479274888463, 0.2031377192560938, 0.2938566606783038], Action prob: [0.6918931  0.30810693], Action: 0, state: 0\n",
      "Sensor: [0.38040157642519223, 0.6949325026922692, 0.21336697123591883, 0.27025801126474136], Action prob: [0.6924442  0.30755576], Action: 0, state: 0\n",
      "Sensor: [0.3547653776096638, 0.5968971121282625, 0.189204426160451, 0.22359955690894695], Action prob: [0.69186866 0.30813137], Action: 0, state: 1\n",
      "Sensor: [0.36112732241464746, 0.6299735106004364, 0.24066242067630128, 0.26483620755048315], Action prob: [0.6917817 0.3082183], Action: 0, state: 2\n",
      "Sensor: [0.3591362463345961, 0.6335797558273977, 0.22575071253884568, 0.2216158154240647], Action prob: [0.6916201  0.30837983], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1100\n",
      "tensor([-1.7685, -0.8127, -0.5911, -0.4150, -0.8407, -0.1957, -0.0681,  0.1450,\n",
      "         0.0454,  0.4404,  0.1381,  0.6542,  0.2388,  0.2987,  0.3522,  0.3979,\n",
      "         0.4328,  1.4833], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 17 is 10500, loss is 0.003612456311717854\n",
      "Sensor: [0.3509604691759095, 0.6176427711068436, 0.19371585634521626, 0.28410108214261], Action prob: [0.6577082  0.34229174], Action: 0, state: 0\n",
      "Sensor: [0.3988780427651117, 0.598200020574221, 0.2444747913760889, 0.24378602647368247], Action prob: [0.68210566 0.31789434], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.2977228752247562, 0.6034232781425888, 0.2040278770257303, 0.20650130127775357], Action prob: [0.69661677 0.3033833 ], Action: 0, state: 0\n",
      "Sensor: [0.36580008731162095, 0.602555800309312, 0.23677835335320108, 0.5488083858084944], Action prob: [0.7065149  0.29348516], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.30429102035563216, 0.6439541981859193, 0.18658249410265498, 0.2595353450488568], Action prob: [0.7109837  0.28901625], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3082581523321389, 0.6354442691285216, 0.2381037252463162, 0.2521363723888391], Action prob: [0.71289617 0.28710386], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3934750933646278, 0.7149861530600272, 0.2153298721494427, 0.2692171250968178], Action prob: [0.71484596 0.28515404], Action: 0, state: 0\n",
      "Sensor: [0.4158499502373183, 0.614019648693796, 0.18303089512107873, 0.24388907815132269], Action prob: [0.71525025 0.28474972], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35996531937670434, 0.5921840217002695, 0.2128199636620048, 0.2695487607777416], Action prob: [0.7146435 0.2853565], Action: 0, state: 0\n",
      "Sensor: [0.2981875070111286, 0.6009338306153086, 0.2023472697032763, 0.24773789965431317], Action prob: [0.7135858 0.2864142], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3425065493900456, 0.6720228465816651, 0.2171664568269867, 0.2550667697467662], Action prob: [0.71389043 0.28610963], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.36823283934313084, 0.5157495953834927, 0.19846403705669782, 0.38731672253817845], Action prob: [0.71361285 0.2863872 ], Action: 0, state: 0\n",
      "Sensor: [0.33282390944801155, 0.6318629169690966, 0.20406085762092602, 0.2108304102682582], Action prob: [0.7133707 0.2866293], Action: 0, state: 0\n",
      "Sensor: [0.3975727897565002, 0.7025854997763972, 0.22249515881208062, 0.2734142720387185], Action prob: [0.71453863 0.28546134], Action: 0, state: 0\n",
      "tensor([-0.7348, -0.3572, -0.5818, -0.5421, -0.5487, -0.5522, -0.2918, -0.2223,\n",
      "         0.0563,  0.9856,  1.3341,  0.2760,  0.4284,  0.5627],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 18 is 5900, loss is 0.013429299932875616\n",
      "Sensor: [0.3065674037264976, 0.6487164751262477, 0.21621897379366026, 0.286976670053934], Action prob: [0.6690542  0.33094573], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3198952227093306, 0.4913353947669019, 0.26278247380735953, 0.2947171660654841], Action prob: [0.69545376 0.30454627], Action: 0, state: 0\n",
      "Sensor: [0.3648666625614797, 0.6958767195502862, 0.2158095356824785, 0.24563509545736867], Action prob: [0.71402866 0.2859713 ], Action: 0, state: 1\n",
      "Sensor: [0.3582433966172117, 0.6368189212134631, 0.2163881585638504, 0.18455695083779522], Action prob: [0.7238018  0.27619824], Action: 0, state: 1\n",
      "Sensor: [0.3036824560759752, 0.6374304631739705, 0.18671248830353104, 0.18760399898649094], Action prob: [0.72833014 0.27166986], Action: 0, state: 2\n",
      "Sensor: [0.3803078344895279, 0.651976586925936, 0.19468625462287165, 0.23585902015002458], Action prob: [0.7312945  0.26870546], Action: 0, state: 3\n",
      "Sensor: [0.5608925536021991, 0.6574673273083668, 0.19362998072764617, 0.26816677394726696], Action prob: [0.7343649  0.26563507], Action: 1, state: 8\n",
      "Sensor: [0.38594732106831536, 0.5847043674394211, 0.2385356515634523, 0.4968550459975928], Action prob: [0.7350223  0.26497775], Action: 0, state: 8\n",
      "Sensor: [0.5960659239400871, 0.688235434875123, 0.26003976176668486, 0.20415796707004147], Action prob: [0.73669785 0.26330215], Action: 0, state: 8\n",
      "Sensor: [0.4915273211835253, 0.16503512303985918, 0.24910658778892458, 0.2290616354928295], Action prob: [0.7329214  0.26707858], Action: 1, state: 8\n",
      "Sensor: [0.3228198780125209, 0.41201284430797186, 0.2258161380681314, 0.23272735186851207], Action prob: [0.7299813 0.2700187], Action: 0, state: 8\n",
      "Sensor: [0.3971599335629118, 0.5882282432009417, 0.5031314865260581, 0.2352905194270841], Action prob: [0.7311515  0.26884854], Action: 1, state: 8\n",
      "Sensor: [0.570677331371782, 0.6222032105445914, 0.19419439070094552, 0.2610997520354932], Action prob: [0.73360884 0.26639113], Action: 0, state: 8\n",
      "Sensor: [0.39150729195560957, 0.4969864966037155, 0.1789093729617715, 0.577150673941161], Action prob: [0.7337318  0.26626822], Action: 0, state: 8\n",
      "Sensor: [0.31663069616907785, 0.35214838872858867, 0.19513491603152044, 0.28399849624359513], Action prob: [0.73104894 0.26895112], Action: 0, state: 8\n",
      "Sensor: [0.4798727665786461, 0.379283950947495, 0.19298133276856091, 0.2207590649211072], Action prob: [0.730252   0.26974803], Action: 1, state: 8\n",
      "Sensor: [0.6646951391798263, 0.3573232727327015, 0.21175400573719075, 0.29659363868814553], Action prob: [0.73136723 0.26863274], Action: 0, state: 8\n",
      "Sensor: [0.5573406747636811, 0.7233337000105143, 0.20265748434657166, 0.2949908817206759], Action prob: [0.7338536  0.26614648], Action: 0, state: 8\n",
      "Sensor: [0.3637700494163686, 0.6186016398957471, 0.4773990803806268, 0.2714423089208032], Action prob: [0.7342999  0.26570016], Action: 0, state: 8\n",
      "Sensor: [0.4169988618849233, 0.35221897722628287, 0.2122458121422675, 0.48433245785704837], Action prob: [0.73308206 0.266918  ], Action: 0, state: 8\n",
      "Sensor: [0.376229866473121, 0.3912175565389284, 0.3872785391592727, 0.289833824558234], Action prob: [0.7315291  0.26847094], Action: 0, state: 8\n",
      "Sensor: [0.37023354942490655, 0.631936522749774, 0.20100253078932137, 0.6012525721297736], Action prob: [0.7329663  0.26703367], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.34314917937525663, 0.3876513313491103, 0.2312942522006366, 0.18817739508161668], Action prob: [0.7312482 0.2687518], Action: 1, state: 8\n",
      "Sensor: [0.3203890484260293, 0.38796329966793397, 0.2381185778215536, 0.23289377176601975], Action prob: [0.72935504 0.27064493], Action: 0, state: 8\n",
      "Sensor: [0.3341990363032813, 0.6013099584695555, 0.5064417065317475, 0.26563427269905837], Action prob: [0.7305773 0.2694227], Action: 0, state: 8\n",
      "Sensor: [0.3509988811174883, 0.6095800479376932, 0.5030705604601151, 0.20502601287911593], Action prob: [0.73211277 0.26788723], Action: 0, state: 8\n",
      "Sensor: [0.31604623824495737, 0.34581166179017886, 0.2167755925251923, 0.23390544439246597], Action prob: [0.73021895 0.269781  ], Action: 0, state: 8\n",
      "Sensor: [0.6100235202168993, 0.6113979689320354, 0.5386982812403742, 0.27091831027069185], Action prob: [0.73349035 0.2665096 ], Action: 0, state: 8\n",
      "tensor([ 1.3005,  0.4281,  0.4454,  0.4705,  0.4950,  0.5072,  1.7235,  0.3112,\n",
      "         0.2291,  0.6945,  0.0976,  0.1488, -0.0165, -0.0636, -0.1067, -0.6090,\n",
      "        -0.1803, -0.2119, -0.2401, -0.2641, -0.2897, -0.3094, -1.3797, -0.3484,\n",
      "        -0.3642, -0.3753, -0.3878, -0.3960], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 19 is -65900, loss is -0.04673496110014631\n",
      "Sensor: [0.33334065988155, 0.6772949870293357, 0.21990352662363732, 0.24393706836521312], Action prob: [0.6851784  0.31482166], Action: 0, state: 0\n",
      "Sensor: [0.3406945531725839, 0.6333427714307847, 0.21418607144059834, 0.20371835322623316], Action prob: [0.7183642  0.28163582], Action: 0, state: 0\n",
      "Sensor: [0.40415861721173674, 0.6644744746041695, 0.23983841521008972, 0.2668831836682844], Action prob: [0.7409321  0.25906792], Action: 0, state: 1\n",
      "Sensor: [0.35134153440821325, 0.49193681555488405, 0.1905705015256124, 0.2600664965058554], Action prob: [0.75184995 0.24815008], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.34925128103891845, 0.6386780253685949, 0.20907694623629297, 0.2783187979238016], Action prob: [0.75897264 0.24102737], Action: 0, state: 0\n",
      "Sensor: [0.37854502108902216, 0.667862563034662, 0.18943507879990568, 0.2704087444873941], Action prob: [0.76369864 0.23630133], Action: 0, state: 0\n",
      "Sensor: [0.3753494997302829, 0.6374161085764236, 0.21047109897803018, 0.221800744893645], Action prob: [0.7659893  0.23401071], Action: 0, state: 0\n",
      "Sensor: [0.354804527541482, 0.6659436268177261, 0.20239171702533507, 0.24268138434853878], Action prob: [0.7672097  0.23279032], Action: 0, state: 0\n",
      "Sensor: [0.3043380753312249, 0.6315110879240291, 0.20258429945006595, 0.26068245137905677], Action prob: [0.7672372  0.23276283], Action: 0, state: 1\n",
      "Sensor: [0.3506429664770948, 0.6387078308152412, 0.19769077332390117, 0.24607476475216286], Action prob: [0.7674377  0.23256235], Action: 0, state: 1\n",
      "Sensor: [0.31565425028336, 0.6103743856840937, 0.20212730407571786, 0.2569732174707212], Action prob: [0.7670705  0.23292959], Action: 0, state: 1\n",
      "Sensor: [0.3231038343854189, 0.47008336284610985, 0.1941083214385052, 0.27372065893462216], Action prob: [0.7657902  0.23420975], Action: 0, state: 1\n",
      "Sensor: [0.3641588484743556, 0.6553264540489585, 0.22633469367651637, 0.262207863924048], Action prob: [0.7664623  0.23353766], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3004916254775216, 0.6631744361518085, 0.1994889438954134, 0.26694071201997266], Action prob: [0.76679325 0.23320675], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3889835519494812, 0.6008209039556945, 0.22925307210594142, 0.4914339506830917], Action prob: [0.7680913 0.2319087], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -3000\n",
      "tensor([-0.7692, -0.4766, -0.2884, -0.7326, -0.2651, -0.1543, -0.0592,  0.0244,\n",
      "         0.0922,  0.1529,  0.2080,  0.2598,  1.6533,  1.7767,  1.7847],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 20 is 6800, loss is -0.21376888382273712\n",
      "Sensor: [0.35525557875737446, 0.6737069841137979, 0.23562266784431796, 0.2207391461625024], Action prob: [0.7152066  0.28479338], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.40308611709464803, 0.6645951120906649, 0.24660721027264987, 0.3505711083394323], Action prob: [0.7638197  0.23618026], Action: 0, state: 0\n",
      "Sensor: [0.3574046694883174, 0.6207518435043541, 0.20084477661199202, 0.2340394020656955], Action prob: [0.79511106 0.20488894], Action: 0, state: 0\n",
      "Sensor: [0.3445960816087126, 0.6743185814869639, 0.20131110739473715, 0.24550187268488857], Action prob: [0.81484187 0.18515816], Action: 0, state: 0\n",
      "Sensor: [0.38809833943506383, 0.6907811826392056, 0.19092921055853002, 0.24029822441545318], Action prob: [0.8276222 0.1723778], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.34734883500078334, 0.680733367685802, 0.1793314522351513, 0.28296734644501137], Action prob: [0.8353598  0.16464022], Action: 0, state: 0\n",
      "Sensor: [0.39010227275536996, 0.5655318109069947, 0.1971151462808534, 0.2307284246178042], Action prob: [0.83977336 0.16022658], Action: 0, state: 0\n",
      "Sensor: [0.34834813046271873, 0.6101301259962684, 0.16329136408903733, 0.22435026736542704], Action prob: [0.8420374  0.15796262], Action: 0, state: 0\n",
      "Sensor: [0.39571239925253804, 0.6297923544299429, 0.23404605706651727, 0.22523623416987418], Action prob: [0.8440355 0.1559645], Action: 0, state: 0\n",
      "Sensor: [0.3670082406105008, 0.6167815920696397, 0.23039621655992257, 0.22323573398149238], Action prob: [0.84510314 0.15489683], Action: 0, state: 0\n",
      "Sensor: [0.35622874999005116, 0.542801593510243, 0.19109633870677, 0.4195376201414333], Action prob: [0.8456911  0.15430887], Action: 0, state: 1\n",
      "Sensor: [0.36736570508405386, 0.6170539485799196, 0.2028075649796851, 0.2566918644918943], Action prob: [0.8461698  0.15383014], Action: 0, state: 1\n",
      "Sensor: [0.41770439930242187, 0.6498184197670636, 0.22176233023455189, 0.27894634391419176], Action prob: [0.84719545 0.1528046 ], Action: 0, state: 2\n",
      "Sensor: [0.35187719675303303, 0.6051159519280453, 0.22869497373638273, 0.19525044318100418], Action prob: [0.84701145 0.15298858], Action: 0, state: 3\n",
      "Sensor: [0.35700704797346505, 0.6416018145470818, 0.2226282013081963, 0.6051673687116368], Action prob: [0.8480832  0.15191677], Action: 0, state: 3\n",
      "Sensor: [0.3719994992284181, 0.6435712593875458, 0.21275132402317432, 0.22589155080409318], Action prob: [0.8484378  0.15156217], Action: 0, state: 3\n",
      "Sensor: [0.47074334403044626, 0.5840689496620007, 0.19777777798756005, 0.2537070201461956], Action prob: [0.84869945 0.15130061], Action: 0, state: 3\n",
      "Sensor: [0.34261574510198206, 0.388700441743445, 0.2540048643826746, 0.23643788089055898], Action prob: [0.8465856 0.1534145], Action: 1, state: 9\n",
      "Sensor: [0.37779573495016194, 0.6757789034004131, 0.20088807765855055, 0.5236257255977089], Action prob: [0.8474705  0.15252946], Action: 1, state: 9\n",
      "Sensor: [0.38431399721500276, 0.6043602315454499, 0.3298793825066225, 0.5757715750334425], Action prob: [0.8489011  0.15109886], Action: 1, state: 9\n",
      "Sensor: [0.3846309336202305, 0.6986838001470241, 0.23610168920137423, 0.25711673840775323], Action prob: [0.8497474  0.15025258], Action: 0, state: 0\n",
      "Sensor: [0.3236946700228473, 0.6500780096510045, 0.2004523639007258, 0.19875971552045876], Action prob: [0.84899163 0.15100834], Action: 0, state: 1\n",
      "Sensor: [0.329594395168303, 0.6663990336951381, 0.2064674496075859, 0.5445997655569573], Action prob: [0.84922284 0.15077719], Action: 0, state: 9\n",
      "Sensor: [0.5674974379472053, 0.6578775151134437, 0.20168499083201763, 0.21938073524920468], Action prob: [0.85061693 0.14938311], Action: 0, state: 9\n",
      "Sensor: [0.3058657095611103, 0.33273569387009233, 0.19240413313151783, 0.2177905364239245], Action prob: [0.8472761  0.15272392], Action: 1, state: 9\n",
      "Sensor: [0.6190756204755403, 0.6486432442783165, 0.2100032932401222, 0.2942766288015183], Action prob: [0.8487511 0.1512489], Action: 0, state: 9\n",
      "Sensor: [0.5358429762347098, 0.5931178848898275, 0.20271159786615106, 0.28481059699136785], Action prob: [0.8493965  0.15060346], Action: 0, state: 9\n",
      "tensor([-3.2610, -0.6265, -0.4210, -0.2864, -1.7644, -0.1805, -0.1189, -0.0677,\n",
      "        -0.0230,  0.0164,  0.0483,  0.0763,  0.0982,  0.1112,  0.1215,  0.1314,\n",
      "         0.1406,  1.4247,  1.2482,  1.1004,  0.1067,  0.1172,  0.1071,  0.0977,\n",
      "         1.0562,  0.0841,  0.0775], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 21 is 5000, loss is 0.02169015022543989\n",
      "Sensor: [0.3551591239679708, 0.7146506790479548, 0.192534556763915, 0.2015739001202838], Action prob: [0.7466394  0.25336066], Action: 0, state: 0\n",
      "Sensor: [0.3631412734224755, 0.6022840629773679, 0.19088416822244492, 0.2885751442188994], Action prob: [0.8098672  0.19013281], Action: 0, state: 1\n",
      "Sensor: [0.34983631742575005, 0.610283917534959, 0.2083656181321042, 0.23505516684554986], Action prob: [0.8547218  0.14527819], Action: 0, state: 1\n",
      "Sensor: [0.33308978526627686, 0.6413948756801854, 0.2171682196315605, 0.23180356753989928], Action prob: [0.883547   0.11645304], Action: 0, state: 2\n",
      "Sensor: [0.36560927152189027, 0.636125053746197, 0.23198548946200076, 0.24858904793138425], Action prob: [0.90216714 0.09783291], Action: 0, state: 2\n",
      "Sensor: [0.42026624635739285, 0.6491806993676112, 0.2769180814129558, 0.27320082078740693], Action prob: [0.91482157 0.08517841], Action: 0, state: 2\n",
      "Sensor: [0.42381050975258605, 0.7060527225559567, 0.2635377806455579, 0.24391813758630795], Action prob: [0.92337227 0.07662775], Action: 0, state: 2\n",
      "Sensor: [0.35427265407883646, 0.6091765677387433, 0.22493304108369144, 0.2820278223983423], Action prob: [0.9284613  0.07153871], Action: 0, state: 2\n",
      "Sensor: [0.37823091551696303, 0.6470366468634297, 0.30713221030951876, 0.23655633325557227], Action prob: [0.93213487 0.0678651 ], Action: 0, state: 3\n",
      "Sensor: [0.3183668345373487, 0.5746202938329327, 0.2137645496826499, 0.2441835545200481], Action prob: [0.93409944 0.06590052], Action: 0, state: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.39162037996650156, 0.5977215019716897, 0.5221748290074739, 0.23631580097253935], Action prob: [0.9362087  0.06379124], Action: 0, state: 8\n",
      "Sensor: [0.5839975420792688, 0.6003839014264803, 0.24996837499320376, 0.24034369192914348], Action prob: [0.9382782  0.06172174], Action: 0, state: 8\n",
      "Sensor: [0.5726582086210215, 0.6272642944595161, 0.21233270213383768, 0.22978973349191578], Action prob: [0.939501 0.060499], Action: 0, state: 8\n",
      "Sensor: [0.5127583654178981, 0.6710011191691007, 0.1980198373895068, 0.25593019899473973], Action prob: [0.94021064 0.05978933], Action: 0, state: 8\n",
      "Sensor: [0.3658493011328768, 0.6522793747223953, 0.22773748276628417, 0.5823927596825866], Action prob: [0.9404234  0.05957653], Action: 0, state: 8\n",
      "Sensor: [0.32974896331107295, 0.38308267024584464, 0.20058675690895666, 0.2785559292156283], Action prob: [0.9399162  0.06008388], Action: 0, state: 8\n",
      "Sensor: [0.4212393703560172, 0.6724964863873838, 0.5349220639512962, 0.25836687387413215], Action prob: [0.9405264  0.05947356], Action: 0, state: 8\n",
      "Sensor: [0.6283036886905006, 0.35568334326427736, 0.22636407227218355, 0.27048550084060524], Action prob: [0.941071 0.058929], Action: 0, state: 8\n",
      "Sensor: [0.5866689561106772, 0.624556057578749, 0.5146776256483631, 0.21611439323059362], Action prob: [0.94169754 0.05830242], Action: 0, state: 8\n",
      "Sensor: [0.35317995795609586, 0.6708713213308928, 0.5078285002926548, 0.2293378855393345], Action prob: [0.9418083  0.05819172], Action: 0, state: 8\n",
      "Sensor: [0.5686977302037582, 0.3458471907884731, 0.4635125840014158, 0.3065623442431691], Action prob: [0.94220483 0.05779517], Action: 0, state: 8\n",
      "Sensor: [0.3771163867436172, 0.41472821288644446, 0.19278389062474086, 0.26203226054849393], Action prob: [0.94111943 0.05888056], Action: 0, state: 8\n",
      "Sensor: [0.33461680799320326, 0.39809537131521655, 0.2305036002445111, 0.28358616111399826], Action prob: [0.9399728 0.0600272], Action: 0, state: 8\n",
      "Sensor: [0.41159905279127595, 0.3491195442075774, 0.2532949727377459, 0.28181889585334013], Action prob: [0.9392892  0.06071071], Action: 0, state: 8\n",
      "Sensor: [0.5728465309472551, 0.3654715050390811, 0.23046679458097297, 0.28647076913520647], Action prob: [0.9393534  0.06064667], Action: 0, state: 8\n",
      "Sensor: [0.3880356880598201, 0.4171451890302352, 0.20004263440632675, 0.23493065774602834], Action prob: [0.9387137  0.06128629], Action: 0, state: 8\n",
      "Sensor: [0.3292218774911047, 0.350294210261046, 0.26069448306291526, 0.5296039311781086], Action prob: [0.9381645  0.06183556], Action: 1, state: 8\n",
      "Sensor: [0.31938861372131594, 0.3812114649463459, 0.2112444207948628, 0.21710652556224191], Action prob: [0.9376781  0.06232189], Action: 0, state: 8\n",
      "Sensor: [0.4113472353793164, 0.378112610774055, 0.20182545501893262, 0.2512220626341655], Action prob: [0.9374942  0.06250581], Action: 1, state: 8\n",
      "Sensor: [0.6035058034025755, 0.6595905330070085, 0.2367847163606933, 0.19918387512889868], Action prob: [0.93873006 0.06126995], Action: 0, state: 8\n",
      "tensor([ 3.5312e-02,  8.1995e-02,  9.8521e-02,  1.0129e-01,  1.0195e-01,\n",
      "         1.0188e-01,  1.0228e-01,  1.0471e-01,  1.0398e-01,  1.0538e-01,\n",
      "         7.8995e-02,  5.6929e-02,  3.8414e-02,  2.2467e-02,  8.5002e-03,\n",
      "        -3.5742e-03, -1.5346e-02, -2.4485e-02, -3.3663e-02, -4.1650e-02,\n",
      "        -4.8009e-02, -5.5375e-02, -6.2504e-02, -6.8640e-02, -7.3457e-02,\n",
      "        -7.8791e-02, -3.6448e+00, -8.7908e-02, -3.9293e+00, -9.2911e-02],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 22 is -56200, loss is 0.2372598109219051\n",
      "Sensor: [0.3084675371409965, 0.6919450652818262, 0.16703313818744825, 0.253574889448143], Action prob: [0.7546602  0.24533986], Action: 0, state: 0\n",
      "Sensor: [0.3698355220166043, 0.6251352568496786, 0.20020069576109614, 0.25057163608481625], Action prob: [0.8176425  0.18235748], Action: 0, state: 1\n",
      "Sensor: [0.35235227503763933, 0.6568840185745304, 0.19416878429174148, 0.2716248918701103], Action prob: [0.8589767  0.14102323], Action: 0, state: 1\n",
      "Sensor: [0.4010786781243333, 0.6402554614742986, 0.2128561422880377, 0.25237751828426647], Action prob: [0.8841217  0.11587825], Action: 0, state: 2\n",
      "Sensor: [0.30384581388187365, 0.5670110195960638, 0.16113482143070149, 0.19041652180512536], Action prob: [0.89768183 0.10231812], Action: 0, state: 3\n",
      "Sensor: [0.3033785952496876, 0.6199867948896299, 0.21768209024561422, 0.5377770194746596], Action prob: [0.9071875  0.09281242], Action: 0, state: 8\n",
      "Sensor: [0.3653924119173538, 0.33950333992958115, 0.23734061560066605, 0.1753353467565218], Action prob: [0.912039   0.08796102], Action: 0, state: 8\n",
      "Sensor: [0.33663047759529274, 0.4275233825672244, 0.1959891013401072, 0.2264245126192308], Action prob: [0.9147975  0.08520249], Action: 1, state: 8\n",
      "Sensor: [0.577045427946417, 0.3913241076687835, 0.2407555085375382, 0.3189003777643839], Action prob: [0.9180582  0.08194179], Action: 0, state: 8\n",
      "Sensor: [0.36817498736406107, 0.35757304419307046, 0.23097697455433167, 0.24739383023178785], Action prob: [0.91881216 0.0811878 ], Action: 0, state: 8\n",
      "Sensor: [0.7033747136893638, 0.6308033526905571, 0.209146645781054, 0.583091571793424], Action prob: [0.92253244 0.07746755], Action: 0, state: 8\n",
      "Sensor: [0.6152350977680882, 0.6142133209914485, 0.2022859224300017, 0.5434526502655235], Action prob: [0.9249884 0.0750116], Action: 0, state: 8\n",
      "Sensor: [0.5796827682560195, 0.6516574148260832, 0.2736901723995076, 0.26229932321574395], Action prob: [0.926542   0.07345799], Action: 0, state: 8\n",
      "Sensor: [0.3410745191115783, 0.6576811683483272, 0.5071832400387885, 0.26286558557949347], Action prob: [0.92690426 0.07309569], Action: 0, state: 8\n",
      "Sensor: [0.5634156431923542, 0.6049771302628146, 0.19962258608204891, 0.2559099526733919], Action prob: [0.92753595 0.07246406], Action: 0, state: 8\n",
      "Sensor: [0.3411721869532033, 0.6911459996649837, 0.5161897023232914, 0.2252212436378196], Action prob: [0.9274718  0.07252813], Action: 0, state: 8\n",
      "Sensor: [0.6204862931664491, 0.714417409475594, 0.23820317992133958, 0.20934984495463452], Action prob: [0.9285387  0.07146133], Action: 0, state: 8\n",
      "Sensor: [0.530062019489413, 0.6231347360800553, 0.2415168976303346, 0.25422805658059927], Action prob: [0.9284163  0.07158365], Action: 0, state: 8\n",
      "Sensor: [0.5819747944571557, 0.32070257712401057, 0.1723911152895431, 0.28424813012817024], Action prob: [0.9273448  0.07265522], Action: 0, state: 8\n",
      "Sensor: [0.36974171351964286, 0.39961724289766026, 0.2414754597641258, 0.26625286407563226], Action prob: [0.9254534  0.07454658], Action: 0, state: 8\n",
      "Sensor: [0.6076609674600134, 0.6645328041704908, 0.22558181651602482, 0.24783651218551117], Action prob: [0.9262517  0.07374831], Action: 1, state: 8\n",
      "Sensor: [0.3888366372968632, 0.5784775557559984, 0.5202899636097207, 0.2608654920010378], Action prob: [0.9264379  0.07356215], Action: 1, state: 8\n",
      "Sensor: [0.37328307649637016, 0.671043498858863, 0.539690525369558, 0.25679450062999315], Action prob: [0.927125   0.07287505], Action: 0, state: 8\n",
      "Sensor: [0.5726324599821203, 0.6861100214810198, 0.24948807686858324, 0.27841421474792294], Action prob: [0.9281471  0.07185294], Action: 0, state: 8\n",
      "Sensor: [0.3528884833280098, 0.42498772915972766, 0.21488144767751413, 0.24274791029404102], Action prob: [0.92657286 0.0734271 ], Action: 0, state: 8\n",
      "Sensor: [0.5687619915313769, 0.6291096801290998, 0.17758984423012036, 0.2868165437126595], Action prob: [0.92674476 0.07325521], Action: 0, state: 8\n",
      "Sensor: [0.4044689525781545, 0.5543999998351564, 0.5649048860555235, 0.2632895611359802], Action prob: [0.9268332  0.07316677], Action: 0, state: 8\n",
      "Sensor: [0.3610975179144981, 0.3508896323563673, 0.23712575016344345, 0.26627124960225096], Action prob: [0.92556125 0.07443871], Action: 0, state: 8\n",
      "Sensor: [0.37431423398134805, 0.41631984093595625, 0.21301670885351115, 0.21803305653327987], Action prob: [0.92427284 0.07572712], Action: 1, state: 8\n",
      "Sensor: [0.4251406448133841, 0.6746733548000369, 0.2046437408452083, 0.26004033305038593], Action prob: [0.92447543 0.0755245 ], Action: 0, state: 0\n",
      "tensor([ 0.3727,  0.2960,  0.2432,  0.2100,  0.1906,  0.1409,  0.1075,  2.2386,\n",
      "         0.0580,  0.0399,  0.0224,  0.0086, -0.0033, -0.0139, -0.0226, -0.0314,\n",
      "        -0.0380, -0.0446, -0.0509, -0.0581, -2.1378, -2.2996, -0.0709, -0.0731,\n",
      "        -0.0776, -0.0806, -0.0834, -0.0867, -2.9669, -0.0901],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 23 is -66900, loss is 0.1433713608020679\n",
      "Sensor: [0.3680063830131359, 0.6220456946581174, 0.1852103462061843, 0.2680032927234809], Action prob: [0.75209737 0.2479027 ], Action: 0, state: 0\n",
      "Sensor: [0.33303990612286855, 0.6371845613797938, 0.22084761391835592, 0.2961612736541423], Action prob: [0.80867493 0.1913251 ], Action: 0, state: 1\n",
      "Sensor: [0.3408264115876442, 0.6814750229311888, 0.23122724731081154, 0.23376464629757315], Action prob: [0.84299433 0.1570057 ], Action: 0, state: 1\n",
      "Sensor: [0.3642977037091986, 0.6429139576936415, 0.24352099240716177, 0.2804903271275164], Action prob: [0.8626975  0.13730258], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.33903570173643494, 0.6527994429007689, 0.22278516853086627, 0.17395120696266927], Action prob: [0.87353414 0.12646583], Action: 0, state: 0\n",
      "Sensor: [0.35575790540363145, 0.6621178973194661, 0.1954964291515434, 0.2337009100010514], Action prob: [0.8802037 0.1197963], Action: 0, state: 0\n",
      "Sensor: [0.33379759227270156, 0.7044174262571792, 0.1935197526584293, 0.25236629243482095], Action prob: [0.8844239  0.11557608], Action: 0, state: 0\n",
      "Sensor: [0.40697856911605135, 0.617780492153089, 0.23693456490604914, 0.24140016069211628], Action prob: [0.88721555 0.11278448], Action: 0, state: 0\n",
      "Sensor: [0.4131786307763734, 0.6511732549575002, 0.19695589179993273, 0.2930094818959002], Action prob: [0.88900477 0.11099529], Action: 0, state: 0\n",
      "Sensor: [0.40804515611477427, 0.6585813279703411, 0.19838320175695712, 0.2259548393833326], Action prob: [0.8899807  0.11001935], Action: 0, state: 0\n",
      "Sensor: [0.37977939426547047, 0.6577384736977562, 0.20974521752840397, 0.27202990956319123], Action prob: [0.8904392  0.10956078], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.43910218735732676, 0.5808126147472783, 0.20825379659961493, 0.264151272769347], Action prob: [0.8907129  0.10928701], Action: 0, state: 0\n",
      "Sensor: [0.3874172503817569, 0.5252885523286538, 0.22533277779374367, 0.21373904706853605], Action prob: [0.890026   0.10997402], Action: 0, state: 0\n",
      "Sensor: [0.4144119415440789, 0.6233437540941592, 0.21231832136630058, 0.26947410434163344], Action prob: [0.8902466  0.10975339], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3320799371320771, 0.6487052113694501, 0.20388681925203267, 0.3383518570404088], Action prob: [0.89023983 0.10976016], Action: 0, state: 0\n",
      "Sensor: [0.33289243891394604, 0.58515119370355, 0.2027539083328076, 0.2704366655036565], Action prob: [0.8898656  0.11013439], Action: 0, state: 0\n",
      "Sensor: [0.32424271322009385, 0.6432924046851028, 0.21601541534626367, 0.17673273481092427], Action prob: [0.8895953  0.11040468], Action: 0, state: 0\n",
      "Sensor: [0.33464007891781067, 0.5957963034467486, 0.2309336472951589, 0.264202589851948], Action prob: [0.889438   0.11056205], Action: 0, state: 1\n",
      "Sensor: [0.36875924729168197, 0.6624060819147952, 0.22793451146665172, 0.26469630313171133], Action prob: [0.8899851  0.11001488], Action: 0, state: 2\n",
      "Sensor: [0.31561401134465666, 0.6293992329766911, 0.17583361479979118, 0.2232511773741988], Action prob: [0.889636   0.11036403], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "Sensor: [0.3614047282508335, 0.6698388397346873, 0.2422744229559528, 0.22370346575547226], Action prob: [0.8900546  0.10994544], Action: 0, state: 1\n",
      "Sensor: [0.35871973440187777, 0.7027625218052588, 0.22835607121143997, 0.26766663835899757], Action prob: [0.89066535 0.10933463], Action: 0, state: 1\n",
      "Sensor: [0.3973302878765201, 0.638874397991764, 0.20707822512799584, 0.4782465635400229], Action prob: [0.8914203  0.10857971], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-6.4199e-01, -3.9455e-01, -2.5655e-01, -2.3436e+00, -1.5957e-01,\n",
      "        -1.1370e-01, -7.7619e-02, -4.7420e-02, -2.1873e-02,  4.2472e-04,\n",
      "         3.8476e-01,  2.9247e-02,  4.5660e-02,  5.9788e-02,  7.2711e-02,\n",
      "         8.4912e-02,  9.5594e-02,  1.0443e-01,  1.1058e-01,  2.2104e+00,\n",
      "         1.1594e-01,  1.2076e-01,  2.4151e+00], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 24 is 18400, loss is -0.07797512886031932\n",
      "Sensor: [0.36382806379928456, 0.6343735200770085, 0.23587235172169244, 0.23587599650345464], Action prob: [0.7578062 0.2421938], Action: 0, state: 0\n",
      "Sensor: [0.38679351821872093, 0.6647944685830052, 0.24338912799553178, 0.26960188034270705], Action prob: [0.8128074  0.18719262], Action: 0, state: 1\n",
      "Sensor: [0.38860908228403984, 0.6592912616979548, 0.24986929975888728, 0.29450069098338155], Action prob: [0.8439448  0.15605518], Action: 0, state: 2\n",
      "Sensor: [0.3109537421500962, 0.6364946687835257, 0.1882839715130487, 0.2701356543745451], Action prob: [0.85958594 0.14041412], Action: 0, state: 2\n",
      "Sensor: [0.4102403296602706, 0.574455884392207, 0.19831130732550625, 0.24560445478025267], Action prob: [0.86848986 0.13151014], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.35652155125205065, 0.6254779168536023, 0.2640655130593329, 0.2783219275363377], Action prob: [0.87396944 0.1260305 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "Sensor: [0.3485924525700285, 0.6899924243862041, 0.22772750861214291, 0.23887983572559768], Action prob: [0.87753874 0.12246125], Action: 0, state: 1\n",
      "Sensor: [0.40455818282625444, 0.6906663630944737, 0.18929423316054975, 0.2688319333346507], Action prob: [0.8800196  0.11998046], Action: 0, state: 1\n",
      "Sensor: [0.3355280926007707, 0.6881605439161731, 0.21183286611723318, 0.24795487771628086], Action prob: [0.88091666 0.11908337], Action: 0, state: 1\n",
      "Sensor: [0.32633860251277585, 0.6211635590656409, 0.219837739047521, 0.2868313812965561], Action prob: [0.8810295  0.11897049], Action: 0, state: 1\n",
      "Sensor: [0.3747349750909621, 0.6701337602441138, 0.17077774674354498, 0.2129792107913096], Action prob: [0.8812914  0.11870868], Action: 0, state: 1\n",
      "Sensor: [0.3652795635649635, 0.6044741054528746, 0.2956850422779302, 0.2949120925534211], Action prob: [0.8815969  0.11840303], Action: 0, state: 1\n",
      "Sensor: [0.31286256023754644, 0.6305737927052449, 0.17619963839914074, 0.2821722166231995], Action prob: [0.88116103 0.11883895], Action: 0, state: 1\n",
      "Sensor: [0.3773285340374078, 0.6663886760091838, 0.23055466132645758, 0.26501188396591885], Action prob: [0.88167244 0.11832761], Action: 0, state: 1\n",
      "Sensor: [0.30747089738283845, 0.6852369496462035, 0.22118005771288005, 0.25743433615147326], Action prob: [0.8816275  0.11837256], Action: 0, state: 1\n",
      "Sensor: [0.43651634172290205, 0.6059788908483921, 0.1856873999207803, 0.5514767282898353], Action prob: [0.8826634  0.11733662], Action: 0, state: 2\n",
      "Sensor: [0.44602871836659924, 0.6624767862396039, 0.20689764569981228, 0.2043746336799094], Action prob: [0.88310534 0.11689463], Action: 0, state: 3\n",
      "Sensor: [0.4087817570301904, 0.4098412978111696, 0.21083324383559057, 0.2781123101624645], Action prob: [0.88148457 0.11851546], Action: 0, state: 3\n",
      "Sensor: [0.33529237578977716, 0.6471934844888683, 0.43436327971049504, 0.26593157061526507], Action prob: [0.8818581 0.1181419], Action: 0, state: 3\n",
      "Sensor: [0.3807859696516256, 0.47920383738406236, 0.2102863360091639, 0.2050713379749679], Action prob: [0.8808766  0.11912345], Action: 0, state: 3\n",
      "Sensor: [0.3856553105154078, 0.6701949974795828, 0.19494880573497547, 0.22061518881679157], Action prob: [0.8809849  0.11901511], Action: 0, state: 3\n",
      "Sensor: [0.6099564962977471, 0.68541426723815, 0.20673370309976913, 0.29152630113027383], Action prob: [0.8833116 0.1166884], Action: 0, state: 8\n",
      "Sensor: [0.34501073777417257, 0.36832769842160673, 0.19529118504803616, 0.4934386281961241], Action prob: [0.88136643 0.11863354], Action: 0, state: 8\n",
      "Sensor: [0.6026263402983462, 0.6327669472979505, 0.2131256402382157, 0.28986592395551025], Action prob: [0.8830432  0.11695675], Action: 0, state: 8\n",
      "Sensor: [0.6000502833688558, 0.29973518307814523, 0.2079744575208747, 0.2832411674796611], Action prob: [0.88208777 0.11791223], Action: 0, state: 8\n",
      "Sensor: [0.5724531655170407, 0.4111047094121913, 0.19813833857944282, 0.2772215344792053], Action prob: [0.88134015 0.11865981], Action: 0, state: 8\n",
      "Sensor: [0.42805864163344054, 0.644501231620952, 0.47712602345708593, 0.21689505590141336], Action prob: [0.8823183  0.11768165], Action: 0, state: 8\n",
      "tensor([-0.7217, -0.4261, -0.2745, -0.1851, -2.0283, -1.8274, -0.1201, -0.0802,\n",
      "        -0.0465, -0.0164,  0.0104,  0.0344,  0.0563,  0.0754,  0.0929,  0.1062,\n",
      "         0.1134,  0.1229,  0.1278,  0.1356,  0.1401,  0.1097,  0.0872,  0.0630,\n",
      "         0.0441,  0.0258,  0.0080], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 25 is -7300, loss is 0.1619628873306182\n",
      "Sensor: [0.2825901226995406, 0.6772611023334011, 0.2286081633652947, 0.2568794212851463], Action prob: [0.7557585  0.24424148], Action: 0, state: 0\n",
      "Sensor: [0.326495048716704, 0.6668673085964991, 0.2318442514084323, 0.2477886049241399], Action prob: [0.80380034 0.19619973], Action: 0, state: 0\n",
      "Sensor: [0.38092743232713816, 0.6377753552768394, 0.19995019866020708, 0.5072980185169952], Action prob: [0.83095276 0.16904724], Action: 0, state: 0\n",
      "Sensor: [0.37945064330523964, 0.6397131321244186, 0.1940446873626236, 0.2656746566374295], Action prob: [0.84423727 0.15576276], Action: 0, state: 0\n",
      "Sensor: [0.3694464377801359, 0.6771360154027186, 0.20908116547315878, 0.24255745587842828], Action prob: [0.85157436 0.1484256 ], Action: 0, state: 0\n",
      "Sensor: [0.36440735829215537, 0.6595796208563458, 0.20095431018681664, 0.29638916734199866], Action prob: [0.8556914  0.14430858], Action: 0, state: 0\n",
      "Sensor: [0.38592535866098876, 0.647984704862954, 0.22822809168096447, 0.2341388816074509], Action prob: [0.8581104  0.14188959], Action: 0, state: 1\n",
      "Sensor: [0.33028311896386203, 0.6768657226722462, 0.18578268265488115, 0.22160887451816705], Action prob: [0.85897535 0.1410247 ], Action: 0, state: 1\n",
      "Sensor: [0.35771473319470076, 0.6531295089208249, 0.2460719328013866, 0.2753222032711751], Action prob: [0.85978884 0.14021114], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.2969173940437914, 0.6685069824440674, 0.21046709851462705, 0.2405941474516402], Action prob: [0.85967034 0.14032969], Action: 0, state: 0\n",
      "Sensor: [0.3315288671913796, 0.6653164563490355, 0.2699334145401792, 0.29733701963918135], Action prob: [0.86019945 0.13980062], Action: 0, state: 0\n",
      "Sensor: [0.3524335909513528, 0.6808508347799851, 0.2868956851923068, 0.2294684857456539], Action prob: [0.8608198  0.13918024], Action: 0, state: 0\n",
      "Sensor: [0.32882531870170006, 0.6146971771490503, 0.21660620127912625, 0.17762952099416687], Action prob: [0.86006033 0.13993968], Action: 0, state: 0\n",
      "Sensor: [0.38314114810504923, 0.6073450254317506, 0.21071256690870552, 0.2730172413192837], Action prob: [0.8599131  0.14008687], Action: 0, state: 0\n",
      "Sensor: [0.3697845239214297, 0.6490592428859249, 0.19903703778144832, 0.24332182920588932], Action prob: [0.85995543 0.14004461], Action: 0, state: 0\n",
      "Sensor: [0.3281420963268154, 0.6902417554525826, 0.24703213056512285, 0.2687894877508062], Action prob: [0.86029637 0.13970365], Action: 0, state: 1\n",
      "Sensor: [0.34518721958559867, 0.6649121490490021, 0.20603567198388373, 0.27742929808321715], Action prob: [0.860453   0.13954698], Action: 0, state: 1\n",
      "Sensor: [0.3903890280422494, 0.6702281919247863, 0.17513634543505627, 0.23012934187581738], Action prob: [0.8606286  0.13937145], Action: 0, state: 2\n",
      "Sensor: [0.37799253579765346, 0.3626095051465582, 0.22633198835836443, 0.24979137375820104], Action prob: [0.8583833 0.1416167], Action: 0, state: 3\n",
      "Sensor: [0.4807282471890675, 0.6728015132931472, 0.4371206956495556, 0.2778083141504559], Action prob: [0.86081487 0.13918512], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -700\n",
      "Sensor: [0.40339294464351594, 0.6505157719151081, 0.18482628149401353, 0.2648689259063806], Action prob: [0.86111856 0.13888142], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1600\n",
      "tensor([-0.6473, -0.4136, -0.2810, -0.1997, -0.1407, -0.0938, -0.0581, -0.0275,\n",
      "        -0.0024,  0.0134,  0.0376,  0.0592,  0.0796,  0.0975,  0.1134,  0.1257,\n",
      "         0.1374,  0.1465,  0.1553,  2.0503,  1.9806], dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 26 is 14500, loss is -0.14916197239632872\n",
      "Sensor: [0.3820756748882991, 0.6384439108474153, 0.1943031133261689, 0.2440945415755722], Action prob: [0.7653447  0.23465529], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3087787881870861, 0.6625671351548267, 0.22601415077625595, 0.2807160411234586], Action prob: [0.81184316 0.18815681], Action: 0, state: 0\n",
      "Sensor: [0.36403156575919915, 0.6258123732639228, 0.23378267960083088, 0.24489280266720334], Action prob: [0.83576846 0.16423154], Action: 0, state: 0\n",
      "Sensor: [0.375405040248648, 0.6589580908849673, 0.19744203289566428, 0.29143253692874055], Action prob: [0.848205   0.15179501], Action: 0, state: 0\n",
      "Sensor: [0.34554285396731355, 0.6666461023673055, 0.23572123000545162, 0.28347761570566377], Action prob: [0.8548615  0.14513853], Action: 0, state: 0\n",
      "Sensor: [0.39948752953180333, 0.6355191025281653, 0.1699105248936447, 0.28374036429423044], Action prob: [0.85859394 0.14140603], Action: 0, state: 0\n",
      "Sensor: [0.37588910240291595, 0.6520555504718683, 0.193850185130385, 0.243112550178483], Action prob: [0.8605035  0.13949648], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3657216483422014, 0.6457460288315191, 0.16842116198742843, 0.2613658110231833], Action prob: [0.8613291  0.13867095], Action: 0, state: 0\n",
      "Sensor: [0.3566298832781189, 0.657833721497365, 0.22263758446633283, 0.2252664441363522], Action prob: [0.8618396  0.13816044], Action: 0, state: 0\n",
      "Sensor: [0.42190929884604345, 0.6355982284133772, 0.24261084987122644, 0.3418320543502408], Action prob: [0.8630154  0.13698456], Action: 0, state: 0\n",
      "Sensor: [0.36656935135607305, 0.6093269968254391, 0.23289713417677574, 0.1882257556303629], Action prob: [0.8625036  0.13749643], Action: 0, state: 1\n",
      "Sensor: [0.3249111196202482, 0.6681573103269363, 0.32349053515910986, 0.24020709212676808], Action prob: [0.8627763  0.13722372], Action: 0, state: 1\n",
      "Sensor: [0.38921415821644595, 0.6548063703535101, 0.20719774340017488, 0.2692918615171473], Action prob: [0.86308235 0.1369177 ], Action: 0, state: 1\n",
      "Sensor: [0.3706865606012522, 0.632098171043191, 0.21201227095825387, 0.31268773014520385], Action prob: [0.86298895 0.13701104], Action: 0, state: 1\n",
      "Sensor: [0.4113952607012669, 0.5962750696154842, 0.2387122460531919, 0.2635173410748483], Action prob: [0.8629763  0.13702363], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35477397194318844, 0.5742008965356248, 0.22793424417269445, 0.18771992972431778], Action prob: [0.86192584 0.13807413], Action: 0, state: 0\n",
      "Sensor: [0.40121550617780866, 0.6499112739364082, 0.18279512502067508, 0.239428335124765], Action prob: [0.862155   0.13784501], Action: 0, state: 0\n",
      "Sensor: [0.32197423983451806, 0.6362314937529132, 0.2417134235141269, 0.24690085677608214], Action prob: [0.861883   0.13811703], Action: 0, state: 0\n",
      "Sensor: [0.35827640948071926, 0.6294848789774593, 0.21526993545037146, 0.2501606269173264], Action prob: [0.8619599  0.13804016], Action: 0, state: 1\n",
      "Sensor: [0.3682483238264779, 0.6118134752127685, 0.23102205869048145, 0.20267067204796646], Action prob: [0.86183774 0.13816226], Action: 0, state: 2\n",
      "Sensor: [0.3747045935186169, 0.662237136992578, 0.23084218028532769, 0.2860842318153327], Action prob: [0.86246884 0.13753124], Action: 0, state: 2\n",
      "Sensor: [0.36424607543403964, 0.6582542832840301, 0.22971709835528523, 0.24379933299489984], Action prob: [0.86270183 0.13729814], Action: 0, state: 2\n",
      "Sensor: [0.36331171097862497, 0.5951605884569187, 0.22392424358066157, 0.2120688756950457], Action prob: [0.86215395 0.13784604], Action: 0, state: 3\n",
      "Sensor: [0.3655717264868932, 0.6512747215233161, 0.48043944140114475, 0.3375644652320158], Action prob: [0.8638354  0.13616459], Action: 0, state: 8\n",
      "Sensor: [0.6383009877003224, 0.6557876736968563, 0.24447766553725098, 0.6096887170620345], Action prob: [0.8672414  0.13275865], Action: 0, state: 8\n",
      "Sensor: [0.3687856377499915, 0.6414404013758388, 0.18571026810852712, 0.582100403705435], Action prob: [0.8664783  0.13352172], Action: 0, state: 8\n",
      "Sensor: [0.5805027766145053, 0.6178631781674861, 0.19590651730539926, 0.286202585109922], Action prob: [0.86666876 0.13333122], Action: 0, state: 8\n",
      "tensor([-3.5185, -0.4608, -0.3261, -0.2412, -0.1801, -0.1312, -1.1902, -0.0729,\n",
      "        -0.0417, -0.0137,  0.0089,  0.0287,  0.0469,  0.0633,  1.0537,  0.0863,\n",
      "         0.0992,  0.1114,  0.1211,  0.1290,  0.1352,  0.1412,  0.1456,  0.1242,\n",
      "         0.1048,  0.0905,  0.0772], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 27 is 3800, loss is 0.1336751865076826\n",
      "Sensor: [0.32819719470059877, 0.6185708614301743, 0.21075221847972986, 0.19655930102550406], Action prob: [0.76651824 0.2334817 ], Action: 0, state: 0\n",
      "Sensor: [0.2976643510497455, 0.6538486904981073, 0.2541983817885983, 0.22981492055688812], Action prob: [0.8115184  0.18848157], Action: 0, state: 0\n",
      "Sensor: [0.3500055977002194, 0.6528268099182715, 0.208069236991296, 0.21346169446316124], Action prob: [0.8340222 0.1659778], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.38021864031746216, 0.47522235182498407, 0.16206578829329718, 0.24211255262342402], Action prob: [0.8432057  0.15679435], Action: 0, state: 0\n",
      "Sensor: [0.3503348715698066, 0.6258385967641226, 0.2295956823419872, 0.24070538619578058], Action prob: [0.8492512  0.15074874], Action: 0, state: 1\n",
      "Sensor: [0.3633721238844266, 0.6833305793530424, 0.19838934787454116, 0.2645713381963767], Action prob: [0.8536168  0.14638329], Action: 0, state: 1\n",
      "Sensor: [0.3262844226091002, 0.5973231473195006, 0.23190497792539527, 0.2937547443243337], Action prob: [0.8552917  0.14470826], Action: 0, state: 2\n",
      "Sensor: [0.4104640002495184, 0.6286112500211943, 0.29163339224038864, 0.2300788950799515], Action prob: [0.85719615 0.14280388], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.3387298132836022, 0.6027556961730279, 0.2115675240603058, 0.2717881963758514], Action prob: [0.85713446 0.14286552], Action: 0, state: 2\n",
      "Sensor: [0.3624188353091119, 0.6743593091158299, 0.19736012445478934, 0.2322097391646397], Action prob: [0.8575466  0.14245333], Action: 0, state: 2\n",
      "Sensor: [0.34893399108439443, 0.5852754801254416, 0.20736504567969313, 0.25347204361456], Action prob: [0.8570641  0.14293583], Action: 0, state: 2\n",
      "Sensor: [0.38660549253549076, 0.6206063551659479, 0.2312861294811115, 0.2746406829964298], Action prob: [0.85754913 0.14245085], Action: 0, state: 3\n",
      "Sensor: [0.6168979110092174, 0.6105854035514338, 0.46261203836700004, 0.2205265623852593], Action prob: [0.86078006 0.13922   ], Action: 0, state: 8\n",
      "Sensor: [0.32451909222882247, 0.4461094019222793, 0.24482729933900385, 0.611653633075111], Action prob: [0.85929674 0.14070325], Action: 0, state: 8\n",
      "Sensor: [0.3827778760389368, 0.37139993352298434, 0.1927803432716764, 0.22021981286668513], Action prob: [0.8563282  0.14367181], Action: 0, state: 8\n",
      "Sensor: [0.4370503741245266, 0.3785557097820737, 0.15916723391915266, 0.5907737611729957], Action prob: [0.85577905 0.14422092], Action: 1, state: 8\n",
      "Sensor: [0.5857200831015575, 0.36523444341077627, 0.192566223200001, 0.3020543987404325], Action prob: [0.8560459  0.14395413], Action: 0, state: 8\n",
      "Sensor: [0.3415098187817271, 0.37216373468911407, 0.23595798551563746, 0.29870055788204525], Action prob: [0.8540837  0.14591625], Action: 0, state: 8\n",
      "Sensor: [0.335256353191765, 0.5338646534925381, 0.5655188312700669, 0.5370411025076112], Action prob: [0.85695946 0.14304058], Action: 0, state: 8\n",
      "Sensor: [0.5939095992946903, 0.6354975617059704, 0.22515094331879237, 0.23468094823245736], Action prob: [0.85960793 0.14039204], Action: 1, state: 8\n",
      "Sensor: [0.3489615434547486, 0.6308990494676604, 0.2505165206556256, 0.30205344724271943], Action prob: [0.85895634 0.14104366], Action: 0, state: 0\n",
      "Sensor: [0.32103469520412065, 0.6222821032897988, 0.19303613499769284, 0.2307494465327427], Action prob: [0.85775894 0.14224106], Action: 0, state: 0\n",
      "Sensor: [0.3411873654131451, 0.6117463177529378, 0.34821353023305934, 0.20227337462824135], Action prob: [0.85772854 0.14227146], Action: 0, state: 0\n",
      "Sensor: [0.3398935068096677, 0.6713558180098795, 0.2345779114605019, 0.42342030619017856], Action prob: [0.85866266 0.14133734], Action: 0, state: 0\n",
      "Sensor: [0.3446809525286321, 0.6430382525312279, 0.24345613549418194, 0.2908288871258563], Action prob: [0.8587302  0.14126982], Action: 0, state: 0\n",
      "Sensor: [0.4098416636822892, 0.6683789761717666, 0.20520393207438808, 0.2874491685065163], Action prob: [0.8592265  0.14077342], Action: 0, state: 0\n",
      "Sensor: [0.4127357209631915, 0.7013602508505119, 0.2261589631499058, 0.26464855866086356], Action prob: [0.85980684 0.14019322], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "tensor([-0.3168, -0.1331, -0.2458,  0.0157,  0.0740,  0.1234,  0.1631,  2.3162,\n",
      "         0.1959,  0.2245,  0.2521,  0.2659,  0.1809,  0.1122,  0.0496, -0.1204,\n",
      "        -0.0628, -0.1126, -0.1541, -2.4472, -0.1783, -0.1694, -0.1603, -0.1509,\n",
      "        -0.1433, -0.1360, -1.6920], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 28 is -10100, loss is 0.08331706391890374\n",
      "Sensor: [0.3222069721782122, 0.6215661104931645, 0.1764066324464805, 0.507169288170573], Action prob: [0.76800334 0.23199663], Action: 0, state: 0\n",
      "Sensor: [0.3285946089178175, 0.6356967597248266, 0.22569236826306283, 0.23234662494494163], Action prob: [0.80855626 0.19144371], Action: 0, state: 0\n",
      "Sensor: [0.4031577506355352, 0.6428472602680464, 0.19804752341563664, 0.21972704636027945], Action prob: [0.82809997 0.17190003], Action: 0, state: 0\n",
      "Sensor: [0.38729577175834, 0.4264220560749117, 0.19954608871242077, 0.2674534610631752], Action prob: [0.8350385  0.16496155], Action: 0, state: 1\n",
      "Sensor: [0.32551022152310505, 0.6598140713008638, 0.23096460600941363, 0.26612897761051996], Action prob: [0.84004545 0.15995461], Action: 0, state: 1\n",
      "Sensor: [0.3362262395793636, 0.6577313471190133, 0.22561485609561988, 0.2438990227771955], Action prob: [0.84323955 0.15676038], Action: 0, state: 2\n",
      "Sensor: [0.60830576462679, 0.3978117574703003, 0.21131384710183013, 0.29821849098295183], Action prob: [0.8453054  0.15469457], Action: 0, state: 3\n",
      "Sensor: [0.4216745096641699, 0.6086155891023535, 0.17301377925870165, 0.24241337999246215], Action prob: [0.8456631  0.15433697], Action: 0, state: 3\n",
      "Sensor: [0.39179380293068033, 0.626936499258311, 0.2099905575155314, 0.24831598829427548], Action prob: [0.84614366 0.1538564 ], Action: 0, state: 3\n",
      "Sensor: [0.39181694153012536, 0.6440847413527013, 0.19904946907207943, 0.21093420169397306], Action prob: [0.84643453 0.15356544], Action: 0, state: 3\n",
      "Sensor: [0.4032968074638196, 0.6630463574895834, 0.17867171745266539, 0.2817854037266328], Action prob: [0.8470074  0.15299256], Action: 0, state: 3\n",
      "Sensor: [0.39845211127316016, 0.3906701540003297, 0.20360699800359716, 0.2631387408641645], Action prob: [0.8450248  0.15497519], Action: 0, state: 3\n",
      "Sensor: [0.5818169928160888, 0.6236046828020093, 0.19137249633385905, 0.19943093706332204], Action prob: [0.84690434 0.15309566], Action: 1, state: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -700\n",
      "Sensor: [0.3837060078818087, 0.6459595044652209, 0.2056191075839305, 0.24509061784182654], Action prob: [0.8468765  0.15312351], Action: 0, state: 2\n",
      "Sensor: [0.5960092062775766, 0.6135380121939579, 0.18371535473470557, 0.27154321729815606], Action prob: [0.8485566  0.15144339], Action: 0, state: 9\n",
      "Sensor: [0.5700061887238266, 0.6171242038443678, 0.22243846026794195, 0.2806820951130296], Action prob: [0.8494334  0.15056653], Action: 1, state: 9\n",
      "Sensor: [0.5525177664910035, 0.3707814694319105, 0.21397923272340522, 0.23537315519231955], Action prob: [0.8475643  0.15243569], Action: 0, state: 9\n",
      "Sensor: [0.36872944771751665, 0.3453284587826523, 0.2574511348926142, 0.21318332306600635], Action prob: [0.8441537  0.15584628], Action: 0, state: 9\n",
      "Sensor: [0.6050988463493133, 0.6374666090439913, 0.23007883198597132, 0.24333552937015007], Action prob: [0.8468968  0.15310316], Action: 0, state: 9\n",
      "Sensor: [0.37587787856532817, 0.5652684854965796, 0.20652874159240084, 0.4722222545564676], Action prob: [0.8469205 0.1530795], Action: 0, state: 9\n",
      "Sensor: [0.39519169272040555, 0.6111342492675835, 0.20830031851342642, 0.531063490566519], Action prob: [0.84782183 0.15217815], Action: 0, state: 9\n",
      "Sensor: [0.38876686922386117, 0.6044215957046881, 0.5054161057777583, 0.22588440926746278], Action prob: [0.8487238 0.1512762], Action: 0, state: 9\n",
      "Sensor: [0.38473982080816455, 0.6198039259399819, 0.5449086063882196, 0.26005416925596936], Action prob: [0.84967726 0.15032272], Action: 1, state: 9\n",
      "Sensor: [0.33914471022095416, 0.6146290046176649, 0.2056279566529952, 0.5609974454513026], Action prob: [0.84938544 0.15061453], Action: 0, state: 9\n",
      "Sensor: [0.793227718124904, 0.7318224590824965, 0.2412177988743593, 0.24657677302377387], Action prob: [0.85280126 0.14719874], Action: 0, state: 9\n",
      "Sensor: [0.3270812297357198, 0.37508010086401056, 0.21469550839104784, 0.22541491098125005], Action prob: [0.84758884 0.15241112], Action: 0, state: 9\n",
      "Sensor: [0.3387936778676564, 0.6369267113227128, 0.5385259980202972, 0.21599991497398632], Action prob: [0.8478545 0.1521455], Action: 1, state: 9\n",
      "tensor([-8.1663e-01, -4.8479e-01, -2.9227e-01, -1.7175e-01, -7.4047e-02,\n",
      "         3.2609e-04,  4.1704e-02,  7.7043e-02,  1.0911e-01,  1.3802e-01,\n",
      "         1.6356e-01,  1.9064e-01,  2.3566e+00,  1.8176e-01,  1.4594e-01,\n",
      "         1.3295e+00,  8.9312e-02,  6.5901e-02,  4.1281e-02,  2.1091e-02,\n",
      "         2.6717e-03, -1.3893e-02, -3.3031e-01, -4.1111e-02, -5.1671e-02,\n",
      "        -6.3388e-02, -8.4715e-01], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 29 is -4600, loss is -0.06545786772514085\n",
      "Sensor: [0.33809045367215773, 0.606696905201658, 0.2416820983131456, 0.2805293363893902], Action prob: [0.7704659  0.22953403], Action: 0, state: 0\n",
      "Sensor: [0.6063427267487834, 0.6551561222482952, 0.18364036090500763, 0.24742396006416337], Action prob: [0.8135548  0.18644512], Action: 0, state: 1\n",
      "Sensor: [0.29124212671014, 0.6372604362923674, 0.21746326325872736, 0.20710657551797856], Action prob: [0.8290631  0.17093687], Action: 0, state: 1\n",
      "Sensor: [0.38176079323430967, 0.6784402315069489, 0.20804507280846907, 0.21926874926137938], Action prob: [0.8369894  0.16301066], Action: 0, state: 2\n",
      "Sensor: [0.30093352159397907, 0.6010845379949672, 0.2148023268537501, 0.2551981556106479], Action prob: [0.8397034  0.16029665], Action: 0, state: 2\n",
      "Sensor: [0.3291541276845218, 0.690340227123468, 0.22958991436012974, 0.22116463109469647], Action prob: [0.84215546 0.15784448], Action: 0, state: 2\n",
      "Sensor: [0.4414018639783034, 0.6381092709816965, 0.202285072031626, 0.19614535913270992], Action prob: [0.8440046  0.15599543], Action: 0, state: 3\n",
      "Sensor: [0.5139430983359805, 0.3910933478632878, 0.24089583276162688, 0.26329797756905604], Action prob: [0.8438112  0.15618883], Action: 0, state: 3\n",
      "Sensor: [0.34252599805625206, 0.6147451989342054, 0.5575481351459426, 0.24226206678844595], Action prob: [0.8449198  0.15508018], Action: 0, state: 3\n",
      "Sensor: [0.5969506897362553, 0.6648655733582938, 0.1779030390862076, 0.21711305632577035], Action prob: [0.84722614 0.15277387], Action: 0, state: 8\n",
      "Sensor: [0.3855969141160517, 0.3942016567409516, 0.18407534592909114, 0.28561543432856656], Action prob: [0.8440067  0.15599333], Action: 0, state: 8\n",
      "Sensor: [0.5846248507290057, 0.38763477993980505, 0.17829207824072582, 0.26555278627834544], Action prob: [0.8434244  0.15657559], Action: 1, state: 8\n",
      "Sensor: [0.3698996526064588, 0.5998699805664407, 0.21026135360269002, 0.28574395321433177], Action prob: [0.8432778  0.15672222], Action: 0, state: 0\n",
      "Sensor: [0.3581399300835523, 0.6140393662223137, 0.2544041912269126, 0.2643453825542384], Action prob: [0.8437994  0.15620063], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3277245625464572, 0.6765926358670469, 0.2241557678113231, 0.23501167231244996], Action prob: [0.84420544 0.15579452], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3435584563738036, 0.6153745013391434, 0.49992118404318286, 0.2522405756804947], Action prob: [0.8453618  0.15463823], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.41074672880275875, 0.706193942969687, 0.19632355682698371, 0.22383384794744002], Action prob: [0.8462424  0.15375757], Action: 0, state: 0\n",
      "Sensor: [0.3674654613853197, 0.6892807368953674, 0.20787056924165298, 0.21800170900529542], Action prob: [0.84592646 0.15407349], Action: 0, state: 0\n",
      "Sensor: [0.330283392913178, 0.6572236990234472, 0.21646945508486204, 0.230175052079564], Action prob: [0.84516686 0.15483318], Action: 0, state: 0\n",
      "Sensor: [0.3672661517511384, 0.6699761221976988, 0.21214875024319924, 0.2436328330476831], Action prob: [0.84525704 0.15474294], Action: 0, state: 1\n",
      "Sensor: [0.353088110134631, 0.6615382256566501, 0.21154130330447032, 0.2557226687496749], Action prob: [0.84519446 0.15480557], Action: 0, state: 1\n",
      "Sensor: [0.32000365514012824, 0.648814169636391, 0.43875060904632496, 0.2371272838502754], Action prob: [0.8456621  0.15433788], Action: 0, state: 1\n",
      "Sensor: [0.39758293591145266, 0.6686954606854983, 0.23898126629779262, 0.23826644163596117], Action prob: [0.84621537 0.15378463], Action: 0, state: 1\n",
      "Sensor: [0.4502933320686581, 0.678336510147263, 0.23217280931757633, 0.2399727096694228], Action prob: [0.84679615 0.15320393], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.3931532063106164, 0.5977809392816723, 0.21588904590362865, 0.26763762780943334], Action prob: [0.8458627  0.15413737], Action: 0, state: 1\n",
      "tensor([-0.5480, -0.2511, -0.0791,  0.0381,  0.1377,  0.2237,  0.2703,  0.3159,\n",
      "         0.3517,  0.1362, -0.0536, -2.4897, -0.1772, -1.4678, -1.4718, -1.2698,\n",
      "        -0.0965, -0.0663, -0.0390, -0.0167,  0.0034,  0.0212,  0.0375,  0.5664,\n",
      "         0.0566], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 30 is 7200, loss is 0.23470103006348045\n",
      "Sensor: [0.3816164712886791, 0.6862773868169292, 0.2485952998944605, 0.2636112777003347], Action prob: [0.7645454  0.23545462], Action: 0, state: 0\n",
      "Sensor: [0.3893602473106673, 0.5913572136182346, 0.19411799494070897, 0.2580593089489497], Action prob: [0.7974813  0.20251864], Action: 0, state: 0\n",
      "Sensor: [0.35736289911538266, 0.6493863636703816, 0.19872625124829052, 0.4204417318083639], Action prob: [0.8117196  0.18828042], Action: 0, state: 0\n",
      "Sensor: [0.4090079247921065, 0.6298799784900087, 0.20167228661742584, 0.254429986526499], Action prob: [0.8167517  0.18324824], Action: 0, state: 1\n",
      "Sensor: [0.42370991950103176, 0.6553125125765574, 0.18941371190610456, 0.26395617929489407], Action prob: [0.819182   0.18081802], Action: 0, state: 1\n",
      "Sensor: [0.36617670849303324, 0.6561229358072774, 0.22378853895380937, 0.26922769962636606], Action prob: [0.82012576 0.1798742 ], Action: 0, state: 2\n",
      "Sensor: [0.29956498819382704, 0.6044053528195635, 0.18885089070009725, 0.22157413795682082], Action prob: [0.81925815 0.18074183], Action: 0, state: 2\n",
      "Sensor: [0.3547746275947803, 0.37524561804317236, 0.21098845749665807, 0.2593201027412051], Action prob: [0.8172142  0.18278582], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "Sensor: [0.3746986080580322, 0.6214974954869685, 0.23780690148749625, 0.298495309858413], Action prob: [0.81874967 0.18125033], Action: 0, state: 2\n",
      "Sensor: [0.3359757217499483, 0.6337821596615466, 0.2268811110458351, 0.25675762784577805], Action prob: [0.819455   0.18054493], Action: 0, state: 2\n",
      "Sensor: [0.41515505444814765, 0.6742410790442966, 0.24358290541487249, 0.24263779050923737], Action prob: [0.8209758  0.17902425], Action: 0, state: 3\n",
      "Sensor: [0.3475298583410615, 0.3835362214510244, 0.22621015509143994, 0.25763326964437727], Action prob: [0.81829166 0.1817084 ], Action: 0, state: 3\n",
      "Sensor: [0.34488493064858616, 0.3728359695053845, 0.21489338415007353, 0.2183263841425572], Action prob: [0.8160892  0.18391082], Action: 1, state: 9\n",
      "Sensor: [0.2959336447755772, 0.6733753655578322, 0.19672905120629536, 0.25009203685439624], Action prob: [0.81745356 0.18254647], Action: 0, state: 0\n",
      "Sensor: [0.35226708631770837, 0.6929957133197292, 0.17869471287373848, 0.18072937020665447], Action prob: [0.8190678  0.18093218], Action: 0, state: 1\n",
      "Sensor: [0.3318744465750966, 0.6182904826575513, 0.22448512261363032, 0.2050147191111122], Action prob: [0.81919974 0.18080026], Action: 0, state: 1\n",
      "Sensor: [0.2706163645499551, 0.6354388973326799, 0.24499983305786094, 0.21990059555333402], Action prob: [0.8189826  0.18101734], Action: 0, state: 1\n",
      "Sensor: [0.37285813953721847, 0.6498156801142922, 0.17780802438488583, 0.2806392129605306], Action prob: [0.8200851 0.1799149], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "Sensor: [0.44018702382882113, 0.5778775414184312, 0.23716259892290803, 0.3129890927131767], Action prob: [0.82089686 0.17910309], Action: 0, state: 1\n",
      "Sensor: [0.30410875783365676, 0.6544517478668317, 0.20487372991687686, 0.22604656444950155], Action prob: [0.8201921  0.17980796], Action: 0, state: 2\n",
      "Sensor: [0.3853482517939745, 0.6451673185992086, 0.22345245630878066, 0.27295584249050564], Action prob: [0.8208273  0.17917266], Action: 0, state: 2\n",
      "Sensor: [0.36714461434839973, 0.6080480096306701, 0.1960454672308125, 0.28346302203464435], Action prob: [0.82055706 0.179443  ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.37101810437821514, 0.5718571463240135, 0.2464754500409251, 0.30136025047311293], Action prob: [0.8203186  0.17968145], Action: 0, state: 1\n",
      "Sensor: [0.36346012611212364, 0.6170047626355717, 0.21149619821462942, 0.2667463690860153], Action prob: [0.8202805  0.17971954], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-0.7437, -0.4899, -0.3386, -0.2394, -0.1570, -0.0934, -0.0369, -0.0343,\n",
      "        -0.0166,  0.0248,  0.0475,  0.0705,  0.2754,  0.0659,  0.0928,  0.1177,\n",
      "         0.1401,  1.3574,  0.1445,  0.1592,  0.1715,  1.5941,  0.1891,  1.7293],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 31 is 14100, loss is -0.16792311157296166\n",
      "Sensor: [0.3527377247489736, 0.5884201364441674, 0.19254803770480866, 0.29596899379249486], Action prob: [0.7650605  0.23493952], Action: 0, state: 0\n",
      "Sensor: [0.3793577907262014, 0.6417361624592555, 0.19856312895474634, 0.25149849792060375], Action prob: [0.7977849  0.20221512], Action: 0, state: 0\n",
      "Sensor: [0.37411451633970083, 0.6983125813448274, 0.19803087440975237, 0.29774347902691933], Action prob: [0.8107181  0.18928188], Action: 0, state: 0\n",
      "Sensor: [0.4038291953407223, 0.6434126583081481, 0.17824373603996532, 0.2308820924898243], Action prob: [0.81447667 0.18552329], Action: 0, state: 0\n",
      "Sensor: [0.3605346711170866, 0.6181442723947068, 0.23663463461618708, 0.22781801126675985], Action prob: [0.8153311  0.18466891], Action: 0, state: 0\n",
      "Sensor: [0.3745902849649071, 0.6035616379415532, 0.21009793085725811, 0.27056789441642076], Action prob: [0.8160142  0.18398575], Action: 0, state: 1\n",
      "Sensor: [0.35779692565831983, 0.6175474200616529, 0.20776475068340233, 0.24007871746594422], Action prob: [0.8162543 0.1837457], Action: 0, state: 1\n",
      "Sensor: [0.35902420723651873, 0.5945880400320558, 0.1950386161057471, 0.24070695649142934], Action prob: [0.8161047  0.18389527], Action: 0, state: 1\n",
      "Sensor: [0.3496236806201841, 0.4028214095534395, 0.23652936530888272, 0.29284221138044886], Action prob: [0.81429857 0.18570149], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -2500\n",
      "Sensor: [0.3004655759178067, 0.6039631071931651, 0.21021429699030386, 0.22238669726003585], Action prob: [0.8142875  0.18571255], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.37456853203998036, 0.5869536857600278, 0.17661966241458874, 0.22925393723216944], Action prob: [0.81499285 0.18500713], Action: 0, state: 0\n",
      "Sensor: [0.3532363013083008, 0.6854451288896162, 0.1728548407697384, 0.2575113183012056], Action prob: [0.81623924 0.18376075], Action: 0, state: 1\n",
      "Sensor: [0.34342803370276925, 0.6161078363441148, 0.2468477447406585, 0.2463482028339978], Action prob: [0.81642383 0.18357618], Action: 0, state: 1\n",
      "Sensor: [0.3085771825272885, 0.6329727326241216, 0.20055347646402877, 0.21092215260374458], Action prob: [0.81602556 0.18397449], Action: 0, state: 1\n",
      "Sensor: [0.3709115077503755, 0.6729224120404883, 0.2569354718496922, 0.25536064856924273], Action prob: [0.8171973  0.18280268], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3141186746836083, 0.6595581753634532, 0.18755802203475164, 0.18921873268843692], Action prob: [0.8166647  0.18333532], Action: 0, state: 0\n",
      "Sensor: [0.3701863898479794, 0.6078237809240282, 0.20632601255282276, 0.3035486322312705], Action prob: [0.8168791  0.18312097], Action: 0, state: 0\n",
      "Sensor: [0.3567023070002891, 0.6210821139411733, 0.23307156545315613, 0.2187030917929287], Action prob: [0.81667805 0.18332198], Action: 0, state: 1\n",
      "Sensor: [0.3334070099104364, 0.6097837686492491, 0.2171907853094565, 0.26649859435067763], Action prob: [0.81643546 0.18356457], Action: 0, state: 1\n",
      "Sensor: [0.30006077091286126, 0.5531203384073247, 0.24351141881573676, 0.23999621404416885], Action prob: [0.8153429  0.18465716], Action: 0, state: 1\n",
      "Sensor: [0.3841511007803217, 0.61395026457411, 0.23901178345534901, 0.20981464960190083], Action prob: [0.816029   0.18397099], Action: 0, state: 1\n",
      "tensor([-6.9053e-01, -4.5504e-01, -3.1613e-01, -2.1493e-01, -1.2972e-01,\n",
      "        -6.1228e-02, -2.0178e-04,  5.4848e-02,  8.6955e-01, -1.6081e-01,\n",
      "         3.0171e-03,  3.8629e-02,  7.1108e-02,  1.0049e-01,  1.0579e+00,\n",
      "         1.3931e-01,  1.6285e-01,  1.8205e-01,  1.9957e-01,  2.1664e-01,\n",
      "         2.2955e-01], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 32 is 15200, loss is -0.061756008256840564\n",
      "Sensor: [0.3216677836028409, 0.6544414151275882, 0.21239897735005786, 0.24456342663824124], Action prob: [0.77216786 0.22783211], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3271119535774289, 0.6643091415225519, 0.19034403192860397, 0.3396957990187511], Action prob: [0.8043568  0.19564322], Action: 0, state: 0\n",
      "Sensor: [0.3081632488145572, 0.6509967960365723, 0.21229529185167026, 0.2532244871317242], Action prob: [0.81419617 0.18580382], Action: 0, state: 0\n",
      "Sensor: [0.3434116376629473, 0.6744097080771903, 0.22943215366322964, 0.24409172488136233], Action prob: [0.81750274 0.18249725], Action: 0, state: 1\n",
      "Sensor: [0.36543100347310176, 0.6481507838752636, 0.2301594992935809, 0.20155537305448468], Action prob: [0.8184822  0.18151772], Action: 0, state: 2\n",
      "Sensor: [0.30181974454217064, 0.6074222526142313, 0.22096445294427136, 0.27618839205660717], Action prob: [0.8183305  0.18166952], Action: 0, state: 2\n",
      "Sensor: [0.30702920614223844, 0.6515521692864816, 0.20802144066510217, 0.30730977637422124], Action prob: [0.81898504 0.18101498], Action: 0, state: 2\n",
      "Sensor: [0.34127676478932356, 0.6545783410471573, 0.23093252255614238, 0.2519163392541988], Action prob: [0.81951314 0.18048686], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1600\n",
      "Sensor: [0.42339072672377887, 0.6898071264645576, 0.22725912209562066, 0.28572873246985425], Action prob: [0.82103586 0.17896415], Action: 0, state: 1\n",
      "Sensor: [0.34155107318339345, 0.6730231175738712, 0.23930684160785895, 0.22408345417304548], Action prob: [0.8205467  0.17945331], Action: 0, state: 2\n",
      "Sensor: [0.38516900054014874, 0.6620492979135926, 0.19796974393991118, 0.2608615057884606], Action prob: [0.8206013  0.17939869], Action: 0, state: 2\n",
      "Sensor: [0.39700625570299103, 0.5846164339676215, 0.19532440332330983, 0.220061914040731], Action prob: [0.819626   0.18037404], Action: 0, state: 2\n",
      "Sensor: [0.35575289794252757, 0.5810638529480663, 0.23305314777893615, 0.2794083403606132], Action prob: [0.81905156 0.18094842], Action: 0, state: 2\n",
      "Sensor: [0.32339775593403614, 0.6427286999626438, 0.19723138269010132, 0.20933930781346746], Action prob: [0.81873405 0.18126601], Action: 0, state: 3\n",
      "Sensor: [0.812201801798246, 0.5816075701778501, 0.20263795326295572, 0.2719080464488119], Action prob: [0.8229153  0.17708468], Action: 1, state: 8\n",
      "Sensor: [0.5554364895866243, 0.3712199745896998, 0.21314371300226154, 0.24260089382932437], Action prob: [0.8201229  0.17987713], Action: 0, state: 8\n",
      "Sensor: [0.5715401332378619, 0.6005275289276197, 0.21472776951873956, 0.2288016390072915], Action prob: [0.82086605 0.17913395], Action: 0, state: 8\n",
      "Sensor: [0.39602539896952543, 0.4284055562951235, 0.24316978692746768, 0.2526880120134001], Action prob: [0.81819206 0.18180797], Action: 1, state: 8\n",
      "Sensor: [0.3182179721882313, 0.684049259218605, 0.2294092718711124, 0.2604538613158931], Action prob: [0.81870943 0.18129064], Action: 0, state: 0\n",
      "Sensor: [0.3531035632999967, 0.5928497396280528, 0.33901211939236015, 0.26092133394523415], Action prob: [0.8191148  0.18088515], Action: 0, state: 0\n",
      "Sensor: [0.4005002214928792, 0.5301327908148348, 0.20038217316702447, 0.23180961210370135], Action prob: [0.8185038  0.18149623], Action: 0, state: 0\n",
      "Sensor: [0.3704690169748268, 0.6348048512087019, 0.21909220649188693, 0.3101792097060041], Action prob: [0.8192867  0.18071328], Action: 0, state: 0\n",
      "Sensor: [0.42222708202885817, 0.6563845619656784, 0.20811023036421195, 0.2795107340481342], Action prob: [0.8203739  0.17962608], Action: 0, state: 1\n",
      "Sensor: [0.3399901755698444, 0.6543427432588319, 0.1979754853619426, 0.1976418177100447], Action prob: [0.8196442  0.18035571], Action: 0, state: 2\n",
      "tensor([-3.7132, -0.4527, -0.2679, -0.1361, -0.0344,  0.0564,  0.1374,  1.8050,\n",
      "         0.0777,  0.1367,  0.1896,  0.2388,  0.2828,  0.3075,  1.5280,  0.0583,\n",
      "        -0.0479, -1.2266, -0.1161, -0.0898, -0.0664, -0.0456, -0.0285, -0.0151],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 33 is 2200, loss is 0.05925321563844115\n",
      "Sensor: [0.31932732443344714, 0.6400995554745429, 0.22858113720886203, 0.5005843781721636], Action prob: [0.77851605 0.22148392], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3785848532468911, 0.5012122972511431, 0.20819739019090858, 0.281279655614909], Action prob: [0.8070608  0.19293925], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35769787889218424, 0.633800992418206, 0.15365794888757744, 0.2234536917869624], Action prob: [0.81599766 0.18400234], Action: 0, state: 0\n",
      "Sensor: [0.5737723098798783, 0.6405056242423586, 0.2399593754848283, 0.2182702950518062], Action prob: [0.8207811  0.17921884], Action: 0, state: 1\n",
      "Sensor: [0.34281404014153505, 0.697250755424334, 0.20193984957289576, 0.22082570693858208], Action prob: [0.8209982  0.17900187], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "Sensor: [0.3623135140246799, 0.6024884224460364, 0.17349582850665904, 0.296470022145242], Action prob: [0.82070446 0.17929555], Action: 0, state: 0\n",
      "Sensor: [0.36366131597375745, 0.7303923397998713, 0.20289686885994176, 0.289944845624961], Action prob: [0.82201546 0.1779845 ], Action: 0, state: 0\n",
      "Sensor: [0.2740848234399683, 0.5554168058755145, 0.19658557584307, 0.40593823690233954], Action prob: [0.82072735 0.17927273], Action: 0, state: 0\n",
      "Sensor: [0.330883651235913, 0.5771927804200472, 0.23680186067175696, 0.26401642905744793], Action prob: [0.82008183 0.17991814], Action: 0, state: 1\n",
      "Sensor: [0.3564226743336983, 0.6094403571086163, 0.20644239809792808, 0.2237020352768295], Action prob: [0.8200032  0.17999677], Action: 0, state: 1\n",
      "Sensor: [0.3831789385752648, 0.591452817396998, 0.19094769000904926, 0.2617144003565036], Action prob: [0.82012403 0.17987604], Action: 0, state: 1\n",
      "Sensor: [0.33346211123393993, 0.5478600767800151, 0.2383586683109954, 0.2217934365676427], Action prob: [0.8191583 0.1808417], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3831010534639546, 0.7092611312921825, 0.21031876960976117, 0.2240677832332057], Action prob: [0.82090473 0.17909528], Action: 0, state: 1\n",
      "Sensor: [0.3851080813001763, 0.634400853634163, 0.24747406728897972, 0.27829315553846445], Action prob: [0.82150126 0.17849879], Action: 0, state: 2\n",
      "Sensor: [0.3397772050842915, 0.6365500996120843, 0.28350291460219573, 0.2596483988526817], Action prob: [0.82138515 0.17861478], Action: 0, state: 2\n",
      "Sensor: [0.40578725096279067, 0.39267455579204474, 0.1898127541173126, 0.22863922471588147], Action prob: [0.81873757 0.18126248], Action: 0, state: 3\n",
      "Sensor: [0.3937196499093076, 0.3757906518316693, 0.18438903468806406, 0.26714466384259833], Action prob: [0.81683403 0.18316597], Action: 0, state: 3\n",
      "Sensor: [0.39690491954492024, 0.6372842183685451, 0.2669301609583408, 0.2667524621080595], Action prob: [0.8192631  0.18073684], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "Sensor: [0.4191403298502359, 0.5821082169701205, 0.2373523364139165, 0.28257295298676904], Action prob: [0.8204763  0.17952369], Action: 0, state: 2\n",
      "Sensor: [0.38000062428717934, 0.6142417201198311, 0.512084833027611, 0.21032668099323798], Action prob: [0.8215682 0.1784318], Action: 0, state: 2\n",
      "Sensor: [0.34880523777585837, 0.6342158355395549, 0.19141351369320092, 0.23528625135021192], Action prob: [0.8212361  0.17876391], Action: 0, state: 2\n",
      "tensor([-3.0108, -2.7766, -0.2873, -0.1907, -0.9700, -0.2305, -0.1580, -0.0942,\n",
      "        -0.0422,  0.0049,  0.0475,  0.0863,  0.1191,  0.1461,  0.1707,  0.1886,\n",
      "         0.2037,  1.8106,  0.2056,  0.2182,  0.2321], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 34 is 13100, loss is 0.2060463972500836\n",
      "Sensor: [0.3849064253820673, 0.6264641829571238, 0.20277588915918793, 0.4388056234797551], Action prob: [0.7709721  0.22902796], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.436627085536042, 0.6732932606115634, 0.22677244202787247, 0.2756080069234544], Action prob: [0.80032283 0.19967717], Action: 0, state: 0\n",
      "Sensor: [0.3484725285106179, 0.6160291677378851, 0.19511072783269393, 0.23484618054809303], Action prob: [0.80665815 0.19334185], Action: 0, state: 0\n",
      "Sensor: [0.3086270025374383, 0.6302077098539481, 0.26970790749931, 0.2666155704658883], Action prob: [0.80768496 0.19231506], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.34330451998446865, 0.6197346152799144, 0.21052042460791037, 0.26846895543933436], Action prob: [0.80794835 0.19205157], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.3626937227421598, 0.6182057867520041, 0.21459545816126657, 0.22506443114552188], Action prob: [0.80803806 0.19196202], Action: 0, state: 0\n",
      "Sensor: [0.3827636260010232, 0.6310604646755931, 0.2068771340185904, 0.2339571581916266], Action prob: [0.8085219  0.19147807], Action: 0, state: 1\n",
      "Sensor: [0.38950278100578645, 0.6223899933594269, 0.20813387118459478, 0.24429875453986674], Action prob: [0.8087771  0.19122289], Action: 0, state: 1\n",
      "Sensor: [0.3773376706523424, 0.6182126785915897, 0.2443514266075805, 0.2339464234030285], Action prob: [0.8087581  0.19124192], Action: 0, state: 2\n",
      "Sensor: [0.31599074100512475, 0.6422914782594215, 0.21917306958702282, 0.2368516287136325], Action prob: [0.80836457 0.1916354 ], Action: 0, state: 2\n",
      "Sensor: [0.273976247500685, 0.7162569056119721, 0.20318382466054719, 0.22015600348834238], Action prob: [0.80845857 0.19154142], Action: 0, state: 3\n",
      "Sensor: [0.2982369330549451, 0.572345223347781, 0.24405448201707378, 0.20093465057429563], Action prob: [0.8072693 0.1927307], Action: 0, state: 3\n",
      "Sensor: [0.34440954876359486, 0.6302616755201652, 0.191241161334122, 0.2688029378539443], Action prob: [0.8078584  0.19214152], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -700\n",
      "Sensor: [0.34467257026656595, 0.6242014953437773, 0.20204374021021043, 0.2318808313260516], Action prob: [0.80798477 0.19201525], Action: 0, state: 2\n",
      "Sensor: [0.3794452668674917, 0.6543606354602877, 0.19192039418724027, 0.27583029989171187], Action prob: [0.8088644  0.19113559], Action: 0, state: 2\n",
      "Sensor: [0.3597492239516624, 0.6471812338662805, 0.18940204639347483, 0.26126564125273183], Action prob: [0.8089534  0.19104664], Action: 0, state: 2\n",
      "Sensor: [0.38949194999077075, 0.6851349986063558, 0.5162668800067841, 0.2075751675777684], Action prob: [0.81047803 0.18952197], Action: 0, state: 3\n",
      "Sensor: [0.45295134462171294, 0.5953572615938615, 0.16600702651499455, 0.22070231290183331], Action prob: [0.8100896  0.18991041], Action: 0, state: 3\n",
      "Sensor: [0.4247931121183761, 0.61377851937163, 0.5410777866363164, 0.23254806664231167], Action prob: [0.8105018  0.18949816], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "tensor([-3.3508, -0.4171, -0.2467, -0.8214, -0.8209, -0.2184, -0.1271, -0.0453,\n",
      "         0.0200,  0.0788,  0.1116,  0.1428,  1.3076,  0.1351,  0.1691,  0.2002,\n",
      "         0.2151,  0.2322,  1.9403], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 35 is 9100, loss is 0.0786780253237466\n",
      "Sensor: [0.336816911266233, 0.6247268365160629, 0.19614800159139154, 0.26906746584496843], Action prob: [0.7585716  0.24142839], Action: 0, state: 0\n",
      "Sensor: [0.3706722124549603, 0.7161638408561202, 0.24556286644448064, 0.5093869046793964], Action prob: [0.78874195 0.21125802], Action: 0, state: 0\n",
      "Sensor: [0.40407022605584086, 0.6192526425598394, 0.19629240513173468, 0.27080004343548425], Action prob: [0.7951277  0.20487231], Action: 0, state: 0\n",
      "Sensor: [0.4003054860506248, 0.621920985960096, 0.20951409277862948, 0.24547732644433873], Action prob: [0.7956046  0.20439547], Action: 0, state: 0\n",
      "Sensor: [0.34143193147853573, 0.6535533321350704, 0.2466129922468767, 0.2787503592126889], Action prob: [0.7954561 0.2045439], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35356452271728034, 0.6381343968293539, 0.17017800556155926, 0.23442121600106203], Action prob: [0.7950799  0.20492007], Action: 0, state: 0\n",
      "Sensor: [0.3339849921368998, 0.5891920164249237, 0.18072351786120872, 0.20319288197765117], Action prob: [0.7940924  0.20590758], Action: 0, state: 0\n",
      "Sensor: [0.37855607058795465, 0.651927694469499, 0.23707132585297483, 0.3276563386768881], Action prob: [0.7955195  0.20448051], Action: 0, state: 1\n",
      "Sensor: [0.31799821685442897, 0.5332625621299049, 0.2339492849285136, 0.22724660397098406], Action prob: [0.7940392  0.20596077], Action: 0, state: 1\n",
      "Sensor: [0.28446428526271467, 0.6387833335668804, 0.22769161766595275, 0.2076892314216152], Action prob: [0.7938297  0.20617029], Action: 0, state: 2\n",
      "Sensor: [0.3999959505676542, 0.6008464804738611, 0.2319585843122931, 0.23215255624719958], Action prob: [0.7946308  0.20536919], Action: 0, state: 2\n",
      "Sensor: [0.34794512936900496, 0.5309325076592408, 0.22153287987576983, 0.25419833472207654], Action prob: [0.79380906 0.20619099], Action: 0, state: 2\n",
      "Sensor: [0.3794516617121937, 0.6405970275631993, 0.20746503950972062, 0.21157470815055696], Action prob: [0.7945595  0.20544052], Action: 0, state: 2\n",
      "Sensor: [0.37372790039928616, 0.6001983565535589, 0.19316162069046258, 0.25640652396509644], Action prob: [0.7946736  0.20532644], Action: 0, state: 2\n",
      "Sensor: [0.4043779385431395, 0.645212633165752, 0.2414829956591475, 0.25860710242397655], Action prob: [0.795615   0.20438507], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "Sensor: [0.36706397492009246, 0.6428563898375387, 0.22908703488042287, 0.3273015257633109], Action prob: [0.79607254 0.20392749], Action: 0, state: 1\n",
      "Sensor: [0.3975480287482472, 0.5932783312353432, 0.21168932798854195, 0.17462148355683513], Action prob: [0.7952112  0.20478886], Action: 0, state: 2\n",
      "Sensor: [0.3549836582125985, 0.3681255477349243, 0.17991512741485072, 0.23412653010340698], Action prob: [0.7919393 0.2080606], Action: 0, state: 3\n",
      "Sensor: [0.387529996494227, 0.6432034101208077, 0.22119233313413492, 0.21116248424414238], Action prob: [0.79356086 0.2064391 ], Action: 0, state: 3\n",
      "Sensor: [0.3319294843676315, 0.3852843452654699, 0.23741458561950166, 0.5260244156880611], Action prob: [0.79306465 0.20693533], Action: 0, state: 8\n",
      "Sensor: [0.7160599665933899, 0.614280495600595, 0.14107595119504227, 0.2363240470081271], Action prob: [0.7969332  0.20306677], Action: 1, state: 8\n",
      "Sensor: [0.3518910633422154, 0.393787631097378, 0.20169824551935503, 0.26665829550649756], Action prob: [0.7931974  0.20680258], Action: 0, state: 8\n",
      "Sensor: [0.32078252245442174, 0.4252179932361608, 0.17555502373058132, 0.2436153434787267], Action prob: [0.7910213  0.20897874], Action: 0, state: 8\n",
      "Sensor: [0.5754494775083385, 0.632897723463977, 0.2309458685916758, 0.2664762720411629], Action prob: [0.7951234  0.20487662], Action: 0, state: 8\n",
      "Sensor: [0.397384884052537, 0.4410854989387022, 0.21415572012730605, 0.25561986129224884], Action prob: [0.7935146  0.20648539], Action: 0, state: 8\n",
      "Sensor: [0.3287003193223944, 0.3880993087710502, 0.2528496710495176, 0.2862913792869871], Action prob: [0.7915573  0.20844264], Action: 0, state: 8\n",
      "Sensor: [0.36622152680746384, 0.3804163001901242, 0.25100852062260687, 0.29188940696596904], Action prob: [0.7909431  0.20905688], Action: 1, state: 8\n",
      "tensor([-0.7529, -0.5187, -0.3891, -0.2880, -1.4372, -0.1668, -0.0940, -0.0343,\n",
      "         0.0195,  0.0621,  0.1005,  0.1361,  0.1663,  0.1945,  1.5166,  0.2151,\n",
      "         0.2367,  0.2535,  0.2606,  0.2059,  1.0625,  0.1093,  0.0688,  0.0300,\n",
      "        -0.0024, -0.0325, -0.3996], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 36 is -13300, loss is -0.019345955147688724\n",
      "Sensor: [0.3451187252126964, 0.6174047035217489, 0.22030712780983647, 0.2519146979099633], Action prob: [0.75102395 0.248976  ], Action: 0, state: 0\n",
      "Sensor: [0.28890622262515253, 0.6727375297000288, 0.17546251595089996, 0.2305727901013984], Action prob: [0.7760724 0.2239276], Action: 0, state: 0\n",
      "Sensor: [0.3740686262649636, 0.70248421367925, 0.2621079556567148, 0.22136374581480145], Action prob: [0.7834858 0.2165143], Action: 0, state: 0\n",
      "Sensor: [0.3167886905321757, 0.6268148203022932, 0.22439788471390806, 0.22905435321232218], Action prob: [0.78343236 0.21656767], Action: 0, state: 0\n",
      "Sensor: [0.3160116711217744, 0.617861954030759, 0.24137658770796014, 0.24549078662016108], Action prob: [0.78278244 0.21721753], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3477693119356667, 0.6474773534827739, 0.18925005031584663, 0.575525978474165], Action prob: [0.7844776  0.21552242], Action: 0, state: 0\n",
      "Sensor: [0.3376884316962385, 0.651574974754347, 0.17930696701055387, 0.21933256562671166], Action prob: [0.7838137  0.21618629], Action: 0, state: 0\n",
      "Sensor: [0.37071187776698605, 0.6938144826176765, 0.2270003795777214, 0.21356691846481304], Action prob: [0.7841448 0.2158552], Action: 0, state: 0\n",
      "Sensor: [0.30444274819466466, 0.6509358130459918, 0.1727938141879796, 0.2514848433572812], Action prob: [0.78327245 0.21672754], Action: 0, state: 1\n",
      "Sensor: [0.3300554999185545, 0.6807832688942855, 0.25225470488729085, 0.23095347648466508], Action prob: [0.7835356 0.2164644], Action: 0, state: 2\n",
      "Sensor: [0.38128711019266237, 0.6160896431162769, 0.1875835850391685, 0.24170400661274855], Action prob: [0.78342646 0.21657349], Action: 0, state: 2\n",
      "Sensor: [0.36511050408372936, 0.6660368606328659, 0.1787253772414786, 0.219310272604652], Action prob: [0.7834723  0.21652772], Action: 0, state: 2\n",
      "Sensor: [0.34145064959590454, 0.6178518788123264, 0.3463754358799397, 0.2820019286954254], Action prob: [0.78366303 0.21633703], Action: 0, state: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3433146945223128, 0.6678319868630834, 0.22727339266404456, 0.29165308807496193], Action prob: [0.78410107 0.21589896], Action: 0, state: 2\n",
      "Sensor: [0.40470790824836933, 0.6478948135571214, 0.20251849076880224, 0.22716075846185071], Action prob: [0.7841356  0.21586439], Action: 0, state: 3\n",
      "Sensor: [0.3546195737018961, 0.6030722255255423, 0.4962931964330509, 0.48612785895159605], Action prob: [0.78524125 0.21475881], Action: 0, state: 8\n",
      "Sensor: [0.38174780139655123, 0.34820976406100096, 0.2014880075974003, 0.22739329835569436], Action prob: [0.7815322  0.21846782], Action: 0, state: 8\n",
      "Sensor: [0.5400703576533582, 0.6491242939939429, 0.2068879722634723, 0.21715349986383994], Action prob: [0.7836141  0.21638587], Action: 0, state: 8\n",
      "Sensor: [0.5663307951700167, 0.6679370149361681, 0.21624932320892748, 0.1955824425518224], Action prob: [0.78515184 0.21484813], Action: 0, state: 8\n",
      "Sensor: [0.40987653756994175, 0.4161112159349601, 0.2464894003200481, 0.5019030576036972], Action prob: [0.783456   0.21654397], Action: 0, state: 8\n",
      "Sensor: [0.5972558218895633, 0.6447578422449638, 0.189632653217333, 0.25425459071000495], Action prob: [0.785303 0.214697], Action: 0, state: 8\n",
      "Sensor: [0.39009530436006506, 0.6519817975770552, 0.2204014520102777, 0.5068199219034691], Action prob: [0.7856391  0.21436086], Action: 1, state: 8\n",
      "Sensor: [0.4033970965187882, 0.651812032163995, 0.19630904364662588, 0.2883984262306203], Action prob: [0.7849927 0.2150073], Action: 0, state: 0\n",
      "Sensor: [0.38253251857524473, 0.6793804694532095, 0.2181145740376657, 0.2604310684091977], Action prob: [0.7846173  0.21538273], Action: 0, state: 0\n",
      "Sensor: [0.33848707429573155, 0.6741248779158419, 0.2509914164707496, 0.28154418745080345], Action prob: [0.7843087  0.21569134], Action: 0, state: 1\n",
      "Sensor: [0.3465528893247012, 0.6570420565346198, 0.21604178471454702, 0.22158403863038362], Action prob: [0.7837996 0.2162004], Action: 0, state: 1\n",
      "Sensor: [0.4377623800412768, 0.7044563693829382, 0.18359930387167445, 0.21180999407509976], Action prob: [0.78466713 0.21533291], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.36069908868703376, 0.6908276949461551, 0.23351820780089286, 0.24478788577658134], Action prob: [0.78454894 0.21545112], Action: 0, state: 1\n",
      "tensor([-0.7371, -0.4990, -0.3474, -0.2272, -0.7463, -0.0702,  0.0166,  0.0947,\n",
      "         0.1592,  0.2097,  0.2561,  0.2971,  0.3338,  0.3664,  0.3852,  0.2822,\n",
      "         0.1967,  0.1113,  0.0369, -0.0285, -0.0884, -0.9042, -0.1261, -0.1121,\n",
      "        -0.1005, -0.0901, -0.5149, -0.0776], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 37 is -3200, loss is 0.06869631705372789\n",
      "Sensor: [0.36369660335395065, 0.6494159346036057, 0.1949956957117388, 0.23497617019963432], Action prob: [0.74118155 0.2588185 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.30469124628418237, 0.6456877321759952, 0.21793384327820917, 0.2741342146784238], Action prob: [0.7624582  0.23754182], Action: 0, state: 0\n",
      "Sensor: [0.30930239345511057, 0.6653365384435309, 0.1941850588229834, 0.20100725644302592], Action prob: [0.76580876 0.23419125], Action: 0, state: 1\n",
      "Sensor: [0.36788468666509977, 0.653261881181019, 0.1957583475435219, 0.23912916593737532], Action prob: [0.76542926 0.23457076], Action: 0, state: 2\n",
      "Sensor: [0.3931234991026219, 0.6724007562025641, 0.19492618576902893, 0.2961072879998527], Action prob: [0.7652655  0.23473446], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.31074514313581225, 0.6254802596459755, 0.26097867728915225, 0.2588138121657144], Action prob: [0.76413524 0.23586479], Action: 0, state: 2\n",
      "Sensor: [0.34141328150845685, 0.5756184869226726, 0.2356317745436061, 0.24556937179066776], Action prob: [0.76334786 0.2366522 ], Action: 0, state: 2\n",
      "Sensor: [0.32587371352933897, 0.664816483282974, 0.20872224846727527, 0.27320838187057483], Action prob: [0.763705   0.23629493], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "Sensor: [0.3425394910625262, 0.6985036942477014, 0.21485624114344432, 0.22499806479512743], Action prob: [0.7642501  0.23574983], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3714812278290836, 0.6733001445734956, 0.20039890177318787, 0.5702864829660395], Action prob: [0.76567626 0.23432377], Action: 0, state: 0\n",
      "Sensor: [0.4026792059408837, 0.623430492455841, 0.2102521512602791, 0.24245735658773399], Action prob: [0.7649438  0.23505627], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.31728155764948973, 0.623223316345056, 0.22545853474974684, 0.23488323822648835], Action prob: [0.76365525 0.23634475], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.3149954457061846, 0.6433213165089765, 0.21349956748895474, 0.30012028450418293], Action prob: [0.76353216 0.23646785], Action: 0, state: 0\n",
      "Sensor: [0.3606245295490077, 0.6509204445037229, 0.2021289905765672, 0.5600219951359604], Action prob: [0.76499486 0.23500508], Action: 0, state: 0\n",
      "Sensor: [0.37082477705419936, 0.6281945173611609, 0.22393396705741003, 0.22785080213019476], Action prob: [0.7643935  0.23560648], Action: 0, state: 0\n",
      "Sensor: [0.38607967736090454, 0.5973529734878666, 0.22351159118204086, 0.23738863244336741], Action prob: [0.76380867 0.23619139], Action: 0, state: 0\n",
      "Sensor: [0.3075800963984754, 0.6550640888280886, 0.2494351281052309, 0.28841128643865954], Action prob: [0.7636881  0.23631188], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-2.7353, -0.5489, -0.3614, -0.2187, -0.7491, -0.0953,  0.0101,  0.5595,\n",
      "         0.5024,  0.1407,  1.2268,  1.0138,  0.1196,  0.1815,  0.2383,  0.2901,\n",
      "         1.7974], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 38 is 8500, loss is -0.08069429295694672\n",
      "Sensor: [0.4482903865570727, 0.6923158305290307, 0.20705959921989275, 0.2160966537104533], Action prob: [0.73797 0.26203], Action: 0, state: 0\n",
      "Sensor: [0.4090570186258413, 0.6990013225682422, 0.20247378253433057, 0.2791005973206799], Action prob: [0.7597185  0.24028148], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3503685994430359, 0.6438399619295937, 0.23208274758573544, 0.2775901523370577], Action prob: [0.7623759  0.23762415], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.34835307055076425, 0.5950115789786494, 0.17799325446708597, 0.1837137981873016], Action prob: [0.7601558  0.23984426], Action: 0, state: 0\n",
      "Sensor: [0.34585666944655513, 0.639840912478228, 0.2338226218203569, 0.1629391624478327], Action prob: [0.7590404  0.24095957], Action: 0, state: 0\n",
      "Sensor: [0.3985587569234139, 0.6712829542511103, 0.2171317076726811, 0.22034334937212047], Action prob: [0.7596989  0.24030104], Action: 0, state: 0\n",
      "Sensor: [0.3566455500448839, 0.6405226873065507, 0.19161541654682218, 0.2834203762352293], Action prob: [0.7596116  0.24038847], Action: 0, state: 1\n",
      "Sensor: [0.3547225970746887, 0.6273942721216471, 0.21761328288279244, 0.2752334082431268], Action prob: [0.75943553 0.24056448], Action: 0, state: 1\n",
      "Sensor: [0.36172461184274035, 0.6584788098631245, 0.2548833835326543, 0.5127616022141264], Action prob: [0.7605849  0.23941505], Action: 0, state: 1\n",
      "Sensor: [0.38639209174198924, 0.6804596246605159, 0.22741336380798857, 0.2212106966382017], Action prob: [0.7606095  0.23939049], Action: 0, state: 1\n",
      "Sensor: [0.37926366824230123, 0.6290279999199059, 0.1797769624914295, 0.3298301175541969], Action prob: [0.76001316 0.23998684], Action: 0, state: 1\n",
      "Sensor: [0.37777759760062424, 0.6158455177517359, 0.20979650750452694, 0.2834642651237055], Action prob: [0.7594656  0.24053441], Action: 0, state: 1\n",
      "Sensor: [0.4224907712876368, 0.6219557038899667, 0.21380556777907617, 0.24339316009677803], Action prob: [0.75960255 0.24039741], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3291809388691215, 0.6117747852062617, 0.2195336887994258, 0.26165839923360834], Action prob: [0.7588599 0.2411401], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.39412586803017186, 0.639760485997267, 0.24641359093349674, 0.26373038129379317], Action prob: [0.7595226 0.2404774], Action: 0, state: 0\n",
      "Sensor: [0.32129133476188787, 0.6340768761858273, 0.2013110515701766, 0.22420288822262457], Action prob: [0.7589154  0.24108456], Action: 0, state: 1\n",
      "Sensor: [0.4164767496923222, 0.6241020618994829, 0.23066698155774915, 0.20320700325308994], Action prob: [0.7593243  0.24067573], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.4021819172247586, 0.6352790333655645, 0.20638155946083767, 0.23521016507477252], Action prob: [0.75951344 0.24048653], Action: 0, state: 1\n",
      "Sensor: [0.36050418105053816, 0.6603538483632412, 0.215129493017321, 0.2584323316674551], Action prob: [0.75960356 0.24039644], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.5562, -1.8655, -1.8794, -0.4229, -0.3088, -0.2032, -0.1183, -0.0420,\n",
      "         0.0266,  0.0879,  0.1440,  0.1945,  1.2410,  1.1217,  0.2371,  0.2708,\n",
      "         1.5343,  0.3082,  1.7205], dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 39 is 12200, loss is -0.0784407108394156\n",
      "Sensor: [0.3644325426127512, 0.6150329846539717, 0.25232798433315884, 0.209728593896937], Action prob: [0.73600227 0.26399776], Action: 0, state: 0\n",
      "Sensor: [0.3594080016922543, 0.6178204231665668, 0.22938966573223613, 0.24120092347687144], Action prob: [0.75846815 0.24153179], Action: 0, state: 1\n",
      "Sensor: [0.3469809181891826, 0.6431591423147177, 0.25468702991282083, 0.25569269419607976], Action prob: [0.76384497 0.23615503], Action: 0, state: 1\n",
      "Sensor: [0.33227942812197003, 0.5911937252420898, 0.20998776290856597, 0.24557560842928486], Action prob: [0.7631296  0.23687042], Action: 0, state: 2\n",
      "Sensor: [0.4186707561737896, 0.6372561634500504, 0.21317864261828443, 0.26598205841320394], Action prob: [0.76346165 0.23653832], Action: 0, state: 2\n",
      "Sensor: [0.37527760074705757, 0.6658629232156257, 0.22714025440784977, 0.18154265167958394], Action prob: [0.7635467  0.23645331], Action: 0, state: 2\n",
      "Sensor: [0.35462085408210986, 0.6493216563076183, 0.19026424704667297, 0.19996895993669375], Action prob: [0.7632912  0.23670882], Action: 0, state: 3\n",
      "Sensor: [0.3785726003886219, 0.342993676417763, 0.22007126947419023, 0.24607715583610362], Action prob: [0.76036596 0.23963404], Action: 1, state: 9\n",
      "Sensor: [0.3317462019485089, 0.6448380233944461, 0.20852365186837435, 0.516140785859856], Action prob: [0.76234037 0.23765968], Action: 0, state: 9\n",
      "Sensor: [0.36761866342939714, 0.38788250515537603, 0.21739077226253944, 0.261066173003759], Action prob: [0.76067334 0.23932664], Action: 0, state: 9\n",
      "Sensor: [0.3480178728705054, 0.6882569102511762, 0.24960393309225282, 0.5595338566176358], Action prob: [0.7633748  0.23662516], Action: 1, state: 9\n",
      "Sensor: [0.3533370634176732, 0.6751181570817754, 0.5325490358798924, 0.2843064515747534], Action prob: [0.7650455  0.23495446], Action: 0, state: 9\n",
      "Sensor: [0.649663092458044, 0.6275547460003706, 0.24982432078512884, 0.2087613738381547], Action prob: [0.7666045  0.23339549], Action: 0, state: 9\n",
      "Sensor: [0.3688414553714846, 0.34177712807228744, 0.2678004034839302, 0.25527769535314343], Action prob: [0.761769   0.23823097], Action: 1, state: 9\n",
      "Sensor: [0.35330655268998656, 0.3492287331477228, 0.20559188879964863, 0.2274956533217904], Action prob: [0.7588182  0.24118178], Action: 1, state: 9\n",
      "Sensor: [0.32746717938107034, 0.615907971253923, 0.22564046445047292, 0.5552509720599114], Action prob: [0.7613357  0.23866436], Action: 0, state: 9\n",
      "Sensor: [0.3715006742642367, 0.6485115331793138, 0.23422883328094712, 0.5890391311469838], Action prob: [0.76398104 0.23601902], Action: 0, state: 9\n",
      "Sensor: [0.38579761594267514, 0.6928307504961035, 0.21162765526996516, 0.5597009405585149], Action prob: [0.7655754  0.23442462], Action: 0, state: 9\n",
      "Sensor: [0.3556372798671496, 0.6378700797417064, 0.22481110801927656, 0.5791018724537889], Action prob: [0.76546144 0.23453848], Action: 0, state: 9\n",
      "Sensor: [0.3299824990383773, 0.3954024780209507, 0.25699836610260274, 0.24872303012015354], Action prob: [0.7617758  0.23822425], Action: 0, state: 9\n",
      "Sensor: [0.34516220069556325, 0.6353943908275281, 0.5287013936167744, 0.2810606022591672], Action prob: [0.7631906 0.2368094], Action: 0, state: 9\n",
      "Sensor: [0.5211145882031905, 0.6182023520648157, 0.19173135783042686, 0.33418905121030895], Action prob: [0.7649064  0.23509358], Action: 0, state: 9\n",
      "Sensor: [0.3394986458220058, 0.6796956012560754, 0.5425619569997638, 0.22994398266038255], Action prob: [0.7650079  0.23499209], Action: 0, state: 9\n",
      "Sensor: [0.3627150044791252, 0.6876408596412292, 0.22737427374701963, 0.550991395314937], Action prob: [0.7657423 0.2342577], Action: 1, state: 9\n",
      "Sensor: [0.5648991494179928, 0.3835488758348181, 0.1759602525393799, 0.25951430362249783], Action prob: [0.76352835 0.23647165], Action: 1, state: 9\n",
      "Sensor: [0.39210675074991963, 0.3364635692947251, 0.2111358083932667, 0.21781153864943806], Action prob: [0.75978494 0.24021505], Action: 0, state: 9\n",
      "Sensor: [0.35842022058988915, 0.29794169894801364, 0.2845750686621531, 0.24700855600002616], Action prob: [0.75775373 0.24224633], Action: 0, state: 9\n",
      "Sensor: [0.3799698346724782, 0.6102693015226888, 0.218162720183555, 0.5628917390082135], Action prob: [0.7615038  0.23849615], Action: 0, state: 9\n",
      "Sensor: [0.38321711989828544, 0.4669951145178678, 0.2156256657290008, 0.5813284680897683], Action prob: [0.76229006 0.23770997], Action: 0, state: 9\n",
      "Sensor: [0.5834623464460156, 0.6246899911907203, 0.17707180205759326, 0.2606707674145921], Action prob: [0.7645607  0.23543929], Action: 0, state: 9\n",
      "tensor([-0.1561,  0.0270,  0.1733,  0.2923,  0.3978,  0.4929,  0.5474,  2.3894,\n",
      "         0.3654,  0.2898,  1.1450,  0.1490,  0.0925,  0.2313, -0.0141, -0.0456,\n",
      "        -0.0825, -0.1153, -0.1453, -0.1748, -0.1997, -0.2191, -0.2399, -1.3913,\n",
      "        -1.4626, -0.2934, -0.3097, -0.3169, -0.3257, -0.3323],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 40 is -19300, loss is -0.025625278723795674\n",
      "Sensor: [0.3205754718587851, 0.5965173892085719, 0.19316921786505462, 0.2647731854614623], Action prob: [0.73615366 0.2638463 ], Action: 0, state: 0\n",
      "Sensor: [0.3298833336013594, 0.6385613309580059, 0.22424031211734136, 0.27871022539701185], Action prob: [0.76014435 0.23985565], Action: 0, state: 0\n",
      "Sensor: [0.2934342286990066, 0.602340315684587, 0.19474284595201757, 0.25468994140608997], Action prob: [0.76581484 0.23418517], Action: 0, state: 0\n",
      "Sensor: [0.37317384758892935, 0.6291078277836607, 0.19142932511549804, 0.2609244692835402], Action prob: [0.7671481  0.23285191], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35299910980644345, 0.6057438068179758, 0.21694655146451544, 0.26142047413812736], Action prob: [0.76702976 0.23297025], Action: 0, state: 0\n",
      "Sensor: [0.29209018174558954, 0.8378791611473517, 0.19220901954418276, 0.23629047025714953], Action prob: [0.7688161  0.23118386], Action: 0, state: 0\n",
      "Sensor: [0.4119603429917219, 0.6587698946284687, 0.24659603690263385, 0.24685209624240143], Action prob: [0.7693196 0.2306804], Action: 0, state: 0\n",
      "Sensor: [0.34940100937253354, 0.6375559135798547, 0.20091015518876476, 0.2592145724459559], Action prob: [0.76859885 0.23140112], Action: 0, state: 0\n",
      "Sensor: [0.3453547817198897, 0.603090466098229, 0.20148877540667542, 0.25663098831962666], Action prob: [0.76777357 0.23222643], Action: 0, state: 1\n",
      "Sensor: [0.3443163996848617, 0.6255327253288827, 0.2400637987772586, 0.2355331140551794], Action prob: [0.7676166  0.23238334], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3415518256641568, 0.6403276473445074, 0.22894230382300068, 0.5482601305745874], Action prob: [0.7686342  0.23136579], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.363062444161672, 0.6309987482126629, 0.21280116920072675, 0.2851183505999879], Action prob: [0.7686414  0.23135859], Action: 0, state: 0\n",
      "Sensor: [0.31513435513407395, 0.6162721750274469, 0.18684932894088488, 0.2985716289286852], Action prob: [0.7677987  0.23220128], Action: 0, state: 0\n",
      "Sensor: [0.3567899460194413, 0.6195242664391982, 0.2269668528687009, 0.24561543234961528], Action prob: [0.76766676 0.23233323], Action: 0, state: 0\n",
      "Sensor: [0.33629064218396276, 0.6207327748190548, 0.1870846354099847, 0.22558515777767857], Action prob: [0.76731336 0.23268664], Action: 0, state: 0\n",
      "Sensor: [0.39002235136054536, 0.6691876841381077, 0.24760257904165317, 0.25335780924942847], Action prob: [0.76829433 0.23170562], Action: 0, state: 0\n",
      "Sensor: [0.3501410829172169, 0.617906625180616, 0.23234813179147074, 0.16427039169270868], Action prob: [0.76775086 0.23224913], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.39243026512747287, 0.6749349867640979, 0.19338795161903796, 0.4238645484496442], Action prob: [0.76888686 0.2311131 ], Action: 0, state: 0\n",
      "Sensor: [0.3345749499598787, 0.4475217234072034, 0.18631752526787587, 0.2951996420855764], Action prob: [0.76650596 0.23349409], Action: 0, state: 1\n",
      "Sensor: [0.32312584015425405, 0.6135456037438473, 0.2105301634784119, 0.27697999158959974], Action prob: [0.7666551 0.2333449], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.33605733531712356, 0.6584657276148307, 0.2272738418103919, 0.18708558211090637], Action prob: [0.7672911  0.23270895], Action: 0, state: 0\n",
      "Sensor: [0.3021609424961171, 0.680662557935536, 0.22865698290815714, 0.24628208251193245], Action prob: [0.76769304 0.23230697], Action: 0, state: 1\n",
      "Sensor: [0.3356552178141501, 0.6650508809337293, 0.20966236439641006, 0.2331045552973972], Action prob: [0.76796275 0.23203726], Action: 0, state: 1\n",
      "Sensor: [0.327941068332645, 0.5353472000598436, 0.44073495903415416, 0.29445779048732407], Action prob: [0.7675942  0.23240583], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.7415, -0.5414, -0.4192, -1.7622, -0.2775, -0.1987, -0.1284, -0.0662,\n",
      "        -0.0155,  0.1664,  0.1684,  0.0506,  0.0880,  0.1213,  0.1517,  0.1777,\n",
      "         1.1191,  0.2125,  0.2335,  1.3622,  0.2557,  0.2681,  0.2794,  1.6027],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 41 is 19800, loss is -0.08778256825000781\n",
      "Sensor: [0.33496754737365325, 0.575704681675638, 0.2275887673275207, 0.23466229047419945], Action prob: [0.7412622  0.25873777], Action: 0, state: 0\n",
      "Sensor: [0.3462810940576101, 0.6496275393537555, 0.1987253756739202, 0.32037476004201854], Action prob: [0.76730275 0.23269722], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3695970707630606, 0.6907424366353854, 0.247466704737035, 0.2588266889371975], Action prob: [0.77554286 0.22445716], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3680142771762628, 0.689376632485556, 0.1932164965677389, 0.21435191739126278], Action prob: [0.77717656 0.22282347], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.38542850764743164, 0.6503171137757368, 0.23179635262658643, 0.2920618761608633], Action prob: [0.7776772  0.22232276], Action: 0, state: 0\n",
      "Sensor: [0.32691913116827115, 0.5897644835398718, 0.1887725015254054, 0.22271103241747586], Action prob: [0.77672696 0.22327295], Action: 0, state: 0\n",
      "Sensor: [0.41342584558117235, 0.6089701444543245, 0.24692409041803232, 0.2775550910750281], Action prob: [0.77747834 0.22252168], Action: 0, state: 1\n",
      "Sensor: [0.35801745556622655, 0.6279568040985127, 0.24550620521637506, 0.2095576919844211], Action prob: [0.7775305  0.22246951], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.37116851380149257, 0.6138000838761279, 0.2055104040052327, 0.20069244670846553], Action prob: [0.77724046 0.22275954], Action: 0, state: 0\n",
      "Sensor: [0.37363226085355405, 0.5946123936150043, 0.22440405271782088, 0.27936189987723015], Action prob: [0.77713746 0.22286254], Action: 0, state: 1\n",
      "Sensor: [0.32137416764034155, 0.6814347363568986, 0.262710778502762, 0.22276165979002266], Action prob: [0.7775558  0.22244424], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.4023760504040168, 0.6231740135164662, 0.19026428086691966, 0.28928011890033584], Action prob: [0.7779082  0.22209181], Action: 0, state: 0\n",
      "Sensor: [0.35673986270066754, 0.663524351195432, 0.20508774700994528, 0.2580505991867434], Action prob: [0.7779517  0.22204831], Action: 0, state: 1\n",
      "Sensor: [0.37544428411424385, 0.6567732575314563, 0.22886374672776644, 0.2078672584968522], Action prob: [0.7780105  0.22198953], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.35523466509741725, 0.614129887861916, 0.23172895843266292, 0.17805888171316134], Action prob: [0.7773251  0.22267492], Action: 0, state: 0\n",
      "tensor([-0.5630, -1.6918, -0.3868, -1.3107, -0.2194, -0.0875,  0.0198,  0.6930,\n",
      "         0.1163,  0.1947,  1.5776,  0.1939,  0.2504,  1.8071,  0.2513],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 42 is 6800, loss is -0.056323460080670885\n",
      "Sensor: [0.390004902085788, 0.631897792651596, 0.21623631989764536, 0.2717994610689315], Action prob: [0.75053376 0.24946621], Action: 0, state: 0\n",
      "Sensor: [0.3538007533549935, 0.6168655309275647, 0.24404355405053632, 0.26127285857691623], Action prob: [0.77731293 0.22268705], Action: 0, state: 0\n",
      "Sensor: [0.3518202687546039, 0.4479843001942614, 0.2821982954449491, 0.1926278337751467], Action prob: [0.78374314 0.21625689], Action: 0, state: 1\n",
      "Sensor: [0.4075078872512526, 0.6154539588200902, 0.19237882785160015, 0.25784982995199096], Action prob: [0.7869365  0.21306345], Action: 0, state: 2\n",
      "Sensor: [0.38075667204163766, 0.6648200548572609, 0.20885230146917402, 0.16585969043060356], Action prob: [0.7883907  0.21160929], Action: 0, state: 2\n",
      "Sensor: [0.4030643020990058, 0.5687919401961481, 0.23565143072573974, 0.26738878935214916], Action prob: [0.78890973 0.21109027], Action: 0, state: 2\n",
      "Sensor: [0.3873117212933296, 0.5996885429954183, 0.21232197362364819, 0.2443807458698783], Action prob: [0.78928894 0.21071106], Action: 0, state: 2\n",
      "Sensor: [0.4094195114893816, 0.7193069596396932, 0.2322791438362785, 0.2323651670762301], Action prob: [0.7907794  0.20922054], Action: 0, state: 2\n",
      "Sensor: [0.47593142766927216, 0.636871700805522, 0.22883397844288988, 0.2802245048011311], Action prob: [0.79144424 0.20855577], Action: 0, state: 2\n",
      "Sensor: [0.3993641496735997, 0.3829880989332135, 0.22228490640311668, 0.24117445898787224], Action prob: [0.7884538  0.21154617], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "Sensor: [0.3254404343580355, 0.7027588431379391, 0.2335810083529824, 0.2802061447328854], Action prob: [0.7894587  0.21054134], Action: 0, state: 2\n",
      "Sensor: [0.3828753542055415, 0.6271541717345459, 0.21363681858452416, 0.30523192211260863], Action prob: [0.79006153 0.2099385 ], Action: 0, state: 2\n",
      "Sensor: [0.3988074282946041, 0.6134577542323633, 0.22739710633512616, 0.25870534021397995], Action prob: [0.7901744  0.20982558], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.3468273766513462, 0.6336556944735757, 0.18998821885181394, 0.2355386591561835], Action prob: [0.7897242  0.21027581], Action: 0, state: 1\n",
      "Sensor: [0.3350111380115042, 0.6071749619564317, 0.18050104100826544, 0.2566360223968853], Action prob: [0.78915566 0.21084431], Action: 0, state: 1\n",
      "Sensor: [0.3757101459132741, 0.6971608484091003, 0.20943128688450557, 0.2676973682073394], Action prob: [0.7902045  0.20979549], Action: 0, state: 1\n",
      "Sensor: [0.3147675138373584, 0.6256953235347664, 0.1983516052166676, 0.23017546750349077], Action prob: [0.78956467 0.21043533], Action: 0, state: 1\n",
      "Sensor: [0.3056169774594761, 0.6337530842525595, 0.2265829293607835, 0.267461453224051], Action prob: [0.78936684 0.21063314], Action: 0, state: 2\n",
      "Sensor: [0.3428556970671517, 0.637753135547412, 0.23682041303722803, 0.1972513967157152], Action prob: [0.78947854 0.21052147], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "Sensor: [0.3384081233211656, 0.6414661151479017, 0.2117678643681723, 0.2646763986743348], Action prob: [0.7896347  0.21036524], Action: 0, state: 2\n",
      "Sensor: [0.38300144816334725, 0.6304132826746289, 0.23516429859798796, 0.23271198616134942], Action prob: [0.78994554 0.21005444], Action: 0, state: 3\n",
      "Sensor: [0.3341526976328692, 0.6900894969480962, 0.19327680426868515, 0.17700908235843282], Action prob: [0.7898639  0.21013609], Action: 0, state: 3\n",
      "Sensor: [0.6385967863185242, 0.649377506713372, 0.21297870405681993, 0.21021978830816282], Action prob: [0.791794   0.20820597], Action: 0, state: 8\n",
      "Sensor: [0.4184651357421463, 0.37137801300534634, 0.22660265588264783, 0.25245353353220373], Action prob: [0.7886101  0.21138996], Action: 0, state: 8\n",
      "Sensor: [0.29537316821777876, 0.3691764178358201, 0.19933492982251363, 0.27353373321185087], Action prob: [0.78595155 0.21404846], Action: 0, state: 8\n",
      "tensor([-0.7591, -0.5272, -0.4005, -0.3083, -0.2297, -0.1599, -0.0979, -0.0424,\n",
      "         0.0075,  0.2394,  0.0253,  0.0619,  0.6262,  0.1094,  0.1398,  0.1654,\n",
      "         0.1904,  0.2099,  1.4540,  0.2166,  0.2250,  0.2328,  0.1883,  0.1536,\n",
      "         0.1205], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 43 is 1800, loss is -0.07363474687839879\n",
      "Sensor: [0.37768329369553105, 0.7343177224241287, 0.26098148669411525, 0.2781702014190254], Action prob: [0.76325643 0.23674358], Action: 0, state: 0\n",
      "Sensor: [0.38496671115767284, 0.6620082402156992, 0.2496974835772141, 0.2653606892271039], Action prob: [0.7922517  0.20774832], Action: 0, state: 1\n",
      "Sensor: [0.3769319606963579, 0.624746551371803, 0.20129470978012481, 0.22597342155365877], Action prob: [0.8005218  0.19947815], Action: 0, state: 1\n",
      "Sensor: [0.3553139855896403, 0.6641104050689073, 0.39660796603634296, 0.28890921878658427], Action prob: [0.80393296 0.19606705], Action: 0, state: 2\n",
      "Sensor: [0.3428022458171453, 0.6547556755359055, 0.204234314729926, 0.2975941481561596], Action prob: [0.80489767 0.19510232], Action: 0, state: 2\n",
      "Sensor: [0.3503013504750388, 0.6369859484306254, 0.23311849447899366, 0.26404010755799695], Action prob: [0.8051025  0.19489749], Action: 0, state: 2\n",
      "Sensor: [0.3768973006295651, 0.6296927799245382, 0.2077935228680815, 0.22321526957391583], Action prob: [0.8050646 0.1949354], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.361513001172155, 0.6494231268684143, 0.19138345295701512, 0.23683038091085015], Action prob: [0.8050468 0.1949532], Action: 0, state: 1\n",
      "Sensor: [0.3810019301727321, 0.6916228129648752, 0.1953075320689031, 0.2647844958054234], Action prob: [0.8057216  0.19427848], Action: 0, state: 2\n",
      "Sensor: [0.3599989810605597, 0.5983896577659908, 0.2684213402276722, 0.21557242315576022], Action prob: [0.8051726  0.19482742], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -2100\n",
      "Sensor: [0.41704713881029404, 0.6435970144580894, 0.2551530697253326, 0.2734105576724181], Action prob: [0.8058961  0.19410391], Action: 0, state: 1\n",
      "Sensor: [0.4260469437627005, 0.6248479848814613, 0.1964187733585279, 0.24781015395091066], Action prob: [0.80586135 0.19413868], Action: 0, state: 1\n",
      "Sensor: [0.3875000204393614, 0.6353164186561422, 0.21084488971991355, 0.3111294920604853], Action prob: [0.80583906 0.19416095], Action: 0, state: 1\n",
      "Sensor: [0.32669121052366873, 0.6027296844039784, 0.23527858774465651, 0.26491336852712766], Action prob: [0.8050619  0.19493815], Action: 0, state: 1\n",
      "Sensor: [0.30834618309591, 0.6614332353827357, 0.23243995936086057, 0.206598398489314], Action prob: [0.80483836 0.19516167], Action: 0, state: 1\n",
      "Sensor: [0.362285000165525, 0.6416322067790744, 0.23982764119561303, 0.23367167028402347], Action prob: [0.8050827  0.19491732], Action: 0, state: 1\n",
      "Sensor: [0.31963217150749174, 0.6297386212528279, 0.24819966236347463, 0.21798621263446163], Action prob: [0.804764   0.19523601], Action: 0, state: 1\n",
      "Sensor: [0.3867833045590396, 0.5978397934678001, 0.18622614347225452, 0.22739944654021843], Action prob: [0.80455774 0.19544226], Action: 0, state: 1\n",
      "Sensor: [0.36357114318134237, 0.6950865205103388, 0.17344815319766202, 0.2036071334172087], Action prob: [0.8049901 0.1950099], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.39969874509246456, 0.6365578591778194, 0.21726069516437646, 0.548715574814223], Action prob: [0.8063713 0.1936287], Action: 0, state: 0\n",
      "Sensor: [0.32007217130929155, 0.6625391753553563, 0.24529946533743768, 0.28674703321335243], Action prob: [0.80635214 0.19364788], Action: 0, state: 0\n",
      "Sensor: [0.3316570072351453, 0.6332787530957318, 0.25669921142171614, 0.27971866576452037], Action prob: [0.8059377  0.19406231], Action: 0, state: 1\n",
      "tensor([-0.6812, -0.4610, -0.3321, -0.2412, -0.1634, -0.0949, -0.2518, -0.0057,\n",
      "         0.0439,  0.6711, -0.0170,  0.0239,  0.0605,  0.0938,  0.1236,  0.1503,\n",
      "         0.1747,  0.1970,  1.6259,  0.2242,  0.2413,  0.2561],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 44 is 15300, loss is -0.07445038125219514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3557180898473924, 0.4374823210315828, 0.20420191117048658, 0.24870969269767923], Action prob: [0.770822   0.22917803], Action: 0, state: 0\n",
      "Sensor: [0.3682085951262185, 0.6661670848535376, 0.19885576209611067, 0.24063210858302814], Action prob: [0.8054995  0.19450046], Action: 0, state: 0\n",
      "Sensor: [0.3487696662767721, 0.6257003919179982, 0.2440352002330045, 0.2652264308331317], Action prob: [0.8167296 0.1832704], Action: 0, state: 0\n",
      "Sensor: [0.4062011955226992, 0.6132053860357904, 0.2201587719487101, 0.22530179525558922], Action prob: [0.8204237 0.1795763], Action: 0, state: 1\n",
      "Sensor: [0.42338739374979345, 0.6454952193238245, 0.22317433839867862, 0.2608464624116148], Action prob: [0.82245946 0.17754056], Action: 0, state: 1\n",
      "Sensor: [0.31932109712216855, 0.6802769340239481, 0.21926348857727884, 0.23556681883037156], Action prob: [0.82309264 0.17690738], Action: 0, state: 2\n",
      "Sensor: [0.3272406100070761, 0.5705911513085938, 0.25429258325230947, 0.27663105321846493], Action prob: [0.8227316  0.17726839], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.33924991139521005, 0.6400746873856626, 0.22955139316385711, 0.22112456278927425], Action prob: [0.8229882  0.17701174], Action: 0, state: 1\n",
      "Sensor: [0.3649373971781568, 0.656975597420714, 0.23650701646949573, 0.18101978133568009], Action prob: [0.8232859  0.17671409], Action: 0, state: 1\n",
      "Sensor: [0.3304866303907419, 0.5793962840873139, 0.22330261046047004, 0.22770792700412895], Action prob: [0.82248724 0.1775128 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1600\n",
      "Sensor: [0.3699146717914689, 0.6647693425975809, 0.1616062368256626, 0.25854104300420044], Action prob: [0.82306844 0.17693159], Action: 0, state: 1\n",
      "Sensor: [0.36478615401708464, 0.7350768643541715, 0.23516325954269435, 0.24745168261307396], Action prob: [0.8243206  0.17567942], Action: 0, state: 1\n",
      "Sensor: [0.3293872291958464, 0.603616186167777, 0.22162165607241974, 0.19100878226651063], Action prob: [0.8232429  0.17675711], Action: 0, state: 2\n",
      "Sensor: [0.384254513162437, 0.6163081824615432, 0.20647074189089562, 0.24914366085519762], Action prob: [0.823216   0.17678401], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.4181907007745339, 0.6602591798109929, 0.20029925109866512, 0.30134330020382316], Action prob: [0.82412875 0.17587122], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35198482390812275, 0.6476123261250529, 0.24895710794933895, 0.1788550425323734], Action prob: [0.8237678  0.17623217], Action: 0, state: 0\n",
      "Sensor: [0.3153697853685605, 0.6233682696608236, 0.21748062287873934, 0.21351405279792185], Action prob: [0.8229922 0.1770078], Action: 0, state: 0\n",
      "Sensor: [0.34522741226761183, 0.6684512559688571, 0.19284750705474063, 0.2732371250406247], Action prob: [0.8233708 0.1766292], Action: 0, state: 0\n",
      "Sensor: [0.3749403361407537, 0.5958403165272929, 0.19594438164891786, 0.2784950086313488], Action prob: [0.82317364 0.17682633], Action: 0, state: 0\n",
      "Sensor: [0.3740621823621032, 0.5903874136895458, 0.21803518496481766, 0.26154281261241674], Action prob: [0.8230245  0.17697546], Action: 0, state: 1\n",
      "Sensor: [0.3660971579531936, 0.6410404893597337, 0.2087699598860288, 0.300224137898662], Action prob: [0.82354045 0.17645957], Action: 0, state: 1\n",
      "Sensor: [0.36626579824030747, 0.6799746452950074, 0.2431088629247246, 0.17975450907117696], Action prob: [0.8238847  0.17611529], Action: 0, state: 1\n",
      "tensor([-0.6723, -0.4365, -0.3051, -0.2164, -0.1410, -0.0825, -0.2673, -0.0068,\n",
      "         0.0406,  0.7014,  0.0104,  0.0445,  0.0728,  0.8709,  0.9735,  0.1210,\n",
      "         0.1445,  0.1646,  0.1834,  0.1984,  0.2111,  0.2224],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 45 is 15900, loss is -0.08325441814898048\n",
      "Sensor: [0.3300892456163383, 0.6671900552812771, 0.1885511837210493, 0.2390233979260207], Action prob: [0.79147804 0.208522  ], Action: 0, state: 0\n",
      "Sensor: [0.31248701999572226, 0.45255186450239593, 0.2160305371289858, 0.21846892343030944], Action prob: [0.82410854 0.17589147], Action: 0, state: 0\n",
      "Sensor: [0.4088150087806089, 0.6369436117102775, 0.23994333804554813, 0.2261117508298156], Action prob: [0.83752894 0.16247101], Action: 0, state: 0\n",
      "Sensor: [0.327689859505761, 0.6175292905372736, 0.19545798439107467, 0.25964754220230146], Action prob: [0.84143466 0.15856533], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3435357813093116, 0.6820247979510041, 0.2681386516246701, 0.30294527523681286], Action prob: [0.8442689  0.15573107], Action: 0, state: 0\n",
      "Sensor: [0.33817218611651817, 0.6154567002604764, 0.18694066055176728, 0.22762896865973858], Action prob: [0.8445877  0.15541233], Action: 0, state: 0\n",
      "Sensor: [0.2754372447477243, 0.7051614766448269, 0.25779178292661414, 0.3234528746994878], Action prob: [0.84576035 0.15423971], Action: 0, state: 1\n",
      "Sensor: [0.3243939780434345, 0.6006698525763013, 0.23916021262648085, 0.2506296507431025], Action prob: [0.8454579  0.15454213], Action: 0, state: 2\n",
      "Sensor: [0.32521053223144936, 0.6750606222871482, 0.25777007900747184, 0.22321906488237087], Action prob: [0.84586006 0.15413997], Action: 0, state: 2\n",
      "Sensor: [0.33005859872257864, 0.6248011692007039, 0.23535918423295155, 0.24431427915113474], Action prob: [0.8455757  0.15442427], Action: 0, state: 2\n",
      "Sensor: [0.3346435569641458, 0.6300988747183773, 0.17790374673230908, 0.24493383432577603], Action prob: [0.8451937  0.15480633], Action: 0, state: 2\n",
      "Sensor: [0.3632219950168699, 0.5813775740248595, 0.2141041303344093, 0.22816508012864004], Action prob: [0.84475076 0.15524928], Action: 0, state: 3\n",
      "Sensor: [0.3956034954660061, 0.32428599982463935, 0.2336955855394227, 0.5076799589494223], Action prob: [0.8433152  0.15668483], Action: 0, state: 8\n",
      "Sensor: [0.40556172417581926, 0.4129349462019125, 0.24025026900108787, 0.23081890147928835], Action prob: [0.84281933 0.15718067], Action: 0, state: 8\n",
      "Sensor: [0.32158562005974844, 0.6741692263482859, 0.20196784758134503, 0.5524602381115523], Action prob: [0.8455707  0.15442932], Action: 0, state: 8\n",
      "Sensor: [0.347716724025594, 0.3543442931062026, 0.2110317357928937, 0.22967916483559625], Action prob: [0.84295666 0.1570434 ], Action: 1, state: 8\n",
      "Sensor: [0.3712254439100776, 0.7112161328954969, 0.2009481023754955, 0.20942416046433726], Action prob: [0.8447763  0.15522373], Action: 0, state: 0\n",
      "Sensor: [0.3270808904087071, 0.6641466603614924, 0.2083064453752332, 0.24707065703970987], Action prob: [0.8452523  0.15474771], Action: 0, state: 0\n",
      "Sensor: [0.3402869736573738, 0.652508427306321, 0.21841959931039823, 0.2602994579770303], Action prob: [0.84557134 0.1544287 ], Action: 0, state: 1\n",
      "Sensor: [0.3549068938320039, 0.6371514504482508, 0.21609204345599883, 0.2731265919474978], Action prob: [0.84577495 0.15422511], Action: 0, state: 1\n",
      "Sensor: [0.3767206156861705, 0.6233078733357498, 0.2484608037494912, 0.2594769268925003], Action prob: [0.8460115  0.15398844], Action: 0, state: 1\n",
      "Sensor: [0.3794700154925103, 0.6180966869093517, 0.19088862415200702, 0.24265522025063338], Action prob: [0.84576845 0.15423153], Action: 0, state: 1\n",
      "Sensor: [0.35740929236425584, 0.6200875903163108, 0.1805986684852397, 0.22232614204170142], Action prob: [0.84523565 0.15476435], Action: 0, state: 2\n",
      "Sensor: [0.3402196777851173, 0.6228064549090628, 0.2288205112029352, 0.2101404499713669], Action prob: [0.84498525 0.15501474], Action: 0, state: 2\n",
      "Sensor: [0.41939185602361734, 0.6481903233237251, 0.17211430448878393, 0.2567906913640455], Action prob: [0.8457017  0.15429837], Action: 0, state: 2\n",
      "Sensor: [0.36048915540276466, 0.6278737325069834, 0.2146073656954958, 0.2810020039120024], Action prob: [0.84576803 0.15423194], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "tensor([-0.6048, -0.3304, -0.1636, -0.3916, -0.0902,  0.0072,  0.0849,  0.1477,\n",
      "         0.2032,  0.2543,  0.3007,  0.3275,  0.1911,  0.0644, -0.0490, -1.6490,\n",
      "        -0.1206, -0.0928, -0.0706, -0.0506, -0.0327, -0.0167, -0.0039,  0.0077,\n",
      "         0.0181,  0.3065], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 46 is 5300, loss is 0.06743271499411681\n",
      "Sensor: [0.3765084471697884, 0.7114094532647752, 0.20495042103075656, 0.3220550437660032], Action prob: [0.80619955 0.19380046], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.36278235429307853, 0.6239523254507885, 0.19721389411217433, 0.2811987110927049], Action prob: [0.8410522  0.15894786], Action: 0, state: 0\n",
      "Sensor: [0.31206085459610405, 0.6107038760851706, 0.187520785279596, 0.2411984396819159], Action prob: [0.85089535 0.14910464], Action: 0, state: 1\n",
      "Sensor: [0.39786624351191024, 0.6376918401852208, 0.19816297228462773, 0.25779224136373463], Action prob: [0.85480905 0.1451909 ], Action: 0, state: 2\n",
      "Sensor: [0.40191740231957646, 0.6822170565406035, 0.15850428800863653, 0.21459442045355406], Action prob: [0.8566292 0.1433708], Action: 0, state: 2\n",
      "Sensor: [0.36909925172362107, 0.6549429770810176, 0.2041952845445491, 0.2748552864725792], Action prob: [0.85745305 0.14254698], Action: 0, state: 2\n",
      "Sensor: [0.37105673783382265, 0.6256451581262671, 0.23098341916299897, 0.2270336709459517], Action prob: [0.8576763  0.14232364], Action: 0, state: 2\n",
      "Sensor: [0.3286354053593615, 0.6032875322715494, 0.25122983428806145, 0.19845016475159988], Action prob: [0.8572085  0.14279155], Action: 0, state: 3\n",
      "Sensor: [0.41675851657081353, 0.6526462667487452, 0.2338653928998168, 0.2510734178513973], Action prob: [0.85817534 0.14182465], Action: 0, state: 3\n",
      "Sensor: [0.35430960353574475, 0.6351269670723454, 0.22872748199016363, 0.263543353897463], Action prob: [0.85811096 0.14188899], Action: 0, state: 3\n",
      "Sensor: [0.3397862940768677, 0.593508605669293, 0.5110897621024442, 0.29336529652593524], Action prob: [0.8590972 0.1409028], Action: 0, state: 3\n",
      "Sensor: [0.4037612557129196, 0.6624998125827981, 0.22691896635986308, 0.2749984893606555], Action prob: [0.85961735 0.14038265], Action: 0, state: 3\n",
      "Sensor: [0.3815818693230267, 0.5990137492242552, 0.22226701860154605, 0.2207732291114849], Action prob: [0.85838896 0.14161102], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.3771870768211388, 0.672522809659517, 0.2514666829375789, 0.22277800771018116], Action prob: [0.858524   0.14147598], Action: 0, state: 2\n",
      "Sensor: [0.32304893206057717, 0.6533684435678779, 0.1943028932770997, 0.2899380463025483], Action prob: [0.8581364  0.14186352], Action: 0, state: 3\n",
      "Sensor: [0.3694654295913516, 0.3978327573498878, 0.20222028226682404, 0.24152869102810404], Action prob: [0.8552829  0.14471704], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "Sensor: [0.3433958767183187, 0.6785902486552207, 0.23484401251717832, 0.2247182636314358], Action prob: [0.8568537  0.14314629], Action: 0, state: 2\n",
      "Sensor: [0.38795674879599307, 0.6364963454920712, 0.1972665702548002, 0.22317333846601725], Action prob: [0.85743475 0.14256525], Action: 0, state: 2\n",
      "Sensor: [0.38178217926431995, 0.6626230325581454, 0.5388836075420146, 0.23815657217401845], Action prob: [0.8596172 0.1403828], Action: 0, state: 3\n",
      "Sensor: [0.31066092633093484, 0.6062170397302771, 0.5293225732257822, 0.22766616664277395], Action prob: [0.8600472  0.13995285], Action: 0, state: 8\n",
      "Sensor: [0.37222155364824583, 0.6527111220251228, 0.21621171549108395, 0.560994932173975], Action prob: [0.8607501  0.13924986], Action: 0, state: 8\n",
      "Sensor: [0.28327949999896535, 0.6961965907624839, 0.5331724378116415, 0.5054817847367242], Action prob: [0.86200714 0.13799286], Action: 0, state: 8\n",
      "Sensor: [0.3743488095633247, 0.425964356278495, 0.22341496961825918, 0.2601749576477822], Action prob: [0.85853165 0.14146838], Action: 0, state: 8\n",
      "Sensor: [0.3966178287919311, 0.3211093898110725, 0.2169060400929672, 0.28993025714744], Action prob: [0.8549275  0.14507252], Action: 0, state: 8\n",
      "Sensor: [0.37928744194918984, 0.38646662626656203, 0.19573101525283068, 0.24925319087000186], Action prob: [0.85345155 0.14654839], Action: 0, state: 8\n",
      "Sensor: [0.49541058329776255, 0.42078881714814986, 0.18916634973647367, 0.3102616281640816], Action prob: [0.8542362  0.14576378], Action: 0, state: 8\n",
      "tensor([-4.2718, -0.3894, -0.2708, -0.1914, -0.1252, -0.0674, -0.0161,  0.0128,\n",
      "         0.0385,  0.0618,  0.0819,  0.1004,  1.5147,  0.1271,  0.1414,  1.9486,\n",
      "         0.1506,  0.1662,  0.1719,  0.1235,  0.0805,  0.0409,  0.0074, -0.0248,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        -0.0550, -0.0813], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 47 is -14000, loss is 0.027875666148012825\n",
      "Sensor: [0.34161818138327565, 0.5627626133604303, 0.21949657719930393, 0.23796330473872385], Action prob: [0.811738 0.188262], Action: 0, state: 0\n",
      "Sensor: [0.394922292418619, 0.6276134770075382, 0.17626875564718475, 0.28599792749838093], Action prob: [0.8514627  0.14853726], Action: 0, state: 1\n",
      "Sensor: [0.3549217780219629, 0.6228174356420756, 0.21728592180295556, 0.2538675131845164], Action prob: [0.86335516 0.13664487], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3888578521041306, 0.6587554405038838, 0.18630724646106697, 0.28266339989798556], Action prob: [0.867759   0.13224103], Action: 0, state: 0\n",
      "Sensor: [0.41078971409693643, 0.6422984304367931, 0.18507420045969997, 0.283131642185088], Action prob: [0.86964107 0.13035892], Action: 0, state: 0\n",
      "Sensor: [0.3343603382855678, 0.6167776627320194, 0.18075392020385564, 0.22400779747310842], Action prob: [0.8696371  0.13036288], Action: 0, state: 0\n",
      "Sensor: [0.3476646328026497, 0.6350627703565696, 0.2822349122179164, 0.24708304557443636], Action prob: [0.8703765  0.12962344], Action: 0, state: 1\n",
      "Sensor: [0.37370462916911246, 0.6414937886021344, 0.19228585155814637, 0.22866172918021668], Action prob: [0.87072974 0.12927026], Action: 0, state: 1\n",
      "Sensor: [0.4115785221793808, 0.5711647814721319, 0.22161949467570638, 0.2515619091271726], Action prob: [0.87041056 0.12958944], Action: 0, state: 1\n",
      "Sensor: [0.36410733943089046, 0.6092301775668025, 0.25273289770144786, 0.22236653646616955], Action prob: [0.8704044  0.12959555], Action: 0, state: 2\n",
      "Sensor: [0.44255604614781197, 0.6479856039230681, 0.21285173945161553, 0.2014616503496626], Action prob: [0.8711075  0.12889244], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.37951412739583945, 0.6813101300334122, 0.20998286554827061, 0.2255905036835506], Action prob: [0.8713885  0.12861149], Action: 0, state: 2\n",
      "Sensor: [0.35097170884519835, 0.6302706318005483, 0.22881354390699718, 0.2336828744553748], Action prob: [0.8709073  0.12909266], Action: 0, state: 3\n",
      "Sensor: [0.3801997068235872, 0.5680014636037068, 0.22489454265431366, 0.2284713932380377], Action prob: [0.87018216 0.12981789], Action: 0, state: 3\n",
      "Sensor: [0.6178105963047829, 0.6440802247721963, 0.23848642678402673, 0.2515322511301364], Action prob: [0.8722952 0.1277048], Action: 0, state: 3\n",
      "Sensor: [0.5499012425605065, 0.347079468359813, 0.2634946899368108, 0.2574059285796922], Action prob: [0.87008584 0.1299142 ], Action: 0, state: 8\n",
      "Sensor: [0.34392354523030255, 0.36039576212161206, 0.20319872853549334, 0.24107841467584987], Action prob: [0.86717635 0.13282369], Action: 0, state: 8\n",
      "Sensor: [0.3643244379375224, 0.696786539353151, 0.21020494701436965, 0.5381745065213784], Action prob: [0.87046605 0.12953395], Action: 0, state: 8\n",
      "Sensor: [0.36872410649256104, 0.33682897376728044, 0.23507937556098635, 0.2572665055486789], Action prob: [0.8679461  0.13205385], Action: 0, state: 8\n",
      "Sensor: [0.31874371698554854, 0.3923695020576413, 0.2633354624052796, 0.2541742079174284], Action prob: [0.8665511  0.13344893], Action: 1, state: 8\n",
      "Sensor: [0.3870777192196778, 0.5864673477699571, 0.1965061076551345, 0.2676448055948013], Action prob: [0.8683526 0.1316474], Action: 0, state: 0\n",
      "Sensor: [0.3454408595298058, 0.6533736924608091, 0.16742791720208416, 0.3035307450460925], Action prob: [0.8696309  0.13036914], Action: 0, state: 0\n",
      "Sensor: [0.3657212597859279, 0.6887148568548636, 0.18849998411746083, 0.23144718554246174], Action prob: [0.87065107 0.1293489 ], Action: 0, state: 1\n",
      "Sensor: [0.3627305603736649, 0.5793177818590259, 0.2093309211498967, 0.24428653023620217], Action prob: [0.8700735  0.12992653], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.3862413521142109, 0.6570985665354124, 0.2519279727036768, 0.24888344163170736], Action prob: [0.8709678  0.12903215], Action: 0, state: 1\n",
      "Sensor: [0.39975532747030773, 0.5904426079957767, 0.21161966761919526, 0.25815673262719396], Action prob: [0.8707871  0.12921289], Action: 0, state: 2\n",
      "Sensor: [0.36095338369288477, 0.6008964838908275, 0.189419073326207, 0.23768850270820488], Action prob: [0.87027645 0.12972349], Action: 0, state: 3\n",
      "tensor([-0.5498, -0.3252, -2.9264, -0.1694, -0.0973, -0.0348,  0.0156,  0.0608,\n",
      "         0.1019,  0.1344,  2.2535,  0.1612,  0.1767,  0.1913,  0.1997,  0.1388,\n",
      "         0.0821,  0.0269, -0.0205, -0.9120, -0.0512, -0.0391, -0.0296, -0.3241,\n",
      "        -0.0188, -0.0126, -0.0093], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 48 is 1000, loss is 0.07322367968527244\n",
      "Sensor: [0.4039421260702872, 0.6772646312995669, 0.20197495145523597, 0.24128752731101755], Action prob: [0.82059693 0.17940304], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.49114936269422116, 0.6141842463435981, 0.18273540711969716, 0.248499741576918], Action prob: [0.8589249 0.141075 ], Action: 0, state: 0\n",
      "Sensor: [0.36531411484150167, 0.6261477424396217, 0.19309254065326173, 0.265541770088558], Action prob: [0.86931276 0.13068724], Action: 0, state: 1\n",
      "Sensor: [0.33724980635298274, 0.637251701459503, 0.18779806771833674, 0.23002356956286374], Action prob: [0.87229943 0.12770055], Action: 0, state: 2\n",
      "Sensor: [0.3497801472416924, 0.6421857945257965, 0.2592095855210309, 0.19574700945723417], Action prob: [0.87381697 0.126183  ], Action: 0, state: 2\n",
      "Sensor: [0.39465956979087813, 0.5520159157803095, 0.4325337870517751, 0.21490396885407054], Action prob: [0.87492806 0.12507193], Action: 0, state: 3\n",
      "Sensor: [0.5264451276391581, 0.664989945939071, 0.1952709680940279, 0.26787179052109733], Action prob: [0.8769418  0.12305813], Action: 0, state: 8\n",
      "Sensor: [0.5973707986547397, 0.6150115309266726, 0.1690801871539928, 0.24142873189395372], Action prob: [0.8773721  0.12262796], Action: 0, state: 8\n",
      "Sensor: [0.5785160574987938, 0.44623171512842835, 0.21845216025018221, 0.26027836903782164], Action prob: [0.8757643  0.12423573], Action: 0, state: 8\n",
      "Sensor: [0.49456096704050223, 0.6453819558385451, 0.20507779892109568, 0.29029976101643434], Action prob: [0.8766622  0.12333778], Action: 0, state: 8\n",
      "Sensor: [0.406096487829069, 0.35702435576072283, 0.2396153467314513, 0.28697147248073757], Action prob: [0.873508   0.12649198], Action: 0, state: 8\n",
      "Sensor: [0.3250582102700362, 0.6302122255672388, 0.20634933320455878, 0.5226999196197678], Action prob: [0.8749798  0.12502018], Action: 0, state: 8\n",
      "Sensor: [0.6047848663175381, 0.6134704454520145, 0.2552454398023677, 0.29791701113893776], Action prob: [0.87742025 0.12257971], Action: 0, state: 8\n",
      "Sensor: [0.5315382769661396, 0.5913981875450562, 0.20088426771846693, 0.21823363357216888], Action prob: [0.8771608  0.12283915], Action: 0, state: 8\n",
      "Sensor: [0.32144637418279454, 0.40241526110686454, 0.24873629622258986, 0.2455433624841323], Action prob: [0.87345076 0.12654924], Action: 0, state: 8\n",
      "Sensor: [0.6067044001333002, 0.5796051748286781, 0.23015571201927082, 0.19201852534280886], Action prob: [0.8753657  0.12463433], Action: 0, state: 8\n",
      "Sensor: [0.6100490179960368, 0.6708053761052671, 0.16487667720576002, 0.18038377886799145], Action prob: [0.8769598  0.12304025], Action: 1, state: 8\n",
      "Sensor: [0.34195579449197655, 0.3563686745200191, 0.21113219626588886, 0.2597384947644336], Action prob: [0.8728313  0.12716872], Action: 0, state: 8\n",
      "Sensor: [0.3077781464055531, 0.5663369562024301, 0.2357195404078312, 0.5093143257815327], Action prob: [0.8737631  0.12623696], Action: 0, state: 8\n",
      "Sensor: [0.32618089053844396, 0.6184713424411575, 0.5210308436043048, 0.28103340272605204], Action prob: [0.8760271  0.12397291], Action: 0, state: 8\n",
      "Sensor: [0.32210158718544724, 0.40069257492626187, 0.2497549116867221, 0.20318520204231605], Action prob: [0.8735016  0.12649843], Action: 0, state: 8\n",
      "Sensor: [0.5666062573233873, 0.640280065893761, 0.2675551622026029, 0.24794736830042657], Action prob: [0.87613    0.12386999], Action: 0, state: 8\n",
      "Sensor: [0.5681383899887439, 0.5899520584948398, 0.18904519621399707, 0.22083572435467425], Action prob: [0.87649375 0.12350621], Action: 1, state: 8\n",
      "Sensor: [0.3503304708975891, 0.6397553875188913, 0.20936452746059214, 0.2747622385633615], Action prob: [0.875928   0.12407199], Action: 0, state: 0\n",
      "Sensor: [0.31113991784434414, 0.6831895158833322, 0.23368420733225762, 0.23547623183130456], Action prob: [0.8759456 0.1240544], Action: 0, state: 0\n",
      "Sensor: [0.3724903078361448, 0.6753160107537692, 0.231474154739351, 0.2765838103769785], Action prob: [0.87639046 0.12360951], Action: 0, state: 0\n",
      "Sensor: [0.32212930860870914, 0.6582650253044624, 0.20859288516578087, 0.25719741844320204], Action prob: [0.87599814 0.12400186], Action: 0, state: 0\n",
      "Sensor: [0.4004765800000046, 0.6173081151158583, 0.18921308419922425, 0.2192952090164991], Action prob: [0.8756098  0.12439022], Action: 0, state: 0\n",
      "Sensor: [0.47550277419994463, 0.6373946905190367, 0.20241320828657217, 0.35797787332134084], Action prob: [0.87654394 0.12345602], Action: 0, state: 1\n",
      "tensor([ 2.0234,  0.1936,  0.1997,  0.2115,  0.2235,  0.2296,  0.1819,  0.1420,\n",
      "         0.1083,  0.0751,  0.0479,  0.0207, -0.0031, -0.0241, -0.0441, -0.0609,\n",
      "        -1.2037, -0.0919, -0.1041, -0.1140, -0.1262, -0.1328, -2.2276, -0.1387,\n",
      "        -0.1366, -0.1341, -0.1327, -0.1314, -0.1290], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 49 is -40700, loss is 0.044066568187349005\n",
      "Sensor: [0.34473131692372694, 0.670822323720931, 0.2030317086497261, 0.21494028514881264], Action prob: [0.8213968  0.17860316], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35085056289920713, 0.6319732933645041, 0.22735017215142997, 0.2442681808429607], Action prob: [0.85790676 0.1420932 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.35530795434188595, 0.6361854582845755, 0.1866495335092057, 0.22081015490332012], Action prob: [0.8676766  0.13232343], Action: 0, state: 0\n",
      "Sensor: [0.2992464267009555, 0.6424929143058845, 0.2153895655915202, 0.28191042902145], Action prob: [0.87044084 0.12955913], Action: 0, state: 0\n",
      "Sensor: [0.3530911574225947, 0.6325784053624691, 0.18163324048395282, 0.18874204474908168], Action prob: [0.871272   0.12872794], Action: 0, state: 0\n",
      "Sensor: [0.4055684712657158, 0.7058074636548963, 0.21999368361799815, 0.2255664589302924], Action prob: [0.8731662 0.1268338], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3542408859513606, 0.6547149447664978, 0.21374196983848587, 0.2331819763490518], Action prob: [0.8733281  0.12667195], Action: 0, state: 1\n",
      "Sensor: [0.37495558550269004, 0.589464322088915, 0.23082857449750002, 0.20835067572933846], Action prob: [0.8727403  0.12725972], Action: 0, state: 1\n",
      "Sensor: [0.371537258175097, 0.6425567446994318, 0.23442183585639617, 0.2509285693666913], Action prob: [0.8731439  0.12685606], Action: 0, state: 1\n",
      "Sensor: [0.34157867917940193, 0.6334025167902604, 0.23048787676731322, 0.23663925516221526], Action prob: [0.8730408  0.12695922], Action: 0, state: 2\n",
      "Sensor: [0.3531678731436259, 0.688389948074102, 0.22276029413967258, 0.2092791893181744], Action prob: [0.8735259  0.12647408], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "Sensor: [0.4140181778710922, 0.6125618410561952, 0.20237239008381075, 0.2097639236844673], Action prob: [0.87312937 0.12687057], Action: 0, state: 1\n",
      "Sensor: [0.3681184804997653, 0.679246629654012, 0.19214240505126282, 0.24104037529863992], Action prob: [0.87342364 0.12657638], Action: 0, state: 2\n",
      "Sensor: [0.2989617292723699, 0.5732753822774364, 0.2546044760493775, 0.2317978505330954], Action prob: [0.87219965 0.12780029], Action: 0, state: 3\n",
      "Sensor: [0.3491156168085941, 0.4330212848208893, 0.26649323263999675, 0.2990550907381848], Action prob: [0.87056005 0.1294399 ], Action: 0, state: 8\n",
      "Sensor: [0.37357711788184245, 0.32561319015636336, 0.19127881094276628, 0.25024410439511036], Action prob: [0.8682093  0.13179073], Action: 0, state: 8\n",
      "Sensor: [0.3711456559215468, 0.42150004327537516, 0.22776557330296598, 0.2806973265821499], Action prob: [0.8683764  0.13162357], Action: 0, state: 8\n",
      "Sensor: [0.5812167285388612, 0.6337509962742784, 0.19484945368442894, 0.17276967320575579], Action prob: [0.8721288  0.12787126], Action: 1, state: 8\n",
      "Sensor: [0.3988860509435841, 0.29117533571928816, 0.242095850941911, 0.2616362257701919], Action prob: [0.8688319  0.13116814], Action: 0, state: 8\n",
      "Sensor: [0.2687172040899872, 0.20100902304779936, 0.196904015102975, 0.30257752007147454], Action prob: [0.86496234 0.13503769], Action: 0, state: 8\n",
      "Sensor: [0.39117902071685795, 0.43476963914083094, 0.22586524658983478, 0.23946200524105396], Action prob: [0.8670548  0.13294517], Action: 0, state: 8\n",
      "Sensor: [0.3881143506285437, 0.4008687288708087, 0.1939315630755687, 0.2372557342750089], Action prob: [0.8675053  0.13249466], Action: 1, state: 8\n",
      "Sensor: [0.38023318287343133, 0.3801439994029681, 0.2568936428641226, 0.21829326811007585], Action prob: [0.8675641 0.1324359], Action: 0, state: 8\n",
      "Sensor: [0.38869954413380625, 0.5828194119306608, 0.24663167105204375, 0.5382215212240333], Action prob: [0.87120944 0.12879057], Action: 0, state: 8\n",
      "Sensor: [0.36362590593940997, 0.31123395271100185, 0.18871555168969428, 0.29011707190883734], Action prob: [0.8688271 0.1311729], Action: 0, state: 8\n",
      "tensor([-2.4563, -2.2194, -0.1614, -0.0930, -0.0345,  0.0171,  0.0587,  0.0966,\n",
      "         0.1298,  0.1569,  2.7564,  0.1783,  0.1974,  0.2106,  0.1529,  0.1003,\n",
      "         0.0497,  0.0599, -0.0358, -0.0743, -0.1069, -1.9383, -0.1632, -0.1819,\n",
      "        -0.2067], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 50 is -27000, loss is 0.14029504557091774\n",
      "Sensor: [0.38960767116651024, 0.6103121446528719, 0.16984831613318752, 0.2464958404579634], Action prob: [0.81543005 0.1845699 ], Action: 0, state: 0\n",
      "Sensor: [0.3973426279857891, 0.6614201612520146, 0.20439357275584452, 0.24568295629693915], Action prob: [0.8505129  0.14948708], Action: 0, state: 0\n",
      "Sensor: [0.3681810564621856, 0.6916077113087643, 0.2077510606758914, 0.2597577009524731], Action prob: [0.860055   0.13994499], Action: 0, state: 1\n",
      "Sensor: [0.364507598011129, 0.5943615404629653, 0.22873061245565388, 0.24931291234187133], Action prob: [0.86128426 0.13871576], Action: 0, state: 1\n",
      "Sensor: [0.37466520222618316, 0.6100356990508219, 0.20584105463085728, 0.20735765054689023], Action prob: [0.86155766 0.13844232], Action: 0, state: 1\n",
      "Sensor: [0.3344843511386546, 0.6086829892686864, 0.21757815776321612, 0.21100194940426076], Action prob: [0.86150336 0.13849668], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.3769716606282013, 0.642934691799128, 0.19173889364769878, 0.22290486751567573], Action prob: [0.8621812 0.1378188], Action: 0, state: 1\n",
      "Sensor: [0.3528042590042985, 0.6317450501070354, 0.191166396100441, 0.2754830293609457], Action prob: [0.8623257  0.13767433], Action: 0, state: 1\n",
      "Sensor: [0.3865520765356363, 0.6021163493924858, 0.19370086349749982, 0.3012822871681521], Action prob: [0.86237925 0.13762072], Action: 0, state: 1\n",
      "Sensor: [0.37454785426459813, 0.6709861554995097, 0.19819473243806088, 0.2525565177733332], Action prob: [0.8630967 0.1369033], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.33427478100538394, 0.6164567086569417, 0.23202536014519287, 0.2518356391094126], Action prob: [0.8625958  0.13740413], Action: 0, state: 0\n",
      "Sensor: [0.33225243157209655, 0.6539572850876242, 0.1798971699171331, 0.2504496149856804], Action prob: [0.86259043 0.13740958], Action: 0, state: 0\n",
      "Sensor: [0.3743223871847796, 0.626864635891223, 0.19339393519078804, 0.304341088799998], Action prob: [0.8626745  0.13732547], Action: 0, state: 1\n",
      "Sensor: [0.3565476686599644, 0.6157992441194791, 0.20739059328760234, 0.31543220847289194], Action prob: [0.8626601 0.1373399], Action: 0, state: 1\n",
      "Sensor: [0.3227174606372628, 0.6178673978233928, 0.2080261121036122, 0.2812094814262533], Action prob: [0.86241704 0.13758291], Action: 0, state: 1\n",
      "Sensor: [0.39483585707584284, 0.6425706078737269, 0.19884404910651615, 0.25620792445166096], Action prob: [0.8629126  0.13708739], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3583874501546344, 0.6801823603734626, 0.2801536237311655, 0.27555551300897085], Action prob: [0.8637405  0.13625954], Action: 0, state: 0\n",
      "Sensor: [0.38317225677895417, 0.6156528015604865, 0.22839410405206556, 0.24766846388163846], Action prob: [0.86328274 0.13671732], Action: 0, state: 0\n",
      "Sensor: [0.29935588867509966, 0.6159366564451957, 0.19067981691194902, 0.2738541382443266], Action prob: [0.8623123  0.13768767], Action: 0, state: 0\n",
      "Sensor: [0.4204746906765113, 0.5943326714655779, 0.1897035705935173, 0.294488393262192], Action prob: [0.8624112  0.13758884], Action: 0, state: 1\n",
      "Sensor: [0.324717357662336, 0.6294790803542822, 0.19129408727033287, 0.23649725922987364], Action prob: [0.86214525 0.1378547 ], Action: 0, state: 2\n",
      "Sensor: [0.40461432714347084, 0.6248716512144213, 0.19509478181039686, 0.22862759628759077], Action prob: [0.8624353  0.13756475], Action: 0, state: 3\n",
      "Sensor: [0.34648339500754743, 0.6160480268412332, 0.20962316245810125, 0.22552852698293038], Action prob: [0.862117   0.13788296], Action: 0, state: 3\n",
      "Sensor: [0.3629827439615478, 0.6573373863448057, 0.5215225045759989, 0.24893951754954347], Action prob: [0.8641314  0.13586861], Action: 0, state: 3\n",
      "Sensor: [0.6129627245973114, 0.6169705895353179, 0.20357804482375813, 0.27856080412121037], Action prob: [0.8651732  0.13482675], Action: 0, state: 8\n",
      "Sensor: [0.36221178155456046, 0.3826240630110088, 0.23527548063714607, 0.21067106487037168], Action prob: [0.8606163  0.13938369], Action: 0, state: 8\n",
      "tensor([-0.5124, -0.3311, -0.2512, -0.1977, -0.1516, -1.5261, -0.0981, -0.0648,\n",
      "        -0.0349, -0.1102,  0.0053,  0.0294,  0.0490,  0.0665,  0.0825,  1.2978,\n",
      "         0.0955,  0.1088,  0.1212,  0.1306,  0.1382,  0.1421,  0.1462,  0.1468,\n",
      "         0.1281,  0.1163], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 51 is 8900, loss is 0.018228592914451936\n",
      "Sensor: [0.39956253604414255, 0.6187900324159287, 0.2236593536675051, 0.271591674552317], Action prob: [0.8109728  0.18902715], Action: 0, state: 0\n",
      "Sensor: [0.3560928442258553, 0.6613767783311764, 0.19542629556869506, 0.254342166100362], Action prob: [0.8417436  0.15825644], Action: 0, state: 1\n",
      "Sensor: [0.3508395967795206, 0.6725248554874453, 0.19730781936878194, 0.23406827027262683], Action prob: [0.84843564 0.15156439], Action: 0, state: 2\n",
      "Sensor: [0.378022716316148, 0.6417382439824533, 0.2287023396877412, 0.2977290234082764], Action prob: [0.8492574  0.15074259], Action: 0, state: 2\n",
      "Sensor: [0.39328344176174224, 0.6881006563213463, 0.24935305487109635, 0.1919445272720285], Action prob: [0.84990513 0.15009479], Action: 0, state: 3\n",
      "Sensor: [0.3832308667377236, 0.643559273653377, 0.20409314999866632, 0.25918479864605265], Action prob: [0.8495226  0.15047741], Action: 0, state: 3\n",
      "Sensor: [0.34528019110859975, 0.604279658604516, 0.21856647691855824, 0.17552264923178956], Action prob: [0.84840316 0.1515969 ], Action: 0, state: 3\n",
      "Sensor: [0.5583277416450542, 0.6539930851233844, 0.1848489012690837, 0.22427784429017572], Action prob: [0.8497839 0.1502161], Action: 0, state: 8\n",
      "Sensor: [0.3709981029506215, 0.34447638142060266, 0.16400382169706235, 0.2655896956740518], Action prob: [0.844925   0.15507504], Action: 0, state: 8\n",
      "Sensor: [0.6232921668923614, 0.635740892132704, 0.2453102734359063, 0.23492130026767036], Action prob: [0.84878373 0.1512162 ], Action: 0, state: 8\n",
      "Sensor: [0.5193403513208934, 0.6199847627861088, 0.23596905672487953, 0.5158752635998957], Action prob: [0.8505315  0.14946845], Action: 0, state: 8\n",
      "Sensor: [0.6198194117082436, 0.6202751643740356, 0.22816877284705922, 0.4424076773024122], Action prob: [0.85192525 0.14807475], Action: 1, state: 8\n",
      "Sensor: [0.28233450601742793, 0.6593535745565731, 0.23090556667408857, 0.24389442304211437], Action prob: [0.8502555 0.1497445], Action: 0, state: 0\n",
      "Sensor: [0.34385644262938386, 0.6017746655684949, 0.16200971140522874, 0.2341000533453017], Action prob: [0.84853005 0.15146999], Action: 0, state: 0\n",
      "Sensor: [0.348908593767914, 0.6536737188645166, 0.24636978852409158, 0.20539477741681944], Action prob: [0.8486614  0.15133859], Action: 0, state: 1\n",
      "Sensor: [0.3091705590718502, 0.607313430677166, 0.21011221301651034, 0.23268042313733134], Action prob: [0.8479201  0.15207982], Action: 0, state: 1\n",
      "Sensor: [0.3123478083269214, 0.5826677091508854, 0.2201455446047531, 0.24670836416839698], Action prob: [0.8474097  0.15259027], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.35754812095595506, 0.6869231477151537, 0.26056135573008105, 0.303282065554021], Action prob: [0.84932965 0.15067041], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.40226050048269796, 0.6116666304416991, 0.24478565160167076, 0.21720615814270708], Action prob: [0.8491927  0.15080732], Action: 0, state: 0\n",
      "Sensor: [0.3534678935996297, 0.6340946362643206, 0.21280814926212172, 0.2539874885850219], Action prob: [0.84892404 0.15107593], Action: 0, state: 1\n",
      "Sensor: [0.3287235318250291, 0.5764481132470182, 0.18647578061634276, 0.20923511677397125], Action prob: [0.8475547  0.15244538], Action: 0, state: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3416630628767485, 0.6767489683798199, 0.20968727528604394, 0.2869454452482636], Action prob: [0.84870267 0.15129733], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "tensor([ 0.0621,  0.1245,  0.1747,  0.2240,  0.2507,  0.2770,  0.3022,  0.1763,\n",
      "         0.0688, -0.0342, -0.1225, -2.3929, -0.1794, -0.1595, -0.1418, -0.1263,\n",
      "        -1.2737, -1.4511, -0.1188, -0.1085, -0.1010, -1.0678],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 52 is -4900, loss is 0.2553238424822127\n",
      "Sensor: [0.3766060538367276, 0.6332404179511367, 0.20087494314394108, 0.24805005207486283], Action prob: [0.7935757  0.20642433], Action: 0, state: 0\n",
      "Sensor: [0.37679927632905064, 0.6505217387869484, 0.183343105978927, 0.26194745816104376], Action prob: [0.81702644 0.18297356], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "Sensor: [0.3790031778749672, 0.6582379147841813, 0.26812096573215405, 0.22834894034047248], Action prob: [0.81878495 0.18121509], Action: 0, state: 0\n",
      "Sensor: [0.34993182689746094, 0.6657048875840266, 0.2041253266309655, 0.26729701578014586], Action prob: [0.81704575 0.18295424], Action: 0, state: 0\n",
      "Sensor: [0.32749743304881657, 0.6341487909228684, 0.23427451468074006, 0.2416090559181153], Action prob: [0.8151632  0.18483686], Action: 0, state: 0\n",
      "Sensor: [0.3120649604495768, 0.621694425807018, 0.23075067989835335, 0.24351738018883157], Action prob: [0.8140306  0.18596944], Action: 0, state: 0\n",
      "Sensor: [0.38434833303916904, 0.600539575613884, 0.27717005807562545, 0.3553206367645568], Action prob: [0.8142283  0.18577176], Action: 0, state: 0\n",
      "Sensor: [0.34489966178985937, 0.7052990239520733, 0.21295383623688233, 0.1711451230719109], Action prob: [0.8148356  0.18516435], Action: 0, state: 1\n",
      "Sensor: [0.3395848362477115, 0.6012535262244887, 0.20477736117483314, 0.2985884824726734], Action prob: [0.81355554 0.18644445], Action: 0, state: 1\n",
      "Sensor: [0.4018772414643559, 0.6126504544100929, 0.20863239146124257, 0.21633363303256192], Action prob: [0.81335896 0.18664098], Action: 0, state: 2\n",
      "Sensor: [0.38034310130626037, 0.6436013107834934, 0.20718938861306715, 0.5325894520674008], Action prob: [0.8145961 0.1854039], Action: 0, state: 2\n",
      "Sensor: [0.3733987514481539, 0.5969334612200257, 0.5986123403495961, 0.30278049885998803], Action prob: [0.81572354 0.18427649], Action: 0, state: 3\n",
      "Sensor: [0.38312999774342194, 0.6083720851849798, 0.23006960768366325, 0.2327595541599023], Action prob: [0.81475633 0.18524371], Action: 0, state: 3\n",
      "Sensor: [0.6014239322845257, 0.43941573738568507, 0.1920108629310725, 0.24037698721730244], Action prob: [0.8122157  0.18778434], Action: 0, state: 3\n",
      "Sensor: [0.3660489738868434, 0.6512174517915555, 0.2013716833589411, 0.2568937221159231], Action prob: [0.8128586  0.18714139], Action: 0, state: 3\n",
      "Sensor: [0.6137995862500892, 0.6646045686051014, 0.19003122805577993, 0.22920766277770202], Action prob: [0.814802 0.185198], Action: 1, state: 8\n",
      "Sensor: [0.37582090316579875, 0.3355795990304752, 0.18736914195055965, 0.28145438793399874], Action prob: [0.80939937 0.19060057], Action: 0, state: 8\n",
      "Sensor: [0.3884643795482585, 0.6381656815608017, 0.18622438437491065, 0.5458078414219882], Action prob: [0.8129209  0.18707913], Action: 0, state: 8\n",
      "Sensor: [0.5473657608162699, 0.6152433324188683, 0.25170820854713843, 0.23801843872385248], Action prob: [0.8145371  0.18546295], Action: 0, state: 8\n",
      "Sensor: [0.3790494876797455, 0.6286524126286538, 0.2148614606562664, 0.5627177429175553], Action prob: [0.8149846  0.18501543], Action: 0, state: 8\n",
      "Sensor: [0.5628598967537818, 0.6218371100353651, 0.2039078535743465, 0.19447134567411764], Action prob: [0.815095   0.18490498], Action: 0, state: 8\n",
      "Sensor: [0.6239030021561222, 0.6241771296494538, 0.23435553919494778, 0.2531434418911681], Action prob: [0.8152734  0.18472661], Action: 0, state: 8\n",
      "Sensor: [0.38669933686735297, 0.3441816174103811, 0.25166652566302233, 0.23492822370751654], Action prob: [0.809904   0.19009607], Action: 0, state: 8\n",
      "Sensor: [0.3795599264283604, 0.6237565369467867, 0.49290564466893183, 0.27927266732799494], Action prob: [0.8132223  0.18677774], Action: 0, state: 8\n",
      "Sensor: [0.36824323141512233, 0.5939084018009927, 0.5273542445160061, 0.25403104892162126], Action prob: [0.8146109 0.1853891], Action: 0, state: 8\n",
      "tensor([-0.3315, -1.3395, -0.3320, -0.2298, -0.1364, -0.0502,  0.0283,  0.0909,\n",
      "         0.1494,  0.1953,  0.2352,  0.2555,  0.2784,  0.3022,  0.3174,  1.8366,\n",
      "         0.1471,  0.0693,  0.0020, -0.0570, -0.1108, -0.1588, -0.2078, -0.2444,\n",
      "        -0.2776], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 53 is -24100, loss is -0.01727138108896369\n",
      "Sensor: [0.3365531494643264, 0.6557476447038778, 0.19582788486717725, 0.20440732204931186], Action prob: [0.7787795  0.22122052], Action: 0, state: 0\n",
      "Sensor: [0.39739278117222, 0.6694492699801815, 0.19563116275565237, 0.2726931869945537], Action prob: [0.7942972  0.20570274], Action: 0, state: 0\n",
      "Sensor: [0.3933901173033027, 0.6333100832735798, 0.23270225505365, 0.2681063006708369], Action prob: [0.7909944  0.20900556], Action: 0, state: 0\n",
      "Sensor: [0.3432360556651764, 0.5988903173897776, 0.20343536664351275, 0.2354921592073962], Action prob: [0.7857429 0.2142571], Action: 0, state: 1\n",
      "Sensor: [0.3777031963606534, 0.6501322393579978, 0.2460874237423374, 0.25025783298168924], Action prob: [0.78372306 0.21627694], Action: 0, state: 1\n",
      "Sensor: [0.4006239044310495, 0.5514727158299779, 0.2087659611688814, 0.25682894730875466], Action prob: [0.7811394  0.21886066], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.32661005463630244, 0.6452291244055459, 0.27815939916909654, 0.32067885221999803], Action prob: [0.7814388  0.21856116], Action: 0, state: 1\n",
      "Sensor: [0.3557253931326447, 0.5895681519532393, 0.21898588188624518, 0.24392679181918023], Action prob: [0.7804476  0.21955247], Action: 0, state: 1\n",
      "Sensor: [0.37712075829009517, 0.7032043289692372, 0.23662128432798601, 0.26383680599174963], Action prob: [0.7817723 0.2182277], Action: 0, state: 2\n",
      "Sensor: [0.3641557901965339, 0.6445286585848254, 0.1974763879675508, 0.21088970871434887], Action prob: [0.7809961  0.21900387], Action: 0, state: 3\n",
      "Sensor: [0.34106920234498506, 0.6165019831642069, 0.22898750702485124, 0.22869617671299353], Action prob: [0.7802121  0.21978788], Action: 0, state: 3\n",
      "Sensor: [0.3944289047651125, 0.6558521886706972, 0.2298494180534074, 0.20491997141166612], Action prob: [0.78085494 0.21914509], Action: 0, state: 3\n",
      "Sensor: [0.44674594324164274, 0.5990015042863817, 0.20556210960699486, 0.27072421584316464], Action prob: [0.78053963 0.21946031], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "Sensor: [0.3446179604591164, 0.6030827865719416, 0.2201056608261986, 0.20349770831654213], Action prob: [0.7797607  0.22023925], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.36106334394140555, 0.6356361891681406, 0.18638808584623429, 0.22915173573797157], Action prob: [0.78002334 0.21997672], Action: 0, state: 1\n",
      "Sensor: [0.32504827967288585, 0.662613846891902, 0.24034174037348688, 0.22872897635187767], Action prob: [0.78059447 0.21940552], Action: 0, state: 1\n",
      "Sensor: [0.36835444082014457, 0.6339637858353738, 0.21689777468077626, 0.2258120536888046], Action prob: [0.78060293 0.21939708], Action: 0, state: 2\n",
      "Sensor: [0.3764465075499819, 0.6588817970101761, 0.21039163016732607, 0.23264411785698444], Action prob: [0.7809682  0.21903183], Action: 0, state: 2\n",
      "Sensor: [0.3794047613190728, 0.6231213614254132, 0.2305203348421589, 0.21719339706720406], Action prob: [0.78057647 0.21942353], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "Sensor: [0.478697361163249, 0.6487100234850975, 0.22987913854276337, 0.2717910391679942], Action prob: [0.7814666  0.21853338], Action: 0, state: 2\n",
      "Sensor: [0.573700933870033, 0.6582079906656647, 0.20893431103455512, 0.22536075699699099], Action prob: [0.78214395 0.21785605], Action: 0, state: 3\n",
      "Sensor: [0.3839383883750955, 0.6330374080444967, 0.14468286402574268, 0.16205994592779865], Action prob: [0.7803719  0.21962805], Action: 0, state: 3\n",
      "Sensor: [0.3888916710268911, 0.3562997517500571, 0.20472224434331893, 0.21531183324299133], Action prob: [0.7756609  0.22433911], Action: 0, state: 8\n",
      "Sensor: [0.6546282345269498, 0.6460396225188585, 0.21634485268293838, 0.27850068001229694], Action prob: [0.78037316 0.21962681], Action: 0, state: 8\n",
      "tensor([-0.6772, -0.4926, -0.3814, -0.2920, -0.2044, -0.8177, -0.1000, -0.0328,\n",
      "         0.0207,  0.0512,  0.0788,  0.1030,  0.7690,  0.7174,  0.1322,  0.1606,\n",
      "         0.1840,  0.2044,  1.3265,  0.2115,  0.2201,  0.2308,  0.1899,  0.1428],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 54 is 3700, loss is -0.07270241426110219\n",
      "Sensor: [0.36545216739177766, 0.6235906928676938, 0.20571410681573085, 0.2763692491883982], Action prob: [0.7693329  0.23066714], Action: 0, state: 0\n",
      "Sensor: [0.36796604971729185, 0.607117388181497, 0.2556099507716112, 0.23150230382599146], Action prob: [0.77645105 0.22354889], Action: 0, state: 0\n",
      "Sensor: [0.34119061313885785, 0.6143354489613412, 0.20484184473785638, 0.24327331232770344], Action prob: [0.7691486 0.2308515], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.34291942774511863, 0.6720675948977044, 0.25338927549569923, 0.23243531455391836], Action prob: [0.76328874 0.23671128], Action: 0, state: 0\n",
      "Sensor: [0.32533416732074166, 0.6178899000876452, 0.21729734361443967, 0.21175909367965717], Action prob: [0.75849056 0.24150942], Action: 0, state: 0\n",
      "Sensor: [0.31413451476759435, 0.6606572571967066, 0.21837648596725, 0.2528286597853562], Action prob: [0.75679296 0.24320704], Action: 0, state: 1\n",
      "Sensor: [0.3699951328529534, 0.5981856966576957, 0.20494715102017358, 0.253459633507347], Action prob: [0.755139   0.24486099], Action: 0, state: 1\n",
      "Sensor: [0.36059599387600105, 0.5961351529880604, 0.1935456163666173, 0.2484832992396359], Action prob: [0.75410354 0.24589641], Action: 0, state: 1\n",
      "Sensor: [0.3427285003704202, 0.6087938444218254, 0.20730362810038983, 0.279499495249221], Action prob: [0.75383437 0.24616563], Action: 0, state: 2\n",
      "Sensor: [0.35911311770302595, 0.6299639842933515, 0.216223222678176, 0.2748639527473878], Action prob: [0.75417376 0.24582629], Action: 0, state: 2\n",
      "Sensor: [0.4046313521214016, 0.6640682136920433, 0.2578684803632227, 0.2933077973776406], Action prob: [0.75517297 0.24482703], Action: 0, state: 2\n",
      "Sensor: [0.3594161703389583, 0.6172189693871413, 0.2580637828250678, 0.28416793872845897], Action prob: [0.75444615 0.24555388], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1200\n",
      "Sensor: [0.4117269959222776, 0.591161852853259, 0.22913095297067518, 0.223895099055318], Action prob: [0.75370324 0.24629675], Action: 0, state: 2\n",
      "Sensor: [0.3804379169446544, 0.632662839981725, 0.23671244710398112, 0.24027217412110466], Action prob: [0.753866   0.24613401], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "Sensor: [0.37007048002447457, 0.626377475586147, 0.198429553561539, 0.3017750471400843], Action prob: [0.7538843  0.24611568], Action: 0, state: 2\n",
      "Sensor: [0.28077692885060357, 0.6332079356552455, 0.2024642943186643, 0.2290653374145802], Action prob: [0.7534769  0.24652301], Action: 0, state: 2\n",
      "Sensor: [0.3748562324342078, 0.5939083023228758, 0.22093117041140753, 0.26910553929391146], Action prob: [0.7534547  0.24654533], Action: 0, state: 2\n",
      "Sensor: [0.3071484996978756, 0.43252488673753436, 0.2322722332624808, 0.22303993547805243], Action prob: [0.7504211 0.2495789], Action: 0, state: 2\n",
      "Sensor: [0.3854986662970724, 0.6263016112805588, 0.22738612778926975, 0.2791589937986593], Action prob: [0.75307345 0.24692652], Action: 0, state: 2\n",
      "Sensor: [0.35312939379710295, 0.6365747695592374, 0.22193698765519004, 0.24456742059407663], Action prob: [0.75391465 0.24608535], Action: 0, state: 2\n",
      "Sensor: [0.4345298195686765, 0.6378571027470038, 0.23324162013691907, 0.20700238194865445], Action prob: [0.7544714  0.24552856], Action: 0, state: 3\n",
      "tensor([-0.6299, -0.4507, -1.7902, -0.3983, -0.2820, -0.1821, -0.0905, -0.0070,\n",
      "         0.0602,  0.1204,  0.1737,  1.0217,  0.1396,  0.8145,  0.1555,  0.1878,\n",
      "         0.2170,  0.2470,  0.2669,  0.2868,  0.2978], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for up to this episode 55 is 8700, loss is -0.007540622820540273\n",
      "Sensor: [0.35736438845881136, 0.6022909804342116, 0.21315226970158502, 0.29035408680924735], Action prob: [0.75936955 0.24063051], Action: 0, state: 0\n",
      "Sensor: [0.40748476821407265, 0.6429051033763878, 0.18805979144879453, 0.27845374253718885], Action prob: [0.7581642  0.24183582], Action: 0, state: 0\n",
      "Sensor: [0.3452167058813258, 0.6574578032645497, 0.23042188944732667, 0.30452908248787025], Action prob: [0.7456666 0.2543334], Action: 0, state: 0\n",
      "Sensor: [0.4463949249581446, 0.5791911185497827, 0.19608761781590073, 0.2640770298241236], Action prob: [0.73442537 0.2655746 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3159428864730566, 0.6526030309025839, 0.24968601519388206, 0.2514657489830052], Action prob: [0.72834533 0.27165464], Action: 0, state: 0\n",
      "Sensor: [0.37997039760789264, 0.6403155397325214, 0.23801737628106492, 0.21242445391495526], Action prob: [0.7249856 0.2750145], Action: 0, state: 0\n",
      "Sensor: [0.3458435765760524, 0.6150854724570932, 0.22363567042615543, 0.2522113791130639], Action prob: [0.7225402 0.2774598], Action: 0, state: 0\n",
      "Sensor: [0.3142429016848345, 0.6156970339549726, 0.23065039772166704, 0.20499427169340395], Action prob: [0.72118944 0.2788106 ], Action: 0, state: 0\n",
      "Sensor: [0.37535301507210383, 0.6125257930535447, 0.20705461530013397, 0.29871312698209934], Action prob: [0.7209308  0.27906922], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.36564924683424627, 0.7122959402553425, 0.22026455910875786, 0.21512737684166094], Action prob: [0.72217906 0.27782091], Action: 0, state: 0\n",
      "Sensor: [0.3553590880833077, 0.6106887053639982, 0.18220193721055056, 0.26128876560481296], Action prob: [0.72071093 0.27928907], Action: 0, state: 0\n",
      "Sensor: [0.38093991672196004, 0.6272053017174667, 0.18949969024931673, 0.2697261495170101], Action prob: [0.72062784 0.27937216], Action: 0, state: 0\n",
      "Sensor: [0.4026387123619023, 0.6409390862555533, 0.21572592783567213, 0.27908340388764724], Action prob: [0.7209679  0.27903205], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.36906792240837666, 0.6400647725737201, 0.2012726459321573, 0.22681019032205801], Action prob: [0.7206766 0.2793234], Action: 0, state: 0\n",
      "Sensor: [0.35545222349286437, 0.6572987363767725, 0.20814630930930886, 0.23797200309083386], Action prob: [0.72082597 0.27917403], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3005125900460783, 0.6345051933617001, 0.18268798737669031, 0.24880969721674828], Action prob: [0.7203508  0.27964926], Action: 0, state: 0\n",
      "Sensor: [0.3475651024939285, 0.6648572910515382, 0.21835817145990222, 0.2979708165696323], Action prob: [0.72127235 0.27872765], Action: 0, state: 1\n",
      "Sensor: [0.3760016134827901, 0.3905002371228523, 0.23504996001580247, 0.2545571730151285], Action prob: [0.71707135 0.28292868], Action: 1, state: 1\n",
      "Sensor: [0.4038695428317326, 0.42059490285752155, 0.2124084759805421, 0.25187518914185664], Action prob: [0.71605253 0.28394744], Action: 1, state: 9\n",
      "Sensor: [0.5158922435027097, 0.6309419549451725, 0.20892023613497285, 0.5484201982201945], Action prob: [0.7205943  0.27940577], Action: 1, state: 9\n",
      "Sensor: [0.3983585707111894, 0.33261308613943924, 0.21907534834124304, 0.20085293079019356], Action prob: [0.7154421  0.28455794], Action: 0, state: 9\n",
      "Sensor: [0.35598372675699536, 0.40955136037880413, 0.19882517981669706, 0.24230498619783108], Action prob: [0.71455675 0.28544328], Action: 1, state: 9\n",
      "tensor([-0.6814, -0.5397, -0.4331, -1.3896, -0.3328, -0.2265, -0.1276, -0.0370,\n",
      "         0.1784,  0.0448,  0.1126,  0.1727,  0.8622,  0.2212,  1.0320,  0.2655,\n",
      "         0.2962,  1.2598,  1.1454,  1.0583,  0.2546,  0.8724],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 56 is 7700, loss is -0.18220282499336163\n",
      "Sensor: [0.3715542009887426, 0.7132304628063478, 0.20757481881748932, 0.22804896605384137], Action prob: [0.7642222  0.23577783], Action: 0, state: 0\n",
      "Sensor: [0.36015260002336447, 0.6907792558368734, 0.18430305657738877, 0.27594373266060507], Action prob: [0.7646025  0.23539759], Action: 0, state: 0\n",
      "Sensor: [0.3926192647666243, 0.6400923444063745, 0.23894923920278802, 0.20863519168570013], Action prob: [0.75393    0.24606998], Action: 0, state: 0\n",
      "Sensor: [0.36056649742403685, 0.6557333438529752, 0.2041703181687512, 0.24294097910972057], Action prob: [0.7459566  0.25404337], Action: 0, state: 0\n",
      "Sensor: [0.3242398506241979, 0.6280604212554205, 0.17200415831614987, 0.31156039525873663], Action prob: [0.740965   0.25903496], Action: 0, state: 0\n",
      "Sensor: [0.36403298692567826, 0.6528535757119571, 0.25329615473228595, 0.22135550855651803], Action prob: [0.7391473  0.26085263], Action: 0, state: 1\n",
      "Sensor: [0.32427646944125815, 0.6735807574474819, 0.2021509248684827, 0.23663332674473858], Action prob: [0.738003   0.26199698], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.34118220846998276, 0.6977302322302384, 0.19811204145575362, 0.21244023498997383], Action prob: [0.7377545  0.26224548], Action: 0, state: 0\n",
      "Sensor: [0.3468846268207495, 0.6352987143299836, 0.21552252039541148, 0.28946393355392164], Action prob: [0.7368716  0.26312843], Action: 0, state: 0\n",
      "Sensor: [0.35281441878475484, 0.6686635347105521, 0.20589766265410567, 0.23302513670401565], Action prob: [0.7368949  0.26310515], Action: 0, state: 1\n",
      "Sensor: [0.3246102600572577, 0.6145898446856792, 0.212507636379673, 0.19214091170413736], Action prob: [0.73584735 0.26415274], Action: 0, state: 2\n",
      "Sensor: [0.35205525504756396, 0.5804656232874797, 0.2206994247361091, 0.26427313540313396], Action prob: [0.73533154 0.26466846], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "Sensor: [0.3440632154311098, 0.7165689345288845, 0.22016833224333685, 0.3054795466005296], Action prob: [0.73728967 0.26271036], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.479036653187688, 0.6542244565686243, 0.24502446027568314, 0.26973623714234274], Action prob: [0.73749197 0.26250806], Action: 0, state: 0\n",
      "Sensor: [0.33930117829370376, 0.6613651184012436, 0.20321758108000657, 0.2572291798566092], Action prob: [0.7365519  0.26344806], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.37442575176987775, 0.6686501344399685, 0.22380305874192893, 0.4206637471746333], Action prob: [0.73702407 0.262976  ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.31817638373601165, 0.6291546908879826, 0.22475270044608547, 0.2928276222871956], Action prob: [0.736157   0.26384294], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.27973802726927455, 0.71518931118271, 0.4097704673552639, 0.29372711753908737], Action prob: [0.73762625 0.26237375], Action: 0, state: 0\n",
      "Sensor: [0.32875368645455366, 0.6882061306722791, 0.23104534711948863, 0.28117692920530196], Action prob: [0.7373331  0.26266688], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.6564, -0.5099, -0.3994, -0.2861, -0.1741, -0.0798,  0.0317, -0.0366,\n",
      "         0.0425,  0.1062,  0.1582,  0.8870,  0.8672,  0.2208,  1.1328,  1.1355,\n",
      "         1.2063,  0.2898,  1.3963], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 57 is 12600, loss is -0.28062484914333047\n",
      "Sensor: [0.3192190122780832, 0.6726265398276534, 0.22268754095417856, 0.2467295935575613], Action prob: [0.7794872  0.22051282], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3552656261291635, 0.6706375798969051, 0.2321079171504837, 0.2881674572246053], Action prob: [0.7884588  0.21154118], Action: 0, state: 0\n",
      "Sensor: [0.3217967069355542, 0.6241125701866103, 0.2405813495395388, 0.2514563436744189], Action prob: [0.7835484  0.21645166], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.32579523779975506, 0.6774487201395343, 0.23276737872098738, 0.2882984628660683], Action prob: [0.7804078  0.21959223], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.34982753990111387, 0.5935112090338641, 0.20850745420293995, 0.43202376047567514], Action prob: [0.77792037 0.22207965], Action: 0, state: 0\n",
      "Sensor: [0.39076798857114325, 0.6156044435130198, 0.19812606681360412, 0.2294741083318062], Action prob: [0.7766632  0.22333682], Action: 0, state: 0\n",
      "Sensor: [0.3151573920446288, 0.6812130683663643, 0.23358012849222323, 0.22965128740572657], Action prob: [0.7766842  0.22331583], Action: 0, state: 0\n",
      "Sensor: [0.3866185376456861, 0.5826739488847974, 0.20230259724259905, 0.25771573086271465], Action prob: [0.7755587  0.22444129], Action: 0, state: 0\n",
      "Sensor: [0.33399370889126745, 0.6336842574640092, 0.20754372221147058, 0.3343212184393623], Action prob: [0.7758378  0.22416225], Action: 0, state: 0\n",
      "Sensor: [0.4240206360037318, 0.652829362252384, 0.23757948747471694, 0.24415056190293025], Action prob: [0.77658683 0.22341317], Action: 0, state: 0\n",
      "Sensor: [0.34555325528883984, 0.6549544870291112, 0.17415149756721027, 0.5518911140096107], Action prob: [0.77701944 0.22298054], Action: 0, state: 0\n",
      "Sensor: [0.35367095132173565, 0.6144312689758487, 0.21258563241057293, 0.23535541525856057], Action prob: [0.77596974 0.2240302 ], Action: 0, state: 1\n",
      "Sensor: [0.3805975853957893, 0.6306376627241578, 0.23958507601540013, 0.2755639151357512], Action prob: [0.77602154 0.22397843], Action: 0, state: 2\n",
      "Sensor: [0.3936127109324843, 0.6467535950288104, 0.21095788867516882, 0.26945047437066977], Action prob: [0.7762186  0.22378144], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "Sensor: [0.3256837968578575, 0.6224967599419841, 0.2139874278413585, 0.22546053997245577], Action prob: [0.7754766  0.22452344], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.3940538138801956, 0.666355024889129, 0.21545047619565202, 0.31566715558088454], Action prob: [0.7765306  0.22346935], Action: 0, state: 0\n",
      "Sensor: [0.40150468101312964, 0.6515646006072989, 0.24740238629250239, 0.5041103533489272], Action prob: [0.7774697 0.2225303], Action: 1, state: 0\n",
      "Sensor: [0.3589272474064251, 0.3818184411361841, 0.20268459885570864, 0.20419852826256135], Action prob: [0.7725386  0.22746143], Action: 0, state: 9\n",
      "Sensor: [0.5608069848602337, 0.6183144772979432, 0.20855077665496186, 0.24286583199980394], Action prob: [0.77525157 0.22474846], Action: 0, state: 9\n",
      "Sensor: [0.32002896036109635, 0.5778065405348161, 0.2150914428463034, 0.8264734967870478], Action prob: [0.7762913  0.22370869], Action: 1, state: 9\n",
      "tensor([-3.1963, -0.4399, -2.1803, -1.8374, -0.2556, -0.1705, -0.0923, -0.0213,\n",
      "         0.0426,  0.0993,  0.1513,  0.1934,  0.2268,  1.5168,  1.3936,  0.2055,\n",
      "         1.3859,  0.2133,  0.1873,  0.9909], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 58 is 6300, loss is 0.07933637764432358\n",
      "Sensor: [0.30892676584822354, 0.6248111531200479, 0.2684480587133152, 0.23709555086155323], Action prob: [0.789264 0.210736], Action: 0, state: 0\n",
      "Sensor: [0.3475696345085535, 0.6858547634186474, 0.21063453302261753, 0.2688896217864048], Action prob: [0.80476433 0.19523568], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.32913601512921414, 0.6187756279095318, 0.1797865685482261, 0.22315428935111098], Action prob: [0.80360067 0.19639938], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.34147602112621805, 0.5956762908227184, 0.1472840384231757, 0.2579617411177923], Action prob: [0.8019859  0.19801413], Action: 0, state: 0\n",
      "Sensor: [0.31861299146955036, 0.598697991784968, 0.20350565589913894, 0.2663271908443116], Action prob: [0.8015923  0.19840768], Action: 0, state: 0\n",
      "Sensor: [0.33886045244532376, 0.6541190391201571, 0.19449956014493494, 0.21191146807845057], Action prob: [0.8022372  0.19776274], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.36605424808129455, 0.6349366428292116, 0.18818337386950523, 0.2386128172871667], Action prob: [0.8023255  0.19767453], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.34753835007941175, 0.616433336032634, 0.1983873299302111, 0.2516559816817131], Action prob: [0.8020399  0.19796002], Action: 0, state: 0\n",
      "Sensor: [0.32453378686305645, 0.6533609697658188, 0.2753095459759936, 0.22670768847281994], Action prob: [0.80265975 0.19734032], Action: 0, state: 0\n",
      "Sensor: [0.35242430041442535, 0.581338882574738, 0.21532459852293076, 0.23678459424145654], Action prob: [0.8017574  0.19824259], Action: 0, state: 0\n",
      "Sensor: [0.35593486882883213, 0.6188243391837166, 0.19886838791420045, 0.29857640932623075], Action prob: [0.80204463 0.19795537], Action: 0, state: 1\n",
      "Sensor: [0.3675260750629455, 0.6219505504220202, 0.2651128451768879, 0.2588096498237372], Action prob: [0.8024997 0.1975003], Action: 0, state: 1\n",
      "Sensor: [0.3780461808866202, 0.6029657959381818, 0.20455409660120694, 0.2877328672067026], Action prob: [0.80222106 0.19777897], Action: 0, state: 2\n",
      "Sensor: [0.32872773441656633, 0.6568992936271271, 0.21299677078061144, 0.2832012463578888], Action prob: [0.802581   0.19741899], Action: 0, state: 2\n",
      "Sensor: [0.4042529786527084, 0.6547656393633914, 0.18505559623126092, 0.2378307676799207], Action prob: [0.80287796 0.19712205], Action: 0, state: 2\n",
      "Sensor: [0.36417207410546476, 0.6466616281121442, 0.18000100355626056, 0.24984561032567706], Action prob: [0.8025762  0.19742379], Action: 0, state: 2\n",
      "Sensor: [0.35298864567303523, 0.6091620246515482, 0.25399153263153496, 0.26674072418587175], Action prob: [0.8023593  0.19764072], Action: 0, state: 2\n",
      "Sensor: [0.3458802944925827, 0.6474541190242941, 0.2369530754968251, 0.2366947584266006], Action prob: [0.8026367  0.19736336], Action: 0, state: 2\n",
      "Sensor: [0.332516384564965, 0.6346479669894687, 0.2418458328551834, 0.2542182597193347], Action prob: [0.80253565 0.19746438], Action: 0, state: 2\n",
      "Sensor: [0.38219566654292214, 0.6292817742024561, 0.1746134651592124, 0.24942470429306246], Action prob: [0.8023643  0.19763574], Action: 0, state: 3\n",
      "Sensor: [0.3828510590004873, 0.6374151069613774, 0.24431030342373508, 0.20748495483351415], Action prob: [0.802588   0.19741195], Action: 0, state: 3\n",
      "Sensor: [0.34276293019569204, 0.3237778784256163, 0.20065472991636712, 0.2566253387483748], Action prob: [0.7979997  0.20200032], Action: 1, state: 8\n",
      "Sensor: [0.3490581263141499, 0.6655131008640359, 0.4910435470513177, 0.22960266463912932], Action prob: [0.80264705 0.19735298], Action: 1, state: 8\n",
      "tensor([-0.5383, -0.3647, -1.9467, -0.3169, -0.2218, -0.9940, -1.2784, -0.1390,\n",
      "        -0.0763, -0.0197,  0.0262,  0.0670,  0.1003,  0.1295,  0.1558,  0.1801,\n",
      "         0.2019,  0.2208,  0.2385,  0.2487,  0.2570,  1.5301,  1.2221],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 59 is 4800, loss is 0.05729202274280854\n",
      "Sensor: [0.3640212707314108, 0.7024409004379537, 0.19830473862665104, 0.2650587586140116], Action prob: [0.7976353  0.20236465], Action: 0, state: 0\n",
      "Sensor: [0.3522700696092272, 0.6296626251250556, 0.20368339205111563, 0.26031290441546373], Action prob: [0.8138393  0.18616073], Action: 0, state: 0\n",
      "Sensor: [0.37542694251260894, 0.675034941874785, 0.19978284466380625, 0.25361916695905495], Action prob: [0.81654537 0.18345465], Action: 0, state: 0\n",
      "Sensor: [0.34549397966770584, 0.6054464257554538, 0.2645815088006257, 0.2846944723282672], Action prob: [0.8165388  0.18346116], Action: 0, state: 1\n",
      "Sensor: [0.3390338467529361, 0.6754054487989264, 0.24446021798611353, 0.258202456020081], Action prob: [0.817473   0.18252699], Action: 0, state: 1\n",
      "Sensor: [0.3137959841078762, 0.711960659498222, 0.17229857073413934, 0.26866640556159777], Action prob: [0.8179094  0.18209063], Action: 0, state: 1\n",
      "Sensor: [0.40939088614932423, 0.5937749162227934, 0.2185776387798329, 0.29379861932081125], Action prob: [0.81737995 0.18262   ], Action: 0, state: 1\n",
      "Sensor: [0.3817975729652219, 0.5738913858154748, 0.22731575630215015, 0.21968828630932946], Action prob: [0.81653875 0.18346122], Action: 0, state: 2\n",
      "Sensor: [0.4098841441374474, 0.5796649971894977, 0.21196544202016468, 0.24065399152453637], Action prob: [0.81645715 0.18354289], Action: 0, state: 3\n",
      "Sensor: [0.3835081038663411, 0.5920739070367779, 0.16664161686907553, 0.2727900513659746], Action prob: [0.8162856  0.18371436], Action: 0, state: 3\n",
      "Sensor: [0.4030644371701572, 0.6626380263594986, 0.5163268720478105, 0.24969776955625086], Action prob: [0.8190325  0.18096752], Action: 0, state: 3\n",
      "Sensor: [0.4166345678231713, 0.700270975174176, 0.19148165399632713, 0.27689427646061565], Action prob: [0.8190265  0.18097346], Action: 0, state: 3\n",
      "Sensor: [0.36106347738592687, 0.6408455834872785, 0.20243879365398595, 0.5682083984481149], Action prob: [0.818871   0.18112902], Action: 0, state: 8\n",
      "Sensor: [0.395042780968911, 0.6072508167899318, 0.49343684486958134, 0.24936227149037807], Action prob: [0.81909776 0.18090217], Action: 0, state: 8\n",
      "Sensor: [0.6050168344322949, 0.5749525244886665, 0.21652632731268098, 0.21786644802646332], Action prob: [0.8184998 0.1815002], Action: 0, state: 8\n",
      "Sensor: [0.28468436588550616, 0.4052655877238427, 0.21872649754662563, 0.4637530744458401], Action prob: [0.8147928  0.18520725], Action: 1, state: 8\n",
      "Sensor: [0.5680648045533158, 0.6262006452629253, 0.2025336332879628, 0.2436847574582987], Action prob: [0.81747365 0.18252635], Action: 0, state: 8\n",
      "Sensor: [0.34695807453249566, 0.3585113800769991, 0.23000227133043882, 0.2442567100040744], Action prob: [0.81341064 0.18658932], Action: 0, state: 8\n",
      "Sensor: [0.35263687203833466, 0.6850652882856364, 0.5290716070399549, 0.2448353569033538], Action prob: [0.8180587  0.18194124], Action: 0, state: 8\n",
      "Sensor: [0.624112105501122, 0.6382632969924606, 0.2001168421388446, 0.2645057025789227], Action prob: [0.8191692  0.18083076], Action: 1, state: 8\n",
      "Sensor: [0.3937980185092301, 0.6226540406090808, 0.5069132859431457, 0.2666879578565968], Action prob: [0.81912434 0.18087569], Action: 0, state: 8\n",
      "Sensor: [0.3468135656333871, 0.3755214416579079, 0.24750627819877602, 0.2491962600730036], Action prob: [0.8143415 0.1856585], Action: 0, state: 8\n",
      "Sensor: [0.3599817367856024, 0.6443123007072042, 0.5185643230489031, 0.21951468483701916], Action prob: [0.81766075 0.18233922], Action: 1, state: 8\n",
      "Sensor: [0.40352430004330136, 0.6389024231000411, 0.21390283493344708, 0.20236237230259987], Action prob: [0.8174817  0.18251836], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.32884687626723247, 0.6548598128161874, 0.20724711345807936, 0.30543677463511976], Action prob: [0.81741095 0.18258907], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.32384886550110215, 0.6829968932286249, 0.21328464068619377, 0.3122671033959845], Action prob: [0.81794274 0.18205723], Action: 0, state: 0\n",
      "tensor([-0.2293, -0.1154, -0.0311,  0.0359,  0.0954,  0.1490,  0.1983,  0.2382,\n",
      "         0.2603,  0.2805,  0.2924,  0.3088,  0.2245,  0.1466,  0.0785,  0.1447,\n",
      "        -0.0401, -0.0923, -0.1368, -1.5071, -0.2130, -0.2519, -2.3524, -2.2694,\n",
      "        -2.3016, -0.2684], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 60 is -22700, loss is 0.282908903850749\n",
      "Sensor: [0.38904194300792116, 0.6974959496647828, 0.1912542732444505, 0.2693091654582578], Action prob: [0.79218584 0.20781419], Action: 0, state: 0\n",
      "Sensor: [0.3698398266792348, 0.6058605797717661, 0.22465469814203748, 0.18068993898053648], Action prob: [0.8067953  0.19320469], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.32645573574538084, 0.6069528889642251, 0.19393961620551314, 0.2504530689758966], Action prob: [0.8080848  0.19191521], Action: 0, state: 0\n",
      "Sensor: [0.4082364493398249, 0.36711306446774455, 0.21807403425564292, 0.21445262712400515], Action prob: [0.8056727  0.19432731], Action: 0, state: 1\n",
      "Sensor: [0.35172903375724135, 0.5960455714768705, 0.2197487376012613, 0.2001299151195749], Action prob: [0.80745405 0.19254598], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "Sensor: [0.3772138880708341, 0.7010739570393039, 0.2114658958159933, 0.2638587230044697], Action prob: [0.80995136 0.19004865], Action: 0, state: 1\n",
      "Sensor: [0.3339103600587495, 0.6456777569611728, 0.21520943081513172, 0.2551350814354913], Action prob: [0.80981284 0.19018725], Action: 0, state: 1\n",
      "Sensor: [0.3648228071648263, 0.6053476701259168, 0.23873633997490956, 0.22418861215800573], Action prob: [0.8094234  0.19057666], Action: 0, state: 1\n",
      "Sensor: [0.3827943063480426, 0.6296027993227813, 0.19463604074382684, 0.27506888661224044], Action prob: [0.80970347 0.19029652], Action: 0, state: 1\n",
      "Sensor: [0.3432906233785159, 0.6268592241742043, 0.20590253632019542, 0.24219798606436876], Action prob: [0.8094572  0.19054282], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3812019823603296, 0.6496263591420769, 0.22030358509688602, 0.30706763495891015], Action prob: [0.81024945 0.18975052], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3334500895010102, 0.6881603833274519, 0.2365940482520471, 0.27387728782045523], Action prob: [0.81066215 0.18933782], Action: 0, state: 0\n",
      "Sensor: [0.3578563207310229, 0.6181949203076815, 0.2506439987419138, 0.3132031313945918], Action prob: [0.81028277 0.18971728], Action: 0, state: 0\n",
      "Sensor: [0.28914102623689164, 0.6197107997684773, 0.2228385471282951, 0.23377955721608173], Action prob: [0.8093051  0.19069491], Action: 0, state: 0\n",
      "Sensor: [0.39678035337364026, 0.6003949782223735, 0.22048993407786102, 0.286335432027189], Action prob: [0.80960333 0.19039662], Action: 0, state: 0\n",
      "Sensor: [0.3650525013584712, 0.5892822360749789, 0.19290155961973401, 0.2654384338455611], Action prob: [0.8091225  0.19087759], Action: 0, state: 0\n",
      "Sensor: [0.26524347331930437, 0.5857169555569315, 0.20157207523472498, 0.22923628111896036], Action prob: [0.80819815 0.19180185], Action: 0, state: 0\n",
      "Sensor: [0.3761827710875233, 0.6244370097613925, 0.2063834301601491, 0.24121440752173723], Action prob: [0.8092166  0.19078337], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.39788590477441715, 0.6677434307934151, 0.2006074833021505, 0.2797864124137231], Action prob: [0.8103248 0.1896752], Action: 0, state: 1\n",
      "Sensor: [0.3577422846434253, 0.6210519129323235, 0.24181200709082484, 0.2700585357119148], Action prob: [0.80996567 0.19003429], Action: 0, state: 1\n",
      "Sensor: [0.3300536436725118, 0.6158363144433604, 0.2084935987741786, 0.20278083818497397], Action prob: [0.8091985  0.19080153], Action: 0, state: 1\n",
      "Sensor: [0.30438736476888606, 0.6434493907096344, 0.22994318634330627, 0.22045543075900928], Action prob: [0.80929756 0.19070242], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "tensor([-0.4987, -2.6161, -0.3389, -0.2566, -1.4338, -0.1912, -0.1297, -0.0744,\n",
      "        -0.0243,  0.1615,  0.1618,  0.0404,  0.0769,  0.1101,  0.1395,  0.1666,\n",
      "         0.1916,  0.2097,  0.2256,  0.2417,  0.2569,  2.0989],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 61 is 15500, loss is 0.06738543819347895\n",
      "Sensor: [0.34998637709901503, 0.5956086239528146, 0.2151521438348038, 0.25848058680236075], Action prob: [0.782698   0.21730198], Action: 0, state: 0\n",
      "Sensor: [0.4983264432785246, 0.6090456658191259, 0.20652231441189833, 0.16865605651557194], Action prob: [0.7973623  0.20263766], Action: 0, state: 0\n",
      "Sensor: [0.4315556929854689, 0.3935867903872892, 0.22952629480966355, 0.23083531587730577], Action prob: [0.79609674 0.20390329], Action: 0, state: 0\n",
      "Sensor: [0.3646660141071074, 0.6783955595758863, 0.20524255689364376, 0.31107302149310356], Action prob: [0.79871583 0.20128417], Action: 0, state: 0\n",
      "Sensor: [0.3846375145604254, 0.666373292230675, 0.181554231580518, 0.2594905671522898], Action prob: [0.79954153 0.2004585 ], Action: 0, state: 0\n",
      "Sensor: [0.3873406708275896, 0.624843248577544, 0.2330909308912565, 0.2894771495254304], Action prob: [0.79965883 0.20034122], Action: 0, state: 1\n",
      "Sensor: [0.36135680709373924, 0.6653979370923723, 0.18682372494268323, 0.28291115336281214], Action prob: [0.799884   0.20011589], Action: 0, state: 1\n",
      "Sensor: [0.34180451204719775, 0.6633003851168409, 0.24612391502099934, 0.3121183608531965], Action prob: [0.8001443  0.19985574], Action: 0, state: 1\n",
      "Sensor: [0.3056797462758031, 0.6534138336122806, 0.2455183687019116, 0.2163182305396361], Action prob: [0.7995447 0.2004553], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3749657654977169, 0.6343228017152506, 0.2156701383724922, 0.274520912019219], Action prob: [0.7996306  0.20036942], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.33627215082279605, 0.6642040234966481, 0.23634723628772913, 0.28255255917012984], Action prob: [0.7998934 0.2001066], Action: 0, state: 0\n",
      "Sensor: [0.39013161910267585, 0.5794860189244486, 0.23531272400408307, 0.24824168593293447], Action prob: [0.7991201  0.20087984], Action: 0, state: 1\n",
      "Sensor: [0.3728449165363873, 0.6418659466815568, 0.21709627158374264, 0.24583206466429414], Action prob: [0.799418   0.20058197], Action: 0, state: 1\n",
      "Sensor: [0.36598075709080236, 0.6745675240076784, 0.22355846485107733, 0.24964918625260493], Action prob: [0.79995024 0.20004974], Action: 0, state: 1\n",
      "Sensor: [0.3449702321531978, 0.6656066849880112, 0.2541463116613212, 0.2477475239409087], Action prob: [0.79998726 0.20001274], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3427704072271165, 0.6750910491441862, 0.16577778634815754, 0.21493158283032665], Action prob: [0.7997104  0.20028958], Action: 0, state: 0\n",
      "Sensor: [0.38694723304492784, 0.6671602522154768, 0.20720860005115113, 0.24064534665162735], Action prob: [0.80001974 0.19998023], Action: 0, state: 1\n",
      "Sensor: [0.37508938645804385, 0.659749773323967, 0.23517953164729588, 0.2581731879744889], Action prob: [0.8001082 0.1998918], Action: 0, state: 1\n",
      "Sensor: [0.36796897267564865, 0.5662421257476007, 0.22262586765402068, 0.24308231279836628], Action prob: [0.79878145 0.20121852], Action: 1, state: 2\n",
      "Sensor: [0.3585753701226884, 0.603512481142451, 0.22563873635790424, 0.5434086397823006], Action prob: [0.80012214 0.19987784], Action: 0, state: 9\n",
      "Sensor: [0.5580173568236636, 0.6478789983627347, 0.21220911001821285, 0.24852011980231797], Action prob: [0.8011394  0.19886059], Action: 0, state: 9\n",
      "Sensor: [0.36763260207937937, 0.6421715122728175, 0.5112419577966095, 0.2770583982785172], Action prob: [0.8011845  0.19881555], Action: 0, state: 9\n",
      "Sensor: [0.5933757915262395, 0.6706143730678986, 0.18908257293914657, 0.21364558216156687], Action prob: [0.8015388  0.19846119], Action: 0, state: 9\n",
      "Sensor: [0.3790324833549731, 0.402525069958795, 0.2584230725871661, 0.24656204110620908], Action prob: [0.7971019  0.20289807], Action: 0, state: 9\n",
      "tensor([-0.6488, -0.4837, -0.3810, -0.2827, -0.1977, -0.1298, -0.0687, -0.0139,\n",
      "         0.2539,  0.0777,  0.0329,  0.0693,  0.1015,  0.1302,  1.1277,  0.1568,\n",
      "         0.1776,  0.1966,  1.5254,  0.1953,  0.1782,  0.1637,  0.1515,  0.1446],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 62 is 7800, loss is -0.10318815725987236\n",
      "Sensor: [0.3558066762715959, 0.7019683741989104, 0.20655900587310463, 0.4427324429835824], Action prob: [0.78267807 0.21732195], Action: 0, state: 0\n",
      "Sensor: [0.39987255774933395, 0.627552771415969, 0.23065253424863963, 0.2636898955551827], Action prob: [0.79482067 0.20517933], Action: 0, state: 1\n",
      "Sensor: [0.37531238309940307, 0.6452512398902454, 0.24589846363938683, 0.23843377647923564], Action prob: [0.7959063  0.20409374], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.34832624632644554, 0.6786204106543685, 0.22219310301059417, 0.24859502533558078], Action prob: [0.7962864  0.20371364], Action: 0, state: 0\n",
      "Sensor: [0.319548670691638, 0.6604616408178837, 0.2315597673013467, 0.2519346161537908], Action prob: [0.79621345 0.20378652], Action: 0, state: 0\n",
      "Sensor: [0.3358263763074476, 0.7092407004075778, 0.19629950173038743, 0.2731740798951559], Action prob: [0.79694605 0.20305389], Action: 0, state: 0\n",
      "Sensor: [0.4366418324516122, 0.6585736857139097, 0.2326910616499966, 0.2375641637669475], Action prob: [0.7971366  0.20286343], Action: 0, state: 1\n",
      "Sensor: [0.3412259011191516, 0.6229893822992913, 0.21972342367847877, 0.27016497707115], Action prob: [0.7962355  0.20376444], Action: 0, state: 2\n",
      "Sensor: [0.3334701373490522, 0.6758497331367574, 0.41941223524287247, 0.2442099571416984], Action prob: [0.79708946 0.20291048], Action: 0, state: 2\n",
      "Sensor: [0.38171665859733617, 0.6498069485088609, 0.2021894828330885, 0.2724831556219965], Action prob: [0.7967458  0.20325427], Action: 0, state: 2\n",
      "Sensor: [0.3945054148430233, 0.6386202557154366, 0.22845925840769502, 0.18695488384281694], Action prob: [0.7962771  0.20372292], Action: 0, state: 3\n",
      "Sensor: [0.4943715997657469, 0.667512943073025, 0.23641328474832835, 0.21192421982606982], Action prob: [0.79714006 0.20285986], Action: 0, state: 3\n",
      "Sensor: [0.3766083278729986, 0.6295278459515772, 0.2048497008172431, 0.22122666661037618], Action prob: [0.79619527 0.20380476], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -2700\n",
      "Sensor: [0.30763333995585834, 0.6401653644702555, 0.23633914187409194, 0.24473148602538264], Action prob: [0.79587954 0.20412046], Action: 0, state: 2\n",
      "Sensor: [0.3695775474619609, 0.6363681321555444, 0.17682426976066382, 0.2664393748968444], Action prob: [0.79608357 0.20391642], Action: 0, state: 2\n",
      "Sensor: [0.4246011344274836, 0.626140286927407, 0.5226603393928329, 0.23835526668167106], Action prob: [0.79734635 0.2026537 ], Action: 0, state: 9\n",
      "Sensor: [0.5693304195472952, 0.6034560036624533, 0.25676541691173604, 0.24542162008695015], Action prob: [0.7973633  0.20263669], Action: 0, state: 9\n",
      "Sensor: [0.3797189310363563, 0.6232962387860278, 0.23847534678762985, 0.5641823114800609], Action prob: [0.7976022  0.20239781], Action: 0, state: 9\n",
      "Sensor: [0.3581859517631699, 0.598484331149586, 0.20383111592190611, 0.6049870562370989], Action prob: [0.7976559  0.20234409], Action: 1, state: 9\n",
      "Sensor: [0.34085882830699316, 0.6679807879728787, 0.21761404662870726, 0.5549973575965802], Action prob: [0.7982874  0.20171262], Action: 0, state: 9\n",
      "Sensor: [0.5767602310741993, 0.6706146712680613, 0.2222347676974453, 0.21773650478612172], Action prob: [0.7985188  0.20148128], Action: 0, state: 9\n",
      "Sensor: [0.3928699378554461, 0.6368056279105718, 0.2173261338445114, 0.5406590824311807], Action prob: [0.79819    0.20180997], Action: 1, state: 9\n",
      "tensor([-0.6471, -0.4689, -2.3876, -0.2808, -0.1701, -0.0702,  0.0101,  0.0749,\n",
      "         0.1317,  0.1848,  0.2145,  0.2397,  1.8497,  0.1494,  0.1803,  0.1436,\n",
      "         0.1132,  0.0857,  0.4295,  0.0377,  0.0168, -0.0054],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 63 is -800, loss is 0.007656588030358894\n",
      "Sensor: [0.3730167227657199, 0.6349598037676536, 0.16961606103197105, 0.281120766131929], Action prob: [0.7785157 0.2214843], Action: 0, state: 0\n",
      "Sensor: [0.33215163695648336, 0.6944341369200987, 0.2167601143827096, 0.2621369556225772], Action prob: [0.7907931  0.20920686], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3450096282342915, 0.6197511991621835, 0.21549255028071995, 0.2209572739923124], Action prob: [0.7913976 0.2086024], Action: 0, state: 0\n",
      "Sensor: [0.36620253616743725, 0.6635091770474011, 0.2004511569123884, 0.25003002056291446], Action prob: [0.7920569 0.2079431], Action: 0, state: 1\n",
      "Sensor: [0.3495926158596946, 0.6567446137666522, 0.18676064331283007, 0.23805037784530086], Action prob: [0.7920935  0.20790641], Action: 0, state: 2\n",
      "Sensor: [0.3393934347462909, 0.6843459672140852, 0.5406047682325806, 0.23894334793481564], Action prob: [0.79344994 0.20655006], Action: 0, state: 2\n",
      "Sensor: [0.3567046036622473, 0.6323382761075199, 0.19158510840647452, 0.2355633254635702], Action prob: [0.7922931  0.20770696], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "Sensor: [0.3741426032049115, 0.6750824551321801, 0.19357765295472046, 0.27797490272279046], Action prob: [0.79265505 0.20734495], Action: 0, state: 1\n",
      "Sensor: [0.3818936961557155, 0.6790372061057471, 0.2228439256734501, 0.2413796406107247], Action prob: [0.7928762  0.20712374], Action: 0, state: 2\n",
      "Sensor: [0.3932858415380896, 0.6687913697328673, 0.22399213650704167, 0.23386002805123038], Action prob: [0.79287815 0.20712188], Action: 0, state: 3\n",
      "Sensor: [0.39624762268592, 0.4186213439544426, 0.23066147319105662, 0.2380481964302331], Action prob: [0.7899089  0.21009107], Action: 0, state: 3\n",
      "Sensor: [0.31518749868359264, 0.5876023393170718, 0.2058616054370408, 0.1741981774090523], Action prob: [0.79014176 0.2098582 ], Action: 0, state: 3\n",
      "Sensor: [0.3130351975048806, 0.377960185330997, 0.1958214072594674, 0.2614143456697382], Action prob: [0.7880327  0.21196736], Action: 0, state: 8\n",
      "Sensor: [0.3796867993946519, 0.5582082548112186, 0.5500460355267949, 0.2612884075683193], Action prob: [0.7910749  0.20892513], Action: 0, state: 8\n",
      "Sensor: [0.4026931131295321, 0.3657184290499358, 0.22493357342584583, 0.23176449964667178], Action prob: [0.78855956 0.21144049], Action: 0, state: 8\n",
      "Sensor: [0.550054834247048, 0.5156558235168932, 0.2518840289549661, 0.19877819516449016], Action prob: [0.79032576 0.20967416], Action: 0, state: 8\n",
      "Sensor: [0.4312024311971522, 0.1786143613333085, 0.1830345597955994, 0.22880871929516367], Action prob: [0.7858422  0.21415785], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.31438461399627493, 0.6603547493993465, 0.25413738147301485, 0.577656944263101], Action prob: [0.7914692  0.20853075], Action: 0, state: 8\n",
      "Sensor: [0.3831121344849797, 0.42766161325449537, 0.1795326875734319, 0.15936833898700853], Action prob: [0.7891909  0.21080914], Action: 0, state: 8\n",
      "Sensor: [0.33243386950473613, 0.39169440118349064, 0.22374589552249663, 0.2103544838766405], Action prob: [0.7877792  0.21222074], Action: 0, state: 8\n",
      "Sensor: [0.5461128841764619, 0.4104702929080239, 0.22312956635523204, 0.2541803975146999], Action prob: [0.78914535 0.21085462], Action: 1, state: 8\n",
      "Sensor: [0.5620533952416807, 0.6268041473014736, 0.195533465070464, 0.2268726320514574], Action prob: [0.7918589  0.20814112], Action: 1, state: 8\n",
      "Sensor: [0.571302178563915, 0.6595689977825839, 0.22555770082677712, 0.2363885608651795], Action prob: [0.7932248  0.20677514], Action: 0, state: 8\n",
      "Sensor: [0.34233162886607016, 0.3764421017879278, 0.22743825901107928, 0.20455720912452008], Action prob: [0.78878987 0.21121016], Action: 1, state: 8\n",
      "Sensor: [0.3302982314545, 0.6500567931798175, 0.23083189646430138, 0.24905970394084234], Action prob: [0.79097015 0.20902981], Action: 0, state: 0\n",
      "Sensor: [0.377560399130021, 0.6719436409429612, 0.21996863649852907, 0.24369286010761718], Action prob: [0.7922671  0.20773295], Action: 0, state: 0\n",
      "tensor([-1.0796e-01,  2.3511e-02,  3.6630e-03,  7.9644e-02,  1.4051e-01,\n",
      "         1.9278e-01,  1.6491e+00,  2.3822e-01,  2.7753e-01,  2.9988e-01,\n",
      "         3.2589e-01,  3.4340e-01,  2.4771e-01,  1.5331e-01,  7.5735e-02,\n",
      "         2.0829e-03, -6.3118e-02, -1.2044e-01, -1.7472e-01, -2.2401e-01,\n",
      "        -1.7450e+00, -2.0198e+00, -3.3229e-01, -2.4298e+00, -3.5786e-01,\n",
      "        -3.4713e-01], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 64 is -26500, loss is 0.14881026234325867\n",
      "Sensor: [0.3457513654974651, 0.6838913786147491, 0.2291205574744276, 0.22565334808124868], Action prob: [0.77045006 0.22954997], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3509479398076759, 0.5618939587478333, 0.21728893947911254, 0.27675579381263415], Action prob: [0.77834404 0.221656  ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3449277148874234, 0.6279169613965923, 0.1655231695945404, 0.2353033571366749], Action prob: [0.77861917 0.22138084], Action: 0, state: 0\n",
      "Sensor: [0.3664084079857288, 0.6101862348612014, 0.17169887730040587, 0.2621138271858624], Action prob: [0.7784628  0.22153713], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3544429787785538, 0.6770004596232582, 0.23116683182823491, 0.3061520296071175], Action prob: [0.77947503 0.220525  ], Action: 0, state: 0\n",
      "Sensor: [0.3886104028611071, 0.6244559419613456, 0.24644089614285364, 0.2588493075684111], Action prob: [0.7791186  0.22088134], Action: 0, state: 1\n",
      "Sensor: [0.41545152804860724, 0.32686416880019675, 0.23354082696075584, 0.2755982124514346], Action prob: [0.7753414 0.2246586], Action: 0, state: 9\n",
      "Sensor: [0.3756300474982329, 0.4293432165766905, 0.20987838914361137, 0.2707627642066457], Action prob: [0.77505356 0.22494638], Action: 0, state: 9\n",
      "Sensor: [0.397324864351957, 0.6556443658874697, 0.24232021210617793, 0.562105177832963], Action prob: [0.7795526  0.22044738], Action: 0, state: 9\n",
      "Sensor: [0.6360391319167487, 0.39440740157980025, 0.24785113460070599, 0.24595359496227276], Action prob: [0.7776443  0.22235572], Action: 0, state: 9\n",
      "Sensor: [0.3605976039213896, 0.576522879076697, 0.21551015232904855, 0.6018284900138678], Action prob: [0.7790743  0.22092569], Action: 0, state: 9\n",
      "Sensor: [0.37779112775614127, 0.38629719963388526, 0.23023504894996388, 0.19361071752084025], Action prob: [0.77542716 0.22457285], Action: 0, state: 9\n",
      "Sensor: [0.3665112701075487, 0.6627800695507429, 0.5108024658485312, 0.5381464636342431], Action prob: [0.7801954  0.21980461], Action: 0, state: 9\n",
      "Sensor: [0.36884905919649713, 0.6636481547598018, 0.18988803422515044, 0.5960006429519513], Action prob: [0.7810063  0.21899372], Action: 1, state: 9\n",
      "Sensor: [0.3719780586106053, 0.628595653388489, 0.46410365732190234, 0.2501664334723828], Action prob: [0.7799661  0.22003391], Action: 0, state: 9\n",
      "Sensor: [0.35965017386872733, 0.6438165783084374, 0.49351295767862235, 0.2816427854591414], Action prob: [0.77983826 0.2201617 ], Action: 0, state: 9\n",
      "Sensor: [0.5534971563917975, 0.6793860336262534, 0.24937831681125822, 0.2954921330735433], Action prob: [0.78053296 0.219467  ], Action: 0, state: 9\n",
      "Sensor: [0.3906650752409554, 0.6605443352541273, 0.7758450621049003, 0.20558891113861072], Action prob: [0.78073376 0.21926628], Action: 0, state: 9\n",
      "Sensor: [0.37172154957815584, 0.39415377377357236, 0.20895770372279013, 0.2742911424724797], Action prob: [0.7759325  0.22406745], Action: 0, state: 9\n",
      "Sensor: [0.6205998678521301, 0.671320024294318, 0.17229886442740253, 0.288875112749728], Action prob: [0.7792808  0.22071916], Action: 0, state: 9\n",
      "Sensor: [0.5579441225236195, 0.7030664898482869, 0.1880729456266938, 0.25773076082251045], Action prob: [0.7802805  0.21971954], Action: 0, state: 9\n",
      "Sensor: [0.32238640934073715, 0.42794601563542256, 0.17809376046340972, 0.24482665615761715], Action prob: [0.7759766  0.22402337], Action: 0, state: 9\n",
      "Sensor: [0.386841922628017, 0.38295098060277194, 0.23439601660085985, 0.17189086782272156], Action prob: [0.7743816 0.2256184], Action: 0, state: 9\n",
      "Sensor: [0.5584536228541587, 0.6856210467186057, 0.22273636468663083, 0.20589788803737624], Action prob: [0.77873677 0.2212632 ], Action: 0, state: 9\n",
      "Sensor: [0.39437550358729356, 0.6548090722873057, 0.21701757006185446, 0.5213019162002372], Action prob: [0.7801438  0.21985614], Action: 0, state: 9\n",
      "Sensor: [0.5277717235829739, 0.6349336476532201, 0.2545875035459191, 0.23687550160381107], Action prob: [0.77994883 0.22005117], Action: 1, state: 9\n",
      "Sensor: [0.5977542359336145, 0.6773530581717715, 0.2197824191866704, 0.31118651107828876], Action prob: [0.7807594  0.21924055], Action: 1, state: 9\n",
      "tensor([ 0.3872,  0.8681,  0.2141,  2.0496,  0.3950,  0.4874,  0.4044,  0.3205,\n",
      "         0.2388,  0.1739,  0.1127,  0.0596,  0.0085, -0.2085, -0.0746, -0.1101,\n",
      "        -0.1410, -0.1709, -0.1988, -0.2197, -0.2395, -0.2630, -0.2827, -0.2928,\n",
      "        -0.3037, -1.9305, -2.0028], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 65 is -18600, loss is 0.026618312396317997\n",
      "Sensor: [0.35639253188044884, 0.6073225772991339, 0.2528180115244011, 0.21726217080431207], Action prob: [0.7602585  0.23974149], Action: 0, state: 0\n",
      "Sensor: [0.36107157373318144, 0.5975337954487985, 0.5104546650893563, 0.25198984752587783], Action prob: [0.7669899  0.23301019], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3665759015500405, 0.7188065771828651, 0.1655067336370455, 0.27156269899121727], Action prob: [0.76601326 0.23398674], Action: 0, state: 0\n",
      "Sensor: [0.33175358895284096, 0.6850905098358915, 0.19633491146325835, 0.2216762482080015], Action prob: [0.7645329  0.23546712], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3461505447358226, 0.6524333466357104, 0.22758556617247014, 0.540673352175147], Action prob: [0.7651647  0.23483536], Action: 0, state: 0\n",
      "Sensor: [0.3484730720384952, 0.6838961547188829, 0.20637596144406825, 0.23617913621476402], Action prob: [0.7643773 0.2356227], Action: 0, state: 1\n",
      "Sensor: [0.2847794851272314, 0.649577307384844, 0.20605978023131352, 0.2574378385956288], Action prob: [0.7633657  0.23663431], Action: 0, state: 1\n",
      "Sensor: [0.3254030724534575, 0.6715390522502709, 0.2107062304375562, 0.2643950374998331], Action prob: [0.7636309  0.23636904], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "Sensor: [0.34016408140742965, 0.6247714178014725, 0.17645422773081898, 0.2719377541356202], Action prob: [0.7631578  0.23684226], Action: 0, state: 0\n",
      "Sensor: [0.33641562298619, 0.6145946614272927, 0.23417565059225812, 0.24501823772789322], Action prob: [0.76283234 0.23716763], Action: 0, state: 0\n",
      "Sensor: [0.3535726907717825, 0.6514969057841663, 0.23083615984750616, 0.28182535315591367], Action prob: [0.76342106 0.23657893], Action: 0, state: 0\n",
      "Sensor: [0.3105258482548555, 0.6259066167382193, 0.2132273524703768, 0.3319330811883736], Action prob: [0.7632563  0.23674373], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.32747910403877983, 0.6426340102644384, 0.172117028587164, 0.26476192153547823], Action prob: [0.7631585  0.23684148], Action: 0, state: 0\n",
      "Sensor: [0.28444666633048965, 0.618779647200278, 0.23336880182288527, 0.24531620628190734], Action prob: [0.7626664  0.23733364], Action: 0, state: 0\n",
      "Sensor: [0.3309256625716933, 0.6160021770847879, 0.2629010847970849, 0.6110996566262952], Action prob: [0.7645272  0.23547284], Action: 0, state: 0\n",
      "Sensor: [0.3355681459646885, 0.6502564975711149, 0.23705284248498554, 0.22659838133360208], Action prob: [0.76366    0.23633997], Action: 0, state: 0\n",
      "Sensor: [0.3636190101116681, 0.6976265333573501, 0.24335873164276034, 0.24875567797283318], Action prob: [0.76408255 0.23591742], Action: 0, state: 1\n",
      "Sensor: [0.32653525413064105, 0.6815620834021512, 0.20681569441231426, 0.26084914152919075], Action prob: [0.7638096 0.2361904], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.32741859372243165, 0.5982198834565983, 0.20528508247496552, 0.24112676911362368], Action prob: [0.7626583  0.23734172], Action: 0, state: 2\n",
      "Sensor: [0.30862083228703063, 0.6631113290549057, 0.20248275051045705, 0.28322509982821087], Action prob: [0.76326686 0.2367332 ], Action: 0, state: 2\n",
      "Sensor: [0.38334131082951006, 0.701209541205786, 0.24820716316623992, 0.2519004704870561], Action prob: [0.76426226 0.23573773], Action: 0, state: 3\n",
      "tensor([-0.6039, -2.3467, -0.4287, -1.6286, -0.2429, -0.1499, -0.0650,  0.0630,\n",
      "        -0.1034, -0.0344,  0.0279,  0.4495,  0.1095,  0.1552,  0.1949,  0.2318,\n",
      "         0.2608,  0.2882,  0.3115,  0.3298,  0.3386], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 66 is 11100, loss is 0.13535958800721923\n",
      "Sensor: [0.4153578320976316, 0.6367040451127172, 0.2051949084564477, 0.2356237590280703], Action prob: [0.74632114 0.25367883], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.33887642702229026, 0.692081550564371, 0.23417825342735096, 0.23356729825378716], Action prob: [0.7475601  0.25243995], Action: 0, state: 0\n",
      "Sensor: [0.3233544546218403, 0.6605346235660411, 0.20621539462296964, 0.30537068790160043], Action prob: [0.74319255 0.2568075 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.31282714581092796, 0.6334340900076886, 0.1967579512552977, 0.30704828894899916], Action prob: [0.7403655 0.2596344], Action: 0, state: 0\n",
      "Sensor: [0.3597861812428316, 0.6043476277384793, 0.19520419708896206, 0.24955367447169766], Action prob: [0.738721   0.26127896], Action: 0, state: 1\n",
      "Sensor: [0.3913208897112992, 0.6601866404270322, 0.2343853841780243, 0.2713978938490069], Action prob: [0.7389181  0.26108187], Action: 0, state: 1\n",
      "Sensor: [0.40779802620314676, 0.6329505771453418, 0.24094878347425314, 0.232133959747272], Action prob: [0.7382653 0.2617347], Action: 0, state: 1\n",
      "Sensor: [0.36739194064480646, 0.6705132189761899, 0.24303602639321537, 0.25557317497527393], Action prob: [0.73833716 0.2616628 ], Action: 1, state: 2\n",
      "Sensor: [0.34453828900921946, 0.6741529900980767, 0.5113709777431166, 0.1984200860872251], Action prob: [0.7383638  0.26163617], Action: 1, state: 9\n",
      "Sensor: [0.5527555961098896, 0.5825768427685787, 0.20560455674195693, 0.2391800776423249], Action prob: [0.7375512  0.26244882], Action: 0, state: 9\n",
      "Sensor: [0.3445863162593326, 0.3586158477467294, 0.207547975270266, 0.2512137920515431], Action prob: [0.7334314  0.26656857], Action: 0, state: 9\n",
      "Sensor: [0.34838074784411666, 0.6694663154855681, 0.5134908060605884, 0.25541683882596544], Action prob: [0.73726    0.26274002], Action: 0, state: 9\n",
      "Sensor: [0.36413628492037764, 0.3555398760946242, 0.20149083223245548, 0.24064833498749214], Action prob: [0.7336201  0.26637986], Action: 0, state: 9\n",
      "Sensor: [0.38935398935200294, 0.5953710856726775, 0.24032223903755678, 0.5549305470921254], Action prob: [0.73778623 0.26221377], Action: 0, state: 9\n",
      "Sensor: [0.3493723989410925, 0.38093465867513493, 0.23296639674045394, 0.22503509610603478], Action prob: [0.73436916 0.26563087], Action: 0, state: 9\n",
      "Sensor: [0.5880642812803843, 0.647018114062688, 0.194442784099001, 0.2510969651550384], Action prob: [0.7378809 0.2621191], Action: 0, state: 9\n",
      "Sensor: [0.370785521229539, 0.3571167059145759, 0.2786989619747887, 0.22421702854436587], Action prob: [0.7339428  0.26605725], Action: 0, state: 9\n",
      "Sensor: [0.29506577882844137, 0.6166599939812346, 0.20929268692932346, 0.5149967059169505], Action prob: [0.73749685 0.26250312], Action: 1, state: 9\n",
      "Sensor: [0.5412739938393384, 0.678101032647998, 0.2323598292628025, 0.24615465524013222], Action prob: [0.7390851  0.26091495], Action: 0, state: 9\n",
      "Sensor: [0.5877155687221944, 0.6521977294921715, 0.22440812487554596, 0.26240674120898044], Action prob: [0.7391378  0.26086217], Action: 0, state: 9\n",
      "Sensor: [0.37009712336873757, 0.6161744497510876, 0.22643818593975093, 0.5822335005468258], Action prob: [0.73920774 0.2607922 ], Action: 0, state: 9\n",
      "Sensor: [0.3182310194100211, 0.5948185998377783, 0.18591002303187226, 0.5753426920957326], Action prob: [0.73904896 0.26095104], Action: 1, state: 9\n",
      "Sensor: [0.35978121658682594, 0.3752694565125008, 0.2321941968362867, 0.24447033637453708], Action prob: [0.73477983 0.26522022], Action: 0, state: 9\n",
      "Sensor: [0.582068356713678, 0.6699128278057218, 0.22613137821166657, 0.2566789474770273], Action prob: [0.73828 0.26172], Action: 0, state: 9\n",
      "Sensor: [0.3437766547671369, 0.3713743662801224, 0.2518626602527718, 0.24688268240253572], Action prob: [0.7341322 0.2658678], Action: 1, state: 9\n",
      "Sensor: [0.3692060796691703, 0.40643504392426255, 0.20684441503360795, 0.20959305597463262], Action prob: [0.73343253 0.26656744], Action: 1, state: 9\n",
      "Sensor: [0.37075537178243967, 0.6326371165624176, 0.5061699338762515, 0.2442935708974256], Action prob: [0.7370555  0.26294458], Action: 0, state: 9\n",
      "tensor([-1.0931, -0.2321, -0.0866,  0.0801,  0.2425,  0.3874,  0.5198,  2.7605,\n",
      "         2.2337,  0.4018,  0.3124,  0.2184,  0.1451,  0.0720,  0.0095, -0.0483,\n",
      "        -0.1001, -0.6351, -0.1856, -0.2224, -0.2547, -1.2643, -0.3174, -0.3381,\n",
      "        -1.5666, -1.6496, -0.4004], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 67 is -15000, loss is 0.03745400785924738\n",
      "Sensor: [0.3374624700559849, 0.6358537750484572, 0.23757860011995394, 0.22778822819355798], Action prob: [0.73064476 0.26935518], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.35080330923841624, 0.6451810596246811, 0.22481006656104568, 0.2683566382912157], Action prob: [0.72596943 0.2740306 ], Action: 0, state: 0\n",
      "Sensor: [0.3843665238357894, 0.6624084629021411, 0.26138978086507025, 0.24034495642272435], Action prob: [0.7185387  0.28146133], Action: 0, state: 0\n",
      "Sensor: [0.3284694825083958, 0.6373981971393569, 0.22510049836513019, 0.21492361035293275], Action prob: [0.71358913 0.28641087], Action: 0, state: 0\n",
      "Sensor: [0.33628165899401, 0.660368271750809, 0.22329440456393482, 0.2209442619735819], Action prob: [0.7117773  0.28822267], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3289830862041593, 0.6424998474326099, 0.2349542765943578, 0.2332376553146459], Action prob: [0.71066666 0.28933337], Action: 0, state: 0\n",
      "Sensor: [0.3663184239665601, 0.6191290233410651, 0.24176455908293276, 0.2107418514496276], Action prob: [0.70981634 0.2901837 ], Action: 0, state: 0\n",
      "Sensor: [0.32745867256002176, 0.6276029453378706, 0.24304195402459347, 0.2175616261697529], Action prob: [0.7094024  0.29059762], Action: 0, state: 0\n",
      "Sensor: [0.3386100506339973, 0.6454462460805371, 0.2631174302059025, 0.2989700985650781], Action prob: [0.7098709 0.2901291], Action: 0, state: 0\n",
      "Sensor: [0.37902151924006394, 0.6354962624753183, 0.22228911309064178, 0.22947034122220483], Action prob: [0.70961106 0.29038897], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.2574870423478549, 0.6285413644108124, 0.2130354229342455, 0.25921205598568], Action prob: [0.7091794  0.29082054], Action: 0, state: 0\n",
      "Sensor: [0.372765648205872, 0.6073263300937101, 0.2021543104209268, 0.2580403605285085], Action prob: [0.7093684  0.29063153], Action: 0, state: 1\n",
      "Sensor: [0.36552211936761, 0.6590267026654087, 0.21160246041514488, 0.2228928659581362], Action prob: [0.70988345 0.29011655], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.35136613466900724, 0.6343581703662807, 0.21531452166885312, 0.268886904562123], Action prob: [0.70978177 0.29021832], Action: 0, state: 0\n",
      "Sensor: [0.31509210860079717, 0.5877417135200107, 0.22022461401009982, 0.27768273430614293], Action prob: [0.70903856 0.29096144], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.350793428067821, 0.5908498655571282, 0.21132554080573204, 0.24375731201136777], Action prob: [0.70890516 0.29109484], Action: 0, state: 0\n",
      "Sensor: [0.30963075358499476, 0.6352835831347815, 0.23994816632045807, 0.2596948502044963], Action prob: [0.7094105 0.2905895], Action: 0, state: 0\n",
      "Sensor: [0.34204383652732373, 0.6705102098296377, 0.20658221133051877, 0.23731988401891901], Action prob: [0.71005046 0.28994954], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-1.9288, -0.6448, -0.5042, -0.3660, -0.8571, -0.2353, -0.1262, -0.0273,\n",
      "         0.0618,  0.5123,  0.1788,  0.2372,  1.0435,  0.2893,  1.1960,  0.3546,\n",
      "         0.3920,  1.5255], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 68 is 11600, loss is -0.06118976633445547\n",
      "Sensor: [0.3644595990019746, 0.5935715341070773, 0.20788428614182558, 0.2781248332594688], Action prob: [0.72080296 0.2791971 ], Action: 0, state: 0\n",
      "Sensor: [0.41356067190500445, 0.6244947108685925, 0.18210359088564493, 0.6173572062907893], Action prob: [0.71646464 0.2835354 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3804972451834383, 0.6464745453649442, 0.17779412803826364, 0.278079234482429], Action prob: [0.70780253 0.29219753], Action: 0, state: 0\n",
      "Sensor: [0.37811339771320374, 0.6236717192189126, 0.23534815586931992, 0.4052524452888957], Action prob: [0.7034761  0.29652396], Action: 0, state: 0\n",
      "Sensor: [0.3667182935132328, 0.591346050937228, 0.17693593250196304, 0.2531678310356997], Action prob: [0.7002999  0.29970002], Action: 0, state: 0\n",
      "Sensor: [0.27504822238050014, 0.6083218458662882, 0.22775768932126425, 0.27880206779203764], Action prob: [0.6992312 0.3007688], Action: 0, state: 0\n",
      "Sensor: [0.34272555835214513, 0.6521051650762001, 0.22684147942429309, 0.27698147586299604], Action prob: [0.6995896  0.30041042], Action: 0, state: 0\n",
      "Sensor: [0.3213258783333884, 0.6460739925359152, 0.18714318154736542, 0.17205251114978273], Action prob: [0.69906545 0.30093452], Action: 0, state: 0\n",
      "Sensor: [0.42598462906594164, 0.5957499729685874, 0.18680599597595438, 0.2888825646847212], Action prob: [0.6990084  0.30099156], Action: 0, state: 1\n",
      "Sensor: [0.39826744678822823, 0.6565736702117432, 0.17927185139712437, 0.24994553500081543], Action prob: [0.69938815 0.30061185], Action: 0, state: 1\n",
      "Sensor: [0.3828451114383293, 0.6178320642243352, 0.19757225474303125, 0.24252712581984692], Action prob: [0.6988783  0.30112177], Action: 0, state: 1\n",
      "Sensor: [0.36632417572657444, 0.6270665850169146, 0.18466297178649427, 0.17907064904056194], Action prob: [0.6985903  0.30140966], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -2000\n",
      "Sensor: [0.37547010417513754, 0.579376120687443, 0.20328366824437377, 0.26852264837410644], Action prob: [0.6983041  0.30169588], Action: 0, state: 0\n",
      "Sensor: [0.36088146074813116, 0.6369488669286376, 0.20425142633197185, 0.24697092235922424], Action prob: [0.69883716 0.30116284], Action: 0, state: 0\n",
      "Sensor: [0.32233645495419255, 0.6352213894298159, 0.19464785193815692, 0.24037606143342824], Action prob: [0.6988576  0.30114242], Action: 0, state: 1\n",
      "Sensor: [0.2925109633651634, 0.6631118472137252, 0.2087662215385678, 0.195157614711839], Action prob: [0.6991008 0.3008992], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3642175590426351, 0.5723021155219115, 0.23519531934140503, 0.3032202514381717], Action prob: [0.69864565 0.3013544 ], Action: 0, state: 1\n",
      "Sensor: [0.32632232852166404, 0.6249554936154704, 0.20083071336320724, 0.25479600006238085], Action prob: [0.6987501  0.30124992], Action: 0, state: 1\n",
      "Sensor: [0.38022374925778346, 0.6288008946661894, 0.21962199639740249, 0.24298041996560557], Action prob: [0.69893646 0.30106357], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "tensor([-0.6623, -1.8759, -0.5979, -0.4566, -0.3239, -0.2003, -0.0879,  0.0134,\n",
      "         0.0959,  0.1693,  0.2363,  0.9913,  0.1770,  0.2303,  0.2740,  0.3128,\n",
      "         0.3492,  0.3808,  1.3707], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 69 is 12600, loss is -0.020857972866864187\n",
      "Sensor: [0.3930165332839626, 0.649021896024384, 0.25024942284894186, 0.2313915920567735], Action prob: [0.7138575 0.2861425], Action: 0, state: 0\n",
      "Sensor: [0.35848521008343803, 0.6506706347331496, 0.21172642627936944, 0.24773189702526963], Action prob: [0.70716596 0.292834  ], Action: 0, state: 0\n",
      "Sensor: [0.43984107009344214, 0.6442458637565996, 0.19279523185941239, 0.23778843562365637], Action prob: [0.69959706 0.3004029 ], Action: 0, state: 0\n",
      "Sensor: [0.404089168567435, 0.6159396180436709, 0.20985063990864797, 0.2470978063262011], Action prob: [0.69507205 0.30492792], Action: 0, state: 0\n",
      "Sensor: [0.3662954724633917, 0.6386996972820526, 0.20420795337737221, 0.19659538403510532], Action prob: [0.69307053 0.30692947], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3440676594407465, 0.5881690109319685, 0.21912017492910865, 0.5255297804872772], Action prob: [0.6927696  0.30723038], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3609895160743344, 0.6214931789555033, 0.26292149146513255, 0.2994669027902652], Action prob: [0.692016 0.307984], Action: 0, state: 0\n",
      "Sensor: [0.35480985123374303, 0.6943380635479333, 0.18276615240512045, 0.2798126084072677], Action prob: [0.6923356 0.3076644], Action: 1, state: 0\n",
      "Sensor: [0.3481483218155824, 0.6106950336225634, 0.48444879399093743, 0.23986927175502093], Action prob: [0.69136256 0.30863744], Action: 0, state: 9\n",
      "Sensor: [0.3690671237530407, 0.3617379970192765, 0.20972288570408767, 0.22405396667373023], Action prob: [0.6876505  0.31234947], Action: 1, state: 9\n",
      "Sensor: [0.32953295679434985, 0.3230759982103688, 0.18661758318264654, 0.1830333981031403], Action prob: [0.68614185 0.31385818], Action: 0, state: 9\n",
      "Sensor: [0.36210623518655755, 0.3620352142005285, 0.27079357878918126, 0.2501174487747352], Action prob: [0.6871459 0.3128541], Action: 0, state: 9\n",
      "Sensor: [0.38764808600209943, 0.6543198778272223, 0.47808976715930507, 0.3206727506809419], Action prob: [0.69134265 0.30865735], Action: 0, state: 9\n",
      "Sensor: [0.34944797986722864, 0.6548008166433458, 0.5431516119181081, 0.24769158691887547], Action prob: [0.6915306  0.30846944], Action: 0, state: 9\n",
      "Sensor: [0.312409932516473, 0.3494348997336717, 0.24691624564973275, 0.25425642993955316], Action prob: [0.6872728  0.31272724], Action: 0, state: 9\n",
      "Sensor: [0.42374876522822336, 0.3335302678897884, 0.22637759969971954, 0.21547816178544663], Action prob: [0.68637687 0.31362313], Action: 0, state: 9\n",
      "Sensor: [0.5864671550671026, 0.6877827009386405, 0.22441906991372862, 0.24257789663844817], Action prob: [0.6912596  0.30874044], Action: 1, state: 9\n",
      "Sensor: [0.34308387503112486, 0.38909214507562173, 0.22970618777476573, 0.23641233763421454], Action prob: [0.6881075 0.3118925], Action: 0, state: 9\n",
      "Sensor: [0.2902268081113217, 0.37372092194676265, 0.21262396543608206, 0.2304363544033095], Action prob: [0.6871625 0.3128375], Action: 0, state: 9\n",
      "Sensor: [0.6178668381292731, 0.6266619602145365, 0.3909077916105932, 0.3149008906170438], Action prob: [0.6914637 0.3085363], Action: 0, state: 9\n",
      "Sensor: [0.5111844435230142, 0.6264007064659695, 0.21391605982082645, 0.2750342882217941], Action prob: [0.69131565 0.30868432], Action: 1, state: 9\n",
      "Sensor: [0.3401445276390341, 0.4049119784115407, 0.2189379077156361, 0.222524747712342], Action prob: [0.68792146 0.3120785 ], Action: 0, state: 9\n",
      "Sensor: [0.5882932739429338, 0.6202521508284875, 0.17229414468439463, 0.21300335801334147], Action prob: [0.6906305  0.30936953], Action: 0, state: 9\n",
      "Sensor: [0.31802517776887285, 0.6758633542397618, 0.5264420056120247, 0.2982594005672984], Action prob: [0.6915608  0.30843922], Action: 1, state: 9\n",
      "Sensor: [0.565003166143336, 0.6403506278928552, 0.24409160599285099, 0.2472062647329242], Action prob: [0.6914729  0.30852714], Action: 1, state: 9\n",
      "Sensor: [0.32331638995809725, 0.6503760206418552, 0.2076500539059531, 0.5694007024833625], Action prob: [0.6920416  0.30795842], Action: 0, state: 9\n",
      "Sensor: [0.6490204323392476, 0.4145290637365739, 0.1921772338672342, 0.28317421918266217], Action prob: [0.6894017 0.3105983], Action: 0, state: 9\n",
      "tensor([-0.4529, -0.1998,  0.0405,  0.2672,  1.4610,  1.7594,  0.5480,  2.2348,\n",
      "         0.5633,  1.3994,  0.3413,  0.2393,  0.1446,  0.0642, -0.0051, -0.0711,\n",
      "        -0.4126, -0.1828, -0.2313, -0.2719, -0.9854, -0.3475, -0.3758, -1.2876,\n",
      "        -1.3636, -0.4483, -0.4732], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 70 is -14600, loss is -0.07237328928617266\n",
      "Sensor: [0.3453333705446282, 0.6140594284582499, 0.24406303827710366, 0.26026333087449827], Action prob: [0.710818   0.28918192], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.36986864187452395, 0.6445342352295574, 0.2206378876161717, 0.28000331864166783], Action prob: [0.706164   0.29383603], Action: 0, state: 0\n",
      "Sensor: [0.3263355441481205, 0.6792309934184695, 0.24528891486891996, 0.25506377240946343], Action prob: [0.70008665 0.29991326], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3208108297144694, 0.6254214547625858, 0.2697350639643742, 0.30689681301034893], Action prob: [0.69638 0.30362], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3759402012200325, 0.6580664924960395, 0.23358703486557936, 0.19638516232770492], Action prob: [0.6948267 0.3051733], Action: 0, state: 0\n",
      "Sensor: [0.3745658458283131, 0.651562085326354, 0.25595501006474053, 0.27454822134096635], Action prob: [0.69424784 0.30575216], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.37684321523188763, 0.6141488898039023, 0.20680039986058965, 0.3342100756845392], Action prob: [0.6937444  0.30625558], Action: 0, state: 0\n",
      "Sensor: [0.43460822817965244, 0.6171475083157216, 0.20581044568338372, 0.2595683746557425], Action prob: [0.69342065 0.3065793 ], Action: 0, state: 0\n",
      "Sensor: [0.4755335353553799, 0.6341699879306939, 0.20127454088451927, 0.3288601141969504], Action prob: [0.69381297 0.306187  ], Action: 0, state: 0\n",
      "Sensor: [0.3632623249747185, 0.5995102203795588, 0.20188750978256909, 0.31154173258106205], Action prob: [0.69310933 0.30689064], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.36916324940692746, 0.6257587737610258, 0.20373972671777807, 0.2226201360115037], Action prob: [0.69304657 0.30695346], Action: 0, state: 0\n",
      "Sensor: [0.37131730456710627, 0.6938542735449635, 0.22473687325073646, 0.2737333939910314], Action prob: [0.6940611  0.30593887], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3652140822666239, 0.6455738124706121, 0.18278096747575723, 0.23046030744900287], Action prob: [0.69368297 0.3063171 ], Action: 0, state: 0\n",
      "Sensor: [0.3754198407883189, 0.3215322201563628, 0.5924225299945893, 0.23398362026078653], Action prob: [0.68987465 0.31012532], Action: 0, state: 9\n",
      "Sensor: [0.5865718702046542, 0.6322752950731695, 0.19398289312261374, 0.21871926775984482], Action prob: [0.6922147  0.30778536], Action: 0, state: 9\n",
      "Sensor: [0.36297449111652025, 0.3424958532422349, 0.27385231644702684, 0.1909093413892425], Action prob: [0.688886   0.31111404], Action: 1, state: 9\n",
      "tensor([-1.6759e+00, -6.7678e-01, -1.1837e+00, -1.1709e+00, -3.5791e-01,\n",
      "        -3.3250e-01, -2.3044e-01,  3.9574e-04,  2.0838e-01,  1.2181e+00,\n",
      "         2.9330e-01,  1.3885e+00,  4.9731e-01,  3.7968e-01,  2.6532e-01,\n",
      "         5.2762e-01], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 71 is 600, loss is 0.05309548105935562\n",
      "Sensor: [0.36231525709259155, 0.6324756574150084, 0.2245055435217748, 0.24133494360849742], Action prob: [0.7059872 0.2940128], Action: 0, state: 0\n",
      "Sensor: [0.36914890449738336, 0.6215152692217213, 0.2241006580769783, 0.2743263896167601], Action prob: [0.7018197  0.29818028], Action: 0, state: 0\n",
      "Sensor: [0.31511790864367706, 0.6327712530063753, 0.20660336068642574, 0.2079438912351478], Action prob: [0.69622356 0.3037765 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35030615540932625, 0.6339434559930526, 0.20878900323983812, 0.4276637902120398], Action prob: [0.6942795  0.30572054], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3225062922944565, 0.6599870847328265, 0.22424686804478655, 0.2572787404175587], Action prob: [0.6929256 0.3070745], Action: 0, state: 0\n",
      "Sensor: [0.3142604481028373, 0.6110779968683435, 0.20982105302704562, 0.263580273823899], Action prob: [0.69183916 0.30816087], Action: 0, state: 0\n",
      "Sensor: [0.3947299183589399, 0.6437687073176758, 0.16925550951301924, 0.3076737789138888], Action prob: [0.69217    0.30782992], Action: 0, state: 0\n",
      "Sensor: [0.3179732887036985, 0.6858742435730035, 0.22920488746988577, 0.2523339139925436], Action prob: [0.6922363  0.30776376], Action: 0, state: 1\n",
      "Sensor: [0.39283999824664656, 0.62628071388099, 0.2507096000727508, 0.31814444646437623], Action prob: [0.69195706 0.30804294], Action: 0, state: 1\n",
      "Sensor: [0.4064054686019129, 0.5931696857245504, 0.23891327337025528, 0.3087995898876081], Action prob: [0.6913795 0.3086205], Action: 0, state: 2\n",
      "Sensor: [0.39214267835931343, 0.6118522789289574, 0.2227671235156898, 0.2596145396541168], Action prob: [0.691163 0.308837], Action: 0, state: 2\n",
      "Sensor: [0.570498093110222, 0.612121044897989, 0.24176256963571865, 0.24589319111166133], Action prob: [0.69141144 0.30858856], Action: 0, state: 3\n",
      "Sensor: [0.3492568340024273, 0.6253967867104686, 0.27781960692532226, 0.24217760578768777], Action prob: [0.69090366 0.30909634], Action: 0, state: 3\n",
      "Sensor: [0.30096436274282046, 0.6016554448908855, 0.22329734385885575, 0.23017452281374542], Action prob: [0.6906073  0.30939275], Action: 0, state: 3\n",
      "Sensor: [0.43006848823261107, 0.34024509054024366, 0.2194127125721303, 0.2273492382091195], Action prob: [0.68810964 0.31189033], Action: 1, state: 8\n",
      "Sensor: [0.5459573755643256, 0.6262813921118868, 0.4291595026960486, 0.2838680457083139], Action prob: [0.6908216  0.30917838], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.40549815824461577, 0.6572929497962474, 0.19584152940684268, 0.5469018024072145], Action prob: [0.6923079  0.30769214], Action: 0, state: 8\n",
      "Sensor: [0.5392292728944553, 0.6638170468249128, 0.2374391329857707, 0.22866123935838575], Action prob: [0.69196755 0.30803245], Action: 1, state: 8\n",
      "Sensor: [0.3830657778947485, 0.39898886734252215, 0.17752135749184753, 0.24466024402338435], Action prob: [0.68866545 0.31133455], Action: 0, state: 8\n",
      "Sensor: [0.549387564232531, 0.624287238201289, 0.19452788785999692, 0.19304499847955997], Action prob: [0.6906272  0.30937275], Action: 0, state: 8\n",
      "Sensor: [0.3554123626188432, 0.4368612711372179, 0.23067395217327505, 0.5612697666102865], Action prob: [0.69009924 0.30990082], Action: 1, state: 8\n",
      "Sensor: [0.3571018219584762, 0.6892901836575047, 0.19161449533898045, 0.24090976685604423], Action prob: [0.6916108  0.30838916], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3913111525467737, 0.6548020279181477, 0.18998927912147875, 0.23331422226269755], Action prob: [0.69180286 0.30819708], Action: 0, state: 0\n",
      "Sensor: [0.32822566495251937, 0.5867594705996699, 0.22650522034638457, 0.20614924068098375], Action prob: [0.6908957  0.30910435], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3818722561364077, 0.7149943491196211, 0.2516529053032896, 0.4134917221943706], Action prob: [0.69282866 0.30717134], Action: 0, state: 0\n",
      "tensor([-0.7456, -0.5359, -1.1302, -0.8212, -0.1708, -0.0195,  0.1170,  0.2269,\n",
      "         0.3269,  0.4076,  0.4797,  0.5194,  0.5568,  0.5906,  1.3044,  0.2526,\n",
      "         0.1102, -0.0616, -0.1351, -0.2400, -1.0525, -0.9724, -0.2918, -0.8569,\n",
      "        -0.2680], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 72 is -7700, loss is 0.09636945274896465\n",
      "Sensor: [0.3662149112664852, 0.6227549249043522, 0.23342325578498616, 0.2512359965770375], Action prob: [0.69616324 0.30383676], Action: 0, state: 0\n",
      "Sensor: [0.36153925550788146, 0.6527462155144886, 0.27005720435739977, 0.23207997522226334], Action prob: [0.69039553 0.3096045 ], Action: 0, state: 1\n",
      "Sensor: [0.3962850247349827, 0.6942410833258553, 0.1910302117998, 0.21505839174391847], Action prob: [0.6848232  0.31517673], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.388432171036717, 0.6135664770594239, 0.21460364968792378, 0.30246078631756923], Action prob: [0.6813439  0.31865612], Action: 0, state: 0\n",
      "Sensor: [0.3139576015259668, 0.6212493258163176, 0.19187377336112227, 0.2613892088921378], Action prob: [0.6798274 0.3201726], Action: 0, state: 0\n",
      "Sensor: [0.2814718624536818, 0.6621954768701259, 0.24406649019047727, 0.23082859219585294], Action prob: [0.67955536 0.3204446 ], Action: 0, state: 1\n",
      "Sensor: [0.5479281949154681, 0.7008514889989429, 0.17123418386440326, 0.2873398186229859], Action prob: [0.68043697 0.31956303], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.37868432568947774, 0.6277861591053967, 0.27793591871250634, 0.23755059003985643], Action prob: [0.67903113 0.32096884], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.37969062547064697, 0.6478376172510506, 0.17785824351018503, 0.26104987875696917], Action prob: [0.6790285  0.32097155], Action: 0, state: 0\n",
      "Sensor: [0.28494497489694254, 0.6381395858813779, 0.21675095253601392, 0.24752168612228292], Action prob: [0.6788457  0.32115424], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3642490153529845, 0.6656053499401653, 0.21959291918488255, 0.24990646276459436], Action prob: [0.6793757  0.32062423], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.36614905451311935, 0.6418626117869225, 0.18607332055647283, 0.2502625953699869], Action prob: [0.6792857 0.3207143], Action: 0, state: 0\n",
      "Sensor: [0.34463878288133915, 0.5593761153609506, 0.18762472243691306, 0.2741301202977629], Action prob: [0.678433   0.32156697], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.37884935913794604, 0.6442817698554151, 0.22377584901374156, 0.26277131630975986], Action prob: [0.6790801 0.3209199], Action: 0, state: 0\n",
      "Sensor: [0.3728725192767302, 0.6119734235853282, 0.20443662908143487, 0.5520439222281878], Action prob: [0.67971706 0.3202829 ], Action: 0, state: 0\n",
      "Sensor: [0.34262706913159796, 0.640092568704625, 0.24876600280321054, 0.2039798313626478], Action prob: [0.6789732  0.32102674], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "tensor([-0.8726, -0.6542, -1.3683, -0.3429, -0.1433,  0.0194,  0.4923,  0.7059,\n",
      "         0.1083,  0.6326,  0.7909,  0.2208,  0.9042,  0.2687,  0.3394,  1.1813],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 73 is 7500, loss is -0.14265793267207155\n",
      "Sensor: [0.32811677782536386, 0.6630950494743028, 0.2449041092907096, 0.2508840961782881], Action prob: [0.69492054 0.30507952], Action: 0, state: 0\n",
      "Sensor: [0.30965216844727506, 0.5963576188968359, 0.2005821212803196, 0.25460283354880237], Action prob: [0.689268   0.31073198], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3493936567756115, 0.7001337337676363, 0.19259022812593515, 0.25683848152559946], Action prob: [0.6847393  0.31526077], Action: 0, state: 0\n",
      "Sensor: [0.3716796534713249, 0.6425293042203148, 0.19198756825700516, 0.24471519544752576], Action prob: [0.68180054 0.31819943], Action: 0, state: 0\n",
      "Sensor: [0.34011763953192387, 0.676208146780213, 0.21313613513534135, 0.28117674730624503], Action prob: [0.6809051  0.31909493], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35089443671456105, 0.639167275698723, 0.19171267758087973, 0.24681231925469604], Action prob: [0.68008953 0.31991044], Action: 0, state: 0\n",
      "Sensor: [0.3256276182621366, 0.6118767372603914, 0.21208363483588225, 0.2690855127984873], Action prob: [0.6794931  0.32050693], Action: 0, state: 0\n",
      "Sensor: [0.35027213001471197, 0.6471751466825506, 0.1596848104250052, 0.2743716128102406], Action prob: [0.6798316  0.32016838], Action: 0, state: 0\n",
      "Sensor: [0.3800405662918418, 0.635711668287686, 0.21317388528729167, 0.29200446541578295], Action prob: [0.6798249  0.32017508], Action: 0, state: 0\n",
      "Sensor: [0.35814527783427963, 0.6834866015185105, 0.19115168907401417, 0.20703612854541162], Action prob: [0.68000466 0.3199953 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.35156877712087076, 0.6492405315108806, 0.24659120597008113, 0.2345727792638807], Action prob: [0.67968047 0.32031953], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3270937782450146, 0.6504650493925911, 0.22592440709866143, 0.21903395427308706], Action prob: [0.6795252 0.3204748], Action: 0, state: 0\n",
      "Sensor: [0.34389937027606116, 0.6529339461572985, 0.22508115393733927, 0.2425331395918978], Action prob: [0.67963046 0.3203696 ], Action: 0, state: 0\n",
      "Sensor: [0.3312985579735643, 0.5735655805444196, 0.22051937529235585, 0.38866379538109364], Action prob: [0.6792321  0.32076788], Action: 0, state: 0\n",
      "Sensor: [0.34034354070298667, 0.6247445735024438, 0.2439106431114888, 0.4019218583137928], Action prob: [0.6796381 0.3203619], Action: 0, state: 0\n",
      "Sensor: [0.3668309711626266, 0.6127818654813622, 0.23999103416483503, 0.24104209015780192], Action prob: [0.6791824  0.32081756], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -2000\n",
      "tensor([-0.6674, -1.5264, -0.5947, -0.4197, -0.7650, -0.1840, -0.0509,  0.0693,\n",
      "         0.1771,  0.7802,  0.7794,  0.2646,  0.3354,  0.4006,  0.4571,  1.4815],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 74 is 8700, loss is -0.033568360767227204\n",
      "Sensor: [0.408495474815553, 0.6599002763405779, 0.195305090064049, 0.2756603412937958], Action prob: [0.6953032  0.30469677], Action: 0, state: 0\n",
      "Sensor: [0.4926208703895587, 0.6679548923268851, 0.17748318249051484, 0.19610617135797548], Action prob: [0.6909069 0.3090931], Action: 0, state: 0\n",
      "Sensor: [0.3305189589724435, 0.6850688714796769, 0.21515332560431133, 0.30592492184223885], Action prob: [0.68619907 0.3138009 ], Action: 0, state: 0\n",
      "Sensor: [0.35820601641066413, 0.6398807232536166, 0.22900606844027366, 0.2972296409654704], Action prob: [0.6836651 0.3163348], Action: 0, state: 0\n",
      "Sensor: [0.30704692351237184, 0.655991164690518, 0.22060977180372618, 0.24874375305759153], Action prob: [0.6826861  0.31731385], Action: 0, state: 0\n",
      "Sensor: [0.3637985027988656, 0.6261243685479938, 0.2318031496968267, 0.24926468765358598], Action prob: [0.68214107 0.31785887], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3468993996407014, 0.6714147426226249, 0.19245139293566788, 0.20704657520661432], Action prob: [0.6822974 0.3177026], Action: 0, state: 0\n",
      "Sensor: [0.34796851868646506, 0.6262883518762461, 0.2147567437979752, 0.5228548296136177], Action prob: [0.6826258  0.31737426], Action: 0, state: 0\n",
      "Sensor: [0.3748886485723565, 0.6415162394787566, 0.20752428720857485, 0.32360949192328403], Action prob: [0.68241113 0.31758887], Action: 0, state: 1\n",
      "Sensor: [0.325582534451092, 0.6382923089691707, 0.23190910651561905, 0.1946627433680494], Action prob: [0.6818316  0.31816843], Action: 0, state: 1\n",
      "Sensor: [0.40004008256036333, 0.6827149483353521, 0.49039721911996964, 0.2350191951894601], Action prob: [0.68185776 0.3181423 ], Action: 0, state: 9\n",
      "Sensor: [0.6160226936605495, 0.6227443982442799, 0.5405064197718897, 0.24029961713662293], Action prob: [0.68122363 0.31877643], Action: 0, state: 9\n",
      "Sensor: [0.3738464686009253, 0.6205471901648383, 0.49634455554796375, 0.2171550393068883], Action prob: [0.68014014 0.31985986], Action: 0, state: 9\n",
      "Sensor: [0.6504061830488181, 0.6460215107951593, 0.221778934491945, 0.5218932882137162], Action prob: [0.68189347 0.31810647], Action: 0, state: 9\n",
      "Sensor: [0.39423970962372973, 0.6294376284621985, 0.22715897704045118, 0.5633188954279086], Action prob: [0.6819633  0.31803665], Action: 0, state: 9\n",
      "Sensor: [0.351851725046076, 0.3798324985396285, 0.18043920778227515, 0.22357584339518746], Action prob: [0.67896944 0.32103053], Action: 0, state: 9\n",
      "Sensor: [0.3276785377375275, 0.1411387651071733, 0.23640855485933224, 0.2478980411059302], Action prob: [0.6759748  0.32402524], Action: 1, state: 9\n",
      "Sensor: [0.3322669409848832, 0.6403739569566123, 0.5220427935059408, 0.2249049820246659], Action prob: [0.67991626 0.3200838 ], Action: 0, state: 9\n",
      "Sensor: [0.3364804030517149, 0.3909466483257537, 0.19722024777332275, 0.2724027700692704], Action prob: [0.6789275  0.32107255], Action: 1, state: 9\n",
      "Sensor: [0.3929718638214955, 0.6113699172191515, 0.49478089164660644, 0.19990937421798397], Action prob: [0.68032867 0.31967136], Action: 1, state: 9\n",
      "Sensor: [0.49818201032431486, 0.2800001692560821, 0.4219867478113002, 0.25993915576895443], Action prob: [0.6776123 0.3223877], Action: 0, state: 9\n",
      "Sensor: [0.3844060850156982, 0.554166494886546, 0.2266004073899437, 0.8633470150179872], Action prob: [0.6811068  0.31889325], Action: 0, state: 9\n",
      "Sensor: [0.5883578773635794, 0.6206943122481923, 0.45431061839013676, 0.23043261415544053], Action prob: [0.6811794 0.3188206], Action: 0, state: 9\n",
      "Sensor: [0.5577054413834973, 0.6059590149654163, 0.2130967755627647, 0.5061816908480603], Action prob: [0.6816788  0.31832126], Action: 0, state: 9\n",
      "Sensor: [0.6155710754889631, 0.6468301816298454, 0.19364959447514146, 0.2432057023783594], Action prob: [0.68179435 0.31820562], Action: 0, state: 9\n",
      "Sensor: [0.6576422841687696, 0.5779469380451819, 0.18980324067646698, 0.5825420732697615], Action prob: [0.6821497 0.3178503], Action: 0, state: 9\n",
      "Sensor: [0.3424534086610328, 0.6149622027171179, 0.5176274280081642, 0.2742346309962424], Action prob: [0.68069506 0.319305  ], Action: 1, state: 9\n",
      "tensor([-0.9181, -0.6208, -0.3449, -0.0870,  0.1484,  1.0196,  0.2443,  0.4169,\n",
      "         0.5561,  0.6827,  0.5555,  0.4433,  0.3429,  0.2509,  0.1686,  0.0958,\n",
      "         0.0845, -0.0353, -0.2563, -0.4102, -0.1826, -0.2185, -0.2571, -0.2866,\n",
      "        -0.3160, -0.3403, -1.0924], dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 75 is -10800, loss is 0.013204431657968942\n",
      "Sensor: [0.27809169485373086, 0.6682251019804973, 0.2162594418520951, 0.23646657136696045], Action prob: [0.6944452  0.30555487], Action: 0, state: 0\n",
      "Sensor: [0.359201843229048, 0.622988954307974, 0.25126958512878056, 0.28591156847447685], Action prob: [0.689889 0.310111], Action: 0, state: 0\n",
      "Sensor: [0.3707493054218131, 0.6341169638186237, 0.22344683690395298, 0.20365078916196017], Action prob: [0.6850653  0.31493464], Action: 0, state: 0\n",
      "Sensor: [0.33360220076001457, 0.6283514957163369, 0.2073194979079903, 0.2957853134296847], Action prob: [0.6829637  0.31703624], Action: 0, state: 0\n",
      "Sensor: [0.34011676329238427, 0.6572915715606735, 0.28172121669185624, 0.24415237437773096], Action prob: [0.6822123  0.31778774], Action: 0, state: 0\n",
      "Sensor: [0.31219583776805243, 0.6790957012764867, 0.1830079604177808, 0.23436567288798282], Action prob: [0.6822161  0.31778386], Action: 0, state: 0\n",
      "Sensor: [0.3744923237927954, 0.617104452062587, 0.1787979036429817, 0.2783593078492459], Action prob: [0.6818604  0.31813958], Action: 0, state: 0\n",
      "Sensor: [0.3077485289595391, 0.5639501839573163, 0.39187449619840187, 0.2526174963051007], Action prob: [0.68056    0.31943995], Action: 0, state: 0\n",
      "Sensor: [0.40514887109212333, 0.6278045925474748, 0.24033350290039227, 0.2135821844620338], Action prob: [0.68105406 0.318946  ], Action: 0, state: 0\n",
      "Sensor: [0.36508753933214705, 0.6502091072790438, 0.1752931264738515, 0.2923333812205829], Action prob: [0.68165696 0.31834307], Action: 0, state: 0\n",
      "Sensor: [0.3805794159202708, 0.6523906337922448, 0.2107233236339643, 0.21625925319816058], Action prob: [0.6817493 0.3182507], Action: 0, state: 1\n",
      "Sensor: [0.31003794450354266, 0.652596829188181, 0.22144668145799842, 0.2685343788627632], Action prob: [0.6817699 0.3182301], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.33004697240580494, 0.6377343509986902, 0.2170068741662351, 0.22134908351655347], Action prob: [0.68163365 0.3183663 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.39412446648618626, 0.6861228957073536, 0.20549642228753426, 0.25837893058788686], Action prob: [0.6822578  0.31774226], Action: 0, state: 0\n",
      "Sensor: [0.41324521206062564, 0.6191777890076353, 0.23801699906431323, 0.27056840076666927], Action prob: [0.6816884  0.31831157], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.36104341596091305, 0.623946139912978, 0.1916491959667551, 0.27647220356122026], Action prob: [0.6815156  0.31848443], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.34042446567246903, 0.6369745112728677, 0.2017645260428143, 0.262874040082555], Action prob: [0.6816056  0.31839442], Action: 0, state: 0\n",
      "Sensor: [0.39459228660838247, 0.6608284586691999, 0.17621732164251253, 0.3152059475682418], Action prob: [0.6821837 0.3178163], Action: 0, state: 1\n",
      "Sensor: [0.33513446035281474, 0.7128582626896623, 0.21414839871292007, 0.25359723068201745], Action prob: [0.6825078  0.31749216], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3965930924483265, 0.6934579883829554, 0.21095254910096484, 0.2694674651079367], Action prob: [0.68253833 0.3174617 ], Action: 0, state: 0\n",
      "Sensor: [0.39480426564685944, 0.573050865325496, 0.22456184821686492, 0.2230960191101862], Action prob: [0.68115854 0.31884146], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.8605, -0.7141, -0.5794, -0.4491, -0.3295, -0.2198, -0.1211, -0.0335,\n",
      "         0.0470,  0.1193,  0.1770,  0.6860,  0.6856,  0.2525,  0.8832,  0.9406,\n",
      "         0.2978,  0.3251,  1.0485,  0.3617,  1.1506], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 76 is 16100, loss is -0.1746643888439292\n",
      "Sensor: [0.36232050958042844, 0.6717992347888898, 0.25135072636068334, 0.16017380353615174], Action prob: [0.70191956 0.29808044], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.338649723079301, 0.6340014092758188, 0.2609773065674624, 0.2477519623406021], Action prob: [0.6988347 0.3011653], Action: 0, state: 0\n",
      "Sensor: [0.36091213998340194, 0.6538747070405291, 0.21552149504732673, 0.31018140277167444], Action prob: [0.69561285 0.30438718], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3582254781678586, 0.6522385377163347, 0.1729682981733368, 0.5752876902037196], Action prob: [0.6947618  0.30523828], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.2920394339716018, 0.6670457397916878, 0.20801396173561087, 0.20528088820559734], Action prob: [0.6934467  0.30655333], Action: 0, state: 0\n",
      "Sensor: [0.3918337080752672, 0.7137875107620966, 0.19828393166478478, 0.2157258335205508], Action prob: [0.6937234 0.3062766], Action: 0, state: 0\n",
      "Sensor: [0.32723346018412175, 0.6396021864319851, 0.2356959673666675, 0.25920611422412704], Action prob: [0.6928987  0.30710128], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3239428539719365, 0.6371320807317221, 0.20765879272790794, 0.2655365864801788], Action prob: [0.69272095 0.30727905], Action: 0, state: 0\n",
      "Sensor: [0.2902956241979609, 0.7078380273897973, 0.21577072655407262, 0.2179057762580877], Action prob: [0.69323164 0.30676842], Action: 0, state: 0\n",
      "Sensor: [0.3704540370486597, 0.6477287302075729, 0.22659088738758268, 0.19757852817613084], Action prob: [0.6928958  0.30710414], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3023011244754833, 0.5663174141082237, 0.18446025421749404, 0.26500934139081506], Action prob: [0.6920528 0.3079472], Action: 0, state: 0\n",
      "Sensor: [0.38221879341766857, 0.668166269306681, 0.2517010189615436, 0.24966368076234066], Action prob: [0.6928669  0.30713305], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3269414125616996, 0.6414334494658104, 0.225103137241655, 0.22368204561357524], Action prob: [0.69263047 0.30736953], Action: 0, state: 0\n",
      "Sensor: [0.3502039688007817, 0.6777018047271237, 0.1977260690141787, 0.22521677521635083], Action prob: [0.6930372  0.30696276], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3667186168910638, 0.6039755043895564, 0.2380717056171558, 0.2740324034548534], Action prob: [0.69250304 0.307497  ], Action: 0, state: 0\n",
      "Sensor: [0.36081135361285616, 0.6403209008051917, 0.19408402135296007, 0.28002384742292796], Action prob: [0.6927669  0.30723304], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3410265798244567, 0.6637517873739719, 0.21512125692738138, 0.29258700024672485], Action prob: [0.6930388  0.30696118], Action: 0, state: 0\n",
      "Sensor: [0.35341291172828593, 0.6937406818851709, 0.2082495424311566, 0.23740298328145268], Action prob: [0.69332355 0.30667648], Action: 0, state: 0\n",
      "Sensor: [0.3882082494938568, 0.5830474027093981, 0.20239349443321517, 0.23703432928959792], Action prob: [0.69238645 0.30761355], Action: 0, state: 0\n",
      "tensor([-2.2305, -0.6600, -1.6630, -1.3934, -0.3581, -0.2267, -0.3500, -0.0553,\n",
      "         0.0401,  0.4075,  0.1668,  0.7573,  0.2673,  1.0418,  0.3244,  1.1749,\n",
      "         0.3649,  0.4013,  0.4368], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 77 is 13300, loss is 0.08179214103221738\n",
      "Sensor: [0.3061287665172242, 0.7222299937461428, 0.1803339812191608, 0.2700570104246812], Action prob: [0.70517266 0.29482734], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35840501433862126, 0.5837251073087204, 0.19518895745774867, 0.228231437911033], Action prob: [0.70298856 0.2970114 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.30895640636996446, 0.6239954446008465, 0.21535783868395605, 0.21188471551817895], Action prob: [0.69981027 0.30018976], Action: 0, state: 0\n",
      "Sensor: [0.3024975867913095, 0.6632025674521163, 0.21186170267351445, 0.2716254030971538], Action prob: [0.69888526 0.3011147 ], Action: 0, state: 0\n",
      "Sensor: [0.3113103310945147, 0.6097619983461412, 0.2310946892903456, 0.5248152218886734], Action prob: [0.6985892  0.30141082], Action: 0, state: 1\n",
      "Sensor: [0.36523617978817824, 0.4464197884460552, 0.2413478292445501, 0.20406732315382795], Action prob: [0.6962559  0.30374417], Action: 0, state: 2\n",
      "Sensor: [0.32993829649422113, 0.6488904222469729, 0.23886935111365964, 0.24200544417015202], Action prob: [0.69746625 0.30253372], Action: 0, state: 2\n",
      "Sensor: [0.3395838137504199, 0.6499902045392785, 0.19579255737469553, 0.2284228538736265], Action prob: [0.6979745  0.30202544], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "Sensor: [0.4095068351221485, 0.5210749670362984, 0.18819592861223486, 0.20781962111601252], Action prob: [0.697      0.30299997], Action: 0, state: 1\n",
      "Sensor: [0.3993103805169992, 0.6374756492796856, 0.2380376379327113, 0.2702675577290895], Action prob: [0.69779176 0.30220824], Action: 0, state: 2\n",
      "Sensor: [0.36051558051037164, 0.6229201906848681, 0.23303195337419577, 0.19745668377881498], Action prob: [0.69763243 0.30236754], Action: 0, state: 3\n",
      "Sensor: [0.35802974511994956, 0.3517053743924966, 0.22782816445421394, 0.28375337700856273], Action prob: [0.69508624 0.30491373], Action: 0, state: 3\n",
      "Sensor: [0.4026377514813197, 0.6822462431763158, 0.49941308172903215, 0.21264956243302666], Action prob: [0.69697154 0.30302846], Action: 0, state: 3\n",
      "Sensor: [0.3889630189280216, 0.3800386090062294, 0.20994866104570328, 0.23774746667758834], Action prob: [0.69499916 0.3050008 ], Action: 0, state: 3\n",
      "Sensor: [0.35922399339296146, 0.37314402013756265, 0.19720775744712454, 0.2782826332383606], Action prob: [0.6945117  0.30548832], Action: 0, state: 8\n",
      "Sensor: [0.37826129303013556, 0.5924443625426139, 0.5077656075005417, 0.21837981519659094], Action prob: [0.6959722  0.30402777], Action: 0, state: 8\n",
      "Sensor: [0.5547500309550208, 0.6447703691715626, 0.19277610029296716, 0.23855841511107512], Action prob: [0.6977488 0.3022512], Action: 0, state: 8\n",
      "Sensor: [0.6059635238361545, 0.5787372895321975, 0.24000656913018475, 0.2500051237782989], Action prob: [0.69751483 0.30248514], Action: 0, state: 8\n",
      "Sensor: [0.38376887955932704, 0.3709407438181721, 0.22939049236984582, 0.2618795868545459], Action prob: [0.69485825 0.30514172], Action: 0, state: 8\n",
      "Sensor: [0.6371098580433812, 0.6702657028139369, 0.22290862426929056, 0.30746421310166117], Action prob: [0.69796103 0.30203897], Action: 1, state: 8\n",
      "Sensor: [0.3870354177723132, 0.6569039704822209, 0.24120257956032454, 0.23834452607476897], Action prob: [0.6978528 0.3021472], Action: 0, state: 0\n",
      "Sensor: [0.3146813929346455, 0.6347582153505568, 0.19565468808208636, 0.27181903780677197], Action prob: [0.6977669 0.3022331], Action: 0, state: 0\n",
      "Sensor: [0.32971958150007735, 0.5974365691055658, 0.21935862980176862, 0.22830675798541714], Action prob: [0.697467   0.30253297], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3306545921113122, 0.5966586592417275, 0.20135768172937768, 0.2791643252523749], Action prob: [0.6975577 0.3024423], Action: 0, state: 2\n",
      "tensor([-1.9365, -1.4579, -0.4290, -0.2078, -0.0267,  0.1186,  0.2479,  1.2150,\n",
      "         0.2873,  0.3810,  0.4346,  0.4890,  0.5261,  0.5723,  0.3602,  0.1648,\n",
      "        -0.0056, -0.1592, -0.2998, -1.4028, -0.3844, -0.3506, -0.3239, -0.3018],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 78 is -6800, loss is 0.10371539487337683\n",
      "Sensor: [0.39112280045426284, 0.63338971046805, 0.22194095712978076, 0.2472038720870531], Action prob: [0.7023276  0.29767242], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35053938982483945, 0.6050808169824466, 0.22913159876299277, 0.24798382219988818], Action prob: [0.700963   0.29903698], Action: 0, state: 0\n",
      "Sensor: [0.43852242696016885, 0.5177948398729131, 0.24105839105562038, 0.27892035021187483], Action prob: [0.69753027 0.3024697 ], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -4000\n",
      "Maintenance in progress, cumulative -3000\n",
      "Sensor: [0.371435518872443, 0.6576959185095693, 0.18475489168796655, 0.2525273752181002], Action prob: [0.69724196 0.30275807], Action: 0, state: 0\n",
      "Sensor: [0.36620899359025544, 0.6175420112983945, 0.22403250174473838, 0.24827321773572844], Action prob: [0.6967367  0.30326337], Action: 0, state: 1\n",
      "Sensor: [0.4145085135985632, 0.631574305676108, 0.20243571090498083, 0.2217660319136653], Action prob: [0.6967871  0.30321294], Action: 0, state: 2\n",
      "Sensor: [0.3250880078606997, 0.5998620511253947, 0.19917723270575802, 0.3066985366548972], Action prob: [0.69646615 0.30353388], Action: 0, state: 2\n",
      "Sensor: [0.36568374327323877, 0.640199135968016, 0.2362149406438792, 0.27015051777786964], Action prob: [0.6967512  0.30324885], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.3558589523495325, 0.6267822681544875, 0.2063203035631637, 0.2635936244650258], Action prob: [0.69671667 0.30328333], Action: 0, state: 1\n",
      "Sensor: [0.33166556618029475, 0.6278724534329112, 0.2185751396681463, 0.18961840121364248], Action prob: [0.6965356  0.30346438], Action: 0, state: 1\n",
      "Sensor: [0.3576840227944172, 0.6275796626439208, 0.2445567723592724, 0.20097463528968942], Action prob: [0.6965024  0.30349764], Action: 0, state: 2\n",
      "Sensor: [0.4108171859362455, 0.6487587115679038, 0.21863959252832701, 0.26121784612431653], Action prob: [0.6969034  0.30309656], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.35573567163012365, 0.7219602389086229, 0.21756621419457098, 0.24273373515734073], Action prob: [0.6975174  0.30248263], Action: 0, state: 1\n",
      "Sensor: [0.36617611813886025, 0.620710020099362, 0.21145723294397967, 0.2509116620111451], Action prob: [0.6968424 0.3031576], Action: 0, state: 1\n",
      "Sensor: [0.42118937612379537, 0.6540963180630867, 0.16520268392360637, 0.4539803752423087], Action prob: [0.6975252 0.3024749], Action: 0, state: 1\n",
      "Sensor: [0.33822194874312533, 0.6618276561664098, 0.49214775239503017, 0.26370336469182437], Action prob: [0.69652253 0.30347753], Action: 0, state: 1\n",
      "Sensor: [0.4010931522255951, 0.5484453848374308, 0.24479149591495894, 0.2171881414716421], Action prob: [0.69561017 0.30438986], Action: 0, state: 1\n",
      "Sensor: [0.3643286683445165, 0.6453492670261778, 0.18620271874839953, 0.20320674209179176], Action prob: [0.6963234  0.30367655], Action: 0, state: 1\n",
      "Sensor: [0.3845876040844435, 0.623665793416382, 0.22997929937729883, 0.20988374534394105], Action prob: [0.6964533 0.3035468], Action: 0, state: 1\n",
      "tensor([-1.3943, -0.2734, -0.1813, -0.7225, -0.5434, -0.3989, -0.2689, -0.5018,\n",
      "        -0.0992,  0.0072,  0.0925,  0.5597,  0.2030,  0.2739,  0.3366,  0.3926,\n",
      "         0.4467,  0.4913,  0.5323], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 79 is 11200, loss is 0.05514908025272834\n",
      "Sensor: [0.36412254193778837, 0.5787661196750398, 0.18749591723936687, 0.29255465923024887], Action prob: [0.69746906 0.30253094], Action: 0, state: 0\n",
      "Sensor: [0.3098403611599682, 0.619831122273902, 0.2033783109346372, 0.2894807097456652], Action prob: [0.6968902  0.30310982], Action: 0, state: 0\n",
      "Sensor: [0.4064501219858705, 0.6528498533260317, 0.18494055641112114, 0.23540203891119593], Action prob: [0.6947093 0.3052907], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -1500\n",
      "Sensor: [0.3413819110269439, 0.6446835996814769, 0.19610182551417726, 0.23546183569590998], Action prob: [0.69338983 0.3066102 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3392484600739404, 0.651610861140458, 0.20866439583479948, 0.23690624307622687], Action prob: [0.6930206 0.3069794], Action: 0, state: 0\n",
      "Sensor: [0.3944376273534852, 0.623734447057497, 0.23699973451068443, 0.24108063403285118], Action prob: [0.6926655 0.3073345], Action: 0, state: 0\n",
      "Sensor: [0.38230447758480246, 0.6439146517182787, 0.1726505754369718, 0.24661592846184824], Action prob: [0.69281536 0.30718464], Action: 0, state: 0\n",
      "Sensor: [0.3352910291591715, 0.6645910312040276, 0.21622683994732542, 0.2223365620138826], Action prob: [0.6928573  0.30714267], Action: 0, state: 0\n",
      "Sensor: [0.30627215566014165, 0.6541693960607816, 0.25580353384665916, 0.2689236824946459], Action prob: [0.6927324 0.3072677], Action: 0, state: 1\n",
      "Sensor: [0.4068128156689237, 0.6606676204499651, 0.1947437768667215, 0.2680011202432453], Action prob: [0.6930692 0.3069308], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.34587250908973644, 0.6160209948889648, 0.20666852907853164, 0.3048976503678111], Action prob: [0.69264907 0.30735093], Action: 0, state: 1\n",
      "Sensor: [0.3313502061019093, 0.6167337795323763, 0.21089199184828328, 0.22928842634474997], Action prob: [0.69243294 0.30756697], Action: 0, state: 1\n",
      "Sensor: [0.37111471686352415, 0.6344026757219852, 0.26099489357601047, 0.23484227762490006], Action prob: [0.6924836 0.3075164], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.28879074136558713, 0.6029963088895556, 0.21735457758201532, 0.2610637921390681], Action prob: [0.69219846 0.3078015 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.37563436474030776, 0.5879548053959568, 0.2347628512474689, 0.2316228874911061], Action prob: [0.6921024  0.30789763], Action: 0, state: 0\n",
      "Sensor: [0.3642493756195109, 0.6532220662709763, 0.18406344871698296, 0.2530730941577691], Action prob: [0.6927524  0.30724758], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.40681859331144093, 0.6526704647710592, 0.2293860936314868, 0.21032992364280206], Action prob: [0.6928375  0.30716255], Action: 0, state: 0\n",
      "Sensor: [0.35120891075937183, 0.6689913749613929, 0.21248573450012764, 0.20008591754401883], Action prob: [0.6928803  0.30711973], Action: 0, state: 1\n",
      "Sensor: [0.3755614700830879, 0.652262099641752, 0.23303525950757578, 0.28659613762077685], Action prob: [0.69287246 0.30712757], Action: 0, state: 1\n",
      "tensor([-0.6578, -0.4220, -0.7551, -1.6972, -0.5265, -0.3688, -0.2258, -0.0979,\n",
      "         0.0060,  0.2878,  0.1271,  0.2029,  0.8690,  0.9791,  0.3364,  1.2567,\n",
      "         0.4153,  0.4554,  0.4919], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 80 is 12400, loss is -0.035599900525839674\n",
      "Sensor: [0.32995065903381937, 0.6473609189486054, 0.23211595170386318, 0.2153887696600349], Action prob: [0.69541436 0.30458564], Action: 0, state: 0\n",
      "Sensor: [0.33701504346188793, 0.6240878645554047, 0.2110556825515949, 0.24052097295409458], Action prob: [0.6946107  0.30538926], Action: 0, state: 1\n",
      "Sensor: [0.30770726034962226, 0.664216870222353, 0.21018652050321227, 0.24005461803258354], Action prob: [0.69233555 0.30766448], Action: 0, state: 1\n",
      "Sensor: [0.35217607853668637, 0.6492178350784686, 0.25639041520601913, 0.2604826321919024], Action prob: [0.69121903 0.30878097], Action: 0, state: 1\n",
      "Sensor: [0.33563617526934114, 0.4757545134700882, 0.22697279137703338, 0.26397025800046864], Action prob: [0.6893346 0.3106655], Action: 0, state: 2\n",
      "Sensor: [0.32995964528026217, 0.6814325426533583, 0.19913532791334018, 0.2555289173354089], Action prob: [0.69065857 0.30934137], Action: 0, state: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.40163077112342116, 0.6220437613825229, 0.22898942563925642, 0.24488248013674735], Action prob: [0.69057465 0.3094253 ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.3460909338377579, 0.6807337696006789, 0.17964253550414955, 0.26650334290224326], Action prob: [0.6910536  0.30894637], Action: 0, state: 1\n",
      "Sensor: [0.36545670438655636, 0.6773504848331453, 0.2508990557130242, 0.21771244150069968], Action prob: [0.69097817 0.30902186], Action: 0, state: 1\n",
      "Sensor: [0.362950211777546, 0.6879645127915561, 0.2182597831784266, 0.24761992223873572], Action prob: [0.6911187  0.30888134], Action: 0, state: 1\n",
      "Sensor: [0.39550149876182106, 0.6224346409998087, 0.2007484734072881, 0.258313372736401], Action prob: [0.6906996  0.30930042], Action: 0, state: 1\n",
      "Sensor: [0.3247303430227799, 0.6965403872488893, 0.1946658721934238, 0.26439666770035586], Action prob: [0.69114155 0.30885845], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.38765823883045825, 0.624930460933092, 0.23698458633653682, 0.2049926541916116], Action prob: [0.690613   0.30938706], Action: 0, state: 0\n",
      "Sensor: [0.4059960919930395, 0.6304901632543313, 0.21855975120758644, 0.2458497171675546], Action prob: [0.6905527  0.30944726], Action: 0, state: 1\n",
      "Sensor: [0.37499116583116954, 0.6509545034759245, 0.22764910521006232, 0.2578845871773655], Action prob: [0.6906473  0.30935264], Action: 0, state: 1\n",
      "Sensor: [0.36898224638389504, 0.6107450157830457, 0.22719626880625873, 0.27321368412843106], Action prob: [0.69035774 0.30964226], Action: 0, state: 2\n",
      "Sensor: [0.3677529057310015, 0.5961401029711694, 0.21356011707768574, 0.22991469605925383], Action prob: [0.69014096 0.309859  ], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "Sensor: [0.38195117812862656, 0.6718916057067487, 0.23565238095556146, 0.24302039405438242], Action prob: [0.6907271  0.30927286], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.2910876422269781, 0.6351565336582952, 0.19031854792815245, 0.2833862989504487], Action prob: [0.6906378  0.30936214], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.34773674652301717, 0.5923991033438961, 0.19687533900929102, 0.2520639023544941], Action prob: [0.6903525  0.30964747], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.8432, -0.6776, -0.5314, -0.3960, -0.2870, -0.1866, -0.3077, -0.0566,\n",
      "         0.0244,  0.0979,  0.1645,  0.7103,  0.2236,  0.2721,  0.3153,  0.3505,\n",
      "         1.2072,  1.1412,  1.0924,  1.1367], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 81 is 12400, loss is -0.1724960628992293\n",
      "Sensor: [0.3623748674224224, 0.5753097029561832, 0.239033263748467, 0.2475696481494309], Action prob: [0.69991326 0.30008677], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3842435313165896, 0.6079937289111714, 0.21694455332272794, 0.2547592841491417], Action prob: [0.7008173 0.2991827], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.30128891403330205, 0.6130323456574802, 0.20610808508039727, 0.28647847874284627], Action prob: [0.6988628  0.30113724], Action: 0, state: 0\n",
      "Sensor: [0.34764490163879735, 0.6709443991097477, 0.2355565627254471, 0.24677140661718613], Action prob: [0.6985858 0.3014142], Action: 0, state: 0\n",
      "Sensor: [0.2949994051274052, 0.6364007286955303, 0.2660955308840667, 0.24094423825564223], Action prob: [0.6980105  0.30198944], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.34451333184607447, 0.6605464972876832, 0.19272678369516166, 0.2647667453070729], Action prob: [0.6983716  0.30162838], Action: 1, state: 0\n",
      "Sensor: [0.6237093037481859, 0.6050785790225596, 0.20781574245352102, 0.2185528559557581], Action prob: [0.69825643 0.30174354], Action: 0, state: 9\n",
      "Sensor: [0.5523487076667492, 0.6566125770530604, 0.2586139393657718, 0.22514180203044742], Action prob: [0.69817555 0.30182442], Action: 0, state: 9\n",
      "Sensor: [0.6419022137252018, 0.6235560644810637, 0.25485369929665685, 0.2527244153985321], Action prob: [0.6979467 0.3020532], Action: 0, state: 9\n",
      "Sensor: [0.394774272449308, 0.6343577887140919, 0.48017094951892236, 0.17564150049311497], Action prob: [0.6968699  0.30313003], Action: 0, state: 9\n",
      "Sensor: [0.3434964547081392, 0.6266854160981038, 0.5105547412793803, 0.23206937510525558], Action prob: [0.69643325 0.3035668 ], Action: 0, state: 9\n",
      "Sensor: [0.3444405117422709, 0.6720596784646858, 0.19251389154662502, 0.5750980087597565], Action prob: [0.69812614 0.30187386], Action: 0, state: 9\n",
      "Sensor: [0.3596166079842938, 0.3516829793468488, 0.19225722242355894, 0.5325149799965526], Action prob: [0.6960753  0.30392477], Action: 1, state: 9\n",
      "Sensor: [0.6696896113599364, 0.5865052110163144, 0.5132438515758376, 0.18609548155886474], Action prob: [0.6966123  0.30338773], Action: 0, state: 9\n",
      "Sensor: [0.396766435485135, 0.6233574656148421, 0.22860711189652436, 0.5853852210183026], Action prob: [0.6976746  0.30232546], Action: 0, state: 9\n",
      "Sensor: [0.4095224727031545, 0.39374669295080955, 0.27330456142493476, 0.22143372219888777], Action prob: [0.6955495  0.30445045], Action: 0, state: 9\n",
      "Sensor: [0.33567597610053773, 0.6093018155588326, 0.4969462193226619, 0.19530419613645442], Action prob: [0.6960549 0.3039451], Action: 0, state: 9\n",
      "Sensor: [0.3462253527729767, 0.325538716639901, 0.255724766255075, 0.25073506258079586], Action prob: [0.69441396 0.30558607], Action: 1, state: 9\n",
      "Sensor: [0.5508614106455503, 0.6761416688473546, 0.18372570189542925, 0.23075579831007414], Action prob: [0.69769245 0.3023076 ], Action: 0, state: 9\n",
      "Sensor: [0.6258736366954675, 0.6546177725346126, 0.20120774471930233, 0.29316436903005394], Action prob: [0.69852537 0.30147466], Action: 0, state: 9\n",
      "Sensor: [0.5566644332438684, 0.6380309878635136, 0.22160054873935087, 0.20947513929948613], Action prob: [0.6981976  0.30180237], Action: 1, state: 9\n",
      "Sensor: [0.34407264074867605, 0.6251303649030368, 0.19188830772493504, 0.2742631399292757], Action prob: [0.69785655 0.30214354], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.29669463670363777, 0.616096220074175, 0.22393265225216166, 0.5050707325860548], Action prob: [0.6980126  0.30198744], Action: 0, state: 0\n",
      "Sensor: [0.2998749253336248, 0.7000779992510597, 0.21885276054155817, 0.4051445239210849], Action prob: [0.6988265  0.30117345], Action: 0, state: 0\n",
      "tensor([ 0.4576,  0.8350,  0.3486,  0.5296,  2.2575,  2.0158,  0.4718,  0.3525,\n",
      "         0.2458,  0.1485,  0.0615, -0.0145, -0.2780, -0.1516, -0.2054, -0.2595,\n",
      "        -0.3074, -1.1350, -0.3830, -0.4151, -1.4879, -1.3944, -0.4060, -0.3833],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 82 is -9100, loss is -0.037630808695678274\n",
      "Sensor: [0.26452467012174535, 0.5313944390226388, 0.16725260118466906, 0.5880091851144312], Action prob: [0.70576996 0.29423004], Action: 0, state: 0\n",
      "Sensor: [0.3063878328690703, 0.6170532331684866, 0.2513107088076225, 0.2560576038925186], Action prob: [0.7085303 0.2914697], Action: 0, state: 1\n",
      "Sensor: [0.372476178840725, 0.6878571140777345, 0.2102092663452383, 0.27057477460314083], Action prob: [0.7078844  0.29211566], Action: 0, state: 1\n",
      "Sensor: [0.37827820860387595, 0.6758099160173003, 0.22504584309317766, 0.257288108017519], Action prob: [0.7073343  0.29266575], Action: 0, state: 2\n",
      "Sensor: [0.28546426013361614, 0.6266059716498659, 0.20922930388936078, 0.24318798200987038], Action prob: [0.7065882  0.29341182], Action: 0, state: 2\n",
      "Sensor: [0.36963432159793835, 0.6441899415581951, 0.2037359292063398, 0.23969713672200524], Action prob: [0.7067083  0.29329163], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.4280068104484351, 0.6159606360023876, 0.2225148914681283, 0.22627678193105516], Action prob: [0.7064329  0.29356712], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.42012286894914186, 0.6432794362227332, 0.26450378943755515, 0.20447027706786639], Action prob: [0.70636284 0.29363716], Action: 1, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3348104112156976, 0.6479985279312582, 0.252115377442242, 0.325319261311641], Action prob: [0.7064785  0.29352158], Action: 0, state: 0\n",
      "Sensor: [0.34018044681259973, 0.6555189363792914, 0.2317551198965629, 0.22044540820652742], Action prob: [0.7066111  0.29338887], Action: 0, state: 1\n",
      "Sensor: [0.288887083903732, 0.6876595903659858, 0.24365649939605907, 0.2520282493372438], Action prob: [0.70690596 0.293094  ], Action: 0, state: 1\n",
      "Sensor: [0.3639292123865444, 0.6391441126522237, 0.21950697308842268, 0.2457940541534482], Action prob: [0.7067455  0.29325458], Action: 0, state: 2\n",
      "Sensor: [0.3165953502345007, 0.6106046661556235, 0.5164962071008737, 0.282343625532841], Action prob: [0.7055247  0.29447535], Action: 0, state: 2\n",
      "Sensor: [0.3562116214551747, 0.6063667161887163, 0.17856068403294792, 0.20745878819407254], Action prob: [0.70597416 0.29402584], Action: 0, state: 2\n",
      "Sensor: [0.430476997800012, 0.641360402065957, 0.2543410958907646, 0.25455037188014074], Action prob: [0.7063728  0.29362714], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -700\n",
      "Sensor: [0.326428093057011, 0.6434150864474946, 0.26423433701916565, 0.22329349827067005], Action prob: [0.7063176  0.29368237], Action: 0, state: 2\n",
      "Sensor: [0.35579485283594514, 0.5901611174581679, 0.2366394074682882, 0.23275061671644945], Action prob: [0.7059749  0.29402515], Action: 0, state: 3\n",
      "Sensor: [0.5259317518009345, 0.6794572057509269, 0.19345085109069923, 0.2321295226302305], Action prob: [0.7069934  0.29300657], Action: 0, state: 3\n",
      "Sensor: [0.5264776158806711, 0.6176382293649864, 0.24683051112662197, 0.22587651018670604], Action prob: [0.70642465 0.29357535], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.3011930802904294, 0.659165709457138, 0.1958879906815083, 0.26477152862711995], Action prob: [0.7065265  0.29347345], Action: 0, state: 2\n",
      "Sensor: [0.36658284593653184, 0.5904389818925839, 0.20076460011664873, 0.24439395606135741], Action prob: [0.7061724 0.2938276], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1100\n",
      "tensor([-0.8762, -0.6690, -0.4911, -0.3483, -0.2191, -0.5156, -0.3760, -0.2100,\n",
      "        -0.0591,  0.0270,  0.1046,  0.1671,  0.2228,  0.2744,  1.0645,  0.2661,\n",
      "         0.2899,  0.3092,  1.1583,  0.3386,  1.2792], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 83 is 10100, loss is -0.08273242418145493\n",
      "Sensor: [0.38753654032085527, 0.670190492682773, 0.20807162537772908, 0.25850249599701297], Action prob: [0.71638256 0.28361735], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3609126791089711, 0.3071392914109701, 0.20807535390532236, 0.2526825191790685], Action prob: [0.7166325  0.28336757], Action: 0, state: 0\n",
      "Sensor: [0.3241133450329666, 0.6049344593376434, 0.22879783591900837, 0.2634395504285475], Action prob: [0.717367   0.28263298], Action: 0, state: 1\n",
      "Sensor: [0.36833020247311943, 0.6790928566730206, 0.2427194754375842, 0.22614165876273576], Action prob: [0.7181926 0.2818074], Action: 0, state: 2\n",
      "Sensor: [0.40216622579776684, 0.5940033301833757, 0.19232478061873162, 0.2731042090163821], Action prob: [0.7178607 0.2821393], Action: 0, state: 3\n",
      "Sensor: [0.33398944646324547, 0.62897921495026, 0.21543214738304034, 0.2302121378287451], Action prob: [0.71784467 0.2821553 ], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -2700\n",
      "Sensor: [0.35220293726155555, 0.6362746061247055, 0.19238228877863833, 0.2495769706642045], Action prob: [0.71808785 0.2819122 ], Action: 0, state: 2\n",
      "Sensor: [0.6093174501789831, 0.650283257763538, 0.17371712098670408, 0.2920933689984561], Action prob: [0.7187093  0.28129077], Action: 0, state: 3\n",
      "Sensor: [0.5909291243588668, 0.6344268415777689, 0.2252162747062193, 0.2589432688529225], Action prob: [0.71832174 0.28167826], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.4153164329095507, 0.5855231220391237, 0.23107808322379775, 0.23148230651440901], Action prob: [0.71740866 0.28259128], Action: 0, state: 2\n",
      "Sensor: [0.37182350541158005, 0.6285598459156984, 0.20601416418070903, 0.15639266204254235], Action prob: [0.717561   0.28243902], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.3822295649978197, 0.5907930365451071, 0.2429176698811668, 0.2410960551263435], Action prob: [0.71739113 0.2826089 ], Action: 0, state: 2\n",
      "Sensor: [0.3313598309647817, 0.638018723702835, 0.17676349790001947, 0.24351415305042445], Action prob: [0.71797013 0.2820299 ], Action: 0, state: 2\n",
      "Sensor: [0.35024086378221414, 0.6238308778275637, 0.2286438185548659, 0.21618121319437672], Action prob: [0.71789557 0.28210452], Action: 0, state: 2\n",
      "Sensor: [0.33794562673614387, 0.634493990892029, 0.23906049639849974, 0.24115911581567145], Action prob: [0.71794796 0.28205204], Action: 0, state: 3\n",
      "Sensor: [0.37007794981864994, 0.6386610349968763, 0.21392795352475394, 0.25758435800366447], Action prob: [0.7181437  0.28185633], Action: 0, state: 3\n",
      "Sensor: [0.6111203054440354, 0.6316115781756828, 0.2233016874312705, 0.27068709629773907], Action prob: [0.7183731  0.28162694], Action: 0, state: 8\n",
      "Sensor: [0.39607281867682537, 0.6453652978208506, 0.5675396181943836, 0.25318663127447705], Action prob: [0.71708477 0.28291526], Action: 0, state: 8\n",
      "Sensor: [0.3626194804447244, 0.3008826667522971, 0.23009637032952088, 0.21537725432815072], Action prob: [0.7141787 0.2858213], Action: 1, state: 8\n",
      "tensor([-2.3926, -0.6315, -0.2243,  0.1000,  0.2833,  1.7068, -0.3505, -0.2168,\n",
      "        -0.3753, -0.0336,  0.2411,  0.1160,  0.2415,  0.3544,  0.4179,  0.4749,\n",
      "         0.1659, -0.1142, -1.3662], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 84 is -7300, loss is 0.08437649767717091\n",
      "Sensor: [0.41978061672408123, 0.6411601610453871, 0.21117945351046263, 0.4016293880411321], Action prob: [0.7211287  0.27887133], Action: 0, state: 0\n",
      "Sensor: [0.3274116273915827, 0.6856553184791606, 0.20048548054657983, 0.2785828964493224], Action prob: [0.7259456  0.27405438], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3551911916669631, 0.6339384973461581, 0.2299256225858828, 0.22783653909805304], Action prob: [0.7246365 0.2753635], Action: 0, state: 0\n",
      "Sensor: [0.349052940275057, 0.6219414544624647, 0.2346110953841227, 0.289951662068997], Action prob: [0.7240193 0.2759807], Action: 0, state: 0\n",
      "Sensor: [0.3479107498327927, 0.6095436897950084, 0.201534433415053, 0.23602683891086937], Action prob: [0.72379804 0.276202  ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -3500\n",
      "Maintenance in progress, cumulative -2500\n",
      "Sensor: [0.41366432054141217, 0.6326472897006878, 0.205239797814618, 0.2594875877817354], Action prob: [0.7240872  0.27591282], Action: 0, state: 0\n",
      "Sensor: [0.3133106225683891, 0.6837599201865765, 0.24052292076364648, 0.24101723704438613], Action prob: [0.7243773  0.27562276], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.368305552545887, 0.6126241125237334, 0.2267057831771367, 0.21649467817373946], Action prob: [0.7239022  0.27609777], Action: 0, state: 0\n",
      "Sensor: [0.3399558254020528, 0.6797766997456363, 0.1968127965598254, 0.22109668425569962], Action prob: [0.72442645 0.27557358], Action: 0, state: 0\n",
      "Sensor: [0.38366552016013655, 0.6204173393972432, 0.46970716372323584, 0.25279543042237895], Action prob: [0.7233236 0.2766764], Action: 0, state: 9\n",
      "Sensor: [0.3589110483735567, 0.6176360510385167, 0.22583182991214523, 0.6080795668235168], Action prob: [0.724301   0.27569902], Action: 0, state: 9\n",
      "Sensor: [0.6155627598877706, 0.40096114595118576, 0.18894609621995367, 0.20773654165489744], Action prob: [0.7223253  0.27767473], Action: 1, state: 9\n",
      "Sensor: [0.35959561790469813, 0.37696478773292186, 0.24649956708549628, 0.23987363284757832], Action prob: [0.720687   0.27931306], Action: 0, state: 9\n",
      "Sensor: [0.3310976312839133, 0.6585066280799515, 0.46020328218052714, 0.2642125963727201], Action prob: [0.7226459  0.27735406], Action: 0, state: 9\n",
      "Sensor: [0.35069225461806336, 0.6419934465797466, 0.19898295387862405, 0.5870252481398128], Action prob: [0.72449696 0.27550307], Action: 0, state: 9\n",
      "Sensor: [0.30419473860038126, 0.43845393572198677, 0.20926579536303563, 0.22244125321227332], Action prob: [0.7223982  0.27760178], Action: 0, state: 9\n",
      "Sensor: [0.3884655923463095, 0.40007885321596137, 0.25490134108516105, 0.24996545421630814], Action prob: [0.72131103 0.27868894], Action: 0, state: 9\n",
      "Sensor: [0.5701411412003552, 0.6357095786290322, 0.1979956367795644, 0.24480417623634504], Action prob: [0.72369486 0.2763051 ], Action: 0, state: 9\n",
      "Sensor: [0.5633036849594526, 0.6290272203092606, 0.17541144365075287, 0.2835487585952519], Action prob: [0.7242602 0.2757398], Action: 0, state: 9\n",
      "Sensor: [0.39772490063273724, 0.4243847981160579, 0.21485002982836987, 0.25967443445439164], Action prob: [0.7220087  0.27799135], Action: 0, state: 9\n",
      "tensor([-0.3455, -0.0745,  0.1263,  0.3886,  2.4869,  0.0942,  1.1357,  0.2849,\n",
      "         0.4385,  0.3000,  0.1761,  0.2509, -0.0388, -0.1322, -0.2107, -0.2876,\n",
      "        -0.3563, -0.4131, -0.4657, -0.5187], dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 85 is -9000, loss is -0.14195848258573768\n",
      "Sensor: [0.34374133668637824, 0.6095836386101614, 0.20211720269794686, 0.2816986393127391], Action prob: [0.7306391  0.26936093], Action: 0, state: 0\n",
      "Sensor: [0.37011936227919423, 0.6664935937724271, 0.20030898667761463, 0.24136469031141772], Action prob: [0.7380219  0.26197806], Action: 0, state: 1\n",
      "Sensor: [0.358485217248969, 0.6571019104155378, 0.1956232555232163, 0.24399338218803557], Action prob: [0.7382282  0.26177177], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.37291005402799793, 0.6412735654692063, 0.23061003190567675, 0.2758459004418702], Action prob: [0.73799133 0.2620087 ], Action: 0, state: 0\n",
      "Sensor: [0.3579919527814849, 0.6520740535958441, 0.2519475364256423, 0.3251440653557961], Action prob: [0.7381758 0.2618242], Action: 0, state: 1\n",
      "Sensor: [0.3702935851385793, 0.6615551614522823, 0.22542582403288702, 0.22622347858588487], Action prob: [0.7383151  0.26168483], Action: 0, state: 1\n",
      "Sensor: [0.3869446830094836, 0.6502528676599276, 0.2173941953403294, 0.2462886437314626], Action prob: [0.73830384 0.26169622], Action: 0, state: 1\n",
      "Sensor: [0.3257700435603693, 0.619092009370574, 0.42470781938689034, 0.27440169813624726], Action prob: [0.7373116 0.2626884], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.38363490071294604, 0.6414974443634183, 0.25649468876727466, 0.3080229457294201], Action prob: [0.738008 0.261992], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.35406832784294234, 0.6584706816631016, 0.21743959111774433, 0.5490358862546623], Action prob: [0.7388948  0.26110512], Action: 0, state: 0\n",
      "Sensor: [0.3836413927549529, 0.6506004302083912, 0.2017558446378992, 0.2892073067822663], Action prob: [0.7388493 0.2611507], Action: 0, state: 1\n",
      "Sensor: [0.4078504408170321, 0.6217151954067515, 0.2377793315955612, 0.26147650073056367], Action prob: [0.73828363 0.26171637], Action: 0, state: 1\n",
      "Sensor: [0.3015537737873494, 0.6355868685483296, 0.18525958855782784, 0.21914912287157773], Action prob: [0.7381317 0.2618683], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.2819765900908585, 0.6171918601806038, 0.19127333146085435, 0.2694843273455961], Action prob: [0.7380117  0.26198825], Action: 0, state: 0\n",
      "Sensor: [0.3547962397699934, 0.6528454344726412, 0.1874442473644774, 0.5020176684487031], Action prob: [0.73895067 0.26104936], Action: 0, state: 1\n",
      "Sensor: [0.35094180603246355, 0.6730977435625818, 0.17237098163895082, 0.23840410304014611], Action prob: [0.73903245 0.26096755], Action: 0, state: 2\n",
      "Sensor: [0.342026024625481, 0.692722946865419, 0.17952201963101372, 0.24886703179123706], Action prob: [0.7390785  0.26092142], Action: 0, state: 2\n",
      "Sensor: [0.32081788474454154, 0.6386709110552569, 0.2522795024233604, 0.24180344219652994], Action prob: [0.7382935  0.26170638], Action: 0, state: 2\n",
      "Sensor: [0.3905337854630906, 0.6191423283232138, 0.24195383367034304, 0.2732758258546617], Action prob: [0.7380613  0.26193866], Action: 0, state: 2\n",
      "Sensor: [0.2895704241206942, 0.6631019708740151, 0.2199442955054821, 0.2301557368983909], Action prob: [0.7382332  0.26176682], Action: 0, state: 2\n",
      "Sensor: [0.41855467928124307, 0.6493845892774378, 0.16766397987719156, 0.23514149637438264], Action prob: [0.7385441  0.26145586], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "Sensor: [0.3545754200683328, 0.6352058336009171, 0.227285031828508, 0.25713294892314037], Action prob: [0.7381954  0.26180452], Action: 0, state: 1\n",
      "tensor([-0.7440, -0.5778, -1.9831, -0.3854, -0.2812, -0.1878, -0.1036, -0.1268,\n",
      "         0.0437,  0.0108,  0.0651,  0.1147,  0.7043,  0.1599,  0.1960,  0.2239,\n",
      "         0.2498,  0.2739,  0.2955,  0.3141,  1.4654,  0.3295],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 86 is 15600, loss is -0.0025780097155086294\n",
      "Sensor: [0.3238838686625094, 0.41212963641508366, 0.20170943398571842, 0.28313086848279756], Action prob: [0.7376973 0.2623028], Action: 0, state: 0\n",
      "Sensor: [0.44532527754361484, 0.6685881768626702, 0.24136865715643832, 0.2362383050275719], Action prob: [0.7486179  0.25138214], Action: 0, state: 1\n",
      "Sensor: [0.3391704695019689, 0.6103015098744785, 0.20996850126095143, 0.2960370823690088], Action prob: [0.7494916  0.25050843], Action: 0, state: 1\n",
      "Sensor: [0.3181546371072387, 0.6415087468097177, 0.18197820063202153, 0.22227682829531423], Action prob: [0.7499254  0.25007468], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.35824321847369367, 0.664770143433904, 0.24047973265220496, 0.22519421735418022], Action prob: [0.7503273  0.24967268], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.42482858827842285, 0.6483221680280089, 0.21998302620044533, 0.2684934643158095], Action prob: [0.75061166 0.24938834], Action: 0, state: 0\n",
      "Sensor: [0.33743452360592124, 0.6658765716493622, 0.18592880567363781, 0.24697077622622693], Action prob: [0.7507998  0.24920015], Action: 0, state: 1\n",
      "Sensor: [0.39509197908003824, 0.602977503664533, 0.23781906609141204, 0.24230276914160845], Action prob: [0.7501935  0.24980652], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.3886440912907695, 0.6849606672674612, 0.20564376087616054, 0.2718802397363837], Action prob: [0.7509675  0.24903254], Action: 0, state: 1\n",
      "Sensor: [0.365565447870539, 0.7023899389528288, 0.2636703587298546, 0.25394608192253215], Action prob: [0.7511276  0.24887241], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.35436469518218383, 0.6045443902583485, 0.23366550733897953, 0.240008402094835], Action prob: [0.750284   0.24971603], Action: 0, state: 0\n",
      "Sensor: [0.2986701173285964, 0.6521056129380125, 0.22929473235856596, 0.26758497327995395], Action prob: [0.75046736 0.2495326 ], Action: 0, state: 0\n",
      "Sensor: [0.4068878283372939, 0.6787273834321802, 0.23690055116318043, 0.26846639838704695], Action prob: [0.7509985 0.2490015], Action: 0, state: 0\n",
      "Sensor: [0.3354975266708158, 0.6406742880211669, 0.25217785799454584, 0.25667878711482806], Action prob: [0.7505526  0.24944742], Action: 0, state: 1\n",
      "Sensor: [0.3676015154571515, 0.676568444951378, 0.2039702549466657, 0.29597549492283076], Action prob: [0.7510667  0.24893336], Action: 0, state: 1\n",
      "Sensor: [0.40527211384183, 0.599603233699158, 0.23730867068570713, 0.27780379960571666], Action prob: [0.75039566 0.24960428], Action: 0, state: 2\n",
      "Sensor: [0.24949452931884353, 0.6409993207223516, 0.18343561628075938, 0.27540062938891124], Action prob: [0.7504964  0.24950363], Action: 0, state: 2\n",
      "Sensor: [0.4137328789373843, 0.5821823955196878, 0.22530281226246582, 0.2992414066119926], Action prob: [0.75021803 0.24978192], Action: 0, state: 2\n",
      "Sensor: [0.33446035212213354, 0.35964592966398495, 0.22228689382956984, 0.2684156002377907], Action prob: [0.7476274  0.25237262], Action: 0, state: 3\n",
      "Sensor: [0.3813967452932664, 0.6007250333059817, 0.2164120681250924, 0.5430439675728114], Action prob: [0.75004524 0.24995473], Action: 0, state: 3\n",
      "Sensor: [0.3384973609876398, 0.673610961423676, 0.2305408414526449, 0.5861113882134196], Action prob: [0.75161356 0.24838643], Action: 1, state: 8\n",
      "Sensor: [0.6217661735100077, 0.6151137473450825, 0.21068755673356915, 0.26020746192653854], Action prob: [0.75135714 0.24864285], Action: 0, state: 8\n",
      "Sensor: [0.39347143466846646, 0.6166247411461383, 0.5548020112024894, 0.24012282556932962], Action prob: [0.74938524 0.25061473], Action: 1, state: 8\n",
      "tensor([-0.7792, -0.5850, -0.4409, -1.5090, -1.2064, -0.1922, -0.0999, -0.1269,\n",
      "         0.0070,  0.3578,  0.0070,  0.0675,  0.1216,  0.1659,  0.2054,  0.2378,\n",
      "         0.2664,  0.2926,  0.3114,  0.3212,  1.2132,  0.1852,  0.6135],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 87 is 900, loss is 0.024607774280720782\n",
      "Sensor: [0.37189866774122365, 0.6036323017944297, 0.19966498296806334, 0.2784952094896466], Action prob: [0.7479431  0.25205696], Action: 0, state: 0\n",
      "Sensor: [0.3885128560195858, 0.6643410175668912, 0.25303754960435004, 0.24611604547223837], Action prob: [0.7576209  0.24237913], Action: 0, state: 1\n",
      "Sensor: [0.3400231860628402, 0.6030267962824795, 0.21596832634657498, 0.2616152985546355], Action prob: [0.75810957 0.24189043], Action: 0, state: 1\n",
      "Sensor: [0.31676412656442665, 0.6602784973608746, 0.2107587431819113, 0.22427680736450473], Action prob: [0.7586998  0.24130026], Action: 0, state: 1\n",
      "Sensor: [0.3624453514516559, 0.6816891193667171, 0.17746499413951566, 0.21855938189515467], Action prob: [0.75943464 0.24056537], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.410532042181831, 0.6414065347404447, 0.21628439432407656, 0.28630739313637316], Action prob: [0.7594323  0.24056767], Action: 0, state: 1\n",
      "Sensor: [0.3958474511004223, 0.6864349740612912, 0.22255242470131997, 0.23560224129695306], Action prob: [0.7597532  0.24024677], Action: 0, state: 1\n",
      "Sensor: [0.3689592824369012, 0.6800813900506847, 0.16427308325833537, 0.20851323385100928], Action prob: [0.7598567  0.24014331], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.36199873893817086, 0.6394089216696676, 0.19604004865473512, 0.25272385744390985], Action prob: [0.759463  0.2405369], Action: 0, state: 0\n",
      "Sensor: [0.3281720276199946, 0.6679256177203372, 0.19981926652871282, 0.23192402531128498], Action prob: [0.7595581 0.2404419], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.4314463272696437, 0.6203907054501665, 0.2508379717878649, 0.29144321662679157], Action prob: [0.7593063  0.24069367], Action: 0, state: 0\n",
      "Sensor: [0.3670666270879587, 0.6002262332029272, 0.1795660359030552, 0.24874414223598976], Action prob: [0.7590374  0.24096256], Action: 0, state: 0\n",
      "Sensor: [0.3223212455465114, 0.6352571011109888, 0.23847530468645933, 0.3261186694020172], Action prob: [0.7592138 0.2407862], Action: 0, state: 1\n",
      "Sensor: [0.3889600619721591, 0.6297977591278131, 0.2079887729664292, 0.2816516378274242], Action prob: [0.7594322  0.24056782], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.33471494276846825, 0.6219072514331255, 0.21580810042792056, 0.31743518160167944], Action prob: [0.7593224  0.24067764], Action: 0, state: 0\n",
      "Sensor: [0.34365135485496906, 0.6424140842685603, 0.20577099069051294, 0.28301878443590694], Action prob: [0.75949854 0.24050148], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.43202972433895453, 0.6711979888314861, 0.19694956401625646, 0.2615106912119463], Action prob: [0.75994825 0.24005178], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3555411089658171, 0.5977123368765864, 0.22859542221884824, 0.3217337319692538], Action prob: [0.7592013  0.24079874], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3588540402492856, 0.5815930103415351, 0.27369828756789133, 0.2758445797542874], Action prob: [0.7586362  0.24136382], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.4054041025184589, 0.6252434775492774, 0.19966646258739768, 0.2677450015310554], Action prob: [0.7591991  0.24080089], Action: 0, state: 0\n",
      "Sensor: [0.39403727843418546, 0.7048990355772334, 0.22279830050384128, 0.24430337733621413], Action prob: [0.75994503 0.24005492], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "tensor([-0.6674, -0.5149, -0.4026, -0.3022, -1.1486, -0.1860, -0.1139, -0.2534,\n",
      "        -0.0163,  0.2180,  0.0686,  0.1164,  0.1546,  0.9785,  0.2065,  0.2373,\n",
      "         1.3752,  1.4387,  1.4347,  0.2885,  1.5872], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 88 is 14500, loss is -0.21422699628053582\n",
      "Sensor: [0.2907670671048652, 0.6617249983445164, 0.21600969370183132, 0.26128132048768554], Action prob: [0.76408416 0.23591585], Action: 0, state: 0\n",
      "Sensor: [0.3779879378487351, 0.6680494983100271, 0.24721619113329388, 0.2719311782939899], Action prob: [0.7762135  0.22378641], Action: 0, state: 1\n",
      "Sensor: [0.3801334440642763, 0.6080937422692807, 0.20068157979596823, 0.2726565144507379], Action prob: [0.777851   0.22214898], Action: 0, state: 1\n",
      "Sensor: [0.33935294809666083, 0.7026104665360355, 0.20201678216189822, 0.2257304422380646], Action prob: [0.7791306  0.22086944], Action: 0, state: 1\n",
      "Sensor: [0.32979556763977524, 0.6107440729068491, 0.20236743064271395, 0.21465411214747013], Action prob: [0.778732   0.22126797], Action: 0, state: 1\n",
      "Sensor: [0.34627126311642437, 0.6178595779242345, 0.23508285023587547, 0.2577235188100463], Action prob: [0.7788529 0.2211471], Action: 0, state: 2\n",
      "Sensor: [0.39598865021373336, 0.6125519436711674, 0.21593939688628597, 0.2433314285977346], Action prob: [0.7790818  0.22091809], Action: 0, state: 3\n",
      "Sensor: [0.37282401973900775, 0.6542662098608095, 0.505556722646364, 0.2460521576923146], Action prob: [0.7785321 0.2214679], Action: 0, state: 3\n",
      "Sensor: [0.38385623453381584, 0.6493122931667803, 0.21067640937156967, 0.5851675895162813], Action prob: [0.78043985 0.21956016], Action: 1, state: 8\n",
      "Sensor: [0.3412574701639405, 0.6612806537655711, 0.2449803241473278, 0.25569942552392333], Action prob: [0.7801221  0.21987791], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.303975872924518, 0.6730850081644524, 0.2189233381927204, 0.2571254240828395], Action prob: [0.78000134 0.21999863], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.46282373320242765, 0.6378206579060524, 0.2241952515882752, 0.2806003596900843], Action prob: [0.7799933  0.22000672], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.36921936181760595, 0.6440419807614725, 0.1917677906933358, 0.2442214292162949], Action prob: [0.7797989  0.22020109], Action: 0, state: 0\n",
      "Sensor: [0.36511218011059715, 0.5904438161715975, 0.20466487661821683, 0.22008632617969726], Action prob: [0.77904046 0.22095957], Action: 0, state: 1\n",
      "Sensor: [0.3421638312689621, 0.640059247208134, 0.24163942388965245, 0.25020732573979126], Action prob: [0.77923876 0.2207613 ], Action: 0, state: 1\n",
      "Sensor: [0.3698972881613784, 0.6381845349852844, 0.21884570797855835, 0.2500802920585292], Action prob: [0.7794706  0.22052944], Action: 0, state: 1\n",
      "Sensor: [0.4111721145493432, 0.6041501592496311, 0.18962654050426933, 0.3149195582769534], Action prob: [0.7795353  0.22046475], Action: 0, state: 1\n",
      "Sensor: [0.30642955412955447, 0.6272130878456382, 0.2728676226669198, 0.21140377521628326], Action prob: [0.7789971  0.22100286], Action: 0, state: 2\n",
      "Sensor: [0.37601461826966526, 0.6453175643505564, 0.19961091585931762, 0.23641953490827364], Action prob: [0.77951175 0.22048824], Action: 0, state: 2\n",
      "Sensor: [0.3472838961963464, 0.561486692820042, 0.23123752907093578, 0.22037298328442897], Action prob: [0.77852255 0.22147743], Action: 0, state: 3\n",
      "Sensor: [0.32565150426027817, 0.4275053728672207, 0.20555300880479865, 0.23251536170028766], Action prob: [0.77682173 0.22317831], Action: 0, state: 3\n",
      "Sensor: [0.5506386954287448, 0.5908263191416337, 0.156064429985586, 0.29608887082993035], Action prob: [0.779021   0.22097898], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "Sensor: [0.3243906635950975, 0.6251750698363809, 0.21173997900912547, 0.2663213594809406], Action prob: [0.779196   0.22080399], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "tensor([-0.7723, -0.5375, -0.3633, -0.2099, -0.0736,  0.0355,  0.0969,  0.1512,\n",
      "        -0.8808, -0.3445, -0.0998, -0.0988, -0.0162,  0.0365,  0.0838,  0.1265,\n",
      "         0.1652,  0.1958,  0.2232,  0.2401,  0.2569,  1.6118,  1.5823],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 89 is 10800, loss is -0.06125882889838085\n",
      "Sensor: [0.34843573797071525, 0.6129089220153279, 0.20878314756229652, 0.2678318517710698], Action prob: [0.78114605 0.21885397], Action: 0, state: 0\n",
      "Sensor: [0.2874136870460667, 0.6655472717681531, 0.18896755901079754, 0.21884206063527828], Action prob: [0.7956256  0.20437434], Action: 0, state: 0\n",
      "Sensor: [0.3900076568462194, 0.6564063608477335, 0.20618126663946618, 0.25605134098657956], Action prob: [0.79892206 0.20107791], Action: 0, state: 0\n",
      "Sensor: [0.3530254821304423, 0.6030883482154824, 0.20974204431538848, 0.21557829139930054], Action prob: [0.7994015  0.20059851], Action: 0, state: 0\n",
      "Sensor: [0.3777493188278633, 0.6756108794320416, 0.22298107606346892, 0.23525613613370308], Action prob: [0.8006925  0.19930746], Action: 0, state: 1\n",
      "Sensor: [0.357530666706562, 0.6630739353186884, 0.23113899042370545, 0.27284790593236524], Action prob: [0.80116737 0.19883263], Action: 0, state: 1\n",
      "Sensor: [0.346285904673115, 0.6628820413439164, 0.22236645141044536, 0.26763836241704575], Action prob: [0.80139387 0.1986061 ], Action: 0, state: 1\n",
      "Sensor: [0.322391219922576, 0.5919287579657914, 0.23940399674390722, 0.23295061018017493], Action prob: [0.80050844 0.19949158], Action: 0, state: 1\n",
      "Sensor: [0.32917304426259947, 0.6201310453966493, 0.22824622872303796, 0.22342426466337206], Action prob: [0.80058265 0.19941741], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.33381017142680897, 0.58416804467613, 0.2055803202192651, 0.24975626335088164], Action prob: [0.8003863 0.1996137], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.3209496381592107, 0.6431909988115233, 0.24798768532341378, 0.2466988136422721], Action prob: [0.8007908 0.1992092], Action: 0, state: 0\n",
      "Sensor: [0.3352964043772712, 0.6265696359404211, 0.23509527771447647, 0.31473518156531843], Action prob: [0.80105996 0.19893998], Action: 0, state: 0\n",
      "Sensor: [0.49823544876340753, 0.6799742399768767, 0.238941178079778, 0.26669701990388217], Action prob: [0.80198634 0.1980136 ], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.313510856636759, 0.6298458687510047, 0.2009283334709768, 0.5313820855762847], Action prob: [0.80208015 0.19791986], Action: 0, state: 0\n",
      "Sensor: [0.33760651179604206, 0.6594785944848105, 0.23721363124369751, 0.29498547499158195], Action prob: [0.80193114 0.19806884], Action: 0, state: 0\n",
      "Sensor: [0.3425729139565851, 0.6242694945006365, 0.23165506744035838, 0.24069961568792428], Action prob: [0.80126786 0.19873208], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative 0\n",
      "Sensor: [0.32545977651284497, 0.6818119085158484, 0.1825323881436732, 0.2590999449408499], Action prob: [0.8017657  0.19823436], Action: 0, state: 0\n",
      "Sensor: [0.3335586160246017, 0.6026477335952571, 0.20146632127739483, 0.23772864185519282], Action prob: [0.80093646 0.19906352], Action: 0, state: 0\n",
      "Sensor: [0.3116130262481057, 0.674464097186041, 0.2055736607466206, 0.2110689872424846], Action prob: [0.80127776 0.19872226], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3295196121351534, 0.6447910415404269, 0.22343705742567696, 0.26598346958323865], Action prob: [0.8012115  0.19878852], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3698683477934402, 0.6400731884822998, 0.18966913228448062, 0.2542245888643138], Action prob: [0.8013516  0.19864841], Action: 0, state: 0\n",
      "Sensor: [0.3858624545324127, 0.6822366390275777, 0.25206022533099837, 0.22675266592631915], Action prob: [0.80155915 0.1984409 ], Action: 0, state: 0\n",
      "Sensor: [0.3032875243566511, 0.6827793863341977, 0.2024419505199404, 0.22756014132160957], Action prob: [0.80157995 0.19842009], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "tensor([-0.6087, -0.4578, -0.3560, -0.2712, -0.2019, -0.1407, -0.0861, -0.0372,\n",
      "         0.0508,  0.2131,  0.0291,  0.0651,  0.7084,  0.1118,  0.1370,  1.1739,\n",
      "         0.1606,  0.1805,  0.1952,  1.5257,  0.2162,  0.2280,  1.7500],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 90 is 18300, loss is -0.19937722290066184\n",
      "Sensor: [0.3469437662984647, 0.6644177153827614, 0.2020950541609411, 0.19506037628911518], Action prob: [0.8057763  0.19422375], Action: 0, state: 0\n",
      "Sensor: [0.3877967460341167, 0.6431943778676258, 0.2543732939371908, 0.26596721113715494], Action prob: [0.8241436  0.17585649], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3648241477550912, 0.6681429892474935, 0.16690558854036883, 0.23342509744938492], Action prob: [0.8291474  0.17085256], Action: 0, state: 0\n",
      "Sensor: [0.3236499617260653, 0.643802846905661, 0.20994613812276675, 0.28205247362736535], Action prob: [0.8307538  0.16924621], Action: 0, state: 0\n",
      "Sensor: [0.4085196654990329, 0.6432090597849245, 0.22837095921040412, 0.30613394942394495], Action prob: [0.8320821  0.16791789], Action: 0, state: 0\n",
      "Sensor: [0.417138919660629, 0.682449923768611, 0.22066318139490673, 0.22105762655281389], Action prob: [0.8330237  0.16697627], Action: 0, state: 0\n",
      "Sensor: [0.36550680978428735, 0.6410396215441094, 0.15833614767077142, 0.25501828876181054], Action prob: [0.8330304  0.16696957], Action: 0, state: 0\n",
      "Sensor: [0.3382717328815451, 0.6454805509713402, 0.21804518293398883, 0.23533577705754427], Action prob: [0.8327725  0.16722752], Action: 0, state: 1\n",
      "Sensor: [0.3467701391384011, 0.6524375714268118, 0.24419369362850665, 0.27011615888272855], Action prob: [0.8328795  0.16712055], Action: 0, state: 1\n",
      "Sensor: [0.3541665560068851, 0.6063881755256484, 0.20747277298943334, 0.20327036733374443], Action prob: [0.83239585 0.1676042 ], Action: 0, state: 2\n",
      "Sensor: [0.3859837088718744, 0.6218777250727802, 0.40847073350253466, 0.31085041327473006], Action prob: [0.83213884 0.16786112], Action: 0, state: 2\n",
      "Sensor: [0.3418434318700465, 0.6459525381193918, 0.22792303045970308, 0.26281925064273753], Action prob: [0.8328503  0.16714972], Action: 0, state: 2\n",
      "Sensor: [0.3804050072839453, 0.6866157004452943, 0.21381459010108947, 0.24016994145490955], Action prob: [0.8334351  0.16656485], Action: 0, state: 2\n",
      "Sensor: [0.3639315846394509, 0.5070727509601451, 0.2514640806069915, 0.29709051969952704], Action prob: [0.8316153  0.16838469], Action: 0, state: 2\n",
      "Sensor: [0.37378763769906587, 0.5661810111468137, 0.20042737914671893, 0.2738323792512114], Action prob: [0.8319171 0.1680829], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -100\n",
      "Sensor: [0.3513833581137686, 0.6407834138055484, 0.18745311155108266, 0.25522853936292933], Action prob: [0.83272046 0.16727945], Action: 0, state: 1\n",
      "Sensor: [0.3477931881750345, 0.6747275762281026, 0.18929986104622956, 0.2580013188965227], Action prob: [0.8332761  0.16672392], Action: 0, state: 1\n",
      "Sensor: [0.3601096261307013, 0.604342107864186, 0.17524458502307222, 0.24702845994908096], Action prob: [0.8327063  0.16729373], Action: 0, state: 2\n",
      "Sensor: [0.369566323657754, 0.6563069826872997, 0.24979688653041762, 0.21999765058617746], Action prob: [0.8327896  0.16721037], Action: 0, state: 3\n",
      "Sensor: [0.33938768631248767, 0.3806978876924499, 0.222496097654414, 0.24779139362480895], Action prob: [0.8298086 0.1701914], Action: 0, state: 8\n",
      "Sensor: [0.2922367768793226, 0.31494991660902094, 0.22176147165938026, 0.21575122886667894], Action prob: [0.82776636 0.1722337 ], Action: 0, state: 8\n",
      "Sensor: [0.6297757394800582, 0.6016044793737865, 0.17152784978934205, 0.2926259506696134], Action prob: [0.8321399  0.16786003], Action: 0, state: 8\n",
      "Sensor: [0.37826487962839817, 0.4646712090793669, 0.20259674677783102, 0.1937295546821149], Action prob: [0.8306252  0.16937482], Action: 0, state: 8\n",
      "Sensor: [0.566825831016067, 0.6227997090983879, 0.20312238710425715, 0.21352055024592856], Action prob: [0.8325231  0.16747689], Action: 0, state: 8\n",
      "Sensor: [0.37685366792880964, 0.45822338418122466, 0.21084510452034508, 0.280573790459092], Action prob: [0.8308781  0.16912198], Action: 0, state: 8\n",
      "tensor([-0.4937, -3.0234, -0.3718, -0.2859, -0.2102, -0.1437, -0.0844, -0.0370,\n",
      "         0.0060,  0.0406,  0.0714,  0.0994,  0.1239,  0.1485,  1.6343,  0.1653,\n",
      "         0.1831,  0.1988,  0.2066,  0.1655,  0.1259,  0.0856,  0.0530,  0.0226,\n",
      "        -0.0037], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 91 is -7800, loss is 0.052928530549554716\n",
      "Sensor: [0.36767812440312625, 0.6443201283854271, 0.39137106315390424, 0.2632414998768655], Action prob: [0.82605577 0.17394426], Action: 0, state: 0\n",
      "Sensor: [0.37431303689376605, 0.6558949351132345, 0.2262668026238127, 0.2388793954320008], Action prob: [0.8472921 0.1527079], Action: 0, state: 1\n",
      "Sensor: [0.38177629707607924, 0.5971594160184697, 0.20920981681946707, 0.27482919325731464], Action prob: [0.8527445  0.14725554], Action: 0, state: 2\n",
      "Sensor: [0.351629942024693, 0.6145283307689, 0.19540578759988092, 0.23203971150478037], Action prob: [0.8551105  0.14488944], Action: 0, state: 2\n",
      "Sensor: [0.552707761642186, 0.6859574102786367, 0.20754112797705915, 0.28605655010839476], Action prob: [0.85796493 0.14203502], Action: 0, state: 3\n",
      "Sensor: [0.3818771536658034, 0.6068813308767467, 0.4706083454004908, 0.17819452380833334], Action prob: [0.85670614 0.14329383], Action: 0, state: 3\n",
      "Sensor: [0.30744939527273835, 0.3944585683811941, 0.5808705515402889, 0.258881362005011], Action prob: [0.8540632  0.14593676], Action: 0, state: 8\n",
      "Sensor: [0.5441621139571684, 0.6240644355413542, 0.21185560306015233, 0.2842824357578171], Action prob: [0.8579331  0.14206688], Action: 0, state: 8\n",
      "Sensor: [0.6283004789847966, 0.6658370308889848, 0.2009510225198307, 0.27281756680073976], Action prob: [0.8594781  0.14052188], Action: 0, state: 8\n",
      "Sensor: [0.390037322528866, 0.38723873480350535, 0.20652754626129388, 0.19702041658926894], Action prob: [0.8558279  0.14417206], Action: 0, state: 8\n",
      "Sensor: [0.27175110918250117, 0.2742363412806275, 0.2214855887050353, 0.19693043200331578], Action prob: [0.8527136  0.14728642], Action: 0, state: 8\n",
      "Sensor: [0.5479274618629345, 0.6749857425593908, 0.17195852074735218, 0.2674306149385828], Action prob: [0.85791683 0.1420831 ], Action: 0, state: 8\n",
      "Sensor: [0.2925536750470965, 0.6611787876735954, 0.22324111694633428, 0.5521862294366696], Action prob: [0.8589813  0.14101866], Action: 0, state: 8\n",
      "Sensor: [0.332848923799744, 0.611025716000679, 0.21803285171458806, 0.5569426402755167], Action prob: [0.8591703  0.14082974], Action: 0, state: 8\n",
      "Sensor: [0.39301044311028516, 0.6293498930360748, 0.20657580574672949, 0.5941374526343327], Action prob: [0.8598025  0.14019749], Action: 0, state: 8\n",
      "Sensor: [0.3312449063398794, 0.6191076776528904, 0.5450907037052425, 0.2684909888621261], Action prob: [0.8579056  0.14209443], Action: 0, state: 8\n",
      "Sensor: [0.5802655249353983, 0.4309348567763307, 0.21796545894522074, 0.19437506442831134], Action prob: [0.85696113 0.14303894], Action: 0, state: 8\n",
      "Sensor: [0.5843764601778221, 0.6510473387005415, 0.1888650817592091, 0.22942493792287794], Action prob: [0.8588393  0.14116065], Action: 1, state: 8\n",
      "Sensor: [0.6093116303516466, 0.6189495573724119, 0.2175857192818, 0.28286158737946726], Action prob: [0.859155   0.14084499], Action: 0, state: 8\n",
      "Sensor: [0.33583795479977224, 0.4041203315164784, 0.24871496284324351, 0.21772296598505625], Action prob: [0.8557099  0.14429006], Action: 0, state: 8\n",
      "Sensor: [0.3125663146462846, 0.36278704921887034, 0.24962982386272134, 0.29329218441812677], Action prob: [0.8542916  0.14570838], Action: 0, state: 8\n",
      "Sensor: [0.35342057773572394, 0.6331532146717569, 0.5242709868172438, 0.24088005279395439], Action prob: [0.8562712  0.14372884], Action: 1, state: 8\n",
      "Sensor: [0.5477096356968935, 0.6078320698264866, 0.23064832667931484, 0.2681922852866728], Action prob: [0.85833883 0.1416612 ], Action: 0, state: 8\n",
      "Sensor: [0.3658718013528367, 0.6449129685629571, 0.18906469897330258, 0.5542040152235448], Action prob: [0.8593185  0.14068148], Action: 0, state: 8\n",
      "Sensor: [0.3611215554902811, 0.31804918354340517, 0.25637302730300987, 0.27890281898967234], Action prob: [0.8552484  0.14475165], Action: 0, state: 8\n",
      "Sensor: [0.5857947036124377, 0.6350920655548552, 0.22017312747430653, 0.2756674857674913], Action prob: [0.85834235 0.14165762], Action: 1, state: 8\n",
      "Sensor: [0.3236422086886345, 0.6032514949600661, 0.25426605979443934, 0.2265439313256042], Action prob: [0.85775155 0.14224838], Action: 0, state: 0\n",
      "Sensor: [0.32662649677007727, 0.6562468810987617, 0.26276202512536484, 0.2317406876563371], Action prob: [0.8580846  0.14191537], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.30762069304326584, 0.6587530123644837, 0.24893821479050837, 0.2045403062603821], Action prob: [0.8580667  0.14193335], Action: 0, state: 0\n",
      "Sensor: [0.38447527579174917, 0.6301387414022306, 0.22794832910398002, 0.2495574704398921], Action prob: [0.85813993 0.14186005], Action: 0, state: 1\n",
      "tensor([ 0.2224,  0.2202,  0.2326,  0.2467,  0.2515,  0.2623,  0.2173,  0.1677,\n",
      "         0.1265,  0.0941,  0.0631,  0.0314,  0.0057, -0.0174, -0.0380, -0.0590,\n",
      "        -0.0755, -1.1574, -0.1034, -0.1186, -0.1312, -1.7600, -0.1467, -0.1531,\n",
      "        -0.1656, -2.1592, -0.1677, -0.1656, -0.1640, -0.1624],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 92 is -51700, loss is 0.1534449884965099\n",
      "Sensor: [0.3738285549463565, 0.6103377324599772, 0.19163110553503604, 0.2600250283760555], Action prob: [0.8354527 0.1645473], Action: 0, state: 0\n",
      "Sensor: [0.3220475877267971, 0.6222582907682896, 0.20186345618722312, 0.26733764833501134], Action prob: [0.856693   0.14330691], Action: 0, state: 0\n",
      "Sensor: [0.4044917394363835, 0.6436582423350825, 0.22008670064888647, 0.23068763534846387], Action prob: [0.86293507 0.13706495], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -1000\n",
      "Sensor: [0.363827764718868, 0.6432422206017817, 0.18505530082543997, 0.25657413786529437], Action prob: [0.865514   0.13448603], Action: 0, state: 0\n",
      "Sensor: [0.33326423401317207, 0.6267446982636263, 0.21182069028823314, 0.23604121417862395], Action prob: [0.8663432  0.13365681], Action: 0, state: 0\n",
      "Sensor: [0.3669301432916333, 0.6316654925497533, 0.2139148777244716, 0.5745434469659446], Action prob: [0.8680779  0.13192211], Action: 0, state: 0\n",
      "Sensor: [0.3750569285850904, 0.6657703730682274, 0.22752557105666904, 0.2597946068628237], Action prob: [0.8684635  0.13153647], Action: 0, state: 1\n",
      "Sensor: [0.398381212546356, 0.6667132899751321, 0.19712721191963545, 0.32439263019832965], Action prob: [0.86880803 0.13119197], Action: 0, state: 1\n",
      "Sensor: [0.35557716767977293, 0.6294281665387845, 0.2270387490881567, 0.22059098016103582], Action prob: [0.867996   0.13200401], Action: 0, state: 2\n",
      "Sensor: [0.6652430359006702, 0.5996586355548527, 0.1836701543149004, 0.24759759015766789], Action prob: [0.86857474 0.1314253 ], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -200\n",
      "Sensor: [0.3687315366135812, 0.6699879540522418, 0.21288191860754344, 0.2592582977254855], Action prob: [0.86850756 0.1314924 ], Action: 0, state: 2\n",
      "Sensor: [0.31614108243775446, 0.5872247139497023, 0.27016055297568486, 0.21115340987824227], Action prob: [0.86713547 0.13286446], Action: 0, state: 3\n",
      "Sensor: [0.36369173566900914, 0.6235014413035227, 0.2136840831476654, 0.23585673680707084], Action prob: [0.86753196 0.13246809], Action: 0, state: 3\n",
      "Sensor: [0.3103267515176666, 0.5956226121917843, 0.22482159163663065, 0.1883435016476162], Action prob: [0.86690223 0.13309777], Action: 0, state: 3\n",
      "Sensor: [0.3601790401924528, 0.6035119749222028, 0.24689655344478667, 0.2601067112953071], Action prob: [0.8671141  0.13288587], Action: 0, state: 3\n",
      "Sensor: [0.3763938722318677, 0.609801000603876, 0.22113579206218623, 0.2502638688872444], Action prob: [0.8674096  0.13259043], Action: 0, state: 3\n",
      "Sensor: [0.3595453409740697, 0.6642511050368192, 0.23843065745516667, 0.20945696305910733], Action prob: [0.86782974 0.13217026], Action: 0, state: 3\n",
      "Sensor: [0.3538047513007648, 0.40730415130612907, 0.19107775447082892, 0.2557182413494118], Action prob: [0.8653095  0.13469052], Action: 0, state: 8\n",
      "Sensor: [0.3800420875399909, 0.34339309162484577, 0.26313142955829405, 0.2171385720766641], Action prob: [0.8635392  0.13646086], Action: 0, state: 8\n",
      "Sensor: [0.5566552040910836, 0.6360430514418983, 0.20933035081173804, 0.28451553503901544], Action prob: [0.867478   0.13252202], Action: 0, state: 8\n",
      "Sensor: [0.35964823227015724, 0.647043335026459, 0.48168826033962514, 0.2158543182926133], Action prob: [0.86704755 0.13295247], Action: 0, state: 8\n",
      "Sensor: [0.3285927052569876, 0.37047244722150496, 0.4823751113683039, 0.2450835764322253], Action prob: [0.8640941  0.13590592], Action: 0, state: 8\n",
      "Sensor: [0.33779036655282507, 0.3799716242093389, 0.23024985984939314, 0.2949832692087413], Action prob: [0.86411417 0.13588585], Action: 0, state: 8\n",
      "Sensor: [0.5337171694354542, 0.6259709968715336, 0.19313214991043728, 0.231353553470169], Action prob: [0.867409  0.1325911], Action: 0, state: 8\n",
      "tensor([-0.4297, -0.2512, -1.8582, -0.2246, -0.1430, -0.0693, -0.0123,  0.0395,\n",
      "         0.0811,  1.5006,  0.0957,  0.1157,  0.1325,  0.1486,  0.1623,  0.1744,\n",
      "         0.1848,  0.1276,  0.0730,  0.0215, -0.0236, -0.0645, -0.1005, -0.1305],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 93 is -15100, loss is 0.01875295364396719\n",
      "Sensor: [0.36186548558752735, 0.6153902697072853, 0.17295996955369797, 0.2482138235731421], Action prob: [0.8438653  0.15613471], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3019885378453278, 0.6534345810227212, 0.22711125485502212, 0.5775154178878597], Action prob: [0.8659407 0.1340593], Action: 0, state: 0\n",
      "Sensor: [0.3540083985000913, 0.6580822472275356, 0.22057789503604677, 0.275967904489872], Action prob: [0.8713291  0.12867084], Action: 0, state: 0\n",
      "Sensor: [0.3921962952819421, 0.59266712508085, 0.18687003387068835, 0.2491842047124128], Action prob: [0.8726498  0.12735015], Action: 0, state: 1\n",
      "Sensor: [0.3655256032637988, 0.6707460782630836, 0.24320430135173515, 0.25904594526039904], Action prob: [0.8740514  0.12594856], Action: 0, state: 1\n",
      "Sensor: [0.35141949460405597, 0.6132913211093256, 0.19164429859070928, 0.2585415674219818], Action prob: [0.8742389  0.12576108], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -600\n",
      "Sensor: [0.4177969144811047, 0.5886884422406164, 0.2168094199840341, 0.2444643132641842], Action prob: [0.87419426 0.12580572], Action: 0, state: 1\n",
      "Sensor: [0.37816642362593417, 0.6226569302260014, 0.19151658402271057, 0.24380407779862423], Action prob: [0.8745382  0.12546176], Action: 0, state: 1\n",
      "Sensor: [0.3602461674610737, 0.6003317566676905, 0.2243341446101177, 0.24398001204847614], Action prob: [0.8742291  0.12577096], Action: 0, state: 2\n",
      "Sensor: [0.3595321017768207, 0.654067186124809, 0.23575752469075592, 0.23931503814919905], Action prob: [0.87470436 0.12529561], Action: 0, state: 2\n",
      "Sensor: [0.3833651236568321, 0.6585050505435334, 0.49866948728728006, 0.23793414283929534], Action prob: [0.8742488  0.12575121], Action: 0, state: 3\n",
      "Sensor: [0.4504044746842331, 0.6527643686530102, 0.22492548157801917, 0.2379507765893669], Action prob: [0.8753282  0.12467176], Action: 0, state: 3\n",
      "Sensor: [0.41239709813664094, 0.6180804736765845, 0.20787578060685336, 0.2594949228532547], Action prob: [0.87498444 0.12501559], Action: 0, state: 3\n",
      "Sensor: [0.3483580915206971, 0.5725206918907441, 0.2203035120563246, 0.19936486875749013], Action prob: [0.8739057  0.12609424], Action: 0, state: 3\n",
      "Sensor: [0.39301962408740587, 0.6303981499333842, 0.20619590401193919, 0.22409041568772134], Action prob: [0.8744758  0.12552425], Action: 0, state: 3\n",
      "Sensor: [0.34187263780065297, 0.6236989577984992, 0.5224006634036634, 0.2774872062768353], Action prob: [0.8737128 0.1262872], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.3724297887164002, 0.6676478939779011, 0.21400293917066807, 0.2619996397582529], Action prob: [0.87523466 0.12476536], Action: 0, state: 2\n",
      "Sensor: [0.39242878121050667, 0.6366636189255941, 0.21349902591940503, 0.2413702983243329], Action prob: [0.8750161  0.12498389], Action: 0, state: 2\n",
      "Sensor: [0.4041217109494951, 0.6441258213608005, 0.16842741733603736, 0.2533506278394327], Action prob: [0.87519306 0.12480693], Action: 0, state: 3\n",
      "Sensor: [0.3537266961436921, 0.6365798186264775, 0.4804171990279431, 0.29258193331740684], Action prob: [0.8742376  0.12576239], Action: 1, state: 8\n",
      "Sensor: [0.400961928760932, 0.6430437254394248, 0.2515186486248402, 0.3345287661514043], Action prob: [0.87534165 0.12465837], Action: 0, state: 0\n",
      "Sensor: [0.3841337386367001, 0.6676255619066014, 0.20764315473024597, 0.25725221669246906], Action prob: [0.8755416  0.12445834], Action: 0, state: 0\n",
      "Sensor: [0.38975517390492487, 0.6891366624946709, 0.19311859601241008, 0.25459210424356504], Action prob: [0.87574893 0.1242511 ], Action: 0, state: 0\n",
      "Sensor: [0.31629275935739565, 0.6272639650103445, 0.1840673627760096, 0.20950319439642076], Action prob: [0.8747445  0.12525554], Action: 0, state: 0\n",
      "Sensor: [0.2833917256465252, 0.5692515672859596, 0.21353748082754412, 0.21862516853479785], Action prob: [0.8735732  0.12642685], Action: 0, state: 0\n",
      "tensor([-4.8219, -0.3266, -0.2326, -0.1654, -0.1063, -0.9273, -0.0911, -0.0492,\n",
      "        -0.0160,  0.0139,  0.0302,  0.0457,  0.0596,  0.0724,  0.0831,  1.4253,\n",
      "         0.0978,  0.1109,  0.1180,  1.2186,  0.0906,  0.1008,  0.1101,  0.1196,\n",
      "         0.1286], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 94 is 13500, loss is 0.1164436233880104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.3928910525567228, 0.5254551473490164, 0.23172302102493875, 0.2667145309517077], Action prob: [0.8461846  0.15381534], Action: 0, state: 0\n",
      "Sensor: [0.35224917859552773, 0.6228855603683364, 0.21484863062327256, 0.21781832659278763], Action prob: [0.86742693 0.13257311], Action: 0, state: 0\n",
      "Sensor: [0.354972542899565, 0.7041633595715437, 0.23400889650771736, 0.3256293441357046], Action prob: [0.8739945  0.12600553], Action: 0, state: 0\n",
      "Sensor: [0.3350433382950865, 0.6002411082092494, 0.21215994271842892, 0.2876629541660761], Action prob: [0.87518096 0.12481898], Action: 0, state: 1\n",
      "Sensor: [0.4102448664127071, 0.6342054226482564, 0.23394690239890586, 0.321681761063533], Action prob: [0.87660635 0.12339363], Action: 0, state: 1\n",
      "Sensor: [0.33321312583345064, 0.6305481045376302, 0.20697115108225547, 0.2725601290684451], Action prob: [0.8769411  0.12305894], Action: 0, state: 1\n",
      "Sensor: [0.36050438540070073, 0.6472436830079736, 0.21736301528308613, 0.2807803149979509], Action prob: [0.87733895 0.12266103], Action: 0, state: 1\n",
      "Sensor: [0.3994163037718141, 0.6019434266259418, 0.22049833377483755, 0.21896364897315873], Action prob: [0.87693954 0.12306044], Action: 0, state: 2\n",
      "Sensor: [0.3841460170877451, 0.6337052146410698, 0.20523010466159752, 0.21806017643903167], Action prob: [0.87710834 0.1228917 ], Action: 0, state: 2\n",
      "Sensor: [0.41747173371651725, 0.595649611932364, 0.16801660273584856, 0.23387820427085626], Action prob: [0.876994   0.12300597], Action: 0, state: 3\n",
      "Sensor: [0.5330613935540974, 0.35055795689646785, 0.5130304016545585, 0.27541114570844216], Action prob: [0.8740858 0.1259142], Action: 0, state: 3\n",
      "Sensor: [0.3635674696448705, 0.631898007574063, 0.2029832195604033, 0.22182714650205412], Action prob: [0.8765884 0.1234116], Action: 0, state: 3\n",
      "Sensor: [0.5438116710316541, 0.6350806029481396, 0.20545783386351224, 0.23060333674757058], Action prob: [0.87763774 0.12236229], Action: 0, state: 3\n",
      "Sensor: [0.4046950396925565, 0.5903248024246862, 0.1901137581289029, 0.2376983108985605], Action prob: [0.8770469  0.12295308], Action: 0, state: 3\n",
      "Sensor: [0.3653426402992451, 0.6812959083616873, 0.2550235777573991, 0.1638464296867132], Action prob: [0.8772552  0.12274478], Action: 1, state: 3\n",
      "Maintenance in progress, cumulative 300\n",
      "Sensor: [0.3521871041979819, 0.613198552190532, 0.17938697209634574, 0.22609140277393336], Action prob: [0.87696576 0.12303421], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.3606599569743255, 0.6077584553978903, 0.20343895389556788, 0.24204581573903955], Action prob: [0.8767793  0.12322064], Action: 0, state: 1\n",
      "Sensor: [0.3721500319768919, 0.6633200557274377, 0.21767777347429268, 0.29001406023149445], Action prob: [0.8775148  0.12248525], Action: 0, state: 1\n",
      "Sensor: [0.31693449095371545, 0.5778516443857264, 0.17845572375448543, 0.22459270413229887], Action prob: [0.87659407 0.12340593], Action: 0, state: 1\n",
      "Sensor: [0.3546436154689413, 0.5797383894913745, 0.19325953779450206, 0.22287382080709175], Action prob: [0.87632126 0.12367872], Action: 0, state: 1\n",
      "Sensor: [0.34466658415625456, 0.6497640134840819, 0.22981431502795088, 0.2571566277457084], Action prob: [0.8769917  0.12300831], Action: 0, state: 2\n",
      "Sensor: [0.40338998264572334, 0.6162372490921377, 0.24060799826552684, 0.5122322239940891], Action prob: [0.87790567 0.12209436], Action: 0, state: 3\n",
      "Sensor: [0.3470423753506342, 0.6839811174857053, 0.21658185681518752, 0.2453998227405842], Action prob: [0.878098   0.12190201], Action: 0, state: 3\n",
      "Sensor: [0.30531321806460454, 0.646803989837122, 0.2348421961298379, 0.2308952047965247], Action prob: [0.8773724  0.12262768], Action: 0, state: 3\n",
      "Sensor: [0.3312813626833047, 0.40475778872249074, 0.19901837226850083, 0.23436228691776018], Action prob: [0.8746473  0.12535267], Action: 0, state: 3\n",
      "Sensor: [0.36750137870284544, 0.6861002843288413, 0.2226480981875686, 0.5354838670449075], Action prob: [0.87792605 0.12207391], Action: 0, state: 8\n",
      "Sensor: [0.537221276402293, 0.6457388430498254, 0.2036633358037887, 0.2779974356347276], Action prob: [0.87848544 0.12151463], Action: 0, state: 8\n",
      "Sensor: [0.392232131766773, 0.3552350992936384, 0.2503129521099001, 0.2568056745983872], Action prob: [0.8747623  0.12523778], Action: 1, state: 8\n",
      "tensor([-0.4661, -0.3232, -0.2430, -0.1899, -0.1427, -0.1020, -0.0656, -0.0368,\n",
      "        -0.0107,  0.0041,  0.0174,  0.0292,  0.0396,  0.0495,  0.9234,  1.0035,\n",
      "         0.0686,  0.0794,  0.0905,  0.0999,  0.1066,  0.1103,  0.1133,  0.1173,\n",
      "         0.1237,  0.1041,  0.0888,  1.2183], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 95 is 4400, loss is -0.10026427483930125\n",
      "Sensor: [0.3537408669449956, 0.6573303736108296, 0.20060262395751702, 0.2896738191909214], Action prob: [0.85562855 0.14437148], Action: 0, state: 0\n",
      "Sensor: [0.3701747490052979, 0.638423475776798, 0.24070704190600464, 0.4352424320008341], Action prob: [0.87686527 0.1231347 ], Action: 0, state: 0\n",
      "Sensor: [0.3645691793920573, 0.6588678626743719, 0.2581939834584034, 0.27232322809104403], Action prob: [0.88191223 0.11808773], Action: 0, state: 0\n",
      "Sensor: [0.3748714537251116, 0.6484574124278166, 0.1668417904807859, 0.22395115757504622], Action prob: [0.88368845 0.11631151], Action: 0, state: 0\n",
      "Sensor: [0.3421871813136639, 0.6784961317576066, 0.20741830784205287, 0.2683041380737155], Action prob: [0.8847187  0.11528133], Action: 0, state: 0\n",
      "Sensor: [0.32169196880508855, 0.656242124832982, 0.2087885899943738, 0.2107486118805359], Action prob: [0.8848219  0.11517806], Action: 0, state: 0\n",
      "Sensor: [0.27136784063883573, 0.5916982461691273, 0.2076260248617962, 0.22047937208857155], Action prob: [0.8840916  0.11590832], Action: 0, state: 0\n",
      "Sensor: [0.3305664677383269, 0.635227392640934, 0.21618825222374416, 0.25157164904868085], Action prob: [0.88462204 0.11537797], Action: 0, state: 0\n",
      "Sensor: [0.30900475854752657, 0.6453726567491196, 0.2074973027399043, 0.29332734331597254], Action prob: [0.88502795 0.11497203], Action: 0, state: 0\n",
      "Sensor: [0.37898398666698224, 0.62782840444112, 0.21202081786635307, 0.18270978489739687], Action prob: [0.88483655 0.11516339], Action: 0, state: 0\n",
      "Sensor: [0.30616853937075617, 0.6101250396609535, 0.24926851938404432, 0.27372021991440687], Action prob: [0.88451856 0.11548141], Action: 0, state: 1\n",
      "Sensor: [0.3404186969132999, 0.513301565247801, 0.2350547127799309, 0.28327473219531685], Action prob: [0.88367933 0.11632063], Action: 0, state: 2\n",
      "Sensor: [0.3921341727742485, 0.6172332338683262, 0.20833008233444408, 0.24090243545582204], Action prob: [0.88462454 0.11537541], Action: 0, state: 2\n",
      "Sensor: [0.33620171224274675, 0.5942324918897939, 0.18306713503202435, 0.238650096101165], Action prob: [0.8844961  0.11550386], Action: 0, state: 2\n",
      "Sensor: [0.5870227223294504, 0.6605427459299584, 0.23990287311329855, 0.2467665279657297], Action prob: [0.8857515  0.11424846], Action: 0, state: 3\n",
      "Sensor: [0.4093997720166546, 0.6345387651414647, 0.18853908442060754, 0.2576844110619454], Action prob: [0.8855851  0.11441483], Action: 0, state: 3\n",
      "Sensor: [0.29967863914808474, 0.6179860358512752, 0.19183250583029068, 0.2587771515473595], Action prob: [0.8849546  0.11504542], Action: 0, state: 3\n",
      "Sensor: [0.39861853887196147, 0.688404781843483, 0.2145242451604871, 0.2399711265386365], Action prob: [0.8856658 0.1143343], Action: 0, state: 3\n",
      "Sensor: [0.29134387373118226, 0.3402516013340562, 0.2187563958625123, 0.2644978459258234], Action prob: [0.8819241  0.11807594], Action: 0, state: 8\n",
      "Sensor: [0.5336035279707064, 0.629415922843819, 0.24215161277831854, 0.18966771069986083], Action prob: [0.8844293 0.1155708], Action: 1, state: 8\n",
      "Sensor: [0.30834793176732805, 0.6719034058472958, 0.2231760949269915, 0.5817522269308611], Action prob: [0.88620317 0.11379676], Action: 0, state: 8\n",
      "Sensor: [0.5459561452444013, 0.6529305592748526, 0.242496584588085, 0.2758262708039083], Action prob: [0.8864508  0.11354915], Action: 0, state: 8\n",
      "Sensor: [0.5671062262447621, 0.6988671303653955, 0.2220779717449289, 0.23325610547105916], Action prob: [0.8868077  0.11319239], Action: 0, state: 8\n",
      "Sensor: [0.35693568189992825, 0.3430760308281385, 0.25628690628448053, 0.2531470005334646], Action prob: [0.88255566 0.11744433], Action: 0, state: 8\n",
      "Sensor: [0.31336331173335125, 0.30557523797866487, 0.20246937870334136, 0.2343705375720567], Action prob: [0.8805746  0.11942542], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor: [0.6041795956934813, 0.6173752824533032, 0.19748371346075883, 0.24056477012859026], Action prob: [0.8845119  0.11548807], Action: 0, state: 8\n",
      "Sensor: [0.30638029596987393, 0.3161389586511436, 0.23607334599539231, 0.5427897075359924], Action prob: [0.8824942  0.11750576], Action: 1, state: 8\n",
      "Sensor: [0.32565232119070714, 0.6418130560245642, 0.2148215939951445, 0.5793330746270106], Action prob: [0.8856318  0.11436816], Action: 0, state: 8\n",
      "Sensor: [0.4148667601446998, 0.6645283023848765, 0.23294953372830107, 0.5847534544744533], Action prob: [0.8870525 0.1129475], Action: 0, state: 8\n",
      "Sensor: [0.29750594113556045, 0.6444232652120719, 0.5434481956930326, 0.26348460935439383], Action prob: [0.88520265 0.11479733], Action: 0, state: 8\n",
      "tensor([-4.2184e-01, -2.8728e-01, -2.1653e-01, -1.6106e-01, -1.1337e-01,\n",
      "        -7.1767e-02, -3.4481e-02, -5.9903e-04,  2.9728e-02,  5.6880e-02,\n",
      "         7.9286e-02,  9.7948e-02,  1.1289e-01,  1.2747e-01,  1.3379e-01,\n",
      "         1.4135e-01,  1.4870e-01,  1.5338e-01,  1.2669e-01,  1.6628e+00,\n",
      "         6.8377e-02,  4.4938e-02,  2.4288e-02,  6.5769e-03, -1.0665e-02,\n",
      "        -2.5872e-02, -6.7614e-01, -5.0860e-02, -6.1070e-02, -7.3326e-02],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 96 is -24700, loss is -0.0270071255890906\n",
      "Sensor: [0.3120640115072857, 0.673896104738858, 0.22145975420904407, 0.26812136185294266], Action prob: [0.8632237  0.13677633], Action: 0, state: 0\n",
      "Sensor: [0.3379590697676084, 0.6673737101359958, 0.20910229127421864, 0.2787646855546276], Action prob: [0.8845074  0.11549259], Action: 0, state: 0\n",
      "Sensor: [0.29635171072016087, 0.5067539486832744, 0.25986044807511566, 0.25036687142383934], Action prob: [0.88770914 0.11229089], Action: 0, state: 0\n",
      "Sensor: [0.3543509736976747, 0.6524420876455033, 0.22683802590402827, 0.25387878451062706], Action prob: [0.89093083 0.10906922], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.37463209709403567, 0.5968479493196227, 0.22465347331826077, 0.2800934028279452], Action prob: [0.891888   0.10811201], Action: 0, state: 0\n",
      "Sensor: [0.3520065817421052, 0.6584146379888063, 0.18768820390133356, 0.26424265151311016], Action prob: [0.89295864 0.10704138], Action: 0, state: 0\n",
      "Sensor: [0.3898003847492253, 0.610568129036954, 0.27010965203226267, 0.2716349813338673], Action prob: [0.89280933 0.10719067], Action: 0, state: 0\n",
      "Sensor: [0.3453108643182835, 0.6017347927157711, 0.17714511742030745, 0.2847975504769859], Action prob: [0.8929053  0.10709464], Action: 0, state: 1\n",
      "Sensor: [0.3038226568881983, 0.6474891925313233, 0.18902209161471945, 0.2411837614051847], Action prob: [0.89302015 0.10697984], Action: 0, state: 2\n",
      "Sensor: [0.3703769895513251, 0.6329608695253897, 0.21142274431002078, 0.24513049909889123], Action prob: [0.8930428  0.10695725], Action: 0, state: 2\n",
      "Sensor: [0.38169240318215375, 0.6882602174866069, 0.25743406421575055, 0.25559195366352255], Action prob: [0.8936094  0.10639059], Action: 1, state: 2\n",
      "Maintenance in progress, cumulative 400\n",
      "Sensor: [0.34506453869067344, 0.6664857265571626, 0.21800699842890647, 0.22822490987418642], Action prob: [0.8934985  0.10650147], Action: 0, state: 1\n",
      "Sensor: [0.35640833599612737, 0.7005836109238128, 0.1944058116441444, 0.2478823805104147], Action prob: [0.89389944 0.10610058], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -2000\n",
      "Maintenance in progress, cumulative -2500\n",
      "Maintenance in progress, cumulative -3000\n",
      "Maintenance in progress, cumulative -2000\n",
      "Sensor: [0.3706083164281864, 0.6165279186765805, 0.2465554339587409, 0.22838008161785192], Action prob: [0.8929998  0.10700024], Action: 0, state: 0\n",
      "Sensor: [0.39471991162503567, 0.635274449367519, 0.17987805685138283, 0.40407381167918954], Action prob: [0.89381504 0.1061849 ], Action: 0, state: 0\n",
      "Sensor: [0.32887046457520863, 0.6666332585604202, 0.2252872709151065, 0.2707950326034636], Action prob: [0.89368695 0.10631298], Action: 0, state: 1\n",
      "Sensor: [0.35786362794932486, 0.6059563242073042, 0.21298424138581493, 0.2887305815899535], Action prob: [0.8931873 0.1068127], Action: 0, state: 1\n",
      "Sensor: [0.3465490881329634, 0.6380976977434268, 0.2249073359994847, 0.19630405674677026], Action prob: [0.892965   0.10703497], Action: 0, state: 2\n",
      "Sensor: [0.4004509213675844, 0.63648581923009, 0.21481925165304114, 0.24636042059401253], Action prob: [0.8931796  0.10682041], Action: 0, state: 2\n",
      "Sensor: [0.3639145827089091, 0.6659488576442143, 0.2117320839895181, 0.25422938842146325], Action prob: [0.8934745  0.10652551], Action: 0, state: 2\n",
      "Sensor: [0.3707474305093205, 0.6144108354401768, 0.21491484891783705, 0.18465866869985892], Action prob: [0.89280945 0.10719058], Action: 0, state: 2\n",
      "Sensor: [0.576425407495214, 0.6625851799324453, 0.2429242965708846, 0.2321734921533886], Action prob: [0.8937889  0.10621119], Action: 0, state: 2\n",
      "tensor([-0.3688, -0.2451, -0.1831, -2.4937, -0.1074, -0.0684, -0.0345, -0.0066,\n",
      "         0.0153,  0.0352,  1.0478,  0.0607,  1.5339,  0.0447,  0.0593,  0.0709,\n",
      "         0.0820,  0.0905,  0.0981,  0.1047,  0.1116,  0.1161],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 97 is 15700, loss is 0.001666641117367354\n",
      "Sensor: [0.38325474724215114, 0.6586479386564745, 0.2086971737423622, 0.22000744694354932], Action prob: [0.87042844 0.12957156], Action: 0, state: 0\n",
      "Sensor: [0.34450644705885936, 0.6920028562926792, 0.22425610879211805, 0.24644241411090512], Action prob: [0.8918074  0.10819259], Action: 0, state: 0\n",
      "Sensor: [0.3085972676341938, 0.5972306682478079, 0.19120859228695375, 0.24127513980492826], Action prob: [0.89578164 0.10421833], Action: 0, state: 0\n",
      "Sensor: [0.3572235795079374, 0.6183512009881699, 0.1869916008225137, 0.2597206451239613], Action prob: [0.89778626 0.10221367], Action: 0, state: 0\n",
      "Sensor: [0.36089633359586976, 0.6264128736116703, 0.2371037079140887, 0.2050732496546232], Action prob: [0.89866775 0.10133225], Action: 0, state: 0\n",
      "Sensor: [0.34533078267710526, 0.6378052423191215, 0.22266130838624731, 0.2818366653148194], Action prob: [0.89950603 0.10049391], Action: 0, state: 0\n",
      "Sensor: [0.4121890233650459, 0.6222667539575809, 0.20736808422879338, 0.26556791925326484], Action prob: [0.89987665 0.10012337], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative -1000\n",
      "Maintenance in progress, cumulative -1500\n",
      "Maintenance in progress, cumulative -500\n",
      "Sensor: [0.3259556244756153, 0.6299075028654424, 0.2301008929550786, 0.27777893031737294], Action prob: [0.89982706 0.1001729 ], Action: 0, state: 0\n",
      "Sensor: [0.2996085513368942, 0.6358585190202881, 0.2126001828389346, 0.2714636242710824], Action prob: [0.8998428  0.10015727], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.3718215341946427, 0.6830112942696671, 0.20821861663246344, 0.2944087053390144], Action prob: [0.9005845  0.09941544], Action: 0, state: 0\n",
      "Sensor: [0.36413768661535817, 0.6488684687330514, 0.2104644569741687, 0.18390226693408596], Action prob: [0.90010417 0.09989583], Action: 0, state: 0\n",
      "Sensor: [0.3644025081372502, 0.6567514491551949, 0.21123304822788921, 0.23656953450650364], Action prob: [0.90012646 0.09987348], Action: 0, state: 1\n",
      "Sensor: [0.38744101759732585, 0.694015316817558, 0.2279051840416937, 0.2525584151731954], Action prob: [0.9006165  0.09938352], Action: 1, state: 1\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.34586838755466637, 0.6766209078799988, 0.2119997785565579, 0.24304394960644218], Action prob: [0.90051365 0.09948631], Action: 0, state: 0\n",
      "Sensor: [0.3036751958853352, 0.6197975330797569, 0.16425167491776288, 0.26072702170537054], Action prob: [0.8999012  0.10009882], Action: 0, state: 0\n",
      "Sensor: [0.3017075041671588, 0.5963272674863742, 0.19265377346106557, 0.22249242558014123], Action prob: [0.8992471  0.10075288], Action: 0, state: 1\n",
      "Sensor: [0.3839564071036327, 0.6338482928926268, 0.2313062122086209, 0.23404343975559322], Action prob: [0.89965266 0.10034736], Action: 0, state: 2\n",
      "Sensor: [0.41680661872485186, 0.6522206346687806, 0.19812167562701832, 0.24580474242240466], Action prob: [0.9002024  0.09979758], Action: 0, state: 3\n",
      "Sensor: [0.4417212678326674, 0.6269814583488701, 0.5105791880690991, 0.28171277057649824], Action prob: [0.89970285 0.1002971 ], Action: 0, state: 8\n",
      "Sensor: [0.35386246307976177, 0.39620979338339685, 0.19842034913429232, 0.2131174756999434], Action prob: [0.89758176 0.10241823], Action: 0, state: 8\n",
      "Sensor: [0.3996991861528472, 0.3830719165213639, 0.20515426853871194, 0.27038609940198494], Action prob: [0.8968159 0.1031841], Action: 1, state: 8\n",
      "Sensor: [0.35022661403119293, 0.3759979126456363, 0.2147844636720691, 0.2611328125931932], Action prob: [0.8963094  0.10369055], Action: 0, state: 8\n",
      "Sensor: [0.4417483086574006, 0.42667365814343283, 0.5491852828230552, 0.2005105136849823], Action prob: [0.8962658  0.10373422], Action: 1, state: 8\n",
      "Sensor: [0.34127452558527255, 0.6493189306805849, 0.22445935055364277, 0.5601828096385753], Action prob: [0.90029997 0.09970001], Action: 0, state: 8\n",
      "Sensor: [0.5830986760913385, 0.6039308257468202, 0.21037192307678282, 0.25810310205516457], Action prob: [0.90069    0.09930998], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3778, -0.2459, -0.1791, -0.1252, -0.0794, -0.0386, -0.1340, -0.0223,\n",
      "         0.0837,  0.0168,  0.0402,  0.0593,  1.6746,  0.0846,  0.1007,  0.1139,\n",
      "         0.1234,  0.1283,  0.0980,  0.0730,  1.0069,  0.0255,  0.0814, -0.0131,\n",
      "        -0.0294], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 98 is -10700, loss is -0.09861426664430097\n",
      "Sensor: [0.3340318142972817, 0.6676029820204552, 0.24542110684020496, 0.2802443353742981], Action prob: [0.8811051  0.11889492], Action: 0, state: 0\n",
      "Sensor: [0.29350617942703217, 0.704213180329003, 0.2315022037502746, 0.26812232412141723], Action prob: [0.9028266  0.09717341], Action: 1, state: 0\n",
      "Maintenance in progress, cumulative 500\n",
      "Sensor: [0.31043731755951276, 0.611882829492875, 0.24349171960845148, 0.202885647934776], Action prob: [0.9067341  0.09326587], Action: 0, state: 0\n",
      "Sensor: [0.3594778651817597, 0.6469142529941446, 0.250255110636676, 0.228077163905677], Action prob: [0.9089224  0.09107762], Action: 0, state: 0\n",
      "Sensor: [0.3592772300228153, 0.6471909794841832, 0.24003529741801471, 0.25907740873339746], Action prob: [0.9101272  0.08987281], Action: 0, state: 0\n",
      "Sensor: [0.47011630513587865, 0.6529587625351004, 0.2187250432666267, 0.2560067102945112], Action prob: [0.9110896  0.08891043], Action: 0, state: 1\n",
      "Sensor: [0.33374654924644337, 0.679004404019174, 0.23306633330161003, 0.2675505848757026], Action prob: [0.9113354  0.08866464], Action: 0, state: 1\n",
      "Sensor: [0.40422010579447104, 0.6430639334139882, 0.24533307960182604, 0.22703320376004502], Action prob: [0.9111372  0.08886284], Action: 0, state: 1\n",
      "Sensor: [0.3000742983989113, 0.6453435791359182, 0.20046233901451904, 0.2687802450540498], Action prob: [0.91101354 0.08898652], Action: 0, state: 1\n",
      "Sensor: [0.3657768863223677, 0.5869627067540361, 0.18490634666812905, 0.27511804668030776], Action prob: [0.9106134  0.08938657], Action: 0, state: 1\n",
      "Sensor: [0.3839256535028315, 0.5249226798609408, 0.21334139078404252, 0.27507891254878647], Action prob: [0.9098913  0.09010875], Action: 0, state: 1\n",
      "Sensor: [0.3249115800917833, 0.5754760908528544, 0.19813680067373787, 0.24052116267542312], Action prob: [0.90993214 0.09006786], Action: 0, state: 1\n",
      "Sensor: [0.5155342703248185, 0.6499845077899047, 0.2548131316417709, 0.24352548055793244], Action prob: [0.9111293  0.08887075], Action: 0, state: 2\n",
      "Sensor: [0.3745707076527349, 0.619727435913045, 0.22232464983904054, 0.21440551850141973], Action prob: [0.9107961 0.0892039], Action: 0, state: 3\n",
      "Sensor: [0.3621493210738385, 0.6406191827666414, 0.214618081183985, 0.20041299394789044], Action prob: [0.9107535 0.0892465], Action: 0, state: 3\n",
      "Sensor: [0.3763240894984271, 0.6190122121784346, 0.23322364909103777, 0.1884870004195385], Action prob: [0.91047186 0.08952814], Action: 0, state: 3\n",
      "Sensor: [0.33816784590594884, 0.6463673430745546, 0.25403805625456827, 0.22706641366793817], Action prob: [0.91065454 0.08934549], Action: 0, state: 3\n",
      "Sensor: [0.5689501577449474, 0.6135473182951944, 0.25044999146183466, 0.26502389049431235], Action prob: [0.9112172  0.08878283], Action: 0, state: 8\n",
      "Sensor: [0.34901025696717697, 0.3607394461003458, 0.23030666359311575, 0.22051327254866251], Action prob: [0.90810525 0.0918947 ], Action: 0, state: 8\n",
      "Sensor: [0.38506643446123523, 0.37176683207113326, 0.16096365520722877, 0.2766580217778099], Action prob: [0.9075856  0.09241438], Action: 0, state: 8\n",
      "Sensor: [0.40629327957054573, 0.6510403548658918, 0.48975459054652226, 0.2929571601311687], Action prob: [0.910034   0.08996595], Action: 0, state: 8\n",
      "Sensor: [0.594571485881027, 0.6519266503359998, 0.22980309106430272, 0.27265989865352397], Action prob: [0.911836   0.08816398], Action: 0, state: 8\n",
      "Sensor: [0.36651385412472465, 0.6114733756069969, 0.21309288355377623, 0.5815876340980008], Action prob: [0.9121406  0.08785941], Action: 0, state: 8\n",
      "Sensor: [0.3870438647983262, 0.37897999529082244, 0.2413615451638068, 0.2949951913861896], Action prob: [0.9092051  0.09079486], Action: 0, state: 8\n",
      "Sensor: [0.3703761129300059, 0.578444422288072, 0.5342894808081594, 0.21575055370417281], Action prob: [0.9094436  0.09055641], Action: 0, state: 8\n",
      "Sensor: [0.5145451902317084, 0.598470890352273, 0.2385813693794085, 0.27932713693869915], Action prob: [0.91101795 0.08898201], Action: 0, state: 8\n",
      "Sensor: [0.45882795744148525, 0.7584781642588956, 0.240418209746299, 0.8170257166919428], Action prob: [0.9140201 0.0859799], Action: 0, state: 8\n",
      "Sensor: [0.4604608212769409, 0.46788470184088815, 0.4681415522249019, 0.5268368981705662], Action prob: [0.9115275  0.08847249], Action: 0, state: 8\n",
      "Sensor: [0.3070818244428185, 0.38088788651700234, 0.22981476129333428, 0.4120892222125525], Action prob: [0.9095468  0.09045318], Action: 0, state: 8\n",
      "tensor([-0.3109, -4.4091, -0.1603, -0.1127, -0.0723, -0.0404, -0.0124,  0.0126,\n",
      "         0.0355,  0.0562,  0.0753,  0.0919,  0.1037,  0.1116,  0.1183,  0.1247,\n",
      "         0.1299,  0.1000,  0.0766,  0.0526,  0.0287,  0.0095, -0.0070, -0.0234,\n",
      "        -0.0385, -0.0498, -0.0583, -0.0708, -0.0814], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for up to this episode 99 is -26400, loss is 0.14896274783186314\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnkAAAJNCAYAAABN4mMaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOydd5gkZ3X1fxU6Tp7ZnHcVVzkLBAIBEiJKgEgmB4ONAYMBG+zPBtsEY7AxwQYDBmwwmCCBBAIhEEISIijnXaXNYTZOnp5OVfX98fZbXd1dscNM726d59Ezqw7V1d3V9Z46595zFcuyiBEjRowYMWLEiHF0QV3oHYgRI0aMGDFixIjRfsQkL0aMGDFixIgR4yhETPJixIgRI0aMGDGOQsQkL0aMGDFixIgR4yhETPJixIgRI0aMGDGOQsQkL0aMGDFixIgR4yiEvtA70G1YtGiRtW7duoXejRgxYsSIESNGjEDcc889hyzLWux2X0zy6rBu3Truvvvuhd6NGDFixIgRI0aMQCiKssPrvtiujREjRowYMWLEOAoRk7wYMWLEiBEjRoyjEDHJixEjRowYMWLEOAoRk7wYMWLEiBEjRoyjEDHJixEjRowYMWLEOAoRk7wYMWLEiBEjRoyjEDHJixEjRowYMWLEOAoRk7wYMWLEiBEjRoyjEDHJixEjRowYMWLEOAoRk7wYMWLEiBEjRoyjEDHJixEjRowYMWLEOAoRk7wYMWLEiBEjRoyjEDHJixEjRowYMWLEOAoRk7wYMWLEiBEjRoyjEDHJixEjRowYMWLEOAoRk7wYMWLEiBEjRoyjEDHJixEjRowYMWLEOAoRk7wYMWLEiBEjRoyjEAtG8hRFWa0oyq8VRdmsKMojiqK8p3L7sKIov1QU5YnK3yHHc/5aUZQnFUV5TFGUyx23n6soykOV+z6vKIpSuT2lKMr3KrffoSjKunl/ozFixIgRI0aMGAuAhVTyysD7LcvaCDwFeKeiKKcAHwJ+ZVnWCcCvKv9P5b5XA6cCzwO+qCiKVtnWl4C3AydU/nte5fa3AuOWZR0P/Bvwz/PxxmLEiBEjRowYMRYaC0byLMsatSzr3sq/p4HNwErgSuB/Kg/7H+AllX9fCXzXsqyCZVnbgCeBCxRFWQ70W5b1e8uyLOCbdc+R27oaeI5U+WLEiBEjRowYMY5mdEVNXsVGPRu4A1hqWdYoCCIILKk8bCWwy/G03ZXbVlb+XX97zXMsyyoDk8BIR95EjBgxYsSIESNGF2HBSZ6iKL3ANcB7Lcua8nuoy22Wz+1+z6nfh7crinK3oih3Hzx4MGiXY8SI0QX49I2Pcs09u4MfGCNGjBjHKBaU5CmKkkAQvG9blvXDys37KxYslb8HKrfvBlY7nr4K2Fu5fZXL7TXPURRFBwaAsfr9sCzrK5ZlnWdZ1nmLFy9ux1uLESNGh3Hd/Xv5+SP7Fno3YsSIEaNrsZDdtQrwNWCzZVmfcdz1Y+CNlX+/EbjOcfurKx2z6xENFndWLN1pRVGeUtnmG+qeI7f1cuDmSt1ejBgxjnCUDJPJXGmhdyNGjBgxuhb6Ar7204DXAw8pinJ/5ba/AT4JfF9RlLcCO4FXAFiW9YiiKN8HNiE6c99pWZZRed47gP8GMsANlf9AkMhvKYryJELBe3WH31OMGDHmCSXDYnIuJnkxYsSI4YUFI3mWZd2Oe80cwHM8nvNx4OMut98NnOZye54KSYwRI8bRhVLZZGKuuNC7ESNGjBhdi4VU8mLEiBGjaRQNk2LOXOjdiBEjRoyuxYJ318aIESNGMygZJoWySb5kBD84RowYMY5BxCQvRowYRxwM08KstFDFdXkxYsSI4Y6Y5MWI0UH81dUPcPOj+xd6N446lIyqTTsRd9jGiHFU48B0nrHZuP62GcQkL0aMDuLa+/bymycOLfRuHHWoJXnxyT9GjKMZ7/7OffzttQ8t9G4ckYgbL2LE6CBMyyJfipsD2o2SUY27jO3aGDGObmw5OINF70LvxhGJWMmLEaODMCyLQtwY0HbUKHkxyYsR46hFvmRwaKYYn0ebREzyYsToECzLwrIgX45PTu1GsVwlefHUixgxjl7smZgDiB2RJhGTvBgxOgTZ/VmIT05th1PJi+3aGDGOXuyVJC++WG4KMcmLEaNDMCosLz45tR/Omrx46kWMGEcv9oxLJS8+jzaDmOTFiNEhmFaF5MVKXtsRR6jEiHFsQNq1hXJ8Hm0GMcmLEaNDqJK8+Aq03Yjt2hgxjg3ESl5riElejBgdgm3XxientkPatUlNjUlejBhHMZyNF5ZlBTw6Rj1ikhcjRodgVsSm2K5tP6SSt6g3Gdu1MWIcxZAkD2LLthnEJC9GjA5B2rWFuPGi7ShWSN7ivlQ88SJGjKMUhmmxbzJPJqEBcVJBM4hJXowYHYIRN150DKVyleRNF8q2NR4jRoyjBwem85RNiw2Le4A4qaAZxCQvRowOwYxr8joGWZO3qDeFZcF0PrZsYxy5uGfHGB+9flNcc1YH2XRx3GIx0ixW8qIjJnkxYnQIUskrmxZlIz45tRMlh10L7YlReWTvJF+6ZYtNzmPEmC/8YtN+vnb7NjaPTi/0rnQVZD2eJHmxkhcdMcmLEaNDcHKFfFww3FYU7caLCslrocO2WDb5zC8f58p//y3//PNHefxAvNDGmF9Ihernj+xb4D3pLkiSZ9u1XeKK3LH1MLvHcwu9G6EQk7xjDPftHI8tgXmCUxHqlpPT0YKyw66F5rPyHtk7yZX/8Vs+/6snOH3VAACHZ+JGjlZQMkwe3jO50LtxREE2Z9348JFP8vZOzPHSL/6WQzOFlre1Z3yOoWyCoWwS6J765nf/3318+datC70boRCTvGMIj+yd5KVf/B0/PwpOJEcCjJjkdQyNdm00YlYyqurdoZkCX33DeXz65WcAcHg2Jnmt4MZH9vHif7+9Jvoihj8keXls/zRbD84s8N60hk17p7hv5wSPtsF63jMxx8qhDKmEoCrdch6dKxrMFsoLvRuhEJO8YwhbDs4CcMe2sQXek2MDpuUked1xBVoP07T4z1u3sHl0aqF3JRLqSV5UJe//7tzJ53/1BC8+cwW//ItncNkpSxnuEds63AYF4ljG5FwJy4Idh2cXeleOGBTKBgOZBAA3PrJ/gfemNcxViFg7mqH2TsyxcjBDWq9EqHRJ2UvJNLtmX4IQk7xjCLvGRA3BvTvHF3hPjg3UkrzuuAKtx+dvfoJP3vAoV9+ze6F3JRKKjjBkgMmIjRc7D+fIJDT+7VVnMVixggYzCVQltmtbhYy32TuRX+A9OXKQL5msHs5w5qoBfv7w6ELvTkuQ57qpFkmeZVnsGZ9jxWCGdJcpeSXD6pp9CUJM8roEH7nuYb5865aOvoYkeZv2TjFXPDIO0CMZzobabgxE/vnDo3z2pieA9nSnzidKZUGgs0mdnqQWufFicq5kKycSqqow3JOK7doWIeNt9sZ2bWjkSwZpXePy05bxwO7JI9rqlk1mU3Ot2ZmTcyVmi4ZQ8iphyN1ArEzTwjCtI6bTNyZ5XYB8yeD/7trV8c6qXeM5VEVEejy4e6KjrxWju+3azaNTvO/7D3Dm6kGOX9LL5NyRRWxKhomqgKYqDGajjzZzI3kglMHYrm0NUmWNSV54FMomqYTK805dBsAvjuAu23yxPXatJLqrnDV5XWCRlirzKrvtnO6FmOR1Ae7bOUGxbNpKW6ewcyzH045fBMA9sWXbcURpvPjNEwfn7cQ+Nlvkbd+8m760zldefy5L+lJNd6cuFEqGSUITp6+BTCLy/nuRvOGeZKzktQhZL3kkq1HzDankbVjcy4lLe4/o5riqXRus5H31tq2ejSYyCHmFQ8krdIGSJ5XqbnRn3BCTvC7AH7YeBuDQTLFjHTtlw2TvRJ4zVg2wYVEP9+6Y6MjrxKgiipL35Vu38q+/eLzTu0TJMPmzb9/DgekCX3n9eSztTzOQSRxxdm3RMEnWkLxoxGxyrkS/C8kb6U3FSl6LKMVKXmRIJQ/geacu467tY22JIFkISBtzKuDCaypf4uM/28zXf7vN9X55kbByMENK756aPFlzGit5MUJDkjwQlmonMDqZxzAtVg9lOWftEPfGeXkdRxQlL1csz4uC9NHrN/GHrWP881Wnc+bqQQAGs4mWwoQXAiXDRNcUoLL/EUnqlIeSNxIreS2jWpOXj88xISGVPIDnnbYc04Jfbjoyu2znipWavAAlTzZL3bHVPe1h78Qc6YTKcE+SpKaiKN3RXSsvYrqBcIZBTPIWGPmSwX27Jrhw/TAguv46AWkFrx7Ocs6aIcZmi+zo0Gu1gplCmXd++15GJ498FcA58SLo5DRXMhnPFTs6UmvfZJ5v/n4Hb7poHS89e5V9+0AmWYm9OHIW5LJh2XZtMyTVy64d6UkynS8fMVZMN6JYOdbnSsYRpxAvFJxK3sblfawZzh6xlq2t5AXU5MkSiycOzLiq53smRGetoigoikJa17qCWJVMadcuPOEMg5jkLTBkPd4rzlsNiLq5TkAqhGuGs5y7dgiAe3Z0X13epr1T/PShUa5/4MiOEYBoESpzxTKGaXW0Nm57Jbfs0o1La24fyCQols0jxn4AYddKktdfqckLS1JLhsls0XAneZUJGmOxmtc0So628rguLxzyJYNURclTFIXnnbaM3205dMTVyoKjJi/IrnXcf9f2xrVoz7jIyJNIJ9SuOEdV7dqFJ5xhEJO8BcYfth5GVeCyU5bSl9LZPd6Zk+KusTk0VWH5QJoTlvTSl9K7Mi9PntSOhsDmGrs2QBmSAaKdtAqram6m5vbBrCA7E0dQh23JsEhW6nQGM8lIJFUuLgMZveG+kUruXpyV1zycJG90Ms7KC4NC2bSbCwAuP3UZJcPi148eWMC9ag55Oww5wK51kLw7Xc73eybyrBpykrwuUfIqx3ehCwhnGMQkb4Hxh62HOXXFAAOZBKuHsx1T8naO5VgxmEbXVFRV4aw1g12p5MkF+K7tYx21LucDURovcpXYgU4W/e8aExE6KwbrSF5F0TqSVINS2SThqMmD8CRVvs+BrHuECsSjzVpBybDoSQrCEjdfBMM0LYpl024uADh79SBL+1NHpGUrz3Vh7dq1I1nu3H645r58yeDQTIEVA9VzVUpX2xahsmssxws+9xsOTEe/CJE1p0XDrLmQ71bEJG8BIevxnrJB1OOt6SDJ2zWeY/VQ1v7/c9YM8fj+6baMnmkn5A9/cq7E4wdan324kDCdYciBdq24v5M24a7xOZYPZGybU0KSnSOpfsoZoRKVpNokzzVCJR5t1iqKhsnSgTRJXY1JXgjI2i6nkqeqCpefuoxbHj/QFepVFMj9nSmUfS/U5e/wso1L2bR3qoYUyuNmZZ2S164IlUf3TbNpdIpH9kQf5+hUqotHQF1eTPIWELIe7ykbRuDeb3Kpehe7xnIdUbB2jc3VkLxz1w5hWvDArsm2v1YrCJLwjyQYIWvySoZJufKdH+qwXVtv1UKV7ASRvJsf3c9PH+yOWsliXU4ehCepVZKXbLgvtmtbR6ks4m1WDmbimrwQkE0+TiUP4IxVg+RLJgemjqwLDll6YlkwU/S2bCfnSmiqwrNOXoJpwT2Oujw5Es9Zk5dKaG1T8uRn3pySV92HI4GAxyRvASHr8c4fnIbr/4Irtn2MdHmKg21WEXLFModmCqwZqZK8s9YMoijdN8d2Kl+iN6WzYiDt2Vp/pCCsXZtzjJgb6yC52DlWq+ZKyNmtQVlzX7plCx/76aaO7FtUlJw5eRGVSD8lry+lk9TU2K5tASXDJKmrrBhMx0peCMhzg1PJA8hWLO9ZH6LUjXCe6/yaLybnSvSndc5ZM4SuKjV12HsmhKPlLC1J62rbSJWsp2uGQEu7FoJrrbsBMclbQMh6vP67PgcoJMoz/Jl+XdstW9nM4Sxi7U8nOHFJX9fV5cloiws3jHDHtrEjKtajHmbIxgvnievwbGeu2vMlgwPTBdYMu5C8kHbn4dkio5P5rli4S4ZFQpc1eYKkBnXzSfiRPEVRxNSL2K5tGqVKvM3ygYytyMTwhpeSJ0le7gibM54vGfYFmF/zxVS+zEAmQSapccaqAe7cVq3L2zM+h6rAsoG0fVs77Vppke9vUck7EpovYpK3QJD1eJevLMD934Fz38TMya/gTdovOLjryba+ljMjz4lz1g5y387xrmpwmJor059JcMH6YQ7NFNh2aHahd6lphA1Ddp7EO6UgSaJffwyAWEx0VQlUwmS9YDeov2XDRFfr7NqwjRc5b5IHwrI9lpS8f7nxMX7ywN62bU9Y6QorBjPsn87XLIrdgt9tOcSffOvurshD9FbyRPd37ohT8gwW94na1iAlT/4GL1g/woO7J+3a5D0TeZb1p2vqh9sZoWLbtU0peQ67tguOnyDEJG+BIOvxXjrzXVBUePpfkLzsbwFY99Bn2/paUhmsV3HOWTPEVL7MFo/ZgQuBqYqEf0ElHPpIrsuTdm1S9z85zTlJXocUJK/4FBDqVVCgcNkwbRLYDepv0RGG3BOSpEpMzpXIJDQ7gqUeI72pY4bklQyTr9y2lavv2d22bRbLol5y5WAayxIh3N2Eh/dM8rb/uZsbH9nfFfvWCSWvbJh86ueP8s7v3Fvz37u+c2/NhKVOoIbk+Sh5ztGCF24Ypmxa9gXknolcTdMFQErX2kaqpJJ3YLpFkhcreTG88Ieth1mtHGTF9h/COW+EgZWkRtZytf4CTj7wM9j/SNtea9fYHJmExkhPbaG5DEXuBmVGYiovru42LOphUW/yiM7Lk0JeNumf7zRXKtuP61R3rQzDdlPyQM5/9SZJ4w4Cde/OibbumxOWZXH1PbuZyPl/DqLuS9i1YUiqE17TLiQWHUN27daDsxQNkx2H26eYy3pJWU/VDfa+xI7Ds7zpG3fazQHdMLUgqCavGSXvszc9wRdv2cLmvVM8Olr97+cP7+MHd7eP0LthrmSwtF+QPL/0BudowXPXDqEq1XxUOe3CiXRCbZs9Wq3Jaz5CBeLGixg++MPWw/y//p+hVFQ8iV8teh1zShZu+oe2vdaucdFVqShKze3rF/UwlE10hTIjIRdgRVG4YP3wEa3kSbu2J6n7doXJWY+rhjId6+rcNZYjnVBZXJnoUI+BTMK2Md0gyeea4SyP7Jns2Mntkb1TfOAHD3BDQD6YM0IFqlMvwiCI5ImavGNDyds8KiIkdo3Ptc1Wld+NXKS7JRD50EyBN379TsqmxV8972SgOxZpqeSlE7XLcU9K2rXR9vHWxw/yH7c8yavOW83NH7iEX72/+t/akWxH37NlWeRLJkv6RC1dWLu2P53glBX93LntMIZpsW8yX9NZC5Uw5DYpeXI7B2cKkeu+a2ryuuAiIQgxyVsA5EsGB3Y9zmXFm2wVT2Jk0VK+ob4UnrgRtt/eltfbNZZzLbhXFIVz1gzNC8krG2aoebQ1Ev76EfZMzLF7vLERxTAtPnTNg9zwUHdEerhB2rXZpH/BsLxSXzWUZTxX7EjA5s6xHKuGsg1EX2Iwm/StaZMNIZedspSyafHQns5E78gr+bmAha1UriV5gwEk1YkgkjfSm2KuZBxxtVDNQJI8w7TY06ZpO6IpRrWDbLshRmW2UOYt/30X+6byfO2N53Pqin6gOxZpqeTJsWYSmYqSF/RbcGL/VJ73fe9+TlzSx99fcWrD/dmk3tHjWn6eQXatZVkNv8ML1o1w384J9k7MUTKsBru2nRMvpJJXMqwalyIM4giVGIG4b+cEb+PaBhUPhFLyhdlLsfqWwy8/IsKGWoBlWeyqLPBuOGftEFsOzgbaY63ie3fv4tn/cqvvCaZkmOQcM0X96vKuuXc3371rF3959YOhyONCwEny/O1acd+qoQymRUe+i11jc65EX2IwQAmTypace9upCwPZYRe0+Dpr8iCYpDrhvJBww7GUlbdpdMqeHLKtTZZtsTKNJJPUGO5JLrhdWzJM3vHte3lk7xT/8ZpzOHftkG2NdkN3pDw31Ct52co+zhbCEYmyYfLn/3cfcyWD/3jtOTZJdCKT1DrarSvfS29KJ5vUPO3a2aKBYVq1JG/9MIWyyc8qF+4Ndm2ltrkdiQvOhpuoWXmxXRsjEI9sephXaLdSOusNNSoewJqRLAWSHDj3fbDnbtj8k5ZeazxXYrZoeC7w56wRdXn3dbDOCuDJAzPMlQzfhVNK+/1pYVOctLSP/rTeQPJmC2X+5cbHOHlZH2XT5O+ufbgro1bkBV82qYdqvJARN+2uy5NEf/VQY9OFxEA24du4IPfphKW9rBvJcm8HSJ5lWfZ3HZQkL+q+qqpkEEl1YipIyes5dkabbR6d5mnHLwJge5s62Z0Zht2QlfftP+zgtscP8omXnsZzKhcpssmhGxZpeUFTr+TpmkpSV8mVwilvn/vVE9yxbYyPveQ0jl/S6/qYTIfnvzrrC/vSOlNz7vvuFmMkL+p/dN8eAFbVkbyUJOZtUF+d29gfscM2tmtjBGLd5i+BopB65vsb7pOK26YlL4RFJ8Et/9SSmrfTIz5F4szVA2iqwn0dbr7YXylw9SMwUtqX4baqKury6psvvnzbVg5MF/j4S0/nfZedyE2bD/Czh7pvxqOMpskm/WtJcjbJE9/RoTYrSJNzJaYLZc9jAMTJdjpfpuxRl3V4toiiwFA2yTlrhrh353jbifWTB2Zs66RoBNi1LjV5Ubprg+xaOPpHmx2cLnBopsDTj19Eb0pnx+H25HM6v5tuyMobncyT0lVedf4a+7Z0GwlDq/BS8kCcO3IhlLzfPHGQf//1k7zyvFW87JxVno/LzpOSl0mq9KcTnvNr3WKMhnuSnLi0l0f3iXGW9UqeJObtInlSwY7afFGbk7fwFwlBiEnePKOYm+L82du4f/GVDSoeVGNOdk6U4CnvgAObYM+9Tb+eX3QGCJXpxKV93LdrounXCAMZVTDmY0VO2kpe9Yd/4foRth2atX+Io5NzfOW2LbzojOWcu3aItzxtPaevHOAjP36445ZzVEi7NhPBroX2K3m7xrwz8iRkILJXDc3YbIHBTAJNVThn7RCHZor2dtsFJ5kPstFKhklCd9q1gqQG1TOWDJNZR0mAG44VJU/W452yvJ91i7Jty6QsOaz0lYOZjil5k7lSqDrMfMlo6Fw9EpQ8EE1bQaRstlDmL753Pycs6eUfrjjN97GdtmvluSyta/RXLhzd4BVILtW8wWzCbjyRqFrsre9/oWTYjR1RY1Rq7dqFv0gIQkzy5hnJbD/Ku+9m/cs/6nr/ot4kmYQmFLjTrgI9A/d9s+nXs6MzPGryAM5aPcADuyY6GoosJXE/IjblI+HfuV0QgE/f+BimBR+sdMfpmsonrzqd8VyJj/90c0f2vVnI2bU9FbvWS/maKxo16e7tnnphq7k+x0B1tJn7ojk2W2S4Qn5k9M49O9vb+XzntjGW9qcYzCYo+nR6WpYliIRaa9dC8NSL6jGmez7mWKnJkyRv4/J+1o70tC1GpWiY9jSSFYNppgtlT0WnFbz/Bw/wl1c/EPi4fMlsyKDrRiUv5aLkCVLmb9fuGs9xaKbIu559gmsdXs32Om7XSlWyYtd6KXnygr6B5I0ANHTWym2K12iPkjeQTdKX1ltS8rrhIiEIMclbAPQvWsGipY0qHoiO1zXDWbEwp/vh1JfAQ9dAsbkT8K6xHCM9yYarIifOWj3IVL7M9jZmZTlhmpbDrvVvqYdaknfqin6ySY07t43x0O5JfnjvHt7ytPU1qtSpKwZ4+zM28IN7dnP7E4c68h6agW3XpvwXlLmSQTapM5xNoijtt2urGXk+NXlyaoQHCT88U2SkR9iYJy7tozelc++Oibbto2VZ3LHtMBesHyGpqb41eeXK5+q0a+35tQEkzz7Gst5KXjapk0loR71du3l0imX9aYZ6kqwf6WlLjIog4M6avM5l5R2czodSYQrlI0XJa1yOe0Iob7Ixw0+dlui8XVutyetPJzwvuiT5a1Dy1omLeneSV/nO2hCjUigbpHSVJX2pJpQ8E01VUJXuuEgIQkzyuhCrh7O2zcrZr4fiNGz6cVPb2jU2xyofmw7grNVCmbm/Q5bt4dmivTCP+9bkNV7d6ZrKuWuHuGPrGB/76SZGepL82bOOa3jue55zAusX9fA3P3ooUuRAJ+HMyQNvCzJXFIuQrqkMZhKMtVnJ2zWWYyiboC/tvQgEkSSnkqepCmetHmxrh+3OsRz7pwpcsH6YVMKf5EkiUmPXZsS+BVn2fnNrnRjpTXYsmLpbsHl0mo3L+wBYO5JtS4yKYVpYVpWAd5LkFcpmKJKWL5kN9W7dpOQVSoJwuMUbhVHyZgvi/t6Uv4ontqczVzI65to46wv7M7qnXTvloeQtG0hz6cYlXHzi4obnpHWp5LWD5Al1d2l/uim7NqEpbY106SRikteFkEqeZVmw9iIY3gD3faupbe0ad8/Ic+L4Jb30JLWOkbz9Djl8PERNXv0CfOH6YR7bP80d28Z472Un1tTsSaQTGv/0stPZOZbji7e0d/Zvs5DnUWmheM3JnCuW7XT7kd5U223CnWM533o8CLY7x2aLDPdWJ6acs2aQR/dN2QtMq5D1eBeuHyapqb6Lb6ncBiUvkOSlOHQUk7xC2WDLwRk2Lhd5cesX9QCtx6jIeiVnTR7QkeaLYtkMRdLyZaOh3k0qjd2wSBfKZoPSKBG2Jg+qs279IM8znZq5WmvXisYLtzKVybkSigJ9Lg7Tf73xfF7/lLUNt0s7uy12bckkpWsVJS+6XZvQ1LaGM3cSMcnrQqwezpArGqLwW1Hg7NfBjt/C4S2RtiOvzP2iM0AoM6evGugYyXPOhwwieUlNbbAtLtwg6jSOX9LLH52/2vP5T9kwwlM3jHDLYwdb3OP2wLRr8vxrSeZKBpnKSX64J9n2gv/d43OBJK9q1zaSJMO0GMsVWeQYi3fO2iFMCx5o0zFz57YxhnuSnLCkl6Su+S7esl7PGaEyELImLzTJO8pHmz2xf4ayadkkb+2IIHk7Wmy+kN+N7Fxc3JsioSkdU/LCFOEXXJQ8VVUCLybmC/mKkueGTFILdCZmbCUvmOTJ80yn3A7ZeJGp2LUlw3I9703OlehPJ1BV93B2N1TV1zbZtQmVJf1p9k9Fm3ohyxFSevvGrHUSMcnrQtgdttKyPfM1oKhw3/9G2s7o5Bxl0/Jf4Is52H0PFy7X2Tw61ZEr230VJW/1cMY/QmWuTH9lpJkTZ64a5HmnLuOfXnY6uuZ/yJ6xaoDH9k0H5qzNBwy7Jk+cfL2u+nJFw1b7FvW2l1wYpsXu8Zxv0wX4k7yJXBHLwrZrAc5e3d65x3duG+P8dUMoikJKV30bL2y7tm7ihdf+O+FlE9Vj5CgfbeZsugBx3PWmdLa3GKMiv5tkhbSoqsLS/s5k5RXKhu+4QIm8S00eCGXoSFDyZkPatX511xIZex6u//t+ZO8ktzx2IHB79aipyas0N7kFIgfFGLmhate2p/FC1uQVy6Znnp8bSmULXdq1XbDOBCH4qIgx75Akb9dYToQV9y+H4y+D+78Dz/p/oIX72mTERY1dO3MAdv4edt4Bu/4Aow+AWeY9aoLT1DMYvf0A6y+6ClJ9bXs/+ybzqAqcuKTPd8TR1FzJPjE4kdRV/vP154Z6rVNXDlA0TJ44MM2pKwaa3ud2QNq1tkXisaDk65S8dtaC7Z/KUzIs36YLELWPfSnddWqE3J9hx9zbgWyCE5b0tqUub3Ryjp1jOd540TpAfN9+Co0byfMjqU5EsWvHZotYluU5Cu5IxubRadIJ1bZpFUVh7Ui25eYrt+9mxWBnsvIKZTPUCMB8yWSkp/HiMBWgGM8XgpS8QLu2cn9PiJo8eS6aCyC3X7plCw/unuS2v1oSuE0nnDV5sgZ4Kl9iSX+65nFNkbxE+yx2QfI0e78OTOd9m7GcKJnCrk3p3XGREIRYyetCyFBcu/kC4JzXw8w+ePKm0NvZVR+d8fA18JmN8P03wN1fAz0NF/05vOK/mTvrLZymbmP9re+BTx8P33s97H+kLe9n31SexX0pFlUWTi9M5aP/8OtxWmUm5SN7plraTjtgWrWNF15XoLmiUa3J60kxnit5hhJHhTwGguoyQRA3twgVaR+POJQ8ENNS7mtD9M6djno8ILyS51gYJUkNmnoxOVcik9BcM8mcWNSbpGiYTLep5rDbsHl0ipOW9qE57LJ1i3pannrhVi+5cjDTkfm1svEiyGoT1lzj951O+F9MzBfccvwkZDes33ucLZRJaErgMQ3h7dqZQtlzJJkf5hw1eXJy0aSLStYcyWtj40Wp2l0L0aZelAxL2LVx40WMZpFJioLQnU6Sd8LlkF0UqQFj13gOTVVYPpiGx26AH74dVl0Af/wr+NAuePPP4NKPwKkvpeeKT/Gy5Ff47OrPwzlvgO23w7deCpO7W34/+6fydlTDeK7oecKSdRqtYN1ID70pnYf3Tra0nXbAcEy8AO+T01ypatfKjLaoQ7O9ECYjT2Igk3ANl7WVvDqSd+7aISZyJba2SAzu2DZGX0q3rcOgCBW7uL+unqc/kwicXxt2cZHv9Wi0bC3LYvO+Kfvzllg3km05RqW+Jg9EVt6+qXwo1S0sLMuiWDYxrdpwWjcUSqZt9TmR0rujJk9ah27oSekYpuV70TNbKIdquoDwdm2uYISemetEoWSgKOKzlSUR7bJr7dibNk28SCWqJC9K80WpbAq7tkuOnyDEJK9LYWflSehJOPPV8PjPheUaArvGciwfSJPYfit8/42w7Ax4zfdg1Xlie3U4c80wPzy8Bl7waUEAizn4v1c3ndEnsW8yz9L+NMM9ohB31uMEEzRTNAxUVeGUFf08vGfhSZ5U8rK2kufVXVu1a2UWXbsCkXeNz6EojSOC3DCYTbh2p3oqeWvbU5d357Yxzls3ZKtKqURAd62LJQhi/4MmIIRdXORos3bH2XQD9k8VmMiVXEheT8sxKnZNXp1da5hW5C5GPziPj6AOx3zJcA0aTie0thTxtwo/JU+eF/xGm80UjFBNF1A9F80FzMOdLZYpGmbk2uZ8hbAqimIreW5TdERpTkSS16aJF5Zludi14X/nZbPaXdsNSnAQYpLXpVgznG0cG3X268EswwPfDbWNnWM5Ls1uhe++BkaOh9ddIwKWPXDWmkF2juVE4f+SjfCKbwjL9odvB7P5K5Z9U3mWD6TtqQpeWXnNXN254bQVA2wanWqrctAMpI2ZSfpfgTrtWqkgjbVJQdo9lmPFQMYuhPfDYCbpanfKfRmqI3kbFvUwkElwbwt1eYdmCjx5YMZOuocwSl6jXQsVkhdg107kQpK8ynttdzB1N6C+6UJiXRtiVLxq8qC9WXnFmvmh/uemQtlbyeuGsVSi8cJLyauQPB8yMVsoh6rHA6dd6/++pdIXNSLJecEqXZn6jnfLslqqyWtVPZPHTkpX6U3p9CQ1DkSwa4uVsX3pRHccP0GISV6XYtVwlr2Tc7WL3ZKTYdX5cPtn4Advgl9/Ah66WjRP5KegzgbtPfwQHxr/MPSvgDdcC9lh39c8a/UgAA/urqhgJ1wGz/04PHo93Ow+hi0IuWKZ6XyZpQNphiXJc4lRsSyLqXzZtfEiKk5b2U++ZLL14EzL22oFhmWhqdVaGT+7Nu3orgXaltG2cyxnz8QNQn8m4dq4MDZboD+tNyhnqqpwzprBlpS8uyvj6uT4OhCNF34kr2jXfdXatQMZdyXSicmQCsLRPNpsU4Xknby8trlqXRtiVNwIuMzK29PG5gsnsQuqizoSlDyverpMRXnL+ZCt2WI5VGctVEtHwgYsz0QkeU5VsmrX1m5jrmRQMqzIJC+pqShK6zV59RNGlvSn2R/RrhURKt1x/AQh7q7tUqwZzmJZsGdizu6AA4SV+utPwN77YdN1YDkWQ1WH9CBkBjFTA3yhvJliepD0G34MvcFdUqevHEBV4L5dEzzr5Mrjn/IOOPSYIJaLTxKWcQTIjDxZkwe4Nl/MFg0MM/oP3w2nrRRdtQ/vneSEpe3rEo4KwwRNUXwHaxumqC3KJsRPsarktcuuzXHxCY3p8W4QSlhjR+mh2aJtX9ZjzXCW+1rIyrtj2xiZhMbpK6ud0CldC9V4kawjnQOZZKgIlYEVUWry5seu/e2Th3h8/zRvftr6jr/W5tEpVg1lGupf2xGj4kbAl1dmMo+2UclzLq5+C23ZMCmblqeS5zWRYT4h68Pc0BOihm62ULabu4KQCdldK18vMskrm7aSl9JVEprSML9WxpVEPdcrikJab73ZQV4gSPt3cV+KgxGUvKpde2QoeTHJ61I4Y1RqSN6Ks+G1PxD/LuVhbCscehwmdsDcOMxNQH6CucnD3GOeiPGMT3LZgPuc3Hr0pHROXNpXG4qsKPCCfxFBzD9+N/QshuOfE/p9yIy8Zf1phiot6m5Knj2wusXGCxA2Yjqh8vCeKV56dsubaxqWZaGqztb/xhOCHR5asXQHs0lUhbYEIudLBvunCqE6a0FkzZUMy56lKzE2U2yox5NIhwhr9cMdW8c4Z+1gjZ3cTIQKeJNUJ8LaRCldDFhvdzC1F665dze3PnawbSTPNC2++putvPCM5Xa3vsTm0camC2hPjIobAe9LJ+hL6221a2tq8nwWWvk4Nzt0PpS8mzbtJ5vUuOj4RZ6PyVemL7ghTKPEbMFgcZ/7RVg9siG2Z1mWnc3XjF0ryZOoy2ucXxs2xsgN7SBW8juXSt7S/jQP7Z4I/fyiYZFNHjkTL2KS16VoCER2QyINS0+BpadgWRbbDs1y784J7t05zh2Th9lSmuWHq0+O9LpnrR7khof31S6UWgJe+U342mXwvy+DtU+Hp/+FIHsBGWJypNnSgbStjozPNqotUy388Ouhayobly9884VhWqgOJc/tClTaJtKW0VSFoWx7pl7srhTQB2XkSTiz5mpI3myRtSPuRDGT0Oy8Mi1Cej2Ik/3mfVO89zkn1tyebCIMWe6/G0l1Pm+2aIQ+xhb1puaN5JUMUafUrly+zfum+KcbHuW7d+3i6j99qq3E5ksG2w7N8sIzVrg+b92iHh5p4Xfj9d2IGJX22bXFcji7Vt7n1r3a6Zq8e3eO86f/ew/nrh3yJXmFsuFdkyftWh97daYQ3q6ViqbfhVmhbNqVP1GVvPr30pdunF9rX9A3UZqTaoeSV2/X9qXsqRdhfnulcpyTF6MNWNKXIqmrtVl5HvjdlkOc+7GbePa/3soHfvAAP7l/LysGM/zl5Sdx5qrBSK971upBJudKbKuvy8kOw9tvhcs/IdTDb18F/3mxqAk0vE8E+yaFDL6sPy3G2CgBSl4bSB5Umi/2TnVsEHcYGJaFpigkNBVNVVyv+vKVAuiMo7tupE1TL3aNh8/IA6GEQWOg8OHZol2jVo9MC9lVj+2bxrJEw48TKV2lZFie312xEpmR1GtPyEFTL6oXEuEWl+F5HG1WLBuUTSsw2iIsHh2dBsRF4lv++y5bkXls3zSmBacsdy9jWDeSZXcLMSpeJE8EIndGyfMrxK8qeW45eZ1T8iZyRd79nfsom1bgxIqCj5IXRnmbLZZDd9eqqkI6ofratU71LmqMirPxAsT5vN6ubVXJa7Xxokr8xX4u6UsxVzJCE1oxu1apHD9mpJFoC4GY5HUpVFVh9VDGX8mr4NbHDjKdL/HJl53OL/7iGTzwkefyrbdeyDufdXxkdUUuuA+4ydepXnjqO+E9D8CV/wHlPFzzVvjvF0LZfTHcP5WnL6XTk9JRVYXBrPtEh3YqeSCaL6YL5VCfX6dgWdizGdMeqkGuJIeLV0+M7Zp60RCGHYCBjCByzqw507QYzxUbMvIkwibou0HGkyyuq/eT1q2Xmlcqe9u14E3y7MUlZLL9SJunj/hBZr3VL4jN4tF9U6R0lf94zdk8tGeSd37nXkqG6dlZK7FupIdyCzEqXgR8xWCavZNtJHmO4y2Mkuc61qxDSp5lWXzgBw9yYDrPCUt6fQmazMDzUvLkSEQ/JS9XMEIreSBiVHy359jfmUK047F+hFz77do2KnkJ2Xghs/LCXdCVTcuOULEs7/NUtyAmeV2MNcNZdoQogt52aJY1w1lefcEaTlzaF2nocz1OWNJHNqlx/84J7wfpSTj7dfDOO+HFnxfj0X7+164P3TeZZ+lAdaTNUNa9g9P1h29ZML4dNv0YbvsX2HprQwexF+RIs4UMRRZ2rfi318lJ2iaZpFPJS7Wlq3PXWI6Uroau15EkyXlSnsqXMEyL4R73baQTwfaPF8Yqtn09gZT1XF5X7OVKnE/9HGNJUr1iVKIuLiO9qXmLUJEKWFAETFhsHp3mpGV9PO+05Xz8padzy2MH+dA1D7FpdIqepOZJ/FuNUfEi4CsGM0zkSpFrvLwQtiZP3udq13ZIyfva7du4afN+PvT8jZyzZsg3465oW4ceSl7CX8krlk2Khmk3aIRBJqH5Rqg4lceZiEpevmSGtmubIXmpNsyLLdQdE0v7Kll5IZsvig67FtozS7eTiGvyuhjrFvVwx7axwFqBHYfrmjNagKYqnL5yoLb5wguqCue+EQ4/Cb/7PKy+oKH7dl9l2oXEkJeSVzkRDJQPwy8+AXvuhX0PQ6GOpA0fB+e+Cc56DfR417mcuLSPhKbw8J4pXuRRf9RpyAgVkCTPpfFCkjynXdvTnpq8XWNzrB7Ohq7xcpv/6hWELBG2W88N0rYfrFPWZOG2V4yKVIvcIlQAJj2mXkQmeT1JxmYLmKbV0oVTGEjSEhTmHBaP7pvi2ZUO+T+6YA0Hpgr8202Pk9RV0UXv8X5qYlROiv66duOF3liTB2JO8fFLWu94D1uTJ0mcq11bUfLaOZ/4vp3jfPKGR7nslKW85Wnr+IefbPK1a52zXt0Q1HghSXMUJS+T1HzDkJ0WbTONFw1Knodd29dEk126DXVw1caLil3bH23qhbRr7XDmsgG0x4HqBGIlr4uxYVEPuaLhO1fPNC22H561T87twFlrBtk0OhX+x/Scj4hmjJ+8VxAzB/ZPiWkXEnK0WT2mcnneoP2Cvq9dBH/4TzCKcPpV8KLPwh/fDH+1DV76ZdHd+8u/EzN4r34L3P11ePxG8bq5MVvpS+oqJy3r45EFVPIsSzRegLAG3Gry5MnbadeO9KSYnCu1NF4KRD3W6pAZeeCwOx1qktdIM4mwszDdMD5bJJvUGhbglK3kuW9TqkX1ESqh7drQSl4S0yIwe68dkN+123SAqDg4XeDQTJGTl1Ut2T9/zvG85sI1FMsmGz3q8UDEqPQktaZjVLxq8pYPyEDk9jRfhJ14YSt5LiTKvphok902kSvyru/cx9L+NP/y8jNRFIWelP/sWb+aQRBqk6YqnvbqTBMkT87D9YLztaKSvEK9XZvR7cgUiam5En1pPXIpEVTU1zbZtZJYL46o5Nl2beVCJiiMe6ERK3ldjA2LewHYemiGZQ7L04n903kKZZO1bVLyAM5ePUjJsNg0OsU5a4aCn6Dp8PKvw5efAd9/Pbzt15AZrIwyKrCsPwk7fgd77uV8s4cnZusUuNEHecX9f8KqxCZYeQm88DMwclzj65z5avHfgc1wz//AA/8HD19T+5hEFobWwcjxvE8d5KbdA1h7EihLTwU9nG3ZLsjuWhBdbW4nJztCxXFiHJbza2eL9tidZrBrPMd560J8fxVkEhpJTa2xDGXjgSfJa6UmL1dkKNu4Xbsmz0PJ84tQAW9SNhWxucc52szr/bcL8r22w659dF9j2LGiKHz0ytNYMZDm0lOWej5XURTWLeppOkalqrLWfjdSzZeRSq2iJifPz66tU22ckHabHHHVKv722oc5MJ3nB396kV33mU2K2bNiqkXja/h1/4L4PrIJzbMBQqqEYRsvQNq1/pEsEtORw5Brp4v0pROV8GPTPiZamWyU1lUOtGrX1lnk/WmdlK6GV/LK1bFm0Ho4c6cRk7wuhrRgtx2a5aLj3K1J2QW7vp1K3mpBDO7fORGO5AH0LYVX/o9owrj2z+DV3+bw4UP8kfIL3vbwbfCHLQC8HXirpWB96VSUVeeDqsHd32BA7ecfEu/lI6//+8BYFpZshOd/Ep77MZjZD1N7YWq3+Du5R3T/7n+ES8a382zLgK9+AY57Nrz+R81/KE3AMHHYte5F3m41eYscI7WaJXmTuRLT+XLozlqo5FrVTb2w7dqA7tpmlLyJXMmVPAU2XniQvExCI6EpbavJc34PxwdnibeEdtbkyc5ap5IH4lh817NPCHz+upGephVwr6BqaYntn5xfJU8SQDc7NOVYpNuRz/nbJw/xkrNW2pODoBpmXG9j2vsXoOQBZFPepEwSsqh2rV9DkVTyVKUJu7Zk2JmfgD2/djpftn/rLZG8djRe1BFrRVFY2p/2dcycKBomCd0ZjRUreTGaxLL+NOmEytaD3lfVsjHDK8esqdetZNo9cSB4LNiTB6aZK5qcvmoA1jxFEK+ffwi+eQUju+/hY4lZphKnwRX/Dsdfys9u+iVP3Ptr3pkZQ3/4GihMwblv4m8OXMmWmUQwwXNC02FgpfiP8xvufnDbft7/lev4zrobWLr3/vDbbRNkGDJ45zu5Knk+k0HCQsanhB1pJiEDhSXk3NqOKHmzxYZ6PHAoLB4nT6+aPEVRfKdeTM6VSCfU0KrN8DyONrO7a9tA8jbvm2Jpf6pp9XHdoiw3PrKvRn0Ji2rjRe13k05oDGYTkcZH+aEYsvEiqCYP2mO3WZbFdL7MoromJ9kdO1ssN8x+hmAlDyrdsB6/L7smL0LjRTapsXvcL5JF3LeoNxWJ5JUMkZfpVPKkaj41V2oTyWtHGHKjhb+kLxVaySubFglVdSjB3a3kxTV5XQxVVVi/qLcxs86B7YdmSWqqPQS8XVjWn7aDjP3w0es382ffuad6w4V/Cqe/AnbdyejKy7mi8FF2XPUzOOf10L+cmTXP4t/KL2f0iv+DD+6AD26HF3+OfaV02+JTJE5etYjtyioeTZ4Kc2NiGsg8QubkgXe+U7Umr3q9JW3Cw7PNZ7Qdqtisst4kLAYziVq7drZIX0r36f4T+91UTZ5HNEsYJS+hKa7F8vUk1Ymoi8tIT9Wu7TTaateOTjeoeFGwtoUYlZJhoii41lst60/buZmtotaubTIMuaZwvjXkS2J8Wr0iGJRzF0rJS2qes2ubarxI6L6/V/laS/pTkcKQ3eJqZHOFs8O2ZSWvxe+r3q4F8V7DRKgYpoXhiFCB7lfyYpLX5diwqMef5B2eZfVwpqkiVj8sH0gzGsJa2TMxx66xOUZlBpaiwEu/Ah/cwc0nfYQHreNYOlC9upU1WOO5oujOzQg7WAyOb6+wnE5oHL+4l4dyFct5fJvv4x/ZO8nfXvtQyw0PEjU1eV4RKi6L0EhP6wqSbG4ZCpkJJzFQZ9eOzRZtRcsN6Yo101R37axHTZ4WUJNX9laY6vffiaiLy1A2gaIwLzEqktC2quSVDJMnD8zU1ONFhSwTaaYur2iIBdCNgC8NeeEYBlJ960n623e+YchtjMCYzsuO0dpzmJxY4aWIhVPyvBslJAmLVJOXDAhDLhooilDyopA8uc20Q1WUdq2zw3Zqoe3acuNnvqQvHWp+rV0qoiuOcZWxkhejBaxf1MPOsZzngrf9UPviU5xYNpBmX0B4qWVZ9tDxu7aPV+9QVUik2TeZR1cVFjky1oZ7xI+73oqcmiu3XckDOHVlP78dF5l5jPmTvNseP8T//mEn1963py2vbVrV6A2vK9C5YplMQquJtBjIJNBUpSUlb9wjgy4IA1kXkuezjWZr8kqGyVS+7EryUpo41v0aL7xI3vKBtG1V12NyrsRgJvznoWsqg5lES99DWLRLydt2aJaiYbKxJSVPlH5s97m49ELJMBvq8SSW9afb2HhhoipCwfLPyfMJQ26jkie7outJXpCS57d/1W14hxfL7bY1DLlQJpvQ6EsnIk28sOsfHeTJaddKtKLkpRyxN82iPicPhJI3XSj7fi7gIHlqteyj1QkcnUZM8rocGxb3YJiW68JlmhY7xmZZ28amC4ll/WnGcyXfq5TpQtmu37h7+1jD/fum8izpS9UQGLmo16strfzw/XD6ygEemAmn5BmVkN1///WTlNug5pkmNXat68SLolHTdAHCpvfKEwyL8VwRVSFyQflgJtlg13pl5AFkn/wZ79e/H1nJk9+/JP02xrZy+v+eyYvU33tHqJhWQ82XxMbl/ewam7OVFScm58qRx+a1K5g6CNUIldZInpxo0YqSt7g31XSMirTS3bC0P8WhmUJbfltFQ3TEBo0m8wtDbmdNnvze6n9vPfbECn+7tlUlLxsxDDlfMj3HBs4WDbIpnd6U1pRd6zyf9TkaL+RjCmWz6fGVkgy3EntTKJsk9Vq1eUnIGJWyox44VvJitAVSpXNrvtg/nSdfMu2U+nZCRrb42SujlcwrTVW4c1sjyds/VTvtAqokz0lgimWTuTZ1uNXjtJUD5EhTSC8WXbc+kOeNHYdz/KgNap5hWXYfiV/jRcblKn5Rb7Ilm3A8V2Qwm4wc4juYTTBTKNukwzc+JD+J9tP38m79WvSZvZFeZ8IOQq7b9s0fQyvN8krtFs8rZD+79uRlgtw8vn+64b5mbKIzkqN8cPtbxbSVDqJdSt6j+6ZJaAobFvU2vQ1FUVg70mMTxijwU1mXDqSxLDjYhnnAhZJBKqEGFuIXygaaqrjuk91d2wYlbzpQyfO3a4OVPO/GC11VfEliPSQJ83rfuWKZnqRGT1KP1Hhh27VujRcVEhw1xqge7ZgyUSgbDZ/Xkr5wo82qdq2jJi9uvIjRCuTJetuhxk7X7YfElfa6NnbWSsjwUr+6PFmH97TjF/HY/umGBWrfZO20CxA/blWhJhBZngDCzhSNgo3L+1EUOJxcAWPbfR9rVCyAU1f0t0XNM83aiRduisFc0XC9Cm91fu34bMm1czUIAw57xbKsil3rkS94+7+JhhZg3cFfR3od15DlvffDw9dgZBZxkfoIzB5yfa4fkTi5MpN102gjyWtGLX5t/v9YV94G338DHN4S6blhYZoW5Yqq0jLJG53iuMW9DRMnouIFpy/jjm1j3P6E+3fghWLZ8vxu7Ky8NsSoiGw7NbAQX+S2ue+PVGLaoeRVa/LqGy9kTV6Akucx8UJsQ/MkibOFMj0pPdLEjiALebZgkE2KeeO5ooHhofjVI2/H1VTPZ71JHUWpkrtWRpo5t91KILJbLqIM7A/qsC067FpJZrs9DDkmeV2OgWyCkZ6ka/OFLIxu57QLiTBKnjxZX3HmCiwL7t0xXnP//qlCzbQLEKrfYLZ26oX84XdCyetN6axf1MN2c0mgkmdWZs2+99IT26LmmTVjzVSKlYgBJ0SuVCPJEzZhCzV5uSLDLvVuQXAGCk/ly5QMy92undwNf/gSnPEqtiqrOGksGsmrNoY4tv2rf4DMMFMv/hq6YrJszy9dn1syvO3aFQNp+tI6j9apUGXDZKYQse7z0BOcPXMr13MxKCp851Ud6dAumdVFon46QFQ8um+ajcubr8eT+OOLN7B2JMuHf/ywZ22kG0qG6Ukw5bmgHc0X0nJLBYy5KpQNW7Grh1zoO6rkpcIpeX6xPtmkZpfF1GOmYERquoDgOtpcsUxPSrPfi99YNifsOChHTp6qKvSmdLtmsV0kryUlr2R6KnlBWXm2XasrNjGPlbwYLWP9oh62uNi12w93Jj4FqiTPT8nbO5lHUeC5py5FVxXudNTlzRTKzBTKrpM6BrMJuzEAqld5najJA1g7nGWrsQSm90LJu5nEsCx0VeXSjUvaouYZFvYVdtqjyDtXdLdrW51fKzLoopO86vzXkv9Is19/QoyQe/bf8hv9ItbnHoSZg6FfZ7xSkzcka/K23gJbboZnfABl7VPZYi5n9ejPXZ9b9FHyFEVh47J+Ht1Xq+TZs5GjdHD/5jMYapKP5F9D+RXfhPHtcPWbwWh99JgTkkQNZMR0gCikyomJXJHRybxtWbeCdELjIy8+ha0HZ/n6b/1rWZ3wr8mTJK91u7ZYrtbk+TdeeCt5QXmMUeDVXZut/LaDlDyv2bUg1MBiufECEaqELDRMk2xCfD+udbT5Sc6cvpV3TX+Op2z/YmXfwx3vXoTVOb+2KZJnmnDf/8KWm6t2bQvEShD/xmk5SS146oUziL0d1vF8ICZ5RwDWe8SobD/UmfgUEApYX0r3tVb2Tc6xpC9FfzrBaSsHapov5PPq7VqA4bqmAlvJa3OEioSmquxRl4v/Gd/u+TgxiF4Qhfc854SW1TzTtJDrnVdcQ95LyetJMp0vN935J6ZJNG/XTuZKdj5cQ4TKvofg/u/AhX8Cg2u4M/10VEx47KehX0d+/0PZpCCLN/09DKyG895KMqFxvfkUlo3fA9P7G57rpxaBaDp4bN90TWG5rAEMXRIwvh0e/B5Prn4FhxlgbPH58KLPCCJ649+Efp9hIIOQF/VWw2KbgSS2J7dByQN49slLuXTjUj7/qyeqEUkB8LPSR3qSJDSlLR22sq4qpWu+3Y35kvukCXCqQu1R8lSlGpkioVfIQK7kTpQKJRFX4tWRDP51fTOFck3Gpi9yY/DFC3n+dWdxY/KvWHLD2+BXH4UHvgu3fxa+8UL41AY+OPUJLsr9itO2fJWnqJsik7z6z7s/k7AV6sgk79AT8I3nw3XvhGveRlYV22mFmLvZtYqisLgvFRijIu1aXRWNGyldbXmWbqcRk7wjABsW93JwutDQMbjjcK4jVq3EsoG078l9dDLPskrt3gXrh3lg16T9Q5eWjJuSN9STrKvJkypLZ5Q8TYU9VEieT4xK2ayGF192ylJOWd6amldr17ovKDmvmjx7fm30Bd+yLM+5sEGQ6p+17wEKux8EqInAAeCXH4H0AFz8PgBG08exX1sOm34c+nXGZ4tkk0KJYdO1sPc+uOSvIZEmqalcbzxVEMdN1zU8N2gSw8nL+pkplNkzUT12Iy8uv/0cqBp7T30bUMksPOcN8JR3wp1fhru/Hvq9BkEqd4srllGzHbbSot7YBiVP4iMvPgXDtPjYTzeHerzMyXODqios6Uu3ZbRZtSbPf5GVtq4bnLNrW8V0vkxvSndtdOpJ6eR8lLyU7p4rKFG1fBu3MVsoh7NrTRN++HYY387+E1/LTmspqbFHRV3tj/4EbvoI5Cfhoj/nHcmP8/cn/YR8djl/q/8vMyGPR7fuWhDq5nRUJc8oC+L5pafBwUfF7y53iNV7rhev1ZKS12jXgohRCZrIIu3apC6+r5TuHnLfTYhJ3hEA5wxbCdO02H54tiOdtRLLBtLs87myGZ3Ms7yi1J23doiiYfLQHjHz0k/JG8om3GvyOkTydFVll1IZPupTl2eY1Vw7RVF476VCzbv2/midozXbU/xJntdMSzlt4VATdXnS8nMboxSEwcp3cN4d7+Wpv3wJn9C/yiLVUd+25WbY8it4xl/aQdaZlM7vU0+DbbfC3LjbZhtgk1CjJNSExRvhzFcDQv3YqqzmYGYDPPLDhueWyt41eVCND3F2h0YieVN7hT101mvpWbRa7K9Unp/7UTj+MvjZX8Lmn4R6r0GQFtCiyqSTVpS84Z6kTRbbgdXDWf7skuP56YOj/PbJ4CaMYtnwVaWW9qfao+SVBHkLCsf1U/LaSfKm5koNTRcSmYTmWdeWLxmBY/b8GiVmC0Y4u/b2f4UnfwnP+ycOPO0feFvp/fz+BTfC/9sH77wL3rcZ3nE7XPoRfl8+ET3Tx+5z/orT1O1kN/8gePs4Gi/qCJSwa2uVPBmSzCPXwp1fhfu+DY/8CB7/hfjva5cK4nnCZfDOO+Hyj8PS01n16DcAqyX1tVBq7K6FymizACWvfm52O8KZO42Y5B0BOG5xI8k7MF3oWHyKhBhD5K3k7ZvMs3xQkLjz1w0D2FEq+4KUvNmSHWg51cHGCxAKwoTVJ9Qnn6w8p/IGVTXvCzc/0ZSaZ1pOkudu186V3JW8kd7m59dWrdDon2d/JoFOmd65vYxn1/EK7TaWffNpcMdXoFyEX34YBtfABW+zn5NJ6NyqPRXMMjx+Y6jXmciVRD3efd+CsS3wnA+DWv0ckprKpuHnwM7fw2StZV4y/ZW8k5YKkuesy4tE8n73BTANePp7bZXEtqxUDV7+NVh+Fnzv9fCbzwi7uQUU20TyNu+b5uRlfZE6LcPgT565gTXDWT7y40cC6wVLhkVC9379dk29KFRy8lK6St5nnwol07PeTddUdFVpyyI9lS831ONJ9KQ0XyXPrx4PnB267nZtYBDytttEDe1pL4fz3morbbmiAXoSFp8I/Svsh+cKIievsPGl3G8ex5r7/gWKwcHY3natXtNd25vS0TVVlH384I3wsw/AdX8GP3gTfOcV4r+JXfDyb8Cr/hf6lopJSk99J9mJx7lYfajFCBXTtRlnSV86MEKlGJO8GJ3AmpEsilKblScJXyfiUySWD6Q5OO0eXjqVLzFTKLO8QuKGepKcsKSXuyp1efsm8wxkEq5X0cPZJEXDtK9Mp+ZKdhxCJ6ApogmCofW+dq3hsGtBqHlvumgdOw7nfEfL+W6vQhq9MrlylYkX9bBHmzUxbUEGDTdj12qqwgnpCVRMfrPktbzU+hTKirPhhr+Ez50hTszP+QjoVbUok9R40NwA/StDW7Zjs0WWpk245Z9h9VPgpOfX3J9KqDzQ/2zxP3WWbZBd25PSWTuS5dF9VSUvdD7X7CG4+xtwxqtgaJ17mG16AN50PZz2MtER/KM/hVLzxKXBrm2C5BmmxeP7WptZ64V0QuPvrziFJw/M8I2AJoyg70aQvDbl5IVQ8kTtnvd5RYQpt6fxwusiNZvU26LkuTVK5IoBdu30Prj6rTByArz4c6Ao9vnGTRkslk2KhklPUqM3neSjpdeRzh8QFz4BmPMieemEbdfWTDa686ugZ+DP74P3PADv+D289SZ4w4/h3XeL35fzguW0qyhnl/LH2s9aU/K87Nq+FJNz/gMAnGHI4r3Gdm2MNiCla6wayrDVQTR2dDA+RWLZQAbTI7xU2rEyTw/gvHXD3LNjHMO02DfVmJEnUR+ILObWdkbFA6HkGaYFwxt87dp6JQ+qzSCyOD4KTIvqWDMZ1+A4gZimRb5kknEpnJZ2bTPTFmwlrwm7FuDk1GEAdpmLmejZAK+/Fl75LVATsPpCOPVlNY/PJFRmSxac/CJh5RYaMx3rMZ4r8sLijTCzDy79SO3JHKHk7dVXwbLTGyzbILsWRCjyo6NNKHm//w8o5+16w57KAtuwSCcycNXX4Fl/Cw9+F/7nxTBzwH/bHqjateL7aobk7RzLMVcyWpp04Ydnn7yUpx0/wrfv2On7uKJPUDUIZV923reCYkWNEWHIhueYq7yPkgcERrCExXSAkucVVxK0f+Cv5MlMO1cYZbj6LVCcgVd+E1K9le15R6jI22RO3j3WSWxf+lxRozo16ruf+ZIYaddwDk3rTBfKmKZVPdfPjcOD34czXiHOy0PrYOkpsPp82PBMuxSkBnqSmTPezDO1B0keftR3X/zgZdfK7u+DPmpevV3rFXLfTYhJ3hGCDYt6awKRt3UwPkViuU+Myt5KUftyhx17wfohpvNlHts37TrtQkKSD6k4TeU7M9JMQlMkyVsPk7tEHZgLnMqb/VxVte+LCmHXin+7Ba9KVc/Nru3P6Oiq0lSMimsGXQQcpwuS92RpRCiKigKnXCGutt/0UzGb2IFMQhNX8adcIQjSE78IfI3Z2RkunfgerLsY1l7UcH9SV4XCdepLYfddMFElF7ZaNDUKefepDCcv62fb4Vl70ZqcK5FOqP6qydw43PVfcOpLYNEJAGSlkudmtykKPPMvxQK67yH46rObCkyWSp4k9s3YtdWmi/YreRLrRnoCOy39ZtdC+wKRC2XxOmldw7Sww6TrkS971+RBG5W8QsmT5Aklz8uu9d8/8Xx3UiZVt16vmrxffwx2/BZe9FlYcrJ9c8ZHGZQXMz0pzVYIf7P2naIU4+aP+e5nvtQYTQJCPbcsmCmWK1NndFGDV56D89/msiVvlM5+I3NWkuO2fjPS85xw664FWNwvp154H5uNNXn+E1e6ATHJO0KwflEP2w7O2lesOw7lOhafIrHU54RsN1Y4iNx5a0Vd3t07xirTLtwLwGW0x1jOoeR5nCDbAV1TxDSL4Q3iZDW5y/VxZUejhP3cyudbNqP/kJ32r1vjhTxpu9m1iqKIqRdNKHnjLdTkAaxRD1JCZ0u+rzYjT1VBa9xmJqmLBWPNU6FncWBDQskwubx0M/2lQ/CMD7g+JqWrFAyzqho+8iP7PrNc4IVj3xL28VeeCeM7Gp6/cXkfllUdbxY47eLgY/D15wvV4+LqPsnvxjcQ9pQr4S0/F1bvHV/2fpwHZJ1Pb1onnVDtIvUo2LxvGlWBE5Y2P84sCEFxJeAfVA2OyQJTedHN+b9XweiDkfdF1FWpng1N9uNcgm+daKeS5+VG+E2syAfsH1RjWeqJoiTcrjV5U3tFd+rZr4MzX1Vzl3QV3OxauZ/ZpE5KFzWLo+oyEZd0/7dh9AFRgzq5BzZfL4jf1W+FH7+b5+z8HO9Sr4Hff1GUWJhi+875tZNzJQZSGtz1VXG+WH6G73uvR7J/MVcbz2Dd3p82rZy75eRBNRDZT8krNti1/hNXugExyTtCsGFxD7NFwy4M3X54tqNWLQQoeZUgZOdEi1VDGZYPpPn9lsMcmil42rUypkOSkZo6jQ5AVRSRmTa0XtzgUZdnuip54v+bU/Icdq1LTZ48ybrl5EFl6kUTNXnjuRKK0nwkzUprP/uVxRzKGd4jzRzIJDQR1ooKJ79QKHk+NWoT0zneof+YgwNnwPpnuj4mqVfGwA2vhxVnw8MVy3bnH/h64X08/9DXRZdr7jB8/XmCpDkgpz7Iujxfkvfg9+Erz4LZg/C6a2DZafZdmipqmLxGQNlYcZawmw6GixpxQip5CU1lIJNgMteckrdhcW/H6lpB1EkGEaLgmjxxPO2bysNDP4Anb4J7o6syMifPq6FJIkjJS7VBybMsy9euzSZ1nzDkYCXPVt7qiOKMH8nb9GPAgove03CXWjmm67cH1dDmnpSGoij0pCrzay/+gLBQv/Nq+JcT4N9Oge+9VjQe7b4LHv8FFxy+jj8xvwc3/rUYA3jbp4FqQ93UXInJuRIXGPeKHMoLoql4IJSzrxvPRzeLcNfXIj8fvIl/r1v9bR3KDXatGo81i9EeyBm2Ww/Ozkt8CogU8JSuunbD7ZucY3FvquaErigK568b5pbHDmJaeNq1ctzWeG5+avI01aHkgWddnmHRXpJnNtq1zsXIzpXyOMk3O/ViPFekP50QHWxNYKmxn93WYg7PFu0uXz/IMUZzJQM2XiHUsC03ez7eeOD7rFIOsfWUdzTU4kkkddVWuDj1ZTB6P1zzx/D1y8lYeb65/lPwR9+BN/1MqLNffx7sudd+/uqhLNmkxuZRHyWvNAc/eQ/88G2w/Ez409vhuGc37EtPSgsXCLtkIxyITvJkvWdKV+lPJ5qzayudtZ1EWtcom5Zvp3nJMEn4KFNS+d83lYd7vyVufPznkTuUpeWWcql1dcIvQgXao+TJ+a5eESo9LSp5XhEq8v/rA5gBkT255BTROeuxTT+7Vtb59aZ0ZgoGZAbh+Z+C3sVwwnPh+Z+Gt/4S/no3vPdB+MBjvGfDz3he/4/gg9vh9FfCrf8MO35vn9slyXvmxLXQuwxOfrHv+3ZDUlPZznK2DF0sSit8Jhh5QXQ0Nx4TyRCROg01ebGSF6NdWF+JUdl6aKYan9LBzloQpE0EIjeSvNHJPMtd6gHPXzdknzy8lLz+TAJVcSh5Ha7JU2VNXt8y0c3lMfXCScokWiF5hjMM2WUxytlFzl5KXrKpxovxXMl9FFlIDJdG2VJeTLFshtpOzSzMdReL7tPNHl22psHAPZ/nEXMt5Q2XeW4zpasU5cnz1JeKvw9fA095J1dan2Hb8NPFbctOE1Zpshf+5wrYfjsg1IqTlvU5lDyHWpwbE1bTf10G9/w3PP198MafQP9y133JJvVgJQ9E1t/sQWHbRoBz4RjIJCKHIU/nS+wcy7VlZq0fpMVV9CF5xbJ/TV42qQvFa/QhQdyXnynKJw5sCr0flmWJ19FVe5/cJsNYluXZSSnRju5Ir7m1EtmUKGcwXc4hfrN1MQ0Y2+YoGah9j1Ulr+75U6Ow8w/V340L0h7qtKw9lcSx5gLnjFfAn9wGL/kiXPh2WH0BJKtr0FzJIJVMCsXvhf8Kg2vhmj9mUBFNgmOzRZaU93D81O/hvDeL+JaIkFMmfrfk1ZA7JFT4CDBNi6LhfkzICwa/cG1p1+pa9bweK3kx2oLl/WnSCZVtB2er8SkdVvLAOyvPGYTsxPnrh+1/L/UgeZqqMJBJMJYrYppWpRi3w0qeaQnVaGidt5Jnitm1TlRr8pptvKivyaueEHI+NXkgGifGm1HyZosMNlmPR2GabHmCXdZioBrl4gfZHZwvVXK3TnoBPPpT91qrTdeSmdrGv5dfwqDPtmuS5AdXi+aGt90Mz/sEk0aylkiMHAdvvVFkff3vVXDbv8C93+IV6btYPHoL1rbbOHfmFt408R/wxYvgU+uF1TS1B17zA9Hdq3nXhGaTEZQ8iKzmVe1a8buIquQ9eUA0ZJ24tNNKXvCszqCaPBDnlJP3XQdaEl7yn+LGx93nFLtBkkxn7JLbPhUNE8tqjPRwIqVrLY+lqs6t9VbyLMt9SoOvknfPf8MXzkHd94CrvSqPyYYIlc0Vq/aUl3juczbp3vFrK3kV4tiT0kN3QovGi8pnne4XeZIz+1j3u78GLHaN53i99ktMRYdz3xRqm25IJzSeyJwJy86Au6NZttVjp/GYCBOOLVXspKPxotnRk/OFmOQdIVBVhXUjYobtfMSnSCz3UPL2TeZdg45PXNJnN1G43S8hRpuVmCmWMa3OBSGDIGq2Eje8wbMmz7CshrFErdq1dk6e3qg4eI0BkujPJJgulCO/9niuaFvikVFpYthliQkhoeza+tytp71XKGtfu0zMuJUwTbjtX5ns3cDPzfN9VcKkptYG755ypajNQxDuhrqv/hXw5htg6Wlw80fhx+/iNTs/whesT6L8z4v5WOlfuGDyBuhdImJP3nwDvP9ROPG5ge9PFM6HOJFLkncwWryDXHiSukp/EyRPKknNzCqOArmA+y1qQTV5AKv6VM6f+qWI3Fl6igiWDhmiLV6/keS57ZMkfkGNF60qeVNBSp6M4XGpy/OyDgHRbGSZcNunhaIWtvHikR/5WrVyn9xz92qVvN6IJK/mgnXlufDsv6Nny095tfZr9h8a45Xarexd8VzhqjSJtK6JAOyTXiC62kNENkkUfI6JMCTPPUIlVvJitAkbFvew9dAs2w7PktCUjsanSCwbyHBgqlBjNcgg5BWDjSROVRXOWzdMUlN9icZwRaWaijKJoEmoqoIpa36G1wu71qVbVkSo1N7Wql0rlTxVVUjqqruS50Hy5GcyE7HbUih5TZK8CUnyhJIXqvHCWZMHIq7hT26DVefDte+An7wXygWh1hx4hDtXvRkL1TfixY5QqYNhWkJxdVOLekZEndBfboX3PsSDV/6CKwv/yD2XfJMrC//Il59yC7zhWhF7svaimkBnP/SkvMNsa9C3XFjVEaxHqCp5SWnXRiR5VdLTuaYLsX1/Jc80LXcCXodncxd91ozo/AQ48Xmw606YPRxqP+yFOqH5qouS+HnaobRnYoFU8rwSAmR9m1tdnldmG7OHRfxJzxJ49HpO1Xc3KG8zbkqetGp9VDzwtmslcZRKXq9svAgB18y/i/4cc/0lfET/Jhds+xL9So4DG98Qanve+145j648V5Dg0QdCP7d6TDR+5nol48//IkZ21zojVGIlL0absH5RDzvHcmw5MMPq4WxH41MklvWnKBqmHXcCzvgUd5L59mds4C8uO9F1WLfEYDbJ2GzRMbe2cxEqdk4eCJJXnhMhvHWon3gBVZLXlF1rUhPJUl/kLUlRNuH+3uWiEVXZETV5TZLmipK3Uyp5oWryxH7WLEK9i0WI8tPeC/d8QzRG/PoTMLSOO3suIZPQAgvi3a6o66+kG6CqguwNrmHtyefwgHU8N+ZO5AHrePp6vJVlP2ST3mOpaqAooi7vQDQlr1Sn5Mng2LCwF66AAv5W4aeagRg3B9UCdi9cPHMDe6xFGOsvETeceDlghcpXdL5+SlOrk2RcFlpJButnqTrRDiVPKqleboSsmXNT8jy7fx/7mSAwV30Vkr282bimgWy51vRKq/bUl/jus5dda28zUbVrQ5M8t/eiqqgv+zJzpLh8+hoeNteJQPUWYBPzleeIG/bcE/q5QRdEQd2y1fNPtQwnqBlpoRGTvCMIGxb1YpgWf9g6xvp5sGqhSuScWXkyCHmFhx37lA0jvOOS43y3O9yTYCJXYmqucoLsuJInCrH9YlRMF7tWbzEM2clFRPCqMydPvPcgJS9KIX6+ZDBXMppX8sa3YyR6mUB0c4dqvEh6LLSaDpf9A7zq23D4Sdj/EDz9LxibswK366XklepqYvwwkEmwcjDDHVuFQjTQZJ1iT1InVwqppi7ZKJS8CN2i9Y0XllUlDmFQtaDmR8nzWgRLdRlirpjYydrJu/iB8QwOy6iY5WdB79LQdXnyuBA5ea0ree1rvPAeawYwV3cMGaZFybDspqwaPHo9DKwREUMXvI1nlG5nMFd7znKNUHnk2opVe5LvPotmIpcIlWJZ5ONVfl+9KTGtIgzmioZ7fXHfMj6aeDdlS+Wr5Rcw0Oy5qQLR0WpCzyLR3BGJ5PlfEAWR/pJhoquKPR86jMW70IhJ3hEE2WE7Uyizdp5InszKc5I8tyDkqBjqSTKWcyh5HazJk+qcPdoMXJsv/JW85sKQnUpefTr6XEBNniR5UZQ8GUvTdHftxA7MgTWA6GLz6vx1wm8WJgAbXwRv+zVc+g9w5msYzxUZClAaayJUHAhFJBw4eVkfD+8VHbbNlgRkfQbMN2DJRshPwMz+0Nt35uRJ9TYSsS/LmaGdPZ0HxZWUygEqK9g1mj8oP5P9k5UMSFUVat6Wm6Ec3GhUU5Pns0/5kEpeu+xav7Fm0KjkeVqHhWnY8mvxu1EUeOq7KCpJXjDxnZqHzRbK6KpSJSxTo7Dz94FWLYhzjhsxzhWMGtIou2u9xsY54RdX81D2KZxT+DLXmU9vuTSn5jtbeW5NdFLwPvrXaYrAb3+71nl8B4VxdwNikncEYYOjm3b9os7Gp0jYgciOrLxRlyDkqBjKJimWTbtzt5M1ebJ+y7AsGFgNqg7jjUqe+1gz8f9mxBwv+RynMpium3MY1F3b3wTJG2tx2gXjO1CHhdo50pO0r1j9YEeo+J3oFh0PT38v6MKmDxq5ltI1XyXPL4vNiZOX99kqbLPHWI/PgPkG2B224evynCn6zRD7+VLy7NF8HqpFoJVumnDft5lZ8TT2sFhk5Umc+DwoTAmSEgCn5Va1kBv3Sf7WOj3WbCpfQlMVzwsiWc5Qr5x52slP/BKMgmhMAehZxG39L+bi/C01F6ezhTI9Kb36Gw1p1Yp9cs/umy2Wa95HbyqBafl3VEvkK1NI3NCf1plCrF+tnutrvrOV58LkztDTL+xjx+OYSAVE6hTLZk09sK0kx0pejHZgMJu0FZr5UvJGelNoqlITozLqEoQcFbIpY/vhHNC8lRYGUk0zTYSFOLjGVckzrUaSZ0eoGM1NvNBqlLxakjdXNEjqjQO9JQYcIaJhIecBNzW31rJgYgfq8FqSuspwiM5a8J+F6b6PwSQvqbtHExTDqEUOnOyY5dq0kpfUyZfMcJb9YknywtflyWw5RWmS5Dnsy07CzhHzWNCKQVb6tltgcifGWaLhoobkrX8maKlQXbYy8iRZM/HCvXNV7Le/kids0+YX6el8mV4n2aqDl5KX97KTH70esotgzVPsm25f/EeU0cSEiQpmi0Zt08Uj14rjL8CqBe+O8VzBqAlXlnNxgzpsDVNkFwZdsGaTWkvrBghSXHAqeRBazQtj17pdXEqUzdocSPsiI1byYrQL6ytq3vp5yMgDoWQt7UvVxKiMTuZtha9ZDFXI6o7DsygK9LqltrcJ8jdpSDVuaL1rTV65zWPNjLpwZTe71s8ObUnJa8aunT0IpRzK0DoGM4lQnbXgqMkLEzNS2cfAmjxNpWRYDQ0IUWryQMywlWi27lMu0l5TC2rQu1gs0BGUvJJh2s0K/U0Qe0lwwn4mzcKPUIHDStc91N97vwXpQfrOegmqUplfK5HqhfUXw+M3BNYzuubkuUaohFPyoLWaKr+RZuDdXWsreU5yXi7A47+Ak18AanW/S9mlXKtcCg/8H0zsBISSZ58/pvcJFTSEigfiN1somw2/r9li2e6shWq9XxDJK5T9P2tZr9gOx6bmYnn5GaBooevygoh/0HzmUrnWrg3qOO8GxCTvCMOGRT0kNXVe4lMklg2ka0abCZLX2utLO3HH4Rz96YRvJ26rUJU6oiaz8uoWE7Ouhg5aDEM26+zauhE4Oa9C5Qp6khqaqkSqz5rISbu2CZJX6axlaB1PP34RT90wEupp0m4KkyVXNkym8uXAsGav6QryewirBqwb6bEJVCtKHoR7f4CwbCNk5YlsOXGcNKvkJXW1o78hCFbyfO3a3JhQqM54FVoyw+K+VE2dLyAs27GtoknHB057WhJbt0XWrsnznV3rT1zDYDpf8my6AOdFgoeS57TZt94KxemGkV/ZpMZXjBcBCtz+WUAQL7t+Ts6qDVGPB94lFrlirZIntx/UYRtU/yhrTdtRe11zsZzsEY0mYUleQGmDl4MgUTJq7dqUz0VGtyAmeUcY/vSS4/jcq8+al/gUieUDmRolzysIOQqk0rRzLNfR+BSoErWaGJXCJMyN1zzOcLFrW63J02oiVLQGJc+r6QLECJ/+tB5RyROPbWrihRz3NriWz7zqrMAOaQldU0lqaii7dqLyXsIoedBIKKSV4pqT57FvJy7tJZ1Qm65Zq9ptUTpsHw3dYVssVwOEmyN5HllrbYbfCDEIsNJv+KAY03Xem4HKJJ36mdgnXi7+BnTZOu1pmT/pZpeFiZZJBxDXMJjKlz0z8uRrKErjWDJXJe/Rn0CyDzY8s+axPUmNraUhrLNeC/d9C657F5eOf4+nm3fD4S0iAHnxRpFRGQJe83Br1EGgL6SSF9REJhXqdih5Kb1uXuzKcwTJC/F788vJE9sOiFAxrVq7NqAZqRsQk7wjDMct7uX5p7vP2OwUlvan2TeZx7IspitByK3atbImr2xaHW26ABfL1SNGxajLtXM+t5mavPoJGulE7WLkGTnggAjHDR+nMZ4r0pfWm6t7mdgu/g6uifxU0a0XfKIbnw2nNMqFub4+JqpdC3D26qGWlO/ISt7ik4UaM7k71MOLDrs224R6K+azdrbpApwLmr+S15CT99DV8ND34Zl/ZTemLO2vdQcAcdwtOTWwLk8u1PZoKY/Yi/lT8sq+Sp6qKqLRoY4oyde0vzvTgEd/Jqaw1AV1Z5K6GI32tL8U86Ef/zlvnPkaHzj8YfjCObDzd6GtWrk95z5I5Ir13bVhlbwgu7ai5LXFrq0jYivPFR3tHuMqnQi2awMiVMpmXXdt90eodFZCiXFUYPlAmlzRYLpQti2W5S3axf2ZBIoiLr46GZ8C2ESrOvXCEaOy6lz7caZp2aqfRGtjzaiLUGlsvAiKKIk65mo8RFOD95N3iIT9ZPTObTFbM3ihHAtN8sTnUm/X1ifOh8GHnn9yeBXOBdWxVGGVvFPE3wObxdzdAMjGC8BuvojynYvoioVX8uR3U0PAJ3bC9e+DVRfAxR+wb142kOaObWONGznxcvjt52BuAjKDrq9TrGs08ZpaUSUefo0XsnC+lZq8Ev1p/7nB2aTeoOTJjkx7/3b+AXKHql21Dthqcmoxmdf/EIDnf/I6nrdsmvecCUzugQveFnqfvWKPcnXdtWFr8hoIax36212TVzawLEs0u9jNF/eIOdY+CA5DDopQMWtqTqvHT6zkxTiCscyRlSdt21aVPE1VGGyjhO/7WvU1eUNrxd+6GBU3u1aGITdTk2c0hCGrNa32uZJhX1F7YSCTiKTqjOdKzTVdgLBrh9Y19dRMUiMXRsmT3b8hcvKg8eRZnzgfBj0pnSUtxP14WVuekJbZwc2hHu5svAAqJC9CGHLZZ8h9G+FX/wYuNXmmAT/6U7AMeNlXRGd7BUv700zOlRrJ2YnPE49/8ibP/ahfqL1IXphxb7aS10JN1dRcybfxAgRJa2y8qCNGj14vOoxPuKzh+XYNneMY3FfMcGjwLDEe7pIPQnY49D5Xj+nafZqty8nrjUjyvOxa+fm0i+RZluMCcPHJkMiGqsuzP3MvuzYgQqVkWvaaIPYlbryIcRTAzsqbzDNamXbRKsmDal3efCl5NslLZKB/ZYO8b5iNEy/aWZNXn5M3VyyTCVBg+tMRlbzZYvMZeRM7qgQ4IsIqeWHDmiXpqVfyihFz8toB27IKm5WXGRJzbA+EI3nFOgsoah1moTQ/dq1d/+ZVk1dPwH/7OTF/9QWfFnWwDsiMzYbmi1Xnie7kR6/33A/brtWd80O9c/KCIlSgeSXPsixmCv52LcgJEz5KnmXB5p/Acc+CVKMq6HYM1hOyKHCLPTJMq6HjP2w9amDjRVtr8uqIlaaLqSlhSF4Yu9avJq/sEaESN17EOJJRPSHP2UHIS/raQPIqll0nM/LApfECRF3eoSdE118xB6bIQUtSgtEH4b5vww0fJPHNF3JD8oNo+YlIr2lZFpZFTXaWVBxkerw4ofqfpPsjDqwfzxXtesdIMMrC8hlskuSFrMkLa9fKE2lDTV45ek1eq7BVj4CpF1+6ZQubKtM1WHxyaJJXMqwaJS/qd14oGx3PyJPwWwRrJl7suRd+/XHR7XnmHzU8dpk8p9TX5akabHyxiBEp5lxfp1A3taChEL+CfNkI7Dr2i2AJg9migWl5T7uQ6EkGKHmjD8DkLlerFqqkTBLFYtmkaJh2jl1UyGPaeWEmCV9Nd21SKnn+n4/cjldNXtWubb1CzDWbbuU54rwdMDHFzlj0OH9Et2u7X8mLa/JiBKJK8gqMTs6xqDcVOIQ8DGySN1+NF041btHxcM9/w6eqCsNN6GiPWfBY5UeeyMLAajaqu3h45lHgvNCvKQmlVtd4YVpyUVeYK3qPAZKQjRd2/UkAxmeLzc2tndotbLJm7VqPBP16TOSKZBJa4Pu2I1QaGi+i1+S1CrnQ+Sl5ZcPkn3/+KFP5Eqes6Bd1eXd/vVKY6b+vRUeECojvfM/4nM8zalEome7zTzsAv0VQfjcpaw5+9DZR3/mifxOjueqwbEA0FjQ0XwCcciXc8w3Y8itB+OpQNExUpXrxJpQ8F7u2FGxjt6rkVUea+Z/DMkmtYR6xVPJ6994Ot/29yHs76QWuz5fHoCRTs25zayPArSZPNoY4c/JUVaEnqQUreWV/u3ZRJVh9cRvEAVditfJcMP4dDjwCK872fK4sbfA6l4aZXev8zI+EsWYxyYsRiKSusqg3xb4poeStaINVCzBcqcvyix9oB6oTLxwk75K/FieDUh7Kc1DK893bH2PlUC/PeeYlsPxMGN6AMrUHPns6fXN7Ir2mfCmtLicPqgpDuMYLnaJhki+ZvnErIBSd2aJhf66RIONTmrRr0wmNw7PBc0fHZkuh5up6Rag0U5PXKrIeOWdOyAW8LO3lJSeL42pie7XRxwPFslmjBEVttimUjebrMCOiobPRgZJhcryym7U//EcY2wJvuM6zTkxeOLqSvHUXQ2ZYTHBwIXmym1gu1OmE5lozVigHX0SFsdtuf+IQF6wfdr2wld97sJKnN7zXzPjjfC3xaYauvg8G1sArvwk97tmU9c0/8oKjp8kQ+YyLkicbQ+q32ZPSmcmHtWvdP++1Iz18520Xcv668HWDXnD9zpzNFyFInhcCa/I8Z9fGSt6CQlGU5wGfAzTgvyzL+uQC79IRh2UDYurFvsk8Gxa3Z9qGVPLa0VbvB1clr28ZnPummsf9++9u4jkrlvCc08+o3ti/kpKl0Z+PSvLEazkvGFOOq76+lC4aL0IoeSDmYwaRPDnSrCklTwYhN2nXZsNGqOSKoTL87Jo8T5I3f0peUlPRVcVXqZTNMVLNqumwDSB5JaN24ZHNNmHV2/lqvAAfpcOyWLnt+/wk+Qm0uT547dUNWW9O9KZ0skmNfZOFxjs1HTa+CB7+obgIS9ReVBZKRg3hSukah2YaLzDyJTOw6zhIyds1luN1X7uDf33FmVx17qqG+6WSF3QOy6YcY8RmD8GvP87L7v4fZtQk5Wf/PfpT39HwPmueX1dDJ0ekNavkyTIRZ02eJJD1F569KZ2ZAJVebied9P68LzpuUVP7Wg9XYjW4RtRy7rkXzvd+riht8GnE0TUM06JsmOgu5xjRJFX9TWqqQkJT4pq8hYSiKBrwH8DzgVOAP1IU5ZSF3asjD8v6M3Z3bavTLiTsxosOk7yGiRceMK3GiReoGqMsYiCikmfbtTWNF9UFpVA2sSxve0NC1rKEUXbCNjW4YmKHsIv6V0Z/LtEaL8Lsn9d0hYWwaxVFDJ+vnz3qhFR07Bmocn5oiLq8+saLgUyCkmGFngWcLxnz0ngBHp2s+Um4+i2c/+Dfc495AuOv/zWccKnvdhRFYZlbVp7EKVdCcQa23NxwVz2prc+frD4u+HMJUvJkDeluD/t8KoKSlysasH8TfPmZcO83eWDZVVxS/De0i9/rS/CgSsrkMThj27XNfe+udm3RnTj2pvVAu1Z+/kHKaTuQduuIllEqAc0Xvhb+2FZec99rOE3Z2tDwJVEyzJruWmgMue82HPUkD7gAeNKyrK2WZRWB7wJXLvA+HXFYPpBm26HZtgQhSwzPU02ea+OFC9xm1wLsVpYyWGhOyXO1a0uGTYhCK3khSJ5ckJqedjG4uibmIgoyLoXlri8zGy7Hz45QqVt8F8KuBbHw+Sp5le/HDs1O9QkLLgTJq49QiULsQZCe+cjJgzolz7LgiZvgy8+ATddxz/Hv5g2lv0YbCBfW7hqILLH+mZAehE3XNdxVLJs1jSYp3SsnL7yS57VIS/K+b8qD5FW+o6CSk2xK44ziffD1y8Eswx//ihvWvI+cPhhKrc3URZ5I0tXbpJKXTqgoiujwl5AWcL2S15MMJnl2JuF8hHJ71cGtPBcOPgb5Kc/nit+Kyz6aJlz7ThbNPM5ztbt9ShKshgtMEY0VK3kLiZXALsf/767cFiMClg2k7ZN7qyPNJM5aM8jJy/rYsKg99q8XwgYaGy6zawH2spTBwmik1zQr54j67loQJxqp0oQJQ4ZwC760a5tS8sZ3NG3VglR4gq9mx0JGvARNvJjPCBUQ31N9mK0TU/VKHoi6vBAzbOsXjiqxDxfZMl8TL0AQqmKpJGalfuUS+PZVYJnw5hu4d81bMFFDfzfLBlxGm0loCdFp+tjPoFxr6da/3/r8yerjjEDSEaTkSTu2IerFvl8qef7H9HljP+Or6iex+lfC234FK86iUAquGZSoz2pstfFCUcQUDqdanPOwgHtSekPTSD3mSoZtXXYanpNXVp4LWDB6v+dzPUcA3vll2Pk7ymqac5QnfOczO+1aqDQjxUregsLtqKtZ7RVFebuiKHcrinL3wYMH52m3jiwsc4TJtjIiyokTl/bx8/c+o7kasghomHjhAdNDydurLqPHmPC9QqyHrP9znvPSjhFK8mQdZNc6a/KCEDaexBUtZOSBWISKhlltPHBB2TCZypdDNQnYJM8jJ28+I1SgouT5qBmSDJScFxJLNsKhx0U8jQ8KLnYthFfyhF07D5+HUeZZhV/xL4f+FL7/eihMwRVfgHfdA2subMzJC8CS/hQHpgp2pFADTrlSvMbWW2puLpSNhqwyN7s2XzIDo2V0VUFVgpW80UCS50G2LAtu/jiXPfGP/N48henX/hQGVtn7F1b5SlTmQ9skz6NJIgpER7yz8cKrJk8LzIgU78W7a7Wd8Jy8svIc8dfHsnWtXz30JNz0D3Di89ix+krOUrdQKLo3kbnatbGSt+DYDThnC60C9jofYFnWVyzLOs+yrPMWL148rzt3pMBp0S5rYXrAQqA68cL/cW4TLwBG1aXiHxM7Qr+me4RK9Qo0rF0rbaDJXBglr0m7tjADswebjk+B6vtwU1QkJubCK41Jj4L4Unn+a/IggpLnfP+LN4JRDJypWd940V/JEotm186Dkverf+Dthz9F2VLhqq/Bu+6Gc94Auvg+bZU1IDJGYll/mqJh2hcnDdhwCaQGGizbQp1d66Xk5UvBSp6iKIIkeizS8uLKS3GczpfQKrNpXfHLD8Ntn2LLqpfyltJfMqdWXYt8xHzDrGNqxmyLNXkgLjDnXCJU3Lpr/epRQY7Wm6e6UC8lLzss8k/9SF59cLhpwHV/Jo7hF32WqcVn06vksTym1ZTd7Frd/SKjW3AskLy7gBMURVmvKEoSeDXw4wXepyMO0qJVlGr8wZECueYENl6YuJK8feoy8Q8ZMxICUp1wBrFWT06Gw64NDkMGQo25Gpst0ZPUolt3EzvF31bsWo8xSU6M2zWD4Ule4+xakZHm9j11EqJwPljJK5tOu3aj+Htgk++2ReNFbU4ehKvDLBsixHtelLytv+aJ7Fm8KfVZOP3lIrjYAaFyKL7hw04ss2NUXDpsQSy8J79ATL9whNw2NF5UOiJLdcdKWPKb0t0nZkCVvE/kXEawIZS8vrTurmCZJtz3Ldh4BQ+f+zHK1Na2Rc03zDqUt5kW7VoQFy413bWVbWfriGNvWg8cazY3nyTP4Yg0YOW5sPtuoaC6oCE4/A9fhF13wPM/Df3LmV0solgSe+52fX6xLgxZ7k/ceLGAsCyrDLwLuBHYDHzfsqxHFnavjjxIkteuIOT5hJTXA2vy6saQSezXopM8adeqNTV51a4wSRgyPpEDIBSrnqQWyq6dyBWby0uTCmULSl5WKnlF75OdnFsbZiKH58QLw5x3FQ8qjSUhumuLhuMYW3QioAQ2X7jNroVwSp49pqnTjRelPBzYzK7saRQ8Ow8bVQ4/LB3wycqTOOVK0b277Tb7psaaPPdC/LA2tp+SN+343bnV5U3nS95jGfc/DHPjcPKLyKbEY5z2aHQlT68JQ9ZVpSVyn6kbtZYrim3Wl0L0JnUxYcNHpS+EaHJpF1JejRcgYnumR2Hvva7PrblAOPg43PwxOOmFcMYrATAH13HY6iO1z10NLBlmw+fjd/x0A46s1bpJWJb1M8uyTrQs6zjLsj6+0PtzJCKb1OlP623rrJ1PyN+k4VOTZ1mW6+xagLzWR07tjUby3CJUHHatPdA7EXwlHjYcdywXrnO1AXYQ8rroz63AbRZmPeyawRBhzbqmoqmN+VNFl5PsfKAnqfvWJVW7ax0LYTILy06DO/4Ttv3G9XmmaVE2a8lRX4Tu2up81g6rKAc2gVnmQO/JnkXp9YpkEBb3iqkXB2c8lDyADc+CZB9suta+qSEnz2NIvKjJa03JczYcuNXlSSXPFZKYrr+4IcxYvI+ISl6yWhs3WyjTk/JQEEMik1Brw5ALIpy9fpv23FwfNW8hlDzX43DjFaAl4cEfuD7XvkAwDbj2HWKOuWMqSyqhca95Aj0HGkmiYVqYFi4RKrGSF+MowYlL+zhhSePw7G6H68SLOtgTKlxOmpqqcCixPKJdW3ltB2msxjWEb7wAOdosTE5eqTklb3wHJHog6562HwbV3C0fuzYXrTEkqakN6kHZsOa9sxYq9VBRcvIkXvW/0LsUvvVSuP//Gp5XbVaovidNVehL6aHUW7nQdVxFqXQsHh44xTP0ul6RDILrDNJ6JNJw0vOFZWtUwr6L+7ly8n/h8+fAde+qKYNwQky8CN4fv1Ft0/mS/bt1i1HxJXnbfwPDx0H/iobuWGhCyUtqNY0XPSHOHf7b08mVqr/XXLHsav/KmBY/yzYfIti9XUhqIv7F9TjMDMKJl8PDV7s2PBWkuvvg92HP3fD8T0HfUvv+VELjPvMEMtPbxFxzB6qd/fV2bbgg+IVCTPJihMbX3nQ+H33JqQu9G5ERJkKl2ijh/vyD+vLqVIgQkNtzCoNOmyFshAqI3LRQYcgh40kaIDtrW1AF5ILtp+RFJnl6I8mTdV/zDankeXWCThfqJl5IDK2Dt/4C1l4E1/6psIcc25ALR73tFla9te3aTit5ow9AepB8dmUlyLvxc4hqpac9FLgGnHKlsD1v/hh880q+k3sbLzr8DSjOwoPfo4cc0KjsNBTZ++yHlzo5nS9z/JJeANfpHFP5knt8ilGG7b+F9c8AqmqYk+SF3T+JrKMuVCp5raC+8WLWY8xibzp4dvN8Nl4oiuI/Y/aMV4lGsm23NNwllDxF1OItOglOf0XN/Sld5R7zRPE/u++qua/k0dkv7NpYyYtxFGAgkwhsFOhG2BMvfOxa06VRQkJTFQ5oywUZMsP9mA3XMOSqzSBPrmFOjP2ZhF0A7ofxVuzaFpouoEpW/a5ox2eLZBJaKPUSxAnXLUJlIWrysikN0/KwiKhm2jUoeSDUhdddA2e/Hm77NFzzVlHjRrXmsP49hVVvpQLV8caLvffD8jNJJTQsy4XMEr0mL/Rw9+OfA8le+O1nYWwrX1Vfyac2/kDMejWKrD50W8N2DNOiaISrE/MKUwZB8pb0pehP6+ybjKDkjT4AxWlYfzHgmD3rIEqtKHkz7SB5icbuWrdthrNr568mDwLUsxOeC+kBV8u2UDY5Pv8I7HsQLvyThgvblK7yoLUeU9Fg150198ljvv4iU9i1sZIXI8aCQdfCK3luKpGuKuzTlok4jOlwociWS+OF02aQJ+tQSl5GD1zwS4bJdL4cneRZllAoW8jIA+fAc28SPDZbiqQ0JnW1MULFsBak8UfGSuQ8YlTs7loX8gOIcN8rvgCX/j08fA3836vAKNkLR/17Et95MLG3B8N3UkUpF0VN3oqzqsTMxd4UBDy8ypqo1F0GZowlMoIkv/F6+PMH+HfzKnKZlbDqfOhbzvK9vwRqc9OKERROeyi9UYYdv6u5kJNK3fKBjGtN3pRX48X2Sj3eOkHy7OOnxZo8WTIwWyg3Pe2iZnulEEpepdvWLxA5SrBzO5D2IeboKaH+bv6JUHsdKJQNnnLwB4IEnvnqhqemEhpzpJnoOwl215K8sm3XNip5McmLEWMBoYWYXevWDWs/X1U4oFfqNkLW5UlBx7k9RVHsk9NcySChKaGUjzCqTnXaRUS7NjcGpdmWmi4gfE1elJrBpK42dHKWIhb3twtuhfNOeNbkOaEo8PS/gCv/QwT8/vxDvkpeKLu2NA9K3sHN4gJn+Zn267gl/JfK0VXWdNii9TVPEaqYqlZz8lQVNr6Y4b23kiFfsx17zFZIJc8q5uC7fwTfeD7c+RX7PqnUuU3nME2LmYKHkrftNpGT2LsEqF4EObMWw9YMStTate6ELAoacvKKZddw5aqS501k5tOuhRCxJWe8SpzXHrvBvskwLRYZhzhx7BaR75hsnLQkrdgDA6fDnntFg0YFbvWzIMOQY7s2RowFQ5iJF4bRaK9KaKrCqBItRsWrxk+enOaK4U+K/ekE04WyL0kdz4XPoKuBjE8ZXBPteXUIY71FtZNTutY1ESpuNVUSlmXZTRKlMHb+2a+Di/4c7vov0g/8N9A4JSI0yZuPCJW994u/y8+ylTG3RoWojRcQXQWxLEvMrpUK2MYr0Iw8l6gP1GxHqoNhfmMj6jSfmPobePIm0Sjx64/D9H4sy2K6ouQt6083RKiIGk0albxyEXb+wbZqQZBwTVVqLoLykWvynI0XbVDyEjqFsmmfV3IFg6ybXZsM213bJXYtwJqLoH+VaLCooFg2eb3+S8CCC97u+jT5OxrtPwOKMzUZl1J1r/+tpivnKc/JLQuMmOTFOOoRRcnzInn7lcWgqKFJnumhDMqT05yHNeKGMOG4Mmg48txaOwi5NZKXDRGhMj7bhJJX7pKaPJeaKolC2bQXADmRIxCX/j2ccDmLb/87nqJuamy8SCdCddfOS4TK6AOQ6oeh9Z5xJdDcdxN25rHzNcChXK69iHJ6hBdod9QcK1JpDFQ4J3by/l1/znHmNlHj95rvQzkPv/yw/b1KJe/gTKFGqfUcabbnHijl7KYLECq+k6RBM0qeRtkUJLc9jRfiteVvdrZYdu3Yle/Pv7vWnLfuWsC/8QKEynv6VYK4zx4CoDA3zR9pN7NzybM8z3fyeNndc5q4wVGXV3Yqebvvgel94jl+kS5dgJjkxTjqEaa71jS97VpdVSlYmrgyjEjy6kljOqGRL5vkIkQO9IeYXxu1c9WGVPIGVvs/LgB2d61vTV6R4Qg1eSlNpVinGLmFkc4HbCXPxbKS34ui1E288IOqwVX/RaF/PV9KfJa+ud01dw9kEuSKhr/9yzxFqIzeD8vPBFX1V/LKVmQrPercz2o3ceX9qhpzxz2fZ6n3U8zn7MeFUvL2PQz/dRl9xhjv1P4ONr4YFh0vVNYHv8vck6Kurj+TYPlAGsuCA9PVDtsqyas7prf/BlBg7dNqbu5J6vbxIyZ0WJG7awHmigazBaMNJK+6PagoeT52rRfJsyyLfHl+7dpUGAX4jFeBZcAjPwJAfegHDCkzPLnutZ5PkeeWg9oy6FlcQ/LkBcZAbjt843nwsw8AeEb4dAtikhfjqEeoCJUAJc+wEM0JIefXGh6kUXZizRUN+yQbhDATEOQ0iTBBwzWY2CmKkDOD0Z5XB01VSOpqTe6WE2XDZCpfjmQnpxJeOXkLWJPnouTJBomhbNJ3KkAD0v088eyvAnDW7X8K+Sn7roFsuEDkjkeoGCVBhpafCfjHnjSl5EWc++mm0JVOejG9Sp6h0dsbHudJfrf9Br7xAlBU/vuk/+QP5ZOr9138fhhYQ/aXH0KnTH9at6dzODtsJblvUPK23SZCsLPDNTdnU9Uw44JNQqMpeQATc0WKhmk3RDSLrH1hZmBZllDyXLaZ0FSSuupp14pInQ43/9RBXiz7YumpsORUYdlaFun7/otN5loml1zg+RQ7nsWwYPWFNc0XQq23OPW+j4oa1cdvhLnxat5jrOTFiLEwsEmeX02eGUDyTFM0J0S1a92UvJLBXKlMJuQJvmrXetsl9jSJyErezpbjUySySY28R/fpxJxsDIlg12qNlsyC1eTZ3bWN34HsrB3uSbpGi/hhOruaPyu9h+zUNvjh2+3OTlnnFdRw0/EIlYOPgVGA5WdVXiegJi+yXRttWkDVrq0SCnX9xUxYPazc+wv7Nl8b+4HvinDq/uXw1l8w3X9C7ftJZuH5nyQ19ihv1G6kzzHpx5mVN+1G8kp5of6sf2bDyzrt2nxYO9n5/IqidqgyIaTVOCvZDJIrlSmUTUzLe5u9Ke/5tYX56PCuQ1pXw10cnPEKQdTu/SbJw4/yDeNyUgFlMrYVvOp8GNtq271lw+RF6h8Y3v87UVdrFGHTdf6zdLsAMcmLcdQj1MSLyjrjNfGibFhCyZvZD8Vcw2MatucxQSOdELEgoiYv3Em6PyMe56fqTOREBl3kE+3Ezpbr8SQyCc2zJm/cHmkWrSavXhkrGlbDWKH5QLW71n1IPYiZvKHt2gqKhsnvzVPZfeGH4fEb4PbPAOHn11bJQocW2MqkC1acJV7Hp/6oGQIetfHC7iZ2XCClUml+aZzL6oO3iKYHsFWeGqXMsuCWf4Yf/QmsfSq85UYYXE1K1ygZVq3Sf9ILOLziEv5Cv4Zhc4zl/RkARh1Knqtdu/tOQYrXVZsuJLJJ3VbDChEaQ+znVx57sGIZt9p4YZO8omHvl5uSJ1/LS8nLN6FKtorQx40MO/7ZByinh/mxcVHgbyUlZ9Gurih+lVBkY26Sv0t8i5nh0+DFn4eRE+DBH9jb69bRZjHJi3HUI4xdKxdnNyVPVxXx3KH14oYQlq3bxAuQNoPIyQt7gh8IUZM3NluK3nRhWW1V8gTJcz/R2XZylJo8lzBk0cG5AHZtylvJm6pT8qJ02Unlb/K0N8FpLxednVtvteswg+3aRtLTVow+IIKIh48DqvVHbipKqYmRc1GnBcjHOhXDlK7yM/NCUsYMbLu1Zv/sBb1chOveCbd8As58Dbz2GrtEoRpS7nhPisKDp/0NCQzW3/tP9Gd0MgmtpsNWBpT3O5W8bb8BRRMTTurQk6xeBNnkPIpdWyFgsi6w1Zo8SRrzRWdup/s2e1I6Mx4RKrKmb74bL0KRqoFVsPbpYBQ5cOIfUSAZqJ6mZD7nirNB1e26vJX3f47FTLLroo+JmtozXgk7bmegKBowYiUvRowFgt1d67P2Bk28MCyrmiUXwrK1Gznq7VpHTl7Y7tr+EAPrJ3JFBqOONJs9JLoA26TkpRMacx45ec3Yye5hyAtj18oFzFfJ6xXvrexzMVEPOydP1+DFnxPqwDVvZdg4CBA46SR0F2mz2Hs/LDtDdCvir+QVm8gwjDotwC0yRlUV7lTPIK/1wKbrgDolb24cvv1yuP/bcMlfw0u+CHr1OKzOlK59T/v15XzJeDEDT16Hsv03LBtIM+rIyqvatY7f3bbbhOqZ7m/Y92zKRclrovHioE3yWs/Jg4qSV/ndes3D7U1pzBTczz9R4mrahXTCe95wA857M6QG2HP8a4Dg34pt1yYysOx0oeTte5gVj3+T/zOeTWnZ2eKBFZVw1Z6fAXFNXowYCwbNnnjh/SM0AuxaoeStEzeEIXnSrm2oyavm5IW98s0mNXRV8a3PGssVFyw+RSKb9LZrD8+KhWmkN6Jd6xqGPP+nLU1VyCQ035q8kcrnH9QR64Q9D1NXIdULr/oWFHOsvOmd6JSD7dqyQVJXUVqYO+wJ04B9D9lWLVQXSNcw5KZq8rRI3bVekyw0PcXj/U+DR38KRpl8yUDBZPix78MXzoMdv4WXfAku+VDjKCu7cL52P6bzZb5UvgJzYA3c8CFW9CXYP5mvuT+hKVWbsjgrht67WLUgCFR9TV4ku7ZCwA5Mtceuzdo1eYZ98eKWkwdCyfMKQ66OaJxPuzZCLefpL4cPbmM6uRioft9eSOkOdXnVBSIS56fvo5zo51PlV1XPP8PrYdUFLNleubCIlbwYMRYG1Zw878d4hReL2yo1edkRYV2FIHnVCRq1t8srUNFdG+4EryhK4MD6iVyp+SDkFkeaSdQn6DtxeEYoeSM9qdDbS2qNYcjFiPNR24melFYzsUBiaq6MqlRt9SjNF9WJF5UDZfFJcMXnSe69kw/q3w1uvCiZpDul4h16HMpzdmctOEKvPRovotfkRWu88Go0SSc0Huh7JsyNwY7b6T30AD9KfpjhX70PRo6Dt90MZ73Gcx+gkbhO50sUlSQ896Nw4BFeav6iZrSZDEq2CfbO34NZrsnHc8JZk1dtDIneXXuwbY0X4vnCrvVX8nr8avIWovGicnEQujRC1YI7risQY+4qx/fqC4TbsesOHjntA0zSW3uMn/FKsuOPcbKyMyZ5MWIsFGSdvt/Ei2quXeNPwq7JU5RKh21wTZ5X7p4Mf41i10LwBISoGXRAVclrMSNPIp3QPGe7Hpop0J/WI01EcItQEWrR/NfkgVhU3UisXOzlyT+Kkld0KnkSp78czn8bb9N/xrI9v/B4poAY8dWhxdUx6ULCX8mLTsBTfjNIXSBft/44Sic0HkyfC4ksXPduXvCH17JcGWPuRV8UDRYOouq2D9BIXKfyYqqEesqVsO5iXnj46+SnDtm/7am5upFm234DakKMYHOBs7u2ajtHt2tld23rEy+qowhtJc+DOPb5dNculF1rWTQo/X4IGzdUE7Qsmy9WX8jWFVcAdRMvTn0plqrzEu23sV0bI8ZCIdTEC18lT63GrwyuDWnXukeypBIqM4UyZdOKVKjcn9Y967MMU4zVakrJywy51g81g2zSe8E+NFNgUV94FQ9EcX3RMGu6oheqJg/E+3NTM+R8U7lf5QhKnm3X1r+nyz/Ow8oJvGDrxxuGrDtRKBudq8cbfUCQpkUn2DelPaxNqOTkRWyKSSc0V8LoBa+FOqWrTBtJOPlFMD3Kvatez7ML/4p21h812LON++Cl5JVFPayiwPM+Sao8w7vVH3CoUnogyH2FFJXy8MQvYOW5rjNRQahhcmJFK0qetGvbVpNXcih5Htvs8SN50q7t5NSVOnjVUfohbNxQ0mnXDq6BF/0bvOyryGE2NeefnkXk11zCFdpvyReDJ9QsBGKSF+OoR7juWu+JF5rqeK7MyguwCbzCkNO6Zt8X1q4FfO3aybkSltXkSLM21eOBf4TKoekii3ojkrzKydh5tV5uooOzXehJ6a5K5VS+RH86gV65wo+k5Nl2bd170lN8I/NmMuZMzZD1ehRKZgdJ3v2i8FytHqe6qqAqjYurZVlN5+QVDdP3t+lE0fC2awtlA178WXjfJn695t3MKZlQjSApj4kFU04St+w0dh/3al6n3cTEtgeBCrlPJaAwDd95hZhzev4fe76OXQNXLDsmlYQ/B6R0FVWpKnmtdtemdBVFESRtNkR3ba5ouMZQSSUvyvmsVXjVUfqhYVqK17brM/jOewsMraVoz66tfX7xlKtYoYwxcOCu0Psyn4hJXoyjHooiFibfsWY+Ey90VbXnFjK0TtQpzRzwfU2/2bUSUUnetAfJk52rkbtr2xifArK71oPkzRZYHJHkpepInmVZQi1y+Y7mA9mk5j7xoqLkJZuwa0tudm0FO3rP5LC6CB662vP5hU6NkzJNGH2wweYUEwEaOxsN08KyXMhqAPyUQTcUPKJH7Nq+ZA/0LiFfMkjpWqiGlLRHx3CNUgfMPPWDzJBh5PYPg2UxnS+zPDED//Ni2PE7eNlXRfiuB2Sg9mzRaErJUxSFnqRQAzVVaZncK4pCtlJikQvMyfOe+JIPWevWTqR9yga8UD12gu1at8k1pfr62QqUjS9kxkqzZs/1ofdlPhGTvBjHBOwYFA/Ydq1fdy2E7rC1u3Vdumsl2lWTN1GZWxtJybMz8tqo5Pl01x6aLrAoQmctNNZ/SbV1wRovHLNHnRB2rbMmL3rjhe5CXPuzKW5LPl0MWZ8bd31+odwhJe/wk1CaranHk3Brlih5qBxBSEe03dxy8sQ+1Xbp5ktmaNLhpeTJ71Vi0dJlfKb8ckYO/B4e/SnZub18aPQv4MBmePV3RG6aD2x7tNCckufcRk8yHIENs71cSSh5iuJtufamxOfg1mE7twB2rd0AFCl+JxyxrumudUBmqdYf4+lMHzea57F+/y+Fbd9liElejGMCqqIETLzwzsnTnQQxJMmrKoO1t9coeRFO8AOZBFP5kms3WVMjzWYPQjnfViUvmxCTA+qVrELZYCpfZqRFu1Zud6HsWufsUSem5kr0Z/Tm7FrD8oxAGcgk+Kn1NDBLsPknrs8Xdm0HFtfRB8RfR3yKhJuS59pAEgJRF+tq+HN9TZ5WQxSjKJzeSl5tY8WinhTfsy7jYGYD/Pyv+VLhb+g3xuD118KJlwe+To+thhmukzvCQFq0rTZdSGQqowhzhTLZhOZ6/hOvK/bdLStvIeza6nETrZ5TVdwvqJyo6a51wOtCJqEp/Nh4mgjjfsK/UWohEJO8GMcEatQ4F0gS53YCqHmuVL4Cpl5Ikle/eDvVhUyECIT+dIKSYbkqZbvGxaglOV8zFGSHcJuVPGhcsGV8StSaPElepNpVKneBkufRXdufTjRl1xbL3nVsA5kEdxbWwPAGT8s2XzY6M+1i9H7Q07DopIa7xCLY2PUMRO58jkryih51ValEbR1VPkKtoreSV7KDyEFcAC7q7+Hqxe+EyZ1olPn+6V8WI9JCIOuYf2wreREJurwwbLUez96nhF4JQzY8M/KgSirdpl40M4e3VdjzYiPW5IWx8O2JF3VoiDuqQFEU7tHOZEYfhoevCb0/84WY5MU4JqApiu8kAsNHydNUx3MTaehbHsKudbd/nSf1qEoeiNiGejx5YJrhnmQ0pWyi/SRPLtj1RFQWike1a6UqJK+qi00SiXbBrbvWNC1mCkLxkUpelIkXolvY/f30p3WmCwbWqVfB9t/A9P6Gx4icvDYqKKYBd38d7vuWsGq1xoU/7RJ7YqusTTReQDS71k2Nqd+nfCm8kuc2xcOq1NzVRKQAywbS3FY+jdzLvslLCv9IceSUUK8B1Zq8XEHU5KlKI2EI3EaqvSQvXbFrc8WyZ0ae8/XcustF/WOHArk94EXM/VAohbsg8rNrdVVxfZ+JRIIn+i8Uv9MIYw3nAzHJi3FMQNMU35y8oJo8y6paunaHrQ+8Jl6kmqzJ68+Ik6xbXd6TB2Y4fklv6G0BbZ92AVXSWt98YSt5TUSogEPJa5JItAvZpE6hbFabcBCF6KYllFa7Ji9CXpaYxev+fnrTOpYFcye/BCwTHvlRw2MK7VTydv4BvnIJXP8XsPR0uPLfXR/mquQ1qbJK2zWsIlMom672drpun6LkB7oRhnzJpGxatSPLECRv31SesdWXsYfFDSTQD1lH80JYVakeUv1vNT7F3qfKKMLZguEbrlxV8txJ3nxateAde+OHsPWrcmZ2fXmPXw5kOqHxROYMyB0WIeJdhJjkxTgmoCkBdq2dk+dekwcOhSYMyTOlXVt7e42SF7HxAhpJnmVZPL5/hhOaIXnZETFKq02QpLVeyZMJ/VG7a+2avC4heXJhzTnen5xbK3LyKjV5EWfXer0fuejO9B8PS0+Dhxst2yi2pCem98EP3w5fv1wsUi//Orzp+pp8PCfSemO2XbHJesl0REWmUOmabdhOolHJC/u5uNXkTdlzaWuJz/L+NPsm847vPXxHezVCxagojdG/Nxlg3NPitAvnPs1JJc+HOPYGKHnz2XQB/pNXvCCJdRDkRVN90LLfbOaUrvJo8nTxPzt+G3qf5gMxyYtxTEBV/ZU8r8gTqE7BMJ3NF1N7fTupDM8w5ObsWlkbVD/m6tBMkcm5UnMkr40qHgjrBxqVPGnXRplbC44IFZvkVdSihWq8cNhtEs7Fvhklr+ij5NmksmDAaVeJQel1FxctR6hYFvz3C4VKePH74V13idfyUZhSCbVhcW2+Ji+aIlM03EltOqGSr1Pywn4uUjEu1JB3d5K3bCDNXMlgd6UONpKSl6wSpbwHWQ3cRuWYaGfjhV2T50Mce3yUvLmSOf9Knn1xEC0MOZySJ2N9GutO/ZS83SyD3mUiTqeLEJO8GMcEgpW8yuNca/LE3xolDwsmd3luz+6u9Wm8iBqhAo1K3hMHpgE4fklf6G0BoiavzSTPy649NF0km9Qiz9qs1uTVKnkLVZPX45IVJhWf/oyOXrkYkFELYeDXeGGTgmJZEC+Ah39Y85iWI1R23y3iUl70WXjOhz2nNTjhVpjefE1eVCXPdLWnZci43A+hLoXbF5H9p9YpeeI77nexawEe3y9+d80oeXNFo0JCm1DyZIRKu0heJdsyVwin5HnZtfPZdAHOWs5oI/HC1eTV1gJLlH3s2lRCo2BYsPYi2P7brqrLi0lejGMCNc0TLvBS3sRt4mdiGE6Sh69l6xXJ4lQXoigw/bLxIl9L8p48MAPACUsjKHmmCRO72k7yvOzaQzOFyJ214E3ydJf5wvMBdyVPKj4JkpWRXsWIY828Fg67UL9owNBaWHVBQ/deWAvKE4/8CLQkbHxR6KekEo0RKi2TvCg1eS6vkapb9KPO9BUTM6okTyq0shZWQnawy99dfwQlL6GpJHXVDkNu5nvrsWvy2m3X+it56YSYtuFp187j3Fpw1HJGyskL91uxzzsuFzJeY/tSuir2Ze1FML03MH1hPhGTvBjHBDQ1XE6ef02eY+oF+JI8z7FmlZOTqkSLHJCLSYOSt3+GvrTOkihNDbMHwCi0NSMPHEpefYTKbPQgZHBEqHRJTl6PYyyVhLMmz1byIk28sDztWrtQXy6sp78c9j8MBx6tPFeMA2taRTErzRzHXwrpgdBPEwtafb1Sk2HIkbtrvWvyxP1iO4UISh44FukKnOTdiWUDGaA5JQ/EMSQjVJpR8pxhyO1AJikjVPy7axVFoSelu4Yh50tGpNKTdiBVdwEYBuHtWvdti2k73nZtvmwKkgddZdnGJC/GMQEx8cL7/nJAdy1U1T56l4Ke8Sd5sru2IUJF/OQyiWiddbqm0pvSGyJUnjwgmi4idenZnbXtJXlpH7u2GSWvOvGiEqFiE4kFilBJOZS1CmSNZH86YZPPqDl5Xu/HWagPwKkvBUW1GzCanZpgY/edQnU49WWRnuYWMVEdzxaxJi9q40XZ2651bicfoSYPvJW8+pq7JX0pFKWq5EWpyQOhBs8WukfJyyQ0imWTmXzZNycPoC+l25+LE1Gmi7QLcu5uIYKSF7ZJqVqTF96uTct5t4s3QnowJnkxYsw3VIWQEy8a77NJnny+ogg1b2yb5/bkZIr67cmFJ0oQskR/WnepyZvhhKj1eB0IQoaqyuBm10addgHeEy+8atg6Dal01NbkObprVTnxIkJ3rWGS9FjsexyF+gD0LoH1zxDByJbV9NQEGw//UAQen/S8SE9L1wUPQztq8sLn5Lkt1Kk6RTBqnVi9kifJe71Sl9BUFvWmbNs4KsHOOpS8Zr43+RtrV+OFvJAom1agOiiUPLfGi/m3a2UdZT6ykhe+u9a18cLjIsa+SFBVoebFJC9GjPlF2IkX7jV5FbvWuXgHxKgE2bWZZPSfXn9ltJnE+GyRQzOFaPV44AhCXh15H/yQdemuLRsmY7kii5uya7srQsVW8hyW1VS+ZC/2iaYnXoRU8gDOeBWMb4N7/tte4Jqya00DNl0HJ1wGqWgXCX5KXuScPHt2bZScPG+71lmT16qSpyrutqisy4uq4oE4hkSESrT9k2h3GLKzKzaoMaonpbuO9VsIuxYaY3OCEJZY18/Mlij61M/WXCSsvQjGtohooi5ATPJiHBNQQ068cLNr9XolD6okz6OLyos0aqpCQlPIJppQ8jKJGiXvyYPCMjqumfiUnsWhOimjQFpmTiVvLFfEsqIHIYN348XCjTVrVPKm82W7ON+eeBGx8cI7QsXRXStxxqvguOfADX+FtedeoEm7dufvYWafsIAjIp1oDIstesz1DIKqKiS1xkgWLxQ8FDpnR2QztYpuNXm9Kd21DGJpf/Mkr1qT11xHaibR3jBkJzkL2mZvSvforo3W5NIuuE1e8UOhHXatX02ek+RB16h5McmLcUxAD5h4YYZQ8gzn84fXQ2kWZg+6bk8+1C13L61rTeVKDWQSNTl5T+yvdNZ2QUYeiAU7pas1JK/ZubXQOPFCEomodV/tQjbZWJMnRl8JS08SnPoQVT/4ddemdNHRWFPjqGrwsq9C71KW3PB2BpluTsl75EeirvTEaFat2K/GHDGZDdiMlS7mzraak1e1feVi26qS59VUUVXyojVdQLUmr9Ckkre0P1X5G2FOte/+hFfyelM6M641ec0FO7eKVKKxAcgPoe1aj8YLf7vWEcGz7ExI9MQkL0aM+UQrEy8aavIgsMO2atc23pdKaE3ZG/3pOpJ3YJpsUmNFpeMvNDpE8kDYP05SYgch90S3a3VNRVMVm+SVF1jJS+oqCU2pqUuamivZio7cryhKnt/EC0VR6Em6dDT2jMAr/wc9d4DPJr5IKmojilEWVu2Jlzel5rrliFU7n6MT8Ci2m1Bj/LprDUdDSgs1efmyHVtUD5mVVx+vEgayJq/ZbLmz1wxx0/ueycbl/ZGf6wbnxWaQkudVk7dgdq3eGOXjh7CZkm4TUCA4DDlfMkQttqbDmgtjkhcjxnwiaOKF4ZFrB44IlfqaPAgkeW6kMZ1QIwUhSwzU27WVmbVu++wJ0xQhzh0iedmEO8lrxq4FoQzJE/lC27Ug7K1aJa9kB+ZqqoKqRKzJ84lQARGjknOpg2LluWy/4MNcoj3AcZu/GP4NgBi7NHsQTovWVStRH1cCrX039XNn/SBn17ptA2qVvCjdq41KXsnTjrWVvFR0Ja8npTFrhyE3R4wiz6n2gVO9C1bytAa7tmSIGb/z3XgBlSknEWfXhtlPO7qpIULF8szoTOkqpuVoulp7ERx4BHJjofevU4hJXoxjAqGVPJ+xZjXPl/EjHh22lmWhKLjW9KwdybJ2JLqC0p/RmS0atqIlSV4kzOwDo9gxkpeuhKtKHJpu3q4FoZ7V27X6AkWoQKOaIWy96uKoayqlSBMvDF+LsycpvnM37Fr/Kq4xLmb1g5+HJ24K/Zo88kNhJx1/WfjnOODWLNFsTR5Eq63yqmVzRqjIhT9K92pjTV7ZM+i4lZq8bFJnzg5DXvjlt6YmL4DkLelPM5Uv82Rlyg7gsMYXwq4Nf9yUI9Rpek+8MD1LRZxKMgBrKnV5u+4ItX+dxMIfZTFizANamXihu9XkJdLQt8JbybMsV8II8D9vvoD/98KNIfe8igF76kWZ6XyJ0cl89PgUOyNvXeTXD4NMvZI3WyCpqZEmAziR1NVqhEoLdV/tQjZZq+RN1Sk+SU2lVI7SeBFCyXOxyEAoE/+v9BbywyfDD/8Y9j0U/IJGGTb9GE56PiSzoffTCbeIiVbibaLYtUWvnDxHTZ5caKOoS6k6JU98r141eaI8opmavJ6kUMMWSv2qh9OuDaoTfvX5q+lJavzrLx63b5OEesG6ayMowBCO+Ns1p24TL3zGmoEjCmjluWKSzI7fhtq/TiImeTGOCYSdeOHWKKHaNXl1JxSfGBXDdN8WVGvNokLaglNzJTuMNbKSZ5O8Dtm1Lkreot5ktLBmB5wzRbvBrq2PkRCKT3Wx1zUl2uxawzsMGSqF+m52LWLhypPiwPO/IvLuvvbchrFnDdh2K8yNNW3VgnuAsSTgzQRVh7XdLMvyHE3lVBdtJa+l7tqyp1K3rD+NriqMNBEL5Awc7gYlLxuhJm+kN8VbL97ADQ/v48HdE0D1GFiY7trGvEYv2CQvylizhpo8f7sWHL+JRBpWntcVdXkLf5TFiDEPEBMv/Oxa8VcPW5MHosN23N2uNS3LNVi5FUglb3KuxBMHmu2s7UxGnkQ6UUfymgxClkh2GcnLJjU7J69smOSKRo2ik9DU0DV5hmlhmN4p+iAjN9wXMrmgqCPHw9tvhWVnwNVvgV9+WOTgueGRH0GqX8SwNAkvJU9R3JXwIAhFJnixloquX3dtoWzaC380Ja96nFmWxUzBm+RlkhrffftTeN2F0SfGOElVVyh5jn0IqskDeNvF6xnKJvj0jY8B1WNwIZQ857khCFLdDUOskx52bSmKXQuiLm/v/VCYCbWPnUJM8mIcE1AVfyXPsLwbL1y7a0EoedOjUJpreI5petu1zWIgWyV5Tx6YIamrrB6OaLmN74CeJZCI2JEbEg127Uxzc2slklpjTd5CjTUDWSMnlDW30VcJVbHHrwWhOgrMz65172iEOguqbym88Sdw3lvht5+Db79cFH1bFhzeAnf9F3zvdfDg9+GkFwiloUnYC5pDfStWRj41o9imdC2UkldVY7xz8vIlZ3dthMYLXYz3siyLXNHAMC1fO/a8dcP27zEKnERqIerY6lEbhhz8efWlE7zzWcfzmycO8bsnD9nf20IQ1mSEC6pChDpNmWUaqbvWPv4cz1l7EViGGB+4gFj4oyxGjHlAsJJneqoQrjV5UO2wlRaoc3uW5WnXNgvbrs0Lknfc4t7oykkH41OgEqFSqid5zSt5qcpsTZAnWaVp67cdyKZ0m8RKkueM2kjoami7thiijs1PyWuwoPQkvOgzcMUXYPvt8J9Ph8+eAV84B376ftj7AJzxSrj0I6H2zwtujRclw2y6VtJtTJobij4kT1UVkroIVa5210awax3qpP29NlFzFwTnBI1mZte2GzKLUcQDhfu8XveUtSwfSPPPNz5md34vBGHVNSV0XFEUu1Y+rrEmz9uudVXyVl8Airbglm17ZqPEiNHl0FT/E4JhunfWyucCjY0bQ+vF37FtsPikmrtM04oWbRICtXbtNGevHoq+kYmdsPKctu6XE1lHTp5lWRyeKTYdnwKQckSolH2upOcLPUnNVvLkiLma7lpVCa0u2I0kfkpe0lvJ8yQz57xBDEq/8a+hbxk8/T2w4VkwvEHMXW4RrmHIAbWFfgjbeFEI+LxEjZbZtJIHQvGZdvle2wVnTV43KHmKopBN6pG+u3RC472XnsAHr3mI6x8cBRbGrtW18BdUUexa+Tg3u9YrBzLlpuSl+mD5mTHJixFjPqApwRMvvGrobLu2niT6ZOWZVnP1SX6Q4av7J/PsHp/jledGrKszDZjcDae+pK375YSzJm9yrkTZtFpS8pK6aqsFJcO/fm0+kE3qdk2eG8kTNXnh1IViiBrDnpRQ8kQkT+3x5Gdfsvp8+OMIsSoRUA2LrVXymv1u0olwg+YLAfl3kiw2E+shlbx82WDKxYZvF7pNyQPxuUVtArnqnFV8+batfOfOnfY25hsJVQn9W4uu5DXW+/mp1a5KHogGJxenZz6x8JcSMWLMAzQ1OCcvspLXswiSva4kT9i1Te+uKzIJjYSmcN+uCSwLTlgaseniN/8KZkmoPB1CxqHK2EHILdTkpRwRKn4DwucLIsy2jGVZrrZelMYLGbXi956ySZ2yabmOSpOZcfNtX6fs7lpHTV65eQIeNifPl9RSbZ5oKgzZoeRVyXv77VpnDVyUHL9OIpvUIs/C1TWVDzz3JPucuhCqZJTfWpSaPPG42kgdw7QwLe/faro+QkXionfDCz4d6jU7he44ymLE6DDExAvv+w3T8qnJEz+TBiVQUSoxKo0dtqbZ/po8RVHoTye4b+cEEDE+5bZ/gV9/HM54NZz+8rbulxOZhEbJsCgZJgdbDEKGSgddqZqTt5BNFyBIl2l5124lItQJFUM0XkjlJ1c/2ozwA9fbDa+xZn7vww81I6F8UCz7L9SSLDY11syh5FW/104oec4Ile5Q8rJJLVRnbT2ef9oyTl85ACyMkqdraoSavCbs2rqaU/GaQXZt+DFr84WY5MU4JqApLt2xDpiWN8nzVPLAMyvPb3utYCCTYKZQRleV8FMzbv8s3PxROP2V8JIviiH3HYJUKuZKhkPJa43k2WHIXaLkAcwWyvYc4Xq71k11c4MkLUm/nLxKDZdbVl6hbCxMPpnHWLPma/LqRkJ5wK7J04Ls2mjWHHjV5LVfycs6FLNuqMkDcU4ZaqJTWFEU/vHKU3nuKUvtKSDziYSmhJ4u04xd6/wdB4V9eyp5XYC4Ji/GMQFNVX1JXtlHyatGqLj8gIfWwZM3iZmwjqI+vzDkVtBXab5Yv6gnHOH53Rfgpo/AaVfBS77UUYIHVZKXLxocbpdda3fXWguu5MkC81zRcI9Q0VT3WbMuCBOhIpUftw7bQslcmHFSbmPNyq3U5FWOmbLh+1nYaoyXklcJVc6XDRKaEukiy1XJyxwbSt4/X3VG0xekZ68Z4itvOK/NexQOuqpiWf4ujER0Ja+2u7YUMLbPrU61WxCTvBjHBDQ1QMnzsVc9w5BBkLxyHmb2Q//y6vY6EIYM1Q5bz3o8owTFWfHfw1eLYNxTXwov/Qponf+5SxIklLwiqgJD2RZy8mpm13aDkldV1qbzJbJJDd2xTwktfDF4mMaLrEM5rIfX9IdOQ1UVklptYXor3011JJThG1tSCJhkkU6IkWGFkmkrc2HhzP6bzpfQVKUjHaPObXaLkrduUfQ52t0A2elaMky0gIvX6DV5as1vLsiujZW8GDEWGME5ecFKnmt3roxRGd9eQ/L8GjlagSR5xztn1u69D77zKhF+a5Zqn7DxCnjZV+eF4EE1UDVXFHbtcE+qpSiZpFYtgG6l7qtdkO9vtmA0zK0FUScUNULFf+KFt5K3kEPu68eAtZSTJ2v8AhbIIMstpascmhFKXlQb26lOypFmnWhoUSvkca5kdMXEiyMZicpVdMkwAz/LqHZtUlMZc5nN7PVblcd+N9bkxSQvxjGBMBMvApU8t+cPS5K3DdY+1b5ZKHntXyRkMXjNOLPttwsl8anvgvSgGDyf7IHsCJz4PNDaX1vkhXSNktfatAuoVfK6oyZPkq5yw9xaiJbCH6bxokoq3ZW8hSIKzjFgIOysZpWptEPJ80PREPd7fV6iI9Joivw6s//85ta2Az0pQfK6YXbtkQypqoVpvogakO12fIN3TZ4M4w47Zm0+EZO8GMcEgpQ807Q8pXjVrslzef7AakBpaL4wOzDxApxKnoPkHX4SMsNw+cfb/npRIe2ofFHYtYtbCEKGagG0ZVldUZPnVPLcyICuKe4XAy6oNl745eT51OSVF1LJq69ZMpsmRmGtrkC7trJPgvxG+1ycNVVTcyX6Up27MBKdrMVYyWsRskwiTPNFUPxOPVK61tA9Ll7T+/yTrlO3uwXxpUSMYwKaqjSGGTtgWN4TL3xr8vQkDKxqIHmdsmtPWtbHkr4U6511NIe3wMhxbX+tZpCps2tb6awF57BwszuUvGRVyRN2bS0ZSGiqbcMGwVYHQkSouHfXLkyECgilI19uV+NFtenBD0ELtWi8MCg0YYU6s/86reRlkxqqUj2vxGgOsis9TA1soWygqUpN/awfUo7oJvEawaUVUknuNsRKXoxjApoSPLvWy17V/JQ8EM0XY7VZeaZFR+zaK89ayRVnrqitFzq8BTY8s+2v1QzsmryKXTvS05pdKxf0omG2VPfVLtiNEJXu2voYGxHrELbxwqg8x6/xokIqXXLyhC25QHati5LX7HdTJVhBJE921wZHqEQlvzVKXr7EqqFspOdHQU9KJ53QFnQG89EAmV9aDlEeETVTsn7iRZBdC3IGc/fZtbGSF+OYQCsTL+TJxJMkumTliW7dZvY0GDWLQ3EWpvd2jZInFZTDMwXyJbOlubXgIHllk1LZ21KfL0glb67SXVuv+DQz8cJPyZP2t5eSt1AdmumEWmdnNW+l20pewAIZZG/L8WiFcutKXifiUySyyehjxGI0Qo+k5EUkeQl3u9bvgiyta4Fq9EIgPtJiHBMQEy/8SJ638iajUHyVvNkDgnDJ7XUoDLkBY1vF3+HuIHmSlOwamwNaC0KG7rNrbdJVMJiac6nJUyOk8NsLh/dxIqM8vHLyFk7Ja7SzWpl4AWGUPBNF8f68UrqGYVrMFJoheVUlbzpf8o1yaRXZpBbX47UB8lxQDlWTF031lkqenMISqiYvoTHn8jtdaMQkL8YxAU3xV/LEhAr3+6q2gMfz7Q7b7Y7tdSYMuQGHt4i/I8d3/rVCQNbk7RrPAa0FIUOV5BXLJsUusGtVVSGb1BjPFSkaZgMZSOhK6IkXpRCNF1CZl+vaXWss2PzTtIvS0crsWghH8vxm9UpFcGquFFkpk9l/cyWDmUJna/JOXNoXbSRhDFfI400q4n4olM1Iv5WULoKWpUoYFIYMcq5195G8uCYvxjEBrTK71rIs10VC5OR5tMcr8jEei/fQOvF3fDssPRXorF1bg8NPir/DG+bhxYIhF+xdY5LktWrXiu0Vu0TJA9EduW8yDzTON02oaqgaIQg38UK+nntO3gI2XtTVLLWn8SKou9ZfjZHq2ESuuc7VVEJlfLaIadFRkvf+557UsW0fS7Dt2jBKXsSAbPu8U1Gow1yQ9aYS7JmYC/0a84WFP2PGiDEPCGqeMC0LLyVeURR0vwiWoUYlL8yonbZgbCv0LYdUdygDqqqQTqjsHm+TXatVbbSSYdkp9wuJnpTGvilB8ty6a03Lf7qKhKwxCyJH2WSjkmdZVlO1Z+1CStfqwpCtpu1a2UhRCMzJ87eE5SI+WzSaqlVM6RoHp8Uovk7MrY3RXiSCHBYHoqre8rHymAxj1/andXvucTchJnkxjgnYJM+DqJUNf1Kmqj75Z5khSA3UdNj6hSu3FYef7Jp6PIlMZbwUwEgb7dpSC2pRO5FJaFUlL9OYkweEar4oGaLGLChKoyfVqOSVTQvTCp/71W6kG8JizZYbL4KCZIM6JJ2LeDO1iumEysEZSfJik6vbUQ1DDpeTF7W7Vj4PsDvm/c4/fWndPu91Exb+jBkjxjxAEi4vZT+IlOl+OXuKAkNra5Q8a74aL7ooI08iW+lAHcwmWiZlNd215sLX5IEgXVUy0DjxAsKRvELFfg6K0sgmtYbu2mqC/8IreaZpUTatpr/rpKaiKOFr8vz2yf53U0qeyqHpIhAreUcC7Jq8EKp51DnPzgkoEK5+tjetM50v280a3YKFP2PGiDEPkL9NLyXPDLBXNT8lD0TzRZ1d23Elb24ccoe6juRJZaZVqxYc3bWGWYnpWPhTVjapIQ8jt4kXEM5CKpWtUKS1J6k35OTJxWehIlScNXmyJqrZ70ZRFBE/ESInz78mr/r6Ueqvqs/XOFQh7/W1ljG6D1I5DhM+HnU6TNLRbQ3h7Nq+dALDtJjrsqkXC3/GjBFjHiCbKrzUuKDIEz0ggoWhdTCxA0yjsj1IKSV48PswsbPp/fbF4Up8Spd01krIDttWO2uherLNFw0Mn9Fz8wmZlQc0dtdGUPLCxo5kU41KXtSB6+2G6K6VM4WDg2KDt6cGjzUrB9TkJVpX8uSFXKzkdT/s1IOQjRdRu2vl8yCcXdtbCS6fyXeXZRtfrsQ4JiC5QfNKnuqv5A2tA6MI06OQGebFuR9x1dg18MMxWHcxvOn6FvbeA2PdFZ8iIbPkRtqg5MmTrax16QolL1UlE41hyLLjL1zjRZg6th6X7lpZEL5QESopXcUwLUqGaSsprcwVltMq/BBk1zpJXjNKnpMwx0pe9yMROQy5s3atPBdM5css6Q/9Uh3Hwp8xY8SYBwR11xqW/6xZTfVWAYFqh+3NH4fPncEfz36V/YnVcN5bYPtvYNttTe+7Jw4/CYpajXDpEmQqStfitpA8GT4sSF5X1ORV3p+i1Kp64MzuarOSV6ivyYs2cL3dkIRKhlQDJFrYl3RCC45QKZueI83ENhyNF02QX+fzYyWv+xE9DLmJ7to6u9avu1+q+t3WYbvwZ8wYMeYBcpqFl+VaNizfWbN6kJInA5Ef+A4sO533936Sf13xGbj8n6BvhSB/7S7IPbwFBlaD3jqZaicydk1e++zaqpK38HatVPL6UnrDMaNHWXhC5v71JHUKZbOmizBojmun4YyYKIYY+RS4PV0NVvJK/gu1U71rRcnTKzFAMbobdid72DDkZrprKxdT8tyve2Spgmi8ALquwzY+kmMcE5AqnX9Onn/jRWBN3hVfgD/+Fbz+RzysnSq2l0jDM94Pu/4AW37VyltoxOEnu67pAqp2bVsaLzRJ8gQBaEUtahekeuem9iQrC08xxMJTKofrFs5WahxzDhJUrclbOLsWRIBxe2rygu3aoJw8p3rXTH6gJHZ9aT2w4znGwqPaXRu2Jq95u7YYoiRB2rXTXVaTt/BnzBgx5gGBdm1ATZ4e1F0LcM4bYNV5YnuWZc+85ew3CMWtnWqeZYkg5C6rxwNn40Ub7NrKwjvbTTV5lffnlqUWpRg8rF3bUynodnbYLnSEStoRYBxmeHvw9mpn4bohKCfPqd41Q37lZ9mfia3aIwEyXzKok10GhzeXk1e1axOa4kv++2K7NkaMhUPwxAt87VpVVbzHmrltzxmhoifhGX8Je++Fx28Mv9N+mD0IhamuC0IGyCQEKWk1CBmq6lBX1eRVSJcbGZBKY5ju2mJIu1aSSmeHbbcoeYWyGUrlCIKoyQvTeBE81qz+3+H3oarkxeh+hP2tNRMcLi8ui3YHuelr1UK1uzZW8mLEWAAETbwwTMt38oCuKqGyzyTM+kiWs14jLN1ft0nNO9ydnbUAmWT7cvJ0TUVVuqy7tkK63DowE2r4jr8oOXlQq+RVc/IWLgwZhKLYlsaL0Dl5fmHITru2CSUvIWstYyXvSIAcaxb0W2smbqihu9awAi9iYpIXI8YCojrxwpvk+YUXB9bk1W+vvsZPS8AzPwT7HoTNPwm9HU8cflL8HdnQ+rbajOGeFCldZXFfexpCUno1J64bGi/8avKiKHkFwwxFjGSjR42SZ9u1C6TkOUaRzVdOXjGgeF5VFdv+bmqsmR4reUcSwo41ayZuyM2uDSqt0FSF3pQek7wYMRYCYZQ8vzUqVE2eA6ZJY/3G6a+AkRPgln8SDzAN2HWXqNX7yiXwnVfD1Gi4FxjbAmoCBtaE3qf5wmsuWMP1735621SmpK5WGy+6SMlzr8mLMvEiXOOFreQ5SJ6MG1m4nDwXJa+DjReiriq4Q1IStZaUvDg+5YiA/K0FZVLmmyhtaAhDDmHXglDzZgrdVZMXX7LEOCagBSy+QRMvRE1eBCXPjTRqOlzyIbjmrfCtl/D/27vzMCnqc2/437uqumdgGHY1CMjiEhQYARFBFkGjGPXVuONJ4pbEuMUlj4mS5ETj0fPG5xj18YnReKJBE19ROXE5JyZRRIOKihoVERc0ooKEsMiwzkx31+/9o5beu6u6q6drur6f6+Jipma6p6Z7uvvu+/797hv/eBvYvcXqdTd0MvDxX4G7ZgCn/BrY7yulf8DmD63yrx6+h3CvuI7992oN7PrihoYd9mLmUAR5zpq8Qpk8+/y6PK7Ji5fou+VocTJ5meVaOyCqV7m2OSOT5zwqatkM2bk9y+2QbIrpQEeyotuliZm8HkVE7GU0HjN5PrK7zjIRp1ybTKmSPfIcrc3M5BHVhVM6LVZyNcuUa6tek+cYewqw90RgwzvAAXOB0+4FfvAR8O2ngQv+CvTZE/j9qcDi64BUiSeLzeHcWVsLcV1zA5xwlGuLZ/L8jjXztvEiP5NX/40XGc2Qk9Vn8poMrWQzZK+/rxN8VrS7NlZ8rSWFU0zXyj7WKn2sNBm6W671ukkqjEEe/5opEjxNvCg51kyKlnoLMZUqvN1e04BvL0l/nGmPA4DvLAH+dDXwwq3AJy8Bp90D9BuWc+WmVa7dd47n8+nJmmIaNm6zBseHoU/egJY4NAH26tuc97WYXrty7c4CGy/qtdvY7ZOXSLlvoLy0gyl6fTEdXUnTerNV4HHo7HIs9zOcNiqVNIl2Sr1sodJzGLp433jhs4TfFNMyNl6Y7kaPUvo0x9C+O1zl2vo/YxJ1g3ITL8r3ydP8l2uLZQY1LT/Ac8R6ASfeDpx6D7BhJXDPMUDnjuzv2bYOSHaEshFyLcR1DTu6wtNCZXCfJjx5+Uwc3zYk72t+y7Veglan7+CunI0XTYZWt6a9BceaVbnxwrm+Qrxn8vSs6/MjvSaPuY+eIqZrZXtSVlKutb4/3bvRX7mWQR5Rt3MCrmIZFrNUUAYrSPS18UKhZNBY1vjTgK8vsgK6Zf83+2tbwts+pRaaDM3tOhOGNXkAMOZLfQueiztP00Mmr8tjJi9uaFbJuis7k1ev9XhAsbFmVazJy9jIUYjXF+rmmAaRyt4MpNfkMZPXU3hZRtOd5dq+zQZ2hKxcG45nTKIaK7e7Nulh4oXfZshVJ1lGTAPGngy8+H+AbZ+njzvtU0LYCLkWMl/Yw7AmrxTn/Lw2Q/Za4uzdpGNXZ+aaPH8d/IOW2QzZ+V2rHWsGoGhDZK8v1E2GXnGGs5mZvB4npmtls+aV9Mmzvj+nXOvh75stVIjqxAngisVppiq8Fijz8h5et115ffIq9ZXrAJUCnvm39LHNfwdivYHW/HJhI8oMhMKSySvG8LXxonyDVUdL3MjK5HUkzLq1TwGsgE7EHmsWwMYLp7xarFee5zV5Ma3iDOfEffrjjMnDMGF4/4ouT90vpnvJ5Dk70Stfk5f0+FhtbY5hd0ZboTAI9zMmUUCc15+SffLK7K71lckrs5HDswEjgcMuBN56EPj8TevY5g+BgaOLr+trMJkv7NUs7u8OcTfIK/3CkzIVUqZCXPcWkPSK6zm7a1NZs1q7m4i4mQ7nd61q4kWsTLnWYzamKaZXnOHs2xzD/z7tYJZrexDD05q8SjN5etZYM6+7a4H0GMYwCPczJlFASk28UEqVnV2rV9AMudT1+TLzfwG9BwJP/cQaibblo8hsugCyS3SlRs+Fgdcu/OlRYF4zeXpOn7z6ZvKAdG+7QNbkuZm8YkGet6kF44f2YyYuQgzN++5av28QrTcxzpo85blcC4RrtBkXH1AkuM2QCwRqzqFSAYTutxmyUggsHunVH5g9H3jyKuDdJ4Av1gAHnhjQlYdfVrk25Jk8twt/mSCvy+c6tt5xI69PXiWju4KUzuTZQV4VmeX0xosiu2sT3tbkXXhEdN78kPXcUPaxZgdqlQR5zsxsK5PnrVwLANtCtMM23M+YRAEp1SfPOVauT56fZsjlyr++HXIeMPgA4H+uBMxkZHbWAtmBUBhaqJQiIojpUnbUktc1Zo6WpuxMXkeivhsvAKuc5Yw1MzSpKnPd5LZkKZzJc4PikAf51L287K51ZytXsrvWbaHir1wbph22fMRQJOgl+uQ5QV65iRfFeuzlUvb3BVauBazxZcfcAOzabH0epXJtRoku7BsvALsLf4npDQB895YrlMmrZwsVwCqxOmvyqr1fym28cMu1dc5eUrgYHiZeVLqcIJ5RrvX6N+4EeWEq14b/GZMoAE5WrWAmTzmZvBKX1zTPa/K8BI0V2f8YYPRs6+NIZfKsF3ZNquw92E0MD+s3E0k7u+AxOGpp0nP65IUjk9eZNNGV9FbKKqW5TCbPa7mWoiWml3+sOVlzv8sJMluodPks127vDE+5lmvyKBJKTbzwEpTpWvGRaHnXp8qXfysiApz0K+DjpUDL4GCvO8ScMktPyOIB1vmW693VlbJn8Xrtkxc3svrkdSTMugc8TYbmlmurLaN6313bM/4GqHvEdK1s1sxZT+e3spLdQsV7nzyA5VqibucsiC+0fsP0sCbP0LSyOyYdThwZeCYPAPoNBSacFfz1hpgTQIR9PZ7Dy99Kl99MXlzHrkTK/Vu1Mnn1Ltfq7saLqsu1Rulyrd81jBQNhqaV3V1b6d+ntSavsnLtNgZ5RN3LCbgK9clzjpXbXet1c206M+jzJKkgJ3sT9p21jphRvq1DeiOBtz+S3k0GlEpPhLDW5NU/k9eZTAW0Jq9cJo9r8iif1Qy53BuqSoO83HJt+etojumIe8gudqee8axJVKX0xIvimbxS6XxrnZW3TF7NyrUR5QZ5IR9p5ohp5ReD+9140RK3ghtnh63VJ6/+mbyORLBr8opvvDAh0nP+Bqh7WM2Qy72hquxNSJOhI2kqJFOmXa719rfXp9nAjhCtyWOQR5FQanat8yRRquWJ5qNPnrJfp2pSro0gp0Rn9JAJHzEvO/6S/vvkAcCuriSUUugIxcYLK5PnNctRiq5ZrWdKza6tdCYtNa6YLp7eUFXyWHF29e9OpGAq72/IWpvDNb+2ZzxrElWp1MSLlOdMXp03XkSU8wTdU9ZjGR7mabptHXz0yQOsTF4ipaAU6t5CpSmmoTNhVvwimqvZ7rtXSFfS7DFrMqn7eMmaV5ppdv6mnYbIDPKIQszdeFFw4kX5TJ6uCZQqHCTm4pq8YMV7WrlWL7+7NlFFJi+9Pq3embx0M+Qgdj432eXfQjqTqbqXpyl8vLyhqmbjBZCeQ+u5XNtkcHctUXdzsnSVTrwwSpR7c5m1aIYcYU6fvJ7SQiXmI5PnZ+IFAOzsSrmBUN2DPKcZcrL6jReA3Vy52MaLELSMofDxsjSi0hY/6Uxeyv1ZXrQ2xzjWjKi7lZp4YXoor5YKEoteH9cPBaKph/XJ8/rCA1SQyetMhmanqdMMuTNlBrLzuTmml12TR5TJUzPkSjde2GvynKwcy7VEIZaeeJH/NeeYl0yel3V5NZt4EVE9rk+ernmeXet5TZ4d5O3sSqUbA9e5hYrTwmVnZxLxAErpVnPl4rtr42yfQjk8jTVLpip67nAu4+yUNTz+jbc2Ge46vjDoGc+aRFVyNmYWyuQ5rVFKT7ywrsBTJs/ZXctybSDcNXkee8rVW1yXsrNru+xyrtd1Pr3tcu2urmTGiK/6Z/IAK9MRTLm2+MaLMIxxo/CJaWJvRCr+vJxIqYqeO5w1oE651mug2Nocw47OZMlz6k581FAkOO03Ck+8sP73tCbPT7mWj65A9LRyraFpZXsqOkFgk+4tUHMzeZ0pt6QZlkze9o5EYGvySo01Y5BHuQy9/JvvRKqyndnumjx7fZ2fcm3KVNjVVfhvubvxUUOR4MRvpSZelHoMa265tnxDZOf6WK4NRk+bXRszyo9aSrdQ8fY30hzTIJKdyWsOSSZvZ1cqmCDPKLW7tv7Nnyl8nL+7Ustoqpl4AaRbqHgt1/axR5uFpWTbM541iaokItCkTJ+8EkGZr0we1+QFqudNvPDQoNVnCxURQUvcwM7OVHrjRQjGmjm8jmcrpdTGC/bJo0Kc54RSLYu6KtwY5C5HqKBcC1gZ7jDgo4YiQ9ekYCbPdGfXFn846L7KtdmXoer0vBYqHhaDp6wxXX7+RnrHdbtPXjhaqGQ2Yw6mT57mZilzWX3yesb9T93H3RBXInOeSJloqmZ3bafPcm2TlcnbFpIdtnzUUGRoImUmXhS/rJ9MHpshB8t5su0pQZ7XiRcx3d+YrpYmw+6TF5YWKun7o+YbLxKVvVBTY3PW5CVLvKmqtI9jek2ev2bIrU65lkEeUfcqNpos5WF2re6jhYrJNXmBcsokPSXI8zLxoivpP2jpHdftPnn2mrwQlWuDW5OXH+QppbBpRycG9YlX/TOosTjPDaVaFlnl2krGmmWXaw3f5VoGeUTdStOk4okXfsq1Xq6PvEv3yesZt2fc0LyNWvJZbm2JG9iZVa6tbyYvs1wbxH3THNPQUaD1zJadXehMmhjSr1fVP4Mai7MZolTLokSlGy8y+kAC3tfkORsvuCaPqJvpmhTsk5fyMIaskhYq7JMXjJ7XQsXLxgvleyNB7yYdu7pS7uiveq9Ry/z5QZVrU6bKu+0+39oBANi7P4M8yuaWa0t0PeiqeqyZXa71mA1s5e5aovrQpXAmz/RUrvXRDJnl2kAZuoaYLnUParyK6RqSZukGrZWUkKzdtSHaeJGRSQxmrJl1Hbkl28/bdwMA9u7fXPXPoMYSs99IF2tZpJSygryqJl7YLVRKLdrO0CfOjRcQkf8QkfdEZIWIPCoi/TO+Nl9EPhSR90VkbsbxQ0Tkbftrt4u9YllEmkTkIfv4KyIyMuMy54jIavvfOd35O1L4aMUyeR7Kq/7Gmln/c3ZtcH75L5PwL4eNqPdpeOIs0C7VK8/ZeOGHtbvWyuSJ1H/MWy0yeQDyeuWt32oFeSzXUi63T16Rx1rKVFCqsr9PEUGToblBntfHm6YJ+jQZkS/XPg1gnFKqDcAHAOYDgIgcBGAegLEAjgXwKxFx3i7eCeACAPvb/461j38LwBdKqf0A3ArgJvu6BgK4FsBhAKYAuFZEBtT+V6OwMrTCux7TEyqKB2WaW64t3ww5Xa6t5CypkLljv4ShPaRc57yglCrZVtL3raUpnclrMvztzK2FzDWBgazJs6+vM6dX3vr2DsR1DYNauPGCshll+uQ5b7QqKdc6l3N31/rIvLc2G9HeXauUekop5dwCLwMYZn98EoCFSqlOpdTHAD4EMEVEhgDoq5R6SVk1kPsBfC3jMvfZHy8CcJSd5ZsL4Gml1Bal1BewAksnMKQI0qRwn7ykj0xemaVWANgMOeqMMtkFwB615POFx8nkdSRSdd90AWTv7g2qTx6Qn8n7vL0DX+rXzDWulCdWpoVKl720odK/zyZDx257+YDXci1gBXncXZt2PoA/2R8PBfBZxtfW2seG2h/nHs+6jB04tgMYVOK6KKJ0rUyfPE8tVLyPNePu2miKe+jCX8k8zZYmA0lTYXtHsu7tU4Ds8lWw5dqcTN7W3RjSj+vxKF+5ZTTOY7DSTHPWVBcff+N9mgxs72zwcq2ILBaRlQX+nZTxPT8GkATwgHOowFWpEscrvUzuuV4gIq+JyGsbN24s9itRD2dNvMg/7qVc6293rfU/M3nR5GnHXwVtHXrHrSDoi11docjkGbrmPi6C2XhRvFzLnbVUiFFmaYRzvNJybda6U1/l2ljPKteKyOUi0lcs94jI30TkmFKXUUp9RSk1rsC/x+3rPAfACQC+rtLb0NYCGJ5xNcMAfG4fH1bgeNZlRMQA0A/AlhLXVehc71ZKTVZKTd5jjz3K3RzUQxWfXWv9X2qjhOanGTInXkSauyYvWWrjhaqoTx5g9Y2r985ahxOYBbMmL79cmzIV/rGtgztrqSC3GXKRpRFOkFdNudbh5zp6Yrn2fKXUNgDHANgDwHkAfl7pDxWRYwFcDeBEpdSujC89AWCevWN2FKwNFsuVUusBbBeRqfZ6u7MBPJ5xGWfn7GkAlthB418AHCMiA+wNF8fYxyiiDE0rmF0x/Yw1K9PkFmAz5Khzd9eWyeRV0icPALbs6gpNO5kgexgWKtdu3N6JlKm4s5YKcjZe1G5NXvpyho/n89ZmIzQtVAyP3+f8dscB+K1S6i2nhUmFfgmgCcDT9tW8rJS6UCn1jog8DGAVrDLuJUop5xF/EYAFAHrBWsPnrOO7B8DvRORDWBm8eQCglNoiIv8G4FX7+65XSm2p4pyph7MmXuQfd9bQlVpY6068KNH7LPf6WK6NJi+7a62NF/775AHAFzsT2Ks1HJktJzCrVQuVdVvZI4+KS7+hKr0mr9ogL6aLr93src0x7AjJmjyvQd7rIvIUgFEA5otIKwAP+wwLs9udFPvajQBuLHD8NQDjChzvAHB6keu6F8C9lZ4nNRZdQ8E+eUlPmTzvzZAVN15EmrsYvNzu2grX5O3oTDZoJi+/GfL6dvbIo+Kc5+VimTynjFvp8oamCt/EtDYZ6EiY1vjCOvez9BrkfQvABAB/V0rtEpFBsEq2RD1GdRMvrP/9NENmJi+anLV2pXbXVrLxoqUp/XQdho0XQMZc4QoGwOdyfqeOjI0X652RZgzyqADnsVYsax5UudZPqRbInF+bxMA693csGeSJyKScQ6Pr3YCTqFLVTLxIjzXz00KlkrOkni7mZheC75PnCNvGi2AzeenH2Oftu9E7rqNvL6/5CIqScmPN0hsvqmuh4vex2tocAwDsCHuQB+AX9v/NAA4BsALW+rw2AK8AmFG7UyMKVrmJF6Warfpphqy4Ji/S0mPNiv+xdFaZyXOCq3qr9caL9Vs7MKRfc92ne1A4GeWaIVfbQsWosFzb7Myvrf+6vJJnrpSao5SaA+ATAIfYbUYOATAR1jQKoh6j2MSLlKdyrfexZl6aK1PjKte7y/laI2TyKl2zVPC67N+pM2dNHnvkUTHu7toiy2gSVZZrnceo4TMT2NqULtfWm9fffIxS6m3nE6XUSlhr9Ih6jKITLzxslNB99MljC5VoK9e7C6iwhUo8c01eOII8p7ed39+lEGcgfEcys1zbwfV4VFS5x1r1mbzKMtVuubaz/kGe14UO74nIbwD8HtbUiG8AeLdmZ0VUA9bEiwJBXsp7kOdtd631P2dtRlO53l0pU8FU/l84dE3QHNPQkTDDU651MnkBbLwArJKtU67tTKawcXsnhrB9ChVhaKWXRlTdDDlW2ZuY9MaL+pdrvQZ558LqU3e5/flSAHfW4oSIakWTMpm8EuVVP2PN0n3yKjlL6umcF5Riu2urGbXUEjfQkQjPxIsg1+QBsINYK8jb0N4JgDtrqTi3wlLssWZPnanXmrwwlGvLBnkiogP4H6XUVwDcWvtTIqoNQ5OC5db0xItgMnle1vhR44q5mbzCfyudycp3/PVu0rF5ZzqDVm/Ojtjggjzd3V37udMjj5k8KkJEENOlaDPkzoB21/pek2cHeWEo15Z9ZNoTJ3aJSL9uOB+imrEmXhTO5JVbP+c23fTRDJnl2mgqN/Gi2kweEJ41eU6mI4g1eQDQbKTLtWyETF7EdK1EJs9+rFU98cLf5ZsMHXFdC8XuWq/l2g4Ab4vI0wB2OgeVUpfV5KyIakCXYn3yymfdnGkYzORROUa5UUtVvPA4O2zDl8kLak1eeuPF504jZGbyqARDk7J98iou18YqfxPT2mz0jHKt7Y/2P6IeSy+SyTN9ZPK8rcmz/mcLlWhyd/wlg18M7vTKC0sm79CRA3H0QTsC20neFMvO5PXvHcvaVUyUK6Zrtdt4UWG5FrCCvB09JchTSt1X6xMhqjVr4kX+8WSqfJDnfNlLudb0MAuXGpfboLVIT8VqsgtuJi8kQd7sL++J2V/eM7Dra47paN/VBcBphMxSLZVm6IWb3APprLnfsWSOajYW9Wk2es7uWhHZH8D/C+AgWNMvAABKqdE1Oi+iwFkbL/JfeE2lyu6EFREYmnhqhmx66LtHjSs98aLcxovK1+SFpYVK0JoNDRvcjRcd2LsfS7VUWkzXkCjyvNyVUojrWsUTU6pZc9raFAtFudbrmf8WVsuUJIA5AO4H8LtanRRRLVgtVPKPp8zymTzAygR6aobMsWaR5syuLV5Ccto6VLa7FghPJi9ozTEdHcl0uZY7a6kcq1xbfE1epevxgHSfvIrLtT1hd62tl1LqGQCilPpEKXUdgCNrd1pEwdO1wmvqvOyuBaxMYKE+e7lMjjWLNE0T6JoUDfLSGy/8Z+PSu2sbNJNn98nb1ZXE1l0JlmupLGsmefHHWjWbgpr0asu19Q/yPO+uFRENwGoRuRTAOgDBLcQg6gbFJl6YpvIUkOkeM3nOt7BcG12xEuuEElX07url7q5t3ExeZ9LkzlryzCiTyaumh2NTFX0g+zbHQtFCxeuZXwGgN4DLABwCa6zZOTU6J6KaKDrxwlSeFuYaRXbnFro+6+f5P0dqDDFNKzrxopp5mu6avIbN5Fm7a9kjj7yK64XXWgPWY62qcq078aLycq0qkFjoTl4zeZuVUjsA7ABwXg3Ph6hmik28SCnlqXGx90yegggqXuxLPV/M0Mru+KskO+CuyWvUTJ5hzeb9fKsV5A3tzyCPSjNKtFDpSppVNequandtkwGlgJ1dKfRpql8bIK8/eYGIDAXwKqy5tc8rpd6u3WkRBU8rsqbO68YL3euaPKXYCDnijBJr8qppoTJ5xEAcvu+ghp3n6jSf/WTzLogAe/VluZZKK9cMuapybYWzawGgtTkGANjekQh/kKeUmiUicQCHApgN4I8i0kcpNbCWJ0cUJF0Kr8lLmd6CMkPTvO2uNTnSLOpK7firZuLFl7/Uiv/vO1OrOrcwc1rDfLxpJwb3aaqq1EbRENM17OoqvMEhkVKIVbCL3eFkzOMVlmsBWA2R6zgU1mufvBkAZtr/+gP4HwDP1+60iIJXauKF13KtlzV5XvruUWOL6eUzeTEGMHmcMWkfb9rJHnnkSUwvvowmkQqmXGtUuLsWALbVeYet1xziXwG8Bqsh8pNKqa7anRJRbWhFgjSvmTyva/K8Xh81rpiuFV8MXuXQ9EbmlMc+3rQTcwKcpEGNy9A19zGVqzNZXbm2V1xHc0zDgN4x35ftawd59Z564TXIGwRgOoBZAC4TERPAS0qpf63ZmREFzCjSQiVlemt34mdNHsu10Wa98BQp1zrNkBnk5XEyeZ1Jk42QyZNymbxq1sM1GTr+eNnMijYA9WmyAsN6N0T2uiZvq4j8HcBwAMMAHA7Af2hLVEeaCJQClFJZO19NH82Qi2VnMnntu0eNq1Rbh2o2XjS6zNYwjbq5hIJlaFrRZsjVlmsBYN89+lR0uVY3k9cDgjwR+QjA+wBeAHAXgPNYsqWexgnkUqbKGlOTNINdk+d1ggY1rnJtHYDKem81usyZvMzkkRflNjlVU66tRmsPK9fur5Qqn8IgCjE3yFMq6w/fNBW8vN4W67OXy1QcaRZ1MV2QKFKuTaRMiHAiSiHNGf3/9maPPPKg9CYnVbcNTi1xAyL27to68vrb7yciz4jISgAQkTYR+UkNz4socJmZvExe++QV27iRyyrXVnaO1BhiuoZEiY0XcV1js+wCMjN5LNeSF0aJNXnVzq6thqYJ+sSNuu+u9Rrk/SeA+QASAKCUWgFgXq1OiqgWnB2veUGe8raGzs9YM2Zpoi1WqlwbwDqhRuVk8gxNsEdrU53PhnoCQyv+WEukTLcNSj20Nht1X5Pn9bfvrZRannOsvmdO5JOz7i43wWLmrNErxvtYM5Zro87QpOhYs0SV8zQbmdNCZa++zXyjRJ7ES40QrHLiRbX6NBvY0VnfNXlef/tNIrIvAAUAInIagPU1OyuiGnDiuNw2Kt4zeZrnZsh8gYq2mKGhq8TGi3q+8ISZU64dwkbI5FHJEYJ1fqy1NsfqnsnzuvHiEgB3AxgjIusAfAzg6zU7K6IaCGJNntdmyIzxoi1WMpNX3ailRuaUa4dw0wV5ZOjWuMnc1liA9VirZ9a8tdnA5h31bUTi6bdXSv1dKfUVAHsAGANrfu2MGp4XUeB0zfpzLxjkeVyT56UZcorNkCOv5Jq8JNfkFeNk8vZm+xTyKGY/1+a+AVdK1b9c22SgI5Gq288HymTyRKQvrCzeUACPA1hsf34VgLcAPFDrEyQKivNYzyvX+uiT5yWTpxTHmkWdUap3V51feMIspmu45YyDcejIgfU+FeohnLmyyZRCxuZs9/EXr2M/yv8zb2Ldl+6UK9f+DsAXAF4C8B0APwQQB/A1pdSbtT01omA56+5ys3Gmx6DM2l1bvl1kihMvIi9esndXfXf8hd0pk4bV+xSoB3FapCRME72QjvKcx18931DVO8ADygd5o5VS4wFARH4DYBOAfZRS22t+ZkQBK7kmz8O7Pe9r8sBybcQZevFRS50JZvKIguI8lhLJ7Mcbxwdayv327t5fpVQKwMcM8Kinypx4kclUCHRNnlIKfA2PtlKjlrZ3JtyRR0RUHaf9Ve4b8PT4wGg/GZd7pjlYRLbZHwuAXvbnAkAppfrW9OyIAlQsk5c0TU9pda9r8ry2ZKHGFdMFCdMsuONv2+5kxUPPiShbzN5Ql7s8wmlhFPVNTiWDPKWUXurrRD1JsYkXpumtebGfiRcM8qItpmtQyvpbyG203b47gX69YnU6M6LG4rQjym1Z5G68YLmWKBq0kn3yyl/e++7acCy4pfopVkIyTYVtHQzyiIJiFMvksVwLgEEeRYiTyTMLTLzwWq711CfPY989alxOiSh36sX2ziSUAoM8ooC4u2vzMnlm1tejikEeRUaxNXmmx4kXhqZ5XpPHGC/aDK1wCWnbbmsvW18GeUSBcDJ5SbPImjyWa4mioWgLFY998nSPa/K8Bo3UuGJG4RJSuxPkNTPIIwpC+rGWk8lLcuMFwCCPIqRokJfyM/GifDNk02P5lxqX27srJ8hzMnks1xIFwxlrVmx3bYyZPKJocHa85o0185HJ8xDjIaWQ1zaDoqXYOqF2BnlEgcoca5YpDBMvwiDavz1FipNdyw3UUp7X5HnM5JkKEV/rG3kx94WncLm2X28GeURBMDLGmmXqSjqza6Md5kT7t6dIcR7r+RMvvJdrTZU/+zYXy7XkLAbP3V3LTB5RsOJFMnnpjRfRfi5mkEeRodsvvKmcd3wpU7m7IUsxioxFy5Uy86ccULTEizRo3daRgK4JWuLsM08UBDeTl/OGKsE+eQAY5FGEpCdepI8ppWAqbxMvijVTzmV6XONHjatYg9b23Qn0bTb4JoAoIMUeawm2UAHAII8iRHPKtRlBmvOx1zV5uZcvxOTEi8hL767N3XiRZKmWKEDOJqdi5Vpm8ogiwt14kVFudUqv3iZeOE03ywR5JpshR12sSAmJc2uJguVucsrbeMEgD2CQRxGSLtemgzTnecFLudZrJs/rmDRqXMVeeNp3JzjtgihAzpq8rrwWKtxdCzDIowgp1Aw5nckrf3mva/I4u5bcF55k9t/KdgZ5RIGKaYXbFXFNniXavz1FSsEgz12TV/6h4DWTpxQ8tWShxhUvkcljuZYoOEaxNXlJE5pwfTSDPIqMQhMvnJ53XpoXO08W5Roip0yFiD+vRJ5RYKyZUopBHlHA3E1OZn4mL+rr8QAGeRQh6YkX6SAvWYPdtVyTR4XGmu3qSiFpKgZ5RAFyg7xk/u7aqJdqAQZ5FCF6gWbGzk5brxMvgPK7a5VSnjZyUOOKFcjkcdoFUfB0TSBSeHdt1DddAAzyKEJKrsnzEJQVygQWYpVrGeRFWazAqKVtHVaQ17eZQR5RkGKalteTkuVaC28BioxCLVScj71k8gyPmbyUyXJt1BUatdS+i5k8olqI6VJgd61CLOJzawEGeRQhhVqgOOVaL7Nr07NvPeyuZSYv0pwyURfLtUQ1Z+ha3pvvrhTLtQCDPIqQghMvfGy8cJ4vymbyFHfXRp2b9c0oITHII6qNmC5Zb6gAa00ey7UM8ihC0uXa9DG3XOtpTZ63TB7LteQsBs8s127rSAJgkEcUNEPTCjZD5u5aBnkUIemNF+knAz+za9kMmbwSkbzF4E4mr0+zUa/TImpIMUPymiEnWK4FwCCPIiQd5KWP+cvkeWyGrDjWjKwSUlYmb3cCrc0Gs7xEAYtpGhK5a/JYrgXAII8ixHltzZ54Yf3vbU2e99m1fB0nQ88uIXHaBVFtGLogkcxZk5dSiLFcyyCPokNEoEl2n7uUr9215YM800dLFmpsMV1DV065lkEeUfAMTcursCSSJuJe5lU2OAZ5FCm6JlmZvEr65JUM8pw1fizXRl5u765tDPKIaiJmFG6GzI0XDPIoYnRNqp54UaqFSsrHmDRqbDFdyxtrxmkXRMGLaZI/1owTLwAwyKOI0aVwkKd5eCQYHlqoOM8zbIZMhi5Zi8FZriWqDWtNXk4mjxsvADDIo4jRcjJ5fsqrzvOFp3ItH1mRF9e1rMXg7bsT6NebQR5R0GK6hkReJk+xXAsGeRQxuiZVTLwon8lzy7XM5EWeoYtb2u9IpNCZNJnJI6oBQ8vvk9eVTLFPHhjkUcTklWsraIZcak2e6aPvHjW2zDV52zqsRsh9GeQRBS53/SsAJFIKMe6uZZBH0ZK78cL0lcnLn5iRy7lqNrylrCDPnnbRl9MuiAJXOMjjmjyAQR5FTG6Ql6xg4kWqxMALPy1ZqLFZEy+svwdnpBnLtUTBy1waAVhv3pMm1+QBDPIoYjSRnIkXQWfynKCxmrOkRhDLmHjBII+odgxNy1qT12U/7pjJY5BHEaNrUnDiRVBr8vz03aPGZmjpiRcM8ohqJ25kz4l2PubGCwZ5FDGGlp3WT1VUri3fQoXlWoob6YkX23YnAXDjBVEtGJqWE+RZz8Ms1zLIo4jRclqomIHPrrV/DjN5kZf5wsNMHlHtGHp2C5WuJMu1Dt4CFCn5Ey/s4z6CPC9jzfjcQtaOv3S5tndc54sOUQ3kNkNOuGvy+GabzzgUKdbEi/TnziYKL+VVT2PN2AyZbNbu2nQmj1k8otqI5WbynDV5LNcyyKNo0TXkTLywj3sIypw4kM2QyYuYrrl/KwzyiGrH0KzHmrKf251yLTdeMMijiNE1LXvjhbtRovxlRSRvd24uP7t1qbFZQ9PTzZD7NjPII6oFpyzrLI9IsIWKi7cARYouyArSTJ8tT/Sc3bm5uPGCHPGMdULtuxPcWUtUI4YdzCXtx5sb5LFcyyCPoiV34oXzseEllQdrF66XZsjM5JGRMfFiG8u1RDXjZOycx1tX0m6hwkwegzyKlryJFz7KtUD5TF66717l50iNIaZrSJkKpqm4Jo+ohtLlWusNeHrjBZ+IGeRRpOSuqUv6GGsGOJm88mvy2AyZnOxCRzKFnV0pBnlENeJUYpwdtgn2yXPxFqBIyc3E+Zl44Vy+VJDn7O7iWDNysgubd3QBAPr2Mup5OkQNy8jJ5CXYQsXFW4AiRc+deOEzk1cuyEtx4wXZnOzC5p1WkMdMHlFtxN2NF/aaPO6udfEWoEjJm3jhM/Nm5LRgyeVmBvnIijxnZ9+m7Z0AGOQR1YqTyXNmRbNPXhpvAYoULScTZ5oKIt7X0LFcS17F7L+pzTsZ5BHVkpM173LLtdbzMDN5DPIoYnTJLtemlPIVkJUt13LjBdmcF5hNO1iuJaqlmJvJy26GzDV5DPIoYnQ9e+NF0lS+ArLya/I41owsTglp0w4rk8dmyES1Ectphtzl7q7l8zCDPIoUXSRv4oWfTJ6hiftEUoiTJGQzZHLWA21mJo+opoycsWbceJHGW4AiRdeymyGnTH8BmddMHtfkkeGWazsRNzQ0x/Q6nxFRY0pPvMhpocIgj0EeRYsmgsxEnKmUr+kUXtfkMcajzD55zOIR1Y6hZa/J60qaMDTh2mgwyKOI0TXkza41fLzbKzfWzG/fPWpcsYxMHoM8otoplMljqdbCW4EiRc/pc5dSytcmiXJjzUyuySOb8yKzZVcX+jZz2gVRrcRymiEnUoqbLmwM8ihSdA3ZLVRSCn7e8JXL5LktVPj8EnnOYnCluOmCqJZyx5p1Jk3EDa6BBRjkUcQUmnjht0+e6aFcyxYqlLnom0EeUe3ENKdcm+6TF2cmDwCDPIoYTctvoeKvT17psWZOlpDlWooxyCPqFjEje6xZImW6YwWjjrcCRYouOS1UlPIVkJVbk8dmyOQwMjIJDPKIascZa5YwMzN5DG8ABnkUMbkTL1KmvyCv7O5ajjUjW+aLDKddENWOs8kikUxPvODuWgtvBYqUvIkXftfkSZk1eSr9fRRtmZk8BnlEtWPkjjVLKZZrbbwVKFJyJ14kUz4zeXrpsWZuuZaPrMjjmjyi7hHLGWuWSHLjhYMvRRQpmgiUApQd6JmB98njmjyyxDQGeUTdwXmsJTNm18aZyQPAII8ixsnaOYFa0GvyOLuWHM6OP4BBHlEtaZpAE068KKSut4KIXCUiSkQGZxybLyIfisj7IjI34/ghIvK2/bXbRaxXURFpEpGH7OOviMjIjMucIyKr7X/ndOsvR6HkBHROoJZS/jZJGOX65Nlf4sYLMjRuvCDqLoauIWFy40Wuut0KIjIcwNEAPs04dhCAeQDGAjgWwK9ExGlbfSeACwDsb/871j7+LQBfKKX2A3ArgJvs6xoI4FoAhwGYAuBaERlQ41+LQs4J8pyyqmkqd7i118t7mV3LGI9ibKFC1G1imrjl2gTLta563gq3AvghgMxXzJMALFRKdSqlPgbwIYApIjIEQF+l1EvKWkx1P4CvZVzmPvvjRQCOsrN8cwE8rZTaopT6AsDTSAeGFFFOGTWrXOtz4kXJPnlshkw2EYGhCXRN0BLniCWiWooZmtsMuYt98lx1uRVE5EQA65RSb+V8aSiAzzI+X2sfG2p/nHs86zJKqSSAdgCDSlwXRZhTRnU2yKZM5WsnrOFx4gU3XhBg7bDt1ysG4d8DUU0ZmoYud3etysqkR5lRqysWkcUAvlTgSz8G8CMAxxS6WIFjqsTxSi+T/UNFLoBVCsY+++xT6FuoQTiPeyfjllIqaxdk2ctzdi35YOjCUi1RN4jpkj3WjJk8ADUM8pRSXyl0XETGAxgF4C373e0wAH8TkSmwsm3DM759GIDP7ePDChxHxmXWiogBoB+ALfbx2TmXea7Iud4N4G4AmDx5cvFXcOrx9JymmSnTXwuV8rtr099HFNc19G2u2dMsEdmMjGlGXUmuyXN0+62glHpbKbWnUmqkUmokrGBsklLqHwCeADDP3jE7CtYGi+VKqfUAtovIVHu93dkAHrev8gkAzs7Z0wAssdft/QXAMSIywN5wcYx9jCLMWX/nlGtNn7Nry63JS5drKz9HahyGLtxZS9QNYrrmtlDhmry0UL3FVEq9IyIPA1gFIAngEqVUyv7yRQAWAOgF4E/2PwC4B8DvRORDWBm8efZ1bRGRfwPwqv191yultnTLL0Kh5Tzu3XKtz921hlZ64oWpFETANVgEAGiO6RjYEq/3aRA1vJimsU9eAXUP8uxsXubnNwK4scD3vQZgXIHjHQBOL3Ld9wK4N5ATpYaguZm8dJDnt1xr2hMzCgVyfnfrUmP7+Slt2KO1qd6nQdTwDN1qoZIyFUwFlmttdQ/yiLpT1RMvMlqwGAV2b6WUYiNkck3bd1C9T4EoEqxmyApdSSubx0yehbcCRUr+xAt/QZmuZ18+l1IcaUZE1N3i9u7arpQT5PF5GGCQRxFTaOKFn6DMyMkE5rLKv1WeJBER+WJoGpIp5a7LY7nWwluBIiVv4oXv3bVOC5YSQR6jPCKibmXogq6U6ZZrubvWwluBIkXLycSZpr+edk4FoFhDZOUzaCQiourFdA1J03QzeVyTZ+GtQJHi9snLaKHia3atXiaTp/zt1iUiourF7N21bpDHci0ABnkUMbkbJ5I+y6vl1+RxpBkRUXcz7GbInSzXZuGtQJGi5/TJsyZe+Li8uzu3cENk5fP6iIioejFNkEgpJFLWc3vc4JttgEEeRUzBPnl+yrU5Y9Fy+W2uTERE1TN0DckU1+Tl4q1AkeIEYKmMFiq+yrV66Uwe1+QREXW/mN0MOcFmyFl4K1CkuH3y7BgtpfzNrs3NBOZSyt9uXSIiql7MbobcyT55WXgrUKTkrqnz29fOyJmYkcvvmDQiIqqeoWnWmjxuvMjCW4EiJXfihe81eXYz5KK7a5UCq7VERN0rpgsSKdPdeMFyrYW3AkVKeuKF9bn/iRf25YoEeX7HpBERUfWsZsgKXakUAJZrHbwVKFK0jCBNKQWl/PW1KzfWzOTECyKibmfogpSp0JlwNl7weRhgkEcRY2SUW51snJ+gzEszZGEmj4ioWznl2V1ddiaP5VoADPIoYtxyq1JuGxV/5drSQZ7f5spERFQ95w347gTLtZl4K1CkaBkTL5w2KoEHeczkERF1q3QmL5n1edTxVqBIyQzSnDYq/nbXlmmGbCqWa4mIupmzBm9nZ8r+nOENwCCPIiZz4oUTp1XSJ690uZZBHhFRdzLyMnl8HgYY5FHEOGPJUmbGmjwfzwVly7Wmv8wgERFVz3kDvqsrhbiusaJiY5BHkZLuk1fZ7tpyQV5KKbdNCxERdQ9no8WurhSzeBn4ckSRomVMvDDd3bXeHwblxpqZpvLVd4+IiKrntMfa1ZVEjDtrXbwlKFIKZ/J8XN7DWDOuySMi6l7OUhynXEsW3hIUKZqWH+T5ybyV33jh7/qIiKh6sYwgjztr03hLUKQYBYI8P5k3rezGCwUm8oiIupfbJ68zyUbIGXhLUKS4GycqnHhRbk1eymS5loiou7lr8hLceJGJQR5FSvbEC//l2vTu2sLNkE3FjRdERN3NLdd2ppjJy8BbgiIlHaTBzeQZATdDZpBHRNS9nGbIXSmTa/Iy8JagSHHiuZTK2HhRQZ88lmuJiMIj8806g7w03hIUKSICXROkTDO98aKicm3hIE8pf0EjERFVL7NE28RyrYu3BEWOLmKVa6uYeFE0k6eUrzFpRERUPWbyCuMtQZGjadkTL/xk3oxyzZA58YKIqNtlBnbcXZvGII8ix8rkKaTM9OdeuWv6SvXJY7mWiKhbGTozeYXwlqDI0TSpuBlyek1f8YkXfoJGIiKqXmZgxxYqabwlKHIMO0gzK2iG7Hx/qTV5Gh9VRETdKpbxxMvZtWm8JShydE2QUsoN1Pw+Hxj27txCTK7JIyLqdizXFsZbgiJHE6l44gVgB4mFYzyYin3yiIi6W2aQx3JtGm8Jihy9ijV56csXjvK4u5aIqPtllmuZyUvjLUGRo4lVrnXGmvkNyowSa/JM5f/6iIioOpom7hv2OFuouBjkUeQYur3xwg7UDJ9PCKV31yrfa/yIiKh6TkNkZvLSeEtQ5Lh98pT/sWaA1RC5ZDNkrskjIup2TnDHNXlpvCUocjRNYKr0mjy/QZmmlWiGrLgmj4ioHpxJF8zkpfGWoMhJT7yoPJNXtE+eqdgMmYioDgw7uIsxk+fiLUGRo9ktUKrbXVti4wXLtURE3S5mP/c2MZPn4i1BkeM0M3YmXvgNyowiQV66717150hERP6kM3l8EnYwyKPI0TRBSsFtaOy3vKpJ4RYqlW7kICKi6nFNXj7eEhQ5ulhZt1SFs2utFiz5zZArzQwSEVH1nOCOQV4abwmKHHfihZ3Kq2RNXqFMnhP3cXctEVH3c3qesoVKGm8Jipz0xAvrc/+7a8XN2mVKZwarPkUiIvLJsEebxfkk7OItQZGTO/FC8/ko0DVBMlUgk1fhmDQiIqpenOXaPLwlKHK03IkXAbVQSe+uZZBHRNTdWK7Nx1uCIkfPnXjhMyjTizRDrrTvHhERVc9toeJzHnkjY5BHkeNMvHAyb0YFffJKrcnj7loiou7nNEPmmrw03hIUOZpdbk1WMfGi0Jo8VeFGDiIiqp6zFo/l2jTeEhQ5zsQKUymIAOK3XCuF1+SlOPGCiKhuDDZDzsNbgiLHmnhhrcmrJOum64JkgWbIbpDHKI+IqNuxGXI+3hIUObqIO/GikoDMWpOXf5zlWiKi+jG4Ji8PbwmKHN3O5JmVZvK0Ipk8VVnfPSIiql7M4Jq8XLwlKHI0EZgmkDL976wF7DV5BTZeVNqShYiIqufsrmULlTQGeRQ5hp2JS5lmZeVavfDsWlVhc2UiIqqeoWsQ4XNwJgZ5FDlWCxWrvFrJk0GxiRcpjjUjIqqbvfo24Ut9m313TGhkRr1PgKi76RrsiReVBWSGprkBXSaWa4mI6ufcw0fhzMn71Ps0QoVBHkVO5sSLSjZhaUXW5Lm7a1kqICLqdnFD46aLHLw1KHJ0TXNbqFSyu7bYmrz07NqqT5GIiKhqfDmiyNE1IOlk8irYhVVuTR7XgxARURgwyKPIcSZeJCvsk2fYl89lOpk8BnlERBQCDPIocqqdeKHZa/pUTqBnck0eERGFCIM8ipxqJ144DZRzS7bO50zkERFRGDDIo8jRNYFS1rq8ivrk2ev4cjdfmIrlWiIiCg8GeRQ5ThCWSJkV9smzLmPmlWs58YKIiMKDQR5FjrMOL5EyYVS0u9Z62ORm8tLlWgZ5RERUfwzyKHKcTFtXsrJMnhMX5jZEZiaPiIjChEEeRY5Tru1KmhWuySucyTPN7OsnIiKqJwZ5FDluJi9V3e7a3DV5Tu88jY8qIiIKAb4cUeToGWvyKgnInMvnZ/LsII+ZPCIiCgEGeRQ5mRsvKirX2kFc7pq8FNfkERFRiDDIo8hxW6gkTXenrB+G2yfPzDruJPaYySMiojBgkEeRY++bQFfKRAUdVNxMXV6fPLdcW9XpERERBYJBHkWOk73rrHB3rVFkTZ7TJ4/lWiIiCgMGeRQ5Tiav0okXzmWSRfrksVxLRERhwCCPIkdzx5pVNrvWWZOXKjK7VmMmj4iIQoBBHkWOE9ilTFVRQOaUe1O5ffLYDJmIiEKEQR5FTmYQZlSxJq94Jq+KkyMiIgoIX44ocjJLtJVk3cqtyWMmj4iIwoBBHkVOZpBXSbm22Jq8FCdeEBFRiDDIo8jRqszkuWv68tbkceMFERGFB4M8ipzMwK6SgKxXTAcA7OxMZh13Yj72ySMiojBgkEeRk7Umr4JHwKCWOABg886urOMpxYkXREQUHgzyKHIygzyjgq2wA+wgb8uOnCCPa/KIiChEGORR5GRtvKggIIvpGvr1imHzzs6s40pxrBkREYUHgzyKnMzArpJyLQAM6hPPL9ea+ddPRERULwzyKHKqbaECAINbmrB5R3Ymj2vyiIgoTBjkUeRk7q6ttHHxwJY4tuRk8pRS0AQQZvKIiCgEGORR5GTvrq0sIBvUJ47NBTZecD0eERGFBYM8ipxAgryWOL7Y1ZU19SKlFLN4REQUGgzyKHIyN1tUWq4d1KcJpgK27kpn80xTcW4tERGFBoM8ihytyokXgLUmD0DWujxTsX0KERGFB4M8ipyg1uQBwKaMdXkpU4GJPCIiCgsGeRQ5WUFepeXaliYAuZk8brwgIqLwYJBHkRNEnzwnk5c59cJUXJNHREThwSCPIiczEDMqDPIG9I5DBFltVFIme+QREVF4MMijyNECyOTpmmBA73h2Js9UFY9JIyIiChpfkihygph4AeRPvWC5loiIwoRBHkWOrmfurq38ega1xLN31ypVcWaQiIgoaHUL8kTkeyLyvoi8IyL/O+P4fBH50P7a3Izjh4jI2/bXbhd78ZOINInIQ/bxV0RkZMZlzhGR1fa/c7r1F6TQysy2aVVk3gb1ycnkmaqq6yMiIgqSUY8fKiJzAJwEoE0p1Skie9rHDwIwD8BYAHsDWCwiByilUgDuBHABgJcBPAngWAB/AvAtAF8opfYTkXkAbgJwpogMBHAtgMkAFIDXReQJpdQX3fm7UvgE0ScPsNqobN6x2f08xWbIREQUIvXK5F0E4OdKqU4AUEr90z5+EoCFSqlOpdTHAD4EMEVEhgDoq5R6SSmlANwP4GsZl7nP/ngRgKPsLN9cAE8rpbbYgd3TsAJDirjMbFs1QdnAlji27k4gmTIBWGvyGOMREVFY1CvIOwDATLu8+lcROdQ+PhTAZxnft9Y+NtT+OPd41mWUUkkA7QAGlbguirigMnmD+8ShFPDFrgQAlmuJiChcalauFZHFAL5U4Es/tn/uAABTARwK4GERGQ2g0CukKnEcFV4m91wvgFUKxj777FPoW6iBZMZ11e2uTU+92KO1CSmTEy+IiCg8ahbkKaW+UuxrInIRgD/YpdflImICGAwr2zY841uHAfjcPj6swHFkXGatiBgA+gHYYh+fnXOZ54qc690A7gaAyZMnFwwEqXGICHRNkDKr2w3rTr3Y0QmgFaaqbiMHERFRkOpVrn0MwJEAICIHAIgD2ATgCQDz7B2zowDsD2C5Umo9gO0iMtVeb3c2gMft63oCgLNz9jQAS+zg8S8AjhGRASIyAMAx9jEiN4NXTSZvUIsz2szaYWsqBY1NiYiIKCTqsrsWwL0A7hWRlQC6AJxjB2bviMjDAFYBSAK4xN5ZC1ibNRYA6AVrV+2f7OP3APidiHwIK4M3DwCUUltE5N8AvGp/3/VKqS01/82oR9A0AKkqd9f2scq1ViYPVrmWmTwiIgqJugR5SqkuAN8o8rUbAdxY4PhrAMYVON4B4PQi13UvrICSKIuhaQDMqoK8/r1i0ARurzyTzZCJiChEWFyiSHJisWqCPE0TDGyJY1NmkMdMHhERhQSDPIokJ7irNigb2BLHFnu0Gcu1REQUJgzyKJKcIK/alieDWpqweae1Js9U4MYLIiIKDb4kUSQ5GTy9ykfAwD7x9O5a9skjIqIQYZBHkWQEVK4d3BLHZqdcyzV5REQUIgzyKJKcXbBGlfXVgS1NaN+dQCJlcqwZERGFCoM8iiR340WVjwBn6sUXO7tgqurX+BEREQWFQR5FkjvxouqNF1aQt2lHlzUmjTEeERGFBIM8iiSnXFttyxNn6sWWnV3sk0dERKHCII8iyd14UWXqbaA7v7YTpuLuWiIiCg8GeRRJbguVanfX2mvyNrvlWgZ5REQUDgzyKJKCaobctzkGXRM7k1d9ZpCIiCgoDPIokrSAgjxnfq2zJk9njEdERCHBII8iyQnGglhDN6glnt5dy0weERGFBIM8iiSnCXIQa+gG9bEzeVyTR0REIcIgjyLJaYIcRCZvYEsTNu/oREqpqjdyEBERBYVBHkWSHlCfPMAq1262J16wXEtERGFh1PsEiOrBbaESwE6JQS1xbO9I2tdb9dUREREFgpk8iqRAM3n21IvtHUk2QyYiotBgkEeRlJ54Uf11OVMvgGA2chAREQWBQR5FUlATL4D01IvM6yUiIqo3rsmjSApq4gWQncnT+baJKDCJRAJr165FR0dHvU+FqO6am5sxbNgwxGIxz5dhkEeRpGkCEUACXJPnXC8RBWPt2rVobW3FyJEjA3msEvVUSils3rwZa9euxahRozxfjnkHiiRdxF2XV62+zQZienDlXyKydHR0YNCgQQzwKPJEBIMGDfKd1WaQR5FkaBLY+jkRcUu2XJNHFCwGeESWSh4LDPIokjRNAm13MrClyb1eImoc//jHPzBv3jzsu+++OOigg3Dcccfhgw8+qOnPnD17Nl577bWS33Pbbbdh165d7ufHHXcctm7dWvXPHjlyJMaPH4+2tjYcccQR+OSTT6q+zkqce+65WLRoUd7x9957DxMmTMDEiRPx0Ucfdcu5PPHEE/j5z39e9fV4uV+DxiCPIkkXCbS06uywZbmWqHEopXDyySdj9uzZ+Oijj7Bq1Sr8+7//OzZs2FDvU8sL8p588kn0798/kOt+9tlnsWLFCsyePRs33HBDINdZSiqV8vy9jz32GE466SS88cYb2Hfffct+v1IKpmlWc3o48cQTcc0111R1HfXCII8iSdMk0Kxbulwb2FUSUZ09++yziMViuPDCC91jEyZMwMyZM/Hcc8/hhBNOcI9feumlWLBgAQArG/ajH/0I06ZNw+TJk/G3v/0Nc+fOxb777ou77roLAEpePtNFF12EyZMnY+zYsbj22msBALfffjs+//xzzJkzB3PmzHF/5qZNm3D11VfjV7/6lXv56667Dr/4xS8AAP/xH/+BQw89FG1tbe51lTJt2jSsW7cOALBx40aceuqpOPTQQ3HooYfixRdfBACMHz8eW7duhVIKgwYNwv333w8A+OY3v4nFixdjzZo1mDlzJiZNmoRJkyZh2bJl7u8/Z84c/Mu//AvGjx8PpRQuvfRSHHTQQTj++OPxz3/+M+98nnzySdx22234zW9+4/7et9xyC8aNG4dx48bhtttuAwCsWbMGBx54IC6++GJMmjQJn332Wdb1vP766zjiiCNwyCGHYO7cuVi/fj0AK9N2xRVX4PDDD8e4ceOwfPlyAMCCBQtw6aWXAgAeeeQRjBs3DgcffDBmzZoFwFo7et5552H8+PGYOHEinn32WQDA7t27MW/ePLS1teHMM8/E7t273XN46qmnMG3aNEyaNAmnn346duzYAQC45pprcNBBB6GtrQ1XXXVV2fuoHO6upUga2r8ZQ/o1B3Z9g1iuJaqpn/33O1j1+bZAr/Ogvfvi2v9nbNGvr1y5EoccckhF1z18+HC89NJLuPLKK3HuuefixRdfREdHB8aOHZsVNJZz4403YuDAgUilUjjqqKOwYsUKXHbZZbjlllvw7LPPYvDgwVnfP2/ePFxxxRW4+OKLAQAPP/ww/vznP+Opp57C6tWrsXz5ciilcOKJJ2Lp0qVuoFLIn//8Z3zta18DAFx++eW48sorMWPGDHz66aeYO3cu3n33XUyfPh0vvvgiRowYgdGjR+P555/H2WefjZdffhl33nknNE3D008/jebmZqxevRpnnXWWW7Jcvnw5Vq5ciVGjRuEPf/gD3n//fbz99tvYsGEDDjroIJx//vlZ53PcccfhwgsvRJ8+fXDVVVfh9ddfx29/+1u88sorUErhsMMOwxFHHIEBAwbg/fffx29/+9usgBew2vJ873vfw+OPP4499tgDDz30EH784x/j3nvvBQDs3LkTy5Ytw9KlS3H++edj5cqVWZe//vrr8Ze//AVDhw51y+N33HEHAODtt9/Ge++9h2OOOQYffPAB7rzzTvTu3RsrVqzAihUrMGnSJADApk2bcMMNN2Dx4sVoaWnBTTfdhFtuuQWXXnopHn30Ubz33nsQkUDK7wzyKJIumr0fvjNrdGDXN8gp1zLIIyJYJT7AynTt2LEDra2taG1tRXNzs68X74cffhh33303kskk1q9fj1WrVqGtra3o90+cOBH//Oc/8fnnn2Pjxo0YMGAA9tlnH9x+++146qmnMHHiRADAjh07sHr16oJB3pw5c7Bhwwbsueeebrl28eLFWLVqlfs927Ztw/bt2zFz5kwsXboUI0aMwEUXXYS7774b69atw8CBA9GnTx+0t7fj0ksvxZtvvgld17PWM06ZMsVtB7J06VKcddZZ0HUde++9N4488siyt80LL7yAk08+GS0tLQCAU045Bc8//zxOPPFEjBgxAlOnTs27zPvvv4+VK1fi6KOPBmCViocMGeJ+/ayzzgIAzJo1C9u2bcu7r6ZPn45zzz0XZ5xxBk455RT3PL73ve8BAMaMGYMRI0bggw8+wNKlS3HZZZcBANra2tz77eWXX8aqVaswffp0AEBXVxemTZuGvn37orm5Gd/+9rdx/PHHZ2V6K8UgjyJJ1wS6pgd2fYNYriWqqVIZt1oZO3ZswcX/AGAYRtZar9zWFk1NTnZfcz92Pk8mk2UvDwAff/wxbr75Zrz66qsYMGAAzj33XE8tNE477TQsWrTI3TQCWGvT5s+fj+9+97tlL//ss8+ipaUF5557Ln7605/illtugWmaeOmll9CrV6+s7501axbuuOMOfPrpp7jxxhvx6KOPYtGiRZg5cyYA4NZbb8Vee+2Ft956C6Zpork5XUFxgjOH392jSqmiX8u97szLjB07Fi+99FLBr+eeQ+7nd911F1555RX88Y9/xIQJE/Dmm2+WPI9Cv5NSCkcffTQefPDBvK8tX74czzzzDBYuXIhf/vKXWLJkSdHr9oJr8ogCwBYqRI3nyCOPRGdnJ/7zP//TPfbqq6/ir3/9K0aMGIFVq1ahs7MT7e3teOaZZ3xdt5fLb9u2DS0tLejXrx82bNiAP/3pT+7XWltbsX379oLXPW/ePCxcuBCLFi3CaaedBgCYO3cu7r33Xnft17p16wque3P06tULt912G+6//35s2bIFxxxzDH75y1+6X3/zzTcBWGXpTZs2YfXq1Rg9ejRmzJiBm2++2Q3y2tvbMWTIEGiaht/97ndFN1nMmjULCxcuRCqVwvr16911baXMmjULjz32GHbt2oWdO3fi0UcfdX9uMV/+8pexceNGN8hLJBJ455133K8/9NBDAKzsXL9+/dCvX7+sy3/00Uc47LDDcP3112Pw4MH47LPPMGvWLDzwwAMAgA8++ACffvopvvzlL2cdX7lyJVasWAEAmDp1Kl588UV8+OGHAIBdu3bhgw8+wI4dO9De3o7jjjsOt912m3sbV4OZPKIAOFMvWK4lahwigkcffRRXXHEFfv7zn6O5uRkjR47EbbfdhuHDh+OMM85AW1sb9t9/f7cM6pWXyx988MGYOHEixo4di9GjR7vlPQC44IIL8NWvfhVDhgzJC4jGjh2L7du3Y+jQoW4p8phjjsG7776LadOmAQD69OmD3//+99hzzz2LnuOQIUNw1lln4Y477sDtt9+OSy65BG1tbUgmk5g1a5a7ieSwww5zg7eZM2di/vz5mDFjBgDg4osvxqmnnopHHnkEc+bMKZphO/nkk7FkyRKMHz8eBxxwAI444oiyt+GkSZNw7rnnYsqUKQCAb3/725g4cSLWrFlT9DLxeByLFi3CZZddhvb2diSTSVxxxRUYO9bKFA8YMACHH344tm3b5q7Ty/SDH/wAq1evhlIKRx11FA4++GCMGTMGF154IcaPHw/DMLBgwQI0NTXhoosuwnnnnYe2tjZMmDDBPc899tgDCxYswFlnnYXOzk4AwA033IDW1lacdNJJ6OjogFIKt956a9nboBwplWaMosmTJ6vu7mNDPd+aTTsx++bncP1JY3H2tJH1Ph2ihvDuu+/iwAMPrPdpUETMnj0bN998MyZPnlzvUymq0GNCRF5XShU8aZZriQIwdEAvfHXclzBpnwH1PhUiIiIALNcSBSKma7jzG5W1WiAiovp77rnn6n0KgWMmj4iIiKgBMcgjIiIiakAM8oiIiIgaEIM8IiIiogbEII+IiKgIEcE3v/lN9/NkMok99tij4pFTd911F+6///6gTg8bN25ELBbDr3/968CusxbeeustTJgwwf38wQcfRO/evZFIJABYc1+dsV+HH364r+t+7rnnAhkBlunYY49F//798673448/xmGHHYb9998fZ555Jrq6ugL9uUFjkEdERFRES0sLVq5cid27dwMAnn76aQwdOrTi67vwwgtx9tlnB3V6eOSRRzB16tSCI7IqkUwmA7meXOPHj8cnn3ziTulYtmwZxowZgzfeeMP93Gn2vGzZspqcgx8/+MEP8Lvf/S7v+NVXX40rr7wSq1evxoABA3DPPffU4ey8Y5BHRERUwle/+lX88Y9/BGBloJwh9gCwZcsWfO1rX0NbWxumTp2KFStWwDRNjBw5Mmu4/X777YcNGzbguuuuw8033wzAar579dVXY8qUKTjggAPw/PPPA7DGXDnTMM4880wcdthhKNak/8EHH8QvfvELrF27FuvWrUN7eztGjhzpzsXdtWsXhg8fjkQigY8++gjHHnssDjnkEMycORPvvfceAODcc8/F97//fcyZMwdXX301li9fjsMPPxwTJ07E4Ycfjvfff7/seT311FOYNm0aJk2ahNNPP90dn+bQNA2HHnooXnnlFQDA66+/jksuucQN6JYtW+Zm8Pr06QPAytDNnj0bp512GsaMGYOvf/3r7pzYP//5zxgzZgxmzJiBP/zhDyXvD8AKMrdu3QqlFAYNGuRmU7/5zW9i8eLFebfrUUcdhdbW1qxjSiksWbLEHRV3zjnn4LHHHit4v4QF++QREVH4/eka4B9vB3udXxoPfPXnZb9t3rx5uP7663HCCSdgxYoVOP/8892A7Nprr8XEiRPx2GOPYcmSJTj77LPx5ptv4qSTTsKjjz6K8847D6+88gpGjhyJvfbaK++6k8kkli9fjieffBI/+9nPsHjxYvzqV7/CgAEDsGLFCqxcuTKrzJnps88+wz/+8Q9MmTIFZ5xxBh566CF8//vfx8EHH4y//vWvmDNnDv77v/8bc+fORSwWwwUXXIC77roL+++/P1555RVcfPHFWLJkCQBr5urixYuh6zq2bduGpUuXwjAMLF68GD/60Y/wX//1X0XPa9OmTbjhhhuwePFitLS04KabbsItt9yCn/70p1nne/jhh2PZsmWYNm0aNE3D7NmzMX/+fFxxxRVYtmwZrr322rzf8Y033sA777yDvffeG9OnT8eLL76IyZMn4zvf+Q6WLFmC/fbbD2eeeab7/cXuD+eyI0aMwOjRo/H888/j7LPPxssvv4w777yz7N8AAGzevBn9+/eHYVih07Bhw7Bu3TpPl60XZvKIiIhKaGtrw5o1a/Dggw/iuOOOy/raCy+84K7ZO/LII7F582a0t7fjzDPPdIfdL1y4MCsQyXTKKacAAA455BB35uoLL7yAefPmAQDGjRvnrlXLtXDhQpxxxhkArEDUKdkW+tk7duzAsmXLcPrpp2PChAn47ne/i/Xr17vXdfrpp0PXdQBAe3s7Tj/9dIwbNw5XXnkl3nnnnZLn9fLLL2PVqlWYPn06JkyYgPvuuw+ffPJJ3vlOnz4dy5Ytw/Lly3HooYdi3333xYcffoiNGzdix44dGD16dN5lpkyZgmHDhkHTNEyYMAFr1qzBe++9h1GjRmH//feHiOAb3/hG2ftj5syZWLp0KZYuXYqLLroIb7/9NtatW4eBAwe6mcNyCo2BFQn3vHJm8oiIKPw8ZNxq6cQTT8RVV12F5557Dps3b3aPF3vhnzZtmhvAPPbYY/jJT35S8HqbmpoAALquu+vhvM6Uf/DBB7FhwwY88MADAIDPP/8cq1evxoknnoj58+djy5YteP3113HkkUdi586d6N+/P958rIj0ZQAACihJREFU882C19XS0uJ+/K//+q+YM2cOHn30UaxZswazZ88ueV5KKRx99NFl1wVOnToVr776Kl544QVMmzYNgJUNW7hwYdHNFs7tA2TfRsWCq2L3x6xZs3DHHXfg008/xY033ohHH30UixYtwsyZM0uec6bBgwdj69atSCaTMAwDa9euxd577+358vXATB4REVEZ559/Pn76059i/PjxWcdnzZrlBlnPPfccBg8ejL59+0JEcPLJJ+P73/8+DjzwQAwaNMjzz5oxYwYefvhhAMCqVavw9tv5Zer3338fO3fuxLp167BmzRqsWbMG8+fPx8KFC9GnTx9MmTIFl19+OU444QTouo6+ffti1KhReOSRRwBYwdBbb71V8Oe3t7e7m0sWLFhQ9rymTp2KF198ER9++CEAa+3eBx98kHe9ra2tGD58OBYsWOAGedOmTcNtt93ma0ftmDFj8PHHH+Ojjz4CgKzgstj9MXz4cGzatAmrV6/G6NGjMWPGDNx8882+gjwRwZw5c7Bo0SIAwH333YeTTjrJ8+XrgUEeERFRGcOGDcPll1+ed/y6667Da6+9hra2NlxzzTW477773K+deeaZ+P3vf1+0VFvMxRdfjI0bN6KtrQ033XQT2tra0K9fv6zvefDBB3HyySdnHTv11FOzSra5P/uBBx7APffcg4MPPhhjx47F448/XvDn//CHP8T8+fMxffp0pFKpsue1xx57YMGCBTjrrLPcDQ/Opo5c06dPR2dnJ4YPHw7ACvL+/ve/+wrympubcffdd+P444/HjBkzMGLECPdrpe6Pww47DAcccAAAYObMmVi3bh1mzJhR8GfMnDkTp59+Op555hkMGzYMf/nLXwDAXW+43377YfPmzfjWt77l+bzrQbymhaNi8uTJqtguJiIi6j7vvvsuDjzwwHqfRrdLpVJIJBJobm7GRx99hKOOOgoffPAB4vE4zyviCj0mROR1pdTkQt/PNXlEREQhsmvXLsyZMweJRAJKKdx5552hCKTCel5UHIM8IiKiEGltbS3aF6+ewnpeVBzX5BERERE1IAZ5REQUWlw3TmSp5LHAII+IiEKpubkZmzdvZqBHkaeUwubNm9Hc3OzrclyTR0REoTRs2DCsXbsWGzdurPepENVdc3Mzhg0b5usyDPKIiCiUYrEYRo0aVe/TIOqxWK4lIiIiakAM8oiIiIgaEIM8IiIiogbEsWY5RGQjgE+64UcNBrCpG34O+cP7Jbx434QT75fw4n0TTkHfLyOUUnsU+gKDvDoRkdeKzZqj+uH9El68b8KJ90t48b4Jp+68X1iuJSIiImpADPKIiIiIGhCDvPq5u94nQAXxfgkv3jfhxPslvHjfhFO33S9ck0dERETUgJjJIyIiImpADPK6mYgcKyLvi8iHInJNvc8nykRkuIg8KyLvisg7InK5fXygiDwtIqvt/wfU+1yjSER0EXlDRP7H/pz3SwiISH8RWSQi79mPnWm8b+pPRK60n8dWisiDItLM+6U+ROReEfmniKzMOFb0vhCR+XZM8L6IzA3yXBjkdSMR0QHcAeCrAA4CcJaIHFTfs4q0JID/pZQ6EMBUAJfY98c1AJ5RSu0P4Bn7c+p+lwN4N+Nz3i/h8H8A/FkpNQbAwbDuI943dSQiQwFcBmCyUmocAB3APPB+qZcFAI7NOVbwvrBfc+YBGGtf5ld2rBAIBnndawqAD5VSf1dKdQFYCOCkOp9TZCml1iul/mZ/vB3Wi9VQWPfJffa33Qfga3U5wQgTkWEAjgfwm4zDvF/qTET6ApgF4B4AUEp1KaW2gvdNGBgAeomIAaA3gM/B+6UulFJLAWzJOVzsvjgJwEKlVKdS6mMAH8KKFQLBIK97DQXwWcbna+1jVGciMhLARACvANhLKbUesAJBAHvW8dSi6jYAPwRgZhzj/VJ/owFsBPBbu5T+GxFpAe+bulJKrQNwM4BPAawH0K6Uegq8X8Kk2H1R07iAQV73kgLHuL25zkSkD4D/AnCFUmpbvc8n6kTkBAD/VEq9Xu9zoTwGgEkA7lRKTQSwEywB1p29vuskAKMA7A2gRUS+Ud+zIo9qGhcwyOteawEMz/h8GKyUOtWJiMRgBXgPKKX+YB/eICJD7K8PAfDPep1fRE0HcKKIrIG1pOFIEfk9eL+EwVoAa5VSr9ifL4IV9PG+qa+vAPhYKbVRKZUA8AcAh4P3S5gUuy9qGhcwyOterwLYX0RGiUgc1mLLJ+p8TpElIgJrbdG7SqlbMr70BIBz7I/PAfB4d59blCml5iulhimlRsJ6jCxRSn0DvF/qTin1DwCficiX7UNHAVgF3jf19imAqSLS235eOwrWGmPeL+FR7L54AsA8EWkSkVEA9gewPKgfymbI3UxEjoO13kgHcK9S6sb6nlF0icgMAM8DeBvptV8/grUu72EA+8B68jxdKZW7iJa6gYjMBnCVUuoEERkE3i91JyITYG2IiQP4O4DzYCUMeN/UkYj8DMCZsLoGvAHg2wD6gPdLtxORBwHMBjAYwAYA1wJ4DEXuCxH5MYDzYd13Vyil/hTYuTDIIyIiImo8LNcSERERNSAGeUREREQNiEEeERERUQNikEdERETUgBjkERERETUgBnlERDlEJCUib2b8KznVQUQuFJGzA/i5a0RkcLXXQ0QEsIUKEVEeEdmhlOpTh5+7BsBkpdSm7v7ZRNR4mMkjIvLIzrTdJCLL7X/72cevE5Gr7I8vE5FVIrJCRBbaxwaKyGP2sZdFpM0+PkhEnhKRN0Tk18iYYyki37B/xpsi8msR0e1/C0RkpYi8LSJX1uFmIKIegkEeEVG+Xjnl2jMzvrZNKTUFwC9hTa/JdQ2AiUqpNgAX2sd+BuAN+9iPANxvH78WwAtKqYmwxhvtAwAiciCs6QXTlVITAKQAfB3ABABDlVLjlFLjAfw2qF+YiBqPUe8TICIKod12cFXIgxn/31rg6ysAPCAij8EaZQQAMwCcCgBKqSV2Bq8fgFkATrGP/1FEvrC//ygAhwB41RpFil6wBpr/N4DRIvJ/AfwRwFMV/n5EFAHM5BER+aOKfOw4HsAdsIK010XEQEYZtsBlC12HALhPKTXB/vdlpdR1SqkvABwM4DkAl8CaIUtEVBCDPCIif87M+P+lzC+IiAZguFLqWQA/BNAf1pD4pbDKrRCR2QA2KaW25Rz/KoAB9lU9A+A0EdnT/tpAERlh77zVlFL/BeBfAUyqza9IRI2A5Voiony9ROTNjM//rJRy2qg0icgrsN4kn5VzOR3A7+1SrAC4VSm1VUSuA/BbEVkBYBeAc+zv/xmAB0XkbwD+CuBTAFBKrRKRnwB4yg4cE7Ayd7vt63HeoM8P7DcmoobDFipERB6xxQkR9SQs1xIRERE1IGbyiIiIiBoQM3lEREREDYhBHhEREVEDYpBHRERE1IAY5BERERE1IAZ5RERERA2IQR4RERFRA/r/Aaq/Wx2x35V1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "machine2 = Machine_env2(tm,r_func)\n",
    "print(r_func)\n",
    "baseline = StateValueNetwork(machine2.observation_space)\n",
    "pol2 = policy_estimator(machine2)\n",
    "\n",
    "#Hyper Parameters\n",
    "episodes = 100\n",
    "gamma = 0.90\n",
    "lr= 0.01\n",
    "\n",
    "\n",
    "results = recurrent_pg_baseline_montecarlo(machine2,baseline,pol2,episodes,gamma,lr)\n",
    "rewards = results[0]\n",
    "actions = np.array(results[1])\n",
    "states = results[2]\n",
    "\n",
    "episode = [i for i in range(len(rewards))]\n",
    "\n",
    "#Moving average we will use a window size of 50\n",
    "\n",
    "moving_averages = []\n",
    "window_size = 10\n",
    "\n",
    "df = pd.DataFrame(rewards,columns = ['r'])\n",
    "moving_ave = df.r.rolling(window_size,min_periods=1).mean().values\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.plot(episode,rewards,label = 'Cumulative Reward for episodes')\n",
    "plt.plot(episode,moving_ave,label = f'Moving Average Window {window_size}')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Rewards')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 14)\n",
      "torch.Size([1, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "class policy_estimator_cnn(nn.Module): #neural network\n",
    "    def __init__(self, env):\n",
    "        super(policy_estimator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d()\n",
    "        self.lstm = nn.LSTMCell(env.observation_space,128)\n",
    "        self.layer1 = nn.Linear(128,128)\n",
    "        \n",
    "        self.layer2 = nn.Linear(128,len(env.action_space))\n",
    "       \n",
    "            \n",
    "    \n",
    "    def forward(self, x):#prediction is raw value\n",
    "        x = torch.FloatTensor(x)\n",
    "        output = []\n",
    "        hx = torch.zeros(1,128)\n",
    "        cx = torch.zeros(1,128)\n",
    "        \n",
    "        if(len(x.size()) == 1): #single tensor ie. [x1,x2,x3,x4]\n",
    "            x = x.unsqueeze(0)\n",
    "            #print(x)\n",
    "            hx, cx = self.lstm(x, (hx, cx))\n",
    "            output = hx\n",
    "            #print(output)\n",
    "\n",
    "        elif(len(x.size()) == 2): #2 dimension\n",
    "            x = x.unsqueeze(1) #dim = (timestep,batch,features), note batch = 1\n",
    "#             print(x.size())\n",
    "            for i in range(x.size()[0]): #loop to simulate recurrent network\n",
    "                #print(y)\n",
    "                hx, cx = self.lstm(x[i], (hx, cx))\n",
    "                output.append(hx)\n",
    "        \n",
    "            output = torch.stack(output, dim=0).squeeze(1) #convert to tensor\n",
    "        \n",
    "        x = F.leaky_relu(output)\n",
    "        x = self.layer1(x)\n",
    "        x  = F.relu(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        return F.softmax(x,dim = -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4) [[2.1 2.3 5.3 6.4]\n",
      " [2.3 4.3 1.3 8.4]\n",
      " [1.1 9.3 5.3 0.4]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv1d(): argument 'padding' (position 5) must be tuple of ints, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-208-1b6ef873af01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimple1DCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-208-1b6ef873af01>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"First layer\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    254\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m--> 256\u001b[1;33m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    257\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: conv1d(): argument 'padding' (position 5) must be tuple of ints, not str"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import torch\n",
    "\n",
    "X = np.array([[2.1,2.3,5.3,6.4],[2.3,4.3,1.3,8.4],[1.1,9.3,5.3,0.4]])\n",
    "# Y = np.random.randint(0, 9, 10).reshape(1, 1, -1)\n",
    "\n",
    "class Simple1DCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple1DCNN, self).__init__()\n",
    "        self.layer1 = torch.nn.Conv1d(in_channels=1, out_channels=20, kernel_size=3, stride=1,padding = \"SAME\")\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.layer2 = torch.nn.Conv1d(in_channels=20, out_channels=1, kernel_size=1,padding = 1)\n",
    "        self.lstm = nn.LSTMCell(6,10)\n",
    "        self.act2 = torch.nn.ReLU()\n",
    "        self.layer3 = nn.Linear(10,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        print(\"First layer\",x.shape)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "\n",
    "        print(\"CNN out\", x.shape)\n",
    "        output = []\n",
    "        hx = torch.zeros(x.shape[1],10)\n",
    "        cx = torch.zeros(x.shape[1],10)\n",
    "        \n",
    "        for i in range(x.size()[0]):\n",
    "            hx, cx = self.lstm(x[i], (hx, cx))\n",
    "            output.append(hx)\n",
    "            \n",
    "        output = torch.stack(output, dim=0).squeeze(1) #convert to tensor\n",
    "        print(output,output.shape)\n",
    "#         output = torch.reshape(output,(3,1,20))\n",
    "#         print(output)\n",
    "        \n",
    "        x = self.layer3(output)\n",
    "        print(x)\n",
    "        log_probs = torch.nn.functional.softmax(x, dim=-1)\n",
    "\n",
    "        return log_probs\n",
    "print(X.shape, X)\n",
    "model = Simple1DCNN()\n",
    "y = model(torch.FloatTensor(X))\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
