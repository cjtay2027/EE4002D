{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "from collections import namedtuple, deque\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://github.com/g6ling/Reinforcement-Learning-Pytorch-Cartpole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory/Replay Buffer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'next_state', 'action', 'reward', 'mask'))\n",
    "\n",
    "class Memory(object):\n",
    "    def __init__(self):\n",
    "        self.memory = deque()\n",
    "\n",
    "    def push(self, state, next_state, action, reward, mask):\n",
    "        self.memory.append(Transition(state, next_state, action, reward, mask))\n",
    "\n",
    "    def sample(self):\n",
    "        memory = self.memory\n",
    "        return Transition(*zip(*memory)) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_grad(grads):\n",
    "    grad_flatten = []\n",
    "    for grad in grads:\n",
    "        grad_flatten.append(grad.view(-1))\n",
    "    grad_flatten = torch.cat(grad_flatten)\n",
    "    return grad_flatten\n",
    "\n",
    "def flat_hessian(hessians):\n",
    "    hessians_flatten = []\n",
    "    for hessian in hessians:\n",
    "        hessians_flatten.append(hessian.contiguous().view(-1))\n",
    "    hessians_flatten = torch.cat(hessians_flatten).data\n",
    "    return hessians_flatten\n",
    "\n",
    "def flat_params(model):\n",
    "    params = []\n",
    "    for param in model.parameters():\n",
    "        params.append(param.data.view(-1))\n",
    "    params_flatten = torch.cat(params)\n",
    "    return params_flatten\n",
    "\n",
    "def update_model(model, new_params):\n",
    "    index = 0\n",
    "    for params in model.parameters():\n",
    "        params_length = len(params.view(-1))\n",
    "        new_param = new_params[index: index + params_length]\n",
    "        new_param = new_param.view(params.size())\n",
    "        params.data.copy_(new_param)\n",
    "        index += params_length\n",
    "\n",
    "def kl_divergence(policy, old_policy):\n",
    "    kl = old_policy * torch.log(old_policy / policy)\n",
    "\n",
    "    kl = kl.sum(1, keepdim=True)\n",
    "    return kl\n",
    "\n",
    "def fisher_vector_product(net, states, p, cg_damp=0.1):\n",
    "    policy = net(states)\n",
    "    old_policy = net(states).detach()\n",
    "    kl = kl_divergence(policy, old_policy)\n",
    "    kl = kl.mean()\n",
    "    kl_grad = torch.autograd.grad(kl, net.parameters(), create_graph=True) # create_graph is True if we need higher order derivative products\n",
    "    kl_grad = flat_grad(kl_grad)\n",
    "\n",
    "    kl_grad_p = (kl_grad * p.detach()).sum()\n",
    "    kl_hessian_p = torch.autograd.grad(kl_grad_p, net.parameters())\n",
    "    kl_hessian_p = flat_hessian(kl_hessian_p)\n",
    "\n",
    "    return kl_hessian_p + cg_damp * p.detach()\n",
    "\n",
    "\n",
    "def conjugate_gradient(net, states, loss_grad, n_step=10, residual_tol=1e-10):\n",
    "    x = torch.zeros(loss_grad.size())\n",
    "    r = loss_grad.clone()\n",
    "    p = loss_grad.clone()\n",
    "    r_dot_r = torch.dot(r, r)\n",
    "\n",
    "    for i in range(n_step):\n",
    "        A_dot_p = fisher_vector_product(net, states, p)\n",
    "        alpha = r_dot_r / torch.dot(p, A_dot_p)\n",
    "        x += alpha * p\n",
    "        r -= alpha * A_dot_p\n",
    "        new_r_dot_r = torch.dot(r,r)\n",
    "        betta = new_r_dot_r / r_dot_r\n",
    "        p = r + betta * p\n",
    "        r_dot_r = new_r_dot_r\n",
    "        if r_dot_r < residual_tol:\n",
    "            break\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRPO(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(TRPO, self).__init__()\n",
    "        self.t = 0\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "        self.fc_1 = nn.Linear(num_inputs, 128)\n",
    "        self.fc_2 = nn.Linear(128, 64)\n",
    "        self.fc_3 = nn.Linear(64, num_outputs)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform(m.weight)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = torch.relu(self.fc_1(input))\n",
    "        x = torch.relu(self.fc_2(x))\n",
    "        policy = F.softmax(self.fc_3(x),dim=-1)\n",
    "\n",
    "        return policy\n",
    "\n",
    "    @classmethod\n",
    "    def train_model(cls, net, transitions):\n",
    "        states, actions, rewards, masks = transitions.state, transitions.action, transitions.reward, transitions.mask\n",
    "\n",
    "        states = torch.stack(states)\n",
    "        actions = torch.stack(actions)\n",
    "        rewards = torch.Tensor(rewards)\n",
    "        masks = torch.Tensor(masks)\n",
    "\n",
    "        returns = torch.zeros_like(rewards)\n",
    "\n",
    "        running_return = 0\n",
    "        for t in reversed(range(len(rewards))):\n",
    "            running_return = rewards[t] + gamma * running_return * masks[t]\n",
    "            returns[t] = running_return\n",
    "\n",
    "        policy = net(states)\n",
    "        policy = policy.view(-1, net.num_outputs)\n",
    "        policy_action = (policy * actions.detach()).sum(dim=1)\n",
    "\n",
    "        old_policy = net(states).detach()\n",
    "        old_policy = old_policy.view(-1, net.num_outputs)\n",
    "        old_policy_action = (old_policy * actions.detach()).sum(dim=1)\n",
    "\n",
    "        surrogate_loss = ((policy_action / old_policy_action) * returns).mean()\n",
    "\n",
    "        surrogate_loss_grad = torch.autograd.grad(surrogate_loss, net.parameters())\n",
    "        surrogate_loss_grad = flat_grad(surrogate_loss_grad)\n",
    "\n",
    "        step_dir = conjugate_gradient(net, states, surrogate_loss_grad.data)\n",
    "\n",
    "        params = flat_params(net)\n",
    "        shs = (step_dir * fisher_vector_product(net, states, step_dir)).sum(0, keepdim=True)\n",
    "        step_size = torch.sqrt((2 * max_kl) / shs)[0]\n",
    "        full_step = step_size * step_dir\n",
    "\n",
    "        fraction = 1.0\n",
    "        for _ in range(10):\n",
    "            new_params = params + fraction * full_step\n",
    "            update_model(net, new_params)\n",
    "            policy = net(states)\n",
    "            policy = policy.view(-1, net.num_outputs)\n",
    "            policy_action = (policy * actions.detach()).sum(dim=1)\n",
    "            surrogate_loss = ((policy_action / old_policy_action) * returns).mean()\n",
    "\n",
    "            kl = kl_divergence(policy, old_policy)\n",
    "            kl = kl.mean()\n",
    "\n",
    "            if kl < max_kl:\n",
    "                break\n",
    "            fraction = fraction * 0.5\n",
    "\n",
    "        return -surrogate_loss\n",
    "\n",
    "    def get_action(self, input):\n",
    "        try:\n",
    "            policy = Categorical(self.forward(input))\n",
    "#         policy = policy[0].data.numpy()\n",
    "        \n",
    "        except:\n",
    "            print(\"Nan occured, terminating\")\n",
    "            return -1\n",
    "        \n",
    "        action = policy.sample()\n",
    "        \n",
    "        return action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v1'\n",
    "gamma = 0.99\n",
    "goal_score = 200\n",
    "log_interval = 10\n",
    "max_kl = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state size: 4\n",
      "action size: 2\n",
      "0 episode | score: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ac9b7ac10176>:13: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(m.weight)\n",
      "<ipython-input-5-ac9b7ac10176>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  policy = F.softmax(self.fc_2(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 episode | score: 2.93\n",
      "20 episode | score: 5.46\n",
      "30 episode | score: 6.93\n",
      "40 episode | score: 8.54\n",
      "50 episode | score: 10.45\n",
      "60 episode | score: 13.11\n",
      "70 episode | score: 16.10\n",
      "80 episode | score: 18.57\n",
      "90 episode | score: 21.83\n",
      "100 episode | score: 25.27\n",
      "110 episode | score: 28.13\n",
      "120 episode | score: 28.03\n",
      "130 episode | score: 28.41\n",
      "140 episode | score: 29.44\n",
      "150 episode | score: 32.23\n",
      "160 episode | score: 34.21\n",
      "170 episode | score: 35.29\n",
      "180 episode | score: 37.53\n",
      "190 episode | score: 40.59\n",
      "200 episode | score: 43.23\n",
      "210 episode | score: 46.44\n",
      "220 episode | score: 49.07\n",
      "230 episode | score: 50.52\n",
      "240 episode | score: 51.84\n",
      "250 episode | score: 53.11\n",
      "260 episode | score: 55.19\n",
      "270 episode | score: 55.46\n",
      "280 episode | score: 55.81\n",
      "290 episode | score: 57.23\n",
      "300 episode | score: 57.25\n",
      "310 episode | score: 58.80\n",
      "320 episode | score: 60.02\n",
      "330 episode | score: 59.54\n",
      "340 episode | score: 58.80\n",
      "350 episode | score: 60.66\n",
      "360 episode | score: 60.49\n",
      "370 episode | score: 61.65\n",
      "380 episode | score: 63.06\n",
      "390 episode | score: 64.18\n",
      "400 episode | score: 67.03\n",
      "410 episode | score: 67.35\n",
      "420 episode | score: 68.13\n",
      "430 episode | score: 67.70\n",
      "440 episode | score: 68.66\n",
      "450 episode | score: 71.93\n",
      "460 episode | score: 74.25\n",
      "470 episode | score: 77.64\n",
      "480 episode | score: 86.16\n",
      "490 episode | score: 102.26\n",
      "500 episode | score: 108.71\n",
      "510 episode | score: 118.13\n",
      "520 episode | score: 132.04\n",
      "530 episode | score: 144.00\n",
      "540 episode | score: 163.06\n",
      "550 episode | score: 169.30\n",
      "560 episode | score: 184.53\n",
      "570 episode | score: 189.73\n",
      "580 episode | score: 192.84\n",
      "590 episode | score: 187.41\n",
      "600 episode | score: 182.84\n",
      "610 episode | score: 178.97\n",
      "620 episode | score: 171.95\n",
      "630 episode | score: 161.63\n",
      "640 episode | score: 154.37\n",
      "650 episode | score: 151.18\n",
      "660 episode | score: 148.60\n",
      "670 episode | score: 154.11\n",
      "680 episode | score: 157.02\n",
      "690 episode | score: 171.23\n",
      "700 episode | score: 174.53\n",
      "710 episode | score: 177.83\n",
      "720 episode | score: 174.65\n",
      "730 episode | score: 167.99\n",
      "740 episode | score: 181.78\n",
      "750 episode | score: 187.89\n",
      "760 episode | score: 192.24\n",
      "770 episode | score: 187.44\n",
      "780 episode | score: 192.67\n",
      "790 episode | score: 198.44\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "env.seed(500)\n",
    "torch.manual_seed(500)\n",
    "\n",
    "num_inputs = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.n\n",
    "print('state size:', num_inputs)\n",
    "print('action size:', num_actions)\n",
    "\n",
    "net = TRPO(num_inputs, num_actions)\n",
    "writer = SummaryWriter('logs')\n",
    "\n",
    "\n",
    "running_score = 0\n",
    "steps = 0\n",
    "loss = 0\n",
    "for e in range(30000):\n",
    "    done = False\n",
    "    memory = Memory()\n",
    "\n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    state = torch.Tensor(state)\n",
    "    state = state.unsqueeze(0)\n",
    "\n",
    "    while not done:\n",
    "        steps += 1\n",
    "\n",
    "        action = net.get_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        next_state = torch.Tensor(next_state)\n",
    "        next_state = next_state.unsqueeze(0)\n",
    "\n",
    "        mask = 0 if done else 1\n",
    "        reward = reward if not done or score == 499 else -1\n",
    "\n",
    "        action_one_hot = torch.zeros(2)\n",
    "        action_one_hot[action] = 1\n",
    "        memory.push(state, next_state, action_one_hot, reward, mask)\n",
    "\n",
    "        score += reward\n",
    "        state = next_state\n",
    "\n",
    "    loss = TRPO.train_model(net, memory.sample())\n",
    "\n",
    "    score = score if score == 500.0 else score + 1\n",
    "    running_score = 0.99 * running_score + 0.01 * score\n",
    "    if e % log_interval == 0:\n",
    "        print('{} episode | score: {:.2f}'.format(e, running_score))\n",
    "        print(\"Average steps per episode:\", steps/log_interval)\n",
    "        steps = 0\n",
    "        writer.add_scalar('log/score', float(running_score), e)\n",
    "        writer.add_scalar('log/loss', float(loss), e)\n",
    "\n",
    "    if running_score > goal_score:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine GMM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine import Machine\n",
    "from GymMachEnv import MachineEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.95\n",
    "log_interval = 10\n",
    "max_kl = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\overl\\anaconda3\\envs\\env1\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.mixture.gaussian_mixture module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.mixture. Anything that cannot be imported from sklearn.mixture is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\overl\\anaconda3\\envs\\env1\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator GaussianMixture from version 0.20.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "machine = Machine()\n",
    "machine.curr_state = 0\n",
    "env = MachineEnv(machine)\n",
    "\n",
    "num_inputs = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-40517c17db77>:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(m.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 episode | Average score: 2730.00 | Average steps per episode: 7.8| Average number of maintenance: 4.6\n",
      "10 episode | Average score: 18600.00 | Average steps per episode: 48.9| Average number of maintenance: 27.8\n",
      "20 episode | Average score: 18600.00 | Average steps per episode: 52.1| Average number of maintenance: 29.4\n",
      "30 episode | Average score: 23490.00 | Average steps per episode: 48.2| Average number of maintenance: 20.9\n",
      "40 episode | Average score: 24970.00 | Average steps per episode: 48.8| Average number of maintenance: 17.6\n",
      "50 episode | Average score: 15620.00 | Average steps per episode: 33.3| Average number of maintenance: 14.3\n",
      "60 episode | Average score: 28490.00 | Average steps per episode: 54.5| Average number of maintenance: 20.4\n",
      "70 episode | Average score: 18580.00 | Average steps per episode: 35.8| Average number of maintenance: 12.9\n",
      "80 episode | Average score: 28850.00 | Average steps per episode: 67.3| Average number of maintenance: 31.8\n",
      "90 episode | Average score: 26900.00 | Average steps per episode: 55.8| Average number of maintenance: 23.5\n",
      "100 episode | Average score: 16950.00 | Average steps per episode: 38.1| Average number of maintenance: 14.2\n",
      "110 episode | Average score: 13600.00 | Average steps per episode: 33.4| Average number of maintenance: 14.3\n",
      "120 episode | Average score: 17590.00 | Average steps per episode: 34.8| Average number of maintenance: 13.2\n",
      "130 episode | Average score: 17410.00 | Average steps per episode: 34.3| Average number of maintenance: 12.2\n",
      "140 episode | Average score: 21990.00 | Average steps per episode: 42.5| Average number of maintenance: 12.4\n",
      "150 episode | Average score: 26050.00 | Average steps per episode: 45.7| Average number of maintenance: 13.2\n",
      "160 episode | Average score: 19470.00 | Average steps per episode: 36.3| Average number of maintenance: 9.4\n",
      "170 episode | Average score: 23070.00 | Average steps per episode: 44.0| Average number of maintenance: 14.4\n",
      "180 episode | Average score: 11650.00 | Average steps per episode: 21.7| Average number of maintenance: 7.8\n",
      "190 episode | Average score: 20950.00 | Average steps per episode: 46.2| Average number of maintenance: 17.9\n",
      "200 episode | Average score: 27020.00 | Average steps per episode: 53.0| Average number of maintenance: 22.2\n",
      "210 episode | Average score: 15770.00 | Average steps per episode: 40.8| Average number of maintenance: 19.9\n",
      "220 episode | Average score: 20630.00 | Average steps per episode: 43.1| Average number of maintenance: 17.3\n",
      "230 episode | Average score: 15520.00 | Average steps per episode: 33.3| Average number of maintenance: 14.2\n",
      "240 episode | Average score: 11840.00 | Average steps per episode: 27.6| Average number of maintenance: 11.6\n",
      "250 episode | Average score: 17780.00 | Average steps per episode: 36.6| Average number of maintenance: 12.9\n",
      "260 episode | Average score: 20720.00 | Average steps per episode: 46.6| Average number of maintenance: 18.9\n",
      "270 episode | Average score: 20080.00 | Average steps per episode: 44.3| Average number of maintenance: 19.1\n",
      "280 episode | Average score: 22310.00 | Average steps per episode: 46.3| Average number of maintenance: 19.4\n",
      "290 episode | Average score: 16580.00 | Average steps per episode: 36.4| Average number of maintenance: 15.6\n",
      "300 episode | Average score: 13230.00 | Average steps per episode: 27.1| Average number of maintenance: 10.1\n",
      "310 episode | Average score: 15790.00 | Average steps per episode: 33.6| Average number of maintenance: 11.1\n",
      "320 episode | Average score: 24070.00 | Average steps per episode: 46.4| Average number of maintenance: 18.3\n",
      "330 episode | Average score: 25070.00 | Average steps per episode: 50.2| Average number of maintenance: 19.5\n",
      "340 episode | Average score: 17950.00 | Average steps per episode: 39.3| Average number of maintenance: 15.5\n",
      "350 episode | Average score: 21820.00 | Average steps per episode: 43.3| Average number of maintenance: 17.0\n",
      "360 episode | Average score: 23820.00 | Average steps per episode: 47.5| Average number of maintenance: 20.0\n",
      "370 episode | Average score: 24870.00 | Average steps per episode: 55.6| Average number of maintenance: 26.8\n",
      "380 episode | Average score: 20760.00 | Average steps per episode: 41.3| Average number of maintenance: 16.8\n",
      "390 episode | Average score: 25580.00 | Average steps per episode: 47.8| Average number of maintenance: 17.4\n",
      "400 episode | Average score: 24080.00 | Average steps per episode: 44.1| Average number of maintenance: 14.5\n",
      "410 episode | Average score: 14870.00 | Average steps per episode: 31.4| Average number of maintenance: 9.7\n",
      "420 episode | Average score: 17870.00 | Average steps per episode: 31.7| Average number of maintenance: 9.2\n",
      "430 episode | Average score: 22310.00 | Average steps per episode: 40.2| Average number of maintenance: 13.0\n",
      "440 episode | Average score: 18700.00 | Average steps per episode: 33.9| Average number of maintenance: 9.8\n",
      "450 episode | Average score: 31690.00 | Average steps per episode: 60.8| Average number of maintenance: 19.5\n",
      "460 episode | Average score: 21400.00 | Average steps per episode: 44.7| Average number of maintenance: 17.0\n",
      "470 episode | Average score: 29920.00 | Average steps per episode: 56.1| Average number of maintenance: 19.0\n",
      "480 episode | Average score: 20850.00 | Average steps per episode: 41.4| Average number of maintenance: 13.6\n",
      "490 episode | Average score: 17920.00 | Average steps per episode: 36.5| Average number of maintenance: 12.6\n",
      "500 episode | Average score: 22460.00 | Average steps per episode: 44.8| Average number of maintenance: 18.8\n",
      "510 episode | Average score: 16370.00 | Average steps per episode: 33.3| Average number of maintenance: 10.9\n",
      "520 episode | Average score: 16140.00 | Average steps per episode: 29.9| Average number of maintenance: 7.8\n",
      "530 episode | Average score: 14000.00 | Average steps per episode: 27.6| Average number of maintenance: 7.2\n",
      "540 episode | Average score: 15350.00 | Average steps per episode: 31.3| Average number of maintenance: 8.8\n",
      "550 episode | Average score: 16590.00 | Average steps per episode: 34.1| Average number of maintenance: 9.0\n",
      "560 episode | Average score: 20100.00 | Average steps per episode: 36.7| Average number of maintenance: 11.6\n",
      "570 episode | Average score: 8660.00 | Average steps per episode: 16.9| Average number of maintenance: 4.7\n",
      "580 episode | Average score: 13090.00 | Average steps per episode: 23.8| Average number of maintenance: 5.6\n",
      "590 episode | Average score: 12470.00 | Average steps per episode: 27.2| Average number of maintenance: 7.5\n",
      "600 episode | Average score: 24930.00 | Average steps per episode: 48.7| Average number of maintenance: 18.1\n",
      "610 episode | Average score: 20360.00 | Average steps per episode: 43.5| Average number of maintenance: 19.0\n",
      "620 episode | Average score: 23590.00 | Average steps per episode: 46.1| Average number of maintenance: 18.9\n",
      "630 episode | Average score: 14840.00 | Average steps per episode: 28.0| Average number of maintenance: 10.4\n",
      "640 episode | Average score: 23520.00 | Average steps per episode: 47.2| Average number of maintenance: 17.3\n",
      "650 episode | Average score: 21980.00 | Average steps per episode: 46.5| Average number of maintenance: 17.8\n",
      "660 episode | Average score: 23830.00 | Average steps per episode: 45.5| Average number of maintenance: 17.1\n",
      "670 episode | Average score: 7970.00 | Average steps per episode: 19.5| Average number of maintenance: 6.8\n",
      "680 episode | Average score: 30340.00 | Average steps per episode: 57.7| Average number of maintenance: 20.3\n",
      "690 episode | Average score: 33390.00 | Average steps per episode: 60.3| Average number of maintenance: 20.1\n",
      "700 episode | Average score: 14090.00 | Average steps per episode: 28.6| Average number of maintenance: 10.2\n",
      "710 episode | Average score: 25510.00 | Average steps per episode: 41.8| Average number of maintenance: 11.8\n",
      "720 episode | Average score: 20940.00 | Average steps per episode: 38.1| Average number of maintenance: 10.6\n",
      "730 episode | Average score: 19960.00 | Average steps per episode: 36.0| Average number of maintenance: 11.5\n",
      "740 episode | Average score: 19660.00 | Average steps per episode: 36.2| Average number of maintenance: 10.7\n",
      "750 episode | Average score: 13270.00 | Average steps per episode: 26.0| Average number of maintenance: 7.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760 episode | Average score: 13300.00 | Average steps per episode: 27.6| Average number of maintenance: 7.6\n",
      "770 episode | Average score: 15830.00 | Average steps per episode: 30.6| Average number of maintenance: 7.7\n",
      "780 episode | Average score: 29920.00 | Average steps per episode: 51.1| Average number of maintenance: 15.8\n",
      "790 episode | Average score: 31740.00 | Average steps per episode: 59.2| Average number of maintenance: 21.2\n",
      "800 episode | Average score: 16550.00 | Average steps per episode: 32.6| Average number of maintenance: 11.7\n",
      "810 episode | Average score: 19580.00 | Average steps per episode: 39.5| Average number of maintenance: 15.5\n",
      "820 episode | Average score: 30700.00 | Average steps per episode: 53.9| Average number of maintenance: 16.7\n",
      "830 episode | Average score: 33550.00 | Average steps per episode: 59.0| Average number of maintenance: 19.4\n",
      "840 episode | Average score: 18390.00 | Average steps per episode: 34.9| Average number of maintenance: 12.4\n",
      "850 episode | Average score: 19240.00 | Average steps per episode: 35.1| Average number of maintenance: 11.3\n",
      "860 episode | Average score: 15590.00 | Average steps per episode: 28.6| Average number of maintenance: 7.7\n",
      "870 episode | Average score: 17520.00 | Average steps per episode: 32.7| Average number of maintenance: 8.3\n",
      "880 episode | Average score: 27280.00 | Average steps per episode: 47.1| Average number of maintenance: 14.7\n",
      "890 episode | Average score: 15670.00 | Average steps per episode: 31.8| Average number of maintenance: 8.8\n",
      "900 episode | Average score: 25490.00 | Average steps per episode: 42.9| Average number of maintenance: 11.8\n",
      "910 episode | Average score: 27040.00 | Average steps per episode: 47.0| Average number of maintenance: 13.2\n",
      "920 episode | Average score: 17920.00 | Average steps per episode: 35.1| Average number of maintenance: 13.0\n",
      "930 episode | Average score: 20950.00 | Average steps per episode: 43.2| Average number of maintenance: 19.3\n",
      "940 episode | Average score: 14060.00 | Average steps per episode: 31.1| Average number of maintenance: 13.0\n",
      "950 episode | Average score: 23590.00 | Average steps per episode: 45.9| Average number of maintenance: 19.4\n",
      "960 episode | Average score: 28710.00 | Average steps per episode: 58.3| Average number of maintenance: 24.8\n",
      "970 episode | Average score: 31220.00 | Average steps per episode: 55.4| Average number of maintenance: 21.4\n",
      "980 episode | Average score: 24200.00 | Average steps per episode: 46.1| Average number of maintenance: 15.8\n",
      "990 episode | Average score: 18970.00 | Average steps per episode: 40.3| Average number of maintenance: 13.5\n",
      "1000 episode | Average score: 23670.00 | Average steps per episode: 46.5| Average number of maintenance: 14.3\n",
      "1010 episode | Average score: 22780.00 | Average steps per episode: 41.8| Average number of maintenance: 12.9\n",
      "1020 episode | Average score: 18520.00 | Average steps per episode: 33.3| Average number of maintenance: 9.4\n",
      "1030 episode | Average score: 35480.00 | Average steps per episode: 59.2| Average number of maintenance: 16.5\n",
      "1040 episode | Average score: 30420.00 | Average steps per episode: 54.9| Average number of maintenance: 16.6\n",
      "1050 episode | Average score: 14760.00 | Average steps per episode: 29.2| Average number of maintenance: 9.4\n",
      "1060 episode | Average score: 14110.00 | Average steps per episode: 29.2| Average number of maintenance: 9.3\n",
      "1070 episode | Average score: 30240.00 | Average steps per episode: 52.7| Average number of maintenance: 15.7\n",
      "1080 episode | Average score: 24190.00 | Average steps per episode: 42.5| Average number of maintenance: 12.2\n",
      "1090 episode | Average score: 21990.00 | Average steps per episode: 40.1| Average number of maintenance: 12.2\n",
      "1100 episode | Average score: 24310.00 | Average steps per episode: 49.0| Average number of maintenance: 18.3\n",
      "1110 episode | Average score: 15870.00 | Average steps per episode: 29.7| Average number of maintenance: 10.1\n",
      "1120 episode | Average score: 20840.00 | Average steps per episode: 39.2| Average number of maintenance: 14.0\n",
      "1130 episode | Average score: 33390.00 | Average steps per episode: 63.4| Average number of maintenance: 23.4\n",
      "1140 episode | Average score: 31750.00 | Average steps per episode: 57.8| Average number of maintenance: 19.9\n",
      "1150 episode | Average score: 28340.00 | Average steps per episode: 56.4| Average number of maintenance: 22.2\n",
      "1160 episode | Average score: 28160.00 | Average steps per episode: 55.2| Average number of maintenance: 17.3\n",
      "1170 episode | Average score: 16660.00 | Average steps per episode: 31.3| Average number of maintenance: 10.1\n",
      "1180 episode | Average score: 27310.00 | Average steps per episode: 49.2| Average number of maintenance: 16.7\n",
      "1190 episode | Average score: 35130.00 | Average steps per episode: 59.4| Average number of maintenance: 19.1\n",
      "1200 episode | Average score: 10420.00 | Average steps per episode: 22.4| Average number of maintenance: 7.5\n",
      "1210 episode | Average score: 18510.00 | Average steps per episode: 39.2| Average number of maintenance: 14.1\n",
      "1220 episode | Average score: 31390.00 | Average steps per episode: 53.4| Average number of maintenance: 17.4\n",
      "1230 episode | Average score: 24080.00 | Average steps per episode: 46.5| Average number of maintenance: 16.8\n",
      "1240 episode | Average score: 32190.00 | Average steps per episode: 55.2| Average number of maintenance: 18.6\n",
      "1250 episode | Average score: 24130.00 | Average steps per episode: 43.8| Average number of maintenance: 14.4\n",
      "1260 episode | Average score: 30950.00 | Average steps per episode: 52.4| Average number of maintenance: 16.4\n",
      "1270 episode | Average score: 14540.00 | Average steps per episode: 24.6| Average number of maintenance: 6.8\n",
      "1280 episode | Average score: 28680.00 | Average steps per episode: 53.6| Average number of maintenance: 18.5\n",
      "1290 episode | Average score: 27840.00 | Average steps per episode: 51.4| Average number of maintenance: 18.5\n",
      "1300 episode | Average score: 26870.00 | Average steps per episode: 47.6| Average number of maintenance: 17.0\n",
      "1310 episode | Average score: 29950.00 | Average steps per episode: 51.9| Average number of maintenance: 18.1\n",
      "1320 episode | Average score: 25670.00 | Average steps per episode: 51.8| Average number of maintenance: 21.6\n",
      "1330 episode | Average score: 36120.00 | Average steps per episode: 68.5| Average number of maintenance: 26.3\n",
      "1340 episode | Average score: 27500.00 | Average steps per episode: 57.8| Average number of maintenance: 27.2\n",
      "1350 episode | Average score: 34550.00 | Average steps per episode: 71.5| Average number of maintenance: 31.9\n",
      "1360 episode | Average score: 29650.00 | Average steps per episode: 58.5| Average number of maintenance: 23.4\n",
      "1370 episode | Average score: 24340.00 | Average steps per episode: 47.2| Average number of maintenance: 19.2\n",
      "1380 episode | Average score: 20930.00 | Average steps per episode: 40.7| Average number of maintenance: 14.5\n",
      "1390 episode | Average score: 15690.00 | Average steps per episode: 30.4| Average number of maintenance: 9.6\n",
      "1400 episode | Average score: 20000.00 | Average steps per episode: 41.9| Average number of maintenance: 16.2\n",
      "1410 episode | Average score: 29280.00 | Average steps per episode: 55.0| Average number of maintenance: 19.0\n",
      "1420 episode | Average score: 19730.00 | Average steps per episode: 40.2| Average number of maintenance: 13.6\n",
      "1430 episode | Average score: 30420.00 | Average steps per episode: 55.3| Average number of maintenance: 17.2\n",
      "1440 episode | Average score: 23140.00 | Average steps per episode: 42.6| Average number of maintenance: 12.8\n",
      "1450 episode | Average score: 14570.00 | Average steps per episode: 31.4| Average number of maintenance: 10.6\n",
      "1460 episode | Average score: 31960.00 | Average steps per episode: 56.1| Average number of maintenance: 18.4\n",
      "1470 episode | Average score: 28310.00 | Average steps per episode: 51.8| Average number of maintenance: 18.9\n",
      "1480 episode | Average score: 27250.00 | Average steps per episode: 47.7| Average number of maintenance: 16.7\n",
      "1490 episode | Average score: 29590.00 | Average steps per episode: 53.8| Average number of maintenance: 19.9\n",
      "1500 episode | Average score: 23610.00 | Average steps per episode: 48.7| Average number of maintenance: 19.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510 episode | Average score: 24720.00 | Average steps per episode: 45.4| Average number of maintenance: 15.3\n",
      "1520 episode | Average score: 26920.00 | Average steps per episode: 51.8| Average number of maintenance: 19.1\n",
      "1530 episode | Average score: 20870.00 | Average steps per episode: 40.2| Average number of maintenance: 14.2\n",
      "1540 episode | Average score: 42780.00 | Average steps per episode: 77.2| Average number of maintenance: 26.4\n",
      "1550 episode | Average score: 14940.00 | Average steps per episode: 32.6| Average number of maintenance: 14.7\n",
      "1560 episode | Average score: 21700.00 | Average steps per episode: 73.7| Average number of maintenance: 51.3\n",
      "1570 episode | Average score: 11840.00 | Average steps per episode: 50.4| Average number of maintenance: 35.8\n",
      "1580 episode | Average score: 13130.00 | Average steps per episode: 42.5| Average number of maintenance: 28.6\n",
      "1590 episode | Average score: 16380.00 | Average steps per episode: 59.6| Average number of maintenance: 42.6\n",
      "1600 episode | Average score: 13000.00 | Average steps per episode: 42.9| Average number of maintenance: 28.1\n",
      "1610 episode | Average score: 23630.00 | Average steps per episode: 74.1| Average number of maintenance: 48.7\n",
      "1620 episode | Average score: 18080.00 | Average steps per episode: 70.0| Average number of maintenance: 47.7\n",
      "1630 episode | Average score: 22910.00 | Average steps per episode: 72.3| Average number of maintenance: 49.2\n",
      "1640 episode | Average score: 21970.00 | Average steps per episode: 60.1| Average number of maintenance: 35.9\n",
      "1650 episode | Average score: 13420.00 | Average steps per episode: 46.3| Average number of maintenance: 29.9\n",
      "1660 episode | Average score: 18120.00 | Average steps per episode: 52.8| Average number of maintenance: 31.0\n",
      "1670 episode | Average score: 33460.00 | Average steps per episode: 73.3| Average number of maintenance: 36.8\n",
      "1680 episode | Average score: 29490.00 | Average steps per episode: 59.8| Average number of maintenance: 27.7\n",
      "1690 episode | Average score: 35720.00 | Average steps per episode: 75.2| Average number of maintenance: 33.8\n",
      "1700 episode | Average score: 24340.00 | Average steps per episode: 50.7| Average number of maintenance: 24.5\n",
      "1710 episode | Average score: 23160.00 | Average steps per episode: 49.9| Average number of maintenance: 21.9\n",
      "1720 episode | Average score: 13470.00 | Average steps per episode: 27.1| Average number of maintenance: 12.8\n",
      "1730 episode | Average score: 15280.00 | Average steps per episode: 33.3| Average number of maintenance: 16.2\n",
      "1740 episode | Average score: 30810.00 | Average steps per episode: 60.4| Average number of maintenance: 25.8\n",
      "1750 episode | Average score: 19400.00 | Average steps per episode: 43.2| Average number of maintenance: 19.2\n",
      "1760 episode | Average score: 23000.00 | Average steps per episode: 44.1| Average number of maintenance: 18.5\n",
      "1770 episode | Average score: 24000.00 | Average steps per episode: 49.6| Average number of maintenance: 20.4\n",
      "1780 episode | Average score: 18420.00 | Average steps per episode: 39.7| Average number of maintenance: 17.2\n",
      "1790 episode | Average score: 17990.00 | Average steps per episode: 39.5| Average number of maintenance: 17.2\n",
      "1800 episode | Average score: 25580.00 | Average steps per episode: 45.2| Average number of maintenance: 14.3\n",
      "1810 episode | Average score: 15090.00 | Average steps per episode: 35.2| Average number of maintenance: 16.6\n",
      "1820 episode | Average score: 23060.00 | Average steps per episode: 66.9| Average number of maintenance: 43.2\n",
      "1830 episode | Average score: 18700.00 | Average steps per episode: 52.6| Average number of maintenance: 32.7\n",
      "1840 episode | Average score: 20560.00 | Average steps per episode: 58.3| Average number of maintenance: 37.2\n",
      "1850 episode | Average score: 17650.00 | Average steps per episode: 54.2| Average number of maintenance: 36.2\n",
      "1860 episode | Average score: 15350.00 | Average steps per episode: 40.1| Average number of maintenance: 23.6\n",
      "1870 episode | Average score: 16340.00 | Average steps per episode: 46.3| Average number of maintenance: 25.6\n",
      "1880 episode | Average score: 19900.00 | Average steps per episode: 53.2| Average number of maintenance: 29.8\n",
      "1890 episode | Average score: 17070.00 | Average steps per episode: 45.6| Average number of maintenance: 24.9\n",
      "1900 episode | Average score: 18740.00 | Average steps per episode: 45.9| Average number of maintenance: 23.9\n",
      "Nan occured, terminating\n"
     ]
    }
   ],
   "source": [
    "net = TRPO(num_inputs, num_actions)\n",
    "\n",
    "writer = SummaryWriter('./logs/TRPO_5')\n",
    "\n",
    "best_score = 0\n",
    "running_score = 0\n",
    "Total_score = 0\n",
    "steps = 0\n",
    "loss = 0\n",
    "maintenance_count = 0\n",
    "for e in range(2000):\n",
    "    done = False\n",
    "    memory = Memory()\n",
    "\n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    state = torch.Tensor(state)\n",
    "    state = state.unsqueeze(0)\n",
    "\n",
    "    while not done:\n",
    "        steps += 1\n",
    "\n",
    "        action = net.get_action(state)\n",
    "        \n",
    "        if action == -1: break\n",
    "            \n",
    "        if action == 1: maintenance_count+=1\n",
    "        \n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        next_state = torch.Tensor(next_state)\n",
    "        next_state = next_state.unsqueeze(0)\n",
    "\n",
    "        mask = 0 if done else 1\n",
    "\n",
    "        action_one_hot = torch.zeros(2)\n",
    "        action_one_hot[action] = 1\n",
    "        memory.push(state, next_state, action_one_hot, reward, mask)\n",
    "\n",
    "        score += reward\n",
    "        state = next_state\n",
    "    \n",
    "    if action == -1: break\n",
    "        \n",
    "    loss = TRPO.train_model(net, memory.sample())\n",
    "\n",
    "    running_score = 0.99 * running_score + 0.01 * score\n",
    "    Total_score+=score\n",
    "    \n",
    "    if e % log_interval == 0:\n",
    "        print('{} episode | Average score: {:.2f} | Average steps per episode: {}| Average number of maintenance: {}'.format(\n",
    "            e, Total_score/log_interval,steps/log_interval, maintenance_count/log_interval))\n",
    "        Total_score = 0\n",
    "        maintenance_count=0\n",
    "        steps = 0\n",
    "        writer.add_scalar('log/Average_score', float(Total_score/log_interval), e)\n",
    "        writer.add_scalar('log/loss', float(loss), e)\n",
    "        \n",
    "        if best_score < running_score:\n",
    "            best_score = running_score\n",
    "            torch.save(net,'TRPO_agent.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRPO(\n",
       "  (fc_1): Linear(in_features=4, out_features=128, bias=True)\n",
       "  (fc_2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc_3): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = torch.load('TRPO_agent.pt')\n",
    "agent.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
