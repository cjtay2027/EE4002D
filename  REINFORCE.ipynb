{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from machine import Machine\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#Parameters\n",
    "lmd0 = 0.013364\n",
    "lmd1 = 0.333442\n",
    "lmdM = 1 - lmd0 - lmd1 #0.6531...\n",
    "mu0 = 0.125\n",
    "mu1 = 0.25\n",
    "muM = 0.5\n",
    "\n",
    "\n",
    "#transition matrices\n",
    "\n",
    "#transition matrix for a = 0 (no maintenance)\n",
    "a0_tm = np.array([[lmdM, lmd1, 0, 0, 0, 0, 0, 0, 0, lmd0], #current state 0 to next state\n",
    "                  [0, lmdM, lmd1, 0, 0, 0, 0, 0, 0, lmd0], #current state 1 to next state\n",
    "                  [0, 0, lmdM, lmd1, 0, 0, 0, 0, 0, lmd0], #current state 2 to next state\n",
    "                  [0, 0, 0, lmdM, 0, 0, 0, 0, lmd1, lmd0], #current state 3 to next state\n",
    "                  [muM, 0, 0, 0, 1-muM, 0, 0, 0, 0, 0], #current state 4 to next state\n",
    "                  [muM, 0, 0, 0, 0, 1-muM, 0, 0, 0, 0], #current state 5 to next state\n",
    "                  [0, muM, 0, 0, 0, 0, 1-muM, 0, 0, 0], #current state 6 to next state\n",
    "                  [0, 0, muM, 0, 0, 0, 0, 1-muM, 0, 0], #current state 7 to next state\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], #current state 8 to next state\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]) #current state 9 to next state\n",
    "\n",
    "\n",
    "#transition matrix for a = 1 (maintenance steps)\n",
    "a1_tm = np.array([[0, 0, 0, 0, 1-lmd0, 0, 0, 0, 0, lmd0], #current state 0 to next state\n",
    "                  [0, 0, 0, 0, 0, 1-lmd0, 0, 0, 0, lmd0], #current state 1 to next state\n",
    "                  [0, 0, 0, 0, 0, 0, 1-lmd0, 0, 0, lmd0], #current state 2 to next state\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 1-lmd0, 0, lmd0], #current state 3 to next state\n",
    "                  [muM, 0, 0, 0, 1-muM, 0, 0, 0, 0, 0], #current state 4 to next state\n",
    "                  [muM, 0, 0, 0, 0, 1-muM, 0, 0, 0, 0], #current state 5 to next state\n",
    "                  [0, muM, 0, 0, 0, 0, 1-muM, 0, 0, 0], #current state 6 to next state\n",
    "                  [0, 0, muM, 0, 0, 0, 0, 1-muM, 0, 0], #current state 7 to next state\n",
    "                  [mu1, 0, 0, 0, 0, 0, 0, 0, 1-mu1, 0], #current state 8 to next state\n",
    "                  [mu0, 0, 0, 0, 0, 0, 0, 0, 0, 1-mu0]]) #current state 9 to next state\n",
    "\n",
    "\n",
    "\n",
    "class Machine_env():\n",
    "    '''\n",
    "    Description:\n",
    "    Code creates an environment for the policy to interact with the simulated machine.\n",
    "\n",
    "    States:\n",
    "    The simulated machine has 10 states\n",
    "    [0,1,2,3] are working states that degrades as the state number increases.\n",
    "    [4,5,6,7] are maintenance states that are transited from [0,1,2,3] respectively if the action deems it need transition\n",
    "    [8,9] are failure state, where 8 is sudden failure state that can occur from [0,1,2,3] while 9 is a degraded failure from 3\n",
    "\n",
    "    Actions:\n",
    "    Type: Discrete(2)\n",
    "    Num\n",
    "    0: No maintenance\n",
    "    1: Maintenance\n",
    "\n",
    "    Rewards:\n",
    "    reward_func = {0:1000,1:900,2:800,3:500,4:-500,5:-500,6:-500,7:-500,8:-3000,9:-1000}\n",
    "\n",
    "    Observations:\n",
    "    Produced using MachineSensor class that uses gmm from pickle file\n",
    "\n",
    "    Episode:\n",
    "    Since it is continous Markov model, we shall set 1 episode is 20 steps\n",
    "\n",
    "\n",
    "    Pseudo code\n",
    "\n",
    "    initialise class\n",
    "    Loop 20 times: #1 episode\n",
    "        sensor()\n",
    "        action()\n",
    "        step()\n",
    "\n",
    "    final otp: Class that contains rewards,actions, observations --> will be used to improve policy (ie. optimise theta)\n",
    "        \n",
    "''' \n",
    "\n",
    "    def __init__(self):\n",
    "        self.action_space = [0,1]\n",
    "        self.state = 0 #Random initialise the start state, assumes uniform distribution for initial state,random.randrange(10)\n",
    "        self.state_seq = [] #initialise a list that records the actual states\n",
    "        self.reward_func = {0:1000,1:900,2:800,3:500,4:-500,5:-500,6:-500,7:-500,8:-3000,9:-1000}\n",
    "        self.observation_space = 4\n",
    "        self.transition  = [a0_tm,a1_tm]\n",
    "        self.simulator = Machine() #simulator to generate sensor readings\n",
    "        self.done = False\n",
    "        self.steps = 0\n",
    "    \n",
    "    def sensor(self,state): # generate observation at state\n",
    "        self.simulator.curr_state = state\n",
    "        sensor_reading = self.simulator.readSensors()\n",
    "        return sensor_reading\n",
    "    \n",
    "    def step(self,action): # simulate movement of states given an action\n",
    "        self.state_seq.append(self.state) #record current state\n",
    "        \n",
    "        transition_mat_action = self.transition[action]\n",
    "        #print(f\"Transition Prob: {transition_mat_action[self.state]}\")\n",
    "        nxt_state = np.random.choice([i for i in range(10)],1,p=transition_mat_action[self.state])[0] #select nxt state based\n",
    "        reward = self.reward_func[nxt_state] #reward for going to next state\n",
    "        self.state = nxt_state #update state\n",
    "        \n",
    "        self.steps += 1\n",
    "        \n",
    "        if(((nxt_state == 0) and (self.steps > 20)) or (self.steps >= 50)):#condition for end of episode\n",
    "            self.done = True\n",
    "\n",
    "\n",
    "        return reward\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = 0\n",
    "        self.done = False\n",
    "        self.steps = 0\n",
    "        self.state_seq = []\n",
    "        return \n",
    "        \n",
    "class policy_estimator(): #neural network\n",
    "    def __init__(self, env):\n",
    "        self.n_inputs = env.observation_space\n",
    "        self.n_outputs = len(env.action_space)\n",
    "        \n",
    "        # Define network\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(self.n_inputs, 16), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(16, self.n_outputs),\n",
    "        nn.Softmax(dim=-1))\n",
    "        \n",
    "    \n",
    "    def predict(self,observation):#prediction is raw value\n",
    "        return self.network(torch.FloatTensor(observation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, gamma):\n",
    "    r = np.array([gamma**i * rewards[i] \n",
    "        for i in range(len(rewards))])\n",
    "    # Reverse the array direction for cumsum and then\n",
    "    # revert back to the original order\n",
    "    r = r[::-1].cumsum()[::-1]\n",
    "    return r \n",
    "\n",
    "def normalized_discount_reward(rewards,gamma):\n",
    "    r = np.array([gamma**i * rewards[i] \n",
    "        for i in range(len(rewards))])\n",
    "    # Reverse the array direction for cumsum and then\n",
    "    # revert back to the original order\n",
    "    r = r[::-1].cumsum()[::-1]\n",
    "    r = np.array(r)\n",
    "    mean_rewards=np.mean(r)\n",
    "    std_rewards=np.std(r)\n",
    "    norm_discounted_rewards=(r-mean_rewards)/(std_rewards+1e-12)\n",
    "    return norm_discounted_rewards.tolist()\n",
    "\n",
    "def reinforce(machine,policy_estimator,num_episodes,batch_size,gamma,lr): #Learning algo\n",
    "    # Set up lists to hold results\n",
    "    # Set up lists to hold results\n",
    "    total_rewards = [] #Total actual reward for each episode\n",
    "    batch_rewards = []  #Discounted expected future rewards for each batch\n",
    "    batch_actions = []\n",
    "    batch_observation = []\n",
    "    state_seq = []\n",
    "    \n",
    "    # Define optimizer\n",
    "    optimizer = torch.optim.Adam(policy_estimator.network.parameters(),lr=lr)\n",
    "    \n",
    "    action_space = machine.action_space\n",
    "    \n",
    "    for ep in range(num_episodes):\n",
    "        machine.reset()\n",
    "        observation = []\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        \n",
    "        while(not machine.done):\n",
    "            obs = machine.sensor(machine.state).tolist() #observation\n",
    "            \n",
    "            action_probs = policy_estimator.predict(obs).detach().numpy() #convert to numpy and get action prob\n",
    "            action = np.random.choice(action_space, p=action_probs) #select weighted actions based on NN output prob\n",
    "            print(f\"Action prob: {action_probs}, Action: {action}, state: {machine.state}\")\n",
    "            \n",
    "            r = machine.step(action) #receive reward and update machine to the next state after doing the sampled action\n",
    "            \n",
    "            observation.append(obs)\n",
    "            rewards.append(r)\n",
    "            actions.append(action)\n",
    "        \n",
    "        discount_r = normalized_discount_reward(rewards,gamma) #normalised future rewards\n",
    "        \n",
    "        total_rewards.append(sum(rewards)) #Cumulative reward for this episode\n",
    "        \n",
    "        #After batch complete time,store the parameters\n",
    "        batch_rewards.append(discount_r)\n",
    "        batch_observation.append(observation)\n",
    "        batch_actions.append(actions)\n",
    "        state_seq.append(machine.state_seq)\n",
    "        \n",
    "        #update policy\n",
    "        obs_tensor = torch.FloatTensor(observation)\n",
    "        action_tensor = torch.LongTensor(actions)\n",
    "        reward_tensor = torch.from_numpy(np.array(discount_r).copy()) #resolve stride problem\n",
    "        \n",
    "        # Calculate loss Ver 1\n",
    "#         logits = policy_estimator.predict(obs_tensor)\n",
    "#         policy_distribution = torch.distributions.Categorical(logits = logits)\n",
    "#         log_probs = policy_distribution.log_prob(action_tensor)\n",
    "#         print(log_probs*reward_tensor)\n",
    "#         loss = -(log_probs*reward_tensor).mean()\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Calculate loss Ver 2\n",
    "#         logprob = torch.log(policy_estimator.predict(obs_tensor))\n",
    "#         selected_logprobs = reward_tensor * torch.gather(logprob,-1,action_tensor.unsqueeze(-1)).squeeze(-1)\n",
    "#         print(selected_logprobs)\n",
    "#         loss = -selected_logprobs.mean()\n",
    "\n",
    "        #Calculate loss Ver 3\n",
    "        logprob = torch.log(policy_estimator.predict(obs_tensor))\n",
    "        #print(logprob)\n",
    "        #print(logprob[np.arange(len(action_tensor)), action_tensor])\n",
    "        selected_logprobs = reward_tensor * logprob[np.arange(len(action_tensor)), action_tensor]\n",
    "        print(selected_logprobs)\n",
    "        \n",
    "        \n",
    "        loss = -selected_logprobs.mean()\n",
    "        \n",
    "        print(f\"Reward for this episode {total_rewards[-1]}, loss is {loss}\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        # Apply gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "#         #Tensorboard params\n",
    "#         writer.add_scalar(\"Loss\", loss, ep)\n",
    "#         writer.add_scalar('Rewards',sum(rewards),ep)\n",
    "#         for name, weight in policy_estimator.network.named_parameters():\n",
    "#             try:\n",
    "#                 writer.add_histogram(name,weight, ep)\n",
    "#             except:\n",
    "#                 continue\n",
    "#             if weight.grad != None:\n",
    "#                 writer.add_histogram(f\"{name}.grad\",weight.grad, ep)\n",
    "    \n",
    "#     writer.add_graph(policy_estimator.network,torch.FloatTensor(machine.sensor(0))) #draw graph\n",
    "#     writer.flush()\n",
    "#     writer.close()\n",
    "    \n",
    "    return (total_rewards,batch_actions,state_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(distribution,entropy_coeff):\n",
    "    entropy = 0\n",
    "    x = distribution.detach().numpy()\n",
    "    for row in x:\n",
    "        entropy += -np.sum(row + np.log(row))\n",
    "\n",
    "    ave_entropy = entropy/len(x)\n",
    "    return ave_entropy*entropy_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\overl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator GaussianMixture from version 0.20.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.50585335 0.49414667], Action: 0, state: 0\n",
      "Action prob: [0.49812436 0.5018757 ], Action: 0, state: 0\n",
      "Action prob: [0.5008278  0.49917215], Action: 1, state: 0\n",
      "Action prob: [0.46628308 0.5337169 ], Action: 0, state: 4\n",
      "Action prob: [0.50355905 0.49644095], Action: 1, state: 0\n",
      "Action prob: [0.46628308 0.5337169 ], Action: 1, state: 4\n",
      "Action prob: [0.50054145 0.49945858], Action: 1, state: 0\n",
      "Action prob: [0.46628308 0.5337169 ], Action: 1, state: 4\n",
      "Action prob: [0.5024651  0.49753484], Action: 1, state: 0\n",
      "Action prob: [0.46628308 0.5337169 ], Action: 1, state: 4\n",
      "Action prob: [0.49730906 0.5026909 ], Action: 0, state: 0\n",
      "Action prob: [0.501205 0.498795], Action: 1, state: 1\n",
      "Action prob: [0.46628308 0.5337169 ], Action: 0, state: 5\n",
      "Action prob: [0.46628308 0.5337169 ], Action: 0, state: 5\n",
      "Action prob: [0.46628308 0.5337169 ], Action: 0, state: 5\n",
      "Action prob: [0.49777123 0.50222874], Action: 0, state: 0\n",
      "Action prob: [0.49821383 0.50178623], Action: 0, state: 1\n",
      "Action prob: [0.50081235 0.4991877 ], Action: 1, state: 2\n",
      "Action prob: [0.46628308 0.5337169 ], Action: 0, state: 6\n",
      "Action prob: [0.50123423 0.49876577], Action: 0, state: 1\n",
      "Action prob: [0.5000679  0.49993208], Action: 0, state: 1\n",
      "Action prob: [0.50165874 0.49834126], Action: 0, state: 1\n",
      "Action prob: [0.5029023  0.49709767], Action: 0, state: 1\n",
      "Action prob: [0.5018713  0.49812877], Action: 1, state: 1\n",
      "Action prob: [0.46628308 0.5337169 ], Action: 1, state: 5\n",
      "Action prob: [0.46628308 0.5337169 ], Action: 1, state: 5\n",
      "Action prob: [0.46628308 0.5337169 ], Action: 0, state: 5\n",
      "tensor([-2.4892, -1.4607, -0.5371, -1.0188, -0.2657, -0.4933, -0.0660, -0.2440,\n",
      "         0.0771, -0.0638,  0.1808,  0.3719,  0.3086,  0.2241,  0.1523,  0.2509,\n",
      "         0.3358,  0.3991,  0.4008,  0.4147,  0.4604,  0.4957,  0.5257,  0.5603,\n",
      "         0.4932,  0.4833,  0.5771], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for this episode 9600, loss is -0.0027177683591547235\n",
      "Action prob: [0.5806617  0.41933826], Action: 1, state: 0\n",
      "Action prob: [0.39599237 0.60400766], Action: 0, state: 4\n",
      "Action prob: [0.5826487 0.4173513], Action: 1, state: 0\n",
      "Action prob: [0.39599237 0.60400766], Action: 1, state: 4\n",
      "Action prob: [0.5822976  0.41770238], Action: 1, state: 0\n",
      "Action prob: [0.39599237 0.60400766], Action: 0, state: 4\n",
      "Action prob: [0.58063275 0.41936728], Action: 1, state: 0\n",
      "Action prob: [0.39599237 0.60400766], Action: 1, state: 4\n",
      "Action prob: [0.39599237 0.60400766], Action: 1, state: 4\n",
      "Action prob: [0.5802312  0.41976875], Action: 0, state: 0\n",
      "Action prob: [0.581661   0.41833898], Action: 0, state: 0\n",
      "Action prob: [0.57420784 0.42579216], Action: 1, state: 1\n",
      "Action prob: [0.39599237 0.60400766], Action: 0, state: 5\n",
      "Action prob: [0.39599237 0.60400766], Action: 0, state: 5\n",
      "Action prob: [0.39599237 0.60400766], Action: 1, state: 5\n",
      "Action prob: [0.5835547  0.41644534], Action: 0, state: 0\n",
      "Action prob: [0.58565676 0.4143432 ], Action: 1, state: 0\n",
      "Action prob: [0.39599237 0.60400766], Action: 1, state: 4\n",
      "Action prob: [0.39599237 0.60400766], Action: 1, state: 4\n",
      "Action prob: [0.5836799 0.4163201], Action: 1, state: 0\n",
      "Action prob: [0.39599237 0.60400766], Action: 1, state: 4\n",
      "Action prob: [0.39599237 0.60400766], Action: 1, state: 4\n",
      "Action prob: [0.39599237 0.60400766], Action: 0, state: 4\n",
      "tensor([-1.4731, -2.6556, -0.7645, -0.8679, -0.2465, -0.8281,  0.1267, -0.1493,\n",
      "        -0.3387, -0.0181,  0.2761,  0.7896,  0.6751,  0.5207,  0.2120,  0.3561,\n",
      "         0.7629,  0.3927,  0.3554,  0.7279,  0.3919,  0.3690,  0.6422],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode 3400, loss is 0.03232684419964786\n",
      "Action prob: [0.60242945 0.3975706 ], Action: 0, state: 0\n",
      "Action prob: [0.6087796  0.39122042], Action: 1, state: 0\n",
      "Action prob: [0.54127204 0.45872796], Action: 1, state: 4\n",
      "Action prob: [0.54127204 0.45872796], Action: 0, state: 4\n",
      "Action prob: [0.54127204 0.45872796], Action: 0, state: 4\n",
      "Action prob: [0.60699064 0.3930094 ], Action: 0, state: 0\n",
      "Action prob: [0.60994786 0.39005217], Action: 0, state: 0\n",
      "Action prob: [0.611844  0.3881559], Action: 0, state: 1\n",
      "Action prob: [0.6076743  0.39232573], Action: 0, state: 1\n",
      "Action prob: [0.6072621  0.39273793], Action: 0, state: 1\n",
      "Action prob: [0.6246775 0.3753225], Action: 0, state: 1\n",
      "Action prob: [0.6054744  0.39452562], Action: 1, state: 2\n",
      "Action prob: [0.54127204 0.45872796], Action: 0, state: 6\n",
      "Action prob: [0.6109652  0.38903478], Action: 0, state: 1\n",
      "Action prob: [0.6120567  0.38794327], Action: 0, state: 1\n",
      "Action prob: [0.60582185 0.39417812], Action: 0, state: 2\n",
      "Action prob: [0.6065641  0.39343587], Action: 0, state: 2\n",
      "Action prob: [0.6086126  0.39138737], Action: 1, state: 3\n",
      "Action prob: [0.54127204 0.45872796], Action: 1, state: 7\n",
      "Action prob: [0.54127204 0.45872796], Action: 1, state: 7\n",
      "Action prob: [0.54127204 0.45872796], Action: 0, state: 7\n",
      "Action prob: [0.6099414  0.39005858], Action: 0, state: 2\n",
      "Action prob: [0.6064114  0.39358857], Action: 0, state: 2\n",
      "Action prob: [0.61045325 0.38954675], Action: 0, state: 2\n",
      "Action prob: [0.6084005  0.39159954], Action: 1, state: 3\n",
      "Action prob: [0.54127204 0.45872796], Action: 1, state: 7\n",
      "Action prob: [0.60888374 0.39111632], Action: 0, state: 2\n",
      "Action prob: [0.6033651 0.3966349], Action: 1, state: 3\n",
      "Action prob: [0.54127204 0.45872796], Action: 0, state: 7\n",
      "Action prob: [0.606237 0.393763], Action: 0, state: 2\n",
      "Action prob: [0.6078557  0.39214432], Action: 1, state: 2\n",
      "Action prob: [0.54127204 0.45872796], Action: 0, state: 6\n",
      "Action prob: [0.6100576  0.38994235], Action: 1, state: 1\n",
      "Action prob: [0.54127204 0.45872796], Action: 0, state: 5\n",
      "Action prob: [0.54127204 0.45872796], Action: 1, state: 5\n",
      "Action prob: [0.54127204 0.45872796], Action: 0, state: 5\n",
      "Action prob: [0.54127204 0.45872796], Action: 0, state: 5\n",
      "Action prob: [0.54127204 0.45872796], Action: 0, state: 5\n",
      "tensor([-1.2469e+00, -1.1285e+00, -1.3538e+00, -1.3453e+00, -1.5824e+00,\n",
      "        -9.5914e-01, -6.7386e-01, -4.5985e-01, -2.8546e-01, -1.3197e-01,\n",
      "        -1.1047e-03,  1.8209e-01,  5.5568e-02,  1.2395e-01,  1.9070e-01,\n",
      "         2.4651e-01,  2.8986e-01,  5.8769e-01,  4.5729e-01,  4.3099e-01,\n",
      "         3.2188e-01,  2.7853e-01,  2.9838e-01,  3.0833e-01,  5.9972e-01,\n",
      "         4.8859e-01,  3.1964e-01,  6.0428e-01,  3.9632e-01,  3.2846e-01,\n",
      "         6.2281e-01,  4.0544e-01,  6.2896e-01,  4.0782e-01,  5.1546e-01,\n",
      "         4.0448e-01,  4.0317e-01,  4.0206e-01], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for this episode 11500, loss is -0.029755458167756516\n",
      "Action prob: [0.6658171  0.33418292], Action: 0, state: 0\n",
      "Action prob: [0.6652399  0.33476016], Action: 0, state: 0\n",
      "Action prob: [0.6667115  0.33328855], Action: 0, state: 0\n",
      "Action prob: [0.668288 0.331712], Action: 0, state: 1\n",
      "Action prob: [0.6687374 0.3312626], Action: 0, state: 2\n",
      "Action prob: [0.6604629  0.33953705], Action: 1, state: 2\n",
      "Action prob: [0.6533087  0.34669134], Action: 0, state: 6\n",
      "Action prob: [0.66460973 0.3353903 ], Action: 0, state: 1\n",
      "Action prob: [0.66437966 0.33562037], Action: 0, state: 1\n",
      "Action prob: [0.66599256 0.3340074 ], Action: 0, state: 2\n",
      "Action prob: [0.66730696 0.33269298], Action: 1, state: 2\n",
      "Action prob: [0.6533087  0.34669134], Action: 0, state: 6\n",
      "Action prob: [0.66466427 0.33533573], Action: 1, state: 1\n",
      "Action prob: [0.6533087  0.34669134], Action: 1, state: 5\n",
      "Action prob: [0.6740513  0.32594875], Action: 0, state: 0\n",
      "Action prob: [0.6689608  0.33103922], Action: 0, state: 0\n",
      "Action prob: [0.6692488  0.33075112], Action: 1, state: 1\n",
      "Action prob: [0.6533087  0.34669134], Action: 0, state: 5\n",
      "Action prob: [0.66635525 0.33364475], Action: 0, state: 0\n",
      "Action prob: [0.66693765 0.33306232], Action: 1, state: 1\n",
      "Action prob: [0.6533087  0.34669134], Action: 1, state: 5\n",
      "tensor([-1.1744, -0.8451, -0.5601, -0.3435, -0.1820, -0.1213, -0.1247, -0.0068,\n",
      "         0.0892,  0.1608,  0.6015,  0.1985,  0.6435,  0.5626,  0.2483,  0.2867,\n",
      "         0.8598,  0.3180,  0.3241,  0.9209,  0.8676], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for this episode 12100, loss is -0.12970262286512996\n",
      "Action prob: [0.73055613 0.26944384], Action: 1, state: 0\n",
      "Action prob: [0.7395334  0.26046664], Action: 0, state: 4\n",
      "Action prob: [0.7395334  0.26046664], Action: 0, state: 4\n",
      "Action prob: [0.7395334  0.26046664], Action: 1, state: 4\n",
      "Action prob: [0.7395334  0.26046664], Action: 0, state: 4\n",
      "Action prob: [0.7307575 0.2692425], Action: 0, state: 0\n",
      "Action prob: [0.73612744 0.26387253], Action: 0, state: 0\n",
      "Action prob: [0.7318606  0.26813942], Action: 0, state: 0\n",
      "Action prob: [0.72800785 0.27199218], Action: 0, state: 1\n",
      "Action prob: [0.7339463 0.2660537], Action: 0, state: 1\n",
      "Action prob: [0.7328056  0.26719442], Action: 0, state: 1\n",
      "Action prob: [0.73579943 0.2642005 ], Action: 0, state: 1\n",
      "Action prob: [0.7308279 0.2691721], Action: 1, state: 1\n",
      "Action prob: [0.7395334  0.26046664], Action: 0, state: 5\n",
      "Action prob: [0.7277846 0.2722154], Action: 1, state: 0\n",
      "Action prob: [0.7395334  0.26046664], Action: 0, state: 4\n",
      "Action prob: [0.7304661 0.2695339], Action: 0, state: 0\n",
      "Action prob: [0.7306558  0.26934418], Action: 0, state: 0\n",
      "Action prob: [0.73440725 0.26559278], Action: 0, state: 1\n",
      "Action prob: [0.73347634 0.26652366], Action: 0, state: 2\n",
      "Action prob: [0.73363215 0.2663679 ], Action: 0, state: 2\n",
      "Action prob: [0.7336095  0.26639053], Action: 0, state: 2\n",
      "Action prob: [0.73159474 0.2684053 ], Action: 1, state: 3\n",
      "Action prob: [0.7395334  0.26046664], Action: 0, state: 7\n",
      "Action prob: [0.7395334  0.26046664], Action: 1, state: 7\n",
      "Action prob: [0.7395334  0.26046664], Action: 1, state: 7\n",
      "Action prob: [0.7303376  0.26966235], Action: 0, state: 2\n",
      "Action prob: [0.7323136  0.26768646], Action: 1, state: 3\n",
      "Action prob: [0.7395334  0.26046664], Action: 0, state: 7\n",
      "Action prob: [0.7395334  0.26046664], Action: 0, state: 7\n",
      "Action prob: [0.7395334  0.26046664], Action: 0, state: 7\n",
      "Action prob: [0.7328168  0.26718327], Action: 1, state: 2\n",
      "Action prob: [0.7395334  0.26046664], Action: 0, state: 6\n",
      "Action prob: [0.733156   0.26684394], Action: 0, state: 1\n",
      "Action prob: [0.7353247  0.26467535], Action: 0, state: 1\n",
      "Action prob: [0.731985   0.26801506], Action: 0, state: 1\n",
      "Action prob: [0.72838163 0.27161837], Action: 0, state: 1\n",
      "Action prob: [0.7298384  0.27016163], Action: 0, state: 1\n",
      "Action prob: [0.7316871  0.26831284], Action: 0, state: 1\n",
      "Action prob: [0.72710156 0.2728984 ], Action: 0, state: 1\n",
      "Action prob: [0.73114634 0.26885366], Action: 1, state: 2\n",
      "Action prob: [0.7395334  0.26046664], Action: 1, state: 6\n",
      "Action prob: [0.7395334  0.26046664], Action: 0, state: 6\n",
      "Action prob: [0.7395334  0.26046664], Action: 0, state: 6\n",
      "Action prob: [0.7395334  0.26046664], Action: 0, state: 6\n",
      "Action prob: [0.73256075 0.26743928], Action: 0, state: 1\n",
      "Action prob: [0.7358651  0.26413485], Action: 1, state: 2\n",
      "Action prob: [0.7395334  0.26046664], Action: 0, state: 6\n",
      "Action prob: [0.73178065 0.26821935], Action: 0, state: 1\n",
      "Action prob: [0.728353 0.271647], Action: 0, state: 1\n",
      "tensor([-1.3272, -0.5121, -0.6879, -3.7328, -0.9642, -0.7780, -0.5735, -0.4231,\n",
      "        -0.3047, -0.1930, -0.1051, -0.0293,  0.1457,  0.0041,  0.2333,  0.0328,\n",
      "         0.0718,  0.1037,  0.1260,  0.1447,  0.1601,  0.1733,  0.7655,  0.1698,\n",
      "         0.7352,  0.7166,  0.1733,  0.7401,  0.1669,  0.1647,  0.1628,  0.7233,\n",
      "         0.1640,  0.1708,  0.1710,  0.1750,  0.1791,  0.1791,  0.1786,  0.1830,\n",
      "         0.7570,  0.7739,  0.1733,  0.1731,  0.1729,  0.1786,  0.7651,  0.1733,\n",
      "         0.1795,  0.1824], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode 18900, loss is -0.02025943353015689\n",
      "Action prob: [0.79417694 0.20582314], Action: 0, state: 0\n",
      "Action prob: [0.7930434 0.2069567], Action: 0, state: 0\n",
      "Action prob: [0.79183954 0.20816045], Action: 0, state: 0\n",
      "Action prob: [0.791941   0.20805897], Action: 1, state: 0\n",
      "Action prob: [0.7913356  0.20866445], Action: 0, state: 4\n",
      "Action prob: [0.7919606 0.2080394], Action: 0, state: 0\n",
      "Action prob: [0.79397607 0.20602392], Action: 0, state: 1\n",
      "Action prob: [0.81979233 0.18020768], Action: 0, state: 1\n",
      "Action prob: [0.7947257  0.20527425], Action: 1, state: 2\n",
      "Action prob: [0.7913356  0.20866445], Action: 0, state: 6\n",
      "Action prob: [0.7948712  0.20512876], Action: 0, state: 1\n",
      "Action prob: [0.7919352  0.20806478], Action: 0, state: 1\n",
      "Action prob: [0.7892816  0.21071845], Action: 0, state: 1\n",
      "Action prob: [0.79251933 0.20748068], Action: 0, state: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.7959728  0.20402715], Action: 0, state: 2\n",
      "Action prob: [0.79315466 0.20684533], Action: 0, state: 2\n",
      "Action prob: [0.79411954 0.20588045], Action: 1, state: 2\n",
      "Action prob: [0.7913356  0.20866445], Action: 0, state: 6\n",
      "Action prob: [0.79200023 0.20799983], Action: 0, state: 1\n",
      "Action prob: [0.7973815  0.20261846], Action: 0, state: 1\n",
      "Action prob: [0.794361   0.20563893], Action: 0, state: 2\n",
      "Action prob: [0.7951001  0.20489997], Action: 0, state: 3\n",
      "Action prob: [0.78982514 0.21017489], Action: 0, state: 3\n",
      "Action prob: [0.83052844 0.16947153], Action: 0, state: 8\n",
      "Action prob: [0.78893816 0.21106187], Action: 0, state: 8\n",
      "Action prob: [0.79633886 0.20366113], Action: 1, state: 8\n",
      "Action prob: [0.79522413 0.20477583], Action: 0, state: 8\n",
      "Action prob: [0.82123053 0.17876945], Action: 0, state: 8\n",
      "Action prob: [0.79205054 0.20794944], Action: 0, state: 8\n",
      "Action prob: [0.8249526  0.17504735], Action: 1, state: 8\n",
      "Action prob: [0.7941097  0.20589025], Action: 0, state: 8\n",
      "Action prob: [0.855252   0.14474791], Action: 0, state: 8\n",
      "Action prob: [0.79025906 0.20974088], Action: 0, state: 8\n",
      "Action prob: [0.82164335 0.17835662], Action: 0, state: 8\n",
      "Action prob: [0.78809553 0.21190447], Action: 0, state: 8\n",
      "Action prob: [0.8213761  0.17862388], Action: 0, state: 8\n",
      "Action prob: [0.8007997 0.1992002], Action: 1, state: 8\n",
      "tensor([-8.4126e-01, -6.2699e-01, -4.4331e-01, -1.9082e+00, -3.5248e-01,\n",
      "        -2.3604e-01, -1.4627e-01, -6.2137e-02, -1.1076e-01, -4.6553e-02,\n",
      "        -3.6634e-04,  3.8753e-02,  7.3046e-02,  9.6829e-02,  1.1591e-01,\n",
      "         1.3575e-01,  1.0304e+00,  1.4435e-01,  1.5637e-01,  1.6218e-01,\n",
      "         1.7285e-01,  1.7635e-01,  1.8515e-01,  1.3095e-01,  1.5116e-01,\n",
      "         9.2320e-01,  1.2174e-01,  9.6468e-02,  1.0596e-01,  7.3983e-01,\n",
      "         9.1991e-02,  5.9005e-02,  8.4494e-02,  6.7439e-02,  7.8581e-02,\n",
      "         6.2707e-02,  4.9865e-01], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -26400, loss is -0.025018499426853788\n",
      "Action prob: [0.85026824 0.14973173], Action: 0, state: 0\n",
      "Action prob: [0.8458006  0.15419935], Action: 0, state: 0\n",
      "Action prob: [0.8492667  0.15073328], Action: 0, state: 1\n",
      "Action prob: [0.84319204 0.15680794], Action: 0, state: 1\n",
      "Action prob: [0.8437019  0.15629815], Action: 0, state: 2\n",
      "Action prob: [0.8451894  0.15481062], Action: 0, state: 2\n",
      "Action prob: [0.84582496 0.15417495], Action: 0, state: 2\n",
      "Action prob: [0.84845746 0.15154251], Action: 1, state: 3\n",
      "Action prob: [0.8327171 0.1672829], Action: 0, state: 7\n",
      "Action prob: [0.8435818  0.15641813], Action: 0, state: 2\n",
      "Action prob: [0.84452164 0.15547837], Action: 0, state: 3\n",
      "Action prob: [0.8423097  0.15769032], Action: 0, state: 3\n",
      "Action prob: [0.8469424  0.15305758], Action: 0, state: 9\n",
      "Action prob: [0.84285736 0.15714264], Action: 0, state: 9\n",
      "Action prob: [0.8478631  0.15213688], Action: 0, state: 9\n",
      "Action prob: [0.85113496 0.14886504], Action: 0, state: 9\n",
      "Action prob: [0.85189366 0.14810637], Action: 0, state: 9\n",
      "Action prob: [0.84622115 0.15377888], Action: 0, state: 9\n",
      "Action prob: [0.8477693  0.15223062], Action: 0, state: 9\n",
      "Action prob: [0.8735538  0.12644613], Action: 0, state: 9\n",
      "Action prob: [0.84313405 0.15686591], Action: 1, state: 9\n",
      "tensor([-0.4984, -0.3529, -0.2237, -0.1264, -0.0454,  0.0229,  0.0802,  1.2469,\n",
      "         0.0927,  0.1219,  0.1400,  0.1585,  0.1266,  0.1068,  0.0838,  0.0659,\n",
      "         0.0520,  0.0422,  0.0317,  0.0189,  0.1776], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for this episode -1000, loss is -0.06292829218199644\n",
      "Action prob: [0.89104444 0.10895555], Action: 0, state: 0\n",
      "Action prob: [0.89687055 0.10312939], Action: 0, state: 0\n",
      "Action prob: [0.8990379  0.10096213], Action: 0, state: 0\n",
      "Action prob: [0.8970066  0.10299341], Action: 0, state: 0\n",
      "Action prob: [0.888136   0.11186399], Action: 0, state: 0\n",
      "Action prob: [0.900304   0.09969601], Action: 0, state: 1\n",
      "Action prob: [0.89448905 0.10551094], Action: 0, state: 2\n",
      "Action prob: [0.8804841  0.11951586], Action: 0, state: 9\n",
      "Action prob: [0.9088712  0.09112883], Action: 0, state: 9\n",
      "Action prob: [0.90012443 0.09987557], Action: 0, state: 9\n",
      "Action prob: [0.8979536  0.10204636], Action: 0, state: 9\n",
      "Action prob: [0.92386264 0.07613739], Action: 0, state: 9\n",
      "Action prob: [0.8862973  0.11370267], Action: 0, state: 9\n",
      "Action prob: [0.89786583 0.10213418], Action: 0, state: 9\n",
      "Action prob: [0.89878833 0.10121166], Action: 0, state: 9\n",
      "Action prob: [0.89274037 0.1072597 ], Action: 0, state: 9\n",
      "Action prob: [0.9006532  0.09934679], Action: 0, state: 9\n",
      "Action prob: [0.8941977  0.10580231], Action: 0, state: 9\n",
      "Action prob: [0.9237505  0.07624951], Action: 0, state: 9\n",
      "Action prob: [0.91744614 0.08255393], Action: 0, state: 9\n",
      "Action prob: [0.90016276 0.09983715], Action: 0, state: 9\n",
      "Action prob: [0.8902915  0.10970847], Action: 0, state: 9\n",
      "Action prob: [0.89886355 0.10113648], Action: 1, state: 9\n",
      "Action prob: [0.8917653  0.10823472], Action: 0, state: 9\n",
      "Action prob: [0.8864781 0.1135219], Action: 0, state: 9\n",
      "Action prob: [0.8990415  0.10095858], Action: 0, state: 9\n",
      "Action prob: [0.8906097  0.10939031], Action: 0, state: 9\n",
      "Action prob: [0.8996149 0.1003852], Action: 0, state: 9\n",
      "Action prob: [0.8999316  0.10006843], Action: 0, state: 9\n",
      "Action prob: [0.9005087  0.09949132], Action: 0, state: 9\n",
      "Action prob: [0.8905195  0.10948057], Action: 0, state: 9\n",
      "Action prob: [0.9176323  0.08236776], Action: 0, state: 9\n",
      "Action prob: [0.8890401  0.11095989], Action: 1, state: 9\n",
      "tensor([-0.2955, -0.1459, -0.0322,  0.0629,  0.1576,  0.1998,  0.2604,  0.2387,\n",
      "         0.1418,  0.1211,  0.0935,  0.0497,  0.0512,  0.0270,  0.0109, -0.0026,\n",
      "        -0.0136, -0.0246, -0.0236, -0.0313, -0.0440, -0.0541, -1.1593, -0.0619,\n",
      "        -0.0686, -0.0632, -0.0712, -0.0669, -0.0683, -0.0693, -0.0779, -0.0585,\n",
      "        -1.5149], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -19300, loss is 0.07674936172449318\n",
      "Action prob: [0.9212746  0.07872541], Action: 0, state: 0\n",
      "Action prob: [0.9153529  0.08464714], Action: 0, state: 0\n",
      "Action prob: [0.9175886  0.08241138], Action: 0, state: 0\n",
      "Action prob: [0.9164343  0.08356564], Action: 0, state: 0\n",
      "Action prob: [0.92358726 0.07641277], Action: 0, state: 1\n",
      "Action prob: [0.91838807 0.08161199], Action: 0, state: 1\n",
      "Action prob: [0.9176612  0.08233879], Action: 0, state: 1\n",
      "Action prob: [0.91843826 0.08156179], Action: 0, state: 1\n",
      "Action prob: [0.91853094 0.08146904], Action: 0, state: 2\n",
      "Action prob: [0.91613376 0.08386622], Action: 0, state: 3\n",
      "Action prob: [0.93307084 0.06692919], Action: 0, state: 3\n",
      "Action prob: [0.9153724  0.08462763], Action: 0, state: 3\n",
      "Action prob: [0.91687363 0.08312634], Action: 0, state: 8\n",
      "Action prob: [0.9133106  0.08668935], Action: 0, state: 8\n",
      "Action prob: [0.925406   0.07459405], Action: 0, state: 8\n",
      "Action prob: [0.9274274  0.07257255], Action: 0, state: 8\n",
      "Action prob: [0.9237796  0.07622036], Action: 0, state: 8\n",
      "Action prob: [0.9251862  0.07481379], Action: 0, state: 8\n",
      "Action prob: [0.91727394 0.08272607], Action: 0, state: 8\n",
      "Action prob: [0.92217386 0.07782617], Action: 0, state: 8\n",
      "Action prob: [0.91560405 0.08439591], Action: 0, state: 8\n",
      "Action prob: [0.914478   0.08552197], Action: 0, state: 8\n",
      "Action prob: [0.91231483 0.08768518], Action: 0, state: 8\n",
      "Action prob: [0.9199362  0.08006383], Action: 0, state: 8\n",
      "Action prob: [0.9137755  0.08622447], Action: 0, state: 8\n",
      "Action prob: [0.9098268  0.09017316], Action: 0, state: 8\n",
      "Action prob: [0.9123569  0.08764312], Action: 0, state: 8\n",
      "Action prob: [0.9615452  0.03845477], Action: 0, state: 8\n",
      "Action prob: [0.9404925  0.05950752], Action: 0, state: 8\n",
      "Action prob: [0.9244142  0.07558583], Action: 0, state: 8\n",
      "Action prob: [0.925544   0.07445595], Action: 0, state: 8\n",
      "Action prob: [0.91153294 0.08846707], Action: 1, state: 8\n",
      "Action prob: [0.9138909  0.08610914], Action: 0, state: 8\n",
      "Action prob: [0.9291106  0.07088941], Action: 0, state: 8\n",
      "Action prob: [0.93980646 0.06019354], Action: 0, state: 8\n",
      "Action prob: [0.9236369  0.07636307], Action: 0, state: 8\n",
      "Action prob: [0.9098286  0.09017142], Action: 0, state: 8\n",
      "Action prob: [0.9164969  0.08350311], Action: 0, state: 8\n",
      "Action prob: [0.92147255 0.07852747], Action: 0, state: 8\n",
      "Action prob: [0.9158656  0.08413443], Action: 0, state: 8\n",
      "Action prob: [0.9251052  0.07489478], Action: 0, state: 8\n",
      "Action prob: [0.917719   0.08228098], Action: 0, state: 8\n",
      "Action prob: [0.9271644  0.07283555], Action: 0, state: 8\n",
      "Action prob: [0.9235135  0.07648649], Action: 0, state: 8\n",
      "Action prob: [0.9411929 0.0588071], Action: 0, state: 8\n",
      "Action prob: [0.9227218  0.07727814], Action: 0, state: 8\n",
      "Action prob: [0.9207255  0.07927445], Action: 0, state: 8\n",
      "Action prob: [0.9275468  0.07245325], Action: 0, state: 8\n",
      "Action prob: [0.91433734 0.0856627 ], Action: 0, state: 8\n",
      "Action prob: [0.9245638  0.07543623], Action: 0, state: 8\n",
      "tensor([-1.7500e-01, -1.0949e-01, -4.0953e-02,  1.4956e-02,  5.3000e-02,\n",
      "         9.2612e-02,  1.2423e-01,  1.4889e-01,  1.6824e-01,  1.8411e-01,\n",
      "         1.5280e-01,  2.0284e-01,  1.6003e-01,  1.3253e-01,  8.8101e-02,\n",
      "         6.4802e-02,  4.9571e-02,  3.3095e-02,  2.2097e-02,  9.0468e-03,\n",
      "        -9.6529e-04, -1.0296e-02, -1.8698e-02, -2.3286e-02, -3.0932e-02,\n",
      "        -3.7559e-02, -4.0697e-02, -1.8940e-02, -3.1682e-02, -4.2819e-02,\n",
      "        -4.4021e-02, -1.4295e+00, -5.4647e-02, -4.5713e-02, -3.9379e-02,\n",
      "        -5.1239e-02, -6.1815e-02, -5.7713e-02, -5.4667e-02, -5.9238e-02,\n",
      "        -5.2842e-02, -5.8631e-02, -5.1898e-02, -5.4838e-02, -4.1920e-02,\n",
      "        -5.5798e-02, -5.7449e-02, -5.2429e-02, -6.2544e-02, -5.4863e-02],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -108100, loss is 0.02643037200651832\n",
      "Action prob: [0.9356198  0.06438027], Action: 0, state: 0\n",
      "Action prob: [0.9339139  0.06608608], Action: 0, state: 0\n",
      "Action prob: [0.9373525 0.0626475], Action: 0, state: 1\n",
      "Action prob: [0.9343601  0.06563989], Action: 0, state: 1\n",
      "Action prob: [0.9368278  0.06317216], Action: 0, state: 1\n",
      "Action prob: [0.93323714 0.06676287], Action: 0, state: 1\n",
      "Action prob: [0.93592364 0.06407638], Action: 0, state: 1\n",
      "Action prob: [0.9339225  0.06607746], Action: 0, state: 2\n",
      "Action prob: [0.93480235 0.06519768], Action: 0, state: 2\n",
      "Action prob: [0.9350117 0.0649883], Action: 0, state: 3\n",
      "Action prob: [0.9350561  0.06494386], Action: 0, state: 3\n",
      "Action prob: [0.933327   0.06667299], Action: 1, state: 3\n",
      "Action prob: [0.88992137 0.1100786 ], Action: 0, state: 7\n",
      "Action prob: [0.88992137 0.1100786 ], Action: 0, state: 7\n",
      "Action prob: [0.88992137 0.1100786 ], Action: 1, state: 7\n",
      "Action prob: [0.88992137 0.1100786 ], Action: 0, state: 7\n",
      "Action prob: [0.88992137 0.1100786 ], Action: 0, state: 7\n",
      "Action prob: [0.9323851  0.06761487], Action: 0, state: 2\n",
      "Action prob: [0.9359826  0.06401747], Action: 0, state: 2\n",
      "Action prob: [0.934348 0.065652], Action: 0, state: 2\n",
      "Action prob: [0.9325423 0.0674577], Action: 0, state: 3\n",
      "Action prob: [0.9319002 0.0680998], Action: 0, state: 3\n",
      "Action prob: [0.93960357 0.06039635], Action: 0, state: 9\n",
      "Action prob: [0.9538162 0.0461839], Action: 0, state: 9\n",
      "Action prob: [0.926943   0.07305696], Action: 0, state: 9\n",
      "Action prob: [0.9290621  0.07093785], Action: 0, state: 9\n",
      "Action prob: [0.9368494  0.06315058], Action: 0, state: 9\n",
      "Action prob: [0.93504983 0.06495012], Action: 0, state: 9\n",
      "Action prob: [0.93538934 0.06461065], Action: 0, state: 9\n",
      "Action prob: [0.92412084 0.07587922], Action: 0, state: 9\n",
      "Action prob: [0.9485354  0.05146459], Action: 0, state: 9\n",
      "Action prob: [0.92743963 0.07256033], Action: 1, state: 9\n",
      "Action prob: [0.9381665  0.06183357], Action: 0, state: 9\n",
      "Action prob: [0.93709075 0.06290919], Action: 0, state: 9\n",
      "Action prob: [0.9286783  0.07132176], Action: 0, state: 9\n",
      "Action prob: [0.9410222  0.05897781], Action: 0, state: 9\n",
      "Action prob: [0.9381389  0.06186111], Action: 0, state: 9\n",
      "Action prob: [0.9365775  0.06342255], Action: 0, state: 9\n",
      "Action prob: [0.9504233  0.04957666], Action: 0, state: 9\n",
      "Action prob: [0.9391063  0.06089371], Action: 0, state: 9\n",
      "Action prob: [0.9488457  0.05115432], Action: 0, state: 9\n",
      "Action prob: [0.95000386 0.04999613], Action: 0, state: 9\n",
      "Action prob: [0.93182707 0.06817291], Action: 0, state: 9\n",
      "Action prob: [0.92865205 0.07134792], Action: 0, state: 9\n",
      "Action prob: [0.9390972  0.06090282], Action: 0, state: 9\n",
      "Action prob: [0.93507767 0.06492227], Action: 0, state: 9\n",
      "Action prob: [0.95188314 0.04811685], Action: 0, state: 9\n",
      "Action prob: [0.9276807 0.0723194], Action: 0, state: 9\n",
      "Action prob: [0.92651373 0.0734863 ], Action: 0, state: 9\n",
      "Action prob: [0.93811464 0.06188539], Action: 0, state: 9\n",
      "tensor([-0.2987, -0.2332, -0.1673, -0.1280, -0.0841, -0.0541, -0.0233, -0.0018,\n",
      "         0.0168,  0.0266,  0.0350,  1.6994,  0.0627,  0.0537,  0.8727,  0.0397,\n",
      "         0.0342,  0.0250,  0.0272,  0.0311,  0.0337,  0.0355,  0.0291,  0.0207,\n",
      "         0.0312,  0.0287,  0.0242,  0.0239,  0.0229,  0.0261,  0.0170,  0.8212,\n",
      "         0.0195,  0.0195,  0.0218,  0.0177,  0.0183,  0.0186,  0.0143,  0.0175,\n",
      "         0.0146,  0.0141,  0.0194,  0.0202,  0.0171,  0.0182,  0.0133,  0.0203,\n",
      "         0.0206,  0.0172], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -19500, loss is -0.06739985411696375\n",
      "Action prob: [0.946906   0.05309402], Action: 0, state: 0\n",
      "Action prob: [0.95198053 0.04801945], Action: 0, state: 1\n",
      "Action prob: [0.9480498  0.05195025], Action: 0, state: 1\n",
      "Action prob: [0.94903105 0.0509689 ], Action: 0, state: 1\n",
      "Action prob: [0.94735706 0.05264292], Action: 0, state: 1\n",
      "Action prob: [0.94771504 0.05228494], Action: 0, state: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.9464336  0.05356647], Action: 0, state: 2\n",
      "Action prob: [0.95186466 0.04813535], Action: 0, state: 2\n",
      "Action prob: [0.9445162 0.0554838], Action: 0, state: 3\n",
      "Action prob: [0.94826967 0.05173031], Action: 0, state: 3\n",
      "Action prob: [0.94979364 0.05020638], Action: 0, state: 3\n",
      "Action prob: [0.9483193  0.05168062], Action: 0, state: 8\n",
      "Action prob: [0.94062823 0.05937174], Action: 0, state: 8\n",
      "Action prob: [0.941985   0.05801498], Action: 0, state: 8\n",
      "Action prob: [0.9417261  0.05827389], Action: 0, state: 8\n",
      "Action prob: [0.94526213 0.05473789], Action: 0, state: 8\n",
      "Action prob: [0.9468985  0.05310153], Action: 0, state: 8\n",
      "Action prob: [0.9500048  0.04999514], Action: 0, state: 8\n",
      "Action prob: [0.9455666  0.05443345], Action: 0, state: 8\n",
      "Action prob: [0.9563701 0.0436299], Action: 0, state: 8\n",
      "Action prob: [0.943644   0.05635605], Action: 0, state: 8\n",
      "Action prob: [0.9512778  0.04872228], Action: 0, state: 8\n",
      "Action prob: [0.9412731  0.05872684], Action: 0, state: 8\n",
      "Action prob: [0.95366293 0.04633702], Action: 0, state: 8\n",
      "Action prob: [0.94264877 0.0573512 ], Action: 0, state: 8\n",
      "Action prob: [0.9406457  0.05935427], Action: 0, state: 8\n",
      "Action prob: [0.954787   0.04521299], Action: 0, state: 8\n",
      "Action prob: [0.94987714 0.05012286], Action: 0, state: 8\n",
      "Action prob: [0.9650204  0.03497953], Action: 0, state: 8\n",
      "Action prob: [0.9542548  0.04574518], Action: 0, state: 8\n",
      "Action prob: [0.954033   0.04596703], Action: 0, state: 8\n",
      "Action prob: [0.95728403 0.04271603], Action: 0, state: 8\n",
      "Action prob: [0.9501621 0.0498379], Action: 0, state: 8\n",
      "Action prob: [0.94634473 0.05365523], Action: 0, state: 8\n",
      "Action prob: [0.95432097 0.04567904], Action: 0, state: 8\n",
      "Action prob: [0.95070904 0.04929091], Action: 0, state: 8\n",
      "Action prob: [0.9419629  0.05803715], Action: 0, state: 8\n",
      "Action prob: [0.94198644 0.05801353], Action: 0, state: 8\n",
      "Action prob: [0.9420929  0.05790712], Action: 0, state: 8\n",
      "Action prob: [0.961846   0.03815398], Action: 0, state: 8\n",
      "Action prob: [0.9444793  0.05552073], Action: 0, state: 8\n",
      "Action prob: [0.9529543  0.04704568], Action: 0, state: 8\n",
      "Action prob: [0.9434505  0.05654954], Action: 0, state: 8\n",
      "Action prob: [0.953514   0.04648603], Action: 0, state: 8\n",
      "Action prob: [0.9568898  0.04311017], Action: 0, state: 8\n",
      "Action prob: [0.9529908  0.04700923], Action: 0, state: 8\n",
      "Action prob: [0.9501746  0.04982539], Action: 0, state: 8\n",
      "Action prob: [0.94220895 0.05779103], Action: 0, state: 8\n",
      "Action prob: [0.95402205 0.04597794], Action: 0, state: 8\n",
      "Action prob: [0.95531297 0.04468697], Action: 1, state: 8\n",
      "tensor([-0.0608, -0.0195,  0.0114,  0.0383,  0.0634,  0.0809,  0.0985,  0.1001,\n",
      "         0.1231,  0.1203,  0.1215,  0.1001,  0.0910,  0.0685,  0.0515,  0.0344,\n",
      "         0.0220,  0.0115,  0.0041, -0.0024, -0.0095, -0.0128, -0.0203, -0.0191,\n",
      "        -0.0271, -0.0310, -0.0254, -0.0300, -0.0218, -0.0299, -0.0310, -0.0296,\n",
      "        -0.0354, -0.0390, -0.0336, -0.0368, -0.0440, -0.0444, -0.0446, -0.0293,\n",
      "        -0.0433, -0.0367, -0.0445, -0.0365, -0.0339, -0.0371, -0.0395, -0.0461,\n",
      "        -0.0365, -2.4110], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -112500, loss is 0.046024236497784955\n",
      "Action prob: [0.95607865 0.04392134], Action: 0, state: 0\n",
      "Action prob: [0.9597283  0.04027173], Action: 0, state: 0\n",
      "Action prob: [0.95797896 0.04202101], Action: 0, state: 1\n",
      "Action prob: [0.95893234 0.04106766], Action: 0, state: 2\n",
      "Action prob: [0.9574822  0.04251782], Action: 0, state: 2\n",
      "Action prob: [0.9603401  0.03965998], Action: 1, state: 3\n",
      "Action prob: [0.92160195 0.07839804], Action: 0, state: 7\n",
      "Action prob: [0.9595426 0.0404574], Action: 0, state: 2\n",
      "Action prob: [0.95697945 0.04302061], Action: 0, state: 2\n",
      "Action prob: [0.955069   0.04493096], Action: 0, state: 3\n",
      "Action prob: [0.95226574 0.04773429], Action: 1, state: 8\n",
      "Action prob: [0.9576314  0.04236862], Action: 0, state: 0\n",
      "Action prob: [0.95691544 0.04308452], Action: 0, state: 0\n",
      "Action prob: [0.9561421 0.0438578], Action: 0, state: 0\n",
      "Action prob: [0.95761424 0.04238571], Action: 0, state: 0\n",
      "Action prob: [0.9574903  0.04250968], Action: 0, state: 0\n",
      "Action prob: [0.95734245 0.04265754], Action: 0, state: 1\n",
      "Action prob: [0.95649046 0.04350952], Action: 0, state: 2\n",
      "Action prob: [0.95773375 0.04226626], Action: 0, state: 3\n",
      "Action prob: [0.95746547 0.04253448], Action: 0, state: 3\n",
      "Action prob: [0.959592   0.04040801], Action: 0, state: 3\n",
      "Action prob: [0.9565589  0.04344117], Action: 0, state: 3\n",
      "Action prob: [0.9585943  0.04140572], Action: 0, state: 3\n",
      "Action prob: [0.9591798  0.04082019], Action: 0, state: 8\n",
      "Action prob: [0.9529048  0.04709512], Action: 0, state: 8\n",
      "Action prob: [0.9577421  0.04225793], Action: 0, state: 8\n",
      "Action prob: [0.952321 0.047679], Action: 0, state: 8\n",
      "Action prob: [0.9627237  0.03727635], Action: 0, state: 8\n",
      "Action prob: [0.96139425 0.03860579], Action: 0, state: 8\n",
      "Action prob: [0.9628165  0.03718346], Action: 0, state: 8\n",
      "Action prob: [0.94897425 0.05102572], Action: 0, state: 8\n",
      "Action prob: [0.9581419  0.04185806], Action: 0, state: 8\n",
      "Action prob: [0.95751905 0.04248098], Action: 0, state: 8\n",
      "Action prob: [0.9593377  0.04066229], Action: 0, state: 8\n",
      "Action prob: [0.9507145 0.0492854], Action: 0, state: 8\n",
      "Action prob: [0.9511995  0.04880053], Action: 0, state: 8\n",
      "Action prob: [0.96056265 0.03943737], Action: 0, state: 8\n",
      "Action prob: [0.9700955  0.02990445], Action: 0, state: 8\n",
      "Action prob: [0.9530914  0.04690861], Action: 0, state: 8\n",
      "Action prob: [0.9691181  0.03088193], Action: 0, state: 8\n",
      "Action prob: [0.9654406  0.03455937], Action: 0, state: 8\n",
      "Action prob: [0.9596294 0.0403706], Action: 0, state: 8\n",
      "Action prob: [0.9525238  0.04747616], Action: 0, state: 8\n",
      "Action prob: [0.9524473 0.0475527], Action: 1, state: 8\n",
      "Action prob: [0.9499507  0.05004926], Action: 0, state: 8\n",
      "Action prob: [0.9588075  0.04119245], Action: 0, state: 8\n",
      "Action prob: [0.9593298  0.04067021], Action: 0, state: 8\n",
      "Action prob: [0.9454178  0.05458217], Action: 0, state: 8\n",
      "Action prob: [0.95735276 0.04264722], Action: 0, state: 8\n",
      "Action prob: [0.9624536  0.03754644], Action: 0, state: 8\n",
      "tensor([-2.1638e-01, -1.3708e-01, -9.4465e-02, -5.6336e-02, -2.6717e-02,\n",
      "        -7.3557e-01, -4.5464e-02, -4.5218e-03,  1.1907e-02,  2.1736e-02,\n",
      "        -1.6960e+00, -1.1498e-02, -7.6841e-04,  8.6767e-03,  1.6144e-02,\n",
      "         2.2811e-02,  2.7974e-02,  3.2464e-02,  3.3537e-02,  3.5483e-02,\n",
      "         3.5066e-02,  3.9034e-02,  3.8199e-02,  3.2455e-02,  3.2459e-02,\n",
      "         2.5166e-02,  2.4737e-02,  1.6765e-02,  1.5199e-02,  1.2848e-02,\n",
      "         1.5667e-02,  1.1340e-02,  1.0260e-02,  8.7930e-03,  9.6519e-03,\n",
      "         8.6680e-03,  6.3650e-03,  4.4141e-03,  6.4623e-03,  3.9292e-03,\n",
      "         4.1289e-03,  4.5623e-03,  5.1088e-03,  3.0521e-01,  4.9343e-03,\n",
      "         3.8957e-03,  3.7221e-03,  4.8902e-03,  3.7039e-03,  3.1826e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -72200, loss is 0.042264585511003386\n",
      "Action prob: [0.961812   0.03818801], Action: 0, state: 0\n",
      "Action prob: [0.96262634 0.03737366], Action: 0, state: 0\n",
      "Action prob: [0.96089756 0.03910238], Action: 0, state: 0\n",
      "Action prob: [0.95989555 0.04010448], Action: 0, state: 0\n",
      "Action prob: [0.96227366 0.03772634], Action: 1, state: 0\n",
      "Action prob: [0.9357397  0.06426033], Action: 0, state: 4\n",
      "Action prob: [0.96388876 0.03611124], Action: 0, state: 0\n",
      "Action prob: [0.96099037 0.03900961], Action: 0, state: 0\n",
      "Action prob: [0.9581859  0.04181414], Action: 0, state: 1\n",
      "Action prob: [0.96069556 0.0393045 ], Action: 1, state: 1\n",
      "Action prob: [0.9357397  0.06426033], Action: 0, state: 5\n",
      "Action prob: [0.9357397  0.06426033], Action: 0, state: 5\n",
      "Action prob: [0.9357397  0.06426033], Action: 0, state: 5\n",
      "Action prob: [0.9357397  0.06426033], Action: 0, state: 5\n",
      "Action prob: [0.9357397  0.06426033], Action: 0, state: 5\n",
      "Action prob: [0.9357397  0.06426033], Action: 0, state: 5\n",
      "Action prob: [0.9357397  0.06426033], Action: 0, state: 5\n",
      "Action prob: [0.9357397  0.06426033], Action: 0, state: 5\n",
      "Action prob: [0.9357397  0.06426033], Action: 0, state: 5\n",
      "Action prob: [0.9604665  0.03953352], Action: 0, state: 0\n",
      "Action prob: [0.9606381  0.03936186], Action: 0, state: 1\n",
      "Action prob: [0.9566078  0.04339216], Action: 0, state: 1\n",
      "Action prob: [0.9615988  0.03840116], Action: 0, state: 1\n",
      "Action prob: [0.9599383  0.04006173], Action: 0, state: 1\n",
      "Action prob: [0.96139777 0.03860227], Action: 0, state: 1\n",
      "Action prob: [0.9622016  0.03779844], Action: 0, state: 1\n",
      "Action prob: [0.95975095 0.04024909], Action: 0, state: 2\n",
      "Action prob: [0.96168023 0.03831978], Action: 1, state: 3\n",
      "Action prob: [0.9357397  0.06426033], Action: 0, state: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.96047777 0.03952223], Action: 0, state: 2\n",
      "Action prob: [0.96379673 0.03620333], Action: 0, state: 3\n",
      "Action prob: [0.9555456  0.04445435], Action: 0, state: 8\n",
      "Action prob: [0.9739328  0.02606723], Action: 0, state: 8\n",
      "Action prob: [0.9540229  0.04597706], Action: 0, state: 8\n",
      "Action prob: [0.97402734 0.02597259], Action: 0, state: 8\n",
      "Action prob: [0.9667045  0.03329551], Action: 0, state: 8\n",
      "Action prob: [0.97296053 0.02703947], Action: 0, state: 8\n",
      "Action prob: [0.95659137 0.04340867], Action: 0, state: 8\n",
      "Action prob: [0.9580106  0.04198937], Action: 0, state: 8\n",
      "Action prob: [0.9655267  0.03447334], Action: 0, state: 8\n",
      "Action prob: [0.95148104 0.04851899], Action: 0, state: 8\n",
      "Action prob: [0.95554674 0.0444533 ], Action: 0, state: 8\n",
      "Action prob: [0.95558363 0.04441639], Action: 0, state: 8\n",
      "Action prob: [0.9634658  0.03653415], Action: 0, state: 8\n",
      "Action prob: [0.96390337 0.03609662], Action: 0, state: 8\n",
      "Action prob: [0.96587414 0.03412586], Action: 0, state: 8\n",
      "Action prob: [0.9724448  0.02755523], Action: 0, state: 8\n",
      "Action prob: [0.965748   0.03425198], Action: 0, state: 8\n",
      "Action prob: [0.96708727 0.03291273], Action: 0, state: 8\n",
      "Action prob: [0.9572648  0.04273522], Action: 0, state: 8\n",
      "tensor([-0.1883, -0.1333, -0.0944, -0.0574, -1.9111, -0.0619, -0.0125,  0.0065,\n",
      "         0.0234,  2.8356,  0.0479,  0.0392,  0.0318,  0.0255,  0.0201,  0.0156,\n",
      "         0.0117,  0.0084,  0.0056,  0.0063,  0.0085,  0.0114,  0.0116,  0.0135,\n",
      "         0.0141,  0.0148,  0.0165,  1.3427,  0.0268,  0.0167,  0.0155,  0.0177,\n",
      "         0.0096,  0.0161,  0.0085,  0.0104,  0.0081,  0.0125,  0.0117,  0.0093,\n",
      "         0.0128,  0.0114,  0.0112,  0.0090,  0.0087,  0.0082,  0.0065,  0.0080,\n",
      "         0.0076,  0.0099], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -48700, loss is -0.04616337555350142\n",
      "Action prob: [0.9678049  0.03219511], Action: 0, state: 0\n",
      "Action prob: [0.96856254 0.03143738], Action: 0, state: 0\n",
      "Action prob: [0.96849144 0.03150855], Action: 0, state: 1\n",
      "Action prob: [0.96585435 0.03414573], Action: 0, state: 1\n",
      "Action prob: [0.96765643 0.03234349], Action: 0, state: 1\n",
      "Action prob: [0.967991   0.03200902], Action: 0, state: 2\n",
      "Action prob: [0.96707433 0.03292558], Action: 0, state: 2\n",
      "Action prob: [0.9663276  0.03367237], Action: 0, state: 2\n",
      "Action prob: [0.9664395  0.03356054], Action: 0, state: 2\n",
      "Action prob: [0.9675098  0.03249021], Action: 0, state: 2\n",
      "Action prob: [0.96710277 0.03289719], Action: 1, state: 3\n",
      "Action prob: [0.94107985 0.05892019], Action: 0, state: 7\n",
      "Action prob: [0.9671277  0.03287239], Action: 0, state: 2\n",
      "Action prob: [0.97661006 0.02338992], Action: 0, state: 3\n",
      "Action prob: [0.9771253  0.02287469], Action: 0, state: 8\n",
      "Action prob: [0.97011304 0.02988702], Action: 0, state: 8\n",
      "Action prob: [0.9720304  0.02796957], Action: 0, state: 8\n",
      "Action prob: [0.971931   0.02806905], Action: 0, state: 8\n",
      "Action prob: [0.9665173 0.0334826], Action: 0, state: 8\n",
      "Action prob: [0.9721406  0.02785943], Action: 0, state: 8\n",
      "Action prob: [0.9664226  0.03357743], Action: 0, state: 8\n",
      "Action prob: [0.97103935 0.02896059], Action: 0, state: 8\n",
      "Action prob: [0.96970594 0.03029409], Action: 0, state: 8\n",
      "Action prob: [0.97037536 0.02962464], Action: 0, state: 8\n",
      "Action prob: [0.97054124 0.02945882], Action: 0, state: 8\n",
      "Action prob: [0.970974   0.02902593], Action: 0, state: 8\n",
      "Action prob: [0.96125454 0.03874547], Action: 0, state: 8\n",
      "Action prob: [0.9646704  0.03532961], Action: 0, state: 8\n",
      "Action prob: [0.9607184 0.0392816], Action: 0, state: 8\n",
      "Action prob: [0.9596843  0.04031577], Action: 0, state: 8\n",
      "Action prob: [0.9671555  0.03284453], Action: 1, state: 8\n",
      "Action prob: [0.9645719  0.03542803], Action: 0, state: 8\n",
      "Action prob: [0.95990753 0.04009241], Action: 0, state: 8\n",
      "Action prob: [0.9675339  0.03246608], Action: 0, state: 8\n",
      "Action prob: [0.96217024 0.03782973], Action: 0, state: 8\n",
      "Action prob: [0.9687431 0.0312569], Action: 0, state: 8\n",
      "Action prob: [0.963384   0.03661601], Action: 0, state: 8\n",
      "Action prob: [0.961836   0.03816409], Action: 0, state: 8\n",
      "Action prob: [0.97123486 0.02876518], Action: 1, state: 8\n",
      "tensor([-9.8073e-02, -6.4141e-02, -4.0070e-02, -2.1143e-02, -2.0391e-03,\n",
      "         1.1417e-02,  2.3501e-02,  3.4262e-02,  4.2804e-02,  4.8536e-02,\n",
      "         5.4083e+00,  9.0279e-02,  5.4115e-02,  3.9983e-02,  3.0792e-02,\n",
      "         3.1125e-02,  2.1749e-02,  1.5556e-02,  1.2231e-02,  5.6514e-03,\n",
      "         2.2111e-03, -1.4765e-03, -4.5521e-03, -6.9482e-03, -9.0202e-03,\n",
      "        -1.0654e-02, -1.6308e-02, -1.6404e-02, -1.9754e-02, -2.1574e-02,\n",
      "        -1.8818e+00, -2.0688e-02, -2.4255e-02, -2.0104e-02, -2.4026e-02,\n",
      "        -2.0160e-02, -2.4057e-02, -2.5426e-02, -2.3445e+00],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -65000, loss is -0.029622258290293548\n",
      "Action prob: [0.97356886 0.02643111], Action: 0, state: 0\n",
      "Action prob: [0.97459793 0.02540206], Action: 0, state: 0\n",
      "Action prob: [0.9735618 0.0264382], Action: 0, state: 1\n",
      "Action prob: [0.97315264 0.02684738], Action: 0, state: 1\n",
      "Action prob: [0.9733849  0.02661501], Action: 0, state: 1\n",
      "Action prob: [0.97044927 0.02955071], Action: 0, state: 1\n",
      "Action prob: [0.9732281  0.02677194], Action: 0, state: 1\n",
      "Action prob: [0.9723308  0.02766918], Action: 0, state: 1\n",
      "Action prob: [0.97558695 0.02441299], Action: 0, state: 1\n",
      "Action prob: [0.9740704  0.02592961], Action: 0, state: 2\n",
      "Action prob: [0.9719925  0.02800757], Action: 0, state: 3\n",
      "Action prob: [0.97339547 0.02660455], Action: 0, state: 3\n",
      "Action prob: [0.97825307 0.02174699], Action: 0, state: 8\n",
      "Action prob: [0.96797276 0.03202726], Action: 0, state: 8\n",
      "Action prob: [0.9676279  0.03237216], Action: 0, state: 8\n",
      "Action prob: [0.97721374 0.0227863 ], Action: 0, state: 8\n",
      "Action prob: [0.97530633 0.02469361], Action: 0, state: 8\n",
      "Action prob: [0.9732599  0.02674008], Action: 0, state: 8\n",
      "Action prob: [0.9726733  0.02732671], Action: 0, state: 8\n",
      "Action prob: [0.9680312  0.03196885], Action: 1, state: 8\n",
      "Action prob: [0.96866256 0.03133744], Action: 0, state: 8\n",
      "Action prob: [0.97358614 0.02641387], Action: 1, state: 8\n",
      "Action prob: [0.98164326 0.01835677], Action: 0, state: 8\n",
      "Action prob: [0.9701379  0.02986202], Action: 0, state: 8\n",
      "Action prob: [0.9732919  0.02670817], Action: 0, state: 8\n",
      "Action prob: [0.9809178  0.01908217], Action: 0, state: 8\n",
      "Action prob: [0.9701657  0.02983427], Action: 0, state: 8\n",
      "Action prob: [0.97576195 0.0242381 ], Action: 0, state: 8\n",
      "Action prob: [0.96599746 0.03400248], Action: 0, state: 8\n",
      "Action prob: [0.97595584 0.02404413], Action: 0, state: 8\n",
      "Action prob: [0.96751046 0.03248947], Action: 0, state: 8\n",
      "Action prob: [0.9693787  0.03062122], Action: 0, state: 8\n",
      "Action prob: [0.9689987  0.03100136], Action: 0, state: 8\n",
      "Action prob: [0.9838256  0.01617439], Action: 0, state: 8\n",
      "Action prob: [0.98812664 0.0118734 ], Action: 0, state: 8\n",
      "Action prob: [0.9700837  0.02991624], Action: 0, state: 8\n",
      "Action prob: [0.98036444 0.01963553], Action: 0, state: 8\n",
      "Action prob: [0.9673935 0.0326065], Action: 0, state: 8\n",
      "Action prob: [0.967745   0.03225497], Action: 0, state: 8\n",
      "Action prob: [0.9667476  0.03325243], Action: 0, state: 8\n",
      "Action prob: [0.9646354  0.03536467], Action: 0, state: 8\n",
      "Action prob: [0.97113144 0.02886855], Action: 0, state: 8\n",
      "Action prob: [0.9819083  0.01809162], Action: 0, state: 8\n",
      "Action prob: [0.9687913  0.03120867], Action: 0, state: 8\n",
      "Action prob: [0.9822666  0.01773335], Action: 0, state: 8\n",
      "Action prob: [0.9675926  0.03240735], Action: 0, state: 8\n",
      "Action prob: [0.9685795  0.03142054], Action: 0, state: 8\n",
      "Action prob: [0.9807989  0.01920118], Action: 0, state: 8\n",
      "Action prob: [0.96757686 0.03242313], Action: 0, state: 8\n",
      "Action prob: [0.97594553 0.02405443], Action: 0, state: 8\n",
      "tensor([-5.6696e-02, -3.1044e-02, -1.3673e-02,  2.2172e-03,  1.5767e-02,\n",
      "         3.0357e-02,  3.7326e-02,  4.7262e-02,  4.8121e-02,  5.6362e-02,\n",
      "         6.3937e-02,  6.3106e-02,  4.1411e-02,  4.8667e-02,  3.8337e-02,\n",
      "         2.0385e-02,  1.6150e-02,  1.2012e-02,  7.5049e-03,  4.2831e-01,\n",
      "        -3.0831e-06, -3.8489e-01, -3.6289e-03, -8.2561e-03, -9.1315e-03,\n",
      "        -7.5631e-03, -1.3312e-02, -1.1763e-02, -1.7759e-02, -1.3195e-02,\n",
      "        -1.8717e-02, -1.8272e-02, -1.9060e-02, -1.0115e-02, -7.5617e-03,\n",
      "        -1.9559e-02, -1.2953e-02, -2.1914e-02, -2.1893e-02, -2.2773e-02,\n",
      "        -2.4420e-02, -1.9988e-02, -1.2521e-02, -2.1839e-02, -1.2369e-02,\n",
      "        -2.2845e-02, -2.2196e-02, -1.3510e-02, -2.3011e-02, -1.7026e-02],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -107900, loss is -0.0008753551933268419\n",
      "Action prob: [0.9782407  0.02175926], Action: 1, state: 0\n",
      "Action prob: [0.9432843  0.05671571], Action: 0, state: 4\n",
      "Action prob: [0.97747254 0.02252744], Action: 0, state: 0\n",
      "Action prob: [0.9768787  0.02312125], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.9766758  0.02332419], Action: 0, state: 0\n",
      "Action prob: [0.9788479  0.02115211], Action: 0, state: 1\n",
      "Action prob: [0.9778528  0.02214719], Action: 0, state: 1\n",
      "Action prob: [0.97765094 0.02234902], Action: 0, state: 2\n",
      "Action prob: [0.97754204 0.02245798], Action: 0, state: 2\n",
      "Action prob: [0.97793293 0.02206711], Action: 0, state: 3\n",
      "Action prob: [0.9754024  0.02459755], Action: 0, state: 9\n",
      "Action prob: [0.9817499  0.01825008], Action: 0, state: 9\n",
      "Action prob: [0.9749349 0.0250651], Action: 0, state: 9\n",
      "Action prob: [0.9805741  0.01942598], Action: 0, state: 9\n",
      "Action prob: [0.97628284 0.02371708], Action: 0, state: 9\n",
      "Action prob: [0.9847114  0.01528858], Action: 0, state: 9\n",
      "Action prob: [0.9742305 0.0257695], Action: 0, state: 9\n",
      "Action prob: [0.9852555  0.01474452], Action: 0, state: 9\n",
      "Action prob: [0.97812176 0.02187821], Action: 0, state: 9\n",
      "Action prob: [0.98546046 0.0145396 ], Action: 0, state: 9\n",
      "Action prob: [0.9740399  0.02596008], Action: 0, state: 9\n",
      "Action prob: [0.97146106 0.0285389 ], Action: 0, state: 9\n",
      "Action prob: [0.97097224 0.02902779], Action: 0, state: 9\n",
      "Action prob: [0.98505425 0.01494567], Action: 0, state: 9\n",
      "Action prob: [0.973078   0.02692191], Action: 0, state: 9\n",
      "Action prob: [0.9793824  0.02061759], Action: 0, state: 9\n",
      "Action prob: [0.98418057 0.01581948], Action: 0, state: 9\n",
      "Action prob: [0.9711363  0.02886373], Action: 0, state: 9\n",
      "Action prob: [0.9731305  0.02686946], Action: 0, state: 9\n",
      "Action prob: [0.97256887 0.02743112], Action: 0, state: 9\n",
      "Action prob: [0.9783795  0.02162049], Action: 0, state: 9\n",
      "Action prob: [0.97519696 0.02480303], Action: 0, state: 9\n",
      "Action prob: [0.97875273 0.02124725], Action: 0, state: 9\n",
      "Action prob: [0.9824625 0.0175375], Action: 0, state: 9\n",
      "Action prob: [0.9734613  0.02653871], Action: 0, state: 9\n",
      "Action prob: [0.9780984  0.02190159], Action: 0, state: 9\n",
      "Action prob: [0.9749547  0.02504528], Action: 0, state: 9\n",
      "Action prob: [0.9736692  0.02633076], Action: 0, state: 9\n",
      "Action prob: [0.9727436  0.02725646], Action: 0, state: 9\n",
      "Action prob: [0.97746915 0.02253081], Action: 0, state: 9\n",
      "Action prob: [0.97421455 0.02578546], Action: 0, state: 9\n",
      "Action prob: [0.9735603  0.02643972], Action: 0, state: 9\n",
      "Action prob: [0.98098356 0.01901646], Action: 0, state: 9\n",
      "Action prob: [0.9855656  0.01443439], Action: 0, state: 9\n",
      "Action prob: [0.9851977  0.01480232], Action: 0, state: 9\n",
      "Action prob: [0.9849439 0.015056 ], Action: 0, state: 9\n",
      "Action prob: [0.9844602  0.01553975], Action: 0, state: 9\n",
      "Action prob: [0.978233   0.02176704], Action: 0, state: 9\n",
      "Action prob: [0.98145354 0.01854647], Action: 0, state: 9\n",
      "Action prob: [0.9792228  0.02077723], Action: 0, state: 9\n",
      "tensor([-1.0920e+01, -2.1111e-01, -5.2841e-02, -2.8472e-02, -6.6175e-03,\n",
      "         9.3252e-03,  2.3410e-02,  3.4028e-02,  4.3081e-02,  4.6960e-02,\n",
      "         4.3614e-02,  2.6724e-02,  3.0351e-02,  1.9199e-02,  1.9065e-02,\n",
      "         9.8223e-03,  1.3166e-02,  5.8087e-03,  6.5209e-03,  3.1190e-03,\n",
      "         3.7719e-03,  2.4403e-03,  1.0025e-03, -1.3073e-04, -1.2278e-03,\n",
      "        -1.5802e-03, -1.6278e-03, -3.6428e-03, -3.9038e-03, -4.4347e-03,\n",
      "        -3.7842e-03, -4.6406e-03, -4.1806e-03, -3.5930e-03, -5.6543e-03,\n",
      "        -4.7899e-03, -5.6172e-03, -6.0265e-03, -6.3444e-03, -5.3041e-03,\n",
      "        -6.1508e-03, -6.3704e-03, -4.6019e-03, -3.5090e-03, -3.6201e-03,\n",
      "        -3.7008e-03, -3.8366e-03, -5.4100e-03, -4.6158e-03, -5.1899e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -34600, loss is 0.2198291434906584\n",
      "Action prob: [0.97744066 0.02255934], Action: 0, state: 0\n",
      "Action prob: [0.97401613 0.02598386], Action: 0, state: 1\n",
      "Action prob: [0.97486556 0.02513442], Action: 0, state: 1\n",
      "Action prob: [0.9750115  0.02498849], Action: 0, state: 2\n",
      "Action prob: [0.97690296 0.02309703], Action: 0, state: 2\n",
      "Action prob: [0.9753786  0.02462143], Action: 0, state: 2\n",
      "Action prob: [0.9787219  0.02127806], Action: 0, state: 3\n",
      "Action prob: [0.9755044 0.0244956], Action: 0, state: 3\n",
      "Action prob: [0.974912   0.02508798], Action: 0, state: 3\n",
      "Action prob: [0.9755853  0.02441475], Action: 0, state: 3\n",
      "Action prob: [0.97552186 0.02447814], Action: 0, state: 3\n",
      "Action prob: [0.9739942  0.02600577], Action: 0, state: 3\n",
      "Action prob: [0.9743669  0.02563312], Action: 0, state: 8\n",
      "Action prob: [0.97973514 0.02026483], Action: 0, state: 8\n",
      "Action prob: [0.97777987 0.02222015], Action: 0, state: 8\n",
      "Action prob: [0.9708515  0.02914855], Action: 0, state: 8\n",
      "Action prob: [0.97740084 0.02259919], Action: 0, state: 8\n",
      "Action prob: [0.97688884 0.02311115], Action: 0, state: 8\n",
      "Action prob: [0.97611135 0.02388865], Action: 0, state: 8\n",
      "Action prob: [0.9692151  0.03078488], Action: 0, state: 8\n",
      "Action prob: [0.97733945 0.0226606 ], Action: 1, state: 8\n",
      "Action prob: [0.9683705 0.0316295], Action: 0, state: 8\n",
      "Action prob: [0.9760908  0.02390919], Action: 0, state: 8\n",
      "Action prob: [0.97338325 0.02661673], Action: 0, state: 8\n",
      "Action prob: [0.97775686 0.02224323], Action: 0, state: 8\n",
      "Action prob: [0.9752187  0.02478133], Action: 0, state: 8\n",
      "Action prob: [0.97175467 0.02824528], Action: 0, state: 8\n",
      "Action prob: [0.9690062 0.0309938], Action: 0, state: 8\n",
      "Action prob: [0.98347133 0.01652864], Action: 0, state: 8\n",
      "Action prob: [0.97325665 0.02674331], Action: 0, state: 8\n",
      "Action prob: [0.9728468  0.02715318], Action: 0, state: 8\n",
      "Action prob: [0.9734933  0.02650674], Action: 0, state: 8\n",
      "Action prob: [0.9779547  0.02204525], Action: 0, state: 8\n",
      "Action prob: [0.97793293 0.02206704], Action: 0, state: 8\n",
      "Action prob: [0.9780116  0.02198836], Action: 0, state: 8\n",
      "Action prob: [0.9631176  0.03688238], Action: 0, state: 8\n",
      "Action prob: [0.9816523  0.01834771], Action: 0, state: 8\n",
      "Action prob: [0.9717219  0.02827806], Action: 0, state: 8\n",
      "Action prob: [0.98133713 0.01866293], Action: 0, state: 8\n",
      "Action prob: [0.9846942  0.01530581], Action: 0, state: 8\n",
      "Action prob: [0.970022   0.02997792], Action: 0, state: 8\n",
      "Action prob: [0.9772817  0.02271827], Action: 0, state: 8\n",
      "Action prob: [0.9776912  0.02230881], Action: 0, state: 8\n",
      "Action prob: [0.9696498  0.03035018], Action: 0, state: 8\n",
      "Action prob: [0.9823531  0.01764686], Action: 0, state: 8\n",
      "Action prob: [0.9778985  0.02210147], Action: 0, state: 8\n",
      "Action prob: [0.98261213 0.01738781], Action: 0, state: 8\n",
      "Action prob: [0.9716662  0.02833381], Action: 1, state: 8\n",
      "tensor([-3.3558e-02, -1.7361e-02,  7.6703e-04,  1.3947e-02,  2.3228e-02,\n",
      "         3.4164e-02,  3.3776e-02,  4.3162e-02,  4.7891e-02,  4.9625e-02,\n",
      "         5.2343e-02,  5.7991e-02,  4.5398e-02,  2.7917e-02,  2.3295e-02,\n",
      "         2.2445e-02,  1.1944e-02,  7.5232e-03,  3.6528e-03,  1.8783e-04,\n",
      "        -4.4424e-01, -7.1389e-03, -7.5311e-03, -1.0438e-02, -1.0152e-02,\n",
      "        -1.2698e-02, -1.5831e-02, -1.8640e-02, -1.0428e-02, -1.7734e-02,\n",
      "        -1.8678e-02, -1.8781e-02, -1.5976e-02, -1.6324e-02, -1.6547e-02,\n",
      "        -2.8373e-02, -1.4151e-02, -2.2144e-02, -1.4668e-02, -1.2095e-02,\n",
      "        -2.4014e-02, -1.8224e-02, -1.7970e-02, -2.4638e-02, -1.4278e-02,\n",
      "        -1.7970e-02, -1.4135e-02, -2.8772e+00], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for this episode -99800, loss is 0.06859767895385022\n",
      "Action prob: [0.9711547 0.0288453], Action: 0, state: 0\n",
      "Action prob: [0.97019064 0.02980933], Action: 0, state: 0\n",
      "Action prob: [0.96990013 0.03009989], Action: 0, state: 0\n",
      "Action prob: [0.9703949  0.02960507], Action: 0, state: 0\n",
      "Action prob: [0.97179145 0.02820847], Action: 0, state: 0\n",
      "Action prob: [0.97122866 0.02877137], Action: 0, state: 0\n",
      "Action prob: [0.96914804 0.03085201], Action: 0, state: 0\n",
      "Action prob: [0.9707802 0.0292198], Action: 0, state: 0\n",
      "Action prob: [0.97221315 0.02778684], Action: 0, state: 9\n",
      "Action prob: [0.9729585  0.02704154], Action: 0, state: 9\n",
      "Action prob: [0.9738762  0.02612384], Action: 0, state: 9\n",
      "Action prob: [0.9657557  0.03424431], Action: 0, state: 9\n",
      "Action prob: [0.9718445  0.02815553], Action: 0, state: 9\n",
      "Action prob: [0.9642825  0.03571748], Action: 0, state: 9\n",
      "Action prob: [0.9655086  0.03449139], Action: 0, state: 9\n",
      "Action prob: [0.9677136  0.03228634], Action: 0, state: 9\n",
      "Action prob: [0.9729321  0.02706792], Action: 0, state: 9\n",
      "Action prob: [0.963809   0.03619101], Action: 0, state: 9\n",
      "Action prob: [0.97185653 0.02814347], Action: 0, state: 9\n",
      "Action prob: [0.9791708  0.02082926], Action: 0, state: 9\n",
      "Action prob: [0.97274315 0.02725682], Action: 0, state: 9\n",
      "Action prob: [0.975138   0.02486203], Action: 0, state: 9\n",
      "Action prob: [0.96683806 0.03316192], Action: 0, state: 9\n",
      "Action prob: [0.969986   0.03001402], Action: 0, state: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.9677618  0.03223811], Action: 0, state: 9\n",
      "Action prob: [0.97469306 0.02530694], Action: 0, state: 9\n",
      "Action prob: [0.9750866  0.02491335], Action: 0, state: 9\n",
      "Action prob: [0.971503   0.02849695], Action: 0, state: 9\n",
      "Action prob: [0.97998214 0.02001785], Action: 0, state: 9\n",
      "Action prob: [0.9657597  0.03424032], Action: 0, state: 9\n",
      "Action prob: [0.98102826 0.01897167], Action: 0, state: 9\n",
      "Action prob: [0.97434694 0.025653  ], Action: 0, state: 9\n",
      "Action prob: [0.9631613  0.03683867], Action: 0, state: 9\n",
      "Action prob: [0.96409565 0.03590437], Action: 0, state: 9\n",
      "Action prob: [0.9713698  0.02863021], Action: 0, state: 9\n",
      "Action prob: [0.9715649  0.02843504], Action: 0, state: 9\n",
      "Action prob: [0.9752417  0.02475832], Action: 0, state: 9\n",
      "Action prob: [0.97093606 0.02906395], Action: 0, state: 9\n",
      "Action prob: [0.9669485  0.03305152], Action: 0, state: 9\n",
      "Action prob: [0.9700013  0.02999869], Action: 1, state: 9\n",
      "Action prob: [0.96704936 0.03295061], Action: 0, state: 9\n",
      "Action prob: [0.9685957  0.03140435], Action: 0, state: 9\n",
      "Action prob: [0.973431   0.02656895], Action: 0, state: 9\n",
      "Action prob: [0.97238255 0.02761752], Action: 0, state: 9\n",
      "Action prob: [0.964311   0.03568901], Action: 0, state: 9\n",
      "Action prob: [0.9722005  0.02779946], Action: 0, state: 9\n",
      "Action prob: [0.9676934  0.03230656], Action: 0, state: 9\n",
      "Action prob: [0.9700085  0.02999149], Action: 0, state: 9\n",
      "Action prob: [0.979932   0.02006793], Action: 0, state: 9\n",
      "Action prob: [0.9737432  0.02625672], Action: 0, state: 9\n",
      "tensor([-1.0841e-01, -7.0130e-02, -3.4808e-02, -4.1240e-03,  2.0436e-02,\n",
      "         4.1978e-02,  6.4340e-02,  7.6391e-02,  6.0067e-02,  4.8077e-02,\n",
      "         3.7923e-02,  4.0408e-02,  2.6494e-02,  2.6567e-02,  1.9755e-02,\n",
      "         1.3795e-02,  8.2114e-03,  7.2358e-03,  3.1057e-03,  7.2440e-04,\n",
      "        -7.9604e-04, -2.0781e-03, -4.3241e-03, -5.0904e-03, -6.5553e-03,\n",
      "        -5.8467e-03, -6.3562e-03, -7.8697e-03, -5.8526e-03, -1.0594e-02,\n",
      "        -6.0627e-03, -8.5007e-03, -1.2615e-02, -1.2569e-02, -1.0174e-02,\n",
      "        -1.0263e-02, -9.0365e-03, -1.0749e-02, -1.2363e-02, -1.3000e+00,\n",
      "        -1.2503e-02, -1.1973e-02, -1.0153e-02, -1.0601e-02, -1.3803e-02,\n",
      "        -1.0739e-02, -1.2539e-02, -1.1650e-02, -7.7697e-03, -1.0213e-02],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -36000, loss is 0.02563112778049134\n",
      "Action prob: [0.96685296 0.03314695], Action: 0, state: 0\n",
      "Action prob: [0.9652677  0.03473223], Action: 0, state: 0\n",
      "Action prob: [0.96494585 0.03505421], Action: 0, state: 0\n",
      "Action prob: [0.9658431  0.03415688], Action: 0, state: 0\n",
      "Action prob: [0.9668578  0.03314225], Action: 0, state: 1\n",
      "Action prob: [0.96546715 0.0345329 ], Action: 0, state: 1\n",
      "Action prob: [0.9651091  0.03489081], Action: 0, state: 1\n",
      "Action prob: [0.9666717  0.03332834], Action: 0, state: 1\n",
      "Action prob: [0.9639364  0.03606358], Action: 0, state: 1\n",
      "Action prob: [0.96414584 0.03585416], Action: 0, state: 1\n",
      "Action prob: [0.9663549  0.03364506], Action: 0, state: 2\n",
      "Action prob: [0.9645984  0.03540155], Action: 0, state: 2\n",
      "Action prob: [0.9658084  0.03419161], Action: 0, state: 2\n",
      "Action prob: [0.96560436 0.03439558], Action: 0, state: 3\n",
      "Action prob: [0.9612334  0.03876662], Action: 0, state: 8\n",
      "Action prob: [0.96455204 0.03544793], Action: 0, state: 8\n",
      "Action prob: [0.98223025 0.01776973], Action: 0, state: 8\n",
      "Action prob: [0.96810484 0.03189518], Action: 0, state: 8\n",
      "Action prob: [0.96193135 0.03806859], Action: 0, state: 8\n",
      "Action prob: [0.9760393  0.02396069], Action: 0, state: 8\n",
      "Action prob: [0.9573157  0.04268426], Action: 0, state: 8\n",
      "Action prob: [0.9606974  0.03930261], Action: 0, state: 8\n",
      "Action prob: [0.9601689  0.03983108], Action: 0, state: 8\n",
      "Action prob: [0.9604507  0.03954934], Action: 0, state: 8\n",
      "Action prob: [0.97253585 0.02746414], Action: 0, state: 8\n",
      "Action prob: [0.9648051  0.03519491], Action: 0, state: 8\n",
      "Action prob: [0.9743284  0.02567158], Action: 0, state: 8\n",
      "Action prob: [0.9717668  0.02823315], Action: 0, state: 8\n",
      "Action prob: [0.9665282  0.03347185], Action: 0, state: 8\n",
      "Action prob: [0.96422166 0.03577833], Action: 0, state: 8\n",
      "Action prob: [0.9689005  0.03109952], Action: 0, state: 8\n",
      "Action prob: [0.9611267  0.03887329], Action: 0, state: 8\n",
      "Action prob: [0.9606456  0.03935443], Action: 0, state: 8\n",
      "Action prob: [0.9755897  0.02441035], Action: 0, state: 8\n",
      "Action prob: [0.9609489  0.03905112], Action: 0, state: 8\n",
      "Action prob: [0.969403   0.03059691], Action: 0, state: 8\n",
      "Action prob: [0.9753879  0.02461215], Action: 0, state: 8\n",
      "Action prob: [0.9594163  0.04058376], Action: 0, state: 8\n",
      "Action prob: [0.95952415 0.04047588], Action: 0, state: 8\n",
      "Action prob: [0.9670313 0.0329687], Action: 0, state: 8\n",
      "Action prob: [0.96822095 0.03177912], Action: 0, state: 8\n",
      "Action prob: [0.9697474  0.03025259], Action: 0, state: 8\n",
      "Action prob: [0.96169615 0.03830387], Action: 0, state: 8\n",
      "Action prob: [0.9601204  0.03987962], Action: 0, state: 8\n",
      "Action prob: [0.95893437 0.04106561], Action: 0, state: 8\n",
      "Action prob: [0.9677137  0.03228628], Action: 0, state: 8\n",
      "Action prob: [0.97473824 0.02526176], Action: 0, state: 8\n",
      "Action prob: [0.9649393  0.03506068], Action: 0, state: 8\n",
      "Action prob: [0.9598319  0.04016814], Action: 0, state: 8\n",
      "Action prob: [0.9599698  0.04003013], Action: 0, state: 8\n",
      "tensor([-0.1173, -0.0874, -0.0576, -0.0308, -0.0111,  0.0051,  0.0195,  0.0302,\n",
      "         0.0434,  0.0522,  0.0553,  0.0639,  0.0664,  0.0693,  0.0639,  0.0471,\n",
      "         0.0186,  0.0264,  0.0242,  0.0112,  0.0141,  0.0083,  0.0044,  0.0009,\n",
      "        -0.0014, -0.0040, -0.0042, -0.0059, -0.0083, -0.0101, -0.0096, -0.0130,\n",
      "        -0.0139, -0.0090, -0.0150, -0.0121, -0.0100, -0.0169, -0.0172, -0.0141,\n",
      "        -0.0138, -0.0133, -0.0170, -0.0179, -0.0185, -0.0146, -0.0114, -0.0160,\n",
      "        -0.0184, -0.0184], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -99700, loss is 7.150997441437442e-05\n",
      "Action prob: [0.9610738  0.03892614], Action: 0, state: 0\n",
      "Action prob: [0.9599921  0.04000783], Action: 0, state: 0\n",
      "Action prob: [0.96005017 0.03994986], Action: 0, state: 0\n",
      "Action prob: [0.9597597  0.04024027], Action: 0, state: 0\n",
      "Action prob: [0.96087843 0.03912158], Action: 0, state: 1\n",
      "Action prob: [0.9597082  0.04029181], Action: 0, state: 1\n",
      "Action prob: [0.9591193  0.04088075], Action: 0, state: 1\n",
      "Action prob: [0.9605323  0.03946775], Action: 0, state: 2\n",
      "Action prob: [0.960045   0.03995503], Action: 0, state: 2\n",
      "Action prob: [0.9592295  0.04077044], Action: 0, state: 2\n",
      "Action prob: [0.9608585  0.03914151], Action: 0, state: 2\n",
      "Action prob: [0.96193576 0.03806424], Action: 0, state: 2\n",
      "Action prob: [0.95857394 0.04142607], Action: 0, state: 2\n",
      "Action prob: [0.9584445  0.04155547], Action: 0, state: 3\n",
      "Action prob: [0.95455885 0.04544117], Action: 0, state: 8\n",
      "Action prob: [0.9545012  0.04549878], Action: 0, state: 8\n",
      "Action prob: [0.9546902  0.04530983], Action: 0, state: 8\n",
      "Action prob: [0.95366436 0.0463356 ], Action: 0, state: 8\n",
      "Action prob: [0.9615834  0.03841663], Action: 0, state: 8\n",
      "Action prob: [0.95559824 0.0444018 ], Action: 0, state: 8\n",
      "Action prob: [0.9601724  0.03982752], Action: 0, state: 8\n",
      "Action prob: [0.9524493 0.0475507], Action: 1, state: 8\n",
      "Action prob: [0.9557346  0.04426542], Action: 0, state: 8\n",
      "Action prob: [0.9555988  0.04440124], Action: 0, state: 8\n",
      "Action prob: [0.9712504  0.02874963], Action: 0, state: 8\n",
      "Action prob: [0.95411474 0.0458853 ], Action: 0, state: 8\n",
      "Action prob: [0.96008587 0.03991416], Action: 0, state: 8\n",
      "Action prob: [0.97077864 0.02922139], Action: 0, state: 8\n",
      "Action prob: [0.96371377 0.03628621], Action: 0, state: 8\n",
      "Action prob: [0.9656644  0.03433556], Action: 0, state: 8\n",
      "Action prob: [0.97691286 0.02308717], Action: 0, state: 8\n",
      "Action prob: [0.9633561  0.03664396], Action: 0, state: 8\n",
      "Action prob: [0.9714109  0.02858912], Action: 0, state: 8\n",
      "Action prob: [0.95657337 0.04342663], Action: 1, state: 8\n",
      "tensor([-1.2577e-01, -9.3166e-02, -6.2326e-02, -3.6497e-02, -1.5920e-02,\n",
      "         7.1172e-04,  1.5490e-02,  2.5708e-02,  3.5296e-02,  4.4071e-02,\n",
      "         4.8829e-02,  5.2874e-02,  6.2662e-02,  6.5537e-02,  5.6864e-02,\n",
      "         4.4219e-02,  3.3265e-02,  2.4673e-02,  1.3801e-02,  9.5248e-03,\n",
      "         3.5976e-03, -4.4170e-02, -4.6211e-03, -8.0161e-03, -6.9942e-03,\n",
      "        -1.3788e-02, -1.3819e-02, -1.1213e-02, -1.5196e-02, -1.5345e-02,\n",
      "        -1.0816e-02, -1.8044e-02, -1.4520e-02, -1.6161e+00],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -48000, loss is 0.046742331889626294\n",
      "Action prob: [0.9516191  0.04838087], Action: 0, state: 0\n",
      "Action prob: [0.95291936 0.04708064], Action: 0, state: 1\n",
      "Action prob: [0.9525867  0.04741332], Action: 0, state: 1\n",
      "Action prob: [0.954414 0.045586], Action: 0, state: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.95394135 0.04605868], Action: 0, state: 3\n",
      "Action prob: [0.9465139  0.05348609], Action: 0, state: 8\n",
      "Action prob: [0.95521    0.04478999], Action: 0, state: 8\n",
      "Action prob: [0.9467365  0.05326345], Action: 0, state: 8\n",
      "Action prob: [0.965136   0.03486394], Action: 0, state: 8\n",
      "Action prob: [0.9461254  0.05387465], Action: 0, state: 8\n",
      "Action prob: [0.9662207  0.03377932], Action: 0, state: 8\n",
      "Action prob: [0.96225005 0.03774998], Action: 0, state: 8\n",
      "Action prob: [0.9549443  0.04505569], Action: 0, state: 8\n",
      "Action prob: [0.9510654  0.04893464], Action: 0, state: 8\n",
      "Action prob: [0.9484397 0.0515603], Action: 0, state: 8\n",
      "Action prob: [0.94967073 0.05032929], Action: 0, state: 8\n",
      "Action prob: [0.9635038  0.03649618], Action: 0, state: 8\n",
      "Action prob: [0.9498852  0.05011485], Action: 0, state: 8\n",
      "Action prob: [0.9473354  0.05266454], Action: 0, state: 8\n",
      "Action prob: [0.96382165 0.03617833], Action: 1, state: 8\n",
      "Action prob: [0.95471454 0.04528543], Action: 0, state: 0\n",
      "tensor([ 4.5428e-02,  5.7237e-02,  6.8833e-02,  7.4232e-02,  7.9376e-02,\n",
      "         6.6632e-02,  3.7192e-02,  2.5790e-02,  6.4511e-03, -3.5547e-03,\n",
      "        -9.3903e-03, -1.7354e-02, -2.7756e-02, -3.6648e-02, -4.4445e-02,\n",
      "        -4.8147e-02, -3.7596e-02, -5.5437e-02, -6.1417e-02, -3.9289e+00,\n",
      "        -5.4217e-02], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -39900, loss is 0.1839830356503405\n",
      "Action prob: [0.93623006 0.06376996], Action: 0, state: 0\n",
      "Action prob: [0.9374421  0.06255789], Action: 0, state: 0\n",
      "Action prob: [0.9364076  0.06359245], Action: 0, state: 0\n",
      "Action prob: [0.9357002  0.06429989], Action: 0, state: 0\n",
      "Action prob: [0.9370223  0.06297774], Action: 0, state: 0\n",
      "Action prob: [0.9388177  0.06118238], Action: 0, state: 0\n",
      "Action prob: [0.9340465  0.06595354], Action: 0, state: 1\n",
      "Action prob: [0.9546646  0.04533539], Action: 0, state: 1\n",
      "Action prob: [0.9338443  0.06615566], Action: 1, state: 2\n",
      "Action prob: [0.97717834 0.02282165], Action: 0, state: 6\n",
      "Action prob: [0.97717834 0.02282165], Action: 0, state: 6\n",
      "Action prob: [0.97717834 0.02282165], Action: 0, state: 6\n",
      "Action prob: [0.93583846 0.06416157], Action: 0, state: 1\n",
      "Action prob: [0.9344088  0.06559123], Action: 0, state: 1\n",
      "Action prob: [0.9371116  0.06288839], Action: 0, state: 2\n",
      "Action prob: [0.93769133 0.06230866], Action: 0, state: 3\n",
      "Action prob: [0.93192196 0.06807798], Action: 0, state: 3\n",
      "Action prob: [0.9369522  0.06304774], Action: 0, state: 3\n",
      "Action prob: [0.93642884 0.06357123], Action: 0, state: 3\n",
      "Action prob: [0.9374987  0.06250134], Action: 0, state: 8\n",
      "Action prob: [0.95193195 0.04806808], Action: 0, state: 8\n",
      "Action prob: [0.9304036  0.06959637], Action: 0, state: 8\n",
      "Action prob: [0.9321482  0.06785177], Action: 0, state: 8\n",
      "Action prob: [0.932915   0.06708504], Action: 0, state: 8\n",
      "Action prob: [0.9461529  0.05384707], Action: 0, state: 8\n",
      "Action prob: [0.93740034 0.06259973], Action: 0, state: 8\n",
      "Action prob: [0.94716644 0.05283353], Action: 0, state: 8\n",
      "Action prob: [0.9403667  0.05963327], Action: 0, state: 8\n",
      "Action prob: [0.9311762  0.06882383], Action: 0, state: 8\n",
      "Action prob: [0.92788035 0.07211969], Action: 0, state: 8\n",
      "Action prob: [0.93108296 0.06891701], Action: 0, state: 8\n",
      "Action prob: [0.9321205  0.06787956], Action: 1, state: 8\n",
      "Action prob: [0.932446   0.06755397], Action: 0, state: 8\n",
      "Action prob: [0.92967707 0.07032294], Action: 0, state: 8\n",
      "Action prob: [0.94802064 0.05197933], Action: 0, state: 8\n",
      "Action prob: [0.93898714 0.06101284], Action: 0, state: 8\n",
      "Action prob: [0.9300008  0.06999918], Action: 0, state: 8\n",
      "Action prob: [0.9324732  0.06752679], Action: 0, state: 8\n",
      "Action prob: [0.93028516 0.06971483], Action: 1, state: 8\n",
      "Action prob: [0.94979805 0.05020197], Action: 0, state: 8\n",
      "Action prob: [0.9310309  0.06896906], Action: 0, state: 8\n",
      "Action prob: [0.9321837  0.06781638], Action: 0, state: 8\n",
      "Action prob: [0.93157744 0.06842254], Action: 0, state: 8\n",
      "Action prob: [0.94013107 0.05986891], Action: 0, state: 8\n",
      "Action prob: [0.94385207 0.05614796], Action: 0, state: 8\n",
      "Action prob: [0.9477907  0.05220938], Action: 0, state: 8\n",
      "Action prob: [0.9289927  0.07100733], Action: 0, state: 8\n",
      "Action prob: [0.9519491  0.04805087], Action: 0, state: 8\n",
      "Action prob: [0.9347504  0.06524955], Action: 0, state: 8\n",
      "Action prob: [0.9306417  0.06935827], Action: 0, state: 8\n",
      "tensor([-2.9200e-01, -2.1347e-01, -1.5418e-01, -1.0185e-01, -5.4665e-02,\n",
      "        -1.5917e-02,  1.3502e-02,  2.6928e-02,  2.3611e+00,  1.6527e-02,\n",
      "         1.3514e-02,  1.0953e-02,  4.2716e-02,  5.3488e-02,  5.8291e-02,\n",
      "         6.1461e-02,  7.0828e-02,  6.8144e-02,  7.1065e-02,  5.8124e-02,\n",
      "         3.6771e-02,  4.4393e-02,  3.5414e-02,  2.8425e-02,  1.8203e-02,\n",
      "         1.6838e-02,  1.0982e-02,  9.4016e-03,  7.9080e-03,  5.6286e-03,\n",
      "         3.2023e-03,  5.1239e-02, -2.0145e-04, -1.5691e-03, -1.9943e-03,\n",
      "        -3.1998e-03, -4.5193e-03, -5.0342e-03, -2.1380e-01, -4.4967e-03,\n",
      "        -6.6660e-03, -6.9072e-03, -7.2772e-03, -6.5653e-03, -6.3255e-03,\n",
      "        -6.0118e-03, -8.4238e-03, -5.7263e-03, -7.9562e-03, -8.5751e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -85300, loss is -0.04115451758645289\n",
      "Action prob: [0.9267021  0.07329794], Action: 0, state: 0\n",
      "Action prob: [0.923471   0.07652901], Action: 0, state: 1\n",
      "Action prob: [0.9209265  0.07907355], Action: 0, state: 1\n",
      "Action prob: [0.9237076  0.07629241], Action: 0, state: 1\n",
      "Action prob: [0.91979593 0.08020401], Action: 0, state: 1\n",
      "Action prob: [0.9224207  0.07757931], Action: 0, state: 1\n",
      "Action prob: [0.92338324 0.07661673], Action: 0, state: 1\n",
      "Action prob: [0.91972256 0.0802775 ], Action: 0, state: 1\n",
      "Action prob: [0.9232466  0.07675335], Action: 0, state: 1\n",
      "Action prob: [0.92180055 0.07819949], Action: 0, state: 1\n",
      "Action prob: [0.92066056 0.07933944], Action: 0, state: 2\n",
      "Action prob: [0.922582   0.07741805], Action: 0, state: 2\n",
      "Action prob: [0.92074555 0.07925447], Action: 0, state: 2\n",
      "Action prob: [0.9235996  0.07640044], Action: 0, state: 2\n",
      "Action prob: [0.9224084  0.07759158], Action: 0, state: 3\n",
      "Action prob: [0.91688514 0.08311482], Action: 0, state: 3\n",
      "Action prob: [0.9238593  0.07614071], Action: 0, state: 3\n",
      "Action prob: [0.9335859  0.06641416], Action: 0, state: 8\n",
      "Action prob: [0.91628724 0.08371269], Action: 0, state: 8\n",
      "Action prob: [0.92090285 0.07909712], Action: 0, state: 8\n",
      "Action prob: [0.9216388  0.07836121], Action: 0, state: 8\n",
      "Action prob: [0.92543536 0.07456459], Action: 0, state: 8\n",
      "Action prob: [0.91455275 0.08544724], Action: 0, state: 8\n",
      "Action prob: [0.9172915  0.08270852], Action: 0, state: 8\n",
      "Action prob: [0.91566104 0.08433894], Action: 0, state: 8\n",
      "Action prob: [0.9331477  0.06685226], Action: 0, state: 8\n",
      "Action prob: [0.9129294  0.08707064], Action: 0, state: 8\n",
      "Action prob: [0.9353746  0.06462532], Action: 0, state: 8\n",
      "Action prob: [0.9187193  0.08128069], Action: 0, state: 8\n",
      "Action prob: [0.92380923 0.07619075], Action: 1, state: 8\n",
      "Action prob: [0.91659224 0.08340774], Action: 1, state: 8\n",
      "tensor([-0.2443, -0.1987, -0.1557, -0.1091, -0.0784, -0.0456, -0.0198,  0.0017,\n",
      "         0.0198,  0.0361,  0.0487,  0.0576,  0.0677,  0.0724,  0.0774,  0.0867,\n",
      "         0.0819,  0.0589,  0.0618,  0.0478,  0.0385,  0.0294,  0.0269,  0.0202,\n",
      "         0.0157,  0.0090,  0.0081,  0.0036,  0.0021, -0.0010, -0.0539],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -28200, loss is 0.0011156766330027831\n",
      "Action prob: [0.9026798  0.09732021], Action: 0, state: 0\n",
      "Action prob: [0.9042345  0.09576549], Action: 0, state: 0\n",
      "Action prob: [0.90558815 0.0944118 ], Action: 0, state: 0\n",
      "Action prob: [0.9065597  0.09344035], Action: 0, state: 0\n",
      "Action prob: [0.90650797 0.09349209], Action: 0, state: 0\n",
      "Action prob: [0.9093219  0.09067815], Action: 0, state: 0\n",
      "Action prob: [0.90646595 0.09353401], Action: 0, state: 1\n",
      "Action prob: [0.90741277 0.09258721], Action: 0, state: 2\n",
      "Action prob: [0.90770626 0.09229374], Action: 0, state: 2\n",
      "Action prob: [0.90237075 0.09762923], Action: 0, state: 3\n",
      "Action prob: [0.91787696 0.08212301], Action: 0, state: 8\n",
      "Action prob: [0.90134513 0.09865486], Action: 0, state: 8\n",
      "Action prob: [0.9003925  0.09960751], Action: 0, state: 8\n",
      "Action prob: [0.8992927  0.10070731], Action: 0, state: 8\n",
      "Action prob: [0.9019134  0.09808667], Action: 0, state: 8\n",
      "Action prob: [0.9088677  0.09113235], Action: 0, state: 8\n",
      "Action prob: [0.9016205  0.09837952], Action: 0, state: 8\n",
      "Action prob: [0.90878177 0.09121829], Action: 0, state: 8\n",
      "Action prob: [0.9081524  0.09184758], Action: 0, state: 8\n",
      "Action prob: [0.90199506 0.09800497], Action: 0, state: 8\n",
      "Action prob: [0.91342217 0.08657779], Action: 1, state: 8\n",
      "tensor([-1.9296e-01, -1.1598e-01, -5.2514e-02, -3.1519e-05,  4.4121e-02,\n",
      "         7.9073e-02,  1.1041e-01,  1.3071e-01,  1.4847e-01,  1.6776e-01,\n",
      "         9.6322e-02,  7.1817e-02,  3.3966e-02,  1.1837e-03, -2.6276e-02,\n",
      "        -4.5900e-02, -6.9625e-02, -7.9912e-02, -9.3853e-02, -1.1264e-01,\n",
      "        -2.9170e+00], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -24000, loss is 0.13442404378952227\n",
      "Action prob: [0.88454825 0.11545175], Action: 0, state: 0\n",
      "Action prob: [0.88365567 0.11634428], Action: 0, state: 0\n",
      "Action prob: [0.8814184  0.11858157], Action: 0, state: 0\n",
      "Action prob: [0.88594264 0.11405732], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.8815557  0.11844429], Action: 0, state: 1\n",
      "Action prob: [0.88529253 0.11470743], Action: 0, state: 2\n",
      "Action prob: [0.8833942  0.11660578], Action: 0, state: 3\n",
      "Action prob: [0.88047945 0.11952052], Action: 1, state: 3\n",
      "Action prob: [0.9826765  0.01732352], Action: 0, state: 7\n",
      "Action prob: [0.8850323  0.11496772], Action: 1, state: 2\n",
      "Action prob: [0.9826765  0.01732352], Action: 0, state: 6\n",
      "Action prob: [0.9826765  0.01732352], Action: 0, state: 6\n",
      "Action prob: [0.88287383 0.11712614], Action: 0, state: 1\n",
      "Action prob: [0.87814385 0.12185612], Action: 1, state: 2\n",
      "Action prob: [0.9826765  0.01732352], Action: 0, state: 6\n",
      "Action prob: [0.8808223  0.11917774], Action: 0, state: 1\n",
      "Action prob: [0.8842404  0.11575962], Action: 0, state: 1\n",
      "Action prob: [0.88080627 0.11919373], Action: 0, state: 2\n",
      "Action prob: [0.8823742  0.11762577], Action: 0, state: 3\n",
      "Action prob: [0.8837409  0.11625909], Action: 0, state: 3\n",
      "Action prob: [0.884165 0.115835], Action: 0, state: 3\n",
      "Action prob: [0.897698   0.10230204], Action: 0, state: 3\n",
      "Action prob: [0.8831844  0.11681566], Action: 0, state: 3\n",
      "Action prob: [0.88343877 0.11656125], Action: 0, state: 3\n",
      "Action prob: [0.884823   0.11517701], Action: 0, state: 3\n",
      "Action prob: [0.87860113 0.12139878], Action: 0, state: 8\n",
      "Action prob: [0.8660055  0.13399455], Action: 0, state: 8\n",
      "Action prob: [0.8780027 0.1219973], Action: 0, state: 8\n",
      "Action prob: [0.89528966 0.1047103 ], Action: 0, state: 8\n",
      "Action prob: [0.87704545 0.1229546 ], Action: 0, state: 8\n",
      "Action prob: [0.8781797  0.12182023], Action: 0, state: 8\n",
      "Action prob: [0.8890121  0.11098787], Action: 0, state: 8\n",
      "Action prob: [0.8753127  0.12468728], Action: 0, state: 8\n",
      "Action prob: [0.8756167  0.12438327], Action: 0, state: 8\n",
      "Action prob: [0.87423617 0.1257639 ], Action: 0, state: 8\n",
      "Action prob: [0.8917694 0.1082306], Action: 0, state: 8\n",
      "Action prob: [0.8777478  0.12225223], Action: 0, state: 8\n",
      "Action prob: [0.8812856  0.11871435], Action: 0, state: 8\n",
      "Action prob: [0.8786182  0.12138177], Action: 0, state: 8\n",
      "Action prob: [0.87458605 0.12541392], Action: 0, state: 8\n",
      "Action prob: [0.8831236 0.1168764], Action: 0, state: 8\n",
      "Action prob: [0.8947885  0.10521147], Action: 0, state: 8\n",
      "Action prob: [0.87585664 0.12414342], Action: 0, state: 8\n",
      "Action prob: [0.88133293 0.1186671 ], Action: 1, state: 8\n",
      "Action prob: [0.8778767  0.12212332], Action: 0, state: 8\n",
      "Action prob: [0.8971568 0.1028432], Action: 0, state: 8\n",
      "Action prob: [0.8775095  0.12249058], Action: 0, state: 8\n",
      "Action prob: [0.8799803 0.1200196], Action: 1, state: 8\n",
      "Action prob: [0.8958469  0.10415312], Action: 0, state: 8\n",
      "Action prob: [0.8953237  0.10467639], Action: 0, state: 8\n",
      "tensor([-0.5836, -0.4321, -0.3053, -0.1934, -0.1132, -0.0451, -0.0112,  0.3150,\n",
      "        -0.0009,  0.4785,  0.0013, -0.0009,  0.0175,  0.5991,  0.0036,  0.0413,\n",
      "         0.0522,  0.0634,  0.0675,  0.0709,  0.0741,  0.0676,  0.0804,  0.0824,\n",
      "         0.0832,  0.0781,  0.0774,  0.0628,  0.0482,  0.0519,  0.0470,  0.0391,\n",
      "         0.0410,  0.0381,  0.0362,  0.0291,  0.0315,  0.0291,  0.0286,  0.0286,\n",
      "         0.0257,  0.0223,  0.0260,  0.4094,  0.0246,  0.0201,  0.0239,  0.3836,\n",
      "         0.0197,  0.0196], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -65800, loss is -0.04108804442885197\n",
      "Action prob: [0.8655142  0.13448581], Action: 0, state: 0\n",
      "Action prob: [0.8640982  0.13590184], Action: 1, state: 0\n",
      "Action prob: [0.9838382  0.01616175], Action: 0, state: 4\n",
      "Action prob: [0.9838382  0.01616175], Action: 0, state: 4\n",
      "Action prob: [0.9838382  0.01616175], Action: 0, state: 4\n",
      "Action prob: [0.9838382  0.01616175], Action: 1, state: 4\n",
      "Action prob: [0.9838382  0.01616175], Action: 0, state: 4\n",
      "Action prob: [0.8642979  0.13570198], Action: 0, state: 0\n",
      "Action prob: [0.8664734  0.13352661], Action: 0, state: 0\n",
      "Action prob: [0.8637928  0.13620724], Action: 1, state: 1\n",
      "Action prob: [0.9838382  0.01616175], Action: 0, state: 5\n",
      "Action prob: [0.865676   0.13432403], Action: 0, state: 0\n",
      "Action prob: [0.866692 0.133308], Action: 0, state: 0\n",
      "Action prob: [0.86480194 0.13519813], Action: 0, state: 1\n",
      "Action prob: [0.86707336 0.13292661], Action: 0, state: 1\n",
      "Action prob: [0.8547799  0.14522009], Action: 0, state: 1\n",
      "Action prob: [0.8652644  0.13473555], Action: 0, state: 2\n",
      "Action prob: [0.8647549 0.1352451], Action: 0, state: 2\n",
      "Action prob: [0.8642608  0.13573915], Action: 0, state: 2\n",
      "Action prob: [0.8652936  0.13470633], Action: 0, state: 2\n",
      "Action prob: [0.8665697  0.13343032], Action: 0, state: 2\n",
      "Action prob: [0.86493796 0.13506196], Action: 0, state: 2\n",
      "Action prob: [0.86448777 0.13551223], Action: 0, state: 2\n",
      "Action prob: [0.8668052  0.13319474], Action: 0, state: 3\n",
      "Action prob: [0.86862016 0.13137984], Action: 0, state: 3\n",
      "Action prob: [0.8653804  0.13461962], Action: 0, state: 3\n",
      "Action prob: [0.85977554 0.14022449], Action: 0, state: 8\n",
      "Action prob: [0.86124665 0.13875331], Action: 0, state: 8\n",
      "Action prob: [0.8572877  0.14271227], Action: 0, state: 8\n",
      "Action prob: [0.85916597 0.14083405], Action: 0, state: 8\n",
      "Action prob: [0.86113083 0.13886917], Action: 0, state: 8\n",
      "Action prob: [0.8488403  0.15115975], Action: 0, state: 8\n",
      "Action prob: [0.8719774  0.12802261], Action: 0, state: 8\n",
      "Action prob: [0.8734572  0.12654284], Action: 1, state: 8\n",
      "Action prob: [0.8548255  0.14517452], Action: 0, state: 8\n",
      "Action prob: [0.85856634 0.14143363], Action: 0, state: 8\n",
      "Action prob: [0.8736711  0.12632896], Action: 0, state: 8\n",
      "Action prob: [0.8634169  0.13658309], Action: 0, state: 8\n",
      "Action prob: [0.86046773 0.13953227], Action: 0, state: 8\n",
      "Action prob: [0.85865706 0.14134298], Action: 0, state: 8\n",
      "Action prob: [0.8541308  0.14586926], Action: 0, state: 8\n",
      "Action prob: [0.8481938  0.15180616], Action: 1, state: 8\n",
      "Action prob: [0.87045264 0.12954733], Action: 0, state: 8\n",
      "Action prob: [0.8536992 0.1463008], Action: 0, state: 8\n",
      "Action prob: [0.8739691  0.12603094], Action: 0, state: 8\n",
      "Action prob: [0.8619747  0.13802525], Action: 0, state: 8\n",
      "Action prob: [0.87213767 0.12786235], Action: 0, state: 8\n",
      "Action prob: [0.85800004 0.14199996], Action: 0, state: 8\n",
      "Action prob: [0.8607115  0.13928844], Action: 0, state: 8\n",
      "Action prob: [0.86108744 0.13891254], Action: 0, state: 8\n",
      "tensor([-2.6536e-01,  7.3711e-01, -9.2628e-03, -2.2251e-02, -3.3291e-02,\n",
      "        -1.0804e+01, -5.0652e-02, -3.3199e-01, -2.2488e-01, -2.0492e+00,\n",
      "        -2.0912e-02, -1.2247e-01, -6.8640e-02, -2.8655e-02,  6.1100e-03,\n",
      "         3.8747e-02,  5.8053e-02,  7.7335e-02,  9.3893e-02,  1.0683e-01,\n",
      "         1.1727e-01,  1.2874e-01,  1.3767e-01,  1.3955e-01,  1.4121e-01,\n",
      "         1.4818e-01,  1.3764e-01,  1.2163e-01,  1.1272e-01,  1.0050e-01,\n",
      "         9.0105e-02,  9.0490e-02,  6.9759e-02,  9.7720e-01,  6.9284e-02,\n",
      "         6.3335e-02,  5.3064e-02,  5.4905e-02,  5.3751e-02,  5.2407e-02,\n",
      "         5.2380e-02,  6.0752e-01,  4.3539e-02,  4.8501e-02,  4.0483e-02,\n",
      "         4.3865e-02,  3.9799e-02,  4.3979e-02,  4.2595e-02,  4.2066e-02],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -62300, loss is 0.18099092606614484\n",
      "Action prob: [0.8443822  0.15561777], Action: 0, state: 0\n",
      "Action prob: [0.84305507 0.15694489], Action: 0, state: 0\n",
      "Action prob: [0.8446897  0.15531026], Action: 1, state: 1\n",
      "Action prob: [0.9739604  0.02603964], Action: 0, state: 5\n",
      "Action prob: [0.8423224  0.15767762], Action: 1, state: 0\n",
      "Action prob: [0.9739604  0.02603964], Action: 0, state: 4\n",
      "Action prob: [0.8442549 0.1557451], Action: 1, state: 0\n",
      "Action prob: [0.9739604  0.02603964], Action: 0, state: 4\n",
      "Action prob: [0.84516096 0.15483908], Action: 0, state: 0\n",
      "Action prob: [0.84699005 0.1530099 ], Action: 0, state: 1\n",
      "Action prob: [0.84491104 0.155089  ], Action: 0, state: 1\n",
      "Action prob: [0.8456479  0.15435207], Action: 1, state: 1\n",
      "Action prob: [0.9739604  0.02603964], Action: 0, state: 5\n",
      "Action prob: [0.9739604  0.02603964], Action: 0, state: 5\n",
      "Action prob: [0.9739604  0.02603964], Action: 0, state: 5\n",
      "Action prob: [0.9739604  0.02603964], Action: 0, state: 5\n",
      "Action prob: [0.8443735  0.15562645], Action: 0, state: 0\n",
      "Action prob: [0.8435613  0.15643874], Action: 0, state: 1\n",
      "Action prob: [0.84250665 0.15749328], Action: 1, state: 1\n",
      "Action prob: [0.9739604  0.02603964], Action: 0, state: 5\n",
      "Action prob: [0.9739604  0.02603964], Action: 0, state: 5\n",
      "Action prob: [0.9739604  0.02603964], Action: 0, state: 5\n",
      "tensor([-0.5299, -0.3044, -1.3982, -0.0327, -0.7566, -0.0201, -0.3032, -0.0110,\n",
      "         0.0025,  0.0575,  0.1057,  1.6189,  0.0199,  0.0173,  0.0152,  0.0134,\n",
      "         0.1056,  0.1216,  1.4626,  0.0199,  0.0191,  0.0184],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode 6400, loss is -0.01098543617775524\n",
      "Action prob: [0.8267442 0.1732558], Action: 0, state: 0\n",
      "Action prob: [0.8327402  0.16725981], Action: 0, state: 0\n",
      "Action prob: [0.8264754  0.17352454], Action: 0, state: 0\n",
      "Action prob: [0.8275939  0.17240602], Action: 0, state: 0\n",
      "Action prob: [0.8297503  0.17024967], Action: 0, state: 0\n",
      "Action prob: [0.8290436  0.17095646], Action: 0, state: 0\n",
      "Action prob: [0.8282396  0.17176034], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.8303516  0.16964838], Action: 0, state: 1\n",
      "Action prob: [0.83055854 0.16944143], Action: 0, state: 1\n",
      "Action prob: [0.828262   0.17173807], Action: 0, state: 2\n",
      "Action prob: [0.8333684  0.16663164], Action: 0, state: 2\n",
      "Action prob: [0.8337218  0.16627821], Action: 0, state: 2\n",
      "Action prob: [0.8319225 0.1680775], Action: 0, state: 2\n",
      "Action prob: [0.8299629 0.1700371], Action: 0, state: 3\n",
      "Action prob: [0.8282434  0.17175661], Action: 0, state: 3\n",
      "Action prob: [0.83118975 0.1688102 ], Action: 0, state: 3\n",
      "Action prob: [0.83234364 0.16765639], Action: 0, state: 3\n",
      "Action prob: [0.82956165 0.1704383 ], Action: 0, state: 3\n",
      "Action prob: [0.83460325 0.16539675], Action: 0, state: 8\n",
      "Action prob: [0.8212711  0.17872885], Action: 0, state: 8\n",
      "Action prob: [0.819032   0.18096794], Action: 0, state: 8\n",
      "Action prob: [0.8296024 0.1703975], Action: 0, state: 8\n",
      "Action prob: [0.8270983  0.17290169], Action: 0, state: 8\n",
      "Action prob: [0.8207434  0.17925665], Action: 0, state: 8\n",
      "Action prob: [0.8191809  0.18081912], Action: 0, state: 8\n",
      "Action prob: [0.8301538  0.16984624], Action: 0, state: 8\n",
      "Action prob: [0.82510865 0.1748914 ], Action: 0, state: 8\n",
      "Action prob: [0.8263357  0.17366432], Action: 1, state: 8\n",
      "Action prob: [0.8275985  0.17240152], Action: 0, state: 8\n",
      "Action prob: [0.82460254 0.17539749], Action: 0, state: 8\n",
      "Action prob: [0.82337105 0.1766289 ], Action: 0, state: 8\n",
      "Action prob: [0.8303941  0.16960588], Action: 1, state: 8\n",
      "Action prob: [0.825517 0.174483], Action: 1, state: 8\n",
      "Action prob: [0.82366437 0.17633563], Action: 1, state: 8\n",
      "Action prob: [0.83762723 0.16237274], Action: 0, state: 8\n",
      "Action prob: [0.82661986 0.17338014], Action: 0, state: 8\n",
      "Action prob: [0.82871205 0.17128795], Action: 0, state: 8\n",
      "Action prob: [0.82394385 0.17605615], Action: 0, state: 8\n",
      "Action prob: [0.8250261  0.17497388], Action: 0, state: 8\n",
      "Action prob: [0.8237226  0.17627738], Action: 1, state: 8\n",
      "Action prob: [0.8225876  0.17741235], Action: 0, state: 8\n",
      "Action prob: [0.8440589  0.15594114], Action: 0, state: 8\n",
      "Action prob: [0.8259286  0.17407131], Action: 0, state: 8\n",
      "Action prob: [0.82744217 0.17255779], Action: 0, state: 8\n",
      "Action prob: [0.81941235 0.18058765], Action: 0, state: 8\n",
      "Action prob: [0.82289094 0.17710902], Action: 0, state: 8\n",
      "Action prob: [0.8193846 0.1806154], Action: 0, state: 8\n",
      "Action prob: [0.8218927  0.17810732], Action: 1, state: 8\n",
      "Action prob: [0.8201146  0.17988543], Action: 0, state: 8\n",
      "Action prob: [0.8259982  0.17400177], Action: 0, state: 8\n",
      "tensor([-7.9190e-01, -5.9279e-01, -4.6764e-01, -3.3806e-01, -2.2757e-01,\n",
      "        -1.3823e-01, -6.1725e-02, -2.6161e-03,  4.6855e-02,  8.5486e-02,\n",
      "         1.1389e-01,  1.4007e-01,  1.6449e-01,  1.7884e-01,  1.9135e-01,\n",
      "         1.9652e-01,  2.0244e-01,  2.1254e-01,  1.7404e-01,  1.6028e-01,\n",
      "         1.3728e-01,  1.0840e-01,  9.2827e-02,  8.1273e-02,  6.8904e-02,\n",
      "         5.3873e-02,  4.6477e-02,  3.5235e-01,  3.1571e-02,  2.6533e-02,\n",
      "         2.1905e-02,  1.6247e-01,  1.2850e-01,  1.0122e-01,  8.0341e-03,\n",
      "         6.5326e-03,  4.6835e-03,  3.2833e-03,  1.9575e-03,  7.6660e-03,\n",
      "        -9.3724e-05, -7.8697e-04, -1.5644e-03, -2.1190e-03, -2.7371e-03,\n",
      "        -3.1024e-03, -3.5383e-03, -3.3355e-02, -4.0984e-03, -4.1674e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -85500, loss is -0.01272883813419213\n",
      "Action prob: [0.820705   0.17929499], Action: 0, state: 0\n",
      "Action prob: [0.8194454  0.18055463], Action: 0, state: 0\n",
      "Action prob: [0.81832725 0.18167277], Action: 0, state: 0\n",
      "Action prob: [0.8092601  0.19073987], Action: 0, state: 9\n",
      "Action prob: [0.81562144 0.18437855], Action: 0, state: 9\n",
      "Action prob: [0.8062422  0.19375777], Action: 0, state: 9\n",
      "Action prob: [0.81085986 0.18914017], Action: 0, state: 9\n",
      "Action prob: [0.82559687 0.17440316], Action: 1, state: 9\n",
      "Action prob: [0.81646746 0.18353257], Action: 0, state: 9\n",
      "Action prob: [0.8150196  0.18498044], Action: 0, state: 9\n",
      "Action prob: [0.8171829  0.18281715], Action: 0, state: 9\n",
      "Action prob: [0.81207657 0.18792346], Action: 0, state: 9\n",
      "Action prob: [0.82608914 0.1739109 ], Action: 1, state: 9\n",
      "Action prob: [0.81309843 0.18690155], Action: 1, state: 9\n",
      "Action prob: [0.817636   0.18236393], Action: 0, state: 9\n",
      "Action prob: [0.8080399  0.19196014], Action: 0, state: 9\n",
      "Action prob: [0.8075006 0.1924994], Action: 1, state: 9\n",
      "Action prob: [0.8164231  0.18357687], Action: 0, state: 9\n",
      "Action prob: [0.8129087  0.18709126], Action: 0, state: 9\n",
      "Action prob: [0.8130465  0.18695347], Action: 0, state: 9\n",
      "Action prob: [0.8168363  0.18316367], Action: 0, state: 9\n",
      "Action prob: [0.814205   0.18579502], Action: 0, state: 9\n",
      "Action prob: [0.81646055 0.1835395 ], Action: 0, state: 9\n",
      "Action prob: [0.8085545  0.19144548], Action: 0, state: 9\n",
      "Action prob: [0.810002   0.18999791], Action: 0, state: 9\n",
      "Action prob: [0.8164362  0.18356383], Action: 0, state: 9\n",
      "Action prob: [0.81027406 0.18972594], Action: 0, state: 9\n",
      "Action prob: [0.81049037 0.18950963], Action: 0, state: 9\n",
      "Action prob: [0.8118345 0.1881655], Action: 0, state: 9\n",
      "Action prob: [0.81025 0.18975], Action: 1, state: 9\n",
      "Action prob: [0.80861884 0.19138117], Action: 1, state: 9\n",
      "tensor([ 0.2444,  0.3899,  0.5153,  0.4338,  0.3275,  0.2651,  0.1910,  1.1164,\n",
      "         0.0828,  0.0433,  0.0091, -0.0202, -0.3806, -0.5369, -0.0820, -0.1026,\n",
      "        -0.8968, -0.1212, -0.1332, -0.1411, -0.1446, -0.1527, -0.1554, -0.1672,\n",
      "        -0.1694, -0.1660, -0.1748, -0.1768, -0.1773, -1.4259, -1.4292],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -25000, loss is 0.10113713874476657\n",
      "Action prob: [0.8015556  0.19844438], Action: 0, state: 0\n",
      "Action prob: [0.79957956 0.20042044], Action: 1, state: 0\n",
      "Action prob: [0.9313468  0.06865322], Action: 1, state: 4\n",
      "Action prob: [0.79665154 0.20334844], Action: 0, state: 0\n",
      "Action prob: [0.7958747  0.20412527], Action: 0, state: 0\n",
      "Action prob: [0.80310345 0.19689663], Action: 0, state: 0\n",
      "Action prob: [0.79898626 0.20101377], Action: 1, state: 0\n",
      "Action prob: [0.9313468  0.06865322], Action: 0, state: 4\n",
      "Action prob: [0.79880595 0.20119406], Action: 0, state: 0\n",
      "Action prob: [0.8010269  0.19897312], Action: 0, state: 0\n",
      "Action prob: [0.7991969  0.20080309], Action: 0, state: 1\n",
      "Action prob: [0.79979724 0.20020275], Action: 0, state: 1\n",
      "Action prob: [0.79912615 0.20087378], Action: 0, state: 2\n",
      "Action prob: [0.8009103  0.19908965], Action: 1, state: 2\n",
      "Action prob: [0.79244816 0.20755184], Action: 0, state: 9\n",
      "Action prob: [0.80036676 0.19963324], Action: 0, state: 9\n",
      "Action prob: [0.80007446 0.1999255 ], Action: 0, state: 9\n",
      "Action prob: [0.80190986 0.19809015], Action: 1, state: 9\n",
      "Action prob: [0.7858617  0.21413839], Action: 0, state: 9\n",
      "Action prob: [0.80043834 0.1995617 ], Action: 0, state: 9\n",
      "Action prob: [0.79590863 0.20409131], Action: 0, state: 9\n",
      "Action prob: [0.7901675  0.20983246], Action: 0, state: 9\n",
      "Action prob: [0.7934235  0.20657651], Action: 0, state: 9\n",
      "Action prob: [0.7974539  0.20254613], Action: 0, state: 9\n",
      "Action prob: [0.80007815 0.19992185], Action: 1, state: 9\n",
      "Action prob: [0.79949784 0.20050216], Action: 0, state: 9\n",
      "Action prob: [0.7845862  0.21541384], Action: 1, state: 9\n",
      "Action prob: [0.7939172  0.20608285], Action: 1, state: 9\n",
      "tensor([-0.6425, -3.0664, -6.2453, -0.3663, -0.2280, -0.1049, -0.0577, -0.0159,\n",
      "         0.0215,  0.0815,  0.1289,  0.1680,  0.1985,  1.6121,  0.2043,  0.1728,\n",
      "         0.1536,  0.9951,  0.1330,  0.1109,  0.1034,  0.0975,  0.0882,  0.0800,\n",
      "         0.5306,  0.0692,  0.4487,  0.4387], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for this episode -3600, loss is 0.17466145495824884\n",
      "Action prob: [0.7793529  0.22064705], Action: 1, state: 0\n",
      "Action prob: [0.89757746 0.10242253], Action: 0, state: 4\n",
      "Action prob: [0.77422035 0.22577967], Action: 0, state: 0\n",
      "Action prob: [0.78068274 0.21931721], Action: 0, state: 1\n",
      "Action prob: [0.78053385 0.21946613], Action: 1, state: 1\n",
      "Action prob: [0.89757746 0.10242253], Action: 0, state: 5\n",
      "Action prob: [0.7792286  0.22077142], Action: 0, state: 0\n",
      "Action prob: [0.77765644 0.22234361], Action: 0, state: 0\n",
      "Action prob: [0.78161484 0.21838513], Action: 0, state: 1\n",
      "Action prob: [0.7803072  0.21969283], Action: 0, state: 2\n",
      "Action prob: [0.77890056 0.22109948], Action: 0, state: 2\n",
      "Action prob: [0.7808338  0.21916622], Action: 0, state: 2\n",
      "Action prob: [0.77794564 0.22205432], Action: 0, state: 2\n",
      "Action prob: [0.7763291  0.22367086], Action: 1, state: 3\n",
      "Action prob: [0.89757746 0.10242253], Action: 0, state: 7\n",
      "Action prob: [0.77979386 0.2202062 ], Action: 0, state: 2\n",
      "Action prob: [0.7844966  0.21550338], Action: 0, state: 3\n",
      "Action prob: [0.781239   0.21876109], Action: 1, state: 3\n",
      "Action prob: [0.89757746 0.10242253], Action: 0, state: 7\n",
      "Action prob: [0.89757746 0.10242253], Action: 0, state: 7\n",
      "Action prob: [0.781552   0.21844797], Action: 0, state: 2\n",
      "Action prob: [0.77171326 0.22828671], Action: 0, state: 3\n",
      "Action prob: [0.7845141  0.21548584], Action: 0, state: 8\n",
      "Action prob: [0.77454877 0.22545128], Action: 0, state: 8\n",
      "Action prob: [0.77295065 0.22704929], Action: 0, state: 8\n",
      "Action prob: [0.7796691  0.22033088], Action: 1, state: 8\n",
      "Action prob: [0.77038205 0.22961794], Action: 0, state: 8\n",
      "Action prob: [0.7789716  0.22102836], Action: 0, state: 8\n",
      "Action prob: [0.7818627  0.21813728], Action: 0, state: 8\n",
      "Action prob: [0.7695132  0.23048681], Action: 0, state: 8\n",
      "Action prob: [0.7836248  0.21637522], Action: 1, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.7714207  0.22857928], Action: 0, state: 8\n",
      "Action prob: [0.77160096 0.22839907], Action: 0, state: 8\n",
      "Action prob: [0.7857686  0.21423142], Action: 0, state: 8\n",
      "Action prob: [0.772194   0.22780593], Action: 1, state: 8\n",
      "Action prob: [0.7743393  0.22566074], Action: 0, state: 8\n",
      "Action prob: [0.78445786 0.2155421 ], Action: 0, state: 8\n",
      "Action prob: [0.77396536 0.2260347 ], Action: 0, state: 8\n",
      "Action prob: [0.7772536  0.22274631], Action: 1, state: 8\n",
      "tensor([-4.1628, -0.3568, -0.6069, -0.4111, -1.6009, -0.1449, -0.2135, -0.1114,\n",
      "        -0.0314,  0.0276,  0.0784,  0.1203,  0.1588,  1.0638,  0.0696,  0.1826,\n",
      "         0.1898,  1.2501,  0.0852,  0.0820,  0.1968,  0.2125,  0.1727,  0.1583,\n",
      "         0.1395,  0.7189,  0.1093,  0.0926,  0.0812,  0.0774,  0.4070,  0.0625,\n",
      "         0.0569,  0.0486,  0.2753,  0.0443,  0.0393,  0.0391,  0.2169],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -40000, loss is 0.030315812210758367\n",
      "Action prob: [0.7594329  0.24056707], Action: 1, state: 0\n",
      "Action prob: [0.8617862  0.13821381], Action: 0, state: 4\n",
      "Action prob: [0.8617862  0.13821381], Action: 0, state: 4\n",
      "Action prob: [0.7579545  0.24204549], Action: 1, state: 0\n",
      "Action prob: [0.7622609  0.23773909], Action: 1, state: 9\n",
      "Action prob: [0.7523274  0.24767268], Action: 0, state: 9\n",
      "Action prob: [0.7532159 0.2467841], Action: 0, state: 9\n",
      "Action prob: [0.74915385 0.25084615], Action: 1, state: 9\n",
      "Action prob: [0.75141007 0.24859   ], Action: 0, state: 9\n",
      "Action prob: [0.75177366 0.24822631], Action: 0, state: 9\n",
      "Action prob: [0.7627904  0.23720963], Action: 0, state: 9\n",
      "Action prob: [0.7648288  0.23517118], Action: 1, state: 9\n",
      "Action prob: [0.76476836 0.23523164], Action: 1, state: 9\n",
      "Action prob: [0.74617434 0.2538257 ], Action: 0, state: 9\n",
      "Action prob: [0.75141704 0.24858296], Action: 0, state: 9\n",
      "Action prob: [0.7508975  0.24910247], Action: 0, state: 9\n",
      "Action prob: [0.76194966 0.23805031], Action: 1, state: 9\n",
      "Action prob: [0.76364017 0.23635979], Action: 0, state: 9\n",
      "Action prob: [0.76280904 0.23719096], Action: 0, state: 9\n",
      "Action prob: [0.7639599  0.23604007], Action: 1, state: 9\n",
      "Action prob: [0.752376 0.247624], Action: 0, state: 9\n",
      "Action prob: [0.7626312  0.23736884], Action: 0, state: 9\n",
      "Action prob: [0.75034744 0.24965256], Action: 0, state: 9\n",
      "Action prob: [0.7617029  0.23829712], Action: 0, state: 9\n",
      "Action prob: [0.7513247  0.24867524], Action: 0, state: 9\n",
      "Action prob: [0.76351887 0.2364811 ], Action: 0, state: 9\n",
      "Action prob: [0.7567186  0.24328144], Action: 0, state: 9\n",
      "Action prob: [0.7508878  0.24911216], Action: 1, state: 9\n",
      "tensor([ 3.0545,  0.2645,  0.2182,  2.8311,  2.2212,  0.3313,  0.2379,  0.7790,\n",
      "         0.0939,  0.0369, -0.0109, -0.2668, -0.4440, -0.1203, -0.1427, -0.1646,\n",
      "        -0.9165, -0.1869, -0.2001, -1.1238, -0.2310, -0.2277, -0.2482, -0.2408,\n",
      "        -0.2579, -0.2474, -0.2591, -1.3068], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for this episode -23000, loss is -0.12402787547722213\n",
      "Action prob: [0.75168735 0.24831268], Action: 1, state: 0\n",
      "Action prob: [0.82569236 0.17430766], Action: 0, state: 4\n",
      "Action prob: [0.7603534  0.23964664], Action: 0, state: 0\n",
      "Action prob: [0.7562601  0.24373984], Action: 1, state: 1\n",
      "Action prob: [0.82569236 0.17430766], Action: 0, state: 5\n",
      "Action prob: [0.82569236 0.17430766], Action: 0, state: 5\n",
      "Action prob: [0.82569236 0.17430766], Action: 0, state: 5\n",
      "Action prob: [0.7539749  0.24602509], Action: 1, state: 0\n",
      "Action prob: [0.82569236 0.17430766], Action: 0, state: 4\n",
      "Action prob: [0.82569236 0.17430766], Action: 1, state: 4\n",
      "Action prob: [0.75508046 0.24491955], Action: 1, state: 0\n",
      "Action prob: [0.82569236 0.17430766], Action: 0, state: 4\n",
      "Action prob: [0.7542295 0.2457705], Action: 0, state: 0\n",
      "Action prob: [0.7554792  0.24452078], Action: 0, state: 0\n",
      "Action prob: [0.75694394 0.24305603], Action: 1, state: 0\n",
      "Action prob: [0.82569236 0.17430766], Action: 0, state: 4\n",
      "Action prob: [0.82569236 0.17430766], Action: 1, state: 4\n",
      "Action prob: [0.82569236 0.17430766], Action: 0, state: 4\n",
      "Action prob: [0.82569236 0.17430766], Action: 0, state: 4\n",
      "Action prob: [0.82569236 0.17430766], Action: 0, state: 4\n",
      "Action prob: [0.82569236 0.17430766], Action: 0, state: 4\n",
      "tensor([-2.2416, -0.6051, -0.1436,  2.1062,  0.1034, -0.0516, -0.1833,  0.2976,\n",
      "        -0.0545, -1.2353,  0.0155, -0.0564,  0.0634,  0.1866,  1.4717,  0.1688,\n",
      "         1.3028,  0.1208,  0.1020,  0.0861,  0.0726], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for this episode 1400, loss is -0.07266955496478616\n",
      "Action prob: [0.75757784 0.24242212], Action: 0, state: 0\n",
      "Action prob: [0.7545604  0.24543963], Action: 0, state: 1\n",
      "Action prob: [0.7542261  0.24577388], Action: 0, state: 1\n",
      "Action prob: [0.75454366 0.24545634], Action: 1, state: 1\n",
      "Action prob: [0.7978272  0.20217279], Action: 0, state: 5\n",
      "Action prob: [0.7978272  0.20217279], Action: 0, state: 5\n",
      "Action prob: [0.76022995 0.2397701 ], Action: 0, state: 0\n",
      "Action prob: [0.75243175 0.24756825], Action: 0, state: 0\n",
      "Action prob: [0.75607747 0.24392249], Action: 0, state: 0\n",
      "Action prob: [0.7569844  0.24301562], Action: 1, state: 0\n",
      "Action prob: [0.7978272  0.20217279], Action: 0, state: 4\n",
      "Action prob: [0.7978272  0.20217279], Action: 1, state: 4\n",
      "Action prob: [0.75350183 0.2464981 ], Action: 1, state: 0\n",
      "Action prob: [0.7978272  0.20217279], Action: 0, state: 4\n",
      "Action prob: [0.75449646 0.2455035 ], Action: 0, state: 0\n",
      "Action prob: [0.75890195 0.24109797], Action: 0, state: 0\n",
      "Action prob: [0.75500727 0.24499275], Action: 0, state: 1\n",
      "Action prob: [0.7546303 0.2453697], Action: 0, state: 1\n",
      "Action prob: [0.7513051  0.24869487], Action: 0, state: 1\n",
      "Action prob: [0.75423115 0.24576886], Action: 0, state: 1\n",
      "Action prob: [0.7522734  0.24772666], Action: 0, state: 1\n",
      "Action prob: [0.7549867 0.2450133], Action: 0, state: 1\n",
      "Action prob: [0.75494397 0.24505602], Action: 0, state: 1\n",
      "Action prob: [0.7569785  0.24302152], Action: 0, state: 1\n",
      "Action prob: [0.7467397 0.2532603], Action: 0, state: 9\n",
      "Action prob: [0.7615225 0.2384775], Action: 0, state: 9\n",
      "Action prob: [0.762317   0.23768295], Action: 1, state: 9\n",
      "Action prob: [0.7476591  0.25234085], Action: 0, state: 9\n",
      "Action prob: [0.74673307 0.253267  ], Action: 1, state: 9\n",
      "Action prob: [0.7487739  0.25122616], Action: 0, state: 9\n",
      "Action prob: [0.7592399  0.24076009], Action: 0, state: 9\n",
      "Action prob: [0.75915986 0.24084012], Action: 0, state: 9\n",
      "Action prob: [0.7511584 0.2488416], Action: 0, state: 9\n",
      "Action prob: [0.74714816 0.25285187], Action: 0, state: 9\n",
      "Action prob: [0.75527114 0.24472888], Action: 1, state: 9\n",
      "Action prob: [0.74711734 0.2528827 ], Action: 0, state: 9\n",
      "Action prob: [0.750435   0.24956496], Action: 0, state: 9\n",
      "Action prob: [0.770681   0.22931893], Action: 0, state: 9\n",
      "Action prob: [0.7417431 0.2582569], Action: 0, state: 9\n",
      "Action prob: [0.760683   0.23931707], Action: 0, state: 9\n",
      "Action prob: [0.7473268  0.25267318], Action: 0, state: 9\n",
      "Action prob: [0.7619152  0.23808476], Action: 1, state: 9\n",
      "Action prob: [0.7602382  0.23976181], Action: 0, state: 9\n",
      "Action prob: [0.75886935 0.24113064], Action: 0, state: 9\n",
      "Action prob: [0.7484322  0.25156778], Action: 0, state: 9\n",
      "Action prob: [0.7504714  0.24952857], Action: 1, state: 9\n",
      "Action prob: [0.7581752  0.24182476], Action: 0, state: 9\n",
      "Action prob: [0.7598572  0.24014285], Action: 0, state: 9\n",
      "Action prob: [0.75872236 0.24127768], Action: 0, state: 9\n",
      "Action prob: [0.74785215 0.2521479 ], Action: 0, state: 9\n",
      "tensor([-1.1836, -0.8582, -0.5681, -1.5952, -0.3502, -0.4298, -0.3574, -0.2259,\n",
      "        -0.1010,  0.0097, -0.0338, -0.4516, -0.0791, -0.0345,  0.0030,  0.0413,\n",
      "         0.0719,  0.0974,  0.1209,  0.1376,  0.1547,  0.1660,  0.1773,  0.1851,\n",
      "         0.1847,  0.1649,  0.8361,  0.1635,  0.7490,  0.1537,  0.1430,  0.1402,\n",
      "         0.1431,  0.1436,  0.6843,  0.1402,  0.1367,  0.1230,  0.1401,  0.1275,\n",
      "         0.1351,  0.6627,  0.1261,  0.1265,  0.1325,  0.6334,  0.1261,  0.1249,\n",
      "         0.1254,  0.1317], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -12600, loss is -0.027891763101491166\n",
      "Action prob: [0.7565389 0.2434611], Action: 0, state: 0\n",
      "Action prob: [0.757575   0.24242502], Action: 0, state: 1\n",
      "Action prob: [0.7561187  0.24388131], Action: 1, state: 1\n",
      "Action prob: [0.77621865 0.22378139], Action: 0, state: 5\n",
      "Action prob: [0.7565158  0.24348423], Action: 0, state: 0\n",
      "Action prob: [0.7537407  0.24625932], Action: 0, state: 0\n",
      "Action prob: [0.75431776 0.24568225], Action: 0, state: 0\n",
      "Action prob: [0.75602734 0.24397263], Action: 1, state: 0\n",
      "Action prob: [0.77621865 0.22378139], Action: 0, state: 4\n",
      "Action prob: [0.7565041  0.24349582], Action: 1, state: 0\n",
      "Action prob: [0.77621865 0.22378139], Action: 1, state: 4\n",
      "Action prob: [0.77621865 0.22378139], Action: 0, state: 4\n",
      "Action prob: [0.75565803 0.24434201], Action: 0, state: 0\n",
      "Action prob: [0.7612601  0.23873992], Action: 0, state: 0\n",
      "Action prob: [0.75607634 0.24392371], Action: 1, state: 0\n",
      "Action prob: [0.77621865 0.22378139], Action: 0, state: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.755983   0.24401703], Action: 0, state: 0\n",
      "Action prob: [0.7583275  0.24167252], Action: 0, state: 1\n",
      "Action prob: [0.75753206 0.24246794], Action: 1, state: 1\n",
      "Action prob: [0.77621865 0.22378139], Action: 0, state: 5\n",
      "Action prob: [0.77621865 0.22378139], Action: 0, state: 5\n",
      "Action prob: [0.77621865 0.22378139], Action: 1, state: 5\n",
      "Action prob: [0.77621865 0.22378139], Action: 1, state: 5\n",
      "tensor([-0.7956, -0.5472, -1.7244, -0.3991, -0.2719, -0.1311, -0.0083,  0.4794,\n",
      "         0.0463,  0.6352,  0.5035,  0.0608,  0.1131,  0.1481,  0.9330,  0.1548,\n",
      "         0.1948,  0.2108,  1.1583,  0.2004,  0.1948,  1.1228,  1.0986],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode 9100, loss is -0.14683459209481323\n",
      "Action prob: [0.7695024  0.23049763], Action: 1, state: 0\n",
      "Action prob: [0.7702872  0.22971277], Action: 0, state: 4\n",
      "Action prob: [0.7702872  0.22971277], Action: 0, state: 4\n",
      "Action prob: [0.7702872  0.22971277], Action: 0, state: 4\n",
      "Action prob: [0.7702872  0.22971277], Action: 0, state: 4\n",
      "Action prob: [0.7671491  0.23285094], Action: 0, state: 0\n",
      "Action prob: [0.7623306  0.23766947], Action: 0, state: 0\n",
      "Action prob: [0.7670788  0.23292117], Action: 0, state: 0\n",
      "Action prob: [0.76461214 0.23538788], Action: 0, state: 1\n",
      "Action prob: [0.7637696  0.23623037], Action: 1, state: 1\n",
      "Action prob: [0.7702872  0.22971277], Action: 1, state: 5\n",
      "Action prob: [0.7658138  0.23418625], Action: 0, state: 0\n",
      "Action prob: [0.7653826  0.23461738], Action: 1, state: 0\n",
      "Action prob: [0.7702872  0.22971277], Action: 0, state: 4\n",
      "Action prob: [0.76685756 0.23314242], Action: 1, state: 0\n",
      "Action prob: [0.7702872  0.22971277], Action: 0, state: 4\n",
      "Action prob: [0.7625199  0.23748007], Action: 1, state: 0\n",
      "Action prob: [0.7702872  0.22971277], Action: 1, state: 4\n",
      "Action prob: [0.7702872  0.22971277], Action: 0, state: 4\n",
      "Action prob: [0.76314056 0.23685946], Action: 0, state: 0\n",
      "Action prob: [0.7633872  0.23661277], Action: 0, state: 1\n",
      "Action prob: [0.76207304 0.23792696], Action: 1, state: 1\n",
      "Action prob: [0.7702872  0.22971277], Action: 0, state: 5\n",
      "Action prob: [0.7702872  0.22971277], Action: 0, state: 5\n",
      "tensor([-0.1504, -0.2173, -0.3793, -0.5169, -0.6340, -0.4418, -0.2765, -0.1241,\n",
      "        -0.0126,  0.4491,  0.2091,  0.1146,  0.9771,  0.1488,  1.0872,  0.1753,\n",
      "         1.1490,  1.0958,  0.1824,  0.2101,  0.2260,  1.2751,  0.2255,  0.2202],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode 7100, loss is -0.2080217759288382\n",
      "Action prob: [0.7847956  0.21520437], Action: 0, state: 0\n",
      "Action prob: [0.78470445 0.21529555], Action: 0, state: 0\n",
      "Action prob: [0.7786164  0.22138351], Action: 0, state: 9\n",
      "Action prob: [0.7921002  0.20789978], Action: 0, state: 9\n",
      "Action prob: [0.8026183  0.19738168], Action: 1, state: 9\n",
      "Action prob: [0.7893176  0.21068238], Action: 0, state: 9\n",
      "Action prob: [0.7887289 0.2112711], Action: 0, state: 9\n",
      "Action prob: [0.77258235 0.22741769], Action: 0, state: 9\n",
      "Action prob: [0.78184825 0.21815173], Action: 0, state: 9\n",
      "Action prob: [0.7930144  0.20698561], Action: 0, state: 9\n",
      "Action prob: [0.7772218  0.22277814], Action: 0, state: 9\n",
      "Action prob: [0.7796382  0.22036181], Action: 1, state: 9\n",
      "Action prob: [0.7767549  0.22324516], Action: 0, state: 9\n",
      "Action prob: [0.7814792  0.21852079], Action: 0, state: 9\n",
      "Action prob: [0.7749808  0.22501922], Action: 0, state: 9\n",
      "Action prob: [0.779192   0.22080804], Action: 1, state: 9\n",
      "Action prob: [0.77554137 0.2244587 ], Action: 0, state: 9\n",
      "Action prob: [0.7734051 0.226595 ], Action: 0, state: 9\n",
      "Action prob: [0.77215034 0.22784965], Action: 0, state: 9\n",
      "Action prob: [0.79229975 0.20770033], Action: 0, state: 9\n",
      "Action prob: [0.7919078  0.20809215], Action: 0, state: 9\n",
      "Action prob: [0.7928461  0.20715393], Action: 0, state: 9\n",
      "Action prob: [0.7806748  0.21932513], Action: 0, state: 9\n",
      "Action prob: [0.773743   0.22625704], Action: 0, state: 9\n",
      "Action prob: [0.7741145  0.22588551], Action: 0, state: 9\n",
      "Action prob: [0.7766078  0.22339216], Action: 0, state: 9\n",
      "Action prob: [0.7952194  0.20478064], Action: 0, state: 9\n",
      "Action prob: [0.7929325  0.20706752], Action: 0, state: 9\n",
      "Action prob: [0.77596235 0.22403757], Action: 0, state: 9\n",
      "Action prob: [0.7727963  0.22720371], Action: 0, state: 9\n",
      "Action prob: [0.7813165  0.21868347], Action: 0, state: 9\n",
      "Action prob: [0.79286104 0.20713888], Action: 0, state: 9\n",
      "Action prob: [0.7825736 0.2174264], Action: 0, state: 9\n",
      "Action prob: [0.7744918  0.22550821], Action: 1, state: 9\n",
      "Action prob: [0.7752347  0.22476529], Action: 0, state: 9\n",
      "Action prob: [0.77783763 0.22216237], Action: 1, state: 9\n",
      "Action prob: [0.77997893 0.22002105], Action: 0, state: 9\n",
      "Action prob: [0.76932174 0.23067825], Action: 0, state: 9\n",
      "Action prob: [0.7904773  0.20952278], Action: 0, state: 9\n",
      "Action prob: [0.7916563  0.20834368], Action: 0, state: 9\n",
      "Action prob: [0.7744986  0.22550139], Action: 1, state: 9\n",
      "Action prob: [0.779243   0.22075695], Action: 1, state: 9\n",
      "Action prob: [0.7753069  0.22469315], Action: 1, state: 9\n",
      "Action prob: [0.77206427 0.22793575], Action: 1, state: 9\n",
      "Action prob: [0.79088396 0.20911604], Action: 0, state: 9\n",
      "Action prob: [0.7722613  0.22773874], Action: 0, state: 9\n",
      "Action prob: [0.77492076 0.22507921], Action: 0, state: 9\n",
      "Action prob: [0.7925198  0.20748024], Action: 0, state: 9\n",
      "Action prob: [0.7924413  0.20755862], Action: 0, state: 9\n",
      "Action prob: [0.77344054 0.2265594 ], Action: 0, state: 9\n",
      "tensor([ 0.6494,  0.8199,  0.6970,  0.5309,  2.9970,  0.3503,  0.2775,  0.2334,\n",
      "         0.1672,  0.1132,  0.0821,  0.2835,  0.0177, -0.0074, -0.0293, -0.2823,\n",
      "        -0.0631, -0.0772, -0.0891, -0.0890, -0.0967, -0.1025, -0.1150, -0.1242,\n",
      "        -0.1283, -0.1302, -0.1208, -0.1247, -0.1386, -0.1427, -0.1382, -0.1312,\n",
      "        -0.1397, -0.8545, -0.1469, -0.8722, -0.1447, -0.1532, -0.1378, -0.1372,\n",
      "        -0.8767, -0.8908, -0.8818, -0.8744, -0.1389, -0.1531, -0.1512, -0.1380,\n",
      "        -0.1381, -0.1526], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -48000, loss is 0.037866192515646484\n",
      "Action prob: [0.80235386 0.19764617], Action: 0, state: 0\n",
      "Action prob: [0.79832125 0.20167875], Action: 0, state: 0\n",
      "Action prob: [0.8001175  0.19988246], Action: 0, state: 0\n",
      "Action prob: [0.8010747  0.19892538], Action: 0, state: 1\n",
      "Action prob: [0.8011478 0.1988522], Action: 0, state: 1\n",
      "Action prob: [0.79718226 0.2028177 ], Action: 0, state: 2\n",
      "Action prob: [0.7976308  0.20236917], Action: 0, state: 2\n",
      "Action prob: [0.7997204  0.20027958], Action: 0, state: 3\n",
      "Action prob: [0.80686986 0.19313014], Action: 1, state: 3\n",
      "Action prob: [0.78348947 0.21651052], Action: 0, state: 7\n",
      "Action prob: [0.800708   0.19929197], Action: 0, state: 2\n",
      "Action prob: [0.79904556 0.20095447], Action: 0, state: 2\n",
      "Action prob: [0.7972992  0.20270082], Action: 0, state: 2\n",
      "Action prob: [0.7979336 0.2020664], Action: 0, state: 3\n",
      "Action prob: [0.7988351  0.20116492], Action: 0, state: 3\n",
      "Action prob: [0.78914404 0.21085596], Action: 0, state: 8\n",
      "Action prob: [0.8085692  0.19143079], Action: 0, state: 8\n",
      "Action prob: [0.7917777  0.20822236], Action: 1, state: 8\n",
      "Action prob: [0.78277534 0.21722464], Action: 0, state: 8\n",
      "Action prob: [0.79020756 0.20979246], Action: 0, state: 8\n",
      "Action prob: [0.7951024  0.20489761], Action: 1, state: 8\n",
      "Action prob: [0.78623515 0.21376485], Action: 0, state: 8\n",
      "Action prob: [0.80561554 0.19438447], Action: 0, state: 8\n",
      "Action prob: [0.7888722  0.21112777], Action: 0, state: 8\n",
      "Action prob: [0.80460566 0.19539428], Action: 0, state: 8\n",
      "Action prob: [0.79359853 0.20640144], Action: 0, state: 8\n",
      "Action prob: [0.78906906 0.21093093], Action: 1, state: 8\n",
      "Action prob: [0.789679   0.21032104], Action: 0, state: 8\n",
      "Action prob: [0.7891514  0.21084869], Action: 1, state: 8\n",
      "Action prob: [0.7980462  0.20195389], Action: 0, state: 8\n",
      "Action prob: [0.7928834  0.20711659], Action: 0, state: 8\n",
      "Action prob: [0.8071578  0.19284219], Action: 1, state: 8\n",
      "Action prob: [0.79471594 0.20528406], Action: 0, state: 8\n",
      "Action prob: [0.79031783 0.20968221], Action: 0, state: 8\n",
      "Action prob: [0.79242367 0.20757629], Action: 0, state: 8\n",
      "Action prob: [0.8059935  0.19400646], Action: 0, state: 8\n",
      "Action prob: [0.79451793 0.20548199], Action: 0, state: 8\n",
      "Action prob: [0.80484015 0.19515988], Action: 1, state: 8\n",
      "Action prob: [0.8062357  0.19376436], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.82028157 0.17971843], Action: 0, state: 8\n",
      "Action prob: [0.8041793  0.19582072], Action: 0, state: 8\n",
      "Action prob: [0.8078958  0.19210419], Action: 0, state: 8\n",
      "Action prob: [0.7891772  0.21082284], Action: 0, state: 8\n",
      "Action prob: [0.7946308  0.20536919], Action: 0, state: 8\n",
      "Action prob: [0.7850343  0.21496573], Action: 0, state: 8\n",
      "Action prob: [0.8040624  0.19593759], Action: 0, state: 8\n",
      "Action prob: [0.80726004 0.19273996], Action: 0, state: 8\n",
      "Action prob: [0.7925032  0.20749688], Action: 0, state: 8\n",
      "Action prob: [0.80541366 0.19458638], Action: 0, state: 8\n",
      "Action prob: [0.79331213 0.20668785], Action: 0, state: 8\n",
      "tensor([-7.7991e-01, -5.3631e-01, -3.1096e-01, -1.4189e-01,  4.0101e-04,\n",
      "         1.1028e-01,  2.0316e-01,  2.4973e-01,  2.1434e+00,  2.7945e-01,\n",
      "         3.0235e-01,  3.4619e-01,  3.8477e-01,  4.0205e-01,  4.1580e-01,\n",
      "         3.5365e-01,  2.5270e-01,  1.4604e+00,  1.7412e-01,  1.2341e-01,\n",
      "         5.7919e-01,  5.5412e-02,  2.5005e-02,  4.3098e-03, -1.4068e-02,\n",
      "        -3.1246e-02, -3.0353e-01, -5.8075e-02, -4.5019e-01, -7.3539e-02,\n",
      "        -8.2910e-02, -6.3172e-01, -9.3380e-02, -1.0015e-01, -1.0282e-01,\n",
      "        -9.8304e-02, -1.0755e-01, -7.8037e-01, -1.0470e-01, -9.7738e-02,\n",
      "        -1.0886e-01, -1.0767e-01, -1.2056e-01, -1.1792e-01, -1.2493e-01,\n",
      "        -1.1316e-01, -1.1160e-01, -1.2168e-01, -1.1358e-01, -1.2186e-01],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -98700, loss is -0.03609154558361087\n",
      "Action prob: [0.8119865  0.18801354], Action: 0, state: 0\n",
      "Action prob: [0.8133486 0.1866514], Action: 1, state: 0\n",
      "Action prob: [0.7882543  0.21174568], Action: 0, state: 4\n",
      "Action prob: [0.7882543  0.21174568], Action: 0, state: 4\n",
      "Action prob: [0.81317323 0.18682681], Action: 0, state: 0\n",
      "Action prob: [0.8145838  0.18541625], Action: 0, state: 1\n",
      "Action prob: [0.804472   0.19552796], Action: 0, state: 1\n",
      "Action prob: [0.8155208  0.18447918], Action: 0, state: 1\n",
      "Action prob: [0.81189656 0.18810344], Action: 0, state: 1\n",
      "Action prob: [0.80992913 0.19007084], Action: 0, state: 1\n",
      "Action prob: [0.8186707  0.18132935], Action: 0, state: 1\n",
      "Action prob: [0.81358916 0.18641083], Action: 0, state: 2\n",
      "Action prob: [0.8129311  0.18706885], Action: 0, state: 3\n",
      "Action prob: [0.8057001  0.19429988], Action: 0, state: 8\n",
      "Action prob: [0.82159096 0.17840904], Action: 1, state: 8\n",
      "Action prob: [0.8023219  0.19767803], Action: 0, state: 8\n",
      "Action prob: [0.81715536 0.1828447 ], Action: 1, state: 8\n",
      "Action prob: [0.8000403  0.19995977], Action: 0, state: 8\n",
      "Action prob: [0.7906254  0.20937458], Action: 0, state: 8\n",
      "Action prob: [0.81093246 0.1890675 ], Action: 1, state: 8\n",
      "Action prob: [0.80457467 0.19542536], Action: 0, state: 8\n",
      "Action prob: [0.80777377 0.19222622], Action: 0, state: 8\n",
      "Action prob: [0.8211385  0.17886151], Action: 0, state: 8\n",
      "Action prob: [0.81232953 0.18767048], Action: 0, state: 8\n",
      "Action prob: [0.8009126  0.19908741], Action: 0, state: 8\n",
      "Action prob: [0.82048005 0.17951988], Action: 0, state: 8\n",
      "Action prob: [0.8231795  0.17682053], Action: 0, state: 8\n",
      "Action prob: [0.8015654  0.19843456], Action: 0, state: 8\n",
      "Action prob: [0.81401163 0.18598838], Action: 0, state: 8\n",
      "Action prob: [0.80929583 0.19070415], Action: 0, state: 8\n",
      "Action prob: [0.81083816 0.18916184], Action: 0, state: 8\n",
      "Action prob: [0.80402315 0.19597688], Action: 0, state: 8\n",
      "Action prob: [0.81004363 0.1899563 ], Action: 1, state: 8\n",
      "tensor([-0.2854, -0.4154, -0.1724, -0.2690, -0.0912,  0.0178,  0.1164,  0.1869,\n",
      "         0.2585,  0.3195,  0.3501,  0.3975,  0.4185,  0.3330,  1.9549,  0.1735,\n",
      "         0.8388,  0.0543,  0.0073, -0.2495, -0.0660, -0.0926, -0.1074, -0.1329,\n",
      "        -0.1597, -0.1559, -0.1645, -0.1979, -0.1928, -0.2057, -0.2102, -0.2243,\n",
      "        -1.7442], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -51300, loss is -0.008782645279358129\n",
      "Action prob: [0.8267136  0.17328632], Action: 0, state: 0\n",
      "Action prob: [0.8266691  0.17333093], Action: 0, state: 0\n",
      "Action prob: [0.82904106 0.1709589 ], Action: 0, state: 0\n",
      "Action prob: [0.8347441  0.16525589], Action: 1, state: 0\n",
      "Action prob: [0.7942963  0.20570369], Action: 1, state: 4\n",
      "Action prob: [0.7942963  0.20570369], Action: 0, state: 4\n",
      "Action prob: [0.7942963  0.20570369], Action: 0, state: 4\n",
      "Action prob: [0.7942963  0.20570369], Action: 0, state: 4\n",
      "Action prob: [0.7942963  0.20570369], Action: 1, state: 4\n",
      "Action prob: [0.7942963  0.20570369], Action: 0, state: 4\n",
      "Action prob: [0.7942963  0.20570369], Action: 0, state: 4\n",
      "Action prob: [0.8263803 0.1736197], Action: 0, state: 0\n",
      "Action prob: [0.8283157  0.17168432], Action: 0, state: 1\n",
      "Action prob: [0.82745713 0.17254286], Action: 0, state: 2\n",
      "Action prob: [0.8275382  0.17246187], Action: 0, state: 2\n",
      "Action prob: [0.82983845 0.17016152], Action: 0, state: 2\n",
      "Action prob: [0.8282209  0.17177907], Action: 0, state: 2\n",
      "Action prob: [0.8293869 0.1706131], Action: 0, state: 2\n",
      "Action prob: [0.8170504  0.18294963], Action: 0, state: 3\n",
      "Action prob: [0.8269972  0.17300285], Action: 0, state: 3\n",
      "Action prob: [0.82313716 0.17686287], Action: 0, state: 3\n",
      "Action prob: [0.82610124 0.17389877], Action: 0, state: 3\n",
      "Action prob: [0.82700896 0.17299104], Action: 0, state: 3\n",
      "Action prob: [0.81867224 0.18132775], Action: 0, state: 3\n",
      "Action prob: [0.8263494  0.17365058], Action: 0, state: 3\n",
      "Action prob: [0.8277106  0.17228934], Action: 0, state: 3\n",
      "Action prob: [0.82300776 0.1769922 ], Action: 1, state: 3\n",
      "Action prob: [0.7942963  0.20570369], Action: 0, state: 7\n",
      "Action prob: [0.7942963  0.20570369], Action: 0, state: 7\n",
      "Action prob: [0.82617277 0.1738272 ], Action: 0, state: 2\n",
      "Action prob: [0.8256944  0.17430563], Action: 0, state: 3\n",
      "Action prob: [0.82541674 0.17458324], Action: 0, state: 3\n",
      "Action prob: [0.8363776  0.16362238], Action: 0, state: 8\n",
      "Action prob: [0.8208387  0.17916127], Action: 1, state: 8\n",
      "Action prob: [0.825023   0.17497699], Action: 1, state: 8\n",
      "Action prob: [0.8149406  0.18505946], Action: 0, state: 8\n",
      "Action prob: [0.8456859  0.15431412], Action: 0, state: 8\n",
      "Action prob: [0.83866346 0.16133656], Action: 0, state: 8\n",
      "Action prob: [0.8369686  0.16303143], Action: 0, state: 8\n",
      "Action prob: [0.8401297  0.15987036], Action: 0, state: 8\n",
      "Action prob: [0.82402545 0.17597455], Action: 0, state: 8\n",
      "Action prob: [0.8298039  0.17019607], Action: 0, state: 8\n",
      "Action prob: [0.8207019  0.17929812], Action: 0, state: 8\n",
      "Action prob: [0.82346636 0.17653367], Action: 0, state: 8\n",
      "Action prob: [0.8235408  0.17645921], Action: 0, state: 8\n",
      "Action prob: [0.83624166 0.16375834], Action: 0, state: 8\n",
      "Action prob: [0.83557945 0.16442056], Action: 0, state: 8\n",
      "Action prob: [0.8288298  0.17117016], Action: 0, state: 8\n",
      "Action prob: [0.8351256  0.16487433], Action: 0, state: 8\n",
      "Action prob: [0.82365894 0.17634106], Action: 1, state: 8\n",
      "tensor([-9.2906e-01, -4.3744e-01, -1.9042e-02,  3.1783e+00,  1.5370e+00,\n",
      "         6.8517e-02, -6.3512e-02, -1.7574e-01, -1.8617e+00, -3.5221e-01,\n",
      "        -4.2113e-01, -2.5170e-01, -1.7530e-01, -1.2058e-01, -7.3198e-02,\n",
      "        -3.2497e-02,  1.1991e-03,  2.9905e-02,  4.8777e-02,  5.9023e-02,\n",
      "         7.1943e-02,  8.0182e-02,  8.7806e-02,  9.9729e-02,  1.0094e-01,\n",
      "         1.0501e-01,  1.0002e+00,  1.2867e-01,  1.2497e-01,  1.0779e-01,\n",
      "         1.1034e-01,  1.1242e-01,  9.5708e-02,  8.4755e-01,  7.9587e-01,\n",
      "         8.7116e-02,  6.6952e-02,  6.6357e-02,  6.3745e-02,  5.9587e-02,\n",
      "         6.3555e-02,  5.9088e-02,  6.0625e-02,  5.7959e-02,  5.6543e-02,\n",
      "         5.0999e-02,  5.0296e-02,  5.1743e-02,  4.8984e-02,  4.6628e-01],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -46300, loss is -0.1037716295301289\n",
      "Action prob: [0.8461316  0.15386844], Action: 0, state: 0\n",
      "Action prob: [0.84634095 0.1536591 ], Action: 0, state: 0\n",
      "Action prob: [0.8445835  0.15541649], Action: 0, state: 1\n",
      "Action prob: [0.8452404  0.15475959], Action: 0, state: 1\n",
      "Action prob: [0.8446644  0.15533556], Action: 0, state: 1\n",
      "Action prob: [0.8442056  0.15579438], Action: 0, state: 1\n",
      "Action prob: [0.83941054 0.16058947], Action: 0, state: 2\n",
      "Action prob: [0.8415316  0.15846843], Action: 1, state: 3\n",
      "Action prob: [0.80203533 0.19796461], Action: 0, state: 7\n",
      "Action prob: [0.80203533 0.19796461], Action: 0, state: 7\n",
      "Action prob: [0.8455547  0.15444525], Action: 0, state: 2\n",
      "Action prob: [0.8392128  0.16078722], Action: 0, state: 3\n",
      "Action prob: [0.8431186  0.15688133], Action: 0, state: 3\n",
      "Action prob: [0.8450979  0.15490213], Action: 0, state: 3\n",
      "Action prob: [0.8381433  0.16185676], Action: 0, state: 3\n",
      "Action prob: [0.8565209  0.14347912], Action: 0, state: 8\n",
      "Action prob: [0.8620907  0.13790934], Action: 0, state: 8\n",
      "Action prob: [0.8424772 0.1575228], Action: 0, state: 8\n",
      "Action prob: [0.85652727 0.14347272], Action: 0, state: 8\n",
      "Action prob: [0.85699964 0.14300033], Action: 0, state: 8\n",
      "Action prob: [0.8376469  0.16235313], Action: 0, state: 8\n",
      "Action prob: [0.8346011  0.16539891], Action: 0, state: 8\n",
      "Action prob: [0.85634357 0.14365643], Action: 0, state: 8\n",
      "Action prob: [0.8465583  0.15344167], Action: 0, state: 8\n",
      "Action prob: [0.85375994 0.14624007], Action: 0, state: 8\n",
      "Action prob: [0.8316965  0.16830352], Action: 0, state: 8\n",
      "Action prob: [0.85421854 0.14578144], Action: 0, state: 8\n",
      "Action prob: [0.8566201  0.14337996], Action: 0, state: 8\n",
      "Action prob: [0.8381188 0.1618812], Action: 1, state: 8\n",
      "Action prob: [0.8547209  0.14527906], Action: 0, state: 8\n",
      "Action prob: [0.8437927  0.15620731], Action: 0, state: 8\n",
      "Action prob: [0.8525235  0.14747643], Action: 0, state: 8\n",
      "Action prob: [0.83468693 0.16531308], Action: 0, state: 8\n",
      "Action prob: [0.84153867 0.15846133], Action: 0, state: 8\n",
      "Action prob: [0.8416564 0.1583436], Action: 0, state: 8\n",
      "Action prob: [0.83381516 0.16618486], Action: 0, state: 8\n",
      "Action prob: [0.8382304 0.1617696], Action: 0, state: 8\n",
      "Action prob: [0.85065895 0.14934103], Action: 0, state: 8\n",
      "Action prob: [0.83590263 0.16409734], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.84245956 0.1575405 ], Action: 0, state: 8\n",
      "Action prob: [0.8322483  0.16775179], Action: 0, state: 8\n",
      "Action prob: [0.85745543 0.14254463], Action: 0, state: 8\n",
      "Action prob: [0.8440887 0.1559113], Action: 0, state: 8\n",
      "Action prob: [0.85843265 0.14156736], Action: 0, state: 8\n",
      "Action prob: [0.85441816 0.14558186], Action: 0, state: 8\n",
      "Action prob: [0.83422625 0.16577375], Action: 0, state: 8\n",
      "Action prob: [0.8399422  0.16005774], Action: 0, state: 8\n",
      "Action prob: [0.83437854 0.16562149], Action: 1, state: 8\n",
      "Action prob: [0.85268086 0.14731908], Action: 0, state: 8\n",
      "Action prob: [0.8502436  0.14975637], Action: 0, state: 8\n",
      "tensor([-0.5323, -0.3319, -0.1815, -0.0499,  0.0615,  0.1569,  0.2365,  2.9044,\n",
      "         0.3055,  0.2695,  0.2422,  0.2737,  0.2835,  0.2939,  0.3211,  0.2246,\n",
      "         0.1686,  0.1491,  0.0997,  0.0696,  0.0509,  0.0268,  0.0047, -0.0117,\n",
      "        -0.0246, -0.0421, -0.0457, -0.0530, -0.7050, -0.0667, -0.0777, -0.0773,\n",
      "        -0.0918, -0.0910, -0.0939, -0.1016, -0.1008, -0.0940, -0.1058, -0.1024,\n",
      "        -0.1109, -0.0937, -0.1041, -0.0943, -0.0977, -0.1131, -0.1092, -1.1298,\n",
      "        -0.1004, -0.1025], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -100300, loss is -0.022126456017590806\n",
      "Action prob: [0.86532    0.13467997], Action: 1, state: 0\n",
      "Action prob: [0.8071299  0.19287007], Action: 0, state: 4\n",
      "Action prob: [0.8071299  0.19287007], Action: 0, state: 4\n",
      "Action prob: [0.8071299  0.19287007], Action: 1, state: 4\n",
      "Action prob: [0.8071299  0.19287007], Action: 0, state: 4\n",
      "Action prob: [0.8071299  0.19287007], Action: 0, state: 4\n",
      "Action prob: [0.8610856  0.13891439], Action: 0, state: 0\n",
      "Action prob: [0.8625456  0.13745439], Action: 0, state: 0\n",
      "Action prob: [0.86096364 0.13903637], Action: 1, state: 0\n",
      "Action prob: [0.8071299  0.19287007], Action: 0, state: 4\n",
      "Action prob: [0.86404824 0.13595173], Action: 1, state: 0\n",
      "Action prob: [0.8071299  0.19287007], Action: 1, state: 4\n",
      "Action prob: [0.8071299  0.19287007], Action: 0, state: 4\n",
      "Action prob: [0.8071299  0.19287007], Action: 1, state: 4\n",
      "Action prob: [0.86026514 0.13973486], Action: 0, state: 0\n",
      "Action prob: [0.8625776  0.13742238], Action: 1, state: 0\n",
      "Action prob: [0.8071299  0.19287007], Action: 0, state: 4\n",
      "Action prob: [0.8071299  0.19287007], Action: 0, state: 4\n",
      "Action prob: [0.8632129 0.1367871], Action: 0, state: 0\n",
      "Action prob: [0.8615206  0.13847935], Action: 0, state: 0\n",
      "Action prob: [0.8712771 0.1287229], Action: 0, state: 0\n",
      "tensor([ 4.2881e+00,  1.8834e-01, -4.1118e-02, -1.8138e+00, -4.0194e-01,\n",
      "        -5.4286e-01, -2.1170e-01, -6.8786e-02,  6.7591e-01, -1.5508e-04,\n",
      "         1.1631e+00,  5.5108e-01,  2.6574e-02, -9.0815e-02,  3.7548e-02,\n",
      "         1.0091e+00,  8.5357e-02,  6.5313e-02,  6.8229e-02,  8.9288e-02,\n",
      "         9.8374e-02], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode 4500, loss is -0.246430129614445\n",
      "Action prob: [0.88599354 0.11400644], Action: 0, state: 0\n",
      "Action prob: [0.887185   0.11281502], Action: 0, state: 0\n",
      "Action prob: [0.8829114  0.11708862], Action: 0, state: 1\n",
      "Action prob: [0.8783134  0.12168663], Action: 0, state: 2\n",
      "Action prob: [0.8893334  0.11066656], Action: 0, state: 2\n",
      "Action prob: [0.88341767 0.11658238], Action: 0, state: 3\n",
      "Action prob: [0.87535185 0.12464817], Action: 0, state: 3\n",
      "Action prob: [0.896926   0.10307396], Action: 0, state: 8\n",
      "Action prob: [0.8758827  0.12411728], Action: 0, state: 8\n",
      "Action prob: [0.8853169  0.11468313], Action: 0, state: 8\n",
      "Action prob: [0.8991601  0.10083992], Action: 0, state: 8\n",
      "Action prob: [0.88416415 0.11583588], Action: 0, state: 8\n",
      "Action prob: [0.87430286 0.12569718], Action: 1, state: 8\n",
      "Action prob: [0.87470555 0.12529443], Action: 0, state: 8\n",
      "Action prob: [0.87593    0.12407003], Action: 0, state: 8\n",
      "Action prob: [0.8839815  0.11601854], Action: 0, state: 8\n",
      "Action prob: [0.8817485  0.11825148], Action: 0, state: 8\n",
      "Action prob: [0.8739785 0.1260215], Action: 0, state: 8\n",
      "Action prob: [0.8784929  0.12150712], Action: 0, state: 8\n",
      "Action prob: [0.89714885 0.10285114], Action: 0, state: 8\n",
      "Action prob: [0.8725871  0.12741292], Action: 0, state: 8\n",
      "Action prob: [0.8947855  0.10521444], Action: 0, state: 8\n",
      "Action prob: [0.877713   0.12228698], Action: 1, state: 8\n",
      "tensor([ 0.0305,  0.0807,  0.1243,  0.1612,  0.1700,  0.1934,  0.2202,  0.1279,\n",
      "         0.1019,  0.0516,  0.0138, -0.0148, -0.6890, -0.0686, -0.0882, -0.0982,\n",
      "        -0.1142, -0.1349, -0.1401, -0.1247, -0.1645, -0.1397, -2.7279],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -42500, loss is 0.1404053861620738\n",
      "Action prob: [0.9019603  0.09803963], Action: 0, state: 0\n",
      "Action prob: [0.90115    0.09885002], Action: 0, state: 0\n",
      "Action prob: [0.9050486  0.09495141], Action: 0, state: 1\n",
      "Action prob: [0.9083824  0.09161767], Action: 1, state: 1\n",
      "Action prob: [0.81379867 0.18620133], Action: 0, state: 5\n",
      "Action prob: [0.9058237  0.09417623], Action: 1, state: 0\n",
      "Action prob: [0.81379867 0.18620133], Action: 0, state: 4\n",
      "Action prob: [0.90500546 0.09499457], Action: 0, state: 0\n",
      "Action prob: [0.9029225  0.09707748], Action: 0, state: 1\n",
      "Action prob: [0.9019097  0.09809034], Action: 0, state: 2\n",
      "Action prob: [0.8989846  0.10101537], Action: 0, state: 3\n",
      "Action prob: [0.91139144 0.08860862], Action: 0, state: 8\n",
      "Action prob: [0.9014679  0.09853212], Action: 0, state: 8\n",
      "Action prob: [0.88554186 0.11445812], Action: 0, state: 8\n",
      "Action prob: [0.89679307 0.10320688], Action: 0, state: 8\n",
      "Action prob: [0.9134351  0.08656493], Action: 0, state: 8\n",
      "Action prob: [0.8927984  0.10720158], Action: 0, state: 8\n",
      "Action prob: [0.888687   0.11131302], Action: 0, state: 8\n",
      "Action prob: [0.90589386 0.09410611], Action: 0, state: 8\n",
      "Action prob: [0.91613066 0.08386932], Action: 0, state: 8\n",
      "Action prob: [0.8910404  0.10895963], Action: 0, state: 8\n",
      "Action prob: [0.9153898  0.08461022], Action: 1, state: 8\n",
      "Action prob: [0.9117384  0.08826162], Action: 0, state: 8\n",
      "Action prob: [0.90016407 0.09983599], Action: 0, state: 8\n",
      "Action prob: [0.9104738 0.0895261], Action: 0, state: 8\n",
      "Action prob: [0.8901449  0.10985513], Action: 0, state: 8\n",
      "Action prob: [0.90307814 0.0969219 ], Action: 1, state: 8\n",
      "tensor([-0.1184, -0.0324,  0.0327,  2.0828,  0.1267,  2.4834,  0.1784,  0.1179,\n",
      "         0.1452,  0.1656,  0.1812,  0.1120,  0.0817,  0.0524,  0.0139, -0.0118,\n",
      "        -0.0396, -0.0632, -0.0685, -0.0725, -0.1087, -2.5677, -0.1037, -0.1254,\n",
      "        -0.1174, -0.1516, -3.1416], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Reward for this episode -41000, loss is 0.03513790330572554\n",
      "Action prob: [0.9129322  0.08706777], Action: 0, state: 0\n",
      "Action prob: [0.9118233  0.08817676], Action: 1, state: 0\n",
      "Action prob: [0.81419873 0.18580125], Action: 1, state: 4\n",
      "Action prob: [0.81419873 0.18580125], Action: 0, state: 4\n",
      "Action prob: [0.81419873 0.18580125], Action: 0, state: 4\n",
      "Action prob: [0.81419873 0.18580125], Action: 0, state: 4\n",
      "Action prob: [0.9112044  0.08879563], Action: 1, state: 0\n",
      "Action prob: [0.81419873 0.18580125], Action: 1, state: 4\n",
      "Action prob: [0.81419873 0.18580125], Action: 0, state: 4\n",
      "Action prob: [0.921861   0.07813897], Action: 0, state: 0\n",
      "Action prob: [0.9143849  0.08561508], Action: 0, state: 0\n",
      "Action prob: [0.91292036 0.08707961], Action: 0, state: 0\n",
      "Action prob: [0.9189041  0.08109584], Action: 0, state: 1\n",
      "Action prob: [0.91459525 0.08540475], Action: 0, state: 2\n",
      "Action prob: [0.9170129  0.08298714], Action: 0, state: 2\n",
      "Action prob: [0.90912235 0.09087769], Action: 0, state: 3\n",
      "Action prob: [0.92658186 0.07341815], Action: 0, state: 8\n",
      "Action prob: [0.90322256 0.09677751], Action: 0, state: 8\n",
      "Action prob: [0.9017889  0.09821116], Action: 0, state: 8\n",
      "Action prob: [0.91307646 0.08692357], Action: 0, state: 8\n",
      "Action prob: [0.9123538  0.08764619], Action: 0, state: 8\n",
      "Action prob: [0.9000437  0.09995632], Action: 1, state: 8\n",
      "Action prob: [0.91480994 0.08519001], Action: 0, state: 8\n",
      "Action prob: [0.92079294 0.07920706], Action: 0, state: 8\n",
      "Action prob: [0.9212371  0.07876287], Action: 0, state: 8\n",
      "Action prob: [0.9097989  0.09020114], Action: 0, state: 8\n",
      "Action prob: [0.9038041  0.09619591], Action: 0, state: 8\n",
      "Action prob: [0.9094575  0.09054247], Action: 0, state: 8\n",
      "Action prob: [0.89663845 0.10336152], Action: 0, state: 8\n",
      "Action prob: [0.93292665 0.06707331], Action: 1, state: 8\n",
      "Action prob: [0.9335684  0.06643157], Action: 1, state: 8\n",
      "Action prob: [0.9017029  0.09829706], Action: 0, state: 8\n",
      "Action prob: [0.92340964 0.0765903 ], Action: 0, state: 8\n",
      "Action prob: [0.900041   0.09995898], Action: 0, state: 8\n",
      "Action prob: [0.9033023  0.09669767], Action: 0, state: 8\n",
      "Action prob: [0.92108303 0.078917  ], Action: 0, state: 8\n",
      "Action prob: [0.91300744 0.08699261], Action: 0, state: 8\n",
      "Action prob: [0.90195787 0.09804208], Action: 0, state: 8\n",
      "Action prob: [0.9006259  0.09937406], Action: 0, state: 8\n",
      "Action prob: [0.9253296  0.07467034], Action: 0, state: 8\n",
      "Action prob: [0.92343175 0.07656831], Action: 0, state: 8\n",
      "Action prob: [0.8971706  0.10282934], Action: 0, state: 8\n",
      "Action prob: [0.90401787 0.09598207], Action: 0, state: 8\n",
      "Action prob: [0.9284639 0.0715361], Action: 0, state: 8\n",
      "Action prob: [0.92263484 0.07736514], Action: 0, state: 8\n",
      "Action prob: [0.9205468  0.07945318], Action: 0, state: 8\n",
      "Action prob: [0.91825646 0.08174354], Action: 0, state: 8\n",
      "Action prob: [0.9240931 0.0759069], Action: 0, state: 8\n",
      "Action prob: [0.9229852 0.0770148], Action: 0, state: 8\n",
      "Action prob: [0.9231964  0.07680362], Action: 0, state: 8\n",
      "tensor([ 4.9969e-02,  5.5536e+00,  2.6056e+00,  1.8913e-01,  7.9412e-02,\n",
      "        -1.3850e-02,  1.7045e+00,  6.3306e-01,  2.0039e-02,  4.6471e-02,\n",
      "         8.7160e-02,  1.1990e-01,  1.3345e-01,  1.5852e-01,  1.6840e-01,\n",
      "         1.9371e-01,  1.2030e-01,  1.2116e-01,  8.9028e-02,  5.2874e-02,\n",
      "         3.1521e-02,  3.2590e-01, -2.6984e-03, -1.4552e-02, -2.4651e-02,\n",
      "        -3.8380e-02, -5.0135e-02, -5.4279e-02, -6.9468e-02, -1.8692e+00,\n",
      "        -2.0028e+00, -8.0543e-02, -6.4721e-02, -8.8569e-02, -8.8012e-02,\n",
      "        -7.2850e-02, -8.2261e-02, -9.4816e-02, -9.7509e-02, -7.3141e-02,\n",
      "        -7.5810e-02, -1.0412e-01, -9.7494e-02, -7.2134e-02, -7.8642e-02,\n",
      "        -8.1193e-02, -8.3933e-02, -7.7930e-02, -7.9315e-02, -7.9260e-02],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -100000, loss is -0.13542722120393302\n",
      "Action prob: [0.9251253  0.07487468], Action: 0, state: 0\n",
      "Action prob: [0.92307526 0.0769247 ], Action: 0, state: 0\n",
      "Action prob: [0.9231879 0.0768121], Action: 0, state: 1\n",
      "Action prob: [0.9229383  0.07706178], Action: 0, state: 1\n",
      "Action prob: [0.9250718  0.07492825], Action: 0, state: 1\n",
      "Action prob: [0.9253244  0.07467563], Action: 0, state: 1\n",
      "Action prob: [0.92439944 0.07560058], Action: 0, state: 1\n",
      "Action prob: [0.92545956 0.07454044], Action: 0, state: 1\n",
      "Action prob: [0.92197967 0.07802033], Action: 0, state: 1\n",
      "Action prob: [0.9267947  0.07320526], Action: 0, state: 2\n",
      "Action prob: [0.9232994  0.07670061], Action: 0, state: 3\n",
      "Action prob: [0.93068403 0.06931601], Action: 1, state: 8\n",
      "Action prob: [0.93680185 0.06319816], Action: 0, state: 8\n",
      "Action prob: [0.9102398  0.08976024], Action: 0, state: 8\n",
      "Action prob: [0.9405933  0.05940666], Action: 0, state: 8\n",
      "Action prob: [0.91350186 0.08649812], Action: 0, state: 8\n",
      "Action prob: [0.912357 0.087643], Action: 0, state: 8\n",
      "Action prob: [0.93638974 0.06361033], Action: 0, state: 8\n",
      "Action prob: [0.9344122  0.06558781], Action: 0, state: 8\n",
      "Action prob: [0.93377036 0.06622969], Action: 0, state: 8\n",
      "Action prob: [0.9191958 0.0808043], Action: 0, state: 8\n",
      "Action prob: [0.9224575 0.0775425], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.9346297  0.06537025], Action: 0, state: 8\n",
      "Action prob: [0.93251514 0.06748482], Action: 0, state: 8\n",
      "Action prob: [0.91618377 0.08381627], Action: 0, state: 8\n",
      "Action prob: [0.9337367  0.06626336], Action: 0, state: 8\n",
      "Action prob: [0.9222171  0.07778291], Action: 0, state: 8\n",
      "Action prob: [0.91777426 0.08222581], Action: 0, state: 8\n",
      "Action prob: [0.9169485  0.08305155], Action: 0, state: 8\n",
      "Action prob: [0.9216959  0.07830405], Action: 0, state: 8\n",
      "Action prob: [0.9334154  0.06658453], Action: 0, state: 8\n",
      "Action prob: [0.91714287 0.08285711], Action: 0, state: 8\n",
      "Action prob: [0.93437535 0.0656246 ], Action: 0, state: 8\n",
      "Action prob: [0.93318075 0.06681922], Action: 0, state: 8\n",
      "Action prob: [0.9203578  0.07964221], Action: 0, state: 8\n",
      "Action prob: [0.91240424 0.08759581], Action: 0, state: 8\n",
      "Action prob: [0.9355833  0.06441669], Action: 0, state: 8\n",
      "Action prob: [0.9367958  0.06320424], Action: 0, state: 8\n",
      "Action prob: [0.91627747 0.08372253], Action: 0, state: 8\n",
      "Action prob: [0.9348221  0.06517794], Action: 0, state: 8\n",
      "Action prob: [0.92409253 0.07590747], Action: 0, state: 8\n",
      "Action prob: [0.91315293 0.08684711], Action: 0, state: 8\n",
      "Action prob: [0.92441654 0.07558342], Action: 1, state: 8\n",
      "Action prob: [0.9094635  0.09053647], Action: 0, state: 8\n",
      "Action prob: [0.91341573 0.08658426], Action: 0, state: 8\n",
      "Action prob: [0.91199166 0.08800835], Action: 0, state: 8\n",
      "Action prob: [0.91241086 0.08758916], Action: 0, state: 8\n",
      "Action prob: [0.92182475 0.0781752 ], Action: 0, state: 8\n",
      "Action prob: [0.9040854  0.09591457], Action: 0, state: 8\n",
      "Action prob: [0.93504214 0.06495782], Action: 0, state: 8\n",
      "tensor([-1.1332e-01, -5.1375e-02, -1.5136e-03,  4.0940e-02,  7.4811e-02,\n",
      "         1.0424e-01,  1.3114e-01,  1.5064e-01,  1.7705e-01,  1.7919e-01,\n",
      "         1.9562e-01,  5.2592e+00,  1.0195e-01,  1.1419e-01,  5.6275e-02,\n",
      "         6.0418e-02,  4.1684e-02,  1.7947e-02,  8.0665e-03, -8.3142e-04,\n",
      "        -1.0407e-02, -1.7611e-02, -2.0192e-02, -2.5648e-02, -3.7223e-02,\n",
      "        -3.2542e-02, -4.1836e-02, -4.7395e-02, -5.0523e-02, -4.9618e-02,\n",
      "        -4.3440e-02, -5.6140e-02, -4.5133e-02, -4.6915e-02, -5.7251e-02,\n",
      "        -6.4131e-02, -4.7131e-02, -4.6674e-02, -6.3028e-02, -4.8926e-02,\n",
      "        -5.7647e-02, -6.6677e-02, -1.9034e+00, -7.0196e-02, -6.7192e-02,\n",
      "        -6.8526e-02, -6.8334e-02, -6.0794e-02, -7.5426e-02, -5.0308e-02],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -111400, loss is -0.06412133191123653\n",
      "Action prob: [0.9403022  0.05969778], Action: 0, state: 0\n",
      "Action prob: [0.9356292  0.06437087], Action: 0, state: 1\n",
      "Action prob: [0.9380212  0.06197887], Action: 0, state: 1\n",
      "Action prob: [0.936344   0.06365594], Action: 0, state: 1\n",
      "Action prob: [0.93762445 0.06237561], Action: 0, state: 1\n",
      "Action prob: [0.9379591  0.06204091], Action: 0, state: 1\n",
      "Action prob: [0.9367944  0.06320564], Action: 0, state: 2\n",
      "Action prob: [0.9380948  0.06190523], Action: 0, state: 3\n",
      "Action prob: [0.92865914 0.07134086], Action: 0, state: 3\n",
      "Action prob: [0.9340003  0.06599966], Action: 0, state: 3\n",
      "Action prob: [0.9357873  0.06421266], Action: 0, state: 8\n",
      "Action prob: [0.94404125 0.05595876], Action: 0, state: 8\n",
      "Action prob: [0.92394924 0.07605073], Action: 0, state: 8\n",
      "Action prob: [0.9440077  0.05599227], Action: 0, state: 8\n",
      "Action prob: [0.94239855 0.05760146], Action: 0, state: 8\n",
      "Action prob: [0.9382715  0.06172854], Action: 0, state: 8\n",
      "Action prob: [0.91757417 0.08242586], Action: 0, state: 8\n",
      "Action prob: [0.9369838  0.06301622], Action: 0, state: 8\n",
      "Action prob: [0.93515253 0.06484749], Action: 0, state: 8\n",
      "Action prob: [0.92494076 0.07505921], Action: 0, state: 8\n",
      "Action prob: [0.9477655  0.05223452], Action: 0, state: 8\n",
      "Action prob: [0.94764507 0.052355  ], Action: 0, state: 8\n",
      "Action prob: [0.93639827 0.06360176], Action: 0, state: 8\n",
      "Action prob: [0.9359129 0.0640871], Action: 0, state: 8\n",
      "Action prob: [0.94391125 0.05608877], Action: 0, state: 8\n",
      "Action prob: [0.94397783 0.05602212], Action: 0, state: 8\n",
      "Action prob: [0.94369537 0.05630468], Action: 0, state: 8\n",
      "Action prob: [0.9271307  0.07286927], Action: 0, state: 8\n",
      "Action prob: [0.9466554  0.05334462], Action: 0, state: 8\n",
      "Action prob: [0.9451446  0.05485545], Action: 0, state: 8\n",
      "Action prob: [0.9275389  0.07246107], Action: 0, state: 8\n",
      "Action prob: [0.9360169  0.06398302], Action: 0, state: 8\n",
      "Action prob: [0.92676806 0.07323194], Action: 0, state: 8\n",
      "Action prob: [0.9368653  0.06313467], Action: 0, state: 8\n",
      "Action prob: [0.9547928  0.04520721], Action: 0, state: 8\n",
      "Action prob: [0.9263861 0.0736139], Action: 0, state: 8\n",
      "Action prob: [0.9365509  0.06344905], Action: 0, state: 8\n",
      "Action prob: [0.9231798  0.07682025], Action: 0, state: 8\n",
      "Action prob: [0.95437694 0.04562307], Action: 0, state: 8\n",
      "Action prob: [0.93933046 0.06066956], Action: 0, state: 8\n",
      "Action prob: [0.9395157  0.06048428], Action: 0, state: 8\n",
      "Action prob: [0.9283655  0.07163448], Action: 0, state: 8\n",
      "Action prob: [0.9440696  0.05593033], Action: 0, state: 8\n",
      "Action prob: [0.9363447  0.06365531], Action: 0, state: 8\n",
      "Action prob: [0.9467727  0.05322731], Action: 0, state: 8\n",
      "Action prob: [0.9457456  0.05425439], Action: 0, state: 8\n",
      "Action prob: [0.9395894  0.06041063], Action: 0, state: 8\n",
      "Action prob: [0.94535613 0.05464387], Action: 0, state: 8\n",
      "Action prob: [0.9234487  0.07655125], Action: 0, state: 8\n",
      "Action prob: [0.92724043 0.07275955], Action: 1, state: 8\n",
      "tensor([-0.0294,  0.0092,  0.0423,  0.0728,  0.0956,  0.1157,  0.1338,  0.1392,\n",
      "         0.1694,  0.1626,  0.1265,  0.0865,  0.0916,  0.0499,  0.0367,  0.0259,\n",
      "         0.0196,  0.0049, -0.0037, -0.0129, -0.0139, -0.0182, -0.0267, -0.0307,\n",
      "        -0.0296, -0.0319, -0.0341, -0.0468, -0.0353, -0.0376, -0.0515, -0.0463,\n",
      "        -0.0543, -0.0473, -0.0340, -0.0568, -0.0491, -0.0604, -0.0355, -0.0479,\n",
      "        -0.0479, -0.0573, -0.0446, -0.0511, -0.0426, -0.0435, -0.0487, -0.0440,\n",
      "        -0.0624, -2.0551], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -116200, loss is 0.03896824431067913\n",
      "Action prob: [0.9451265  0.05487358], Action: 0, state: 0\n",
      "Action prob: [0.9440373  0.05596264], Action: 0, state: 0\n",
      "Action prob: [0.94505686 0.05494311], Action: 0, state: 0\n",
      "Action prob: [0.9445272 0.0554728], Action: 0, state: 1\n",
      "Action prob: [0.94590074 0.05409925], Action: 0, state: 2\n",
      "Action prob: [0.94573694 0.05426304], Action: 0, state: 2\n",
      "Action prob: [0.9459374  0.05406255], Action: 0, state: 3\n",
      "Action prob: [0.9351311 0.0648689], Action: 0, state: 3\n",
      "Action prob: [0.9440028  0.05599724], Action: 0, state: 3\n",
      "Action prob: [0.9462617  0.05373829], Action: 0, state: 3\n",
      "Action prob: [0.9499987  0.05000136], Action: 0, state: 3\n",
      "Action prob: [0.9331081 0.0668919], Action: 0, state: 8\n",
      "Action prob: [0.9324312  0.06756879], Action: 1, state: 8\n",
      "Action prob: [0.9555203  0.04447974], Action: 0, state: 8\n",
      "Action prob: [0.9333888  0.06661113], Action: 0, state: 8\n",
      "Action prob: [0.95574224 0.04425777], Action: 0, state: 8\n",
      "Action prob: [0.9349894  0.06501057], Action: 0, state: 8\n",
      "Action prob: [0.9464761  0.05352394], Action: 0, state: 8\n",
      "Action prob: [0.9560774  0.04392258], Action: 0, state: 8\n",
      "Action prob: [0.9360166 0.0639834], Action: 0, state: 8\n",
      "Action prob: [0.95437384 0.04562623], Action: 0, state: 8\n",
      "Action prob: [0.93350506 0.06649498], Action: 0, state: 8\n",
      "Action prob: [0.95238316 0.04761683], Action: 0, state: 8\n",
      "Action prob: [0.9414826 0.0585174], Action: 0, state: 8\n",
      "Action prob: [0.9495665  0.05043356], Action: 1, state: 8\n",
      "Action prob: [0.9551735  0.04482651], Action: 0, state: 8\n",
      "Action prob: [0.9532365  0.04676348], Action: 0, state: 8\n",
      "Action prob: [0.94681346 0.05318659], Action: 0, state: 8\n",
      "Action prob: [0.9344477  0.06555233], Action: 0, state: 8\n",
      "Action prob: [0.9544696  0.04553039], Action: 0, state: 8\n",
      "Action prob: [0.9468352  0.05316479], Action: 0, state: 8\n",
      "Action prob: [0.93539286 0.06460714], Action: 0, state: 8\n",
      "Action prob: [0.952823   0.04717704], Action: 0, state: 8\n",
      "Action prob: [0.9350168 0.0649832], Action: 0, state: 8\n",
      "Action prob: [0.92549866 0.07450131], Action: 0, state: 8\n",
      "Action prob: [0.93663687 0.06336313], Action: 0, state: 8\n",
      "Action prob: [0.9521327  0.04786731], Action: 0, state: 8\n",
      "Action prob: [0.93263835 0.06736172], Action: 0, state: 8\n",
      "Action prob: [0.93446183 0.0655381 ], Action: 0, state: 8\n",
      "Action prob: [0.9541243  0.04587571], Action: 0, state: 8\n",
      "Action prob: [0.9574581  0.04254191], Action: 0, state: 8\n",
      "Action prob: [0.93425703 0.0657429 ], Action: 0, state: 8\n",
      "Action prob: [0.93322444 0.06677556], Action: 0, state: 8\n",
      "Action prob: [0.9333771  0.06662287], Action: 1, state: 8\n",
      "tensor([-6.2546e-02, -1.9567e-02,  1.7713e-02,  4.6407e-02,  6.6224e-02,\n",
      "         8.4335e-02,  9.3490e-02,  1.2254e-01,  1.1238e-01,  1.1351e-01,\n",
      "         1.0997e-01,  1.1701e-01,  3.5144e+00,  4.4421e-02,  4.8085e-02,\n",
      "         2.0851e-02,  1.7426e-02,  4.8435e-03, -2.5807e-03, -1.1977e-02,\n",
      "        -1.3368e-02, -2.5846e-02, -2.2031e-02, -3.1123e-02, -1.7057e+00,\n",
      "        -2.8327e-02, -3.1480e-02, -3.7766e-02, -4.8792e-02, -3.4670e-02,\n",
      "        -4.1776e-02, -5.2248e-02, -3.8528e-02, -5.4422e-02, -6.3545e-02,\n",
      "        -5.4328e-02, -4.1092e-02, -5.8886e-02, -5.7619e-02, -4.0143e-02,\n",
      "        -3.7339e-02, -5.8643e-02, -5.9801e-02, -2.3506e+00],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -91000, loss is 0.012526586402115826\n",
      "Action prob: [0.95401335 0.04598664], Action: 0, state: 0\n",
      "Action prob: [0.9549454 0.0450546], Action: 0, state: 1\n",
      "Action prob: [0.9554582  0.04454174], Action: 0, state: 1\n",
      "Action prob: [0.95272475 0.0472752 ], Action: 0, state: 1\n",
      "Action prob: [0.9484578  0.05154221], Action: 0, state: 1\n",
      "Action prob: [0.947476 0.052524], Action: 0, state: 1\n",
      "Action prob: [0.951006   0.04899405], Action: 0, state: 1\n",
      "Action prob: [0.9524432  0.04755678], Action: 0, state: 1\n",
      "Action prob: [0.9504207  0.04957931], Action: 0, state: 1\n",
      "Action prob: [0.9597133  0.04028675], Action: 0, state: 9\n",
      "Action prob: [0.95330477 0.04669521], Action: 0, state: 9\n",
      "Action prob: [0.94323015 0.0567699 ], Action: 0, state: 9\n",
      "Action prob: [0.9598692  0.04013083], Action: 0, state: 9\n",
      "Action prob: [0.95839596 0.04160401], Action: 0, state: 9\n",
      "Action prob: [0.9572414 0.0427586], Action: 0, state: 9\n",
      "Action prob: [0.94272834 0.05727164], Action: 0, state: 9\n",
      "Action prob: [0.94213617 0.05786381], Action: 0, state: 9\n",
      "Action prob: [0.96114707 0.03885291], Action: 1, state: 9\n",
      "Action prob: [0.9511394  0.04886061], Action: 0, state: 9\n",
      "Action prob: [0.9583092  0.04169082], Action: 0, state: 9\n",
      "Action prob: [0.9415462  0.05845382], Action: 0, state: 9\n",
      "Action prob: [0.9532794 0.0467206], Action: 0, state: 9\n",
      "Action prob: [0.951895   0.04810502], Action: 0, state: 9\n",
      "Action prob: [0.9621389  0.03786115], Action: 0, state: 9\n",
      "Action prob: [0.9598722  0.04012784], Action: 0, state: 9\n",
      "Action prob: [0.94617313 0.05382689], Action: 0, state: 9\n",
      "Action prob: [0.96035093 0.03964904], Action: 0, state: 9\n",
      "Action prob: [0.93932635 0.06067368], Action: 0, state: 9\n",
      "Action prob: [0.96013594 0.03986399], Action: 0, state: 9\n",
      "Action prob: [0.9405836 0.0594164], Action: 0, state: 9\n",
      "Action prob: [0.94241124 0.05758875], Action: 1, state: 9\n",
      "Action prob: [0.9585711  0.04142893], Action: 0, state: 9\n",
      "Action prob: [0.9361495  0.06385055], Action: 0, state: 9\n",
      "Action prob: [0.9602131  0.03978688], Action: 0, state: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.95885485 0.0411451 ], Action: 0, state: 9\n",
      "Action prob: [0.94269043 0.05730958], Action: 0, state: 9\n",
      "Action prob: [0.9404583  0.05954165], Action: 0, state: 9\n",
      "Action prob: [0.9605966  0.03940338], Action: 0, state: 9\n",
      "Action prob: [0.9430054  0.05699464], Action: 0, state: 9\n",
      "Action prob: [0.96762264 0.03237736], Action: 0, state: 9\n",
      "Action prob: [0.93998486 0.0600152 ], Action: 0, state: 9\n",
      "Action prob: [0.9519572  0.04804278], Action: 0, state: 9\n",
      "Action prob: [0.9601354  0.03986461], Action: 0, state: 9\n",
      "Action prob: [0.9603195  0.03968046], Action: 0, state: 9\n",
      "Action prob: [0.9498019  0.05019807], Action: 0, state: 9\n",
      "Action prob: [0.9552847  0.04471531], Action: 0, state: 9\n",
      "Action prob: [0.96041757 0.03958246], Action: 0, state: 9\n",
      "Action prob: [0.9419894 0.0580106], Action: 0, state: 9\n",
      "Action prob: [0.9621062  0.03789375], Action: 0, state: 9\n",
      "Action prob: [0.95915985 0.04084014], Action: 0, state: 9\n",
      "tensor([-1.8696e-01, -1.2340e-01, -7.1816e-02, -3.1030e-02,  8.1697e-03,\n",
      "         4.4794e-02,  7.0565e-02,  9.2236e-02,  1.1737e-01,  7.8790e-02,\n",
      "         7.5693e-02,  7.5958e-02,  4.3371e-02,  3.6302e-02,  2.9731e-02,\n",
      "         3.1406e-02,  2.4251e-02,  9.7451e-01,  1.0482e-02,  5.6241e-03,\n",
      "         4.0036e-03,  5.1256e-04, -1.8084e-03, -2.9707e-03, -4.5546e-03,\n",
      "        -7.7636e-03, -6.6776e-03, -1.1648e-02, -8.2972e-03, -1.3424e-02,\n",
      "        -6.6242e-01, -1.0284e-02, -1.6652e-02, -1.0568e-02, -1.1220e-02,\n",
      "        -1.6099e-02, -1.7044e-02, -1.1328e-02, -1.6743e-02, -9.4889e-03,\n",
      "        -1.8001e-02, -1.4426e-02, -1.1994e-02, -1.2001e-02, -1.5334e-02,\n",
      "        -1.3672e-02, -1.2109e-02, -1.7966e-02, -1.1640e-02, -1.2589e-02],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -34800, loss is -0.006636615264455943\n",
      "Action prob: [0.9560892  0.04391076], Action: 0, state: 0\n",
      "Action prob: [0.95808226 0.0419177 ], Action: 0, state: 0\n",
      "Action prob: [0.9610851  0.03891494], Action: 0, state: 1\n",
      "Action prob: [0.9585295  0.04147049], Action: 0, state: 1\n",
      "Action prob: [0.9550313  0.04496869], Action: 0, state: 2\n",
      "Action prob: [0.9610887  0.03891135], Action: 0, state: 3\n",
      "Action prob: [0.96040505 0.03959495], Action: 1, state: 3\n",
      "Action prob: [0.8350779  0.16492212], Action: 0, state: 7\n",
      "Action prob: [0.8350779  0.16492212], Action: 0, state: 7\n",
      "Action prob: [0.8350779  0.16492212], Action: 0, state: 7\n",
      "Action prob: [0.8350779  0.16492212], Action: 0, state: 7\n",
      "Action prob: [0.8350779  0.16492212], Action: 0, state: 7\n",
      "Action prob: [0.8350779  0.16492212], Action: 0, state: 7\n",
      "Action prob: [0.8350779  0.16492212], Action: 0, state: 7\n",
      "Action prob: [0.9581117  0.04188829], Action: 0, state: 2\n",
      "Action prob: [0.96083784 0.03916223], Action: 0, state: 2\n",
      "Action prob: [0.9575458  0.04245414], Action: 0, state: 3\n",
      "Action prob: [0.9561535  0.04384647], Action: 0, state: 3\n",
      "Action prob: [0.95799726 0.04200279], Action: 0, state: 8\n",
      "Action prob: [0.9667786 0.0332215], Action: 0, state: 8\n",
      "Action prob: [0.94681054 0.05318947], Action: 0, state: 8\n",
      "Action prob: [0.9489863  0.05101372], Action: 0, state: 8\n",
      "Action prob: [0.96534014 0.03465985], Action: 0, state: 8\n",
      "Action prob: [0.9560492 0.0439508], Action: 0, state: 8\n",
      "Action prob: [0.9583736  0.04162642], Action: 0, state: 8\n",
      "Action prob: [0.96141684 0.03858311], Action: 0, state: 8\n",
      "Action prob: [0.9446905  0.05530953], Action: 1, state: 8\n",
      "Action prob: [0.94586384 0.05413614], Action: 0, state: 8\n",
      "Action prob: [0.9650844  0.03491564], Action: 0, state: 8\n",
      "Action prob: [0.9588994  0.04110067], Action: 0, state: 8\n",
      "Action prob: [0.9604816  0.03951845], Action: 0, state: 8\n",
      "Action prob: [0.96525985 0.03474011], Action: 0, state: 8\n",
      "Action prob: [0.9640763  0.03592367], Action: 0, state: 8\n",
      "Action prob: [0.9596966  0.04030345], Action: 1, state: 8\n",
      "Action prob: [0.96515745 0.03484252], Action: 0, state: 8\n",
      "Action prob: [0.94737506 0.05262501], Action: 0, state: 8\n",
      "Action prob: [0.94844574 0.05155431], Action: 0, state: 8\n",
      "Action prob: [0.9601299 0.0398701], Action: 0, state: 8\n",
      "Action prob: [0.9630414  0.03695859], Action: 0, state: 8\n",
      "Action prob: [0.94823635 0.05176365], Action: 0, state: 8\n",
      "Action prob: [0.9373503  0.06264973], Action: 0, state: 8\n",
      "Action prob: [0.94822127 0.05177879], Action: 0, state: 8\n",
      "Action prob: [0.9506558  0.04934414], Action: 0, state: 8\n",
      "Action prob: [0.9584688  0.04153119], Action: 0, state: 8\n",
      "Action prob: [0.95811236 0.04188761], Action: 0, state: 8\n",
      "Action prob: [0.96409345 0.03590651], Action: 0, state: 8\n",
      "Action prob: [0.9660505 0.0339495], Action: 0, state: 8\n",
      "Action prob: [0.9451024  0.05489757], Action: 0, state: 8\n",
      "Action prob: [0.94801354 0.05198645], Action: 0, state: 8\n",
      "Action prob: [0.9699017  0.03009828], Action: 0, state: 8\n",
      "tensor([-1.4062e-01, -6.8021e-02, -1.6194e-02,  2.5219e-02,  6.2279e-02,\n",
      "         6.9706e-02,  6.7767e+00,  3.2580e-01,  2.8122e-01,  2.4333e-01,\n",
      "         2.1112e-01,  1.8374e-01,  1.6047e-01,  1.4069e-01,  3.9790e-02,\n",
      "         4.2216e-02,  4.8767e-02,  5.2971e-02,  3.8158e-02,  2.1653e-02,\n",
      "         2.3492e-02,  1.3110e-02,  3.4520e-03, -1.4283e-03, -6.0363e-03,\n",
      "        -9.2716e-03, -9.1259e-01, -2.1312e-02, -1.5653e-02, -2.0537e-02,\n",
      "        -2.1406e-02, -2.0020e-02, -2.1814e-02, -1.9967e+00, -2.2820e-02,\n",
      "        -3.5783e-02, -3.5865e-02, -2.8111e-02, -2.6445e-02, -3.7836e-02,\n",
      "        -4.6585e-02, -3.8652e-02, -3.7087e-02, -3.1302e-02, -3.1759e-02,\n",
      "        -2.7273e-02, -2.5867e-02, -4.2433e-02, -4.0241e-02, -2.3093e-02],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -95300, loss is -0.09922191374626682\n",
      "Action prob: [0.9687262  0.03127383], Action: 0, state: 0\n",
      "Action prob: [0.9662637  0.03373621], Action: 1, state: 1\n",
      "Action prob: [0.829771 0.170229], Action: 0, state: 5\n",
      "Action prob: [0.96832585 0.03167417], Action: 0, state: 0\n",
      "Action prob: [0.9668814  0.03311855], Action: 0, state: 1\n",
      "Action prob: [0.9660655  0.03393444], Action: 0, state: 1\n",
      "Action prob: [0.9673456  0.03265447], Action: 0, state: 2\n",
      "Action prob: [0.9659216 0.0340784], Action: 0, state: 2\n",
      "Action prob: [0.9658386  0.03416141], Action: 0, state: 2\n",
      "Action prob: [0.9636399  0.03636004], Action: 0, state: 3\n",
      "Action prob: [0.9586865  0.04131351], Action: 0, state: 8\n",
      "Action prob: [0.97234625 0.02765378], Action: 0, state: 8\n",
      "Action prob: [0.9711732 0.0288267], Action: 0, state: 8\n",
      "Action prob: [0.95429456 0.04570542], Action: 0, state: 8\n",
      "Action prob: [0.9554354  0.04456457], Action: 0, state: 8\n",
      "Action prob: [0.9544604  0.04553961], Action: 0, state: 8\n",
      "Action prob: [0.9711259  0.02887412], Action: 0, state: 8\n",
      "Action prob: [0.9718998  0.02810027], Action: 0, state: 8\n",
      "Action prob: [0.9549045  0.04509552], Action: 0, state: 8\n",
      "Action prob: [0.9544385  0.04556149], Action: 0, state: 8\n",
      "Action prob: [0.95535433 0.04464569], Action: 0, state: 8\n",
      "Action prob: [0.95549494 0.0445051 ], Action: 0, state: 8\n",
      "Action prob: [0.973424   0.02657599], Action: 0, state: 8\n",
      "Action prob: [0.97261286 0.02738709], Action: 0, state: 8\n",
      "Action prob: [0.94987947 0.0501205 ], Action: 0, state: 8\n",
      "Action prob: [0.9545251  0.04547494], Action: 0, state: 8\n",
      "Action prob: [0.9453201  0.05467995], Action: 0, state: 8\n",
      "Action prob: [0.9540546  0.04594545], Action: 0, state: 8\n",
      "Action prob: [0.97162026 0.02837974], Action: 0, state: 8\n",
      "Action prob: [0.95796245 0.04203759], Action: 0, state: 8\n",
      "Action prob: [0.973019   0.02698103], Action: 0, state: 8\n",
      "Action prob: [0.97420293 0.02579708], Action: 1, state: 8\n",
      "Action prob: [0.9687864  0.03121363], Action: 0, state: 8\n",
      "Action prob: [0.96591485 0.03408523], Action: 0, state: 8\n",
      "Action prob: [0.966509   0.03349098], Action: 0, state: 8\n",
      "Action prob: [0.9556453 0.0443547], Action: 0, state: 8\n",
      "Action prob: [0.9732335  0.02676651], Action: 0, state: 8\n",
      "Action prob: [0.9565705  0.04342946], Action: 0, state: 8\n",
      "Action prob: [0.96697605 0.03302393], Action: 0, state: 8\n",
      "Action prob: [0.9707072  0.02929285], Action: 0, state: 8\n",
      "Action prob: [0.9656397  0.03436027], Action: 0, state: 8\n",
      "Action prob: [0.96666694 0.03333306], Action: 0, state: 8\n",
      "Action prob: [0.97003216 0.02996787], Action: 0, state: 8\n",
      "Action prob: [0.9702564  0.02974362], Action: 0, state: 8\n",
      "Action prob: [0.9743522  0.02564789], Action: 0, state: 8\n",
      "Action prob: [0.9528151  0.04718491], Action: 0, state: 8\n",
      "Action prob: [0.9690288  0.03097124], Action: 0, state: 8\n",
      "Action prob: [0.9737655  0.02623445], Action: 0, state: 8\n",
      "Action prob: [0.9667242  0.03327583], Action: 0, state: 8\n",
      "Action prob: [0.9546824  0.04531763], Action: 0, state: 8\n",
      "tensor([ 4.3953e-03,  2.5978e+00,  8.7680e-02,  3.1355e-02,  4.5802e-02,\n",
      "         5.8270e-02,  6.4261e-02,  7.4414e-02,  8.0820e-02,  8.9641e-02,\n",
      "         8.1652e-02,  4.2712e-02,  3.4301e-02,  4.0926e-02,  2.8340e-02,\n",
      "         1.8945e-02,  6.5498e-03,  1.9403e-03, -2.9568e-03, -8.2263e-03,\n",
      "        -1.2418e-02, -1.6073e-02, -1.1368e-02, -1.3348e-02, -2.7279e-02,\n",
      "        -2.6663e-02, -3.4239e-02, -3.0078e-02, -1.9160e-02, -2.9531e-02,\n",
      "        -1.9322e-02, -2.6422e+00, -2.3339e-02, -2.5924e-02, -2.5799e-02,\n",
      "        -3.4738e-02, -2.0966e-02, -3.4579e-02, -2.6325e-02, -2.3436e-02,\n",
      "        -2.7691e-02, -2.6956e-02, -2.4274e-02, -2.4158e-02, -2.0838e-02,\n",
      "        -3.8844e-02, -2.5327e-02, -2.1433e-02, -2.7318e-02, -3.7477e-02],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -116900, loss is -0.00015099093982586076\n",
      "Action prob: [0.9716123  0.02838768], Action: 0, state: 0\n",
      "Action prob: [0.9701918 0.0298082], Action: 0, state: 0\n",
      "Action prob: [0.97010696 0.02989308], Action: 0, state: 0\n",
      "Action prob: [0.9703353  0.02966469], Action: 0, state: 0\n",
      "Action prob: [0.9719686  0.02803142], Action: 0, state: 0\n",
      "Action prob: [0.97184193 0.02815806], Action: 0, state: 0\n",
      "Action prob: [0.9733146  0.02668539], Action: 0, state: 0\n",
      "Action prob: [0.97278386 0.02721609], Action: 0, state: 1\n",
      "Action prob: [0.9708019  0.02919809], Action: 0, state: 1\n",
      "Action prob: [0.9719657  0.02803437], Action: 0, state: 2\n",
      "Action prob: [0.9698197  0.03018023], Action: 0, state: 2\n",
      "Action prob: [0.96065044 0.03934961], Action: 0, state: 3\n",
      "Action prob: [0.9829882  0.01701181], Action: 0, state: 8\n",
      "Action prob: [0.97583234 0.02416766], Action: 0, state: 8\n",
      "Action prob: [0.9787567  0.02124325], Action: 0, state: 8\n",
      "Action prob: [0.9763074  0.02369254], Action: 0, state: 8\n",
      "Action prob: [0.9782923  0.02170768], Action: 0, state: 8\n",
      "Action prob: [0.9740001  0.02599995], Action: 0, state: 8\n",
      "Action prob: [0.971924 0.028076], Action: 0, state: 8\n",
      "Action prob: [0.9767969  0.02320302], Action: 0, state: 8\n",
      "Action prob: [0.97240293 0.02759712], Action: 0, state: 8\n",
      "Action prob: [0.97672415 0.02327587], Action: 0, state: 8\n",
      "Action prob: [0.96036506 0.03963494], Action: 0, state: 8\n",
      "Action prob: [0.96009785 0.03990223], Action: 0, state: 8\n",
      "Action prob: [0.9732789  0.02672116], Action: 0, state: 8\n",
      "Action prob: [0.9727411  0.02725885], Action: 0, state: 8\n",
      "Action prob: [0.97740096 0.02259906], Action: 0, state: 8\n",
      "Action prob: [0.974019   0.02598101], Action: 0, state: 8\n",
      "Action prob: [0.9757377  0.02426228], Action: 1, state: 8\n",
      "Action prob: [0.9776489  0.02235104], Action: 0, state: 8\n",
      "Action prob: [0.95997775 0.04002223], Action: 0, state: 8\n",
      "Action prob: [0.9724884  0.02751161], Action: 1, state: 8\n",
      "Action prob: [0.96410674 0.0358933 ], Action: 0, state: 8\n",
      "Action prob: [0.98009354 0.01990641], Action: 0, state: 8\n",
      "Action prob: [0.9619809  0.03801906], Action: 0, state: 8\n",
      "Action prob: [0.9615763  0.03842375], Action: 0, state: 8\n",
      "Action prob: [0.96012014 0.03987987], Action: 0, state: 8\n",
      "Action prob: [0.96319836 0.0368017 ], Action: 0, state: 8\n",
      "Action prob: [0.9742362  0.02576383], Action: 0, state: 8\n",
      "Action prob: [0.97627556 0.02372439], Action: 0, state: 8\n",
      "Action prob: [0.9747326  0.02526737], Action: 0, state: 8\n",
      "Action prob: [0.94840974 0.05159026], Action: 0, state: 8\n",
      "Action prob: [0.95156133 0.04843862], Action: 0, state: 8\n",
      "Action prob: [0.9608809  0.03911912], Action: 0, state: 8\n",
      "Action prob: [0.9750997  0.02490031], Action: 0, state: 8\n",
      "Action prob: [0.97516364 0.02483636], Action: 0, state: 8\n",
      "Action prob: [0.97116697 0.02883301], Action: 0, state: 8\n",
      "Action prob: [0.97599274 0.02400725], Action: 0, state: 8\n",
      "Action prob: [0.9715741  0.02842588], Action: 0, state: 8\n",
      "Action prob: [0.9609907  0.03900933], Action: 0, state: 8\n",
      "tensor([-6.8946e-02, -4.5349e-02, -2.2378e-02, -2.7199e-03,  1.3069e-02,\n",
      "         2.6481e-02,  3.5825e-02,  4.4935e-02,  5.5913e-02,  5.9203e-02,\n",
      "         6.8890e-02,  9.3784e-02,  3.2370e-02,  3.6805e-02,  2.5328e-02,\n",
      "         2.1664e-02,  1.4678e-02,  1.2364e-02,  8.5364e-03,  3.6536e-03,\n",
      "         9.2686e-04, -1.6724e-03, -6.4515e-03, -9.5595e-03, -8.0905e-03,\n",
      "        -9.7579e-03, -9.1267e-03, -1.1544e-02, -1.7550e+00, -1.1309e-02,\n",
      "        -2.1420e-02, -1.9580e+00, -2.0556e-02, -1.1605e-02, -2.2859e-02,\n",
      "        -2.3527e-02, -2.4807e-02, -2.3146e-02, -1.6284e-02, -1.5113e-02,\n",
      "        -1.6230e-02, -3.3806e-02, -3.1859e-02, -2.5722e-02, -1.6316e-02,\n",
      "        -1.6326e-02, -1.9045e-02, -1.5855e-02, -1.8853e-02, -2.6057e-02],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -107100, loss is 0.07529753916609577\n",
      "Action prob: [0.975899   0.02410105], Action: 0, state: 0\n",
      "Action prob: [0.9749869  0.02501305], Action: 0, state: 1\n",
      "Action prob: [0.9743833  0.02561666], Action: 0, state: 1\n",
      "Action prob: [0.9744188 0.0255812], Action: 0, state: 2\n",
      "Action prob: [0.9734018  0.02659824], Action: 0, state: 2\n",
      "Action prob: [0.97539365 0.0246063 ], Action: 0, state: 2\n",
      "Action prob: [0.9727025  0.02729745], Action: 0, state: 3\n",
      "Action prob: [0.9733619  0.02663808], Action: 1, state: 3\n",
      "Action prob: [0.832764   0.16723593], Action: 0, state: 7\n",
      "Action prob: [0.9764263  0.02357375], Action: 0, state: 2\n",
      "Action prob: [0.9750019  0.02499817], Action: 0, state: 2\n",
      "Action prob: [0.9734991  0.02650088], Action: 0, state: 2\n",
      "Action prob: [0.97461516 0.02538482], Action: 0, state: 2\n",
      "Action prob: [0.97455454 0.02544548], Action: 0, state: 3\n",
      "Action prob: [0.9732944  0.02670565], Action: 1, state: 3\n",
      "Action prob: [0.832764   0.16723593], Action: 0, state: 7\n",
      "Action prob: [0.832764   0.16723593], Action: 1, state: 7\n",
      "Action prob: [0.832764   0.16723593], Action: 0, state: 7\n",
      "Action prob: [0.832764   0.16723593], Action: 0, state: 7\n",
      "Action prob: [0.9735464  0.02645361], Action: 0, state: 2\n",
      "Action prob: [0.9738043  0.02619578], Action: 0, state: 3\n",
      "Action prob: [0.98117894 0.0188211 ], Action: 0, state: 3\n",
      "Action prob: [0.9657993  0.03420069], Action: 0, state: 3\n",
      "Action prob: [0.98169965 0.01830028], Action: 0, state: 3\n",
      "Action prob: [0.97555953 0.02444053], Action: 0, state: 8\n",
      "Action prob: [0.9808255  0.01917454], Action: 0, state: 8\n",
      "Action prob: [0.9666235  0.03337653], Action: 0, state: 8\n",
      "Action prob: [0.9794078  0.02059225], Action: 0, state: 8\n",
      "Action prob: [0.9790789  0.02092106], Action: 0, state: 8\n",
      "Action prob: [0.97615004 0.0238499 ], Action: 0, state: 8\n",
      "Action prob: [0.9617666  0.03823337], Action: 0, state: 8\n",
      "Action prob: [0.96708995 0.03291009], Action: 0, state: 8\n",
      "Action prob: [0.9795706 0.0204294], Action: 0, state: 8\n",
      "Action prob: [0.97440606 0.02559392], Action: 0, state: 8\n",
      "Action prob: [0.98140717 0.01859284], Action: 0, state: 8\n",
      "Action prob: [0.96361226 0.03638776], Action: 0, state: 8\n",
      "Action prob: [0.980528   0.01947207], Action: 0, state: 8\n",
      "Action prob: [0.980138 0.019862], Action: 0, state: 8\n",
      "Action prob: [0.976105   0.02389501], Action: 0, state: 8\n",
      "Action prob: [0.97564596 0.024354  ], Action: 0, state: 8\n",
      "Action prob: [0.9667654  0.03323465], Action: 0, state: 8\n",
      "Action prob: [0.9743844  0.02561561], Action: 0, state: 8\n",
      "Action prob: [0.97670364 0.02329629], Action: 0, state: 8\n",
      "Action prob: [0.96224    0.03775997], Action: 0, state: 8\n",
      "Action prob: [0.9810451  0.01895491], Action: 0, state: 8\n",
      "Action prob: [0.9672021  0.03279782], Action: 0, state: 8\n",
      "Action prob: [0.97373724 0.02626274], Action: 0, state: 8\n",
      "Action prob: [0.9751452 0.0248547], Action: 0, state: 8\n",
      "Action prob: [0.964366 0.035634], Action: 0, state: 8\n",
      "Action prob: [0.97705793 0.02294204], Action: 0, state: 8\n",
      "tensor([-1.1045e-01, -8.6186e-02, -6.3475e-02, -4.4661e-02, -2.9904e-02,\n",
      "        -1.4630e-02, -8.5759e-03, -2.6870e-01, -5.0234e-02, -4.7190e-05,\n",
      "         5.8141e-03,  1.1457e-02,  1.5271e-02,  1.7600e-02,  2.7476e+00,\n",
      "         1.2703e-01,  1.1438e+00,  1.0855e-01,  1.0133e-01,  1.6283e-02,\n",
      "         1.6879e-02,  1.2542e-02,  2.3687e-02,  1.2895e-02,  1.5067e-02,\n",
      "         1.0320e-02,  1.5905e-02,  8.6080e-03,  7.7617e-03,  7.9054e-03,\n",
      "         1.1454e-02,  8.8748e-03,  4.9720e-03,  5.7093e-03,  3.8029e-03,\n",
      "         6.9570e-03,  3.4411e-03,  3.2942e-03,  3.7493e-03,  3.6300e-03,\n",
      "         4.7522e-03,  3.5023e-03,  3.0685e-03,  4.8540e-03,  2.3470e-03,\n",
      "         3.9919e-03,  3.1192e-03,  2.8964e-03,  4.1100e-03,  2.5934e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -71300, loss is -0.07681008397330205\n",
      "Action prob: [0.9776053  0.02239474], Action: 0, state: 0\n",
      "Action prob: [0.97595835 0.02404159], Action: 0, state: 0\n",
      "Action prob: [0.98272127 0.01727876], Action: 0, state: 0\n",
      "Action prob: [0.9776577  0.02234236], Action: 0, state: 0\n",
      "Action prob: [0.97730196 0.02269799], Action: 0, state: 1\n",
      "Action prob: [0.9778692  0.02213078], Action: 0, state: 1\n",
      "Action prob: [0.9786578  0.02134226], Action: 0, state: 1\n",
      "Action prob: [0.97675997 0.02324009], Action: 0, state: 2\n",
      "Action prob: [0.97841644 0.02158357], Action: 0, state: 2\n",
      "Action prob: [0.9769776  0.02302247], Action: 0, state: 3\n",
      "Action prob: [0.98119915 0.01880083], Action: 0, state: 3\n",
      "Action prob: [0.9769205 0.0230795], Action: 0, state: 3\n",
      "Action prob: [0.9775124  0.02248758], Action: 0, state: 3\n",
      "Action prob: [0.9764565 0.0235435], Action: 0, state: 3\n",
      "Action prob: [0.9619296 0.0380704], Action: 0, state: 8\n",
      "Action prob: [0.9828873  0.01711274], Action: 0, state: 8\n",
      "Action prob: [0.9802783  0.01972166], Action: 1, state: 8\n",
      "Action prob: [0.96869165 0.03130836], Action: 0, state: 8\n",
      "Action prob: [0.98454756 0.01545246], Action: 0, state: 8\n",
      "Action prob: [0.9823033  0.01769671], Action: 0, state: 8\n",
      "Action prob: [0.971602   0.02839793], Action: 0, state: 8\n",
      "Action prob: [0.9826926  0.01730737], Action: 0, state: 8\n",
      "Action prob: [0.9823501  0.01764989], Action: 0, state: 8\n",
      "Action prob: [0.9817027  0.01829737], Action: 0, state: 8\n",
      "Action prob: [0.9709189  0.02908111], Action: 0, state: 8\n",
      "Action prob: [0.9783598  0.02164017], Action: 0, state: 8\n",
      "Action prob: [0.9831579  0.01684207], Action: 0, state: 8\n",
      "Action prob: [0.9836961  0.01630387], Action: 0, state: 8\n",
      "Action prob: [0.9823147 0.0176853], Action: 0, state: 8\n",
      "Action prob: [0.97920805 0.02079191], Action: 0, state: 8\n",
      "Action prob: [0.977835   0.02216503], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.97759557 0.02240435], Action: 0, state: 8\n",
      "Action prob: [0.9798753  0.02012471], Action: 0, state: 8\n",
      "Action prob: [0.9819701  0.01802996], Action: 0, state: 8\n",
      "Action prob: [0.97064567 0.0293543 ], Action: 0, state: 8\n",
      "Action prob: [0.9696041  0.03039592], Action: 0, state: 8\n",
      "Action prob: [0.97797763 0.02202237], Action: 0, state: 8\n",
      "Action prob: [0.98413426 0.01586567], Action: 0, state: 8\n",
      "Action prob: [0.96959764 0.03040239], Action: 0, state: 8\n",
      "Action prob: [0.9681218  0.03187816], Action: 0, state: 8\n",
      "Action prob: [0.97934544 0.02065452], Action: 0, state: 8\n",
      "Action prob: [0.97021925 0.02978068], Action: 0, state: 8\n",
      "Action prob: [0.9671181  0.03288193], Action: 0, state: 8\n",
      "Action prob: [0.9833135  0.01668654], Action: 0, state: 8\n",
      "Action prob: [0.97132295 0.0286771 ], Action: 0, state: 8\n",
      "Action prob: [0.9824997  0.01750027], Action: 0, state: 8\n",
      "Action prob: [0.9677921  0.03220795], Action: 0, state: 8\n",
      "Action prob: [0.9827823  0.01721766], Action: 0, state: 8\n",
      "Action prob: [0.98204285 0.0179572 ], Action: 0, state: 8\n",
      "Action prob: [0.98118895 0.0188111 ], Action: 0, state: 8\n",
      "tensor([-7.4194e-02, -5.4509e-02, -2.3695e-02, -1.3807e-02, -8.8407e-04,\n",
      "         1.0029e-02,  1.8592e-02,  2.7614e-02,  3.1420e-02,  3.6827e-02,\n",
      "         3.2286e-02,  4.2101e-02,  4.2980e-02,  4.6778e-02,  6.1624e-02,\n",
      "         2.1892e-02,  3.9137e+00,  2.4369e-02,  8.8763e-03,  7.2004e-03,\n",
      "         7.5355e-03,  2.4638e-03,  6.8984e-04, -8.9167e-04, -3.6080e-03,\n",
      "        -4.0502e-03, -4.0523e-03, -4.6685e-03, -5.7565e-03, -7.4681e-03,\n",
      "        -8.5921e-03, -9.2233e-03, -8.6849e-03, -8.0844e-03, -1.3672e-02,\n",
      "        -1.4547e-02, -1.0729e-02, -7.8484e-03, -1.5386e-02, -1.6354e-02,\n",
      "        -1.0650e-02, -1.5569e-02, -1.7350e-02, -8.7890e-03, -1.5281e-02,\n",
      "        -9.3150e-03, -1.7341e-02, -9.2298e-03, -9.6570e-03, -1.0145e-02],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -101200, loss is -0.07805826332017488\n",
      "Action prob: [0.98125297 0.018747  ], Action: 0, state: 0\n",
      "Action prob: [0.981087   0.01891295], Action: 0, state: 0\n",
      "Action prob: [0.9831407  0.01685924], Action: 0, state: 0\n",
      "Action prob: [0.98160136 0.01839861], Action: 0, state: 1\n",
      "Action prob: [0.9807499  0.01925004], Action: 0, state: 1\n",
      "Action prob: [0.98157376 0.01842626], Action: 0, state: 1\n",
      "Action prob: [0.9818955  0.01810458], Action: 0, state: 1\n",
      "Action prob: [0.98160326 0.01839669], Action: 0, state: 1\n",
      "Action prob: [0.9815757  0.01842431], Action: 0, state: 1\n",
      "Action prob: [0.98070484 0.01929518], Action: 0, state: 2\n",
      "Action prob: [0.9822494 0.0177506], Action: 0, state: 2\n",
      "Action prob: [0.98346245 0.01653754], Action: 0, state: 2\n",
      "Action prob: [0.980397   0.01960297], Action: 0, state: 2\n",
      "Action prob: [0.97979635 0.02020366], Action: 0, state: 2\n",
      "Action prob: [0.9801498  0.01985027], Action: 0, state: 2\n",
      "Action prob: [0.9802444  0.01975556], Action: 0, state: 3\n",
      "Action prob: [0.98212093 0.01787907], Action: 0, state: 3\n",
      "Action prob: [0.98508364 0.01491632], Action: 0, state: 8\n",
      "Action prob: [0.9867192  0.01328079], Action: 0, state: 8\n",
      "Action prob: [0.9834064  0.01659355], Action: 0, state: 8\n",
      "Action prob: [0.9739248  0.02607519], Action: 0, state: 8\n",
      "Action prob: [0.9736873  0.02631275], Action: 0, state: 8\n",
      "Action prob: [0.985232   0.01476803], Action: 0, state: 8\n",
      "Action prob: [0.9754136  0.02458639], Action: 0, state: 8\n",
      "Action prob: [0.985227   0.01477304], Action: 0, state: 8\n",
      "Action prob: [0.9755259  0.02447408], Action: 0, state: 8\n",
      "Action prob: [0.9866327  0.01336732], Action: 0, state: 8\n",
      "Action prob: [0.9859688 0.0140312], Action: 0, state: 8\n",
      "Action prob: [0.97229487 0.02770521], Action: 0, state: 8\n",
      "Action prob: [0.9857928  0.01420714], Action: 0, state: 8\n",
      "Action prob: [0.9855143  0.01448565], Action: 0, state: 8\n",
      "Action prob: [0.9843039  0.01569609], Action: 0, state: 8\n",
      "Action prob: [0.9872335  0.01276649], Action: 0, state: 8\n",
      "Action prob: [0.98679614 0.01320391], Action: 0, state: 8\n",
      "Action prob: [0.972932   0.02706802], Action: 0, state: 8\n",
      "Action prob: [0.98040956 0.01959042], Action: 0, state: 8\n",
      "Action prob: [0.97215515 0.02784492], Action: 0, state: 8\n",
      "Action prob: [0.9852684  0.01473155], Action: 0, state: 8\n",
      "Action prob: [0.9830819 0.0169181], Action: 0, state: 8\n",
      "Action prob: [0.9863745  0.01362546], Action: 0, state: 8\n",
      "Action prob: [0.985523   0.01447698], Action: 0, state: 8\n",
      "Action prob: [0.9716455  0.02835447], Action: 0, state: 8\n",
      "Action prob: [0.98619425 0.01380568], Action: 0, state: 8\n",
      "Action prob: [0.9740689  0.02593114], Action: 0, state: 8\n",
      "Action prob: [0.9728117  0.02718833], Action: 0, state: 8\n",
      "Action prob: [0.98414075 0.01585926], Action: 0, state: 8\n",
      "Action prob: [0.98443973 0.01556021], Action: 0, state: 8\n",
      "Action prob: [0.98810136 0.01189859], Action: 0, state: 8\n",
      "Action prob: [0.98367137 0.01632855], Action: 0, state: 8\n",
      "Action prob: [0.97252613 0.02747389], Action: 0, state: 8\n",
      "tensor([-7.7923e-02, -5.9823e-02, -3.9045e-02, -3.0756e-02, -2.1618e-02,\n",
      "        -1.2083e-02, -4.6876e-03,  1.4403e-03,  6.7240e-03,  1.1226e-02,\n",
      "         1.3586e-02,  1.5235e-02,  2.0697e-02,  2.3624e-02,  2.5115e-02,\n",
      "         2.6004e-02,  2.4287e-02,  1.6936e-02,  1.2575e-02,  1.3087e-02,\n",
      "         1.7107e-02,  1.4212e-02,  6.4824e-03,  8.7875e-03,  4.2076e-03,\n",
      "         5.5245e-03,  2.3169e-03,  1.8228e-03,  2.5934e-03,  8.7446e-04,\n",
      "         5.0488e-04,  1.9088e-04, -9.1087e-05, -3.1064e-04, -1.0211e-03,\n",
      "        -9.6893e-04, -1.6654e-03, -1.0014e-03, -1.2745e-03, -1.1090e-03,\n",
      "        -1.2549e-03, -2.6029e-03, -1.3104e-03, -2.5608e-03, -2.7618e-03,\n",
      "        -1.6387e-03, -1.6385e-03, -1.2706e-03, -1.7710e-03, -3.0305e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -88800, loss is -3.8856784157204165e-05\n",
      "Action prob: [0.9861872  0.01381279], Action: 0, state: 0\n",
      "Action prob: [0.9884848  0.01151518], Action: 0, state: 1\n",
      "Action prob: [0.984421   0.01557896], Action: 0, state: 1\n",
      "Action prob: [0.98522097 0.01477905], Action: 0, state: 1\n",
      "Action prob: [0.9844967  0.01550325], Action: 0, state: 1\n",
      "Action prob: [0.9856133  0.01438675], Action: 0, state: 1\n",
      "Action prob: [0.9847639  0.01523608], Action: 0, state: 1\n",
      "Action prob: [0.97778475 0.0222152 ], Action: 0, state: 2\n",
      "Action prob: [0.98243743 0.01756259], Action: 0, state: 3\n",
      "Action prob: [0.9863338  0.01366627], Action: 0, state: 3\n",
      "Action prob: [0.9860161  0.01398391], Action: 0, state: 8\n",
      "Action prob: [0.9819664  0.01803365], Action: 0, state: 8\n",
      "Action prob: [0.9802343  0.01976565], Action: 0, state: 8\n",
      "Action prob: [0.9783492  0.02165073], Action: 0, state: 8\n",
      "Action prob: [0.9847052  0.01529487], Action: 0, state: 8\n",
      "Action prob: [0.97814924 0.02185072], Action: 0, state: 8\n",
      "Action prob: [0.9864872  0.01351278], Action: 0, state: 8\n",
      "Action prob: [0.986127   0.01387297], Action: 0, state: 8\n",
      "Action prob: [0.9886568  0.01134314], Action: 0, state: 8\n",
      "Action prob: [0.9867098  0.01329021], Action: 0, state: 8\n",
      "Action prob: [0.98627484 0.01372517], Action: 0, state: 8\n",
      "Action prob: [0.9846049  0.01539508], Action: 0, state: 8\n",
      "Action prob: [0.9899317  0.01006832], Action: 0, state: 8\n",
      "Action prob: [0.985786   0.01421399], Action: 0, state: 8\n",
      "Action prob: [0.9894875  0.01051254], Action: 0, state: 8\n",
      "Action prob: [0.97804093 0.02195911], Action: 0, state: 8\n",
      "Action prob: [0.98579425 0.01420578], Action: 0, state: 8\n",
      "Action prob: [0.98900396 0.01099606], Action: 0, state: 8\n",
      "Action prob: [0.97975826 0.02024176], Action: 0, state: 8\n",
      "Action prob: [0.9883416  0.01165839], Action: 0, state: 8\n",
      "Action prob: [0.963915   0.03608505], Action: 0, state: 8\n",
      "Action prob: [0.97729605 0.02270398], Action: 0, state: 8\n",
      "Action prob: [0.9888171  0.01118289], Action: 0, state: 8\n",
      "Action prob: [0.97804445 0.02195558], Action: 0, state: 8\n",
      "Action prob: [0.98716056 0.01283945], Action: 0, state: 8\n",
      "Action prob: [0.98886245 0.01113756], Action: 0, state: 8\n",
      "Action prob: [0.97778666 0.02221336], Action: 0, state: 8\n",
      "Action prob: [0.97744614 0.02255383], Action: 0, state: 8\n",
      "Action prob: [0.9864271  0.01357281], Action: 0, state: 8\n",
      "Action prob: [0.985891   0.01410908], Action: 1, state: 8\n",
      "Action prob: [0.9752329  0.02476707], Action: 0, state: 8\n",
      "Action prob: [0.9776469  0.02235314], Action: 0, state: 8\n",
      "Action prob: [0.9767957  0.02320429], Action: 0, state: 8\n",
      "Action prob: [0.9770423  0.02295769], Action: 0, state: 8\n",
      "Action prob: [0.97818726 0.02181274], Action: 0, state: 8\n",
      "Action prob: [0.98515934 0.01484073], Action: 0, state: 8\n",
      "Action prob: [0.99126774 0.00873224], Action: 0, state: 8\n",
      "Action prob: [0.9777249 0.0222751], Action: 0, state: 8\n",
      "Action prob: [0.9871798  0.01282014], Action: 0, state: 8\n",
      "Action prob: [0.97823983 0.02176015], Action: 0, state: 8\n",
      "tensor([-8.0478e-03,  5.2555e-04,  9.0403e-03,  1.5285e-02,  2.2027e-02,\n",
      "         2.5150e-02,  3.0897e-02,  4.9909e-02,  4.1332e-02,  3.3399e-02,\n",
      "         2.7396e-02,  2.7951e-02,  2.3714e-02,  1.9525e-02,  9.8723e-03,\n",
      "         9.4286e-03,  3.3342e-03,  1.2662e-03, -4.6353e-04, -2.0365e-03,\n",
      "        -3.4144e-03, -5.0838e-03, -4.0092e-03, -6.5058e-03, -5.3258e-03,\n",
      "        -1.2124e-02, -8.3242e-03, -6.7692e-03, -1.3048e-02, -7.7400e-03,\n",
      "        -2.4943e-02, -1.5951e-02, -7.9627e-03, -1.5974e-02, -9.4240e-03,\n",
      "        -8.2606e-03, -1.6726e-02, -1.7122e-02, -1.0327e-02, -3.2383e+00,\n",
      "        -1.9152e-02, -1.7335e-02, -1.8065e-02, -1.7923e-02, -1.7062e-02,\n",
      "        -1.1592e-02, -6.8117e-03, -1.7522e-02, -1.0049e-02, -1.7153e-02],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -115800, loss is 0.06500976921370405\n",
      "Action prob: [0.9856741  0.01432596], Action: 0, state: 0\n",
      "Action prob: [0.98638064 0.01361935], Action: 0, state: 0\n",
      "Action prob: [0.9866803  0.01331968], Action: 0, state: 0\n",
      "Action prob: [0.98568046 0.01431956], Action: 0, state: 0\n",
      "Action prob: [0.9858596  0.01414048], Action: 0, state: 0\n",
      "Action prob: [0.98640037 0.01359966], Action: 0, state: 0\n",
      "Action prob: [0.98563856 0.01436142], Action: 0, state: 1\n",
      "Action prob: [0.98255986 0.0174401 ], Action: 0, state: 1\n",
      "Action prob: [0.9853277  0.01467229], Action: 0, state: 1\n",
      "Action prob: [0.98446655 0.01553348], Action: 0, state: 2\n",
      "Action prob: [0.98565453 0.01434551], Action: 0, state: 2\n",
      "Action prob: [0.98603016 0.01396982], Action: 0, state: 2\n",
      "Action prob: [0.98621815 0.0137818 ], Action: 0, state: 2\n",
      "Action prob: [0.98585397 0.01414601], Action: 0, state: 2\n",
      "Action prob: [0.9875031  0.01249686], Action: 0, state: 2\n",
      "Action prob: [0.98630595 0.01369406], Action: 0, state: 3\n",
      "Action prob: [0.9873782  0.01262184], Action: 0, state: 3\n",
      "Action prob: [0.98567146 0.01432862], Action: 0, state: 3\n",
      "Action prob: [0.98673964 0.01326041], Action: 0, state: 3\n",
      "Action prob: [0.9874228  0.01257725], Action: 0, state: 3\n",
      "Action prob: [0.9884632 0.0115368], Action: 0, state: 3\n",
      "Action prob: [0.9858273  0.01417269], Action: 0, state: 3\n",
      "Action prob: [0.9818777  0.01812238], Action: 1, state: 8\n",
      "Action prob: [0.99064916 0.00935081], Action: 0, state: 8\n",
      "Action prob: [0.9797019  0.02029819], Action: 0, state: 8\n",
      "Action prob: [0.97790605 0.02209397], Action: 1, state: 8\n",
      "Action prob: [0.9779178  0.02208222], Action: 0, state: 8\n",
      "Action prob: [0.98077184 0.0192282 ], Action: 0, state: 8\n",
      "Action prob: [0.98913294 0.01086708], Action: 0, state: 8\n",
      "Action prob: [0.98996526 0.01003474], Action: 0, state: 8\n",
      "Action prob: [0.98003286 0.01996714], Action: 0, state: 8\n",
      "Action prob: [0.9815622  0.01843787], Action: 0, state: 8\n",
      "Action prob: [0.98609644 0.01390355], Action: 0, state: 8\n",
      "Action prob: [0.98738843 0.01261156], Action: 0, state: 8\n",
      "Action prob: [0.98705286 0.01294709], Action: 0, state: 8\n",
      "Action prob: [0.9871589  0.01284111], Action: 0, state: 8\n",
      "Action prob: [0.98904806 0.01095195], Action: 0, state: 8\n",
      "Action prob: [0.9801512  0.01984886], Action: 0, state: 8\n",
      "Action prob: [0.97787994 0.02212008], Action: 0, state: 8\n",
      "Action prob: [0.9884382  0.01156177], Action: 0, state: 8\n",
      "Action prob: [0.991434   0.00856608], Action: 0, state: 8\n",
      "Action prob: [0.9817059  0.01829418], Action: 0, state: 8\n",
      "Action prob: [0.9778334  0.02216656], Action: 0, state: 8\n",
      "Action prob: [0.97899514 0.02100482], Action: 0, state: 8\n",
      "Action prob: [0.98866117 0.01133882], Action: 0, state: 8\n",
      "Action prob: [0.9698028  0.03019716], Action: 0, state: 8\n",
      "Action prob: [0.99276567 0.00723428], Action: 0, state: 8\n",
      "Action prob: [0.9870827  0.01291729], Action: 0, state: 8\n",
      "Action prob: [0.9812422  0.01875784], Action: 0, state: 8\n",
      "Action prob: [0.98731273 0.01268724], Action: 0, state: 8\n",
      "tensor([-5.9485e-02, -4.5128e-02, -3.4652e-02, -2.8607e-02, -2.0974e-02,\n",
      "        -1.4223e-02, -1.0223e-02, -7.4680e-03, -2.7280e-03, -5.1694e-05,\n",
      "         2.1785e-03,  3.9634e-03,  5.4545e-03,  6.9477e-03,  7.1440e-03,\n",
      "         8.4223e-03,  8.2199e-03,  9.7850e-03,  9.4009e-03,  9.1957e-03,\n",
      "         8.6506e-03,  1.0871e-02,  2.7249e+00,  5.7268e-03,  1.1283e-02,\n",
      "         1.9052e+00,  1.0201e-02,  8.1616e-03,  4.2545e-03,  3.6613e-03,\n",
      "         6.8702e-03,  5.9849e-03,  4.2762e-03,  3.7017e-03,  3.6485e-03,\n",
      "         3.4900e-03,  2.8807e-03,  5.1006e-03,  5.5543e-03,  2.8273e-03,\n",
      "         2.0537e-03,  4.3383e-03,  5.1956e-03,  4.8630e-03,  2.5860e-03,\n",
      "         6.8935e-03,  1.6202e-03,  2.8830e-03,  4.1762e-03,  2.8029e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -71000, loss is -0.09243677976673532\n",
      "Action prob: [0.98819333 0.01180672], Action: 0, state: 0\n",
      "Action prob: [0.9879773  0.01202266], Action: 0, state: 0\n",
      "Action prob: [0.98863167 0.01136836], Action: 0, state: 0\n",
      "Action prob: [0.988192   0.01180793], Action: 0, state: 0\n",
      "Action prob: [0.9882224  0.01177756], Action: 0, state: 0\n",
      "Action prob: [0.99131304 0.00868696], Action: 0, state: 0\n",
      "Action prob: [0.99074966 0.00925039], Action: 0, state: 1\n",
      "Action prob: [0.98907393 0.01092604], Action: 0, state: 1\n",
      "Action prob: [0.98756146 0.01243856], Action: 0, state: 1\n",
      "Action prob: [0.9857364  0.01426363], Action: 0, state: 2\n",
      "Action prob: [0.9882145  0.01178546], Action: 0, state: 2\n",
      "Action prob: [0.9891017  0.01089826], Action: 0, state: 2\n",
      "Action prob: [0.9887659  0.01123403], Action: 0, state: 2\n",
      "Action prob: [0.98724514 0.01275485], Action: 1, state: 2\n",
      "Action prob: [0.8420007  0.15799929], Action: 0, state: 6\n",
      "Action prob: [0.8420007  0.15799929], Action: 0, state: 6\n",
      "Action prob: [0.8420007  0.15799929], Action: 0, state: 6\n",
      "Action prob: [0.8420007  0.15799929], Action: 0, state: 6\n",
      "Action prob: [0.8420007  0.15799929], Action: 0, state: 6\n",
      "Action prob: [0.8420007  0.15799929], Action: 0, state: 6\n",
      "Action prob: [0.8420007  0.15799929], Action: 0, state: 6\n",
      "Action prob: [0.99050635 0.00949367], Action: 0, state: 1\n",
      "Action prob: [0.98814166 0.01185835], Action: 0, state: 2\n",
      "Action prob: [0.9885075  0.01149249], Action: 0, state: 2\n",
      "Action prob: [0.9923596  0.00764041], Action: 0, state: 3\n",
      "Action prob: [0.986826   0.01317407], Action: 0, state: 3\n",
      "Action prob: [0.98913646 0.01086356], Action: 0, state: 3\n",
      "Action prob: [0.9909372  0.00906288], Action: 0, state: 8\n",
      "Action prob: [0.9826126  0.01738744], Action: 0, state: 8\n",
      "Action prob: [0.9842858  0.01571418], Action: 0, state: 8\n",
      "Action prob: [0.99160296 0.00839699], Action: 0, state: 8\n",
      "Action prob: [0.981602   0.01839795], Action: 0, state: 8\n",
      "Action prob: [0.9904507 0.0095493], Action: 0, state: 8\n",
      "Action prob: [0.99267733 0.00732268], Action: 0, state: 8\n",
      "Action prob: [0.98872864 0.01127141], Action: 0, state: 8\n",
      "Action prob: [0.9913635  0.00863647], Action: 0, state: 8\n",
      "Action prob: [0.9827308 0.0172692], Action: 0, state: 8\n",
      "Action prob: [0.9831754  0.01682464], Action: 0, state: 8\n",
      "Action prob: [0.9827875  0.01721249], Action: 0, state: 8\n",
      "Action prob: [0.9817084  0.01829165], Action: 0, state: 8\n",
      "Action prob: [0.9924509  0.00754913], Action: 0, state: 8\n",
      "Action prob: [0.9896047  0.01039524], Action: 0, state: 8\n",
      "Action prob: [0.9834379  0.01656211], Action: 0, state: 8\n",
      "Action prob: [0.9897244  0.01027564], Action: 0, state: 8\n",
      "Action prob: [0.9857759  0.01422406], Action: 0, state: 8\n",
      "Action prob: [0.9896018  0.01039823], Action: 0, state: 8\n",
      "Action prob: [0.9872754  0.01272453], Action: 0, state: 8\n",
      "Action prob: [0.9908592  0.00914084], Action: 0, state: 8\n",
      "Action prob: [0.98936146 0.01063855], Action: 0, state: 8\n",
      "Action prob: [0.97433645 0.02566355], Action: 0, state: 8\n",
      "tensor([-5.0425e-02, -4.0672e-02, -2.9863e-02, -2.3446e-02, -1.6959e-02,\n",
      "        -8.4673e-03, -5.7416e-03, -3.4942e-03, -7.9170e-04,  1.8570e-03,\n",
      "         3.4725e-03,  4.7338e-03,  6.2162e-03,  2.8383e+00,  1.0272e-01,\n",
      "         9.4921e-02,  8.8287e-02,  8.2649e-02,  7.7856e-02,  7.3782e-02,\n",
      "         7.0320e-02,  4.1943e-03,  5.5230e-03,  5.5803e-03,  3.7833e-03,\n",
      "         6.6601e-03,  5.5686e-03,  4.2887e-03,  7.6854e-03,  6.4967e-03,\n",
      "         3.2582e-03,  6.7996e-03,  3.3486e-03,  2.4576e-03,  3.6496e-03,\n",
      "         2.7012e-03,  5.2685e-03,  5.0024e-03,  5.0062e-03,  5.2212e-03,\n",
      "         2.1077e-03,  2.8649e-03,  4.5222e-03,  2.7671e-03,  3.8031e-03,\n",
      "         2.7530e-03,  3.3503e-03,  2.3886e-03,  2.7684e-03,  6.7013e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -59800, loss is -0.06783586163821348\n",
      "Action prob: [0.99113023 0.00886978], Action: 0, state: 0\n",
      "Action prob: [0.9904909  0.00950908], Action: 0, state: 0\n",
      "Action prob: [0.99098575 0.00901422], Action: 0, state: 0\n",
      "Action prob: [0.9912509  0.00874915], Action: 0, state: 0\n",
      "Action prob: [0.9901715  0.00982848], Action: 0, state: 1\n",
      "Action prob: [0.9916419  0.00835813], Action: 0, state: 1\n",
      "Action prob: [0.99055064 0.00944938], Action: 0, state: 2\n",
      "Action prob: [0.9909354  0.00906466], Action: 0, state: 2\n",
      "Action prob: [0.98991907 0.01008095], Action: 0, state: 3\n",
      "Action prob: [0.99216664 0.00783344], Action: 0, state: 3\n",
      "Action prob: [0.992827   0.00717293], Action: 0, state: 8\n",
      "Action prob: [0.98840475 0.01159523], Action: 0, state: 8\n",
      "Action prob: [0.9876667  0.01233329], Action: 0, state: 8\n",
      "Action prob: [0.985092   0.01490795], Action: 0, state: 8\n",
      "Action prob: [0.9844498  0.01555017], Action: 0, state: 8\n",
      "Action prob: [0.9848652  0.01513479], Action: 0, state: 8\n",
      "Action prob: [0.97161084 0.02838923], Action: 0, state: 8\n",
      "Action prob: [0.98445684 0.01554311], Action: 0, state: 8\n",
      "Action prob: [0.98480994 0.01519008], Action: 0, state: 8\n",
      "Action prob: [0.9915509  0.00844909], Action: 0, state: 8\n",
      "Action prob: [0.9928958  0.00710419], Action: 0, state: 8\n",
      "Action prob: [0.9914124  0.00858756], Action: 0, state: 8\n",
      "Action prob: [0.9933007  0.00669937], Action: 0, state: 8\n",
      "Action prob: [0.9918426  0.00815738], Action: 0, state: 8\n",
      "Action prob: [0.99325514 0.00674478], Action: 0, state: 8\n",
      "Action prob: [0.9932179  0.00678211], Action: 0, state: 8\n",
      "Action prob: [0.9923677  0.00763231], Action: 0, state: 8\n",
      "Action prob: [0.9851959  0.01480414], Action: 0, state: 8\n",
      "Action prob: [0.9844295  0.01557055], Action: 0, state: 8\n",
      "Action prob: [0.9839685  0.01603147], Action: 0, state: 8\n",
      "Action prob: [0.9928889  0.00711109], Action: 0, state: 8\n",
      "Action prob: [0.9854079  0.01459211], Action: 0, state: 8\n",
      "Action prob: [0.99235475 0.00764523], Action: 0, state: 8\n",
      "Action prob: [0.9899104 0.0100895], Action: 0, state: 8\n",
      "Action prob: [0.986641   0.01335908], Action: 0, state: 8\n",
      "Action prob: [0.9930541  0.00694594], Action: 0, state: 8\n",
      "Action prob: [0.9930045  0.00699551], Action: 0, state: 8\n",
      "Action prob: [0.9925776  0.00742232], Action: 0, state: 8\n",
      "Action prob: [0.99209493 0.00790503], Action: 0, state: 8\n",
      "Action prob: [0.9842993  0.01570069], Action: 0, state: 8\n",
      "Action prob: [0.9861226  0.01387732], Action: 0, state: 8\n",
      "Action prob: [0.992694   0.00730595], Action: 0, state: 8\n",
      "Action prob: [0.9860458  0.01395417], Action: 0, state: 8\n",
      "Action prob: [0.9873045 0.0126955], Action: 0, state: 8\n",
      "Action prob: [0.98711175 0.01288828], Action: 0, state: 8\n",
      "Action prob: [0.99178195 0.00821807], Action: 0, state: 8\n",
      "Action prob: [0.9849759  0.01502417], Action: 0, state: 8\n",
      "Action prob: [0.9853093  0.01469067], Action: 0, state: 8\n",
      "Action prob: [0.99338293 0.00661713], Action: 0, state: 8\n",
      "Action prob: [0.99091303 0.00908695], Action: 0, state: 8\n",
      "tensor([-0.0064, -0.0003,  0.0050,  0.0093,  0.0142,  0.0148,  0.0191,  0.0202,\n",
      "         0.0236,  0.0190,  0.0140,  0.0179,  0.0147,  0.0134,  0.0100,  0.0065,\n",
      "         0.0071,  0.0015, -0.0006, -0.0013, -0.0017, -0.0028, -0.0026, -0.0037,\n",
      "        -0.0034, -0.0037, -0.0044, -0.0090, -0.0099, -0.0106, -0.0048, -0.0101,\n",
      "        -0.0054, -0.0072, -0.0097, -0.0051, -0.0052, -0.0055, -0.0059, -0.0119,\n",
      "        -0.0106, -0.0056, -0.0107, -0.0098, -0.0100, -0.0063, -0.0117, -0.0114,\n",
      "        -0.0051, -0.0071], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -115600, loss is 0.00018715332369855748\n",
      "Action prob: [0.991891 0.008109], Action: 0, state: 0\n",
      "Action prob: [0.992784   0.00721599], Action: 0, state: 0\n",
      "Action prob: [0.9935609  0.00643913], Action: 0, state: 1\n",
      "Action prob: [0.9927608  0.00723927], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.99145824 0.00854176], Action: 0, state: 2\n",
      "Action prob: [0.99257326 0.00742677], Action: 0, state: 2\n",
      "Action prob: [0.99321175 0.00678824], Action: 0, state: 2\n",
      "Action prob: [0.9918926  0.00810747], Action: 0, state: 2\n",
      "Action prob: [0.9934744  0.00652561], Action: 0, state: 3\n",
      "Action prob: [0.9941338  0.00586622], Action: 1, state: 3\n",
      "Action prob: [0.8441349  0.15586504], Action: 0, state: 7\n",
      "Action prob: [0.992019   0.00798099], Action: 0, state: 2\n",
      "Action prob: [0.99203426 0.00796572], Action: 0, state: 2\n",
      "Action prob: [0.9916469  0.00835304], Action: 0, state: 3\n",
      "Action prob: [0.9950458  0.00495421], Action: 0, state: 8\n",
      "Action prob: [0.9924614  0.00753861], Action: 0, state: 8\n",
      "Action prob: [0.9885514  0.01144859], Action: 0, state: 8\n",
      "Action prob: [0.98897374 0.01102623], Action: 0, state: 8\n",
      "Action prob: [0.99129534 0.00870462], Action: 0, state: 8\n",
      "Action prob: [0.9922052  0.00779483], Action: 0, state: 8\n",
      "Action prob: [0.9942245 0.0057755], Action: 1, state: 8\n",
      "Action prob: [0.9929817  0.00701827], Action: 0, state: 8\n",
      "Action prob: [0.9947719  0.00522815], Action: 0, state: 8\n",
      "Action prob: [0.9934863  0.00651371], Action: 0, state: 8\n",
      "Action prob: [0.9944365  0.00556343], Action: 0, state: 8\n",
      "Action prob: [0.99526477 0.00473519], Action: 0, state: 8\n",
      "Action prob: [0.99461764 0.00538239], Action: 0, state: 8\n",
      "Action prob: [0.99297607 0.00702396], Action: 0, state: 8\n",
      "Action prob: [0.9878563  0.01214372], Action: 0, state: 8\n",
      "Action prob: [0.99402714 0.0059728 ], Action: 0, state: 8\n",
      "Action prob: [0.9930394  0.00696063], Action: 0, state: 8\n",
      "Action prob: [0.9881787  0.01182132], Action: 0, state: 8\n",
      "Action prob: [0.993152   0.00684794], Action: 0, state: 8\n",
      "Action prob: [0.98823315 0.01176689], Action: 0, state: 8\n",
      "Action prob: [0.98798484 0.01201517], Action: 0, state: 8\n",
      "Action prob: [0.9851053  0.01489466], Action: 0, state: 8\n",
      "Action prob: [0.9910103 0.0089897], Action: 0, state: 8\n",
      "Action prob: [0.98746514 0.01253493], Action: 0, state: 8\n",
      "Action prob: [0.99321586 0.00678417], Action: 0, state: 8\n",
      "Action prob: [0.9935029  0.00649708], Action: 0, state: 8\n",
      "Action prob: [0.98916686 0.01083311], Action: 0, state: 8\n",
      "Action prob: [0.99489635 0.00510365], Action: 0, state: 8\n",
      "Action prob: [0.9870897  0.01291027], Action: 0, state: 8\n",
      "Action prob: [0.98668057 0.01331941], Action: 0, state: 8\n",
      "Action prob: [0.9866502  0.01334971], Action: 0, state: 8\n",
      "Action prob: [0.99433327 0.00566675], Action: 0, state: 8\n",
      "Action prob: [0.99425715 0.00574289], Action: 0, state: 8\n",
      "Action prob: [0.99291384 0.0070861 ], Action: 0, state: 8\n",
      "Action prob: [0.98684025 0.01315978], Action: 0, state: 8\n",
      "Action prob: [0.995169   0.00483095], Action: 0, state: 8\n",
      "tensor([-2.4005e-02, -1.3410e-02, -6.5421e-03, -2.1770e-03,  2.0514e-03,\n",
      "         5.1964e-03,  7.3995e-03,  1.1537e-02,  1.0429e-02,  8.9534e+00,\n",
      "         2.7372e-01,  1.4328e-02,  1.5475e-02,  1.6885e-02,  8.0218e-03,\n",
      "         9.6638e-03,  1.1396e-02,  8.2647e-03,  4.7016e-03,  2.8272e-03,\n",
      "         1.0889e+00,  5.8987e-04, -1.2913e-04, -7.6304e-04, -1.0883e-03,\n",
      "        -1.2418e-03, -1.7174e-03, -2.5820e-03, -4.9750e-03, -2.6475e-03,\n",
      "        -3.2931e-03, -5.9051e-03, -3.5588e-03, -6.3449e-03, -6.6660e-03,\n",
      "        -8.4723e-03, -5.1988e-03, -7.3814e-03, -4.0382e-03, -3.9114e-03,\n",
      "        -6.5993e-03, -3.1254e-03, -7.9918e-03, -8.2946e-03, -8.3544e-03,\n",
      "        -3.5473e-03, -3.6077e-03, -4.4678e-03, -8.3436e-03, -3.0567e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -102400, loss is -0.2054270996760208\n",
      "Action prob: [0.99492455 0.00507545], Action: 0, state: 0\n",
      "Action prob: [0.9939672 0.0060328], Action: 0, state: 1\n",
      "Action prob: [0.9949486  0.00505136], Action: 0, state: 1\n",
      "Action prob: [0.99476576 0.00523421], Action: 0, state: 1\n",
      "Action prob: [0.9952695  0.00473049], Action: 0, state: 2\n",
      "Action prob: [0.9937577  0.00624233], Action: 0, state: 3\n",
      "Action prob: [0.99531966 0.00468031], Action: 0, state: 8\n",
      "Action prob: [0.99257237 0.00742766], Action: 0, state: 8\n",
      "Action prob: [0.9915502  0.00844977], Action: 0, state: 8\n",
      "Action prob: [0.99617636 0.00382357], Action: 0, state: 8\n",
      "Action prob: [0.9911403  0.00885972], Action: 0, state: 8\n",
      "Action prob: [0.9947936  0.00520639], Action: 0, state: 8\n",
      "Action prob: [0.9971738  0.00282623], Action: 0, state: 8\n",
      "Action prob: [0.9942432  0.00575682], Action: 0, state: 8\n",
      "Action prob: [0.995346   0.00465393], Action: 0, state: 8\n",
      "Action prob: [0.99163264 0.00836734], Action: 0, state: 8\n",
      "Action prob: [0.996073   0.00392696], Action: 0, state: 8\n",
      "Action prob: [0.9963175  0.00368249], Action: 0, state: 8\n",
      "Action prob: [0.9948836  0.00511641], Action: 0, state: 8\n",
      "Action prob: [0.9960486  0.00395143], Action: 0, state: 8\n",
      "Action prob: [0.99051255 0.0094875 ], Action: 0, state: 8\n",
      "Action prob: [0.98998874 0.01001134], Action: 0, state: 8\n",
      "Action prob: [0.9961671  0.00383281], Action: 0, state: 8\n",
      "Action prob: [0.996197   0.00380307], Action: 0, state: 8\n",
      "Action prob: [0.9914069  0.00859307], Action: 0, state: 8\n",
      "Action prob: [0.9955336  0.00446639], Action: 0, state: 8\n",
      "Action prob: [0.9956605  0.00433947], Action: 0, state: 8\n",
      "Action prob: [0.98976517 0.01023484], Action: 0, state: 8\n",
      "Action prob: [0.99621046 0.00378958], Action: 0, state: 8\n",
      "Action prob: [0.9912914 0.0087086], Action: 0, state: 8\n",
      "Action prob: [0.99473923 0.00526078], Action: 0, state: 8\n",
      "Action prob: [0.9966809  0.00331902], Action: 0, state: 8\n",
      "Action prob: [0.9905363  0.00946377], Action: 0, state: 8\n",
      "Action prob: [0.9912698  0.00873014], Action: 0, state: 8\n",
      "Action prob: [0.9907245  0.00927554], Action: 0, state: 8\n",
      "Action prob: [0.9952996  0.00470042], Action: 0, state: 8\n",
      "Action prob: [0.9913624  0.00863768], Action: 0, state: 8\n",
      "Action prob: [0.9891823  0.01081774], Action: 0, state: 8\n",
      "Action prob: [0.9931744  0.00682563], Action: 0, state: 8\n",
      "Action prob: [0.9908433 0.0091567], Action: 0, state: 8\n",
      "Action prob: [0.9953738  0.00462626], Action: 0, state: 8\n",
      "Action prob: [0.9960375  0.00396254], Action: 0, state: 8\n",
      "Action prob: [0.99098957 0.00901042], Action: 0, state: 8\n",
      "Action prob: [0.99112344 0.00887656], Action: 0, state: 8\n",
      "Action prob: [0.99638546 0.0036146 ], Action: 0, state: 8\n",
      "Action prob: [0.9970188  0.00298125], Action: 0, state: 8\n",
      "Action prob: [0.9916264  0.00837354], Action: 0, state: 8\n",
      "Action prob: [0.9957683  0.00423168], Action: 0, state: 8\n",
      "Action prob: [0.9958087  0.00419132], Action: 0, state: 8\n",
      "Action prob: [0.99607605 0.00392394], Action: 0, state: 8\n",
      "tensor([ 0.0072,  0.0106,  0.0103,  0.0119,  0.0116,  0.0159,  0.0096,  0.0122,\n",
      "         0.0110,  0.0038,  0.0066,  0.0027,  0.0010,  0.0011,  0.0002, -0.0005,\n",
      "        -0.0006, -0.0009, -0.0016, -0.0015, -0.0040, -0.0046, -0.0019, -0.0020,\n",
      "        -0.0048, -0.0026, -0.0026, -0.0063, -0.0024, -0.0056, -0.0034, -0.0022,\n",
      "        -0.0063, -0.0058, -0.0063, -0.0032, -0.0059, -0.0074, -0.0047, -0.0063,\n",
      "        -0.0032, -0.0027, -0.0063, -0.0062, -0.0025, -0.0021, -0.0059, -0.0030,\n",
      "        -0.0029, -0.0027], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -131000, loss is 0.00029783103412262343\n",
      "Action prob: [0.99572194 0.00427806], Action: 0, state: 0\n",
      "Action prob: [0.9962966  0.00370339], Action: 0, state: 1\n",
      "Action prob: [0.9955712 0.0044288], Action: 0, state: 1\n",
      "Action prob: [0.99644715 0.00355293], Action: 0, state: 1\n",
      "Action prob: [0.99584085 0.00415916], Action: 0, state: 1\n",
      "Action prob: [0.9955664  0.00443361], Action: 0, state: 1\n",
      "Action prob: [0.996221   0.00377899], Action: 0, state: 2\n",
      "Action prob: [0.9957386  0.00426138], Action: 0, state: 2\n",
      "Action prob: [0.9956102  0.00438989], Action: 0, state: 2\n",
      "Action prob: [0.9964341  0.00356587], Action: 0, state: 2\n",
      "Action prob: [0.99604154 0.00395843], Action: 0, state: 2\n",
      "Action prob: [0.99608755 0.00391245], Action: 0, state: 3\n",
      "Action prob: [0.9951892  0.00481078], Action: 0, state: 3\n",
      "Action prob: [0.99229926 0.00770076], Action: 0, state: 8\n",
      "Action prob: [0.9975007  0.00249928], Action: 0, state: 8\n",
      "Action prob: [0.997191   0.00280901], Action: 0, state: 8\n",
      "Action prob: [0.9962954  0.00370458], Action: 0, state: 8\n",
      "Action prob: [0.9932388  0.00676124], Action: 0, state: 8\n",
      "Action prob: [0.9963909  0.00360913], Action: 0, state: 8\n",
      "Action prob: [0.99134594 0.00865404], Action: 0, state: 8\n",
      "Action prob: [0.9971723  0.00282775], Action: 0, state: 8\n",
      "Action prob: [0.9962238  0.00377624], Action: 0, state: 8\n",
      "Action prob: [0.9960079  0.00399204], Action: 0, state: 8\n",
      "Action prob: [0.98454857 0.01545142], Action: 0, state: 8\n",
      "Action prob: [0.9971132 0.0028867], Action: 0, state: 8\n",
      "Action prob: [0.997672   0.00232796], Action: 0, state: 8\n",
      "Action prob: [0.9934818  0.00651814], Action: 0, state: 8\n",
      "Action prob: [0.996671   0.00332906], Action: 0, state: 8\n",
      "Action prob: [0.9977895  0.00221055], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.9921812  0.00781886], Action: 0, state: 8\n",
      "Action prob: [0.99333173 0.00666826], Action: 0, state: 8\n",
      "Action prob: [0.9927832  0.00721684], Action: 0, state: 8\n",
      "Action prob: [0.99732035 0.00267969], Action: 0, state: 8\n",
      "Action prob: [0.992986   0.00701401], Action: 0, state: 8\n",
      "Action prob: [0.9965263  0.00347372], Action: 0, state: 8\n",
      "Action prob: [0.99785966 0.00214029], Action: 0, state: 8\n",
      "Action prob: [0.9962548  0.00374524], Action: 0, state: 8\n",
      "Action prob: [0.9924705  0.00752951], Action: 0, state: 8\n",
      "Action prob: [0.9975715  0.00242847], Action: 0, state: 8\n",
      "Action prob: [0.9966354  0.00336468], Action: 0, state: 8\n",
      "Action prob: [0.99392277 0.00607722], Action: 0, state: 8\n",
      "Action prob: [0.9939097  0.00609028], Action: 0, state: 8\n",
      "Action prob: [0.9961737  0.00382636], Action: 0, state: 8\n",
      "Action prob: [0.99276394 0.00723611], Action: 0, state: 8\n",
      "Action prob: [0.9936139  0.00638607], Action: 0, state: 8\n",
      "Action prob: [0.9954886  0.00451144], Action: 0, state: 8\n",
      "Action prob: [0.9966618  0.00333819], Action: 0, state: 8\n",
      "Action prob: [0.9972669  0.00273316], Action: 0, state: 8\n",
      "Action prob: [0.99661285 0.00338718], Action: 0, state: 8\n",
      "Action prob: [0.99837434 0.00162557], Action: 0, state: 8\n",
      "tensor([-1.1322e-02, -6.4455e-03, -4.3012e-03, -1.1250e-03,  9.9573e-04,\n",
      "         3.1578e-03,  4.0402e-03,  5.8508e-03,  7.1606e-03,  6.5962e-03,\n",
      "         8.0617e-03,  8.3553e-03,  1.0684e-02,  1.3814e-02,  3.5602e-03,\n",
      "         3.1311e-03,  3.1546e-03,  4.2488e-03,  1.5770e-03,  2.3864e-03,\n",
      "         3.8849e-04,  7.7297e-05, -3.1527e-04, -2.5410e-03, -6.7903e-04,\n",
      "        -6.8949e-04, -2.2734e-03, -1.3060e-03, -9.4958e-04, -3.6180e-03,\n",
      "        -3.2648e-03, -3.7008e-03, -1.4234e-03, -3.8508e-03, -1.9529e-03,\n",
      "        -1.2282e-03, -2.1891e-03, -4.4750e-03, -1.4575e-03, -2.0414e-03,\n",
      "        -3.7248e-03, -3.7604e-03, -2.3746e-03, -4.5221e-03, -4.0071e-03,\n",
      "        -2.8388e-03, -2.1060e-03, -1.7284e-03, -2.1477e-03, -1.0319e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -104500, loss is 4.303941067135903e-05\n",
      "Action prob: [0.9968258  0.00317425], Action: 0, state: 0\n",
      "Action prob: [0.99700963 0.00299037], Action: 0, state: 1\n",
      "Action prob: [0.99741036 0.0025897 ], Action: 0, state: 1\n",
      "Action prob: [0.9972812  0.00271883], Action: 0, state: 2\n",
      "Action prob: [0.9973667  0.00263329], Action: 0, state: 3\n",
      "Action prob: [0.9951623  0.00483769], Action: 0, state: 8\n",
      "Action prob: [0.997934 0.002066], Action: 0, state: 8\n",
      "Action prob: [0.99668944 0.00331053], Action: 0, state: 8\n",
      "Action prob: [0.994998   0.00500198], Action: 0, state: 8\n",
      "Action prob: [0.99713504 0.00286499], Action: 0, state: 8\n",
      "Action prob: [0.9978224  0.00217762], Action: 0, state: 8\n",
      "Action prob: [0.99451584 0.00548409], Action: 0, state: 8\n",
      "Action prob: [9.990646e-01 9.353515e-04], Action: 0, state: 8\n",
      "Action prob: [0.99711084 0.00288916], Action: 0, state: 8\n",
      "Action prob: [0.99718636 0.00281368], Action: 0, state: 8\n",
      "Action prob: [0.99726033 0.00273961], Action: 0, state: 8\n",
      "Action prob: [0.9956838  0.00431627], Action: 0, state: 8\n",
      "Action prob: [0.9948088  0.00519113], Action: 0, state: 8\n",
      "Action prob: [0.998317   0.00168303], Action: 0, state: 8\n",
      "Action prob: [0.9982583  0.00174167], Action: 0, state: 8\n",
      "Action prob: [0.9982834  0.00171666], Action: 0, state: 8\n",
      "Action prob: [0.99514186 0.00485816], Action: 0, state: 8\n",
      "Action prob: [0.99826473 0.00173528], Action: 0, state: 8\n",
      "Action prob: [0.994856   0.00514397], Action: 0, state: 8\n",
      "Action prob: [0.99523467 0.0047654 ], Action: 0, state: 8\n",
      "Action prob: [0.9959039  0.00409617], Action: 0, state: 8\n",
      "Action prob: [0.99677426 0.00322572], Action: 0, state: 8\n",
      "Action prob: [0.99796355 0.00203644], Action: 0, state: 8\n",
      "Action prob: [0.9952449  0.00475513], Action: 0, state: 8\n",
      "Action prob: [0.9950203  0.00497967], Action: 0, state: 8\n",
      "Action prob: [0.9983543  0.00164576], Action: 0, state: 8\n",
      "Action prob: [0.9941742  0.00582585], Action: 0, state: 8\n",
      "Action prob: [0.99835396 0.0016461 ], Action: 0, state: 8\n",
      "Action prob: [0.9980683 0.0019318], Action: 0, state: 8\n",
      "Action prob: [0.9942239  0.00577611], Action: 0, state: 8\n",
      "Action prob: [0.9982174  0.00178254], Action: 0, state: 8\n",
      "Action prob: [0.9981279  0.00187208], Action: 0, state: 8\n",
      "Action prob: [0.9982773  0.00172274], Action: 0, state: 8\n",
      "Action prob: [0.99461704 0.00538293], Action: 0, state: 8\n",
      "Action prob: [0.997917   0.00208304], Action: 0, state: 8\n",
      "Action prob: [0.9949274 0.0050726], Action: 0, state: 8\n",
      "Action prob: [0.99730706 0.00269299], Action: 0, state: 8\n",
      "Action prob: [0.9989048  0.00109521], Action: 0, state: 8\n",
      "Action prob: [0.99757046 0.00242957], Action: 0, state: 8\n",
      "Action prob: [0.9946919  0.00530804], Action: 0, state: 8\n",
      "Action prob: [0.9981395 0.0018605], Action: 0, state: 8\n",
      "Action prob: [0.99467236 0.00532769], Action: 0, state: 8\n",
      "Action prob: [0.9981761  0.00182391], Action: 0, state: 8\n",
      "Action prob: [0.9940003  0.00599975], Action: 0, state: 8\n",
      "Action prob: [0.99387413 0.00612589], Action: 0, state: 8\n",
      "tensor([ 5.7917e-03,  6.3066e-03,  6.0865e-03,  6.8872e-03,  6.9258e-03,\n",
      "         1.0341e-02,  3.5410e-03,  4.4934e-03,  5.2727e-03,  2.2765e-03,\n",
      "         1.2516e-03,  2.1320e-03,  2.1452e-04,  2.7354e-04, -5.6207e-05,\n",
      "        -3.2171e-04, -8.6503e-04, -1.4068e-03, -5.5595e-04, -6.6392e-04,\n",
      "        -7.2853e-04, -2.2438e-03, -8.5438e-04, -2.6738e-03, -2.5842e-03,\n",
      "        -2.2991e-03, -1.8624e-03, -1.2033e-03, -2.8696e-03, -3.0554e-03,\n",
      "        -1.0221e-03, -3.6680e-03, -1.0443e-03, -1.2358e-03, -3.7281e-03,\n",
      "        -1.1550e-03, -1.2191e-03, -1.1264e-03, -3.5386e-03, -1.3711e-03,\n",
      "        -3.3525e-03, -1.7815e-03, -7.2526e-04, -1.6125e-03, -3.5327e-03,\n",
      "        -1.2375e-03, -3.5531e-03, -1.2152e-03, -4.0086e-03, -4.0956e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -134900, loss is 0.0001334748330276701\n",
      "Action prob: [0.99822205 0.00177789], Action: 0, state: 0\n",
      "Action prob: [0.99776745 0.00223257], Action: 0, state: 1\n",
      "Action prob: [0.9977062  0.00229384], Action: 0, state: 2\n",
      "Action prob: [0.9975274  0.00247255], Action: 0, state: 3\n",
      "Action prob: [0.99827397 0.00172604], Action: 0, state: 8\n",
      "Action prob: [0.9943679  0.00563215], Action: 0, state: 8\n",
      "Action prob: [0.9955605  0.00443945], Action: 0, state: 8\n",
      "Action prob: [0.9979711  0.00202885], Action: 0, state: 8\n",
      "Action prob: [0.99870193 0.00129802], Action: 0, state: 8\n",
      "Action prob: [0.9952366  0.00476341], Action: 0, state: 8\n",
      "Action prob: [0.99591357 0.00408641], Action: 0, state: 8\n",
      "Action prob: [0.9987534  0.00124653], Action: 0, state: 8\n",
      "Action prob: [0.9985273  0.00147266], Action: 0, state: 8\n",
      "Action prob: [0.9960205  0.00397953], Action: 1, state: 8\n",
      "Action prob: [0.9954703  0.00452973], Action: 0, state: 8\n",
      "Action prob: [0.99855596 0.00144407], Action: 0, state: 8\n",
      "Action prob: [0.9957223  0.00427769], Action: 0, state: 8\n",
      "Action prob: [0.9961605  0.00383945], Action: 1, state: 8\n",
      "Action prob: [0.99827266 0.00172728], Action: 0, state: 8\n",
      "Action prob: [0.99812704 0.00187292], Action: 0, state: 8\n",
      "Action prob: [0.9960905  0.00390951], Action: 0, state: 8\n",
      "Action prob: [0.99566215 0.0043378 ], Action: 0, state: 8\n",
      "Action prob: [0.9984895  0.00151043], Action: 0, state: 8\n",
      "Action prob: [0.99868697 0.00131302], Action: 0, state: 8\n",
      "Action prob: [0.99820757 0.00179246], Action: 0, state: 8\n",
      "Action prob: [0.9985298  0.00147019], Action: 0, state: 8\n",
      "Action prob: [0.99831307 0.00168695], Action: 0, state: 8\n",
      "Action prob: [0.9967865  0.00321352], Action: 0, state: 8\n",
      "Action prob: [0.9986558  0.00134415], Action: 0, state: 8\n",
      "Action prob: [0.9984987  0.00150136], Action: 0, state: 8\n",
      "Action prob: [0.9963613  0.00363873], Action: 0, state: 8\n",
      "Action prob: [0.9966725  0.00332751], Action: 0, state: 8\n",
      "Action prob: [0.9984823  0.00151771], Action: 0, state: 8\n",
      "Action prob: [0.99631554 0.00368452], Action: 0, state: 8\n",
      "Action prob: [0.99826366 0.00173635], Action: 0, state: 8\n",
      "Action prob: [0.9970239  0.00297614], Action: 0, state: 8\n",
      "Action prob: [0.9984775  0.00152248], Action: 0, state: 8\n",
      "Action prob: [0.998218   0.00178199], Action: 0, state: 8\n",
      "Action prob: [0.9986908  0.00130924], Action: 0, state: 8\n",
      "Action prob: [0.99594516 0.00405489], Action: 0, state: 8\n",
      "Action prob: [0.9954131  0.00458691], Action: 0, state: 8\n",
      "Action prob: [0.99855536 0.00144467], Action: 0, state: 8\n",
      "Action prob: [0.9947277  0.00527229], Action: 0, state: 8\n",
      "Action prob: [0.99866295 0.00133706], Action: 0, state: 8\n",
      "Action prob: [0.9970132  0.00298682], Action: 0, state: 8\n",
      "Action prob: [0.9985323  0.00146773], Action: 0, state: 8\n",
      "Action prob: [0.99501437 0.00498558], Action: 0, state: 8\n",
      "Action prob: [0.9955533  0.00444666], Action: 0, state: 8\n",
      "Action prob: [0.9982357  0.00176427], Action: 0, state: 8\n",
      "Action prob: [0.9981358  0.00186415], Action: 0, state: 8\n",
      "tensor([ 3.9563e-03,  5.5257e-03,  6.1097e-03,  6.8339e-03,  3.8880e-03,\n",
      "         1.0264e-02,  6.4468e-03,  2.3068e-03,  1.1297e-03,  3.0725e-03,\n",
      "         1.8476e-03,  3.5894e-04,  2.1936e-04,  1.6999e-01, -3.1604e-04,\n",
      "        -2.2388e-04, -9.7503e-04, -1.6080e+00, -5.9036e-04, -7.2367e-04,\n",
      "        -1.6604e-03, -1.9826e-03, -7.3072e-04, -6.6568e-04, -9.4439e-04,\n",
      "        -7.9921e-04, -9.4122e-04, -1.8334e-03, -7.8007e-04, -8.8449e-04,\n",
      "        -2.1732e-03, -2.0081e-03, -9.2327e-04, -2.2607e-03, -1.0711e-03,\n",
      "        -1.8469e-03, -9.4840e-04, -1.1145e-03, -8.2125e-04, -2.5541e-03,\n",
      "        -2.8967e-03, -9.1268e-04, -3.3429e-03, -8.4729e-04, -1.8966e-03,\n",
      "        -9.3223e-04, -3.1750e-03, -2.8331e-03, -1.1233e-03, -1.1876e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -138800, loss is 0.02869968312384113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.9982316  0.00176847], Action: 0, state: 0\n",
      "Action prob: [0.9988668  0.00113327], Action: 0, state: 0\n",
      "Action prob: [0.9981071  0.00189291], Action: 0, state: 0\n",
      "Action prob: [0.9980615  0.00193846], Action: 0, state: 0\n",
      "Action prob: [0.9983121  0.00168785], Action: 0, state: 0\n",
      "Action prob: [0.9980811  0.00191896], Action: 0, state: 0\n",
      "Action prob: [0.99806494 0.00193507], Action: 0, state: 0\n",
      "Action prob: [0.99836    0.00163997], Action: 0, state: 1\n",
      "Action prob: [0.9984944  0.00150555], Action: 0, state: 1\n",
      "Action prob: [0.9981541  0.00184591], Action: 0, state: 2\n",
      "Action prob: [0.9979837  0.00201625], Action: 0, state: 2\n",
      "Action prob: [0.99792814 0.0020719 ], Action: 0, state: 2\n",
      "Action prob: [0.99854493 0.00145506], Action: 0, state: 3\n",
      "Action prob: [0.9984571  0.00154292], Action: 0, state: 8\n",
      "Action prob: [0.99893564 0.0010643 ], Action: 0, state: 8\n",
      "Action prob: [9.9903905e-01 9.6101972e-04], Action: 0, state: 8\n",
      "Action prob: [0.9988746  0.00112535], Action: 0, state: 8\n",
      "Action prob: [9.9912924e-01 8.7080547e-04], Action: 0, state: 8\n",
      "Action prob: [0.9986027  0.00139738], Action: 0, state: 8\n",
      "Action prob: [0.99700564 0.0029944 ], Action: 0, state: 8\n",
      "Action prob: [9.991211e-01 8.788451e-04], Action: 0, state: 8\n",
      "Action prob: [0.9969902  0.00300972], Action: 0, state: 8\n",
      "Action prob: [0.9988537 0.0011463], Action: 0, state: 8\n",
      "Action prob: [0.99858177 0.00141827], Action: 0, state: 8\n",
      "Action prob: [0.9967981  0.00320198], Action: 0, state: 8\n",
      "Action prob: [0.9980227  0.00197734], Action: 0, state: 8\n",
      "Action prob: [9.9902153e-01 9.7843760e-04], Action: 0, state: 8\n",
      "Action prob: [0.9977575  0.00224248], Action: 0, state: 8\n",
      "Action prob: [0.9969683  0.00303171], Action: 0, state: 8\n",
      "Action prob: [0.996655   0.00334501], Action: 0, state: 8\n",
      "Action prob: [0.9974451  0.00255493], Action: 0, state: 8\n",
      "Action prob: [0.99846894 0.00153099], Action: 0, state: 8\n",
      "Action prob: [0.9984523  0.00154766], Action: 0, state: 8\n",
      "Action prob: [0.9973242  0.00267574], Action: 0, state: 8\n",
      "Action prob: [0.99899083 0.00100915], Action: 0, state: 8\n",
      "Action prob: [0.99688137 0.00311862], Action: 0, state: 8\n",
      "Action prob: [0.99877673 0.00122331], Action: 0, state: 8\n",
      "Action prob: [0.99897504 0.00102499], Action: 0, state: 8\n",
      "Action prob: [9.9900633e-01 9.9363539e-04], Action: 0, state: 8\n",
      "Action prob: [0.996576   0.00342394], Action: 0, state: 8\n",
      "Action prob: [0.99836963 0.00163041], Action: 0, state: 8\n",
      "Action prob: [0.99737954 0.00262052], Action: 0, state: 8\n",
      "Action prob: [0.99867505 0.00132497], Action: 0, state: 8\n",
      "Action prob: [0.99660635 0.00339369], Action: 0, state: 8\n",
      "Action prob: [0.99896955 0.00103044], Action: 0, state: 8\n",
      "Action prob: [0.9967134  0.00328661], Action: 0, state: 8\n",
      "Action prob: [0.99695444 0.00304552], Action: 0, state: 8\n",
      "Action prob: [0.9968771 0.0031229], Action: 0, state: 8\n",
      "Action prob: [0.9988919  0.00110815], Action: 0, state: 8\n",
      "Action prob: [0.99621826 0.00378174], Action: 0, state: 8\n",
      "tensor([-5.3590e-03, -2.3482e-03, -2.3830e-03, -1.0992e-03,  3.5666e-05,\n",
      "         9.9984e-04,  1.8305e-03,  2.0842e-03,  2.3292e-03,  3.2415e-03,\n",
      "         3.8989e-03,  4.3189e-03,  3.1488e-03,  2.7087e-03,  1.4985e-03,\n",
      "         1.0693e-03,  9.7001e-04,  5.6478e-04,  6.5324e-04,  9.3921e-04,\n",
      "         1.6029e-04,  2.1418e-04, -2.6963e-05, -1.4744e-04, -5.5228e-04,\n",
      "        -4.5579e-04, -2.7376e-04, -7.2200e-04, -1.0848e-03, -1.2986e-03,\n",
      "        -1.0574e-03, -6.6691e-04, -7.0299e-04, -1.2585e-03, -4.8782e-04,\n",
      "        -1.5448e-03, -6.1726e-04, -5.2562e-04, -5.1654e-04, -1.8025e-03,\n",
      "        -8.6581e-04, -1.4036e-03, -7.1409e-04, -1.8415e-03, -5.6122e-04,\n",
      "        -1.7994e-03, -1.6731e-03, -1.7208e-03, -6.1150e-04, -2.0942e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -103300, loss is 0.0001510154816500832\n",
      "Action prob: [0.99841166 0.00158833], Action: 0, state: 0\n",
      "Action prob: [0.9982222  0.00177784], Action: 0, state: 1\n",
      "Action prob: [0.9984806  0.00151944], Action: 0, state: 1\n",
      "Action prob: [0.9987801  0.00121994], Action: 0, state: 1\n",
      "Action prob: [0.9985158  0.00148416], Action: 0, state: 1\n",
      "Action prob: [0.99848664 0.00151331], Action: 0, state: 1\n",
      "Action prob: [0.9983388  0.00166121], Action: 0, state: 2\n",
      "Action prob: [0.99857867 0.00142139], Action: 0, state: 3\n",
      "Action prob: [0.99885976 0.0011403 ], Action: 0, state: 8\n",
      "Action prob: [0.99865156 0.0013485 ], Action: 0, state: 8\n",
      "Action prob: [0.9973195  0.00268047], Action: 0, state: 8\n",
      "Action prob: [0.9971449  0.00285513], Action: 0, state: 8\n",
      "Action prob: [0.9970822  0.00291782], Action: 0, state: 8\n",
      "Action prob: [0.9974637  0.00253626], Action: 0, state: 8\n",
      "Action prob: [0.9975682  0.00243173], Action: 0, state: 8\n",
      "Action prob: [9.9910885e-01 8.9112885e-04], Action: 0, state: 8\n",
      "Action prob: [9.990133e-01 9.866500e-04], Action: 0, state: 8\n",
      "Action prob: [0.9985275  0.00147244], Action: 0, state: 8\n",
      "Action prob: [0.99700624 0.00299373], Action: 0, state: 8\n",
      "Action prob: [0.99838936 0.00161069], Action: 0, state: 8\n",
      "Action prob: [0.9959455  0.00405446], Action: 0, state: 8\n",
      "Action prob: [0.99867743 0.00132258], Action: 0, state: 8\n",
      "Action prob: [0.9970221  0.00297784], Action: 0, state: 8\n",
      "Action prob: [0.9989666  0.00103342], Action: 0, state: 8\n",
      "Action prob: [0.9969248  0.00307519], Action: 0, state: 8\n",
      "Action prob: [0.9967963  0.00320367], Action: 0, state: 8\n",
      "Action prob: [9.9912816e-01 8.7182655e-04], Action: 0, state: 8\n",
      "Action prob: [0.99669063 0.00330936], Action: 0, state: 8\n",
      "Action prob: [9.9902904e-01 9.7098807e-04], Action: 0, state: 8\n",
      "Action prob: [9.9917185e-01 8.2816905e-04], Action: 0, state: 8\n",
      "Action prob: [9.9926573e-01 7.3427055e-04], Action: 0, state: 8\n",
      "Action prob: [0.99896157 0.00103841], Action: 0, state: 8\n",
      "Action prob: [0.99894017 0.00105982], Action: 0, state: 8\n",
      "Action prob: [0.998833   0.00116703], Action: 0, state: 8\n",
      "Action prob: [9.9902344e-01 9.7657507e-04], Action: 0, state: 8\n",
      "Action prob: [9.9934477e-01 6.5524527e-04], Action: 0, state: 8\n",
      "Action prob: [0.9978264  0.00217361], Action: 0, state: 8\n",
      "Action prob: [0.9972011  0.00279887], Action: 0, state: 8\n",
      "Action prob: [9.9923503e-01 7.6497660e-04], Action: 0, state: 8\n",
      "Action prob: [9.9906164e-01 9.3831978e-04], Action: 0, state: 8\n",
      "Action prob: [0.99894506 0.00105493], Action: 0, state: 8\n",
      "Action prob: [0.99860674 0.00139326], Action: 0, state: 8\n",
      "Action prob: [9.99022e-01 9.77953e-04], Action: 0, state: 8\n",
      "Action prob: [9.9910456e-01 8.9543563e-04], Action: 0, state: 8\n",
      "Action prob: [0.9969373  0.00306274], Action: 0, state: 8\n",
      "Action prob: [9.9916661e-01 8.3340623e-04], Action: 0, state: 8\n",
      "Action prob: [0.9973877  0.00261229], Action: 0, state: 8\n",
      "Action prob: [0.9975083  0.00249167], Action: 0, state: 8\n",
      "Action prob: [0.99760675 0.00239327], Action: 0, state: 8\n",
      "Action prob: [0.9978781  0.00212192], Action: 0, state: 8\n",
      "tensor([ 8.2277e-04,  1.7286e-03,  2.0638e-03,  2.0571e-03,  2.9171e-03,\n",
      "         3.3332e-03,  3.9567e-03,  3.5202e-03,  2.2703e-03,  2.1289e-03,\n",
      "         3.2941e-03,  2.6574e-03,  1.9761e-03,  1.1708e-03,  6.7717e-04,\n",
      "         1.0934e-04, -9.3938e-06, -1.7956e-04, -6.5163e-04, -4.8116e-04,\n",
      "        -1.4930e-03, -5.6396e-04, -1.4195e-03, -5.3594e-04, -1.7074e-03,\n",
      "        -1.8770e-03, -5.3291e-04, -2.0986e-03, -6.3327e-04, -5.5333e-04,\n",
      "        -5.0056e-04, -7.2001e-04, -7.4526e-04, -8.3040e-04, -7.0175e-04,\n",
      "        -4.7472e-04, -1.5871e-03, -2.0566e-03, -5.6434e-04, -6.9527e-04,\n",
      "        -7.8452e-04, -1.0395e-03, -7.3138e-04, -6.7109e-04, -2.3021e-03,\n",
      "        -6.2672e-04, -1.9689e-03, -1.8800e-03, -1.8074e-03, -1.6036e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -123200, loss is 6.886965408496185e-06\n",
      "Action prob: [0.9988337  0.00116626], Action: 0, state: 0\n",
      "Action prob: [0.9987136  0.00128635], Action: 0, state: 1\n",
      "Action prob: [0.9989569  0.00104308], Action: 0, state: 1\n",
      "Action prob: [0.9988061 0.0011939], Action: 0, state: 1\n",
      "Action prob: [0.99895835 0.00104162], Action: 0, state: 1\n",
      "Action prob: [0.99886763 0.00113237], Action: 0, state: 2\n",
      "Action prob: [0.9988858  0.00111423], Action: 0, state: 2\n",
      "Action prob: [0.9988342 0.0011658], Action: 0, state: 3\n",
      "Action prob: [0.9980349  0.00196513], Action: 0, state: 8\n",
      "Action prob: [0.9979493  0.00205074], Action: 0, state: 8\n",
      "Action prob: [0.9977982  0.00220181], Action: 0, state: 8\n",
      "Action prob: [9.990392e-01 9.608430e-04], Action: 0, state: 8\n",
      "Action prob: [9.9941456e-01 5.8544392e-04], Action: 0, state: 8\n",
      "Action prob: [9.991749e-01 8.250889e-04], Action: 0, state: 8\n",
      "Action prob: [0.99787223 0.00212771], Action: 0, state: 8\n",
      "Action prob: [0.99893457 0.0010654 ], Action: 0, state: 8\n",
      "Action prob: [9.992569e-01 7.430429e-04], Action: 0, state: 8\n",
      "Action prob: [0.9981402  0.00185978], Action: 0, state: 8\n",
      "Action prob: [0.99705744 0.00294258], Action: 0, state: 8\n",
      "Action prob: [9.9901855e-01 9.8144496e-04], Action: 0, state: 8\n",
      "Action prob: [0.9978969  0.00210306], Action: 0, state: 8\n",
      "Action prob: [9.9930334e-01 6.9669395e-04], Action: 0, state: 8\n",
      "Action prob: [9.9920362e-01 7.9645106e-04], Action: 0, state: 8\n",
      "Action prob: [9.9967229e-01 3.2774892e-04], Action: 0, state: 8\n",
      "Action prob: [9.9906474e-01 9.3531370e-04], Action: 0, state: 8\n",
      "Action prob: [9.993492e-01 6.507954e-04], Action: 0, state: 8\n",
      "Action prob: [9.9911708e-01 8.8288804e-04], Action: 0, state: 8\n",
      "Action prob: [9.9926490e-01 7.3509215e-04], Action: 0, state: 8\n",
      "Action prob: [9.9920887e-01 7.9116505e-04], Action: 0, state: 8\n",
      "Action prob: [9.992483e-01 7.516143e-04], Action: 0, state: 8\n",
      "Action prob: [0.9988569  0.00114307], Action: 0, state: 8\n",
      "Action prob: [0.9975802  0.00241983], Action: 0, state: 8\n",
      "Action prob: [0.99834895 0.00165102], Action: 0, state: 8\n",
      "Action prob: [9.990996e-01 9.003591e-04], Action: 0, state: 8\n",
      "Action prob: [9.9945134e-01 5.4862513e-04], Action: 0, state: 8\n",
      "Action prob: [9.9937904e-01 6.2094140e-04], Action: 0, state: 8\n",
      "Action prob: [0.9977124  0.00228768], Action: 0, state: 8\n",
      "Action prob: [9.991829e-01 8.170938e-04], Action: 0, state: 8\n",
      "Action prob: [9.9906236e-01 9.3770103e-04], Action: 0, state: 8\n",
      "Action prob: [0.9961784  0.00382163], Action: 0, state: 8\n",
      "Action prob: [9.9948275e-01 5.1724259e-04], Action: 0, state: 8\n",
      "Action prob: [9.9922454e-01 7.7544159e-04], Action: 0, state: 8\n",
      "Action prob: [0.9980393  0.00196072], Action: 0, state: 8\n",
      "Action prob: [0.9989962  0.00100384], Action: 0, state: 8\n",
      "Action prob: [0.99843127 0.00156871], Action: 0, state: 8\n",
      "Action prob: [9.9952698e-01 4.7298154e-04], Action: 0, state: 8\n",
      "Action prob: [9.9930668e-01 6.9334474e-04], Action: 0, state: 8\n",
      "Action prob: [9.9911112e-01 8.8887056e-04], Action: 0, state: 8\n",
      "Action prob: [0.9979532  0.00204679], Action: 0, state: 8\n",
      "Action prob: [9.9927455e-01 7.2542345e-04], Action: 0, state: 8\n",
      "tensor([ 6.2949e-04,  1.2766e-03,  1.4363e-03,  2.0344e-03,  2.0644e-03,\n",
      "         2.4821e-03,  2.6411e-03,  2.8740e-03,  3.8957e-03,  3.2222e-03,\n",
      "         2.6901e-03,  8.8786e-04,  3.9312e-04,  3.7710e-04,  5.8480e-04,\n",
      "         1.2749e-04, -8.9996e-06, -2.3093e-04, -6.4600e-04, -2.9468e-04,\n",
      "        -7.7654e-04, -2.9778e-04, -3.7999e-04, -1.7017e-04, -5.1938e-04,\n",
      "        -3.8123e-04, -5.4015e-04, -4.6589e-04, -5.1625e-04, -5.0246e-04,\n",
      "        -7.7974e-04, -1.6796e-03, -1.1617e-03, -6.4077e-04, -3.9427e-04,\n",
      "        -4.4997e-04, -1.6708e-03, -5.9989e-04, -6.9187e-04, -2.8360e-03,\n",
      "        -3.8459e-04, -5.7841e-04, -1.4671e-03, -7.5239e-04, -1.1784e-03,\n",
      "        -3.5567e-04, -5.2208e-04, -6.7016e-04, -1.5456e-03, -5.4787e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -123300, loss is -5.958932283700823e-05\n",
      "Action prob: [9.990060e-01 9.940057e-04], Action: 0, state: 0\n",
      "Action prob: [0.9989833 0.0010167], Action: 0, state: 1\n",
      "Action prob: [9.992755e-01 7.244770e-04], Action: 0, state: 1\n",
      "Action prob: [0.99898404 0.00101599], Action: 0, state: 1\n",
      "Action prob: [9.9913955e-01 8.6040853e-04], Action: 0, state: 1\n",
      "Action prob: [9.9923956e-01 7.6041080e-04], Action: 0, state: 2\n",
      "Action prob: [9.9918157e-01 8.1836467e-04], Action: 0, state: 2\n",
      "Action prob: [9.9922025e-01 7.7978993e-04], Action: 0, state: 3\n",
      "Action prob: [0.99793565 0.00206442], Action: 0, state: 3\n",
      "Action prob: [9.9903071e-01 9.6927537e-04], Action: 0, state: 3\n",
      "Action prob: [9.992785e-01 7.214950e-04], Action: 0, state: 3\n",
      "Action prob: [9.990952e-01 9.048019e-04], Action: 0, state: 3\n",
      "Action prob: [0.99836415 0.0016359 ], Action: 0, state: 3\n",
      "Action prob: [0.9979937  0.00200633], Action: 0, state: 8\n",
      "Action prob: [0.99775934 0.00224067], Action: 0, state: 8\n",
      "Action prob: [9.994804e-01 5.196101e-04], Action: 0, state: 8\n",
      "Action prob: [9.9952376e-01 4.7623797e-04], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [9.9910200e-01 8.9804595e-04], Action: 0, state: 8\n",
      "Action prob: [9.9932146e-01 6.7854091e-04], Action: 0, state: 8\n",
      "Action prob: [0.9984602  0.00153982], Action: 0, state: 8\n",
      "Action prob: [9.9942231e-01 5.7773513e-04], Action: 0, state: 8\n",
      "Action prob: [9.9952054e-01 4.7947338e-04], Action: 0, state: 8\n",
      "Action prob: [9.995340e-01 4.659873e-04], Action: 0, state: 8\n",
      "Action prob: [0.9979406  0.00205938], Action: 0, state: 8\n",
      "Action prob: [0.9979457  0.00205429], Action: 0, state: 8\n",
      "Action prob: [9.9920732e-01 7.9275144e-04], Action: 0, state: 8\n",
      "Action prob: [0.99827063 0.00172936], Action: 0, state: 8\n",
      "Action prob: [9.9956566e-01 4.3436707e-04], Action: 0, state: 8\n",
      "Action prob: [9.992594e-01 7.405755e-04], Action: 0, state: 8\n",
      "Action prob: [9.9927276e-01 7.2718569e-04], Action: 0, state: 8\n",
      "Action prob: [9.9931443e-01 6.8559655e-04], Action: 0, state: 8\n",
      "Action prob: [9.9927694e-01 7.2306511e-04], Action: 0, state: 8\n",
      "Action prob: [9.9943322e-01 5.6678633e-04], Action: 0, state: 8\n",
      "Action prob: [9.9933136e-01 6.6864496e-04], Action: 0, state: 8\n",
      "Action prob: [9.992009e-01 7.990771e-04], Action: 0, state: 8\n",
      "Action prob: [0.99872726 0.00127273], Action: 0, state: 8\n",
      "Action prob: [9.993038e-01 6.961899e-04], Action: 0, state: 8\n",
      "Action prob: [0.99830085 0.0016992 ], Action: 0, state: 8\n",
      "Action prob: [9.9932647e-01 6.7357626e-04], Action: 0, state: 8\n",
      "Action prob: [9.9938810e-01 6.1194133e-04], Action: 0, state: 8\n",
      "Action prob: [0.99863476 0.0013652 ], Action: 0, state: 8\n",
      "Action prob: [0.99816567 0.00183442], Action: 0, state: 8\n",
      "Action prob: [9.9925965e-01 7.4028544e-04], Action: 0, state: 8\n",
      "Action prob: [0.9982545  0.00174553], Action: 0, state: 8\n",
      "Action prob: [9.9948823e-01 5.1172986e-04], Action: 0, state: 8\n",
      "Action prob: [9.9930000e-01 7.0002634e-04], Action: 0, state: 8\n",
      "Action prob: [9.994777e-01 5.222858e-04], Action: 0, state: 8\n",
      "Action prob: [9.993880e-01 6.120385e-04], Action: 0, state: 8\n",
      "Action prob: [9.9957055e-01 4.2945400e-04], Action: 0, state: 8\n",
      "Action prob: [0.9986218  0.00137821], Action: 0, state: 8\n",
      "tensor([-2.2972e-03, -1.4231e-03, -4.5282e-04,  3.3848e-05,  5.1019e-04,\n",
      "         7.7238e-04,  1.1254e-03,  1.2211e-03,  3.5701e-03,  1.8091e-03,\n",
      "         1.4311e-03,  1.8850e-03,  3.5478e-03,  3.4847e-03,  3.0688e-03,\n",
      "         5.4883e-04,  3.7671e-04,  5.0794e-04,  2.5369e-04,  3.2496e-04,\n",
      "         4.1853e-05, -2.1702e-05, -6.7715e-05, -4.7478e-04, -6.2221e-04,\n",
      "        -2.8866e-04, -7.2042e-04, -2.0010e-04, -3.6919e-04, -3.8586e-04,\n",
      "        -3.8244e-04, -4.2012e-04, -3.4046e-04, -4.1286e-04, -5.0483e-04,\n",
      "        -8.1963e-04, -4.5536e-04, -1.1268e-03, -4.5143e-04, -4.1398e-04,\n",
      "        -9.3132e-04, -1.2600e-03, -5.1113e-04, -1.2115e-03, -3.5640e-04,\n",
      "        -4.8920e-04, -3.6605e-04, -4.2999e-04, -3.0232e-04, -9.7238e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -105800, loss is -0.00010063337794375371\n",
      "Action prob: [9.991429e-01 8.571338e-04], Action: 0, state: 0\n",
      "Action prob: [9.9932706e-01 6.7294936e-04], Action: 0, state: 0\n",
      "Action prob: [9.9918956e-01 8.1039424e-04], Action: 0, state: 0\n",
      "Action prob: [9.9933249e-01 6.6745374e-04], Action: 0, state: 0\n",
      "Action prob: [9.9936277e-01 6.3718908e-04], Action: 0, state: 0\n",
      "Action prob: [9.9922276e-01 7.7726267e-04], Action: 0, state: 0\n",
      "Action prob: [9.9938118e-01 6.1883195e-04], Action: 0, state: 1\n",
      "Action prob: [9.9929798e-01 7.0206105e-04], Action: 0, state: 2\n",
      "Action prob: [9.990427e-01 9.572392e-04], Action: 0, state: 3\n",
      "Action prob: [9.9927348e-01 7.2652457e-04], Action: 0, state: 3\n",
      "Action prob: [9.9949229e-01 5.0774595e-04], Action: 0, state: 3\n",
      "Action prob: [9.9963295e-01 3.6703714e-04], Action: 0, state: 8\n",
      "Action prob: [0.99862564 0.0013744 ], Action: 0, state: 8\n",
      "Action prob: [0.9980794  0.00192053], Action: 0, state: 8\n",
      "Action prob: [9.9930394e-01 6.9605320e-04], Action: 0, state: 8\n",
      "Action prob: [0.9984555  0.00154452], Action: 0, state: 8\n",
      "Action prob: [9.9963558e-01 3.6445176e-04], Action: 0, state: 8\n",
      "Action prob: [0.998431   0.00156894], Action: 0, state: 8\n",
      "Action prob: [9.9951851e-01 4.8150835e-04], Action: 0, state: 8\n",
      "Action prob: [9.9983525e-01 1.6472080e-04], Action: 0, state: 8\n",
      "Action prob: [0.9984425  0.00155755], Action: 0, state: 8\n",
      "Action prob: [9.9940157e-01 5.9839233e-04], Action: 0, state: 8\n",
      "Action prob: [9.994742e-01 5.258254e-04], Action: 0, state: 8\n",
      "Action prob: [9.995962e-01 4.038171e-04], Action: 0, state: 8\n",
      "Action prob: [9.996698e-01 3.302056e-04], Action: 0, state: 8\n",
      "Action prob: [9.9937183e-01 6.2820717e-04], Action: 0, state: 8\n",
      "Action prob: [9.9953651e-01 4.6347422e-04], Action: 0, state: 8\n",
      "Action prob: [9.994042e-01 5.957988e-04], Action: 0, state: 8\n",
      "Action prob: [0.99887604 0.00112398], Action: 0, state: 8\n",
      "Action prob: [0.99844116 0.00155888], Action: 0, state: 8\n",
      "Action prob: [0.998978   0.00102203], Action: 0, state: 8\n",
      "Action prob: [9.9951041e-01 4.8954785e-04], Action: 0, state: 8\n",
      "Action prob: [0.9982957  0.00170424], Action: 0, state: 8\n",
      "Action prob: [9.9950564e-01 4.9433153e-04], Action: 0, state: 8\n",
      "Action prob: [9.994004e-01 5.996347e-04], Action: 0, state: 8\n",
      "Action prob: [9.9959272e-01 4.0729853e-04], Action: 0, state: 8\n",
      "Action prob: [0.99818426 0.00181571], Action: 0, state: 8\n",
      "Action prob: [9.9942219e-01 5.7788246e-04], Action: 0, state: 8\n",
      "Action prob: [9.9941254e-01 5.8749708e-04], Action: 0, state: 8\n",
      "Action prob: [9.9956876e-01 4.3124799e-04], Action: 0, state: 8\n",
      "Action prob: [9.991874e-01 8.125881e-04], Action: 0, state: 8\n",
      "Action prob: [9.9958509e-01 4.1491096e-04], Action: 0, state: 8\n",
      "Action prob: [0.9989165  0.00108349], Action: 0, state: 8\n",
      "Action prob: [0.9986695  0.00133054], Action: 0, state: 8\n",
      "Action prob: [0.9959649  0.00403505], Action: 0, state: 8\n",
      "Action prob: [9.9965012e-01 3.4982557e-04], Action: 0, state: 8\n",
      "Action prob: [9.995480e-01 4.520135e-04], Action: 0, state: 8\n",
      "Action prob: [9.9956626e-01 4.3374166e-04], Action: 0, state: 8\n",
      "Action prob: [9.9984992e-01 1.5005087e-04], Action: 0, state: 8\n",
      "Action prob: [9.9959403e-01 4.0592847e-04], Action: 0, state: 8\n",
      "tensor([-1.2461e-03, -4.4487e-04,  1.0231e-05,  3.9067e-04,  6.8312e-04,\n",
      "         1.1549e-03,  1.1152e-03,  1.4331e-03,  2.0762e-03,  1.6539e-03,\n",
      "         1.2023e-03,  6.9732e-04,  2.0653e-03,  2.2369e-03,  6.1010e-04,\n",
      "         9.7674e-04,  1.5465e-04,  3.8908e-04,  4.7086e-05, -4.9013e-06,\n",
      "        -2.1532e-04, -1.3784e-04, -1.6228e-04, -1.5152e-04, -1.4258e-04,\n",
      "        -3.0150e-04, -2.4139e-04, -3.3103e-04, -6.5786e-04, -9.5176e-04,\n",
      "        -6.4563e-04, -3.1810e-04, -1.1343e-03, -3.3530e-04, -4.1340e-04,\n",
      "        -2.8462e-04, -1.2844e-03, -4.1243e-04, -4.2274e-04, -3.1243e-04,\n",
      "        -5.9224e-04, -3.0382e-04, -7.9695e-04, -9.8219e-04, -2.9917e-03,\n",
      "        -2.5958e-04, -3.3606e-04, -3.2308e-04, -1.1195e-04, -3.0325e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -111800, loss is 1.3124160403797146e-05\n",
      "Action prob: [9.993575e-01 6.425033e-04], Action: 0, state: 0\n",
      "Action prob: [9.9943405e-01 5.6588318e-04], Action: 0, state: 0\n",
      "Action prob: [9.9941087e-01 5.8911275e-04], Action: 0, state: 0\n",
      "Action prob: [9.9943763e-01 5.6230021e-04], Action: 0, state: 1\n",
      "Action prob: [9.9932706e-01 6.7293714e-04], Action: 0, state: 1\n",
      "Action prob: [9.992353e-01 7.647704e-04], Action: 0, state: 1\n",
      "Action prob: [9.9950147e-01 4.9852731e-04], Action: 0, state: 2\n",
      "Action prob: [9.9929416e-01 7.0587429e-04], Action: 0, state: 3\n",
      "Action prob: [0.99850696 0.00149305], Action: 0, state: 8\n",
      "Action prob: [9.996562e-01 3.438526e-04], Action: 0, state: 8\n",
      "Action prob: [9.9967694e-01 3.2302909e-04], Action: 0, state: 8\n",
      "Action prob: [9.9971527e-01 2.8473450e-04], Action: 0, state: 8\n",
      "Action prob: [0.99858296 0.00141711], Action: 0, state: 8\n",
      "Action prob: [0.9986743  0.00132571], Action: 0, state: 8\n",
      "Action prob: [9.996049e-01 3.951184e-04], Action: 0, state: 8\n",
      "Action prob: [9.9965346e-01 3.4650887e-04], Action: 0, state: 8\n",
      "Action prob: [9.9953818e-01 4.6183539e-04], Action: 0, state: 8\n",
      "Action prob: [9.996024e-01 3.976270e-04], Action: 0, state: 8\n",
      "Action prob: [0.99872893 0.00127101], Action: 0, state: 8\n",
      "Action prob: [9.9966729e-01 3.3275876e-04], Action: 0, state: 8\n",
      "Action prob: [9.9962795e-01 3.7207792e-04], Action: 0, state: 8\n",
      "Action prob: [9.9945623e-01 5.4378004e-04], Action: 0, state: 8\n",
      "Action prob: [9.9953008e-01 4.6992925e-04], Action: 0, state: 8\n",
      "Action prob: [9.995566e-01 4.433287e-04], Action: 0, state: 8\n",
      "Action prob: [0.9984761  0.00152388], Action: 0, state: 8\n",
      "Action prob: [9.995797e-01 4.202558e-04], Action: 0, state: 8\n",
      "Action prob: [9.9937195e-01 6.2811561e-04], Action: 0, state: 8\n",
      "Action prob: [9.9958295e-01 4.1703696e-04], Action: 0, state: 8\n",
      "Action prob: [9.9920160e-01 7.9837645e-04], Action: 0, state: 8\n",
      "Action prob: [0.99862015 0.00137984], Action: 0, state: 8\n",
      "Action prob: [9.996111e-01 3.888990e-04], Action: 0, state: 8\n",
      "Action prob: [0.99853706 0.00146299], Action: 0, state: 8\n",
      "Action prob: [9.9954790e-01 4.5201692e-04], Action: 0, state: 8\n",
      "Action prob: [0.9988273  0.00117277], Action: 0, state: 8\n",
      "Action prob: [9.994943e-01 5.056394e-04], Action: 0, state: 8\n",
      "Action prob: [9.9909449e-01 9.0557215e-04], Action: 0, state: 8\n",
      "Action prob: [9.9972826e-01 2.7169831e-04], Action: 0, state: 8\n",
      "Action prob: [0.9982126  0.00178742], Action: 0, state: 8\n",
      "Action prob: [9.9950767e-01 4.9232732e-04], Action: 0, state: 8\n",
      "Action prob: [9.9968147e-01 3.1851322e-04], Action: 0, state: 8\n",
      "Action prob: [9.9911386e-01 8.8608969e-04], Action: 0, state: 8\n",
      "Action prob: [9.9957007e-01 4.2988366e-04], Action: 0, state: 8\n",
      "Action prob: [0.9984854  0.00151466], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [9.9953759e-01 4.6243452e-04], Action: 0, state: 8\n",
      "Action prob: [0.9989213  0.00107879], Action: 0, state: 8\n",
      "Action prob: [9.9984062e-01 1.5940939e-04], Action: 0, state: 8\n",
      "Action prob: [9.9968863e-01 3.1133834e-04], Action: 0, state: 8\n",
      "Action prob: [9.9951315e-01 4.8690429e-04], Action: 0, state: 8\n",
      "Action prob: [0.9987207  0.00127931], Action: 0, state: 8\n",
      "Action prob: [9.9959928e-01 4.0079062e-04], Action: 0, state: 8\n",
      "tensor([ 2.7491e-04,  5.2813e-04,  8.0281e-04,  9.5111e-04,  1.3261e-03,\n",
      "         1.6886e-03,  1.1901e-03,  1.7524e-03,  2.9824e-03,  5.4437e-04,\n",
      "         3.9810e-04,  2.6590e-04,  9.6445e-04,  6.1629e-04,  1.1118e-04,\n",
      "         4.3526e-05, -3.1429e-06, -4.7458e-05, -2.7343e-04, -9.8593e-05,\n",
      "        -1.3597e-04, -2.3069e-04, -2.2282e-04, -2.2906e-04, -8.4271e-04,\n",
      "        -2.4517e-04, -3.8279e-04, -2.6340e-04, -5.1939e-04, -9.2000e-04,\n",
      "        -2.6447e-04, -1.0123e-03, -3.1712e-04, -8.3270e-04, -3.6254e-04,\n",
      "        -6.5478e-04, -1.9783e-04, -1.3100e-03, -3.6244e-04, -2.3547e-04,\n",
      "        -6.5764e-04, -3.1997e-04, -1.1308e-03, -3.4581e-04, -8.0847e-04,\n",
      "        -1.1959e-04, -2.3396e-04, -3.6626e-04, -9.6373e-04, -3.0199e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -123000, loss is 1.5439692298536988e-05\n",
      "Action prob: [9.9946529e-01 5.3472474e-04], Action: 0, state: 0\n",
      "Action prob: [9.9952614e-01 4.7385250e-04], Action: 0, state: 1\n",
      "Action prob: [9.9929333e-01 7.0664496e-04], Action: 0, state: 1\n",
      "Action prob: [9.994715e-01 5.285499e-04], Action: 0, state: 1\n",
      "Action prob: [9.9938703e-01 6.1299384e-04], Action: 0, state: 1\n",
      "Action prob: [9.9951482e-01 4.8520093e-04], Action: 0, state: 1\n",
      "Action prob: [9.9941957e-01 5.8042631e-04], Action: 0, state: 1\n",
      "Action prob: [9.994216e-01 5.784839e-04], Action: 0, state: 1\n",
      "Action prob: [9.9933237e-01 6.6765194e-04], Action: 0, state: 1\n",
      "Action prob: [9.9952292e-01 4.7705762e-04], Action: 0, state: 2\n",
      "Action prob: [9.9930298e-01 6.9705554e-04], Action: 0, state: 3\n",
      "Action prob: [9.9924135e-01 7.5868523e-04], Action: 0, state: 3\n",
      "Action prob: [9.9919409e-01 8.0593466e-04], Action: 0, state: 3\n",
      "Action prob: [9.994593e-01 5.407072e-04], Action: 0, state: 3\n",
      "Action prob: [9.9953747e-01 4.6256170e-04], Action: 0, state: 3\n",
      "Action prob: [9.9945956e-01 5.4045726e-04], Action: 0, state: 3\n",
      "Action prob: [9.9938428e-01 6.1575207e-04], Action: 0, state: 3\n",
      "Action prob: [9.9948967e-01 5.1033427e-04], Action: 0, state: 3\n",
      "Action prob: [9.9939203e-01 6.0798845e-04], Action: 0, state: 3\n",
      "Action prob: [9.9960989e-01 3.9010262e-04], Action: 0, state: 8\n",
      "Action prob: [9.9972337e-01 2.7663066e-04], Action: 0, state: 8\n",
      "Action prob: [9.9962294e-01 3.7701312e-04], Action: 0, state: 8\n",
      "Action prob: [9.9971122e-01 2.8873468e-04], Action: 0, state: 8\n",
      "Action prob: [9.9904078e-01 9.5914624e-04], Action: 0, state: 8\n",
      "Action prob: [0.9988908  0.00110919], Action: 0, state: 8\n",
      "Action prob: [9.9971098e-01 2.8900433e-04], Action: 0, state: 8\n",
      "Action prob: [9.9959677e-01 4.0326375e-04], Action: 0, state: 8\n",
      "Action prob: [9.9959952e-01 4.0053893e-04], Action: 0, state: 8\n",
      "Action prob: [0.9985991  0.00140091], Action: 0, state: 8\n",
      "Action prob: [9.9964762e-01 3.5236805e-04], Action: 0, state: 8\n",
      "Action prob: [0.9986197  0.00138034], Action: 0, state: 8\n",
      "Action prob: [0.9985784  0.00142162], Action: 0, state: 8\n",
      "Action prob: [9.9974972e-01 2.5021873e-04], Action: 0, state: 8\n",
      "Action prob: [9.9954468e-01 4.5530396e-04], Action: 0, state: 8\n",
      "Action prob: [9.9987078e-01 1.2923022e-04], Action: 0, state: 8\n",
      "Action prob: [0.99877304 0.00122695], Action: 0, state: 8\n",
      "Action prob: [9.9957222e-01 4.2777514e-04], Action: 0, state: 8\n",
      "Action prob: [0.99871826 0.00128174], Action: 0, state: 8\n",
      "Action prob: [9.9952412e-01 4.7591896e-04], Action: 0, state: 8\n",
      "Action prob: [9.9969530e-01 3.0469114e-04], Action: 0, state: 8\n",
      "Action prob: [9.9960154e-01 3.9841793e-04], Action: 0, state: 8\n",
      "Action prob: [0.998475   0.00152493], Action: 0, state: 8\n",
      "Action prob: [0.99885595 0.00114409], Action: 0, state: 8\n",
      "Action prob: [9.9961460e-01 3.8542063e-04], Action: 0, state: 8\n",
      "Action prob: [9.9955696e-01 4.4297535e-04], Action: 0, state: 8\n",
      "Action prob: [9.9959666e-01 4.0341716e-04], Action: 0, state: 8\n",
      "Action prob: [9.996182e-01 3.818354e-04], Action: 0, state: 8\n",
      "Action prob: [9.9965763e-01 3.4240933e-04], Action: 0, state: 8\n",
      "Action prob: [9.995086e-01 4.914187e-04], Action: 0, state: 8\n",
      "Action prob: [0.99854976 0.00145023], Action: 0, state: 8\n",
      "tensor([-2.2268e-03, -1.5421e-03, -1.7534e-03, -9.6370e-04, -7.7516e-04,\n",
      "        -3.8303e-04, -2.2387e-04, -2.4561e-05,  1.6644e-04,  2.2408e-04,\n",
      "         4.0905e-04,  5.2075e-04,  6.2140e-04,  4.5572e-04,  4.1811e-04,\n",
      "         5.1663e-04,  6.1581e-04,  5.2955e-04,  6.5028e-04,  3.5374e-04,\n",
      "         2.1256e-04,  2.4542e-04,  1.5910e-04,  4.4712e-04,  4.3695e-04,\n",
      "         9.6075e-05,  1.1301e-04,  9.4483e-05,  2.7784e-04,  5.8564e-05,\n",
      "         1.9191e-04,  1.6473e-04,  2.4061e-05,  3.6163e-05,  8.4251e-06,\n",
      "         6.5209e-05,  1.8333e-05,  4.3758e-05,  1.2709e-05,  6.2148e-06,\n",
      "         5.9913e-06,  1.5990e-05,  7.5605e-06,  1.2771e-06,  2.2823e-07,\n",
      "        -7.5168e-07, -1.4836e-06, -1.9186e-06, -3.4718e-06, -1.2053e-05],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -83500, loss is -6.259230273050531e-06\n",
      "Action prob: [9.9955207e-01 4.4789337e-04], Action: 0, state: 0\n",
      "Action prob: [9.995648e-01 4.351539e-04], Action: 0, state: 1\n",
      "Action prob: [9.9944502e-01 5.5492134e-04], Action: 0, state: 1\n",
      "Action prob: [9.9962080e-01 3.7918662e-04], Action: 0, state: 2\n",
      "Action prob: [9.993944e-01 6.056262e-04], Action: 0, state: 3\n",
      "Action prob: [0.9989913  0.00100869], Action: 0, state: 8\n",
      "Action prob: [9.9937695e-01 6.2303373e-04], Action: 0, state: 8\n",
      "Action prob: [0.99863154 0.00136845], Action: 0, state: 8\n",
      "Action prob: [9.9962914e-01 3.7080169e-04], Action: 0, state: 8\n",
      "Action prob: [9.997414e-01 2.586448e-04], Action: 0, state: 8\n",
      "Action prob: [0.9987185  0.00128153], Action: 0, state: 8\n",
      "Action prob: [9.9962413e-01 3.7584358e-04], Action: 0, state: 8\n",
      "Action prob: [9.9902916e-01 9.7083172e-04], Action: 0, state: 8\n",
      "Action prob: [9.9968839e-01 3.1160918e-04], Action: 0, state: 8\n",
      "Action prob: [9.997056e-01 2.944160e-04], Action: 0, state: 8\n",
      "Action prob: [0.99884355 0.00115645], Action: 0, state: 8\n",
      "Action prob: [0.99893934 0.00106063], Action: 0, state: 8\n",
      "Action prob: [9.9949455e-01 5.0539029e-04], Action: 0, state: 8\n",
      "Action prob: [9.9957973e-01 4.2025678e-04], Action: 0, state: 8\n",
      "Action prob: [0.99896324 0.00103675], Action: 0, state: 8\n",
      "Action prob: [9.9971622e-01 2.8374672e-04], Action: 0, state: 8\n",
      "Action prob: [9.9978048e-01 2.1951235e-04], Action: 0, state: 8\n",
      "Action prob: [0.9988146  0.00118543], Action: 0, state: 8\n",
      "Action prob: [9.9967337e-01 3.2660292e-04], Action: 0, state: 8\n",
      "Action prob: [9.995938e-01 4.062564e-04], Action: 0, state: 8\n",
      "Action prob: [9.9981409e-01 1.8590942e-04], Action: 0, state: 8\n",
      "Action prob: [9.9967146e-01 3.2852474e-04], Action: 0, state: 8\n",
      "Action prob: [0.99817383 0.00182613], Action: 0, state: 8\n",
      "Action prob: [9.993907e-01 6.092812e-04], Action: 0, state: 8\n",
      "Action prob: [9.992174e-01 7.825878e-04], Action: 0, state: 8\n",
      "Action prob: [0.9989743  0.00102574], Action: 0, state: 8\n",
      "Action prob: [0.99885714 0.00114286], Action: 0, state: 8\n",
      "Action prob: [0.9987759  0.00122409], Action: 0, state: 8\n",
      "Action prob: [9.9968266e-01 3.1735084e-04], Action: 0, state: 8\n",
      "Action prob: [9.9970299e-01 2.9693526e-04], Action: 0, state: 8\n",
      "Action prob: [9.9970007e-01 3.0000709e-04], Action: 0, state: 8\n",
      "Action prob: [0.9988047  0.00119531], Action: 0, state: 8\n",
      "Action prob: [9.9968195e-01 3.1808414e-04], Action: 0, state: 8\n",
      "Action prob: [9.991922e-01 8.077791e-04], Action: 0, state: 8\n",
      "Action prob: [9.9978203e-01 2.1796547e-04], Action: 0, state: 8\n",
      "Action prob: [0.99892634 0.00107359], Action: 0, state: 8\n",
      "Action prob: [9.9963033e-01 3.6960494e-04], Action: 0, state: 8\n",
      "Action prob: [0.99865913 0.00134091], Action: 0, state: 8\n",
      "Action prob: [9.9935406e-01 6.4595271e-04], Action: 0, state: 8\n",
      "Action prob: [9.9956626e-01 4.3372202e-04], Action: 0, state: 8\n",
      "Action prob: [0.99896073 0.00103922], Action: 0, state: 8\n",
      "Action prob: [0.9988518  0.00114823], Action: 0, state: 8\n",
      "Action prob: [9.9978966e-01 2.1041569e-04], Action: 0, state: 8\n",
      "Action prob: [9.9962366e-01 3.7632725e-04], Action: 0, state: 8\n",
      "Action prob: [9.9929190e-01 7.0802274e-04], Action: 0, state: 8\n",
      "tensor([ 8.1619e-04,  9.1659e-04,  1.3030e-03,  9.5946e-04,  1.5911e-03,\n",
      "         2.1519e-03,  1.0671e-03,  1.8556e-03,  3.9002e-04,  2.0523e-04,\n",
      "         7.3621e-04,  1.4575e-04,  2.2266e-04,  2.9465e-05, -5.8735e-06,\n",
      "        -1.3569e-04, -2.1223e-04, -1.3665e-04, -1.3874e-04, -3.9506e-04,\n",
      "        -1.2035e-04, -1.0115e-04, -5.8349e-04, -1.6937e-04, -2.1980e-04,\n",
      "        -1.0415e-04, -1.8941e-04, -1.0789e-03, -3.6693e-04, -4.7918e-04,\n",
      "        -6.3681e-04, -7.1787e-04, -7.7645e-04, -2.0285e-04, -1.9118e-04,\n",
      "        -1.9419e-04, -7.7808e-04, -2.0781e-04, -5.2982e-04, -1.4335e-04,\n",
      "        -7.0817e-04, -2.4427e-04, -8.8807e-04, -4.2833e-04, -2.8797e-04,\n",
      "        -6.9096e-04, -7.6417e-04, -1.4004e-04, -2.5074e-04, -4.7213e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for this episode -134900, loss is 2.5997649954641972e-05\n",
      "Action prob: [9.996069e-01 3.931048e-04], Action: 0, state: 0\n",
      "Action prob: [9.995389e-01 4.611012e-04], Action: 0, state: 0\n",
      "Action prob: [9.9963653e-01 3.6344919e-04], Action: 0, state: 1\n",
      "Action prob: [9.9962306e-01 3.7688625e-04], Action: 0, state: 1\n",
      "Action prob: [9.9959189e-01 4.0810634e-04], Action: 0, state: 2\n",
      "Action prob: [9.9976605e-01 2.3397651e-04], Action: 0, state: 3\n",
      "Action prob: [9.9967325e-01 3.2676241e-04], Action: 0, state: 3\n",
      "Action prob: [9.993228e-01 6.772924e-04], Action: 0, state: 3\n",
      "Action prob: [9.9977309e-01 2.2690378e-04], Action: 0, state: 3\n",
      "Action prob: [9.9920136e-01 7.9870375e-04], Action: 0, state: 8\n",
      "Action prob: [9.9979645e-01 2.0357988e-04], Action: 0, state: 8\n",
      "Action prob: [9.9960667e-01 3.9337139e-04], Action: 0, state: 8\n",
      "Action prob: [9.991373e-01 8.626644e-04], Action: 0, state: 8\n",
      "Action prob: [9.9975115e-01 2.4878950e-04], Action: 0, state: 8\n",
      "Action prob: [9.9968922e-01 3.1082382e-04], Action: 0, state: 8\n",
      "Action prob: [9.9961889e-01 3.8113474e-04], Action: 0, state: 8\n",
      "Action prob: [9.9975854e-01 2.4145370e-04], Action: 0, state: 8\n",
      "Action prob: [0.99857545 0.00142458], Action: 0, state: 8\n",
      "Action prob: [9.9976963e-01 2.3040785e-04], Action: 0, state: 8\n",
      "Action prob: [9.9985254e-01 1.4740322e-04], Action: 0, state: 8\n",
      "Action prob: [9.9900705e-01 9.9296449e-04], Action: 0, state: 8\n",
      "Action prob: [9.990139e-01 9.860308e-04], Action: 0, state: 8\n",
      "Action prob: [9.9969506e-01 3.0490500e-04], Action: 0, state: 8\n",
      "Action prob: [9.9972945e-01 2.7052275e-04], Action: 0, state: 8\n",
      "Action prob: [9.9968088e-01 3.1909376e-04], Action: 0, state: 8\n",
      "Action prob: [9.997732e-01 2.268032e-04], Action: 0, state: 8\n",
      "Action prob: [0.9989538  0.00104613], Action: 0, state: 8\n",
      "Action prob: [9.9910694e-01 8.9304219e-04], Action: 0, state: 8\n",
      "Action prob: [9.9979824e-01 2.0183172e-04], Action: 0, state: 8\n",
      "Action prob: [0.99819356 0.00180647], Action: 0, state: 8\n",
      "Action prob: [9.9983370e-01 1.6627279e-04], Action: 0, state: 8\n",
      "Action prob: [9.997167e-01 2.833115e-04], Action: 0, state: 8\n",
      "Action prob: [0.99894565 0.00105435], Action: 0, state: 8\n",
      "Action prob: [9.9905473e-01 9.4522088e-04], Action: 0, state: 8\n",
      "Action prob: [9.990702e-01 9.298354e-04], Action: 0, state: 8\n",
      "Action prob: [9.9979419e-01 2.0579596e-04], Action: 0, state: 8\n",
      "Action prob: [9.9979275e-01 2.0728220e-04], Action: 0, state: 8\n",
      "Action prob: [9.9968517e-01 3.1488857e-04], Action: 0, state: 8\n",
      "Action prob: [9.9910152e-01 8.9845236e-04], Action: 0, state: 8\n",
      "Action prob: [9.9988365e-01 1.1635001e-04], Action: 0, state: 8\n",
      "Action prob: [9.9918109e-01 8.1894826e-04], Action: 0, state: 8\n",
      "Action prob: [0.99899596 0.001004  ], Action: 0, state: 8\n",
      "Action prob: [9.9976915e-01 2.3083948e-04], Action: 0, state: 8\n",
      "Action prob: [9.997795e-01 2.205357e-04], Action: 0, state: 8\n",
      "Action prob: [9.991104e-01 8.896298e-04], Action: 0, state: 8\n",
      "Action prob: [9.9977905e-01 2.2091239e-04], Action: 0, state: 8\n",
      "Action prob: [9.9960810e-01 3.9198317e-04], Action: 0, state: 8\n",
      "Action prob: [9.9980241e-01 1.9766299e-04], Action: 0, state: 8\n",
      "Action prob: [9.9920446e-01 7.9556048e-04], Action: 0, state: 8\n",
      "Action prob: [9.9970955e-01 2.9048524e-04], Action: 0, state: 8\n",
      "tensor([ 7.8207e-05,  3.5582e-04,  4.3970e-04,  5.9636e-04,  7.6052e-04,\n",
      "         4.7089e-04,  6.9923e-04,  1.5226e-03,  5.3089e-04,  1.4951e-03,\n",
      "         2.9995e-04,  4.4662e-04,  7.3173e-04,  1.5019e-04,  1.2302e-04,\n",
      "         8.3581e-05,  1.6715e-05, -8.3147e-05, -3.8416e-05, -3.8178e-05,\n",
      "        -3.3500e-04, -3.9837e-04, -1.4041e-04, -1.3759e-04, -1.7534e-04,\n",
      "        -1.3249e-04, -6.4234e-04, -5.7072e-04, -1.3320e-04, -1.2263e-03,\n",
      "        -1.1537e-04, -2.0026e-04, -7.5734e-04, -6.8791e-04, -6.8412e-04,\n",
      "        -1.5279e-04, -1.5506e-04, -2.3712e-04, -6.8068e-04, -8.8526e-05,\n",
      "        -6.2579e-04, -7.6992e-04, -1.7746e-04, -1.6990e-04, -6.8715e-04,\n",
      "        -1.7091e-04, -3.0362e-04, -1.5326e-04, -6.1789e-04, -2.2574e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -120400, loss is 5.8224373310360445e-05\n",
      "Action prob: [9.9955601e-01 4.4403167e-04], Action: 0, state: 0\n",
      "Action prob: [9.9966228e-01 3.3772772e-04], Action: 0, state: 1\n",
      "Action prob: [9.9975103e-01 2.4897841e-04], Action: 0, state: 1\n",
      "Action prob: [9.9966073e-01 3.3932898e-04], Action: 0, state: 1\n",
      "Action prob: [9.9965787e-01 3.4209868e-04], Action: 0, state: 2\n",
      "Action prob: [9.9952567e-01 4.7429488e-04], Action: 0, state: 2\n",
      "Action prob: [9.9980491e-01 1.9511895e-04], Action: 0, state: 3\n",
      "Action prob: [9.9968302e-01 3.1701184e-04], Action: 0, state: 3\n",
      "Action prob: [9.9953520e-01 4.6485072e-04], Action: 0, state: 3\n",
      "Action prob: [9.9946457e-01 5.3544715e-04], Action: 0, state: 3\n",
      "Action prob: [9.9972516e-01 2.7487709e-04], Action: 0, state: 8\n",
      "Action prob: [0.9989592  0.00104083], Action: 0, state: 8\n",
      "Action prob: [9.9978989e-01 2.1016545e-04], Action: 0, state: 8\n",
      "Action prob: [9.9976903e-01 2.3102334e-04], Action: 0, state: 8\n",
      "Action prob: [9.9914527e-01 8.5474824e-04], Action: 0, state: 8\n",
      "Action prob: [9.990287e-01 9.713749e-04], Action: 0, state: 8\n",
      "Action prob: [0.9989104  0.00108958], Action: 0, state: 8\n",
      "Action prob: [9.9960786e-01 3.9220889e-04], Action: 0, state: 8\n",
      "Action prob: [9.9927455e-01 7.2550442e-04], Action: 0, state: 8\n",
      "Action prob: [9.9980325e-01 1.9675701e-04], Action: 0, state: 8\n",
      "Action prob: [9.9964035e-01 3.5965827e-04], Action: 0, state: 8\n",
      "Action prob: [9.9971277e-01 2.8725283e-04], Action: 0, state: 8\n",
      "Action prob: [0.9988839  0.00111613], Action: 0, state: 8\n",
      "Action prob: [9.999025e-01 9.750123e-05], Action: 0, state: 8\n",
      "Action prob: [9.9981648e-01 1.8352908e-04], Action: 0, state: 8\n",
      "Action prob: [9.994937e-01 5.063118e-04], Action: 1, state: 8\n",
      "Action prob: [9.9980503e-01 1.9497240e-04], Action: 0, state: 8\n",
      "Action prob: [9.991340e-01 8.660785e-04], Action: 0, state: 8\n",
      "Action prob: [9.9973017e-01 2.6986506e-04], Action: 0, state: 8\n",
      "Action prob: [9.9967468e-01 3.2529936e-04], Action: 0, state: 8\n",
      "Action prob: [9.9972767e-01 2.7237009e-04], Action: 0, state: 8\n",
      "Action prob: [9.9931920e-01 6.8084983e-04], Action: 0, state: 8\n",
      "Action prob: [9.997656e-01 2.344696e-04], Action: 0, state: 8\n",
      "Action prob: [9.9975377e-01 2.4626762e-04], Action: 0, state: 8\n",
      "Action prob: [9.9976867e-01 2.3138575e-04], Action: 0, state: 8\n",
      "Action prob: [9.9917966e-01 8.2038000e-04], Action: 0, state: 8\n",
      "Action prob: [9.9975592e-01 2.4408243e-04], Action: 0, state: 8\n",
      "Action prob: [9.9917334e-01 8.2661828e-04], Action: 1, state: 8\n",
      "Action prob: [9.9980551e-01 1.9455717e-04], Action: 0, state: 8\n",
      "Action prob: [9.9918300e-01 8.1701914e-04], Action: 0, state: 8\n",
      "Action prob: [9.9971324e-01 2.8669793e-04], Action: 0, state: 8\n",
      "Action prob: [9.9985945e-01 1.4055005e-04], Action: 0, state: 8\n",
      "Action prob: [9.990815e-01 9.185353e-04], Action: 0, state: 8\n",
      "Action prob: [9.991425e-01 8.574671e-04], Action: 0, state: 8\n",
      "Action prob: [9.9980599e-01 1.9402511e-04], Action: 0, state: 8\n",
      "Action prob: [0.99884737 0.00115266], Action: 0, state: 8\n",
      "Action prob: [9.997092e-01 2.907457e-04], Action: 0, state: 8\n",
      "Action prob: [9.9973053e-01 2.6946783e-04], Action: 0, state: 8\n",
      "Action prob: [9.9978870e-01 2.1126826e-04], Action: 0, state: 8\n",
      "Action prob: [9.9913174e-01 8.6832268e-04], Action: 0, state: 8\n",
      "tensor([-1.4330e-04,  9.6403e-05,  1.9977e-04,  4.2131e-04,  5.3846e-04,\n",
      "         8.8044e-04,  3.9130e-04,  6.7623e-04,  1.0420e-03,  1.2497e-03,\n",
      "         5.1234e-04,  1.5254e-03,  2.3653e-04,  1.9342e-04,  5.0644e-04,\n",
      "         3.7312e-04,  2.2555e-04,  2.2118e-05, -5.1914e-05, -3.5473e-05,\n",
      "        -9.8096e-05, -1.0091e-04, -4.6684e-04, -4.6302e-05, -9.6001e-05,\n",
      "        -4.2803e+00, -1.1678e-04, -5.4456e-04, -1.7642e-04, -2.1968e-04,\n",
      "        -1.8885e-04, -4.8272e-04, -1.6926e-04, -1.8054e-04, -1.7181e-04,\n",
      "        -6.1608e-04, -1.8493e-04, -5.4187e+00, -1.4945e-04, -6.3145e-04,\n",
      "        -2.2260e-04, -1.0952e-04, -7.1841e-04, -6.7254e-04, -1.5248e-04,\n",
      "        -9.0816e-04, -2.2942e-04, -2.1290e-04, -1.6714e-04, -6.8775e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -116700, loss is 0.19397823035973205\n",
      "Action prob: [9.994863e-01 5.136994e-04], Action: 0, state: 0\n",
      "Action prob: [9.9964011e-01 3.5983694e-04], Action: 0, state: 0\n",
      "Action prob: [9.9960774e-01 3.9225636e-04], Action: 0, state: 1\n",
      "Action prob: [9.9963534e-01 3.6461715e-04], Action: 0, state: 1\n",
      "Action prob: [9.9961555e-01 3.8436698e-04], Action: 0, state: 2\n",
      "Action prob: [9.9964869e-01 3.5132404e-04], Action: 0, state: 3\n",
      "Action prob: [9.9955183e-01 4.4811668e-04], Action: 0, state: 3\n",
      "Action prob: [9.9946982e-01 5.3016905e-04], Action: 0, state: 3\n",
      "Action prob: [9.9963987e-01 3.6017847e-04], Action: 0, state: 8\n",
      "Action prob: [0.99892586 0.00107412], Action: 0, state: 8\n",
      "Action prob: [9.9967206e-01 3.2795177e-04], Action: 0, state: 8\n",
      "Action prob: [9.9973553e-01 2.6445510e-04], Action: 0, state: 8\n",
      "Action prob: [9.997503e-01 2.496361e-04], Action: 0, state: 8\n",
      "Action prob: [9.9916220e-01 8.3785487e-04], Action: 0, state: 8\n",
      "Action prob: [9.9980885e-01 1.9117229e-04], Action: 0, state: 8\n",
      "Action prob: [9.9902904e-01 9.7101909e-04], Action: 0, state: 8\n",
      "Action prob: [0.9987501  0.00124989], Action: 0, state: 8\n",
      "Action prob: [9.9922633e-01 7.7368831e-04], Action: 0, state: 8\n",
      "Action prob: [9.9978787e-01 2.1210466e-04], Action: 0, state: 8\n",
      "Action prob: [0.99862957 0.00137048], Action: 0, state: 8\n",
      "Action prob: [9.9900836e-01 9.9163479e-04], Action: 0, state: 8\n",
      "Action prob: [9.9973017e-01 2.6983087e-04], Action: 0, state: 8\n",
      "Action prob: [9.9925762e-01 7.4236956e-04], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [9.9949729e-01 5.0267106e-04], Action: 0, state: 8\n",
      "Action prob: [0.9988286  0.00117143], Action: 0, state: 8\n",
      "Action prob: [9.9942470e-01 5.7532714e-04], Action: 0, state: 8\n",
      "Action prob: [9.997328e-01 2.672144e-04], Action: 0, state: 8\n",
      "Action prob: [9.9931586e-01 6.8415113e-04], Action: 0, state: 8\n",
      "Action prob: [0.99895906 0.00104095], Action: 0, state: 8\n",
      "Action prob: [9.997874e-01 2.126279e-04], Action: 0, state: 8\n",
      "Action prob: [0.9988065  0.00119348], Action: 0, state: 8\n",
      "Action prob: [9.9975318e-01 2.4678494e-04], Action: 0, state: 8\n",
      "Action prob: [9.9913055e-01 8.6942286e-04], Action: 0, state: 8\n",
      "Action prob: [9.991328e-01 8.671630e-04], Action: 0, state: 8\n",
      "Action prob: [9.9979860e-01 2.0140091e-04], Action: 0, state: 8\n",
      "Action prob: [9.997421e-01 2.578886e-04], Action: 0, state: 8\n",
      "Action prob: [9.9902976e-01 9.7027695e-04], Action: 0, state: 8\n",
      "Action prob: [0.99880385 0.00119611], Action: 0, state: 8\n",
      "Action prob: [9.9973613e-01 2.6381318e-04], Action: 0, state: 8\n",
      "Action prob: [9.9967027e-01 3.2970763e-04], Action: 0, state: 8\n",
      "Action prob: [0.9989705  0.00102956], Action: 0, state: 8\n",
      "Action prob: [9.9911505e-01 8.8497897e-04], Action: 0, state: 8\n",
      "Action prob: [9.9969435e-01 3.0562180e-04], Action: 0, state: 8\n",
      "Action prob: [9.999114e-01 8.860987e-05], Action: 0, state: 8\n",
      "Action prob: [0.9989843 0.0010157], Action: 0, state: 8\n",
      "Action prob: [9.990447e-01 9.552517e-04], Action: 0, state: 8\n",
      "Action prob: [9.9916863e-01 8.3137769e-04], Action: 0, state: 8\n",
      "Action prob: [9.9971944e-01 2.8048118e-04], Action: 0, state: 8\n",
      "Action prob: [9.991128e-01 8.871635e-04], Action: 0, state: 8\n",
      "Action prob: [9.997081e-01 2.918104e-04], Action: 0, state: 8\n",
      "tensor([ 3.2486e-04,  4.0403e-04,  5.8749e-04,  6.6240e-04,  7.9096e-04,\n",
      "         7.6772e-04,  1.0282e-03,  1.2654e-03,  6.8966e-04,  1.6271e-03,\n",
      "         3.8487e-04,  2.3379e-04,  1.5927e-04,  3.5926e-04,  4.7953e-05,\n",
      "         9.6865e-05, -3.5947e-05, -1.0675e-04, -4.8952e-05, -4.2461e-04,\n",
      "        -3.7372e-04, -1.1703e-04, -3.5805e-04, -2.6313e-04, -6.5439e-04,\n",
      "        -3.3841e-04, -1.6391e-04, -4.3447e-04, -6.8020e-04, -1.4218e-04,\n",
      "        -8.1429e-04, -1.7109e-04, -6.1115e-04, -6.1659e-04, -1.4454e-04,\n",
      "        -1.8661e-04, -7.0711e-04, -8.7691e-04, -1.9431e-04, -2.4382e-04,\n",
      "        -7.6420e-04, -6.5881e-04, -2.2806e-04, -6.6221e-05, -7.6113e-04,\n",
      "        -7.1692e-04, -6.2470e-04, -2.1099e-04, -6.6805e-04, -2.1989e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -123900, loss is 8.39470356949409e-05\n",
      "Action prob: [9.995074e-01 4.925592e-04], Action: 0, state: 0\n",
      "Action prob: [9.9954271e-01 4.5728433e-04], Action: 0, state: 0\n",
      "Action prob: [9.9963236e-01 3.6757271e-04], Action: 0, state: 1\n",
      "Action prob: [9.9952292e-01 4.7704965e-04], Action: 0, state: 1\n",
      "Action prob: [9.994429e-01 5.570889e-04], Action: 0, state: 2\n",
      "Action prob: [9.9954849e-01 4.5151394e-04], Action: 0, state: 3\n",
      "Action prob: [9.9955326e-01 4.4672014e-04], Action: 0, state: 8\n",
      "Action prob: [0.99860424 0.00139582], Action: 0, state: 8\n",
      "Action prob: [0.99891603 0.00108402], Action: 0, state: 8\n",
      "Action prob: [9.9951184e-01 4.8820252e-04], Action: 0, state: 8\n",
      "Action prob: [9.9975866e-01 2.4134805e-04], Action: 0, state: 8\n",
      "Action prob: [9.9974364e-01 2.5630169e-04], Action: 0, state: 8\n",
      "Action prob: [9.990963e-01 9.037671e-04], Action: 0, state: 8\n",
      "Action prob: [9.9934465e-01 6.5539149e-04], Action: 0, state: 8\n",
      "Action prob: [9.9981147e-01 1.8855029e-04], Action: 0, state: 8\n",
      "Action prob: [9.9972147e-01 2.7857200e-04], Action: 0, state: 8\n",
      "Action prob: [9.9957162e-01 4.2833172e-04], Action: 0, state: 8\n",
      "Action prob: [0.99886876 0.00113125], Action: 0, state: 8\n",
      "Action prob: [9.997898e-01 2.102368e-04], Action: 0, state: 8\n",
      "Action prob: [9.9978048e-01 2.1954795e-04], Action: 0, state: 8\n",
      "Action prob: [9.9980491e-01 1.9507913e-04], Action: 0, state: 8\n",
      "Action prob: [9.9970526e-01 2.9471339e-04], Action: 0, state: 8\n",
      "Action prob: [9.9966586e-01 3.3417664e-04], Action: 0, state: 8\n",
      "Action prob: [9.9907458e-01 9.2542893e-04], Action: 0, state: 8\n",
      "Action prob: [9.996087e-01 3.913329e-04], Action: 0, state: 8\n",
      "Action prob: [9.996474e-01 3.526014e-04], Action: 0, state: 8\n",
      "Action prob: [9.9980944e-01 1.9060535e-04], Action: 0, state: 8\n",
      "Action prob: [9.9979180e-01 2.0824773e-04], Action: 0, state: 8\n",
      "Action prob: [0.99867463 0.00132535], Action: 0, state: 8\n",
      "Action prob: [9.9960583e-01 3.9422186e-04], Action: 0, state: 8\n",
      "Action prob: [9.9954212e-01 4.5786815e-04], Action: 0, state: 8\n",
      "Action prob: [9.9961579e-01 3.8414556e-04], Action: 0, state: 8\n",
      "Action prob: [9.993311e-01 6.689165e-04], Action: 0, state: 8\n",
      "Action prob: [9.9974734e-01 2.5266880e-04], Action: 0, state: 8\n",
      "Action prob: [9.9967754e-01 3.2246017e-04], Action: 0, state: 8\n",
      "Action prob: [9.99879122e-01 1.20901976e-04], Action: 0, state: 8\n",
      "Action prob: [9.9938583e-01 6.1413413e-04], Action: 0, state: 8\n",
      "Action prob: [0.9987136  0.00128645], Action: 0, state: 8\n",
      "Action prob: [9.9902976e-01 9.7030937e-04], Action: 0, state: 8\n",
      "Action prob: [9.9907196e-01 9.2804304e-04], Action: 0, state: 8\n",
      "Action prob: [9.9982542e-01 1.7464539e-04], Action: 0, state: 8\n",
      "Action prob: [9.9957234e-01 4.2760838e-04], Action: 0, state: 8\n",
      "Action prob: [0.99899906 0.00100099], Action: 0, state: 8\n",
      "Action prob: [0.9988091 0.0011909], Action: 0, state: 8\n",
      "Action prob: [9.996519e-01 3.480301e-04], Action: 0, state: 8\n",
      "Action prob: [9.9976033e-01 2.3962036e-04], Action: 0, state: 8\n",
      "Action prob: [9.9972039e-01 2.7959293e-04], Action: 0, state: 8\n",
      "Action prob: [0.99883467 0.00116533], Action: 0, state: 8\n",
      "Action prob: [9.9963367e-01 3.6629610e-04], Action: 0, state: 8\n",
      "Action prob: [9.9967897e-01 3.2105861e-04], Action: 0, state: 8\n",
      "tensor([ 6.8309e-04,  8.0139e-04,  7.4712e-04,  1.0830e-03,  1.3649e-03,\n",
      "         1.1492e-03,  9.1956e-04,  2.2966e-03,  1.4019e-03,  4.8519e-04,\n",
      "         1.7851e-04,  1.3425e-04,  3.0746e-04,  1.2064e-04,  9.6917e-06,\n",
      "        -1.7085e-05, -6.7336e-05, -2.7007e-04, -6.4722e-05, -8.0505e-05,\n",
      "        -8.1301e-05, -1.3537e-04, -1.6555e-04, -4.8707e-04, -2.1612e-04,\n",
      "        -2.0258e-04, -1.1306e-04, -1.2687e-04, -8.2614e-04, -2.5015e-04,\n",
      "        -2.9510e-04, -2.5083e-04, -4.4150e-04, -1.6827e-04, -2.1641e-04,\n",
      "        -8.1645e-05, -4.1721e-04, -8.7822e-04, -6.6489e-04, -6.3807e-04,\n",
      "        -1.2033e-04, -2.9550e-04, -6.9321e-04, -8.2627e-04, -2.4176e-04,\n",
      "        -1.6666e-04, -1.9463e-04, -8.1228e-04, -2.5544e-04, -2.2399e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -130900, loss is -1.3926336824608457e-05\n",
      "Action prob: [9.9952924e-01 4.7078717e-04], Action: 0, state: 0\n",
      "Action prob: [9.9958748e-01 4.1247296e-04], Action: 0, state: 0\n",
      "Action prob: [9.9952459e-01 4.7544445e-04], Action: 0, state: 0\n",
      "Action prob: [9.9952698e-01 4.7305078e-04], Action: 0, state: 1\n",
      "Action prob: [9.9950874e-01 4.9128430e-04], Action: 0, state: 2\n",
      "Action prob: [9.9952042e-01 4.7964667e-04], Action: 0, state: 2\n",
      "Action prob: [9.995022e-01 4.978407e-04], Action: 0, state: 2\n",
      "Action prob: [9.9954647e-01 4.5349923e-04], Action: 0, state: 2\n",
      "Action prob: [9.9905449e-01 9.4550103e-04], Action: 0, state: 3\n",
      "Action prob: [9.9948335e-01 5.1665778e-04], Action: 0, state: 3\n",
      "Action prob: [9.993343e-01 6.657118e-04], Action: 0, state: 3\n",
      "Action prob: [9.9933439e-01 6.6562084e-04], Action: 0, state: 3\n",
      "Action prob: [0.9977209  0.00227911], Action: 0, state: 8\n",
      "Action prob: [9.9968803e-01 3.1198404e-04], Action: 0, state: 8\n",
      "Action prob: [0.9987257  0.00127432], Action: 0, state: 8\n",
      "Action prob: [9.9963140e-01 3.6857452e-04], Action: 0, state: 8\n",
      "Action prob: [0.99868506 0.00131488], Action: 0, state: 8\n",
      "Action prob: [9.9975353e-01 2.4649029e-04], Action: 0, state: 8\n",
      "Action prob: [9.9966204e-01 3.3801442e-04], Action: 0, state: 8\n",
      "Action prob: [9.9968648e-01 3.1349508e-04], Action: 0, state: 8\n",
      "Action prob: [9.9960977e-01 3.9030780e-04], Action: 0, state: 8\n",
      "Action prob: [9.9962306e-01 3.7688462e-04], Action: 0, state: 8\n",
      "Action prob: [9.9957174e-01 4.2821330e-04], Action: 0, state: 8\n",
      "Action prob: [9.9953043e-01 4.6963370e-04], Action: 0, state: 8\n",
      "Action prob: [9.9957687e-01 4.2317781e-04], Action: 0, state: 8\n",
      "Action prob: [0.9987795  0.00122056], Action: 0, state: 8\n",
      "Action prob: [9.996131e-01 3.868996e-04], Action: 0, state: 8\n",
      "Action prob: [9.9975735e-01 2.4259547e-04], Action: 0, state: 8\n",
      "Action prob: [0.99899536 0.00100467], Action: 0, state: 8\n",
      "Action prob: [9.993753e-01 6.247346e-04], Action: 0, state: 8\n",
      "Action prob: [9.9965024e-01 3.4971136e-04], Action: 0, state: 8\n",
      "Action prob: [0.9988512  0.00114884], Action: 0, state: 8\n",
      "Action prob: [9.997191e-01 2.808984e-04], Action: 0, state: 8\n",
      "Action prob: [9.9974042e-01 2.5961208e-04], Action: 0, state: 8\n",
      "Action prob: [0.99869746 0.00130256], Action: 0, state: 8\n",
      "Action prob: [9.9974900e-01 2.5099385e-04], Action: 0, state: 8\n",
      "Action prob: [0.9989235  0.00107645], Action: 0, state: 8\n",
      "Action prob: [0.9988213  0.00117864], Action: 0, state: 8\n",
      "Action prob: [0.998944   0.00105598], Action: 0, state: 8\n",
      "Action prob: [9.9973577e-01 2.6420737e-04], Action: 0, state: 8\n",
      "Action prob: [9.9966657e-01 3.3343927e-04], Action: 0, state: 8\n",
      "Action prob: [9.9972445e-01 2.7552305e-04], Action: 0, state: 8\n",
      "Action prob: [9.9952769e-01 4.7228573e-04], Action: 0, state: 8\n",
      "Action prob: [9.9934071e-01 6.5929315e-04], Action: 0, state: 8\n",
      "Action prob: [0.99857986 0.00142012], Action: 0, state: 8\n",
      "Action prob: [9.9966419e-01 3.3587374e-04], Action: 0, state: 8\n",
      "Action prob: [9.9974543e-01 2.5455753e-04], Action: 0, state: 8\n",
      "Action prob: [9.9922407e-01 7.7595131e-04], Action: 0, state: 8\n",
      "Action prob: [9.9975723e-01 2.4278175e-04], Action: 0, state: 8\n",
      "Action prob: [9.9968183e-01 3.1815967e-04], Action: 0, state: 8\n",
      "tensor([-8.7484e-04, -3.9403e-04, -8.9146e-05,  1.8910e-04,  4.1438e-04,\n",
      "         5.8540e-04,  7.6727e-04,  8.2259e-04,  1.8522e-03,  1.0755e-03,\n",
      "         1.4555e-03,  1.5144e-03,  4.1555e-03,  4.4803e-04,  1.4133e-03,\n",
      "         3.0599e-04,  7.8077e-04,  9.6687e-05,  7.4796e-05,  2.3818e-05,\n",
      "        -1.8564e-05, -5.7516e-05, -1.0358e-04, -1.4920e-04, -1.6173e-04,\n",
      "        -5.3363e-04, -1.8711e-04, -1.2695e-04, -5.5965e-04, -3.6582e-04,\n",
      "        -2.1329e-04, -7.2462e-04, -1.8205e-04, -1.7210e-04, -8.8056e-04,\n",
      "        -1.7230e-04, -7.4918e-04, -8.2951e-04, -7.5014e-04, -1.8911e-04,\n",
      "        -2.4024e-04, -1.9965e-04, -3.4388e-04, -4.8201e-04, -1.0422e-03,\n",
      "        -2.4703e-04, -1.8772e-04, -5.7350e-04, -1.7970e-04, -2.3588e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -108900, loss is -7.517786751088937e-05\n",
      "Action prob: [9.994019e-01 5.981213e-04], Action: 0, state: 0\n",
      "Action prob: [9.9933475e-01 6.6527550e-04], Action: 0, state: 1\n",
      "Action prob: [9.9942172e-01 5.7827664e-04], Action: 0, state: 2\n",
      "Action prob: [9.9971551e-01 2.8444416e-04], Action: 0, state: 3\n",
      "Action prob: [9.9951851e-01 4.8146336e-04], Action: 0, state: 9\n",
      "Action prob: [9.9962008e-01 3.7989614e-04], Action: 0, state: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [9.9968243e-01 3.1753693e-04], Action: 0, state: 9\n",
      "Action prob: [9.9961638e-01 3.8358002e-04], Action: 0, state: 9\n",
      "Action prob: [0.9989636  0.00103641], Action: 0, state: 9\n",
      "Action prob: [0.9988558  0.00114413], Action: 0, state: 9\n",
      "Action prob: [9.9971062e-01 2.8937266e-04], Action: 0, state: 9\n",
      "Action prob: [9.9962449e-01 3.7544392e-04], Action: 0, state: 9\n",
      "Action prob: [0.99896836 0.00103159], Action: 0, state: 9\n",
      "Action prob: [0.99862325 0.0013767 ], Action: 0, state: 9\n",
      "Action prob: [0.9987675  0.00123251], Action: 0, state: 9\n",
      "Action prob: [0.998923   0.00107701], Action: 0, state: 9\n",
      "Action prob: [0.99899536 0.00100468], Action: 0, state: 9\n",
      "Action prob: [9.997094e-01 2.905304e-04], Action: 0, state: 9\n",
      "Action prob: [9.9968469e-01 3.1535843e-04], Action: 0, state: 9\n",
      "Action prob: [9.9956089e-01 4.3905285e-04], Action: 0, state: 9\n",
      "Action prob: [0.9988306  0.00116941], Action: 0, state: 9\n",
      "Action prob: [0.9978405  0.00215941], Action: 0, state: 9\n",
      "Action prob: [9.9983096e-01 1.6897082e-04], Action: 0, state: 9\n",
      "Action prob: [9.997254e-01 2.745785e-04], Action: 0, state: 9\n",
      "Action prob: [0.9987589 0.0012411], Action: 0, state: 9\n",
      "Action prob: [9.9970657e-01 2.9344420e-04], Action: 0, state: 9\n",
      "Action prob: [0.99865365 0.00134628], Action: 0, state: 9\n",
      "Action prob: [9.9957567e-01 4.2427707e-04], Action: 0, state: 9\n",
      "Action prob: [0.9988257  0.00117428], Action: 0, state: 9\n",
      "Action prob: [0.9987507  0.00124926], Action: 0, state: 9\n",
      "Action prob: [9.9985969e-01 1.4032402e-04], Action: 0, state: 9\n",
      "Action prob: [9.996692e-01 3.307989e-04], Action: 0, state: 9\n",
      "Action prob: [0.9986785  0.00132143], Action: 0, state: 9\n",
      "Action prob: [0.99804604 0.00195392], Action: 0, state: 9\n",
      "Action prob: [9.9968195e-01 3.1808083e-04], Action: 0, state: 9\n",
      "Action prob: [0.9987068  0.00129323], Action: 0, state: 9\n",
      "Action prob: [0.9986811  0.00131882], Action: 0, state: 9\n",
      "Action prob: [9.9977666e-01 2.2333841e-04], Action: 0, state: 9\n",
      "Action prob: [0.9988207  0.00117925], Action: 0, state: 9\n",
      "Action prob: [9.9955386e-01 4.4611521e-04], Action: 0, state: 9\n",
      "Action prob: [0.99863714 0.00136287], Action: 0, state: 9\n",
      "Action prob: [9.9970454e-01 2.9549078e-04], Action: 0, state: 9\n",
      "Action prob: [9.9971288e-01 2.8708062e-04], Action: 0, state: 9\n",
      "Action prob: [0.99869674 0.00130332], Action: 0, state: 9\n",
      "Action prob: [9.9968827e-01 3.1171285e-04], Action: 0, state: 9\n",
      "Action prob: [0.9986513  0.00134872], Action: 0, state: 9\n",
      "Action prob: [0.99876726 0.00123281], Action: 0, state: 9\n",
      "Action prob: [9.9964535e-01 3.5459636e-04], Action: 0, state: 9\n",
      "Action prob: [0.9984145  0.00158549], Action: 0, state: 9\n",
      "Action prob: [0.9986051  0.00139489], Action: 0, state: 9\n",
      "tensor([ 7.6712e-04,  1.3909e-03,  1.5621e-03,  8.6065e-04,  1.1912e-03,\n",
      "         7.6187e-04,  5.1032e-04,  4.8657e-04,  1.0166e-03,  8.4235e-04,\n",
      "         1.5278e-04,  1.3189e-04,  2.0742e-04,  1.0095e-04, -4.3472e-05,\n",
      "        -1.3739e-04, -2.0697e-04, -7.9209e-05, -1.0382e-04, -1.6574e-04,\n",
      "        -4.8943e-04, -9.7948e-04, -8.1595e-05, -1.3946e-04, -6.5714e-04,\n",
      "        -1.6063e-04, -7.5818e-04, -2.4441e-04, -6.8974e-04, -7.4570e-04,\n",
      "        -8.4833e-05, -2.0230e-04, -8.1622e-04, -1.2169e-03, -1.9926e-04,\n",
      "        -8.1520e-04, -8.3541e-04, -1.4197e-04, -7.5258e-04, -2.8544e-04,\n",
      "        -8.7452e-04, -1.8989e-04, -1.8485e-04, -8.4078e-04, -2.0127e-04,\n",
      "        -8.7216e-04, -7.9789e-04, -2.2962e-04, -1.0279e-03, -9.0476e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -44800, loss is 0.0001434667319074361\n",
      "Action prob: [9.9929214e-01 7.0783589e-04], Action: 0, state: 0\n",
      "Action prob: [9.994300e-01 5.699391e-04], Action: 0, state: 0\n",
      "Action prob: [9.9939990e-01 6.0014933e-04], Action: 0, state: 1\n",
      "Action prob: [9.9926203e-01 7.3799910e-04], Action: 0, state: 1\n",
      "Action prob: [9.992099e-01 7.901359e-04], Action: 0, state: 2\n",
      "Action prob: [9.9924147e-01 7.5850054e-04], Action: 0, state: 3\n",
      "Action prob: [9.9932325e-01 6.7673874e-04], Action: 0, state: 3\n",
      "Action prob: [9.9953890e-01 4.6118168e-04], Action: 0, state: 8\n",
      "Action prob: [9.9932754e-01 6.7250221e-04], Action: 0, state: 8\n",
      "Action prob: [9.9978381e-01 2.1623417e-04], Action: 0, state: 8\n",
      "Action prob: [0.9984999  0.00150019], Action: 0, state: 8\n",
      "Action prob: [9.9950743e-01 4.9252866e-04], Action: 0, state: 8\n",
      "Action prob: [9.9943227e-01 5.6772568e-04], Action: 0, state: 8\n",
      "Action prob: [9.9965501e-01 3.4501927e-04], Action: 0, state: 8\n",
      "Action prob: [9.9960297e-01 3.9700262e-04], Action: 0, state: 8\n",
      "Action prob: [9.994832e-01 5.167284e-04], Action: 0, state: 8\n",
      "Action prob: [9.9966812e-01 3.3194033e-04], Action: 0, state: 8\n",
      "Action prob: [9.9955493e-01 4.4502615e-04], Action: 0, state: 8\n",
      "Action prob: [9.9961829e-01 3.8170617e-04], Action: 0, state: 8\n",
      "Action prob: [9.995265e-01 4.734895e-04], Action: 0, state: 8\n",
      "Action prob: [0.99867624 0.00132376], Action: 0, state: 8\n",
      "Action prob: [9.9920219e-01 7.9782587e-04], Action: 0, state: 8\n",
      "Action prob: [9.9969089e-01 3.0919147e-04], Action: 0, state: 8\n",
      "Action prob: [0.9987361  0.00126398], Action: 0, state: 8\n",
      "Action prob: [9.993870e-01 6.130073e-04], Action: 0, state: 8\n",
      "Action prob: [9.9963069e-01 3.6930118e-04], Action: 0, state: 8\n",
      "Action prob: [0.9984432  0.00155687], Action: 0, state: 8\n",
      "Action prob: [9.9966466e-01 3.3529894e-04], Action: 0, state: 8\n",
      "Action prob: [9.997191e-01 2.808539e-04], Action: 0, state: 8\n",
      "Action prob: [0.99855405 0.00144599], Action: 0, state: 8\n",
      "Action prob: [9.994918e-01 5.081209e-04], Action: 0, state: 8\n",
      "Action prob: [0.9985428  0.00145718], Action: 0, state: 8\n",
      "Action prob: [9.9960726e-01 3.9270797e-04], Action: 0, state: 8\n",
      "Action prob: [9.9958509e-01 4.1496358e-04], Action: 0, state: 8\n",
      "Action prob: [9.9949682e-01 5.0321134e-04], Action: 0, state: 8\n",
      "Action prob: [0.99899894 0.00100106], Action: 0, state: 8\n",
      "Action prob: [9.9950278e-01 4.9719785e-04], Action: 0, state: 8\n",
      "Action prob: [0.9984775  0.00152245], Action: 0, state: 8\n",
      "Action prob: [9.9962139e-01 3.7856336e-04], Action: 0, state: 8\n",
      "Action prob: [9.9962986e-01 3.7014409e-04], Action: 0, state: 8\n",
      "Action prob: [9.9985480e-01 1.4523472e-04], Action: 0, state: 8\n",
      "Action prob: [0.99872524 0.00127479], Action: 0, state: 8\n",
      "Action prob: [0.998998   0.00100199], Action: 0, state: 8\n",
      "Action prob: [0.9985979  0.00140209], Action: 0, state: 8\n",
      "Action prob: [9.9955219e-01 4.4777401e-04], Action: 0, state: 8\n",
      "Action prob: [9.994368e-01 5.631891e-04], Action: 0, state: 8\n",
      "Action prob: [9.9958116e-01 4.1888491e-04], Action: 0, state: 8\n",
      "Action prob: [9.9961603e-01 3.8398724e-04], Action: 0, state: 8\n",
      "Action prob: [9.9961591e-01 3.8405292e-04], Action: 0, state: 8\n",
      "Action prob: [9.9954045e-01 4.5963618e-04], Action: 0, state: 8\n",
      "tensor([ 7.2427e-04,  8.2364e-04,  1.0608e-03,  1.5071e-03,  1.7774e-03,\n",
      "         1.7899e-03,  1.6602e-03,  9.1094e-04,  1.0558e-03,  2.6480e-04,\n",
      "         1.3987e-03,  3.3630e-04,  2.6739e-04,  1.0036e-04,  5.4755e-05,\n",
      "         4.0602e-06, -3.4080e-05, -8.7529e-05, -1.0555e-04, -1.6309e-04,\n",
      "        -5.3257e-04, -3.6003e-04, -1.5235e-04, -6.6803e-04, -3.4234e-04,\n",
      "        -2.1569e-04, -9.4367e-04, -2.0935e-04, -1.7978e-04, -9.4527e-04,\n",
      "        -3.3784e-04, -9.8329e-04, -2.6809e-04, -2.8612e-04, -3.5000e-04,\n",
      "        -7.0152e-04, -3.5049e-04, -1.0793e-03, -2.6941e-04, -2.6436e-04,\n",
      "        -1.0401e-04, -9.1614e-04, -7.2165e-04, -1.0119e-03, -3.2356e-04,\n",
      "        -4.0752e-04, -3.0339e-04, -2.7841e-04, -2.7873e-04, -3.3374e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -127400, loss is 1.5448811834619453e-05\n",
      "Action prob: [9.9919945e-01 8.0057938e-04], Action: 0, state: 0\n",
      "Action prob: [9.994473e-01 5.526922e-04], Action: 0, state: 1\n",
      "Action prob: [9.9952185e-01 4.7811310e-04], Action: 0, state: 1\n",
      "Action prob: [9.995913e-01 4.087332e-04], Action: 0, state: 1\n",
      "Action prob: [9.9946505e-01 5.3494977e-04], Action: 0, state: 2\n",
      "Action prob: [9.993331e-01 6.668551e-04], Action: 0, state: 2\n",
      "Action prob: [9.992908e-01 7.090998e-04], Action: 0, state: 2\n",
      "Action prob: [9.992286e-01 7.714447e-04], Action: 0, state: 2\n",
      "Action prob: [9.9928075e-01 7.1931427e-04], Action: 0, state: 2\n",
      "Action prob: [9.9922609e-01 7.7385595e-04], Action: 0, state: 3\n",
      "Action prob: [9.9954873e-01 4.5121362e-04], Action: 0, state: 8\n",
      "Action prob: [9.9970180e-01 2.9816618e-04], Action: 0, state: 8\n",
      "Action prob: [9.994710e-01 5.290476e-04], Action: 0, state: 8\n",
      "Action prob: [0.9985538  0.00144615], Action: 0, state: 8\n",
      "Action prob: [0.9989919  0.00100812], Action: 0, state: 8\n",
      "Action prob: [9.9975079e-01 2.4925653e-04], Action: 0, state: 8\n",
      "Action prob: [0.99873847 0.00126159], Action: 0, state: 8\n",
      "Action prob: [9.9978715e-01 2.1289547e-04], Action: 0, state: 8\n",
      "Action prob: [9.9969220e-01 3.0777592e-04], Action: 0, state: 8\n",
      "Action prob: [9.9962461e-01 3.7541622e-04], Action: 0, state: 8\n",
      "Action prob: [0.99835724 0.00164276], Action: 0, state: 8\n",
      "Action prob: [9.9972695e-01 2.7303176e-04], Action: 0, state: 8\n",
      "Action prob: [9.9964499e-01 3.5501277e-04], Action: 0, state: 8\n",
      "Action prob: [9.9934083e-01 6.5917440e-04], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [9.994178e-01 5.822312e-04], Action: 0, state: 8\n",
      "Action prob: [0.9985098  0.00149014], Action: 0, state: 8\n",
      "Action prob: [0.9984971  0.00150289], Action: 0, state: 8\n",
      "Action prob: [9.9965894e-01 3.4101174e-04], Action: 0, state: 8\n",
      "Action prob: [9.9961960e-01 3.8032568e-04], Action: 0, state: 8\n",
      "Action prob: [9.996773e-01 3.226551e-04], Action: 0, state: 8\n",
      "Action prob: [9.9967861e-01 3.2139916e-04], Action: 0, state: 8\n",
      "Action prob: [9.997260e-01 2.739668e-04], Action: 0, state: 8\n",
      "Action prob: [0.99876297 0.00123707], Action: 0, state: 8\n",
      "Action prob: [9.9950540e-01 4.9456576e-04], Action: 0, state: 8\n",
      "Action prob: [0.99854517 0.00145491], Action: 0, state: 8\n",
      "Action prob: [9.9966490e-01 3.3512642e-04], Action: 0, state: 8\n",
      "Action prob: [0.9986376  0.00136243], Action: 0, state: 8\n",
      "Action prob: [9.9961901e-01 3.8095456e-04], Action: 0, state: 8\n",
      "Action prob: [9.996320e-01 3.680033e-04], Action: 0, state: 8\n",
      "Action prob: [0.9989538  0.00104618], Action: 0, state: 8\n",
      "Action prob: [0.99865013 0.00134991], Action: 0, state: 8\n",
      "Action prob: [0.99845755 0.00154251], Action: 0, state: 8\n",
      "Action prob: [0.99788386 0.00211611], Action: 0, state: 8\n",
      "Action prob: [9.997396e-01 2.604555e-04], Action: 0, state: 8\n",
      "Action prob: [9.9950814e-01 4.9185759e-04], Action: 0, state: 8\n",
      "Action prob: [9.9956733e-01 4.3262445e-04], Action: 0, state: 8\n",
      "Action prob: [9.9961215e-01 3.8782720e-04], Action: 0, state: 8\n",
      "Action prob: [0.998307   0.00169297], Action: 0, state: 8\n",
      "Action prob: [9.9955314e-01 4.4681574e-04], Action: 0, state: 8\n",
      "Action prob: [0.9985267  0.00147328], Action: 0, state: 8\n",
      "tensor([-4.3161e-04,  4.9038e-05,  2.9756e-04,  4.3971e-04,  7.5890e-04,\n",
      "         1.1405e-03,  1.3884e-03,  1.6726e-03,  1.6882e-03,  1.8901e-03,\n",
      "         8.8320e-04,  4.6074e-04,  6.3217e-04,  1.2984e-03,  6.4976e-04,\n",
      "         1.0698e-04,  3.1111e-04,  1.9397e-05, -1.2596e-05, -5.7502e-05,\n",
      "        -4.0864e-04, -9.0019e-05, -1.4152e-04, -3.0144e-04, -2.9524e-04,\n",
      "        -8.1913e-04, -8.8022e-04, -2.1007e-04, -2.4420e-04, -2.1428e-04,\n",
      "        -2.1945e-04, -1.9146e-04, -8.8161e-04, -3.5807e-04, -1.0680e-03,\n",
      "        -2.4865e-04, -1.0211e-03, -2.8771e-04, -2.7978e-04, -8.0021e-04,\n",
      "        -1.0376e-03, -1.1906e-03, -1.6396e-03, -2.0218e-04, -3.8286e-04,\n",
      "        -3.3749e-04, -3.0306e-04, -1.3258e-03, -3.5016e-04, -1.1563e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -115800, loss is 7.403430472156001e-05\n",
      "Action prob: [9.9929559e-01 7.0442137e-04], Action: 0, state: 0\n",
      "Action prob: [9.991221e-01 8.779416e-04], Action: 0, state: 1\n",
      "Action prob: [9.9933064e-01 6.6943985e-04], Action: 0, state: 2\n",
      "Action prob: [9.9917030e-01 8.2969276e-04], Action: 0, state: 3\n",
      "Action prob: [9.9940085e-01 5.9909857e-04], Action: 0, state: 3\n",
      "Action prob: [9.9931550e-01 6.8451377e-04], Action: 0, state: 3\n",
      "Action prob: [9.992361e-01 7.638926e-04], Action: 0, state: 3\n",
      "Action prob: [9.9943715e-01 5.6280271e-04], Action: 0, state: 3\n",
      "Action prob: [9.993019e-01 6.981053e-04], Action: 0, state: 3\n",
      "Action prob: [9.9968159e-01 3.1846497e-04], Action: 0, state: 3\n",
      "Action prob: [9.9937063e-01 6.2933768e-04], Action: 0, state: 3\n",
      "Action prob: [9.9902666e-01 9.7334158e-04], Action: 0, state: 3\n",
      "Action prob: [0.9986451  0.00135487], Action: 0, state: 8\n",
      "Action prob: [9.9962914e-01 3.7083705e-04], Action: 0, state: 8\n",
      "Action prob: [9.9960810e-01 3.9189195e-04], Action: 0, state: 8\n",
      "Action prob: [9.9961972e-01 3.8020534e-04], Action: 0, state: 8\n",
      "Action prob: [0.9985065  0.00149352], Action: 0, state: 8\n",
      "Action prob: [0.9985329  0.00146712], Action: 0, state: 8\n",
      "Action prob: [9.994293e-01 5.706275e-04], Action: 0, state: 8\n",
      "Action prob: [9.994419e-01 5.580378e-04], Action: 0, state: 8\n",
      "Action prob: [9.9957961e-01 4.2041147e-04], Action: 0, state: 8\n",
      "Action prob: [9.996636e-01 3.363985e-04], Action: 0, state: 8\n",
      "Action prob: [0.9986528  0.00134711], Action: 0, state: 8\n",
      "Action prob: [9.9984109e-01 1.5890432e-04], Action: 0, state: 8\n",
      "Action prob: [0.9984635  0.00153648], Action: 0, state: 8\n",
      "Action prob: [0.9989028  0.00109722], Action: 0, state: 8\n",
      "Action prob: [0.998628   0.00137201], Action: 0, state: 8\n",
      "Action prob: [0.9985245  0.00147553], Action: 0, state: 8\n",
      "Action prob: [0.99824727 0.00175273], Action: 0, state: 8\n",
      "Action prob: [9.9956495e-01 4.3501263e-04], Action: 0, state: 8\n",
      "Action prob: [0.9981034  0.00189659], Action: 0, state: 8\n",
      "Action prob: [9.9944764e-01 5.5232306e-04], Action: 0, state: 8\n",
      "Action prob: [9.9936599e-01 6.3399674e-04], Action: 0, state: 8\n",
      "Action prob: [9.9961406e-01 3.8599776e-04], Action: 0, state: 8\n",
      "Action prob: [0.99891233 0.00108767], Action: 0, state: 8\n",
      "Action prob: [9.994773e-01 5.227366e-04], Action: 0, state: 8\n",
      "Action prob: [0.9986811 0.0013188], Action: 0, state: 8\n",
      "Action prob: [0.9986029  0.00139705], Action: 0, state: 8\n",
      "Action prob: [9.9921477e-01 7.8522775e-04], Action: 0, state: 8\n",
      "Action prob: [9.9964404e-01 3.5598071e-04], Action: 0, state: 8\n",
      "Action prob: [9.9949396e-01 5.0607679e-04], Action: 0, state: 8\n",
      "Action prob: [0.99860686 0.00139317], Action: 0, state: 8\n",
      "Action prob: [9.993849e-01 6.151493e-04], Action: 0, state: 8\n",
      "Action prob: [0.99891746 0.00108255], Action: 0, state: 8\n",
      "Action prob: [0.9987784  0.00122156], Action: 0, state: 8\n",
      "Action prob: [9.9961579e-01 3.8424192e-04], Action: 0, state: 8\n",
      "Action prob: [9.995834e-01 4.165308e-04], Action: 0, state: 8\n",
      "Action prob: [0.99808216 0.0019179 ], Action: 0, state: 8\n",
      "Action prob: [9.9941707e-01 5.8300310e-04], Action: 0, state: 8\n",
      "Action prob: [9.9972147e-01 2.7853294e-04], Action: 0, state: 8\n",
      "tensor([-6.4468e-04, -8.0265e-05,  3.5542e-04,  7.1496e-04,  6.8462e-04,\n",
      "         9.4570e-04,  1.2106e-03,  9.8901e-04,  1.3292e-03,  6.4583e-04,\n",
      "         1.3435e-03,  2.1658e-03,  2.3925e-03,  5.0974e-04,  4.0857e-04,\n",
      "         2.8916e-04,  7.7788e-04,  4.6488e-04,  8.1857e-05, -2.1606e-06,\n",
      "        -5.4259e-05, -7.9215e-05, -4.3930e-04, -6.4003e-05, -7.1975e-04,\n",
      "        -5.7483e-04, -7.8370e-04, -9.0213e-04, -1.1316e-03, -2.9331e-04,\n",
      "        -1.3264e-03, -3.9761e-04, -4.6770e-04, -2.9051e-04, -8.3300e-04,\n",
      "        -4.0590e-04, -1.0369e-03, -1.1094e-03, -6.2865e-04, -2.8695e-04,\n",
      "        -4.1043e-04, -1.1362e-03, -5.0361e-04, -8.8973e-04, -1.0072e-03,\n",
      "        -3.1747e-04, -3.4498e-04, -1.5924e-03, -4.8447e-04, -2.3176e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -110800, loss is 8.322694810274962e-05\n",
      "Action prob: [9.991503e-01 8.497613e-04], Action: 0, state: 0\n",
      "Action prob: [9.9923766e-01 7.6237024e-04], Action: 0, state: 0\n",
      "Action prob: [9.9922359e-01 7.7644875e-04], Action: 0, state: 1\n",
      "Action prob: [9.9918705e-01 8.1289822e-04], Action: 0, state: 2\n",
      "Action prob: [9.9912149e-01 8.7849173e-04], Action: 0, state: 2\n",
      "Action prob: [9.9910480e-01 8.9517154e-04], Action: 0, state: 2\n",
      "Action prob: [9.9934131e-01 6.5866165e-04], Action: 0, state: 3\n",
      "Action prob: [9.9925596e-01 7.4404204e-04], Action: 0, state: 3\n",
      "Action prob: [9.9965250e-01 3.4749336e-04], Action: 0, state: 3\n",
      "Action prob: [9.992774e-01 7.226060e-04], Action: 0, state: 3\n",
      "Action prob: [9.9962664e-01 3.7335098e-04], Action: 0, state: 8\n",
      "Action prob: [0.99870193 0.00129809], Action: 0, state: 8\n",
      "Action prob: [9.993886e-01 6.114187e-04], Action: 0, state: 8\n",
      "Action prob: [9.9952328e-01 4.7672034e-04], Action: 0, state: 8\n",
      "Action prob: [9.9931085e-01 6.8911287e-04], Action: 0, state: 8\n",
      "Action prob: [0.99838233 0.00161771], Action: 0, state: 8\n",
      "Action prob: [9.993679e-01 6.320932e-04], Action: 0, state: 8\n",
      "Action prob: [0.9986426  0.00135732], Action: 0, state: 8\n",
      "Action prob: [0.9983436  0.00165636], Action: 0, state: 8\n",
      "Action prob: [9.9960846e-01 3.9156931e-04], Action: 0, state: 8\n",
      "Action prob: [0.99847704 0.00152292], Action: 0, state: 8\n",
      "Action prob: [9.9977773e-01 2.2229149e-04], Action: 0, state: 8\n",
      "Action prob: [0.99854255 0.00145752], Action: 0, state: 8\n",
      "Action prob: [9.9955946e-01 4.4053738e-04], Action: 0, state: 8\n",
      "Action prob: [9.994560e-01 5.440416e-04], Action: 0, state: 8\n",
      "Action prob: [9.9948788e-01 5.1215076e-04], Action: 0, state: 8\n",
      "Action prob: [9.9968207e-01 3.1795469e-04], Action: 0, state: 8\n",
      "Action prob: [0.99863845 0.00136157], Action: 0, state: 8\n",
      "Action prob: [0.9982381 0.0017619], Action: 0, state: 8\n",
      "Action prob: [0.9984371  0.00156293], Action: 0, state: 8\n",
      "Action prob: [9.9955755e-01 4.4246114e-04], Action: 0, state: 8\n",
      "Action prob: [9.994029e-01 5.971729e-04], Action: 0, state: 8\n",
      "Action prob: [0.99877757 0.00122242], Action: 0, state: 8\n",
      "Action prob: [0.9983412  0.00165874], Action: 0, state: 8\n",
      "Action prob: [0.9983339  0.00166609], Action: 0, state: 8\n",
      "Action prob: [9.9949682e-01 5.0311995e-04], Action: 0, state: 8\n",
      "Action prob: [0.9984896  0.00151034], Action: 0, state: 8\n",
      "Action prob: [0.9979786  0.00202138], Action: 0, state: 8\n",
      "Action prob: [9.9938309e-01 6.1688485e-04], Action: 0, state: 8\n",
      "Action prob: [9.9947828e-01 5.2174943e-04], Action: 0, state: 8\n",
      "Action prob: [0.9981687  0.00183132], Action: 0, state: 8\n",
      "Action prob: [9.9948335e-01 5.1660871e-04], Action: 0, state: 8\n",
      "Action prob: [9.9960941e-01 3.9058639e-04], Action: 0, state: 8\n",
      "Action prob: [9.9942625e-01 5.7377410e-04], Action: 0, state: 8\n",
      "Action prob: [9.9965346e-01 3.4653000e-04], Action: 0, state: 8\n",
      "Action prob: [9.9977309e-01 2.2694815e-04], Action: 0, state: 8\n",
      "Action prob: [9.9957269e-01 4.2726978e-04], Action: 0, state: 8\n",
      "Action prob: [9.9943906e-01 5.6096120e-04], Action: 0, state: 8\n",
      "Action prob: [9.992781e-01 7.218588e-04], Action: 0, state: 8\n",
      "Action prob: [9.994211e-01 5.789053e-04], Action: 0, state: 8\n",
      "tensor([-2.9122e-04,  2.5337e-04,  6.5901e-04,  1.0073e-03,  1.3799e-03,\n",
      "         1.6585e-03,  1.3188e-03,  1.5845e-03,  7.7748e-04,  1.6835e-03,\n",
      "         6.9460e-04,  1.8983e-03,  6.8665e-04,  3.9802e-04,  4.0671e-04,\n",
      "         6.1830e-04,  1.2966e-04,  7.4363e-05, -1.2106e-04, -7.1129e-05,\n",
      "        -4.1752e-04, -7.8337e-05, -6.1127e-04, -2.0965e-04, -2.8513e-04,\n",
      "        -2.8940e-04, -1.9071e-04, -8.5748e-04, -1.1542e-03, -1.0572e-03,\n",
      "        -3.0715e-04, -4.2379e-04, -8.8392e-04, -1.2182e-03, -1.2395e-03,\n",
      "        -3.7816e-04, -1.1461e-03, -1.5460e-03, -4.7454e-04, -4.0350e-04,\n",
      "        -1.4238e-03, -4.0300e-04, -3.0566e-04, -4.5030e-04, -2.7259e-04,\n",
      "        -1.7884e-04, -3.3739e-04, -4.4358e-04, -5.7159e-04, -4.5881e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -116700, loss is 6.543228023459618e-05\n",
      "Action prob: [9.991799e-01 8.200696e-04], Action: 0, state: 0\n",
      "Action prob: [9.9918634e-01 8.1369607e-04], Action: 0, state: 1\n",
      "Action prob: [9.9917287e-01 8.2706736e-04], Action: 0, state: 1\n",
      "Action prob: [9.9911124e-01 8.8880456e-04], Action: 0, state: 1\n",
      "Action prob: [9.9934059e-01 6.5934873e-04], Action: 0, state: 1\n",
      "Action prob: [9.9920064e-01 7.9935166e-04], Action: 0, state: 1\n",
      "Action prob: [9.991799e-01 8.200426e-04], Action: 0, state: 2\n",
      "Action prob: [9.9929917e-01 7.0084538e-04], Action: 0, state: 2\n",
      "Action prob: [9.9914110e-01 8.5890753e-04], Action: 0, state: 3\n",
      "Action prob: [9.9955279e-01 4.4719176e-04], Action: 0, state: 8\n",
      "Action prob: [9.9956888e-01 4.3109487e-04], Action: 0, state: 8\n",
      "Action prob: [0.99817085 0.00182918], Action: 0, state: 8\n",
      "Action prob: [9.9949324e-01 5.0668110e-04], Action: 0, state: 8\n",
      "Action prob: [9.994373e-01 5.627231e-04], Action: 0, state: 8\n",
      "Action prob: [0.99880064 0.0011994 ], Action: 0, state: 8\n",
      "Action prob: [0.9981862  0.00181381], Action: 0, state: 8\n",
      "Action prob: [0.9978483  0.00215176], Action: 0, state: 8\n",
      "Action prob: [9.996213e-01 3.787536e-04], Action: 0, state: 8\n",
      "Action prob: [9.993950e-01 6.049327e-04], Action: 0, state: 8\n",
      "Action prob: [0.9986791  0.00132093], Action: 0, state: 8\n",
      "Action prob: [0.99859554 0.00140446], Action: 0, state: 8\n",
      "Action prob: [0.9988122  0.00118788], Action: 0, state: 8\n",
      "Action prob: [9.994930e-01 5.069405e-04], Action: 0, state: 8\n",
      "Action prob: [9.9956781e-01 4.3212922e-04], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.998415   0.00158504], Action: 0, state: 8\n",
      "Action prob: [9.992448e-01 7.552675e-04], Action: 0, state: 8\n",
      "Action prob: [9.99516e-01 4.84011e-04], Action: 0, state: 8\n",
      "Action prob: [9.9946886e-01 5.3113210e-04], Action: 0, state: 8\n",
      "Action prob: [0.99852896 0.00147105], Action: 0, state: 8\n",
      "Action prob: [9.9947160e-01 5.2843883e-04], Action: 0, state: 8\n",
      "Action prob: [9.9906284e-01 9.3717891e-04], Action: 0, state: 8\n",
      "Action prob: [0.9985545  0.00144545], Action: 0, state: 8\n",
      "Action prob: [0.99721485 0.00278513], Action: 0, state: 8\n",
      "Action prob: [9.9937516e-01 6.2491035e-04], Action: 0, state: 8\n",
      "Action prob: [0.99819857 0.00180146], Action: 0, state: 8\n",
      "Action prob: [9.993043e-01 6.956738e-04], Action: 0, state: 8\n",
      "Action prob: [9.9930429e-01 6.9574785e-04], Action: 0, state: 8\n",
      "Action prob: [9.9930716e-01 6.9280207e-04], Action: 0, state: 8\n",
      "Action prob: [9.992974e-01 7.026152e-04], Action: 0, state: 8\n",
      "Action prob: [9.9902678e-01 9.7324146e-04], Action: 0, state: 8\n",
      "Action prob: [9.9939764e-01 6.0233288e-04], Action: 0, state: 8\n",
      "Action prob: [0.9985165  0.00148355], Action: 0, state: 8\n",
      "Action prob: [9.9955493e-01 4.4509300e-04], Action: 0, state: 8\n",
      "Action prob: [9.9926764e-01 7.3237286e-04], Action: 0, state: 8\n",
      "Action prob: [0.99853396 0.00146606], Action: 0, state: 8\n",
      "Action prob: [0.99816173 0.00183823], Action: 0, state: 8\n",
      "Action prob: [0.99839526 0.0016047 ], Action: 0, state: 8\n",
      "Action prob: [0.9982438  0.00175624], Action: 0, state: 8\n",
      "Action prob: [0.99844897 0.00155097], Action: 0, state: 8\n",
      "Action prob: [9.994960e-01 5.039808e-04], Action: 0, state: 8\n",
      "tensor([-6.5663e-06,  4.2918e-04,  8.1277e-04,  1.2172e-03,  1.1198e-03,\n",
      "         1.5810e-03,  1.7953e-03,  1.6599e-03,  2.1164e-03,  8.8424e-04,\n",
      "         6.7422e-04,  2.2194e-03,  4.6314e-04,  3.7145e-04,  5.3306e-04,\n",
      "         4.7352e-04,  2.2610e-04, -1.0421e-05, -8.4796e-05, -3.1172e-04,\n",
      "        -4.4580e-04, -4.5918e-04, -2.2574e-04, -2.1402e-04, -8.5272e-04,\n",
      "        -4.3339e-04, -2.9257e-04, -3.3493e-04, -9.6071e-04, -3.5488e-04,\n",
      "        -6.4456e-04, -1.0141e-03, -1.9876e-03, -4.5157e-04, -1.3178e-03,\n",
      "        -5.1358e-04, -5.1778e-04, -5.1921e-04, -5.2960e-04, -7.3729e-04,\n",
      "        -4.5815e-04, -1.1328e-03, -3.4069e-04, -5.6211e-04, -1.1281e-03,\n",
      "        -1.4173e-03, -1.2390e-03, -1.3578e-03, -1.2004e-03, -3.9025e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -119400, loss is 0.00011740913575307302\n",
      "Action prob: [9.99014e-01 9.85983e-04], Action: 0, state: 0\n",
      "Action prob: [9.991768e-01 8.231228e-04], Action: 0, state: 0\n",
      "Action prob: [9.991805e-01 8.195123e-04], Action: 0, state: 0\n",
      "Action prob: [9.9946338e-01 5.3664634e-04], Action: 0, state: 0\n",
      "Action prob: [9.9916124e-01 8.3880749e-04], Action: 0, state: 1\n",
      "Action prob: [9.9903178e-01 9.6819364e-04], Action: 0, state: 1\n",
      "Action prob: [9.990695e-01 9.304588e-04], Action: 0, state: 1\n",
      "Action prob: [9.9914587e-01 8.5411273e-04], Action: 0, state: 1\n",
      "Action prob: [9.9907982e-01 9.2022243e-04], Action: 0, state: 2\n",
      "Action prob: [9.9926037e-01 7.3960359e-04], Action: 0, state: 2\n",
      "Action prob: [9.9925631e-01 7.4370357e-04], Action: 0, state: 3\n",
      "Action prob: [9.990307e-01 9.693336e-04], Action: 0, state: 3\n",
      "Action prob: [0.9978969  0.00210305], Action: 0, state: 3\n",
      "Action prob: [0.9985146  0.00148538], Action: 0, state: 8\n",
      "Action prob: [0.99843735 0.00156263], Action: 0, state: 8\n",
      "Action prob: [9.995309e-01 4.690800e-04], Action: 0, state: 8\n",
      "Action prob: [9.9960166e-01 3.9832396e-04], Action: 0, state: 8\n",
      "Action prob: [0.9989182  0.00108179], Action: 0, state: 8\n",
      "Action prob: [0.9984665  0.00153356], Action: 0, state: 8\n",
      "Action prob: [9.9939501e-01 6.0493906e-04], Action: 0, state: 8\n",
      "Action prob: [9.990319e-01 9.680829e-04], Action: 0, state: 8\n",
      "Action prob: [9.994802e-01 5.197991e-04], Action: 0, state: 8\n",
      "Action prob: [9.994998e-01 5.001890e-04], Action: 0, state: 8\n",
      "Action prob: [0.99807596 0.001924  ], Action: 0, state: 8\n",
      "Action prob: [9.993155e-01 6.845373e-04], Action: 0, state: 8\n",
      "Action prob: [9.9953306e-01 4.6691793e-04], Action: 0, state: 8\n",
      "Action prob: [9.9932337e-01 6.7670783e-04], Action: 0, state: 8\n",
      "Action prob: [0.9981085  0.00189144], Action: 0, state: 8\n",
      "Action prob: [9.992130e-01 7.869813e-04], Action: 0, state: 8\n",
      "Action prob: [0.99806386 0.00193618], Action: 0, state: 8\n",
      "Action prob: [0.9983481 0.0016519], Action: 0, state: 8\n",
      "Action prob: [9.9952805e-01 4.7191198e-04], Action: 0, state: 8\n",
      "Action prob: [0.9982487  0.00175129], Action: 0, state: 8\n",
      "Action prob: [9.9936920e-01 6.3085137e-04], Action: 0, state: 8\n",
      "Action prob: [9.995515e-01 4.484733e-04], Action: 0, state: 8\n",
      "Action prob: [9.993425e-01 6.575249e-04], Action: 0, state: 8\n",
      "Action prob: [0.9985215  0.00147853], Action: 0, state: 8\n",
      "Action prob: [0.9982133  0.00178677], Action: 0, state: 8\n",
      "Action prob: [9.996106e-01 3.894678e-04], Action: 0, state: 8\n",
      "Action prob: [0.9984629  0.00153708], Action: 0, state: 8\n",
      "Action prob: [0.9982102  0.00178982], Action: 0, state: 8\n",
      "Action prob: [9.9966681e-01 3.3325242e-04], Action: 0, state: 8\n",
      "Action prob: [9.9921846e-01 7.8153360e-04], Action: 0, state: 8\n",
      "Action prob: [0.99897003 0.00102996], Action: 0, state: 8\n",
      "Action prob: [9.993787e-01 6.212726e-04], Action: 0, state: 8\n",
      "Action prob: [9.9953043e-01 4.6955197e-04], Action: 0, state: 8\n",
      "Action prob: [9.994868e-01 5.131588e-04], Action: 0, state: 8\n",
      "Action prob: [9.9934024e-01 6.5972965e-04], Action: 0, state: 8\n",
      "Action prob: [9.9919933e-01 8.0062432e-04], Action: 0, state: 8\n",
      "Action prob: [9.9950659e-01 4.9334625e-04], Action: 0, state: 8\n",
      "tensor([-2.7827e-03, -1.5202e-03, -8.3402e-04, -1.6795e-04,  1.8960e-04,\n",
      "         6.6257e-04,  9.9917e-04,  1.1999e-03,  1.5229e-03,  1.3813e-03,\n",
      "         1.4728e-03,  2.0129e-03,  4.5417e-03,  2.5883e-03,  2.1700e-03,\n",
      "         5.1003e-04,  3.3129e-04,  6.6498e-04,  6.5954e-04,  1.6512e-04,\n",
      "         1.3510e-04,  1.3580e-05, -3.5144e-05, -2.9302e-04, -1.5185e-04,\n",
      "        -1.3122e-04, -2.2421e-04, -7.0809e-04, -3.2307e-04, -8.5511e-04,\n",
      "        -7.7287e-04, -2.3122e-04, -8.9181e-04, -3.3121e-04, -2.4163e-04,\n",
      "        -3.6191e-04, -8.2881e-04, -1.0168e-03, -2.2423e-04, -8.9499e-04,\n",
      "        -1.0515e-03, -1.9707e-04, -4.6528e-04, -6.1654e-04, -3.7352e-04,\n",
      "        -2.8335e-04, -3.1068e-04, -4.0053e-04, -4.8724e-04, -3.0080e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -104300, loss is -5.824298782012108e-05\n",
      "Action prob: [9.991091e-01 8.909277e-04], Action: 0, state: 0\n",
      "Action prob: [9.9950874e-01 4.9127423e-04], Action: 0, state: 0\n",
      "Action prob: [9.992889e-01 7.110114e-04], Action: 0, state: 1\n",
      "Action prob: [9.9912375e-01 8.7628351e-04], Action: 0, state: 2\n",
      "Action prob: [9.991673e-01 8.326624e-04], Action: 0, state: 2\n",
      "Action prob: [9.9955279e-01 4.4720373e-04], Action: 0, state: 3\n",
      "Action prob: [0.9984694 0.0015306], Action: 0, state: 3\n",
      "Action prob: [9.9922025e-01 7.7974942e-04], Action: 0, state: 3\n",
      "Action prob: [9.995229e-01 4.770649e-04], Action: 0, state: 3\n",
      "Action prob: [0.99897015 0.00102983], Action: 0, state: 3\n",
      "Action prob: [9.9908447e-01 9.1549684e-04], Action: 0, state: 3\n",
      "Action prob: [9.9902546e-01 9.7450562e-04], Action: 0, state: 3\n",
      "Action prob: [0.9980994  0.00190058], Action: 0, state: 8\n",
      "Action prob: [0.9982437  0.00175636], Action: 0, state: 8\n",
      "Action prob: [0.998307   0.00169296], Action: 0, state: 8\n",
      "Action prob: [9.9956423e-01 4.3577404e-04], Action: 0, state: 8\n",
      "Action prob: [9.9956983e-01 4.3017635e-04], Action: 0, state: 8\n",
      "Action prob: [0.9980755  0.00192455], Action: 0, state: 8\n",
      "Action prob: [9.9952435e-01 4.7565185e-04], Action: 0, state: 8\n",
      "Action prob: [0.9980475  0.00195248], Action: 0, state: 8\n",
      "Action prob: [0.9982899  0.00171011], Action: 0, state: 8\n",
      "Action prob: [9.995852e-01 4.147933e-04], Action: 0, state: 8\n",
      "Action prob: [9.995739e-01 4.261110e-04], Action: 0, state: 8\n",
      "Action prob: [9.9956018e-01 4.3976953e-04], Action: 0, state: 8\n",
      "Action prob: [9.9946314e-01 5.3689192e-04], Action: 0, state: 8\n",
      "Action prob: [9.9948895e-01 5.1099941e-04], Action: 0, state: 8\n",
      "Action prob: [0.99816656 0.00183343], Action: 0, state: 8\n",
      "Action prob: [0.998334   0.00166602], Action: 0, state: 8\n",
      "Action prob: [9.9952531e-01 4.7475044e-04], Action: 0, state: 8\n",
      "Action prob: [0.9981337  0.00186629], Action: 0, state: 8\n",
      "Action prob: [9.9933392e-01 6.6606817e-04], Action: 0, state: 8\n",
      "Action prob: [9.9944884e-01 5.5117399e-04], Action: 0, state: 8\n",
      "Action prob: [9.9943608e-01 5.6389486e-04], Action: 0, state: 8\n",
      "Action prob: [9.9924541e-01 7.5459835e-04], Action: 0, state: 8\n",
      "Action prob: [9.9954718e-01 4.5282557e-04], Action: 0, state: 8\n",
      "Action prob: [9.9957544e-01 4.2455402e-04], Action: 0, state: 8\n",
      "Action prob: [9.9942893e-01 5.7100155e-04], Action: 0, state: 8\n",
      "Action prob: [9.992131e-01 7.868433e-04], Action: 0, state: 8\n",
      "Action prob: [9.9960130e-01 3.9868522e-04], Action: 0, state: 8\n",
      "Action prob: [9.9952853e-01 4.7152487e-04], Action: 0, state: 8\n",
      "Action prob: [9.991147e-01 8.852403e-04], Action: 0, state: 8\n",
      "Action prob: [0.99785477 0.00214521], Action: 0, state: 8\n",
      "Action prob: [0.9981129  0.00188711], Action: 0, state: 8\n",
      "Action prob: [9.9955374e-01 4.4618748e-04], Action: 0, state: 8\n",
      "Action prob: [9.9966490e-01 3.3512962e-04], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [9.9928302e-01 7.1697263e-04], Action: 0, state: 8\n",
      "Action prob: [0.99784327 0.00215673], Action: 0, state: 8\n",
      "Action prob: [9.9957460e-01 4.2536014e-04], Action: 0, state: 8\n",
      "Action prob: [9.9957520e-01 4.2483053e-04], Action: 0, state: 8\n",
      "Action prob: [0.9982041  0.00179583], Action: 0, state: 8\n",
      "tensor([-1.2540e-03, -2.4610e-04,  1.3683e-04,  6.2774e-04,  9.6736e-04,\n",
      "         6.2524e-04,  2.4489e-03,  1.3804e-03,  9.1377e-04,  2.1003e-03,\n",
      "         1.9631e-03,  2.1767e-03,  3.3817e-03,  2.4450e-03,  1.7999e-03,\n",
      "         3.4123e-04,  2.3468e-04,  6.6189e-04,  8.1844e-05,  5.1205e-05,\n",
      "        -1.6732e-04, -8.4268e-05, -1.2474e-04, -1.6224e-04, -2.3279e-04,\n",
      "        -2.4971e-04, -9.8225e-04, -9.5874e-04, -2.8904e-04, -1.1908e-03,\n",
      "        -4.4101e-04, -3.7634e-04, -3.9500e-04, -5.3992e-04, -3.2972e-04,\n",
      "        -3.1374e-04, -4.2729e-04, -5.9500e-04, -3.0406e-04, -3.6224e-04,\n",
      "        -6.8459e-04, -1.6687e-03, -1.4743e-03, -3.4970e-04, -2.6342e-04,\n",
      "        -5.6525e-04, -1.7054e-03, -3.3675e-04, -3.3683e-04, -1.4270e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -110000, loss is -6.999270942131461e-05\n",
      "Action prob: [9.9900216e-01 9.9789223e-04], Action: 0, state: 0\n",
      "Action prob: [9.991991e-01 8.009124e-04], Action: 0, state: 1\n",
      "Action prob: [9.9913365e-01 8.6636230e-04], Action: 0, state: 1\n",
      "Action prob: [9.9903524e-01 9.6474565e-04], Action: 0, state: 1\n",
      "Action prob: [9.9902487e-01 9.7510742e-04], Action: 0, state: 1\n",
      "Action prob: [9.991990e-01 8.010758e-04], Action: 0, state: 2\n",
      "Action prob: [9.9902678e-01 9.7328046e-04], Action: 0, state: 3\n",
      "Action prob: [0.9981055  0.00189451], Action: 0, state: 8\n",
      "Action prob: [9.9956995e-01 4.3006893e-04], Action: 0, state: 8\n",
      "Action prob: [0.9979056  0.00209444], Action: 0, state: 8\n",
      "Action prob: [0.9982212  0.00177875], Action: 0, state: 8\n",
      "Action prob: [9.9933463e-01 6.6535536e-04], Action: 0, state: 8\n",
      "Action prob: [0.99887246 0.00112753], Action: 0, state: 8\n",
      "Action prob: [0.99789584 0.0021041 ], Action: 0, state: 8\n",
      "Action prob: [0.9984275  0.00157253], Action: 0, state: 8\n",
      "Action prob: [0.99772435 0.00227561], Action: 0, state: 8\n",
      "Action prob: [0.99790704 0.00209302], Action: 0, state: 8\n",
      "Action prob: [9.9912924e-01 8.7077095e-04], Action: 0, state: 8\n",
      "Action prob: [9.9957055e-01 4.2950481e-04], Action: 0, state: 8\n",
      "Action prob: [9.990565e-01 9.434844e-04], Action: 0, state: 8\n",
      "Action prob: [9.9934965e-01 6.5030524e-04], Action: 0, state: 8\n",
      "Action prob: [0.9983011  0.00169893], Action: 0, state: 8\n",
      "Action prob: [9.9981660e-01 1.8343619e-04], Action: 0, state: 8\n",
      "Action prob: [0.9983347  0.00166532], Action: 0, state: 8\n",
      "Action prob: [9.9956316e-01 4.3686171e-04], Action: 0, state: 8\n",
      "Action prob: [9.9948323e-01 5.1668845e-04], Action: 0, state: 8\n",
      "Action prob: [9.9934095e-01 6.5900793e-04], Action: 0, state: 8\n",
      "Action prob: [9.9911064e-01 8.8937086e-04], Action: 0, state: 8\n",
      "Action prob: [9.9949777e-01 5.0225697e-04], Action: 0, state: 8\n",
      "Action prob: [0.9980355  0.00196455], Action: 0, state: 8\n",
      "Action prob: [0.99828964 0.00171037], Action: 0, state: 8\n",
      "Action prob: [9.992768e-01 7.231612e-04], Action: 0, state: 8\n",
      "Action prob: [9.994972e-01 5.028652e-04], Action: 0, state: 8\n",
      "Action prob: [9.9927503e-01 7.2497845e-04], Action: 0, state: 8\n",
      "Action prob: [9.994997e-01 5.003158e-04], Action: 0, state: 8\n",
      "Action prob: [9.9946886e-01 5.3111592e-04], Action: 0, state: 8\n",
      "Action prob: [0.99800104 0.001999  ], Action: 0, state: 8\n",
      "Action prob: [0.9988876  0.00111245], Action: 0, state: 8\n",
      "Action prob: [0.99817    0.00182992], Action: 0, state: 8\n",
      "Action prob: [0.99867517 0.00132478], Action: 0, state: 8\n",
      "Action prob: [0.99799204 0.00200795], Action: 0, state: 8\n",
      "Action prob: [0.99811554 0.00188445], Action: 0, state: 8\n",
      "Action prob: [0.9983114  0.00168866], Action: 0, state: 8\n",
      "Action prob: [9.9946493e-01 5.3505506e-04], Action: 0, state: 8\n",
      "Action prob: [9.993229e-01 6.771200e-04], Action: 0, state: 8\n",
      "Action prob: [9.996081e-01 3.918912e-04], Action: 0, state: 8\n",
      "Action prob: [0.9983833  0.00161672], Action: 0, state: 8\n",
      "Action prob: [0.99775213 0.00224787], Action: 0, state: 8\n",
      "Action prob: [0.9984674  0.00153264], Action: 0, state: 8\n",
      "Action prob: [9.9969304e-01 3.0699992e-04], Action: 0, state: 8\n",
      "tensor([ 9.9259e-04,  1.1049e-03,  1.4787e-03,  1.9150e-03,  2.1662e-03,\n",
      "         1.9223e-03,  2.4281e-03,  3.8115e-03,  6.8773e-04,  2.6194e-03,\n",
      "         1.6955e-03,  4.6579e-04,  5.4739e-04,  6.3775e-04,  2.3245e-04,\n",
      "         3.6228e-05, -2.0141e-04, -1.6670e-04, -1.1697e-04, -3.2198e-04,\n",
      "        -2.5996e-04, -7.6397e-04, -9.0161e-05, -8.7912e-04, -2.4381e-04,\n",
      "        -3.0184e-04, -3.9952e-04, -5.5587e-04, -3.2185e-04, -1.2865e-03,\n",
      "        -1.1396e-03, -4.8871e-04, -3.4394e-04, -5.0108e-04, -3.4878e-04,\n",
      "        -3.7298e-04, -1.4134e-03, -7.9032e-04, -1.3064e-03, -9.4904e-04,\n",
      "        -1.4435e-03, -1.3582e-03, -1.2197e-03, -3.8701e-04, -4.9058e-04,\n",
      "        -2.8430e-04, -1.1749e-03, -1.6357e-03, -1.1158e-03, -2.2351e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -127100, loss is 3.115215617058844e-06\n",
      "Action prob: [9.991171e-01 8.829314e-04], Action: 0, state: 0\n",
      "Action prob: [9.991098e-01 8.902348e-04], Action: 0, state: 0\n",
      "Action prob: [9.9912447e-01 8.7549689e-04], Action: 0, state: 0\n",
      "Action prob: [9.994287e-01 5.712599e-04], Action: 0, state: 0\n",
      "Action prob: [9.9901116e-01 9.8883419e-04], Action: 0, state: 1\n",
      "Action prob: [9.992261e-01 7.739342e-04], Action: 0, state: 1\n",
      "Action prob: [0.9988681  0.00113187], Action: 0, state: 1\n",
      "Action prob: [9.990866e-01 9.133814e-04], Action: 0, state: 2\n",
      "Action prob: [0.99877435 0.00122566], Action: 0, state: 3\n",
      "Action prob: [9.990132e-01 9.867817e-04], Action: 0, state: 3\n",
      "Action prob: [9.994467e-01 5.533511e-04], Action: 0, state: 8\n",
      "Action prob: [0.9982851  0.00171486], Action: 0, state: 8\n",
      "Action prob: [0.9980235  0.00197653], Action: 0, state: 8\n",
      "Action prob: [9.9907637e-01 9.2359103e-04], Action: 0, state: 8\n",
      "Action prob: [9.9941134e-01 5.8863516e-04], Action: 0, state: 8\n",
      "Action prob: [9.9947375e-01 5.2629772e-04], Action: 0, state: 8\n",
      "Action prob: [0.99752146 0.00247852], Action: 0, state: 8\n",
      "Action prob: [9.9960715e-01 3.9293533e-04], Action: 0, state: 8\n",
      "Action prob: [9.994087e-01 5.913239e-04], Action: 0, state: 8\n",
      "Action prob: [9.9934751e-01 6.5249746e-04], Action: 0, state: 8\n",
      "Action prob: [0.9979693 0.0020307], Action: 0, state: 8\n",
      "Action prob: [9.997205e-01 2.794426e-04], Action: 0, state: 8\n",
      "Action prob: [0.99820316 0.00179677], Action: 0, state: 8\n",
      "Action prob: [0.9978891  0.00211087], Action: 0, state: 8\n",
      "Action prob: [9.9921608e-01 7.8395224e-04], Action: 0, state: 8\n",
      "Action prob: [9.991953e-01 8.047391e-04], Action: 0, state: 8\n",
      "Action prob: [0.9983929  0.00160711], Action: 0, state: 8\n",
      "Action prob: [0.99835545 0.00164453], Action: 0, state: 8\n",
      "Action prob: [9.9942529e-01 5.7473633e-04], Action: 0, state: 8\n",
      "Action prob: [0.99847883 0.00152121], Action: 0, state: 8\n",
      "Action prob: [0.99843675 0.00156325], Action: 0, state: 8\n",
      "Action prob: [9.994112e-01 5.887451e-04], Action: 0, state: 8\n",
      "Action prob: [0.99786216 0.00213781], Action: 0, state: 8\n",
      "Action prob: [0.9978555  0.00214448], Action: 0, state: 8\n",
      "Action prob: [9.992836e-01 7.163935e-04], Action: 0, state: 8\n",
      "Action prob: [9.9951184e-01 4.8821230e-04], Action: 0, state: 8\n",
      "Action prob: [9.9947113e-01 5.2891026e-04], Action: 0, state: 8\n",
      "Action prob: [9.9971217e-01 2.8786476e-04], Action: 0, state: 8\n",
      "Action prob: [9.992323e-01 7.676602e-04], Action: 0, state: 8\n",
      "Action prob: [9.994610e-01 5.389872e-04], Action: 0, state: 8\n",
      "Action prob: [9.9961227e-01 3.8780563e-04], Action: 0, state: 8\n",
      "Action prob: [9.994715e-01 5.285230e-04], Action: 0, state: 8\n",
      "Action prob: [9.9931312e-01 6.8693206e-04], Action: 0, state: 8\n",
      "Action prob: [9.9926049e-01 7.3955924e-04], Action: 0, state: 8\n",
      "Action prob: [0.99794    0.00205996], Action: 0, state: 8\n",
      "Action prob: [0.9981704  0.00182959], Action: 0, state: 8\n",
      "Action prob: [9.994280e-01 5.719954e-04], Action: 0, state: 8\n",
      "Action prob: [9.9939144e-01 6.0855516e-04], Action: 0, state: 8\n",
      "Action prob: [9.994092e-01 5.908022e-04], Action: 0, state: 8\n",
      "Action prob: [9.992453e-01 7.547717e-04], Action: 0, state: 8\n",
      "tensor([-6.6146e-04, -5.0580e-05,  4.6550e-04,  5.8945e-04,  1.3989e-03,\n",
      "         1.3464e-03,  2.2825e-03,  2.0325e-03,  2.8639e-03,  2.3986e-03,\n",
      "         1.0785e-03,  2.6429e-03,  2.3591e-03,  8.2898e-04,  3.8044e-04,\n",
      "         2.2778e-04,  6.2380e-04,  3.8197e-05, -2.0003e-05, -9.4771e-05,\n",
      "        -4.8759e-04, -8.9543e-05, -6.9913e-04, -9.4431e-04, -3.8921e-04,\n",
      "        -4.3336e-04, -9.2324e-04, -9.9471e-04, -3.6226e-04, -9.9268e-04,\n",
      "        -1.0493e-03, -4.0435e-04, -1.4981e-03, -1.5274e-03, -5.1685e-04,\n",
      "        -3.5619e-04, -3.8962e-04, -2.1374e-04, -5.7413e-04, -4.0537e-04,\n",
      "        -2.9300e-04, -4.0107e-04, -5.2311e-04, -5.6488e-04, -1.5785e-03,\n",
      "        -1.4048e-03, -4.3972e-04, -4.6854e-04, -4.5545e-04, -5.8250e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -115500, loss is -1.5357998368873747e-05\n",
      "Action prob: [9.9905533e-01 9.4472215e-04], Action: 0, state: 0\n",
      "Action prob: [9.9944717e-01 5.5280444e-04], Action: 0, state: 0\n",
      "Action prob: [0.99895006 0.00104991], Action: 0, state: 1\n",
      "Action prob: [9.9917346e-01 8.2648115e-04], Action: 0, state: 1\n",
      "Action prob: [9.990527e-01 9.473054e-04], Action: 0, state: 1\n",
      "Action prob: [9.9920577e-01 7.9420768e-04], Action: 0, state: 2\n",
      "Action prob: [0.9989786  0.00102139], Action: 0, state: 3\n",
      "Action prob: [0.9981681  0.00183187], Action: 0, state: 8\n",
      "Action prob: [9.9952149e-01 4.7852553e-04], Action: 0, state: 8\n",
      "Action prob: [9.9942577e-01 5.7424931e-04], Action: 0, state: 8\n",
      "Action prob: [9.9952424e-01 4.7575613e-04], Action: 0, state: 8\n",
      "Action prob: [0.9982667 0.0017333], Action: 0, state: 8\n",
      "Action prob: [9.9954385e-01 4.5610106e-04], Action: 0, state: 8\n",
      "Action prob: [9.990709e-01 9.291211e-04], Action: 0, state: 8\n",
      "Action prob: [9.991391e-01 8.609540e-04], Action: 0, state: 8\n",
      "Action prob: [9.9953282e-01 4.6721983e-04], Action: 0, state: 8\n",
      "Action prob: [0.99812526 0.0018747 ], Action: 0, state: 8\n",
      "Action prob: [9.994241e-01 5.758697e-04], Action: 0, state: 8\n",
      "Action prob: [0.9979     0.00210003], Action: 0, state: 8\n",
      "Action prob: [9.9912816e-01 8.7183528e-04], Action: 0, state: 8\n",
      "Action prob: [9.992661e-01 7.338514e-04], Action: 0, state: 8\n",
      "Action prob: [0.9986665  0.00133344], Action: 0, state: 8\n",
      "Action prob: [9.992797e-01 7.203738e-04], Action: 0, state: 8\n",
      "Action prob: [0.99806756 0.0019325 ], Action: 0, state: 8\n",
      "Action prob: [9.9949324e-01 5.0678692e-04], Action: 0, state: 8\n",
      "Action prob: [9.991960e-01 8.040338e-04], Action: 0, state: 8\n",
      "Action prob: [0.9980653  0.00193467], Action: 0, state: 8\n",
      "Action prob: [0.9981085  0.00189149], Action: 0, state: 8\n",
      "Action prob: [0.9977818  0.00221821], Action: 0, state: 8\n",
      "Action prob: [9.9927956e-01 7.2050019e-04], Action: 0, state: 8\n",
      "Action prob: [9.9939084e-01 6.0920283e-04], Action: 0, state: 8\n",
      "Action prob: [9.9929011e-01 7.0988614e-04], Action: 0, state: 8\n",
      "Action prob: [9.9916744e-01 8.3256920e-04], Action: 0, state: 8\n",
      "Action prob: [9.994087e-01 5.912799e-04], Action: 0, state: 8\n",
      "Action prob: [9.9917275e-01 8.2721474e-04], Action: 0, state: 8\n",
      "Action prob: [9.9946445e-01 5.3551706e-04], Action: 0, state: 8\n",
      "Action prob: [9.9918407e-01 8.1596803e-04], Action: 0, state: 8\n",
      "Action prob: [0.9980242  0.00197582], Action: 0, state: 8\n",
      "Action prob: [0.9980836  0.00191641], Action: 0, state: 8\n",
      "Action prob: [0.9978531  0.00214688], Action: 0, state: 8\n",
      "Action prob: [9.9946946e-01 5.3056993e-04], Action: 0, state: 8\n",
      "Action prob: [9.9953115e-01 4.6886140e-04], Action: 0, state: 8\n",
      "Action prob: [9.994967e-01 5.032691e-04], Action: 0, state: 8\n",
      "Action prob: [9.993585e-01 6.415065e-04], Action: 0, state: 8\n",
      "Action prob: [9.9956208e-01 4.3791594e-04], Action: 0, state: 8\n",
      "Action prob: [0.99802846 0.00197148], Action: 0, state: 8\n",
      "Action prob: [9.991731e-01 8.268238e-04], Action: 0, state: 8\n",
      "Action prob: [9.992225e-01 7.774582e-04], Action: 0, state: 8\n",
      "Action prob: [0.99832255 0.00167738], Action: 0, state: 8\n",
      "Action prob: [0.99835396 0.00164613], Action: 0, state: 8\n",
      "tensor([ 9.0083e-04,  7.6368e-04,  1.7946e-03,  1.6426e-03,  2.1069e-03,\n",
      "         1.9083e-03,  2.5513e-03,  3.6901e-03,  7.6629e-04,  7.1872e-04,\n",
      "         4.5397e-04,  1.2165e-03,  2.2195e-04,  2.8247e-04,  1.2806e-04,\n",
      "         7.8369e-06, -1.7894e-04, -1.0983e-04, -5.7112e-04, -2.9702e-04,\n",
      "        -2.9299e-04, -5.9889e-04, -3.5388e-04, -1.0195e-03, -2.8264e-04,\n",
      "        -4.6939e-04, -1.1729e-03, -1.1822e-03, -1.4220e-03, -4.7128e-04,\n",
      "        -4.0548e-04, -4.7952e-04, -5.6934e-04, -4.0848e-04, -5.7655e-04,\n",
      "        -3.7593e-04, -5.7637e-04, -1.4038e-03, -1.3676e-03, -1.5380e-03,\n",
      "        -3.8097e-04, -3.3756e-04, -3.6320e-04, -4.6387e-04, -3.1713e-04,\n",
      "        -1.4309e-03, -6.0049e-04, -5.6515e-04, -1.2209e-03, -1.1989e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -127000, loss is 7.69733197436643e-05\n",
      "Action prob: [9.9910235e-01 8.9765148e-04], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [9.990797e-01 9.203150e-04], Action: 0, state: 1\n",
      "Action prob: [9.990651e-01 9.349150e-04], Action: 0, state: 1\n",
      "Action prob: [9.991578e-01 8.422675e-04], Action: 0, state: 1\n",
      "Action prob: [9.9904805e-01 9.5192780e-04], Action: 0, state: 1\n",
      "Action prob: [9.9908900e-01 9.1098214e-04], Action: 0, state: 2\n",
      "Action prob: [9.990221e-01 9.779000e-04], Action: 0, state: 3\n",
      "Action prob: [9.9904567e-01 9.5433067e-04], Action: 0, state: 3\n",
      "Action prob: [0.9976131  0.00238692], Action: 0, state: 8\n",
      "Action prob: [9.995030e-01 4.969787e-04], Action: 0, state: 8\n",
      "Action prob: [0.99873215 0.00126791], Action: 0, state: 8\n",
      "Action prob: [9.993376e-01 6.623416e-04], Action: 0, state: 8\n",
      "Action prob: [9.9918157e-01 8.1840839e-04], Action: 0, state: 8\n",
      "Action prob: [9.9926597e-01 7.3408411e-04], Action: 0, state: 8\n",
      "Action prob: [0.9963546  0.00364541], Action: 0, state: 8\n",
      "Action prob: [0.9984682  0.00153173], Action: 0, state: 8\n",
      "Action prob: [9.9926275e-01 7.3724549e-04], Action: 0, state: 8\n",
      "Action prob: [0.9987797  0.00122026], Action: 0, state: 8\n",
      "Action prob: [0.9979678  0.00203225], Action: 0, state: 8\n",
      "Action prob: [0.99828374 0.00171629], Action: 0, state: 8\n",
      "Action prob: [9.9948549e-01 5.1446795e-04], Action: 0, state: 8\n",
      "Action prob: [0.9980532  0.00194678], Action: 0, state: 8\n",
      "Action prob: [9.9980944e-01 1.9057335e-04], Action: 0, state: 8\n",
      "Action prob: [0.9984707  0.00152925], Action: 0, state: 8\n",
      "Action prob: [9.9916470e-01 8.3536765e-04], Action: 0, state: 8\n",
      "Action prob: [0.99778336 0.00221665], Action: 0, state: 8\n",
      "Action prob: [0.9982023  0.00179771], Action: 0, state: 8\n",
      "Action prob: [0.998028 0.001972], Action: 0, state: 8\n",
      "Action prob: [0.9988626  0.00113742], Action: 0, state: 8\n",
      "Action prob: [0.99820626 0.00179369], Action: 0, state: 8\n",
      "Action prob: [9.9943310e-01 5.6687486e-04], Action: 0, state: 8\n",
      "Action prob: [0.99804854 0.00195142], Action: 0, state: 8\n",
      "Action prob: [9.992575e-01 7.425390e-04], Action: 0, state: 8\n",
      "Action prob: [9.993186e-01 6.813847e-04], Action: 0, state: 8\n",
      "Action prob: [0.9975591  0.00244093], Action: 0, state: 8\n",
      "Action prob: [0.99760735 0.00239263], Action: 0, state: 8\n",
      "Action prob: [0.99769634 0.00230364], Action: 0, state: 8\n",
      "Action prob: [9.994623e-01 5.376537e-04], Action: 0, state: 8\n",
      "Action prob: [0.9978999  0.00210015], Action: 0, state: 8\n",
      "Action prob: [0.9976909  0.00230914], Action: 0, state: 8\n",
      "Action prob: [0.99797887 0.0020212 ], Action: 0, state: 8\n",
      "Action prob: [9.9953055e-01 4.6951463e-04], Action: 0, state: 8\n",
      "Action prob: [9.993211e-01 6.789057e-04], Action: 0, state: 8\n",
      "Action prob: [0.99822015 0.00177987], Action: 0, state: 8\n",
      "Action prob: [9.9961758e-01 3.8240963e-04], Action: 0, state: 8\n",
      "Action prob: [9.9920267e-01 7.9729117e-04], Action: 0, state: 8\n",
      "Action prob: [9.994579e-01 5.421426e-04], Action: 0, state: 8\n",
      "Action prob: [9.9920064e-01 7.9936540e-04], Action: 0, state: 8\n",
      "Action prob: [9.9917573e-01 8.2427514e-04], Action: 0, state: 8\n",
      "Action prob: [9.9967551e-01 3.2454816e-04], Action: 0, state: 8\n",
      "tensor([ 5.3097e-04,  9.5593e-04,  1.3265e-03,  1.4670e-03,  1.9197e-03,\n",
      "         2.0261e-03,  2.2827e-03,  2.3172e-03,  4.6583e-03,  7.6716e-04,\n",
      "         1.5200e-03,  5.9953e-04,  5.3667e-04,  3.2568e-04,  9.6189e-04,\n",
      "         1.6902e-04, -1.4675e-05, -1.5938e-04, -4.5683e-04, -5.2305e-04,\n",
      "        -1.9167e-04, -8.3831e-04, -9.1338e-05, -7.9737e-04, -4.6501e-04,\n",
      "        -1.3018e-03, -1.1016e-03, -1.2515e-03, -7.4260e-04, -1.1998e-03,\n",
      "        -3.8654e-04, -1.3537e-03, -5.2193e-04, -4.8457e-04, -1.7544e-03,\n",
      "        -1.7339e-03, -1.6810e-03, -3.9431e-04, -1.5490e-03, -1.7104e-03,\n",
      "        -1.5023e-03, -3.4971e-04, -5.0708e-04, -1.3330e-03, -2.8674e-04,\n",
      "        -5.9889e-04, -4.0767e-04, -6.0189e-04, -6.2125e-04, -2.4470e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -123600, loss is 9.587044628670588e-05\n",
      "Action prob: [9.9902856e-01 9.7141875e-04], Action: 0, state: 0\n",
      "Action prob: [9.9900264e-01 9.9742843e-04], Action: 0, state: 0\n",
      "Action prob: [0.99890566 0.00109431], Action: 0, state: 0\n",
      "Action prob: [9.9906141e-01 9.3859347e-04], Action: 0, state: 0\n",
      "Action prob: [0.99900013 0.00099984], Action: 0, state: 1\n",
      "Action prob: [0.9989868 0.0010132], Action: 0, state: 1\n",
      "Action prob: [0.9989359  0.00106408], Action: 0, state: 1\n",
      "Action prob: [0.99880815 0.00119191], Action: 0, state: 1\n",
      "Action prob: [9.9909925e-01 9.0079429e-04], Action: 0, state: 1\n",
      "Action prob: [9.9912757e-01 8.7244943e-04], Action: 0, state: 1\n",
      "Action prob: [9.990086e-01 9.914346e-04], Action: 0, state: 2\n",
      "Action prob: [0.99896204 0.00103799], Action: 0, state: 2\n",
      "Action prob: [0.9989197  0.00108031], Action: 0, state: 3\n",
      "Action prob: [9.9927837e-01 7.2162464e-04], Action: 0, state: 8\n",
      "Action prob: [9.992774e-01 7.225464e-04], Action: 0, state: 8\n",
      "Action prob: [9.992174e-01 7.826505e-04], Action: 0, state: 8\n",
      "Action prob: [9.995709e-01 4.291336e-04], Action: 0, state: 8\n",
      "Action prob: [9.9921632e-01 7.8368967e-04], Action: 0, state: 8\n",
      "Action prob: [9.9932384e-01 6.7616173e-04], Action: 0, state: 8\n",
      "Action prob: [0.9978902  0.00210978], Action: 0, state: 8\n",
      "Action prob: [9.9932075e-01 6.7921309e-04], Action: 0, state: 8\n",
      "Action prob: [9.9917322e-01 8.2676794e-04], Action: 0, state: 8\n",
      "Action prob: [9.9948263e-01 5.1738339e-04], Action: 0, state: 8\n",
      "Action prob: [9.994417e-01 5.583543e-04], Action: 0, state: 8\n",
      "Action prob: [0.9979988  0.00200118], Action: 0, state: 8\n",
      "Action prob: [9.992423e-01 7.577673e-04], Action: 0, state: 8\n",
      "Action prob: [9.9908078e-01 9.1921684e-04], Action: 0, state: 8\n",
      "Action prob: [9.990809e-01 9.190500e-04], Action: 0, state: 8\n",
      "Action prob: [0.9979962  0.00200376], Action: 0, state: 8\n",
      "Action prob: [0.9976876  0.00231245], Action: 0, state: 8\n",
      "Action prob: [9.993880e-01 6.119489e-04], Action: 0, state: 8\n",
      "Action prob: [0.9979     0.00209999], Action: 0, state: 8\n",
      "Action prob: [0.9980475  0.00195256], Action: 0, state: 8\n",
      "Action prob: [9.9951029e-01 4.8968435e-04], Action: 0, state: 8\n",
      "Action prob: [0.99762964 0.00237027], Action: 0, state: 8\n",
      "Action prob: [9.9905711e-01 9.4288227e-04], Action: 0, state: 8\n",
      "Action prob: [0.99798065 0.00201935], Action: 0, state: 8\n",
      "Action prob: [0.99823654 0.00176341], Action: 0, state: 8\n",
      "Action prob: [0.9978466  0.00215346], Action: 0, state: 8\n",
      "Action prob: [0.9985083  0.00149172], Action: 0, state: 8\n",
      "Action prob: [9.991510e-01 8.490531e-04], Action: 0, state: 8\n",
      "Action prob: [0.9982456  0.00175446], Action: 0, state: 8\n",
      "Action prob: [0.99849117 0.00150876], Action: 0, state: 8\n",
      "Action prob: [9.993783e-01 6.217053e-04], Action: 0, state: 8\n",
      "Action prob: [9.9925429e-01 7.4569706e-04], Action: 0, state: 8\n",
      "Action prob: [9.9947244e-01 5.2763533e-04], Action: 0, state: 8\n",
      "Action prob: [9.9974209e-01 2.5790976e-04], Action: 0, state: 8\n",
      "Action prob: [0.99784017 0.00215983], Action: 0, state: 8\n",
      "Action prob: [9.9945873e-01 5.4121972e-04], Action: 0, state: 8\n",
      "Action prob: [0.99837095 0.00162912], Action: 0, state: 8\n",
      "tensor([-2.8846e-03, -1.9888e-03, -1.2750e-03, -4.3199e-04,  7.8837e-05,\n",
      "         5.4420e-04,  9.8605e-04,  1.4991e-03,  1.3863e-03,  1.5514e-03,\n",
      "         1.9422e-03,  2.1929e-03,  2.3705e-03,  1.2829e-03,  1.0290e-03,\n",
      "         8.7920e-04,  3.7232e-04,  5.0985e-04,  3.1502e-04,  6.5229e-04,\n",
      "         1.1923e-04,  5.1376e-05, -1.7720e-05, -6.4863e-05, -3.7212e-04,\n",
      "        -1.8566e-04, -2.7151e-04, -3.1079e-04, -7.5083e-04, -9.3812e-04,\n",
      "        -2.6415e-04, -9.5396e-04, -9.2399e-04, -2.3947e-04, -1.1927e-03,\n",
      "        -4.8510e-04, -1.0595e-03, -9.3999e-04, -1.1635e-03, -8.1479e-04,\n",
      "        -4.6798e-04, -9.7519e-04, -8.4422e-04, -3.4966e-04, -4.2146e-04,\n",
      "        -2.9935e-04, -1.4682e-04, -1.2343e-03, -3.0984e-04, -9.3499e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -103500, loss is 0.0001150068092054096\n",
      "Action prob: [9.9900514e-01 9.9488301e-04], Action: 0, state: 0\n",
      "Action prob: [9.990048e-01 9.952523e-04], Action: 0, state: 0\n",
      "Action prob: [9.9902678e-01 9.7326277e-04], Action: 0, state: 0\n",
      "Action prob: [9.991122e-01 8.877901e-04], Action: 0, state: 1\n",
      "Action prob: [0.99891996 0.00108009], Action: 0, state: 2\n",
      "Action prob: [0.9988644  0.00113565], Action: 0, state: 2\n",
      "Action prob: [9.9906534e-01 9.3473465e-04], Action: 0, state: 2\n",
      "Action prob: [9.992126e-01 7.873564e-04], Action: 0, state: 2\n",
      "Action prob: [0.9978783  0.00212176], Action: 0, state: 9\n",
      "Action prob: [9.9941874e-01 5.8127946e-04], Action: 0, state: 9\n",
      "Action prob: [0.9984819 0.0015181], Action: 0, state: 9\n",
      "Action prob: [0.998042   0.00195795], Action: 0, state: 9\n",
      "Action prob: [9.9917126e-01 8.2874298e-04], Action: 0, state: 9\n",
      "Action prob: [9.994267e-01 5.732663e-04], Action: 0, state: 9\n",
      "Action prob: [9.9958104e-01 4.1900694e-04], Action: 0, state: 9\n",
      "Action prob: [9.9956185e-01 4.3818570e-04], Action: 0, state: 9\n",
      "Action prob: [0.99770606 0.00229389], Action: 0, state: 9\n",
      "Action prob: [9.9951077e-01 4.8928178e-04], Action: 0, state: 9\n",
      "Action prob: [9.9918705e-01 8.1296259e-04], Action: 0, state: 9\n",
      "Action prob: [9.993068e-01 6.931669e-04], Action: 0, state: 9\n",
      "Action prob: [0.9975569  0.00244303], Action: 0, state: 9\n",
      "Action prob: [0.99766976 0.00233018], Action: 0, state: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [9.993932e-01 6.067962e-04], Action: 0, state: 9\n",
      "Action prob: [9.9968874e-01 3.1124367e-04], Action: 0, state: 9\n",
      "Action prob: [0.9987936  0.00120639], Action: 0, state: 9\n",
      "Action prob: [9.9952078e-01 4.7919742e-04], Action: 0, state: 9\n",
      "Action prob: [9.9923480e-01 7.6522306e-04], Action: 0, state: 9\n",
      "Action prob: [0.99794835 0.00205167], Action: 0, state: 9\n",
      "Action prob: [9.994993e-01 5.006407e-04], Action: 0, state: 9\n",
      "Action prob: [0.99760985 0.00239014], Action: 0, state: 9\n",
      "Action prob: [9.9941814e-01 5.8186089e-04], Action: 0, state: 9\n",
      "Action prob: [9.9933416e-01 6.6585396e-04], Action: 0, state: 9\n",
      "Action prob: [9.9933368e-01 6.6630595e-04], Action: 0, state: 9\n",
      "Action prob: [0.9983777  0.00162233], Action: 0, state: 9\n",
      "Action prob: [9.9947745e-01 5.2254723e-04], Action: 0, state: 9\n",
      "Action prob: [9.994998e-01 5.002448e-04], Action: 0, state: 9\n",
      "Action prob: [9.9908674e-01 9.1324735e-04], Action: 0, state: 9\n",
      "Action prob: [9.991554e-01 8.445812e-04], Action: 0, state: 9\n",
      "Action prob: [9.9957877e-01 4.2123263e-04], Action: 0, state: 9\n",
      "Action prob: [0.998251   0.00174898], Action: 0, state: 9\n",
      "Action prob: [0.99810946 0.0018905 ], Action: 0, state: 9\n",
      "Action prob: [0.99782866 0.00217132], Action: 0, state: 9\n",
      "Action prob: [9.9939144e-01 6.0858991e-04], Action: 0, state: 9\n",
      "Action prob: [9.992036e-01 7.963929e-04], Action: 0, state: 9\n",
      "Action prob: [0.9980173  0.00198268], Action: 0, state: 9\n",
      "Action prob: [0.99850684 0.00149308], Action: 0, state: 9\n",
      "Action prob: [9.9943632e-01 5.6365173e-04], Action: 0, state: 9\n",
      "Action prob: [9.9921703e-01 7.8291522e-04], Action: 0, state: 9\n",
      "Action prob: [9.991203e-01 8.797446e-04], Action: 0, state: 9\n",
      "Action prob: [0.997692   0.00230802], Action: 0, state: 9\n",
      "tensor([-3.3230e-03, -1.8492e-03, -5.8222e-04,  3.2448e-04,  1.1812e-03,\n",
      "         1.9449e-03,  2.0924e-03,  2.1146e-03,  4.6932e-03,  1.0501e-03,\n",
      "         2.2224e-03,  2.2955e-03,  7.6552e-04,  4.0865e-04,  2.2357e-04,\n",
      "         1.6709e-04,  5.7844e-04,  6.9427e-05,  3.9347e-05, -2.1559e-05,\n",
      "        -2.4128e-04, -3.6408e-04, -1.2434e-04, -7.6689e-05, -3.3994e-04,\n",
      "        -1.4935e-04, -2.5802e-04, -7.3671e-04, -1.8886e-04, -9.3989e-04,\n",
      "        -2.3634e-04, -2.7799e-04, -2.8460e-04, -7.0651e-04, -2.3107e-04,\n",
      "        -2.2414e-04, -4.1390e-04, -3.8637e-04, -1.9418e-04, -8.1218e-04,\n",
      "        -8.8294e-04, -1.0191e-03, -2.8654e-04, -3.7629e-04, -9.4009e-04,\n",
      "        -7.0954e-04, -2.6829e-04, -3.7336e-04, -4.2014e-04, -1.1045e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -36900, loss is -1.655558410232786e-05\n",
      "Action prob: [0.9988343  0.00116565], Action: 0, state: 0\n",
      "Action prob: [9.990025e-01 9.975330e-04], Action: 0, state: 1\n",
      "Action prob: [0.9988159  0.00118415], Action: 0, state: 1\n",
      "Action prob: [0.9989222 0.0010778], Action: 0, state: 1\n",
      "Action prob: [9.991192e-01 8.807850e-04], Action: 0, state: 2\n",
      "Action prob: [0.99869883 0.00130113], Action: 0, state: 3\n",
      "Action prob: [0.99897146 0.00102851], Action: 0, state: 3\n",
      "Action prob: [0.9988997  0.00110028], Action: 0, state: 3\n",
      "Action prob: [9.9967766e-01 3.2240947e-04], Action: 0, state: 8\n",
      "Action prob: [9.9942327e-01 5.7679100e-04], Action: 0, state: 8\n",
      "Action prob: [9.9907935e-01 9.2060782e-04], Action: 0, state: 8\n",
      "Action prob: [9.994960e-01 5.039861e-04], Action: 0, state: 8\n",
      "Action prob: [0.99856746 0.00143249], Action: 0, state: 8\n",
      "Action prob: [9.9907267e-01 9.2730275e-04], Action: 0, state: 8\n",
      "Action prob: [9.9959105e-01 4.0890524e-04], Action: 0, state: 8\n",
      "Action prob: [0.99883264 0.00116742], Action: 0, state: 8\n",
      "Action prob: [0.99787176 0.00212828], Action: 0, state: 8\n",
      "Action prob: [9.9919075e-01 8.0924988e-04], Action: 0, state: 8\n",
      "Action prob: [9.9946433e-01 5.3562474e-04], Action: 0, state: 8\n",
      "Action prob: [0.99798584 0.00201409], Action: 0, state: 8\n",
      "Action prob: [0.9979044  0.00209557], Action: 0, state: 8\n",
      "Action prob: [9.9934572e-01 6.5422314e-04], Action: 0, state: 8\n",
      "Action prob: [9.9921942e-01 7.8057725e-04], Action: 0, state: 8\n",
      "Action prob: [0.9982004  0.00179953], Action: 0, state: 8\n",
      "Action prob: [0.9976705  0.00232956], Action: 0, state: 8\n",
      "Action prob: [0.99805367 0.00194635], Action: 0, state: 8\n",
      "Action prob: [0.99803656 0.0019634 ], Action: 0, state: 8\n",
      "Action prob: [9.992518e-01 7.482244e-04], Action: 0, state: 8\n",
      "Action prob: [9.9946004e-01 5.3993159e-04], Action: 0, state: 8\n",
      "Action prob: [9.9925476e-01 7.4526086e-04], Action: 0, state: 8\n",
      "Action prob: [9.9931943e-01 6.8057934e-04], Action: 0, state: 8\n",
      "Action prob: [9.9946266e-01 5.3732167e-04], Action: 0, state: 8\n",
      "Action prob: [0.9980825  0.00191752], Action: 0, state: 8\n",
      "Action prob: [0.9980287  0.00197134], Action: 0, state: 8\n",
      "Action prob: [9.992612e-01 7.388217e-04], Action: 0, state: 8\n",
      "Action prob: [0.9982003  0.00179965], Action: 0, state: 8\n",
      "Action prob: [9.991091e-01 8.908418e-04], Action: 0, state: 8\n",
      "Action prob: [9.9942064e-01 5.7932560e-04], Action: 0, state: 8\n",
      "Action prob: [0.9980223  0.00197771], Action: 0, state: 8\n",
      "Action prob: [9.9913919e-01 8.6074474e-04], Action: 0, state: 8\n",
      "Action prob: [0.9982712  0.00172872], Action: 0, state: 8\n",
      "Action prob: [0.99803466 0.00196539], Action: 0, state: 8\n",
      "Action prob: [9.9928975e-01 7.1023335e-04], Action: 0, state: 8\n",
      "Action prob: [0.9986523 0.0013477], Action: 0, state: 8\n",
      "Action prob: [9.9946207e-01 5.3798949e-04], Action: 0, state: 8\n",
      "Action prob: [0.9977245  0.00227555], Action: 0, state: 8\n",
      "Action prob: [9.994791e-01 5.209452e-04], Action: 0, state: 8\n",
      "Action prob: [0.99833494 0.00166502], Action: 0, state: 8\n",
      "Action prob: [0.9979638  0.00203623], Action: 0, state: 8\n",
      "Action prob: [9.9914885e-01 8.5117092e-04], Action: 0, state: 8\n",
      "tensor([ 7.9298e-04,  1.1185e-03,  1.7719e-03,  1.9561e-03,  1.8105e-03,\n",
      "         2.8417e-03,  2.3578e-03,  2.6241e-03,  6.1657e-04,  8.7229e-04,\n",
      "         1.0792e-03,  4.4482e-04,  9.1233e-04,  3.9650e-04,  1.0213e-04,\n",
      "         1.1525e-04, -6.3282e-05, -1.1239e-04, -1.2408e-04, -6.2584e-04,\n",
      "        -7.9174e-04, -2.8430e-04, -3.7701e-04, -9.4373e-04, -1.3036e-03,\n",
      "        -1.1468e-03, -1.2066e-03, -4.7561e-04, -3.5305e-04, -4.9890e-04,\n",
      "        -4.6457e-04, -3.7280e-04, -1.3495e-03, -1.4034e-03, -5.3075e-04,\n",
      "        -1.3041e-03, -6.4972e-04, -4.2490e-04, -1.4586e-03, -6.3713e-04,\n",
      "        -1.2846e-03, -1.4649e-03, -5.3040e-04, -1.0089e-03, -4.0327e-04,\n",
      "        -1.7100e-03, -3.9160e-04, -1.2539e-03, -1.5351e-03, -6.4182e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -124000, loss is 0.0001462860689212509\n",
      "Action prob: [0.99888915 0.00111092], Action: 0, state: 0\n",
      "Action prob: [9.9904114e-01 9.5885119e-04], Action: 0, state: 0\n",
      "Action prob: [9.9914277e-01 8.5716968e-04], Action: 0, state: 0\n",
      "Action prob: [9.994054e-01 5.945757e-04], Action: 0, state: 0\n",
      "Action prob: [9.991172e-01 8.828166e-04], Action: 0, state: 0\n",
      "Action prob: [0.9984018  0.00159818], Action: 0, state: 0\n",
      "Action prob: [0.99894696 0.00105305], Action: 0, state: 0\n",
      "Action prob: [0.9988238  0.00117614], Action: 0, state: 1\n",
      "Action prob: [9.9904269e-01 9.5730764e-04], Action: 0, state: 1\n",
      "Action prob: [0.9988803  0.00111962], Action: 0, state: 2\n",
      "Action prob: [0.99876046 0.00123955], Action: 0, state: 2\n",
      "Action prob: [0.9989353  0.00106469], Action: 0, state: 2\n",
      "Action prob: [9.991019e-01 8.981178e-04], Action: 0, state: 2\n",
      "Action prob: [9.990194e-01 9.806309e-04], Action: 0, state: 2\n",
      "Action prob: [0.998919   0.00108106], Action: 0, state: 2\n",
      "Action prob: [9.990434e-01 9.566001e-04], Action: 0, state: 3\n",
      "Action prob: [9.9954385e-01 4.5614803e-04], Action: 0, state: 8\n",
      "Action prob: [9.9960881e-01 3.9124562e-04], Action: 0, state: 8\n",
      "Action prob: [0.99763227 0.00236777], Action: 0, state: 8\n",
      "Action prob: [0.9973304 0.0026696], Action: 0, state: 8\n",
      "Action prob: [0.99896646 0.00103359], Action: 0, state: 8\n",
      "Action prob: [0.9988288  0.00117121], Action: 0, state: 8\n",
      "Action prob: [9.9918288e-01 8.1708835e-04], Action: 0, state: 8\n",
      "Action prob: [0.99887174 0.00112829], Action: 0, state: 8\n",
      "Action prob: [0.9976872  0.00231277], Action: 0, state: 8\n",
      "Action prob: [9.993481e-01 6.519359e-04], Action: 0, state: 8\n",
      "Action prob: [0.9987393  0.00126074], Action: 0, state: 8\n",
      "Action prob: [9.9915504e-01 8.4495306e-04], Action: 0, state: 8\n",
      "Action prob: [9.9949157e-01 5.0843414e-04], Action: 0, state: 8\n",
      "Action prob: [9.9953687e-01 4.6313682e-04], Action: 0, state: 8\n",
      "Action prob: [0.99895763 0.00104231], Action: 0, state: 8\n",
      "Action prob: [9.9932420e-01 6.7585387e-04], Action: 0, state: 8\n",
      "Action prob: [9.9902177e-01 9.7818032e-04], Action: 0, state: 8\n",
      "Action prob: [9.9922311e-01 7.7686686e-04], Action: 0, state: 8\n",
      "Action prob: [9.9934894e-01 6.5104791e-04], Action: 0, state: 8\n",
      "Action prob: [9.994978e-01 5.022479e-04], Action: 0, state: 8\n",
      "Action prob: [0.9980862  0.00191382], Action: 0, state: 8\n",
      "Action prob: [9.990945e-01 9.055462e-04], Action: 0, state: 8\n",
      "Action prob: [0.99787354 0.00212651], Action: 0, state: 8\n",
      "Action prob: [0.99883    0.00116999], Action: 0, state: 8\n",
      "Action prob: [9.9906212e-01 9.3786756e-04], Action: 0, state: 8\n",
      "Action prob: [9.9935514e-01 6.4487377e-04], Action: 0, state: 8\n",
      "Action prob: [9.9929070e-01 7.0928736e-04], Action: 0, state: 8\n",
      "Action prob: [9.993691e-01 6.309069e-04], Action: 0, state: 8\n",
      "Action prob: [9.9959487e-01 4.0519857e-04], Action: 0, state: 8\n",
      "Action prob: [9.9934536e-01 6.5461238e-04], Action: 0, state: 8\n",
      "Action prob: [0.9977476  0.00225234], Action: 0, state: 8\n",
      "Action prob: [0.9980373  0.00196275], Action: 0, state: 8\n",
      "Action prob: [0.9982687  0.00173129], Action: 0, state: 8\n",
      "Action prob: [9.9935454e-01 6.4551819e-04], Action: 0, state: 8\n",
      "tensor([-4.4735e-03, -2.9386e-03, -1.9260e-03, -9.2250e-04, -8.4819e-04,\n",
      "        -7.3315e-04, -3.3377e-05,  3.4687e-04,  5.4804e-04,  8.7589e-04,\n",
      "         1.1907e-03,  1.1841e-03,  1.1144e-03,  1.3241e-03,  1.5604e-03,\n",
      "         1.4280e-03,  5.6580e-04,  4.0138e-04,  2.0002e-03,  1.8418e-03,\n",
      "         5.7646e-04,  5.2222e-04,  2.8659e-04,  3.0457e-04,  4.6570e-04,\n",
      "         9.3092e-05,  1.1749e-04,  4.3083e-05,  7.6889e-06, -7.1111e-06,\n",
      "        -4.3021e-05, -4.2769e-05, -8.0233e-05, -7.6074e-05, -7.2554e-05,\n",
      "        -6.1737e-05, -2.5413e-04, -1.2770e-04, -3.1510e-04, -1.8031e-04,\n",
      "        -1.4931e-04, -1.0544e-04, -1.1859e-04, -1.0746e-04, -7.0075e-05,\n",
      "        -1.1473e-04, -3.9939e-04, -3.5119e-04, -3.1215e-04, -1.1707e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -91900, loss is -3.634508844144231e-05\n",
      "Action prob: [9.9902511e-01 9.7494776e-04], Action: 0, state: 0\n",
      "Action prob: [9.994622e-01 5.377713e-04], Action: 0, state: 0\n",
      "Action prob: [9.9906915e-01 9.3089242e-04], Action: 0, state: 1\n",
      "Action prob: [0.99894303 0.00105694], Action: 0, state: 1\n",
      "Action prob: [9.9905974e-01 9.4026676e-04], Action: 0, state: 2\n",
      "Action prob: [0.998793   0.00120702], Action: 0, state: 2\n",
      "Action prob: [9.9901474e-01 9.8529551e-04], Action: 0, state: 2\n",
      "Action prob: [9.9902761e-01 9.7235263e-04], Action: 0, state: 2\n",
      "Action prob: [0.9989272  0.00107282], Action: 0, state: 2\n",
      "Action prob: [0.9987551  0.00124486], Action: 0, state: 3\n",
      "Action prob: [9.9929595e-01 7.0402672e-04], Action: 0, state: 3\n",
      "Action prob: [9.9922740e-01 7.7260856e-04], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [9.9938345e-01 6.1657920e-04], Action: 0, state: 8\n",
      "Action prob: [0.9978071  0.00219296], Action: 0, state: 8\n",
      "Action prob: [0.99817765 0.00182237], Action: 0, state: 8\n",
      "Action prob: [0.9989291  0.00107086], Action: 0, state: 8\n",
      "Action prob: [0.99814487 0.00185512], Action: 0, state: 8\n",
      "Action prob: [0.9940386  0.00596148], Action: 0, state: 8\n",
      "Action prob: [0.9975319  0.00246809], Action: 0, state: 8\n",
      "Action prob: [9.9926060e-01 7.3936186e-04], Action: 0, state: 8\n",
      "Action prob: [9.9943644e-01 5.6353217e-04], Action: 0, state: 8\n",
      "Action prob: [0.99818075 0.00181931], Action: 0, state: 8\n",
      "Action prob: [0.99773645 0.00226354], Action: 0, state: 8\n",
      "Action prob: [9.991861e-01 8.139420e-04], Action: 0, state: 8\n",
      "Action prob: [0.9980977  0.00190229], Action: 0, state: 8\n",
      "Action prob: [0.9977108  0.00228918], Action: 0, state: 8\n",
      "Action prob: [0.9978871  0.00211291], Action: 0, state: 8\n",
      "Action prob: [9.9929655e-01 7.0346543e-04], Action: 0, state: 8\n",
      "Action prob: [9.9934703e-01 6.5290980e-04], Action: 0, state: 8\n",
      "Action prob: [9.990103e-01 9.896131e-04], Action: 0, state: 8\n",
      "Action prob: [0.9978269  0.00217311], Action: 0, state: 8\n",
      "Action prob: [9.9930775e-01 6.9220318e-04], Action: 0, state: 8\n",
      "Action prob: [9.9915266e-01 8.4733765e-04], Action: 0, state: 8\n",
      "Action prob: [0.99795026 0.00204981], Action: 0, state: 8\n",
      "Action prob: [0.9981061  0.00189381], Action: 0, state: 8\n",
      "Action prob: [0.9976981  0.00230181], Action: 0, state: 8\n",
      "Action prob: [0.99792105 0.00207901], Action: 0, state: 8\n",
      "Action prob: [0.9976273 0.0023727], Action: 0, state: 8\n",
      "Action prob: [0.99618405 0.0038159 ], Action: 0, state: 8\n",
      "Action prob: [9.9926406e-01 7.3594897e-04], Action: 0, state: 8\n",
      "Action prob: [9.992816e-01 7.184706e-04], Action: 0, state: 8\n",
      "Action prob: [9.9947363e-01 5.2636344e-04], Action: 0, state: 8\n",
      "Action prob: [9.9951386e-01 4.8618915e-04], Action: 0, state: 8\n",
      "Action prob: [9.9927729e-01 7.2272134e-04], Action: 0, state: 8\n",
      "Action prob: [9.9916470e-01 8.3535607e-04], Action: 0, state: 8\n",
      "Action prob: [0.99784994 0.0021501 ], Action: 0, state: 8\n",
      "Action prob: [0.99782854 0.00217146], Action: 0, state: 8\n",
      "Action prob: [0.9976197  0.00238027], Action: 0, state: 8\n",
      "Action prob: [9.9925071e-01 7.4931793e-04], Action: 0, state: 8\n",
      "Action prob: [0.99773103 0.00226903], Action: 0, state: 8\n",
      "tensor([-1.1905e-03, -2.2444e-04,  1.8379e-04,  7.6114e-04,  1.0483e-03,\n",
      "         1.7511e-03,  1.7103e-03,  1.9238e-03,  2.3438e-03,  2.8563e-03,\n",
      "         1.6804e-03,  1.4774e-03,  9.3016e-04,  2.5584e-03,  1.5942e-03,\n",
      "         6.7108e-04,  7.7204e-04,  1.4160e-03,  2.0935e-04, -3.2969e-05,\n",
      "        -8.7078e-05, -4.5137e-04, -7.4166e-04, -3.2144e-04, -8.6092e-04,\n",
      "        -1.1480e-03, -1.1472e-03, -4.0645e-04, -3.9683e-04, -6.2676e-04,\n",
      "        -1.4241e-03, -4.6605e-04, -5.8376e-04, -1.4402e-03, -1.3520e-03,\n",
      "        -1.6658e-03, -1.5213e-03, -1.7529e-03, -2.8438e-03, -5.5129e-04,\n",
      "        -5.4122e-04, -3.9841e-04, -3.6945e-04, -5.5119e-04, -6.3896e-04,\n",
      "        -1.6498e-03, -1.6698e-03, -1.8338e-03, -5.7765e-04, -1.7528e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -112200, loss is 0.00014664527216389715\n",
      "Action prob: [0.9989298  0.00107023], Action: 0, state: 0\n",
      "Action prob: [0.998923   0.00107699], Action: 0, state: 1\n",
      "Action prob: [0.9985678  0.00143215], Action: 0, state: 1\n",
      "Action prob: [0.9988996  0.00110043], Action: 0, state: 2\n",
      "Action prob: [9.991385e-01 8.615128e-04], Action: 0, state: 2\n",
      "Action prob: [0.998021   0.00197906], Action: 0, state: 2\n",
      "Action prob: [0.9989795  0.00102044], Action: 0, state: 2\n",
      "Action prob: [9.9935800e-01 6.4204424e-04], Action: 0, state: 2\n",
      "Action prob: [0.99811685 0.00188319], Action: 0, state: 9\n",
      "Action prob: [0.99782014 0.00217984], Action: 0, state: 9\n",
      "Action prob: [0.99760014 0.00239981], Action: 0, state: 9\n",
      "Action prob: [0.99791855 0.0020815 ], Action: 0, state: 9\n",
      "Action prob: [0.9986828  0.00131718], Action: 0, state: 9\n",
      "Action prob: [0.99835473 0.00164523], Action: 0, state: 9\n",
      "Action prob: [0.99792093 0.00207912], Action: 0, state: 9\n",
      "Action prob: [9.9952853e-01 4.7149832e-04], Action: 0, state: 9\n",
      "Action prob: [9.9925691e-01 7.4305607e-04], Action: 0, state: 9\n",
      "Action prob: [9.9948645e-01 5.1349518e-04], Action: 0, state: 9\n",
      "Action prob: [9.9927312e-01 7.2689645e-04], Action: 0, state: 9\n",
      "Action prob: [9.9931657e-01 6.8340986e-04], Action: 0, state: 9\n",
      "Action prob: [9.9937218e-01 6.2786456e-04], Action: 0, state: 9\n",
      "Action prob: [9.9911851e-01 8.8144565e-04], Action: 0, state: 9\n",
      "Action prob: [9.9937904e-01 6.2090199e-04], Action: 0, state: 9\n",
      "Action prob: [9.9943525e-01 5.6468218e-04], Action: 0, state: 9\n",
      "Action prob: [9.9921024e-01 7.8968797e-04], Action: 0, state: 9\n",
      "Action prob: [9.9929035e-01 7.0962100e-04], Action: 0, state: 9\n",
      "Action prob: [0.9981096  0.00189036], Action: 0, state: 9\n",
      "Action prob: [0.9983032  0.00169678], Action: 0, state: 9\n",
      "Action prob: [9.9909306e-01 9.0693246e-04], Action: 0, state: 9\n",
      "Action prob: [9.991478e-01 8.522044e-04], Action: 0, state: 9\n",
      "Action prob: [9.9945801e-01 5.4204365e-04], Action: 0, state: 9\n",
      "Action prob: [0.99892765 0.00107237], Action: 0, state: 9\n",
      "Action prob: [9.9939799e-01 6.0200086e-04], Action: 0, state: 9\n",
      "Action prob: [0.99866176 0.00133825], Action: 0, state: 9\n",
      "Action prob: [9.9931109e-01 6.8888237e-04], Action: 0, state: 9\n",
      "Action prob: [0.9978877  0.00211231], Action: 0, state: 9\n",
      "Action prob: [0.9985096  0.00149038], Action: 0, state: 9\n",
      "Action prob: [9.9969566e-01 3.0433465e-04], Action: 0, state: 9\n",
      "Action prob: [9.9939156e-01 6.0841505e-04], Action: 0, state: 9\n",
      "Action prob: [0.9988433 0.0011567], Action: 0, state: 9\n",
      "Action prob: [0.9979997  0.00200025], Action: 0, state: 9\n",
      "Action prob: [0.99739134 0.00260868], Action: 0, state: 9\n",
      "Action prob: [9.992366e-01 7.633883e-04], Action: 0, state: 9\n",
      "Action prob: [0.9983637  0.00163633], Action: 0, state: 9\n",
      "Action prob: [0.9981352  0.00186479], Action: 0, state: 9\n",
      "Action prob: [0.9979804  0.00201957], Action: 0, state: 9\n",
      "Action prob: [9.994536e-01 5.463634e-04], Action: 0, state: 9\n",
      "Action prob: [0.9978891  0.00211094], Action: 0, state: 9\n",
      "Action prob: [0.99820924 0.00179072], Action: 0, state: 9\n",
      "Action prob: [0.99899393 0.00100612], Action: 0, state: 9\n",
      "tensor([-3.2940e-03, -1.8278e-03, -7.4971e-04,  3.9993e-04,  9.6240e-04,\n",
      "         3.4805e-03,  2.3496e-03,  1.7750e-03,  4.2833e-03,  4.0470e-03,\n",
      "         3.6026e-03,  2.4951e-03,  1.2401e-03,  1.1901e-03,  1.1183e-03,\n",
      "         1.7908e-04,  1.8271e-04,  6.7772e-05,  2.5561e-05, -3.2208e-05,\n",
      "        -7.3499e-05, -1.5563e-04, -1.4100e-04, -1.5249e-04, -2.4210e-04,\n",
      "        -2.3956e-04, -6.8844e-04, -6.5595e-04, -3.6775e-04, -3.5936e-04,\n",
      "        -2.3597e-04, -4.7956e-04, -2.7514e-04, -6.2319e-04, -3.2566e-04,\n",
      "        -1.0122e-03, -7.2167e-04, -1.4862e-04, -2.9945e-04, -5.7313e-04,\n",
      "        -9.9696e-04, -1.3066e-03, -3.8351e-04, -8.2512e-04, -9.4307e-04,\n",
      "        -1.0239e-03, -2.7736e-04, -1.0742e-03, -9.1247e-04, -5.1306e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -37200, loss is -0.00010937723841287273\n",
      "Action prob: [9.9922335e-01 7.7666447e-04], Action: 0, state: 0\n",
      "Action prob: [9.9913377e-01 8.6627278e-04], Action: 0, state: 0\n",
      "Action prob: [0.99898237 0.00101762], Action: 0, state: 0\n",
      "Action prob: [9.991155e-01 8.845103e-04], Action: 0, state: 0\n",
      "Action prob: [0.998889 0.001111], Action: 0, state: 0\n",
      "Action prob: [0.9985331  0.00146686], Action: 0, state: 1\n",
      "Action prob: [9.991117e-01 8.882440e-04], Action: 0, state: 1\n",
      "Action prob: [0.998767   0.00123305], Action: 0, state: 1\n",
      "Action prob: [0.99895453 0.00104544], Action: 0, state: 1\n",
      "Action prob: [0.9987608  0.00123924], Action: 0, state: 2\n",
      "Action prob: [9.9907839e-01 9.2157145e-04], Action: 0, state: 2\n",
      "Action prob: [0.99889165 0.00110832], Action: 0, state: 2\n",
      "Action prob: [0.9988865  0.00111351], Action: 0, state: 3\n",
      "Action prob: [0.9983613  0.00163871], Action: 0, state: 8\n",
      "Action prob: [0.99804974 0.00195032], Action: 0, state: 8\n",
      "Action prob: [9.994886e-01 5.114270e-04], Action: 0, state: 8\n",
      "Action prob: [9.994287e-01 5.713037e-04], Action: 0, state: 8\n",
      "Action prob: [0.99815863 0.00184142], Action: 0, state: 8\n",
      "Action prob: [9.9951577e-01 4.8418075e-04], Action: 0, state: 8\n",
      "Action prob: [0.99873906 0.001261  ], Action: 0, state: 8\n",
      "Action prob: [0.9979716  0.00202844], Action: 0, state: 8\n",
      "Action prob: [9.9935216e-01 6.4780837e-04], Action: 0, state: 8\n",
      "Action prob: [0.9980394  0.00196057], Action: 0, state: 8\n",
      "Action prob: [0.9979849  0.00201514], Action: 0, state: 8\n",
      "Action prob: [0.99856985 0.00143008], Action: 0, state: 8\n",
      "Action prob: [9.9917197e-01 8.2810683e-04], Action: 0, state: 8\n",
      "Action prob: [0.99780387 0.00219609], Action: 0, state: 8\n",
      "Action prob: [9.993418e-01 6.582384e-04], Action: 0, state: 8\n",
      "Action prob: [9.9950373e-01 4.9625611e-04], Action: 0, state: 8\n",
      "Action prob: [9.9950325e-01 4.9670448e-04], Action: 0, state: 8\n",
      "Action prob: [9.9912983e-01 8.7017624e-04], Action: 0, state: 8\n",
      "Action prob: [0.99885035 0.00114962], Action: 0, state: 8\n",
      "Action prob: [9.9905759e-01 9.4246474e-04], Action: 0, state: 8\n",
      "Action prob: [9.9908042e-01 9.1959536e-04], Action: 0, state: 8\n",
      "Action prob: [0.9981646 0.0018354], Action: 0, state: 8\n",
      "Action prob: [9.9927956e-01 7.2047953e-04], Action: 0, state: 8\n",
      "Action prob: [9.9946588e-01 5.3415087e-04], Action: 0, state: 8\n",
      "Action prob: [0.9977551  0.00224495], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [9.9942338e-01 5.7658757e-04], Action: 0, state: 8\n",
      "Action prob: [9.995098e-01 4.902243e-04], Action: 0, state: 8\n",
      "Action prob: [9.9925977e-01 7.4017962e-04], Action: 0, state: 8\n",
      "Action prob: [9.9934512e-01 6.5484014e-04], Action: 0, state: 8\n",
      "Action prob: [0.9981724  0.00182763], Action: 0, state: 8\n",
      "Action prob: [0.9984054  0.00159461], Action: 0, state: 8\n",
      "Action prob: [9.9938977e-01 6.1025313e-04], Action: 0, state: 8\n",
      "Action prob: [9.9953604e-01 4.6397658e-04], Action: 0, state: 8\n",
      "Action prob: [9.9900395e-01 9.9609606e-04], Action: 0, state: 8\n",
      "Action prob: [0.9979802  0.00201987], Action: 0, state: 8\n",
      "Action prob: [9.9942493e-01 5.7511829e-04], Action: 0, state: 8\n",
      "Action prob: [9.9933738e-01 6.6259253e-04], Action: 0, state: 8\n",
      "tensor([-2.3162e-03, -1.7443e-03, -1.2113e-03, -4.3361e-04,  1.1636e-04,\n",
      "         8.2149e-04,  8.4098e-04,  1.5730e-03,  1.6259e-03,  2.1891e-03,\n",
      "         1.7933e-03,  2.3260e-03,  2.4270e-03,  2.8951e-03,  2.7604e-03,\n",
      "         5.7060e-04,  4.9243e-04,  1.1906e-03,  2.2407e-04,  3.8707e-04,\n",
      "         3.5392e-04,  3.9989e-05, -6.6733e-05, -2.3269e-04, -2.6407e-04,\n",
      "        -2.0153e-04, -6.4472e-04, -2.2105e-04, -1.8456e-04, -1.9999e-04,\n",
      "        -3.7310e-04, -5.1850e-04, -4.4275e-04, -4.4676e-04, -9.1711e-04,\n",
      "        -3.6813e-04, -2.7815e-04, -1.1889e-03, -3.0921e-04, -2.6581e-04,\n",
      "        -4.0525e-04, -3.6137e-04, -1.0159e-03, -8.9129e-04, -3.4255e-04,\n",
      "        -2.6148e-04, -5.6344e-04, -1.1465e-03, -3.2698e-04, -3.7757e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -103500, loss is -8.212275651842189e-05\n",
      "Action prob: [0.99895704 0.00104299], Action: 0, state: 0\n",
      "Action prob: [0.9988927 0.0011073], Action: 0, state: 1\n",
      "Action prob: [0.9989697  0.00103034], Action: 0, state: 1\n",
      "Action prob: [9.9904901e-01 9.5099316e-04], Action: 0, state: 1\n",
      "Action prob: [9.991967e-01 8.033469e-04], Action: 0, state: 1\n",
      "Action prob: [9.991208e-01 8.791813e-04], Action: 0, state: 2\n",
      "Action prob: [0.99806553 0.00193449], Action: 0, state: 3\n",
      "Action prob: [0.99788386 0.00211617], Action: 0, state: 8\n",
      "Action prob: [0.9974827 0.0025173], Action: 0, state: 8\n",
      "Action prob: [0.9975062  0.00249383], Action: 0, state: 8\n",
      "Action prob: [0.99769163 0.00230838], Action: 0, state: 8\n",
      "Action prob: [9.9904972e-01 9.5021963e-04], Action: 0, state: 8\n",
      "Action prob: [9.9942601e-01 5.7396665e-04], Action: 0, state: 8\n",
      "Action prob: [9.993923e-01 6.077503e-04], Action: 0, state: 8\n",
      "Action prob: [9.995515e-01 4.484906e-04], Action: 0, state: 8\n",
      "Action prob: [9.993856e-01 6.144055e-04], Action: 0, state: 8\n",
      "Action prob: [9.9947661e-01 5.2344584e-04], Action: 0, state: 8\n",
      "Action prob: [0.9979019  0.00209806], Action: 0, state: 8\n",
      "Action prob: [0.9977575  0.00224257], Action: 0, state: 8\n",
      "Action prob: [9.9936706e-01 6.3297612e-04], Action: 0, state: 8\n",
      "Action prob: [0.99899155 0.00100848], Action: 0, state: 8\n",
      "Action prob: [0.9982109  0.00178912], Action: 0, state: 8\n",
      "Action prob: [0.9983215  0.00167851], Action: 0, state: 8\n",
      "Action prob: [9.992192e-01 7.808194e-04], Action: 0, state: 8\n",
      "Action prob: [9.9934727e-01 6.5276085e-04], Action: 0, state: 8\n",
      "Action prob: [0.99849033 0.00150964], Action: 0, state: 8\n",
      "Action prob: [0.9974942  0.00250582], Action: 0, state: 8\n",
      "Action prob: [0.9989894  0.00101054], Action: 0, state: 8\n",
      "Action prob: [0.99769056 0.00230941], Action: 0, state: 8\n",
      "Action prob: [9.9958593e-01 4.1412286e-04], Action: 0, state: 8\n",
      "Action prob: [9.9910885e-01 8.9115172e-04], Action: 0, state: 8\n",
      "Action prob: [0.9978927  0.00210732], Action: 0, state: 8\n",
      "Action prob: [9.9933004e-01 6.6997693e-04], Action: 0, state: 8\n",
      "Action prob: [0.9977946  0.00220535], Action: 0, state: 8\n",
      "Action prob: [9.9928087e-01 7.1918918e-04], Action: 0, state: 8\n",
      "Action prob: [0.9979691  0.00203085], Action: 0, state: 8\n",
      "Action prob: [9.9933904e-01 6.6097110e-04], Action: 0, state: 8\n",
      "Action prob: [0.99788374 0.00211621], Action: 0, state: 8\n",
      "Action prob: [0.9979254  0.00207462], Action: 0, state: 8\n",
      "Action prob: [0.9978688 0.0021312], Action: 0, state: 8\n",
      "Action prob: [9.995278e-01 4.722441e-04], Action: 0, state: 8\n",
      "Action prob: [9.9922776e-01 7.7221362e-04], Action: 0, state: 8\n",
      "Action prob: [9.990526e-01 9.474055e-04], Action: 0, state: 8\n",
      "Action prob: [9.99395e-01 6.04967e-04], Action: 0, state: 8\n",
      "Action prob: [9.9943763e-01 5.6229217e-04], Action: 0, state: 8\n",
      "Action prob: [0.99823856 0.0017614 ], Action: 0, state: 8\n",
      "Action prob: [0.99789894 0.00210102], Action: 0, state: 8\n",
      "Action prob: [9.9905163e-01 9.4835745e-04], Action: 0, state: 8\n",
      "Action prob: [0.99861777 0.00138226], Action: 0, state: 8\n",
      "Action prob: [0.9982318  0.00176825], Action: 0, state: 8\n",
      "tensor([ 1.0375e-03,  1.5278e-03,  1.7587e-03,  1.8877e-03,  1.7843e-03,\n",
      "         2.1101e-03,  4.8286e-03,  4.2579e-03,  4.0298e-03,  3.1196e-03,\n",
      "         2.2008e-03,  6.6534e-04,  2.7858e-04,  1.8406e-04,  6.6265e-05,\n",
      "         9.7732e-06, -5.0327e-05, -4.0191e-04, -6.1133e-04, -2.1597e-04,\n",
      "        -4.0317e-04, -8.0456e-04, -8.2578e-04, -4.1202e-04, -3.6434e-04,\n",
      "        -8.8223e-04, -1.5204e-03, -6.3169e-04, -1.4813e-03, -2.7096e-04,\n",
      "        -5.9354e-04, -1.4251e-03, -4.5830e-04, -1.5254e-03, -5.0136e-04,\n",
      "        -1.4272e-03, -4.6704e-04, -1.5043e-03, -1.4812e-03, -1.5273e-03,\n",
      "        -3.3918e-04, -5.5628e-04, -6.8408e-04, -4.3760e-04, -4.0743e-04,\n",
      "        -1.2787e-03, -1.5273e-03, -6.8967e-04, -1.0063e-03, -1.2884e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -127100, loss is -3.490406205989815e-05\n",
      "Action prob: [0.9988263  0.00117368], Action: 0, state: 0\n",
      "Action prob: [9.9912483e-01 8.7517744e-04], Action: 0, state: 0\n",
      "Action prob: [0.99872786 0.00127215], Action: 0, state: 0\n",
      "Action prob: [0.998823   0.00117702], Action: 0, state: 1\n",
      "Action prob: [0.9987398  0.00126028], Action: 0, state: 1\n",
      "Action prob: [0.9987375  0.00126245], Action: 0, state: 1\n",
      "Action prob: [0.9989256  0.00107436], Action: 0, state: 1\n",
      "Action prob: [9.990237e-01 9.763085e-04], Action: 0, state: 1\n",
      "Action prob: [0.9988882  0.00111182], Action: 0, state: 2\n",
      "Action prob: [9.9904734e-01 9.5265999e-04], Action: 0, state: 2\n",
      "Action prob: [0.99817944 0.00182058], Action: 0, state: 3\n",
      "Action prob: [0.99888235 0.00111761], Action: 0, state: 3\n",
      "Action prob: [9.993944e-01 6.055916e-04], Action: 0, state: 8\n",
      "Action prob: [9.991380e-01 8.619726e-04], Action: 0, state: 8\n",
      "Action prob: [9.990140e-01 9.859678e-04], Action: 0, state: 8\n",
      "Action prob: [9.993536e-01 6.464583e-04], Action: 0, state: 8\n",
      "Action prob: [9.9943405e-01 5.6590751e-04], Action: 0, state: 8\n",
      "Action prob: [0.99751925 0.00248082], Action: 0, state: 8\n",
      "Action prob: [9.990308e-01 9.691627e-04], Action: 0, state: 8\n",
      "Action prob: [9.993544e-01 6.456225e-04], Action: 0, state: 8\n",
      "Action prob: [9.9930704e-01 6.9297937e-04], Action: 0, state: 8\n",
      "Action prob: [0.99884063 0.00115944], Action: 0, state: 8\n",
      "Action prob: [9.992092e-01 7.907539e-04], Action: 0, state: 8\n",
      "Action prob: [9.9918777e-01 8.1224280e-04], Action: 0, state: 8\n",
      "Action prob: [0.99897826 0.00102176], Action: 0, state: 8\n",
      "Action prob: [9.9930894e-01 6.9111097e-04], Action: 0, state: 8\n",
      "Action prob: [9.9947363e-01 5.2643823e-04], Action: 0, state: 8\n",
      "Action prob: [9.9925226e-01 7.4772257e-04], Action: 0, state: 8\n",
      "Action prob: [9.9908626e-01 9.1374136e-04], Action: 0, state: 8\n",
      "Action prob: [9.9941266e-01 5.8733555e-04], Action: 0, state: 8\n",
      "Action prob: [9.9902844e-01 9.7159838e-04], Action: 0, state: 8\n",
      "Action prob: [9.993049e-01 6.951364e-04], Action: 0, state: 8\n",
      "Action prob: [0.9984836  0.00151639], Action: 0, state: 8\n",
      "Action prob: [0.9982843  0.00171572], Action: 0, state: 8\n",
      "Action prob: [0.998616   0.00138399], Action: 0, state: 8\n",
      "Action prob: [9.995844e-01 4.156336e-04], Action: 0, state: 8\n",
      "Action prob: [0.9976888  0.00231121], Action: 0, state: 8\n",
      "Action prob: [9.994060e-01 5.940285e-04], Action: 0, state: 8\n",
      "Action prob: [9.9945301e-01 5.4697203e-04], Action: 0, state: 8\n",
      "Action prob: [0.99821705 0.0017829 ], Action: 0, state: 8\n",
      "Action prob: [0.9982014  0.00179858], Action: 0, state: 8\n",
      "Action prob: [0.99784994 0.00215003], Action: 0, state: 8\n",
      "Action prob: [0.9989048  0.00109521], Action: 0, state: 8\n",
      "Action prob: [9.994584e-01 5.416410e-04], Action: 0, state: 8\n",
      "Action prob: [0.99795157 0.00204841], Action: 0, state: 8\n",
      "Action prob: [0.9978788  0.00212118], Action: 0, state: 8\n",
      "Action prob: [9.994723e-01 5.277470e-04], Action: 0, state: 8\n",
      "Action prob: [9.9944597e-01 5.5399915e-04], Action: 0, state: 8\n",
      "Action prob: [0.9980108  0.00198921], Action: 0, state: 8\n",
      "Action prob: [0.9988133  0.00118672], Action: 0, state: 8\n",
      "tensor([-2.5295e-03, -1.0936e-03, -6.1094e-04,  1.2772e-04,  7.6743e-04,\n",
      "         1.3059e-03,  1.4996e-03,  1.6627e-03,  2.1517e-03,  2.0316e-03,\n",
      "         4.0750e-03,  2.6004e-03,  1.1334e-03,  1.2806e-03,  1.1411e-03,\n",
      "         5.6759e-04,  3.6267e-04,  1.0906e-03,  2.5962e-04,  7.8866e-05,\n",
      "        -1.1514e-06, -1.2398e-04, -1.5530e-04, -2.2129e-04, -3.4445e-04,\n",
      "        -2.7090e-04, -2.3090e-04, -3.5773e-04, -4.6802e-04, -3.1764e-04,\n",
      "        -5.4921e-04, -4.0729e-04, -9.1559e-04, -1.0617e-03, -8.7395e-04,\n",
      "        -2.6682e-04, -1.5064e-03, -3.9148e-04, -3.6411e-04, -1.1976e-03,\n",
      "        -1.2168e-03, -1.4636e-03, -7.4892e-04, -3.7188e-04, -1.4126e-03,\n",
      "        -1.4674e-03, -3.6570e-04, -3.8482e-04, -1.3853e-03, -8.2742e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -107900, loss is 3.535348818019465e-05\n",
      "Action prob: [0.9986551 0.0013449], Action: 0, state: 0\n",
      "Action prob: [0.9988877  0.00111234], Action: 0, state: 1\n",
      "Action prob: [0.99880373 0.00119632], Action: 0, state: 1\n",
      "Action prob: [0.9983948  0.00160514], Action: 0, state: 2\n",
      "Action prob: [0.9989446  0.00105548], Action: 0, state: 2\n",
      "Action prob: [0.99799263 0.00200742], Action: 0, state: 3\n",
      "Action prob: [0.9988385  0.00116155], Action: 0, state: 3\n",
      "Action prob: [0.9989812  0.00101885], Action: 0, state: 3\n",
      "Action prob: [0.99879825 0.00120177], Action: 0, state: 3\n",
      "Action prob: [9.993605e-01 6.394488e-04], Action: 0, state: 8\n",
      "Action prob: [0.99779874 0.00220121], Action: 0, state: 8\n",
      "Action prob: [9.9912590e-01 8.7410276e-04], Action: 0, state: 8\n",
      "Action prob: [9.9910212e-01 8.9788076e-04], Action: 0, state: 8\n",
      "Action prob: [0.99747795 0.00252209], Action: 0, state: 8\n",
      "Action prob: [9.9936277e-01 6.3720095e-04], Action: 0, state: 8\n",
      "Action prob: [9.9945480e-01 5.4524076e-04], Action: 0, state: 8\n",
      "Action prob: [9.9934036e-01 6.5956835e-04], Action: 0, state: 8\n",
      "Action prob: [0.9983701  0.00162988], Action: 0, state: 8\n",
      "Action prob: [0.99815947 0.00184054], Action: 0, state: 8\n",
      "Action prob: [0.997875   0.00212507], Action: 0, state: 8\n",
      "Action prob: [9.9938190e-01 6.1809074e-04], Action: 0, state: 8\n",
      "Action prob: [0.99897695 0.00102311], Action: 0, state: 8\n",
      "Action prob: [0.9988551  0.00114492], Action: 0, state: 8\n",
      "Action prob: [9.994136e-01 5.864185e-04], Action: 0, state: 8\n",
      "Action prob: [0.9980901  0.00190991], Action: 0, state: 8\n",
      "Action prob: [9.9934310e-01 6.5692794e-04], Action: 0, state: 8\n",
      "Action prob: [0.99872893 0.00127104], Action: 0, state: 8\n",
      "Action prob: [9.994266e-01 5.734067e-04], Action: 0, state: 8\n",
      "Action prob: [9.9958676e-01 4.1321048e-04], Action: 0, state: 8\n",
      "Action prob: [9.9935967e-01 6.4039422e-04], Action: 0, state: 8\n",
      "Action prob: [9.9919802e-01 8.0201257e-04], Action: 0, state: 8\n",
      "Action prob: [9.9933201e-01 6.6799915e-04], Action: 0, state: 8\n",
      "Action prob: [9.990709e-01 9.290901e-04], Action: 0, state: 8\n",
      "Action prob: [9.9904615e-01 9.5384067e-04], Action: 0, state: 8\n",
      "Action prob: [0.9972234  0.00277669], Action: 0, state: 8\n",
      "Action prob: [9.9947697e-01 5.2300113e-04], Action: 0, state: 8\n",
      "Action prob: [9.991247e-01 8.753021e-04], Action: 0, state: 8\n",
      "Action prob: [0.9989748  0.00102518], Action: 0, state: 8\n",
      "Action prob: [9.9933785e-01 6.6215702e-04], Action: 0, state: 8\n",
      "Action prob: [9.9923277e-01 7.6728041e-04], Action: 0, state: 8\n",
      "Action prob: [0.99769294 0.00230712], Action: 0, state: 8\n",
      "Action prob: [0.99786854 0.00213146], Action: 0, state: 8\n",
      "Action prob: [0.9982388  0.00176122], Action: 0, state: 8\n",
      "Action prob: [9.993980e-01 6.019684e-04], Action: 0, state: 8\n",
      "Action prob: [0.99804485 0.00195518], Action: 0, state: 8\n",
      "Action prob: [9.9902999e-01 9.7007497e-04], Action: 0, state: 8\n",
      "Action prob: [0.99894327 0.00105676], Action: 0, state: 8\n",
      "Action prob: [9.995777e-01 4.223424e-04], Action: 0, state: 8\n",
      "Action prob: [9.9922252e-01 7.7746564e-04], Action: 0, state: 8\n",
      "Action prob: [9.9931264e-01 6.8734493e-04], Action: 0, state: 8\n",
      "tensor([ 3.9471e-04,  8.9865e-04,  1.4897e-03,  2.5299e-03,  1.9594e-03,\n",
      "         4.0280e-03,  2.4771e-03,  2.2824e-03,  2.8026e-03,  1.1922e-03,\n",
      "         3.2320e-03,  9.8746e-04,  7.5668e-04,  1.5115e-03,  2.4944e-04,\n",
      "         1.1735e-04,  4.3187e-05, -1.0084e-04, -3.1317e-04, -5.5724e-04,\n",
      "        -2.1028e-04, -4.1613e-04, -5.3040e-04, -2.9974e-04, -1.0549e-03,\n",
      "        -3.8539e-04, -7.8343e-04, -3.6766e-04, -2.7375e-04, -4.3584e-04,\n",
      "        -5.5825e-04, -4.7369e-04, -6.6928e-04, -6.9612e-04, -2.0506e-03,\n",
      "        -3.8940e-04, -6.5686e-04, -7.7447e-04, -5.0290e-04, -5.8547e-04,\n",
      "        -1.7689e-03, -1.6396e-03, -1.3584e-03, -4.6517e-04, -1.5149e-03,\n",
      "        -7.5249e-04, -8.2102e-04, -3.2841e-04, -6.0537e-04, -5.3566e-04],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -120600, loss is -8.153322617564059e-05\n",
      "Action prob: [0.99875426 0.00124571], Action: 0, state: 0\n",
      "Action prob: [9.990134e-01 9.865805e-04], Action: 0, state: 0\n",
      "Action prob: [0.9988079  0.00119207], Action: 0, state: 0\n",
      "Action prob: [0.9989177  0.00108234], Action: 0, state: 1\n",
      "Action prob: [0.9989849 0.0010151], Action: 0, state: 1\n",
      "Action prob: [0.9989537  0.00104623], Action: 0, state: 1\n",
      "Action prob: [0.99895275 0.00104726], Action: 0, state: 1\n",
      "Action prob: [0.99883324 0.00116674], Action: 0, state: 1\n",
      "Action prob: [9.9904805e-01 9.5194869e-04], Action: 0, state: 2\n",
      "Action prob: [0.9988716  0.00112833], Action: 0, state: 2\n",
      "Action prob: [0.9987853  0.00121465], Action: 0, state: 3\n",
      "Action prob: [0.99884546 0.00115446], Action: 0, state: 3\n",
      "Action prob: [9.9924695e-01 7.5306610e-04], Action: 0, state: 8\n",
      "Action prob: [0.9979625  0.00203751], Action: 0, state: 8\n",
      "Action prob: [9.9931061e-01 6.8943086e-04], Action: 0, state: 8\n",
      "Action prob: [0.997959   0.00204099], Action: 0, state: 8\n",
      "Action prob: [9.993767e-01 6.232591e-04], Action: 0, state: 8\n",
      "Action prob: [0.9989116  0.00108844], Action: 0, state: 8\n",
      "Action prob: [0.99792033 0.00207968], Action: 0, state: 8\n",
      "Action prob: [0.99761814 0.00238188], Action: 0, state: 8\n",
      "Action prob: [0.9984363  0.00156376], Action: 0, state: 8\n",
      "Action prob: [9.9918145e-01 8.1850350e-04], Action: 0, state: 8\n",
      "Action prob: [0.99852824 0.00147177], Action: 0, state: 8\n",
      "Action prob: [0.998811   0.00118899], Action: 0, state: 8\n",
      "Action prob: [0.99795806 0.00204188], Action: 0, state: 8\n",
      "Action prob: [0.9957147  0.00428519], Action: 0, state: 8\n",
      "Action prob: [0.99784315 0.00215686], Action: 0, state: 8\n",
      "Action prob: [9.9945325e-01 5.4675358e-04], Action: 0, state: 8\n",
      "Action prob: [9.9962544e-01 3.7448379e-04], Action: 0, state: 8\n",
      "Action prob: [0.9977187  0.00228128], Action: 0, state: 8\n",
      "Action prob: [0.997519 0.002481], Action: 0, state: 8\n",
      "Action prob: [9.9943691e-01 5.6304893e-04], Action: 0, state: 8\n",
      "Action prob: [9.9906594e-01 9.3408825e-04], Action: 0, state: 8\n",
      "Action prob: [9.990159e-01 9.841088e-04], Action: 0, state: 8\n",
      "Action prob: [9.9916065e-01 8.3933753e-04], Action: 0, state: 8\n",
      "Action prob: [9.9940789e-01 5.9211056e-04], Action: 0, state: 8\n",
      "Action prob: [0.9988649  0.00113516], Action: 0, state: 8\n",
      "Action prob: [9.9955434e-01 4.4563046e-04], Action: 0, state: 8\n",
      "Action prob: [0.9979728  0.00202715], Action: 0, state: 8\n",
      "Action prob: [0.99761677 0.00238331], Action: 0, state: 8\n",
      "Action prob: [0.9975204  0.00247963], Action: 0, state: 8\n",
      "Action prob: [9.9906296e-01 9.3710393e-04], Action: 0, state: 8\n",
      "Action prob: [9.993856e-01 6.143401e-04], Action: 0, state: 8\n",
      "Action prob: [9.992411e-01 7.588508e-04], Action: 0, state: 8\n",
      "Action prob: [0.9966446  0.00335539], Action: 0, state: 8\n",
      "Action prob: [0.9985447  0.00145535], Action: 0, state: 8\n",
      "Action prob: [9.991365e-01 8.635004e-04], Action: 0, state: 8\n",
      "Action prob: [0.9989681  0.00103192], Action: 0, state: 8\n",
      "Action prob: [9.993923e-01 6.077367e-04], Action: 0, state: 8\n",
      "Action prob: [0.99804544 0.00195459], Action: 0, state: 8\n",
      "tensor([-2.6849e-03, -1.2329e-03, -5.7248e-04,  1.1744e-04,  6.1810e-04,\n",
      "         1.0821e-03,  1.4617e-03,  1.9872e-03,  1.8422e-03,  2.4065e-03,\n",
      "         2.7180e-03,  2.6863e-03,  1.4096e-03,  3.0287e-03,  7.9773e-04,\n",
      "         1.7934e-03,  3.9943e-04,  4.7815e-04,  5.5742e-04,  2.9123e-04,\n",
      "        -2.5994e-06, -8.7521e-05, -2.8914e-04, -3.2399e-04, -6.8873e-04,\n",
      "        -1.6829e-03, -9.4693e-04, -2.6155e-04, -1.9180e-04, -1.2348e-03,\n",
      "        -1.4035e-03, -3.2991e-04, -5.6382e-04, -6.0875e-04, -5.2987e-04,\n",
      "        -3.8015e-04, -7.3941e-04, -2.9369e-04, -1.3504e-03, -1.6014e-03,\n",
      "        -1.6781e-03, -6.3749e-04, -4.2005e-04, -5.2111e-04, -2.3155e-03,\n",
      "        -1.0064e-03, -5.9853e-04, -7.1690e-04, -4.2293e-04, -1.3633e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -107900, loss is 8.012409751187826e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-53-6c60666a00ca>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  actions = np.array(results[1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "machine1 = Machine_env()\n",
    "pol = policy_estimator(machine1)\n",
    "\n",
    "#Parameters\n",
    "episodes = 100\n",
    "batchsize = 20\n",
    "gamma = 0.85\n",
    "lr = 0.05\n",
    "\n",
    "\n",
    "#writer = SummaryWriter(f\"runs/gamma/lr_{lr}gamma_{gamma}episode_{episodes}batch_{batchsize}_mu0_{mu0}_no_entropy_reg\")\n",
    "\n",
    "results = reinforce(machine1,pol,episodes,batchsize,gamma,lr)\n",
    "rewards = results[0]\n",
    "actions = np.array(results[1])\n",
    "states = results[2]\n",
    "\n",
    "episode = [i for i in range(episodes)]\n",
    "\n",
    "#Moving average we will use a window size of 50\n",
    "\n",
    "moving_averages = []\n",
    "window_size = 10\n",
    "\n",
    "df = pd.DataFrame(rewards,columns = ['r'])\n",
    "moving_ave = df.r.rolling(window_size,min_periods=1).mean().values\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.plot(episode,rewards,label = 'Episodic Reward')\n",
    "plt.plot(episode,moving_ave,label = f'Moving Average Window {window_size}')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Rewards')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy Regularised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce_entropy_regularised(machine,policy_estimator,num_episodes,batch_size,gamma,lr,entropy_coeff): #Learning algo\n",
    "    # Set up lists to hold results\n",
    "    # Set up lists to hold results\n",
    "    total_rewards = [] #Total actual reward for each episode\n",
    "    batch_rewards = []  #Discounted expected future rewards for each batch\n",
    "    batch_actions = []\n",
    "    batch_observation = []\n",
    "    state_seq = []\n",
    "    \n",
    "    # Define optimizer\n",
    "    optimizer = torch.optim.Adam(policy_estimator.network.parameters(),lr=lr)\n",
    "    \n",
    "    action_space = machine.action_space\n",
    "    \n",
    "    for ep in range(num_episodes):\n",
    "        machine.reset()\n",
    "        observation = []\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        \n",
    "        while(not machine.done):\n",
    "            obs = machine.sensor(machine.state).tolist() #observation\n",
    "            \n",
    "            action_probs = policy_estimator.predict(obs).detach().numpy() #convert to numpy and get action prob\n",
    "            action = np.random.choice(action_space, p=action_probs) #select weighted actions based on NN output prob\n",
    "            print(f\"Action prob: {action_probs}, Action: {action}, state: {machine.state}\")\n",
    "            \n",
    "            r = machine.step(action) #receive reward and update machine to the next state after doing the sampled action\n",
    "            \n",
    "            observation.append(obs)\n",
    "            rewards.append(r)\n",
    "            actions.append(action)\n",
    "        \n",
    "        discount_r = normalized_discount_reward(rewards,gamma) #normalised already\n",
    "        \n",
    "        total_rewards.append(sum(rewards)) #Cumulative reward for this episode\n",
    "        \n",
    "        #After batch complete time,store the parameters\n",
    "        batch_rewards.append(discount_r)\n",
    "        batch_observation.append(observation)\n",
    "        batch_actions.append(actions)\n",
    "        state_seq.append(machine.state_seq)\n",
    "        \n",
    "        #update policy\n",
    "        obs_tensor = torch.FloatTensor(observation)\n",
    "        action_tensor = torch.LongTensor(actions)\n",
    "        reward_tensor = torch.from_numpy(np.array(discount_r).copy()) #resolve stride problem\n",
    "\n",
    "\n",
    "        #Calculate loss Ver 3\n",
    "        logprob = torch.log(policy_estimator.predict(obs_tensor))\n",
    "#         print(logprob)\n",
    "#         print(logprob[np.arange(len(action_tensor)), action_tensor])\n",
    "        selected_logprobs = reward_tensor * logprob[np.arange(len(action_tensor)), action_tensor]\n",
    "        #print(selected_logprobs)\n",
    "        \n",
    "        #Entropy\n",
    "        prob = policy_estimator.predict(obs_tensor)\n",
    "        ave_entropy = entropy(prob,entropy_coeff)\n",
    "        \n",
    "        loss = -selected_logprobs.mean() - ave_entropy\n",
    "        \n",
    "        print(f\"Reward for this episode {total_rewards[-1]}, loss is {loss}\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        # Apply gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "#         #Tensorboard params\n",
    "#         writer.add_scalar(\"Loss\", loss, ep)\n",
    "#         writer.add_scalar('Rewards',sum(rewards),ep)\n",
    "#         for name, weight in policy_estimator.network.named_parameters():\n",
    "#             writer.add_histogram(name,weight, ep)\n",
    "#             if weight.grad != None:\n",
    "#                 writer.add_histogram(f\"{name}.grad\",weight.grad, ep)\n",
    "    \n",
    "#     writer.add_graph(policy_estimator.network,torch.FloatTensor(machine.sensor(0))) #draw graph\n",
    "#     writer.flush()\n",
    "#     writer.close()\n",
    "    \n",
    "    return (total_rewards,batch_actions,state_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\overl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator GaussianMixture from version 0.20.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.4615343 0.5384657], Action: 0, state: 0\n",
      "Action prob: [0.46223822 0.5377618 ], Action: 1, state: 0\n",
      "Action prob: [0.4150416 0.5849583], Action: 0, state: 4\n",
      "Action prob: [0.46142536 0.53857464], Action: 0, state: 0\n",
      "Action prob: [0.4534665 0.5465336], Action: 1, state: 1\n",
      "Action prob: [0.4150416 0.5849583], Action: 1, state: 5\n",
      "Action prob: [0.46496356 0.5350364 ], Action: 1, state: 0\n",
      "Action prob: [0.4150416 0.5849583], Action: 1, state: 4\n",
      "Action prob: [0.4150416 0.5849583], Action: 1, state: 4\n",
      "Action prob: [0.4579341 0.5420659], Action: 1, state: 0\n",
      "Action prob: [0.4150416 0.5849583], Action: 1, state: 4\n",
      "Action prob: [0.45811212 0.5418878 ], Action: 0, state: 0\n",
      "Action prob: [0.46233344 0.5376666 ], Action: 0, state: 1\n",
      "Action prob: [0.46278587 0.5372141 ], Action: 1, state: 2\n",
      "Action prob: [0.4150416 0.5849583], Action: 1, state: 6\n",
      "Action prob: [0.46756187 0.5324381 ], Action: 0, state: 1\n",
      "Action prob: [0.46065444 0.5393455 ], Action: 0, state: 2\n",
      "Action prob: [0.4666738  0.53332615], Action: 1, state: 3\n",
      "Action prob: [0.4150416 0.5849583], Action: 1, state: 7\n",
      "Action prob: [0.46373072 0.53626925], Action: 1, state: 2\n",
      "Action prob: [0.4150416 0.5849583], Action: 0, state: 6\n",
      "Action prob: [0.4150416 0.5849583], Action: 1, state: 6\n",
      "Action prob: [0.46065596 0.5393441 ], Action: 0, state: 1\n",
      "Action prob: [0.4673675 0.5326325], Action: 0, state: 2\n",
      "Action prob: [0.46052432 0.53947574], Action: 1, state: 2\n",
      "Action prob: [0.4150416 0.5849583], Action: 1, state: 6\n",
      "Action prob: [0.45974928 0.5402507 ], Action: 1, state: 1\n",
      "Action prob: [0.4150416 0.5849583], Action: 0, state: 5\n",
      "Reward for this episode 9500, loss is 0.0217667033238636\n",
      "Action prob: [0.4929335 0.5070664], Action: 0, state: 0\n",
      "Action prob: [0.4885593 0.5114407], Action: 0, state: 0\n",
      "Action prob: [0.47842908 0.52157086], Action: 1, state: 1\n",
      "Action prob: [0.45531926 0.5446807 ], Action: 1, state: 5\n",
      "Action prob: [0.48299885 0.5170012 ], Action: 1, state: 0\n",
      "Action prob: [0.45531926 0.5446807 ], Action: 1, state: 4\n",
      "Action prob: [0.48506516 0.5149348 ], Action: 1, state: 0\n",
      "Action prob: [0.45531926 0.5446807 ], Action: 1, state: 4\n",
      "Action prob: [0.45531926 0.5446807 ], Action: 1, state: 4\n",
      "Action prob: [0.47782084 0.5221792 ], Action: 0, state: 0\n",
      "Action prob: [0.48345307 0.51654696], Action: 1, state: 0\n",
      "Action prob: [0.45531926 0.5446807 ], Action: 1, state: 4\n",
      "Action prob: [0.4817924  0.51820767], Action: 1, state: 0\n",
      "Action prob: [0.45531926 0.5446807 ], Action: 1, state: 4\n",
      "Action prob: [0.4807757 0.5192243], Action: 1, state: 0\n",
      "Action prob: [0.45531926 0.5446807 ], Action: 0, state: 4\n",
      "Action prob: [0.45531926 0.5446807 ], Action: 1, state: 4\n",
      "Action prob: [0.47768614 0.5223139 ], Action: 1, state: 0\n",
      "Action prob: [0.45531926 0.5446807 ], Action: 1, state: 4\n",
      "Action prob: [0.48474714 0.5152529 ], Action: 1, state: 0\n",
      "Action prob: [0.45531926 0.5446807 ], Action: 1, state: 4\n",
      "Action prob: [0.45531926 0.5446807 ], Action: 0, state: 4\n",
      "Action prob: [0.45531926 0.5446807 ], Action: 1, state: 4\n",
      "Reward for this episode 4900, loss is 0.005529888911304397\n",
      "Action prob: [0.5026727  0.49732724], Action: 0, state: 0\n",
      "Action prob: [0.50688916 0.49311084], Action: 1, state: 0\n",
      "Action prob: [0.47728983 0.52271014], Action: 1, state: 4\n",
      "Action prob: [0.47728983 0.52271014], Action: 0, state: 4\n",
      "Action prob: [0.47728983 0.52271014], Action: 0, state: 4\n",
      "Action prob: [0.5075309  0.49246907], Action: 0, state: 0\n",
      "Action prob: [0.50693196 0.49306804], Action: 1, state: 1\n",
      "Action prob: [0.47728983 0.52271014], Action: 1, state: 5\n",
      "Action prob: [0.47728983 0.52271014], Action: 1, state: 5\n",
      "Action prob: [0.5071127  0.49288738], Action: 0, state: 0\n",
      "Action prob: [0.5084439 0.4915561], Action: 0, state: 1\n",
      "Action prob: [0.5028473  0.49715263], Action: 0, state: 1\n",
      "Action prob: [0.5025234  0.49747658], Action: 0, state: 1\n",
      "Action prob: [0.5085714  0.49142864], Action: 1, state: 1\n",
      "Action prob: [0.47728983 0.52271014], Action: 0, state: 5\n",
      "Action prob: [0.47728983 0.52271014], Action: 1, state: 5\n",
      "Action prob: [0.47728983 0.52271014], Action: 0, state: 5\n",
      "Action prob: [0.51336634 0.4866337 ], Action: 1, state: 0\n",
      "Action prob: [0.47728983 0.52271014], Action: 0, state: 4\n",
      "Action prob: [0.5048347  0.49516526], Action: 1, state: 0\n",
      "Action prob: [0.47728983 0.52271014], Action: 1, state: 4\n",
      "Reward for this episode 5500, loss is -0.004584025110240282\n",
      "Action prob: [0.53264105 0.4673589 ], Action: 0, state: 0\n",
      "Action prob: [0.5353324 0.4646676], Action: 1, state: 1\n",
      "Action prob: [0.5013118  0.49868822], Action: 0, state: 5\n",
      "Action prob: [0.5013118  0.49868822], Action: 0, state: 5\n",
      "Action prob: [0.53672457 0.46327546], Action: 1, state: 0\n",
      "Action prob: [0.5013118  0.49868822], Action: 1, state: 4\n",
      "Action prob: [0.530347   0.46965295], Action: 1, state: 0\n",
      "Action prob: [0.5013118  0.49868822], Action: 1, state: 4\n",
      "Action prob: [0.53398305 0.46601695], Action: 0, state: 0\n",
      "Action prob: [0.5316702  0.46832976], Action: 0, state: 0\n",
      "Action prob: [0.5332415  0.46675852], Action: 1, state: 0\n",
      "Action prob: [0.5013118  0.49868822], Action: 1, state: 4\n",
      "Action prob: [0.5013118  0.49868822], Action: 1, state: 4\n",
      "Action prob: [0.53133273 0.46866727], Action: 1, state: 0\n",
      "Action prob: [0.5013118  0.49868822], Action: 1, state: 4\n",
      "Action prob: [0.53177416 0.46822584], Action: 1, state: 0\n",
      "Action prob: [0.5013118  0.49868822], Action: 1, state: 4\n",
      "Action prob: [0.5013118  0.49868822], Action: 0, state: 4\n",
      "Action prob: [0.533052  0.4669479], Action: 0, state: 0\n",
      "Action prob: [0.5340192  0.46598077], Action: 0, state: 1\n",
      "Action prob: [0.5338441 0.4661559], Action: 0, state: 2\n",
      "Action prob: [0.5316948  0.46830514], Action: 0, state: 2\n",
      "Action prob: [0.53057915 0.46942088], Action: 0, state: 3\n",
      "Action prob: [0.535027   0.46497297], Action: 1, state: 3\n",
      "Action prob: [0.5013118  0.49868822], Action: 1, state: 7\n",
      "Action prob: [0.5013118  0.49868822], Action: 0, state: 7\n",
      "Action prob: [0.5013118  0.49868822], Action: 1, state: 7\n",
      "Action prob: [0.5013118  0.49868822], Action: 1, state: 7\n",
      "Action prob: [0.5013118  0.49868822], Action: 0, state: 7\n",
      "Action prob: [0.53123575 0.4687642 ], Action: 1, state: 2\n",
      "Action prob: [0.5013118  0.49868822], Action: 1, state: 6\n",
      "Action prob: [0.5013118  0.49868822], Action: 0, state: 6\n",
      "Action prob: [0.5013118  0.49868822], Action: 0, state: 6\n",
      "Action prob: [0.5297658  0.47023422], Action: 0, state: 1\n",
      "Action prob: [0.52885044 0.47114947], Action: 0, state: 2\n",
      "Action prob: [0.55138355 0.44861645], Action: 0, state: 3\n",
      "Action prob: [0.5561015 0.4438985], Action: 0, state: 3\n",
      "Action prob: [0.53370214 0.46629786], Action: 0, state: 8\n",
      "Action prob: [0.5226674 0.4773326], Action: 1, state: 8\n",
      "Reward for this episode 2400, loss is -0.0014787296962126082\n",
      "Action prob: [0.5509248  0.44907516], Action: 1, state: 0\n",
      "Action prob: [0.5291062  0.47089386], Action: 1, state: 4\n",
      "Action prob: [0.5469541 0.4530459], Action: 0, state: 0\n",
      "Action prob: [0.5513511  0.44864896], Action: 0, state: 1\n",
      "Action prob: [0.54959077 0.4504092 ], Action: 0, state: 1\n",
      "Action prob: [0.5620446  0.43795544], Action: 0, state: 2\n",
      "Action prob: [0.5524461  0.44755387], Action: 1, state: 2\n",
      "Action prob: [0.5291062  0.47089386], Action: 1, state: 6\n",
      "Action prob: [0.5291062  0.47089386], Action: 1, state: 6\n",
      "Action prob: [0.5590308  0.44096926], Action: 0, state: 1\n",
      "Action prob: [0.55127364 0.44872636], Action: 1, state: 2\n",
      "Action prob: [0.5291062  0.47089386], Action: 1, state: 6\n",
      "Action prob: [0.5530088  0.44699118], Action: 0, state: 1\n",
      "Action prob: [0.54790723 0.45209274], Action: 1, state: 1\n",
      "Action prob: [0.5291062  0.47089386], Action: 0, state: 5\n",
      "Action prob: [0.5291062  0.47089386], Action: 0, state: 5\n",
      "Action prob: [0.5534838  0.44651625], Action: 1, state: 0\n",
      "Action prob: [0.5291062  0.47089386], Action: 1, state: 4\n",
      "Action prob: [0.5291062  0.47089386], Action: 1, state: 4\n",
      "Action prob: [0.5291062  0.47089386], Action: 0, state: 4\n",
      "Action prob: [0.5291062  0.47089386], Action: 1, state: 4\n",
      "Action prob: [0.5291062  0.47089386], Action: 1, state: 4\n",
      "Reward for this episode 4400, loss is -0.008651360179512247\n",
      "Action prob: [0.5742895  0.42571053], Action: 1, state: 0\n",
      "Action prob: [0.5429584 0.4570416], Action: 0, state: 4\n",
      "Action prob: [0.5429584 0.4570416], Action: 0, state: 4\n",
      "Action prob: [0.5429584 0.4570416], Action: 0, state: 4\n",
      "Action prob: [0.5429584 0.4570416], Action: 0, state: 4\n",
      "Action prob: [0.5429584 0.4570416], Action: 1, state: 4\n",
      "Action prob: [0.57423073 0.42576933], Action: 1, state: 0\n",
      "Action prob: [0.5429584 0.4570416], Action: 0, state: 4\n",
      "Action prob: [0.57662463 0.42337537], Action: 0, state: 0\n",
      "Action prob: [0.5724418 0.4275582], Action: 0, state: 0\n",
      "Action prob: [0.57328403 0.42671606], Action: 1, state: 1\n",
      "Action prob: [0.5429584 0.4570416], Action: 0, state: 5\n",
      "Action prob: [0.5429584 0.4570416], Action: 0, state: 5\n",
      "Action prob: [0.57264376 0.42735627], Action: 0, state: 0\n",
      "Action prob: [0.5754282  0.42457187], Action: 0, state: 1\n",
      "Action prob: [0.571511   0.42848903], Action: 1, state: 1\n",
      "Action prob: [0.5429584 0.4570416], Action: 0, state: 5\n",
      "Action prob: [0.5429584 0.4570416], Action: 0, state: 5\n",
      "Action prob: [0.5697229  0.43027705], Action: 1, state: 0\n",
      "Action prob: [0.5429584 0.4570416], Action: 0, state: 4\n",
      "Action prob: [0.5782763  0.42172372], Action: 1, state: 0\n",
      "Action prob: [0.5429584 0.4570416], Action: 1, state: 4\n",
      "Reward for this episode 3700, loss is -0.027493266839415054\n",
      "Action prob: [0.5998181 0.4001819], Action: 1, state: 0\n",
      "Action prob: [0.54844093 0.45155904], Action: 0, state: 4\n",
      "Action prob: [0.54844093 0.45155904], Action: 0, state: 4\n",
      "Action prob: [0.59530914 0.40469092], Action: 0, state: 0\n",
      "Action prob: [0.6020743 0.3979256], Action: 1, state: 1\n",
      "Action prob: [0.54844093 0.45155904], Action: 1, state: 5\n",
      "Action prob: [0.54844093 0.45155904], Action: 1, state: 5\n",
      "Action prob: [0.60380733 0.3961927 ], Action: 0, state: 0\n",
      "Action prob: [0.6004853 0.3995147], Action: 0, state: 0\n",
      "Action prob: [0.60289234 0.3971076 ], Action: 1, state: 1\n",
      "Action prob: [0.54844093 0.45155904], Action: 1, state: 5\n",
      "Action prob: [0.5919403  0.40805972], Action: 1, state: 0\n",
      "Action prob: [0.54844093 0.45155904], Action: 1, state: 4\n",
      "Action prob: [0.59984887 0.40015116], Action: 1, state: 0\n",
      "Action prob: [0.54844093 0.45155904], Action: 0, state: 4\n",
      "Action prob: [0.54844093 0.45155904], Action: 1, state: 4\n",
      "Action prob: [0.59199256 0.40800747], Action: 1, state: 0\n",
      "Action prob: [0.54844093 0.45155904], Action: 1, state: 4\n",
      "Action prob: [0.6050749  0.39492518], Action: 0, state: 0\n",
      "Action prob: [0.6034677  0.39653236], Action: 0, state: 1\n",
      "Action prob: [0.5970817  0.40291825], Action: 1, state: 2\n",
      "Action prob: [0.54844093 0.45155904], Action: 1, state: 6\n",
      "Action prob: [0.54844093 0.45155904], Action: 1, state: 6\n",
      "Action prob: [0.5946313  0.40536866], Action: 0, state: 1\n",
      "Action prob: [0.6022364 0.3977636], Action: 1, state: 1\n",
      "Action prob: [0.54844093 0.45155904], Action: 0, state: 5\n",
      "Reward for this episode 7300, loss is -0.04467323554826846\n",
      "Action prob: [0.61925477 0.38074532], Action: 0, state: 0\n",
      "Action prob: [0.62052006 0.37948003], Action: 1, state: 0\n",
      "Action prob: [0.5663716 0.4336284], Action: 1, state: 4\n",
      "Action prob: [0.62216425 0.37783578], Action: 0, state: 0\n",
      "Action prob: [0.6284021 0.3715978], Action: 1, state: 1\n",
      "Action prob: [0.5663716 0.4336284], Action: 0, state: 5\n",
      "Action prob: [0.6253391 0.3746609], Action: 0, state: 0\n",
      "Action prob: [0.6219413  0.37805867], Action: 0, state: 1\n",
      "Action prob: [0.62184113 0.37815893], Action: 1, state: 1\n",
      "Action prob: [0.5663716 0.4336284], Action: 1, state: 5\n",
      "Action prob: [0.6291069  0.37089312], Action: 0, state: 0\n",
      "Action prob: [0.62106866 0.37893137], Action: 1, state: 0\n",
      "Action prob: [0.5663716 0.4336284], Action: 1, state: 4\n",
      "Action prob: [0.5663716 0.4336284], Action: 0, state: 4\n",
      "Action prob: [0.61657625 0.38342375], Action: 1, state: 0\n",
      "Action prob: [0.5663716 0.4336284], Action: 0, state: 4\n",
      "Action prob: [0.5663716 0.4336284], Action: 1, state: 4\n",
      "Action prob: [0.5663716 0.4336284], Action: 1, state: 4\n",
      "Action prob: [0.5663716 0.4336284], Action: 0, state: 4\n",
      "Action prob: [0.5663716 0.4336284], Action: 1, state: 4\n",
      "Action prob: [0.6238067  0.37619326], Action: 0, state: 0\n",
      "Reward for this episode 5700, loss is -0.03247400639683938\n",
      "Action prob: [0.6319003  0.36809972], Action: 0, state: 0\n",
      "Action prob: [0.64586854 0.35413143], Action: 0, state: 1\n",
      "Action prob: [0.6411789  0.35882103], Action: 1, state: 2\n",
      "Action prob: [0.5818573  0.41814265], Action: 0, state: 6\n",
      "Action prob: [0.64186263 0.35813737], Action: 0, state: 1\n",
      "Action prob: [0.64447707 0.35552293], Action: 0, state: 1\n",
      "Action prob: [0.6519494 0.3480506], Action: 0, state: 1\n",
      "Action prob: [0.67211765 0.32788226], Action: 0, state: 2\n",
      "Action prob: [0.65060985 0.34939018], Action: 1, state: 3\n",
      "Action prob: [0.5818573  0.41814265], Action: 0, state: 7\n",
      "Action prob: [0.5818573  0.41814265], Action: 0, state: 7\n",
      "Action prob: [0.6396652  0.36033484], Action: 0, state: 2\n",
      "Action prob: [0.63897663 0.36102337], Action: 1, state: 3\n",
      "Action prob: [0.5818573  0.41814265], Action: 0, state: 7\n",
      "Action prob: [0.6484382 0.3515618], Action: 0, state: 2\n",
      "Action prob: [0.6351987  0.36480132], Action: 1, state: 3\n",
      "Action prob: [0.5818573  0.41814265], Action: 1, state: 7\n",
      "Action prob: [0.5818573  0.41814265], Action: 1, state: 7\n",
      "Action prob: [0.5818573  0.41814265], Action: 0, state: 7\n",
      "Action prob: [0.5818573  0.41814265], Action: 0, state: 7\n",
      "Action prob: [0.5818573  0.41814265], Action: 1, state: 7\n",
      "Action prob: [0.6488895 0.3511106], Action: 0, state: 2\n",
      "Action prob: [0.6379055  0.36209455], Action: 0, state: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.6445046  0.35549536], Action: 1, state: 3\n",
      "Action prob: [0.5818573  0.41814265], Action: 0, state: 7\n",
      "Action prob: [0.64440966 0.35559028], Action: 0, state: 2\n",
      "Action prob: [0.6427652  0.35723475], Action: 1, state: 2\n",
      "Action prob: [0.5818573  0.41814265], Action: 0, state: 6\n",
      "Action prob: [0.64219266 0.3578074 ], Action: 1, state: 1\n",
      "Action prob: [0.5818573  0.41814265], Action: 1, state: 5\n",
      "Action prob: [0.5818573  0.41814265], Action: 0, state: 5\n",
      "Action prob: [0.5818573  0.41814265], Action: 1, state: 5\n",
      "Action prob: [0.5818573  0.41814265], Action: 0, state: 5\n",
      "Reward for this episode 6100, loss is -0.06303773405224973\n",
      "Action prob: [0.66949046 0.33050963], Action: 1, state: 0\n",
      "Action prob: [0.5974966  0.40250337], Action: 1, state: 4\n",
      "Action prob: [0.5974966  0.40250337], Action: 1, state: 4\n",
      "Action prob: [0.682806   0.31719398], Action: 0, state: 0\n",
      "Action prob: [0.6820419  0.31795812], Action: 0, state: 0\n",
      "Action prob: [0.6741501  0.32584995], Action: 0, state: 0\n",
      "Action prob: [0.6652547 0.3347453], Action: 0, state: 1\n",
      "Action prob: [0.67336404 0.32663593], Action: 1, state: 2\n",
      "Action prob: [0.5974966  0.40250337], Action: 0, state: 6\n",
      "Action prob: [0.6724255 0.3275745], Action: 0, state: 1\n",
      "Action prob: [0.66408056 0.3359194 ], Action: 0, state: 1\n",
      "Action prob: [0.6747565  0.32524347], Action: 1, state: 1\n",
      "Action prob: [0.5974966  0.40250337], Action: 0, state: 5\n",
      "Action prob: [0.5974966  0.40250337], Action: 1, state: 5\n",
      "Action prob: [0.5974966  0.40250337], Action: 0, state: 5\n",
      "Action prob: [0.6681839  0.33181614], Action: 0, state: 0\n",
      "Action prob: [0.6776304  0.32236958], Action: 1, state: 1\n",
      "Action prob: [0.5974966  0.40250337], Action: 0, state: 5\n",
      "Action prob: [0.5974966  0.40250337], Action: 0, state: 5\n",
      "Action prob: [0.5974966  0.40250337], Action: 0, state: 5\n",
      "Action prob: [0.5974966  0.40250337], Action: 0, state: 5\n",
      "Action prob: [0.5974966  0.40250337], Action: 0, state: 5\n",
      "Reward for this episode 4800, loss is 0.04321362056850362\n",
      "Action prob: [0.69449145 0.30550852], Action: 0, state: 0\n",
      "Action prob: [0.6863493  0.31365076], Action: 1, state: 1\n",
      "Action prob: [0.59198856 0.40801147], Action: 1, state: 5\n",
      "Action prob: [0.59198856 0.40801147], Action: 0, state: 5\n",
      "Action prob: [0.59198856 0.40801147], Action: 1, state: 5\n",
      "Action prob: [0.685787   0.31421298], Action: 0, state: 0\n",
      "Action prob: [0.696314   0.30368602], Action: 0, state: 1\n",
      "Action prob: [0.6920283 0.3079717], Action: 0, state: 2\n",
      "Action prob: [0.69769275 0.30230728], Action: 1, state: 2\n",
      "Action prob: [0.59198856 0.40801147], Action: 0, state: 6\n",
      "Action prob: [0.59198856 0.40801147], Action: 1, state: 6\n",
      "Action prob: [0.69616264 0.30383742], Action: 0, state: 1\n",
      "Action prob: [0.689704   0.31029597], Action: 0, state: 2\n",
      "Action prob: [0.6885275 0.3114725], Action: 0, state: 2\n",
      "Action prob: [0.70724034 0.2927597 ], Action: 0, state: 3\n",
      "Action prob: [0.69467956 0.3053204 ], Action: 1, state: 3\n",
      "Action prob: [0.59198856 0.40801147], Action: 0, state: 7\n",
      "Action prob: [0.6970829  0.30291712], Action: 0, state: 2\n",
      "Action prob: [0.6989087  0.30109128], Action: 0, state: 2\n",
      "Action prob: [0.69726264 0.30273739], Action: 0, state: 2\n",
      "Action prob: [0.6877252  0.31227478], Action: 0, state: 3\n",
      "Action prob: [0.6977799  0.30222014], Action: 0, state: 3\n",
      "Action prob: [0.70382667 0.29617336], Action: 1, state: 3\n",
      "Action prob: [0.59198856 0.40801147], Action: 1, state: 7\n",
      "Action prob: [0.59198856 0.40801147], Action: 1, state: 7\n",
      "Action prob: [0.6936745  0.30632547], Action: 0, state: 2\n",
      "Action prob: [0.7202291  0.27977094], Action: 1, state: 2\n",
      "Action prob: [0.59198856 0.40801147], Action: 0, state: 6\n",
      "Action prob: [0.59198856 0.40801147], Action: 0, state: 6\n",
      "Action prob: [0.68802196 0.31197804], Action: 0, state: 1\n",
      "Action prob: [0.69571215 0.30428782], Action: 1, state: 1\n",
      "Action prob: [0.59198856 0.40801147], Action: 0, state: 5\n",
      "Reward for this episode 10700, loss is -0.026666228656982035\n",
      "Action prob: [0.7120975  0.28790244], Action: 0, state: 0\n",
      "Action prob: [0.71138734 0.28861275], Action: 0, state: 0\n",
      "Action prob: [0.6951246  0.30487546], Action: 0, state: 1\n",
      "Action prob: [0.72146374 0.2785363 ], Action: 0, state: 1\n",
      "Action prob: [0.71285355 0.28714645], Action: 0, state: 1\n",
      "Action prob: [0.72286224 0.27713782], Action: 0, state: 1\n",
      "Action prob: [0.7099056 0.2900944], Action: 0, state: 2\n",
      "Action prob: [0.74328107 0.2567189 ], Action: 0, state: 3\n",
      "Action prob: [0.7232457  0.27675426], Action: 0, state: 8\n",
      "Action prob: [0.7388045  0.26119545], Action: 0, state: 8\n",
      "Action prob: [0.7134531  0.28654692], Action: 0, state: 8\n",
      "Action prob: [0.7011582  0.29884177], Action: 1, state: 8\n",
      "Action prob: [0.7203747  0.27962524], Action: 0, state: 8\n",
      "Action prob: [0.71716905 0.28283092], Action: 0, state: 8\n",
      "Action prob: [0.7125931  0.28740692], Action: 0, state: 8\n",
      "Action prob: [0.73997664 0.26002342], Action: 0, state: 8\n",
      "Action prob: [0.73235464 0.26764542], Action: 1, state: 8\n",
      "Action prob: [0.71276015 0.28723988], Action: 1, state: 0\n",
      "Action prob: [0.5828361  0.41716397], Action: 1, state: 4\n",
      "Action prob: [0.5828361  0.41716397], Action: 1, state: 4\n",
      "Action prob: [0.7153206  0.28467944], Action: 0, state: 0\n",
      "Action prob: [0.7114419  0.28855813], Action: 1, state: 1\n",
      "Action prob: [0.5828361  0.41716397], Action: 0, state: 5\n",
      "Reward for this episode -18700, loss is 0.14166797092916084\n",
      "Action prob: [0.7224386  0.27756143], Action: 0, state: 0\n",
      "Action prob: [0.7144747  0.28552532], Action: 1, state: 0\n",
      "Action prob: [0.5715812  0.42841876], Action: 0, state: 4\n",
      "Action prob: [0.5715812  0.42841876], Action: 0, state: 4\n",
      "Action prob: [0.5715812  0.42841876], Action: 1, state: 4\n",
      "Action prob: [0.5715812  0.42841876], Action: 0, state: 4\n",
      "Action prob: [0.5715812  0.42841876], Action: 0, state: 4\n",
      "Action prob: [0.5715812  0.42841876], Action: 0, state: 4\n",
      "Action prob: [0.7226077 0.2773923], Action: 0, state: 0\n",
      "Action prob: [0.72650373 0.2734963 ], Action: 0, state: 0\n",
      "Action prob: [0.7219505 0.2780496], Action: 0, state: 0\n",
      "Action prob: [0.7188953  0.28110468], Action: 0, state: 1\n",
      "Action prob: [0.75892586 0.24107409], Action: 0, state: 9\n",
      "Action prob: [0.711352   0.28864798], Action: 0, state: 9\n",
      "Action prob: [0.74870855 0.2512914 ], Action: 0, state: 9\n",
      "Action prob: [0.7402394  0.25976062], Action: 1, state: 9\n",
      "Action prob: [0.74817646 0.25182357], Action: 1, state: 9\n",
      "Action prob: [0.74985844 0.25014153], Action: 0, state: 9\n",
      "Action prob: [0.72656775 0.2734323 ], Action: 0, state: 9\n",
      "Action prob: [0.74898446 0.25101548], Action: 0, state: 9\n",
      "Action prob: [0.7152044 0.2847956], Action: 0, state: 9\n",
      "Action prob: [0.7074483 0.2925517], Action: 0, state: 9\n",
      "Action prob: [0.7090032  0.29099682], Action: 0, state: 9\n",
      "Action prob: [0.75218    0.24782008], Action: 0, state: 9\n",
      "Action prob: [0.69624096 0.30375898], Action: 0, state: 9\n",
      "Action prob: [0.71241295 0.287587  ], Action: 0, state: 9\n",
      "Action prob: [0.707226   0.29277402], Action: 0, state: 9\n",
      "Action prob: [0.7358095 0.2641905], Action: 0, state: 9\n",
      "Action prob: [0.7350786 0.2649214], Action: 0, state: 9\n",
      "Action prob: [0.7524917 0.2475083], Action: 0, state: 9\n",
      "Action prob: [0.7300399 0.2699601], Action: 0, state: 9\n",
      "Action prob: [0.7303757  0.26962432], Action: 0, state: 9\n",
      "Action prob: [0.7514237 0.2485763], Action: 0, state: 9\n",
      "Action prob: [0.7096788  0.29032117], Action: 1, state: 9\n",
      "Action prob: [0.76586205 0.23413798], Action: 0, state: 9\n",
      "Action prob: [0.7462771  0.25372297], Action: 0, state: 9\n",
      "Action prob: [0.7106237  0.28937632], Action: 1, state: 9\n",
      "Reward for this episode -22100, loss is -0.1040762552170711\n",
      "Action prob: [0.73295057 0.26704946], Action: 0, state: 0\n",
      "Action prob: [0.7354826  0.26451743], Action: 0, state: 0\n",
      "Action prob: [0.73639345 0.26360658], Action: 0, state: 0\n",
      "Action prob: [0.7384095  0.26159048], Action: 0, state: 0\n",
      "Action prob: [0.73222816 0.26777187], Action: 1, state: 0\n",
      "Action prob: [0.5613527  0.43864733], Action: 1, state: 4\n",
      "Action prob: [0.5613527  0.43864733], Action: 1, state: 4\n",
      "Action prob: [0.74497867 0.25502133], Action: 0, state: 0\n",
      "Action prob: [0.7350536  0.26494637], Action: 1, state: 0\n",
      "Action prob: [0.5613527  0.43864733], Action: 1, state: 4\n",
      "Action prob: [0.5613527  0.43864733], Action: 1, state: 4\n",
      "Action prob: [0.5613527  0.43864733], Action: 1, state: 4\n",
      "Action prob: [0.74082524 0.25917476], Action: 0, state: 0\n",
      "Action prob: [0.73216987 0.2678301 ], Action: 0, state: 0\n",
      "Action prob: [0.72899216 0.27100787], Action: 0, state: 0\n",
      "Action prob: [0.7607728  0.23922719], Action: 1, state: 9\n",
      "Action prob: [0.7704477  0.22955233], Action: 1, state: 9\n",
      "Action prob: [0.7689062 0.2310938], Action: 0, state: 9\n",
      "Action prob: [0.7623267  0.23767334], Action: 0, state: 9\n",
      "Action prob: [0.7184131  0.28158692], Action: 0, state: 9\n",
      "Action prob: [0.7239538  0.27604625], Action: 0, state: 9\n",
      "Action prob: [0.7462833  0.25371665], Action: 1, state: 9\n",
      "Action prob: [0.7134991 0.2865008], Action: 0, state: 9\n",
      "Action prob: [0.7637179  0.23628207], Action: 0, state: 9\n",
      "Action prob: [0.7664437  0.23355623], Action: 0, state: 9\n",
      "Action prob: [0.74826574 0.2517343 ], Action: 0, state: 9\n",
      "Action prob: [0.72484016 0.2751598 ], Action: 1, state: 9\n",
      "Action prob: [0.7209079  0.27909204], Action: 0, state: 9\n",
      "Action prob: [0.7683508  0.23164922], Action: 0, state: 9\n",
      "Action prob: [0.73598504 0.264015  ], Action: 0, state: 9\n",
      "Action prob: [0.73805785 0.2619422 ], Action: 1, state: 9\n",
      "Action prob: [0.717757   0.28224307], Action: 0, state: 9\n",
      "Action prob: [0.75428414 0.2457159 ], Action: 0, state: 9\n",
      "Action prob: [0.75962836 0.24037167], Action: 0, state: 9\n",
      "Action prob: [0.76278585 0.23721416], Action: 0, state: 9\n",
      "Action prob: [0.726647 0.273353], Action: 0, state: 9\n",
      "Action prob: [0.77825415 0.22174579], Action: 0, state: 9\n",
      "Action prob: [0.7509088  0.24909121], Action: 0, state: 9\n",
      "Action prob: [0.7615305  0.23846953], Action: 0, state: 9\n",
      "Action prob: [0.7671019  0.23289816], Action: 1, state: 9\n",
      "Action prob: [0.76783586 0.23216417], Action: 1, state: 9\n",
      "Reward for this episode -18500, loss is -0.09531445607718016\n",
      "Action prob: [0.74391705 0.25608292], Action: 0, state: 0\n",
      "Action prob: [0.7484554 0.2515446], Action: 0, state: 0\n",
      "Action prob: [0.75329435 0.24670567], Action: 1, state: 0\n",
      "Action prob: [0.55466944 0.44533047], Action: 0, state: 4\n",
      "Action prob: [0.55466944 0.44533047], Action: 0, state: 4\n",
      "Action prob: [0.7525793  0.24742076], Action: 0, state: 0\n",
      "Action prob: [0.7530551  0.24694492], Action: 0, state: 1\n",
      "Action prob: [0.7504904  0.24950965], Action: 0, state: 1\n",
      "Action prob: [0.74559075 0.25440922], Action: 0, state: 1\n",
      "Action prob: [0.75339425 0.24660572], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.75518805 0.24481197], Action: 0, state: 2\n",
      "Action prob: [0.756815   0.24318501], Action: 0, state: 3\n",
      "Action prob: [0.7260513 0.2739488], Action: 0, state: 8\n",
      "Action prob: [0.7838412  0.21615882], Action: 1, state: 8\n",
      "Action prob: [0.7343059  0.26569408], Action: 0, state: 8\n",
      "Action prob: [0.7314484  0.26855162], Action: 0, state: 8\n",
      "Action prob: [0.7814168  0.21858324], Action: 0, state: 8\n",
      "Action prob: [0.78078246 0.21921752], Action: 0, state: 8\n",
      "Action prob: [0.7835484  0.21645166], Action: 0, state: 8\n",
      "Action prob: [0.7560559  0.24394406], Action: 0, state: 8\n",
      "Action prob: [0.730089 0.269911], Action: 1, state: 8\n",
      "Action prob: [0.7610287  0.23897125], Action: 0, state: 8\n",
      "Action prob: [0.7580414  0.24195859], Action: 0, state: 8\n",
      "Action prob: [0.7678102  0.23218979], Action: 0, state: 8\n",
      "Action prob: [0.75469464 0.24530537], Action: 1, state: 8\n",
      "Action prob: [0.75763017 0.2423698 ], Action: 1, state: 8\n",
      "Action prob: [0.7281807 0.2718193], Action: 1, state: 8\n",
      "Reward for this episode -37100, loss is 0.045516405355902206\n",
      "Action prob: [0.7482198  0.25178024], Action: 0, state: 0\n",
      "Action prob: [0.76163316 0.2383668 ], Action: 1, state: 1\n",
      "Action prob: [0.5497424  0.45025763], Action: 1, state: 5\n",
      "Action prob: [0.5497424  0.45025763], Action: 1, state: 5\n",
      "Action prob: [0.5497424  0.45025763], Action: 0, state: 5\n",
      "Action prob: [0.5497424  0.45025763], Action: 1, state: 5\n",
      "Action prob: [0.7543171  0.24568291], Action: 0, state: 0\n",
      "Action prob: [0.7592287  0.24077126], Action: 0, state: 0\n",
      "Action prob: [0.75748223 0.24251784], Action: 0, state: 1\n",
      "Action prob: [0.7678119  0.23218814], Action: 0, state: 2\n",
      "Action prob: [0.75642526 0.24357471], Action: 0, state: 3\n",
      "Action prob: [0.7722707  0.22772928], Action: 1, state: 8\n",
      "Action prob: [0.7606489  0.23935108], Action: 1, state: 0\n",
      "Action prob: [0.5497424  0.45025763], Action: 1, state: 4\n",
      "Action prob: [0.75785255 0.24214746], Action: 0, state: 0\n",
      "Action prob: [0.75829417 0.24170579], Action: 0, state: 1\n",
      "Action prob: [0.76504153 0.23495844], Action: 0, state: 1\n",
      "Action prob: [0.7649668  0.23503323], Action: 1, state: 1\n",
      "Action prob: [0.5497424  0.45025763], Action: 1, state: 5\n",
      "Action prob: [0.5497424  0.45025763], Action: 0, state: 5\n",
      "Action prob: [0.7625385  0.23746157], Action: 1, state: 0\n",
      "Action prob: [0.5497424  0.45025763], Action: 0, state: 4\n",
      "Action prob: [0.5497424  0.45025763], Action: 0, state: 4\n",
      "Action prob: [0.5497424  0.45025763], Action: 1, state: 4\n",
      "Action prob: [0.5497424  0.45025763], Action: 0, state: 4\n",
      "Reward for this episode 3300, loss is -0.08632388105093533\n",
      "Action prob: [0.7752696 0.2247304], Action: 0, state: 0\n",
      "Action prob: [0.7727533  0.22724675], Action: 0, state: 0\n",
      "Action prob: [0.78397053 0.21602942], Action: 0, state: 1\n",
      "Action prob: [0.76699215 0.23300782], Action: 0, state: 1\n",
      "Action prob: [0.7632509  0.23674914], Action: 0, state: 2\n",
      "Action prob: [0.77521515 0.22478487], Action: 0, state: 2\n",
      "Action prob: [0.7720492  0.22795081], Action: 0, state: 2\n",
      "Action prob: [0.78064394 0.21935607], Action: 0, state: 2\n",
      "Action prob: [0.7752421  0.22475784], Action: 0, state: 2\n",
      "Action prob: [0.77793914 0.22206083], Action: 0, state: 2\n",
      "Action prob: [0.7683772 0.2316228], Action: 0, state: 2\n",
      "Action prob: [0.7738178  0.22618222], Action: 0, state: 2\n",
      "Action prob: [0.7613222  0.23867783], Action: 0, state: 3\n",
      "Action prob: [0.776122   0.22387801], Action: 1, state: 8\n",
      "Action prob: [0.79244685 0.20755315], Action: 0, state: 0\n",
      "Action prob: [0.7791486 0.2208514], Action: 0, state: 0\n",
      "Action prob: [0.7883298  0.21167016], Action: 0, state: 0\n",
      "Action prob: [0.7874258  0.21257414], Action: 0, state: 0\n",
      "Action prob: [0.78277963 0.2172203 ], Action: 0, state: 0\n",
      "Action prob: [0.77038723 0.22961278], Action: 0, state: 0\n",
      "Action prob: [0.780518   0.21948196], Action: 1, state: 1\n",
      "Action prob: [0.5435117  0.45648834], Action: 0, state: 5\n",
      "Reward for this episode 14100, loss is -0.08343772079626956\n",
      "Action prob: [0.78958255 0.21041743], Action: 0, state: 0\n",
      "Action prob: [0.7974393  0.20256075], Action: 0, state: 0\n",
      "Action prob: [0.7924319  0.20756805], Action: 0, state: 0\n",
      "Action prob: [0.7923515  0.20764846], Action: 0, state: 0\n",
      "Action prob: [0.7849353  0.21506475], Action: 0, state: 0\n",
      "Action prob: [0.7977737  0.20222631], Action: 0, state: 0\n",
      "Action prob: [0.78571224 0.21428774], Action: 1, state: 1\n",
      "Action prob: [0.53787374 0.46212628], Action: 1, state: 5\n",
      "Action prob: [0.53787374 0.46212628], Action: 0, state: 5\n",
      "Action prob: [0.53787374 0.46212628], Action: 1, state: 5\n",
      "Action prob: [0.80420494 0.19579507], Action: 0, state: 0\n",
      "Action prob: [0.78074574 0.21925427], Action: 0, state: 0\n",
      "Action prob: [0.79347736 0.20652266], Action: 1, state: 0\n",
      "Action prob: [0.53787374 0.46212628], Action: 1, state: 4\n",
      "Action prob: [0.7895793  0.21042071], Action: 0, state: 0\n",
      "Action prob: [0.78545326 0.2145467 ], Action: 0, state: 0\n",
      "Action prob: [0.78991616 0.21008387], Action: 0, state: 1\n",
      "Action prob: [0.78771126 0.21228874], Action: 0, state: 2\n",
      "Action prob: [0.79196924 0.20803078], Action: 1, state: 2\n",
      "Action prob: [0.53787374 0.46212628], Action: 1, state: 6\n",
      "Action prob: [0.53787374 0.46212628], Action: 1, state: 6\n",
      "Action prob: [0.53787374 0.46212628], Action: 1, state: 6\n",
      "Action prob: [0.7882351  0.21176489], Action: 0, state: 1\n",
      "Action prob: [0.78096664 0.21903339], Action: 0, state: 1\n",
      "Action prob: [0.7927169  0.20728308], Action: 1, state: 2\n",
      "Action prob: [0.53787374 0.46212628], Action: 0, state: 6\n",
      "Action prob: [0.53787374 0.46212628], Action: 0, state: 6\n",
      "Action prob: [0.78974766 0.21025234], Action: 0, state: 1\n",
      "Action prob: [0.78416383 0.21583624], Action: 0, state: 1\n",
      "Action prob: [0.78826743 0.21173255], Action: 0, state: 1\n",
      "Action prob: [0.79713416 0.2028658 ], Action: 0, state: 1\n",
      "Action prob: [0.78430927 0.21569078], Action: 0, state: 2\n",
      "Action prob: [0.7783321  0.22166792], Action: 0, state: 3\n",
      "Action prob: [0.76852655 0.23147342], Action: 0, state: 8\n",
      "Action prob: [0.76483977 0.23516029], Action: 1, state: 8\n",
      "Action prob: [0.76833874 0.23166125], Action: 0, state: 8\n",
      "Action prob: [0.7809545 0.2190455], Action: 0, state: 8\n",
      "Action prob: [0.7738312  0.22616883], Action: 0, state: 8\n",
      "Action prob: [0.7761406  0.22385946], Action: 0, state: 8\n",
      "Action prob: [0.7662601  0.23373987], Action: 0, state: 8\n",
      "Action prob: [0.8211177  0.17888233], Action: 0, state: 8\n",
      "Action prob: [0.77423304 0.22576699], Action: 0, state: 8\n",
      "Action prob: [0.8277058  0.17229414], Action: 0, state: 8\n",
      "Action prob: [0.80371547 0.19628456], Action: 0, state: 8\n",
      "Action prob: [0.76682335 0.23317663], Action: 0, state: 8\n",
      "Action prob: [0.8213904  0.17860956], Action: 0, state: 8\n",
      "Action prob: [0.7665699 0.2334301], Action: 0, state: 8\n",
      "Action prob: [0.81042355 0.18957648], Action: 1, state: 8\n",
      "Action prob: [0.78117245 0.21882749], Action: 0, state: 8\n",
      "Action prob: [0.8157152  0.18428475], Action: 0, state: 8\n",
      "Reward for this episode -37600, loss is -0.07410966868225484\n",
      "Action prob: [0.8108643  0.18913566], Action: 0, state: 0\n",
      "Action prob: [0.79746425 0.20253567], Action: 0, state: 0\n",
      "Action prob: [0.8030126  0.19698733], Action: 0, state: 0\n",
      "Action prob: [0.80290085 0.1970991 ], Action: 1, state: 0\n",
      "Action prob: [0.53321236 0.4667876 ], Action: 0, state: 4\n",
      "Action prob: [0.80925757 0.1907424 ], Action: 0, state: 0\n",
      "Action prob: [0.80335313 0.19664685], Action: 0, state: 1\n",
      "Action prob: [0.79041415 0.20958582], Action: 0, state: 1\n",
      "Action prob: [0.8021374  0.19786265], Action: 0, state: 2\n",
      "Action prob: [0.8163863  0.18361375], Action: 0, state: 2\n",
      "Action prob: [0.8036173  0.19638275], Action: 0, state: 2\n",
      "Action prob: [0.81039625 0.18960375], Action: 0, state: 3\n",
      "Action prob: [0.8082007 0.1917993], Action: 0, state: 3\n",
      "Action prob: [0.79736227 0.20263779], Action: 0, state: 3\n",
      "Action prob: [0.8057202  0.19427978], Action: 0, state: 3\n",
      "Action prob: [0.78495616 0.21504383], Action: 0, state: 3\n",
      "Action prob: [0.8037106 0.1962894], Action: 0, state: 3\n",
      "Action prob: [0.8164731  0.18352686], Action: 0, state: 8\n",
      "Action prob: [0.83059686 0.16940309], Action: 0, state: 8\n",
      "Action prob: [0.78917855 0.21082146], Action: 0, state: 8\n",
      "Action prob: [0.8042538  0.19574614], Action: 0, state: 8\n",
      "Action prob: [0.8142844  0.18571557], Action: 0, state: 8\n",
      "Action prob: [0.8247963 0.1752037], Action: 0, state: 8\n",
      "Action prob: [0.81210804 0.18789199], Action: 0, state: 8\n",
      "Action prob: [0.81865805 0.18134193], Action: 0, state: 8\n",
      "Action prob: [0.8325061  0.16749388], Action: 0, state: 8\n",
      "Action prob: [0.7763404  0.22365963], Action: 0, state: 8\n",
      "Action prob: [0.7879032  0.21209684], Action: 0, state: 8\n",
      "Action prob: [0.8209468  0.17905319], Action: 0, state: 8\n",
      "Action prob: [0.8237488  0.17625117], Action: 0, state: 8\n",
      "Action prob: [0.80827516 0.19172476], Action: 0, state: 8\n",
      "Action prob: [0.81954044 0.18045948], Action: 0, state: 8\n",
      "Action prob: [0.76266617 0.23733383], Action: 0, state: 8\n",
      "Action prob: [0.77887285 0.22112715], Action: 0, state: 8\n",
      "Action prob: [0.80747646 0.19252355], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.81328875 0.18671131], Action: 0, state: 8\n",
      "Action prob: [0.8274154  0.17258456], Action: 1, state: 8\n",
      "Action prob: [0.7840366  0.21596341], Action: 0, state: 8\n",
      "Action prob: [0.83433896 0.16566111], Action: 0, state: 8\n",
      "Action prob: [0.7784653  0.22153476], Action: 0, state: 8\n",
      "Action prob: [0.83423096 0.165769  ], Action: 0, state: 8\n",
      "Action prob: [0.8220647 0.1779353], Action: 0, state: 8\n",
      "Action prob: [0.82412845 0.1758716 ], Action: 0, state: 8\n",
      "Action prob: [0.82136923 0.17863077], Action: 0, state: 8\n",
      "Action prob: [0.8321917 0.1678083], Action: 0, state: 8\n",
      "Action prob: [0.83748007 0.16251993], Action: 0, state: 8\n",
      "Action prob: [0.82203335 0.17796662], Action: 1, state: 8\n",
      "Action prob: [0.82791305 0.17208694], Action: 0, state: 8\n",
      "Action prob: [0.8084532  0.19154681], Action: 0, state: 8\n",
      "Action prob: [0.84374    0.15626003], Action: 0, state: 8\n",
      "Reward for this episode -91300, loss is 0.02493903779489678\n",
      "Action prob: [0.8095774  0.19042255], Action: 0, state: 0\n",
      "Action prob: [0.8156636  0.18433641], Action: 0, state: 1\n",
      "Action prob: [0.82015383 0.17984615], Action: 0, state: 2\n",
      "Action prob: [0.81119996 0.18880008], Action: 0, state: 2\n",
      "Action prob: [0.8133091  0.18669099], Action: 0, state: 2\n",
      "Action prob: [0.8294055  0.17059447], Action: 0, state: 3\n",
      "Action prob: [0.85430145 0.14569853], Action: 1, state: 8\n",
      "Action prob: [0.81266344 0.18733658], Action: 0, state: 0\n",
      "Action prob: [0.80260825 0.19739176], Action: 0, state: 1\n",
      "Action prob: [0.8227106  0.17728941], Action: 0, state: 2\n",
      "Action prob: [0.8270414  0.17295861], Action: 0, state: 2\n",
      "Action prob: [0.82314634 0.17685364], Action: 0, state: 3\n",
      "Action prob: [0.8369335 0.1630665], Action: 0, state: 8\n",
      "Action prob: [0.8025717 0.1974283], Action: 0, state: 8\n",
      "Action prob: [0.8101644  0.18983562], Action: 0, state: 8\n",
      "Action prob: [0.8429277  0.15707235], Action: 0, state: 8\n",
      "Action prob: [0.7905679  0.20943215], Action: 1, state: 8\n",
      "Action prob: [0.8400297  0.15997034], Action: 0, state: 8\n",
      "Action prob: [0.8389903  0.16100971], Action: 0, state: 8\n",
      "Action prob: [0.84519887 0.15480117], Action: 0, state: 8\n",
      "Action prob: [0.80757487 0.19242518], Action: 0, state: 8\n",
      "Action prob: [0.80295527 0.1970447 ], Action: 0, state: 8\n",
      "Action prob: [0.8323794  0.16762063], Action: 0, state: 8\n",
      "Action prob: [0.82223827 0.17776175], Action: 0, state: 8\n",
      "Action prob: [0.8287309 0.1712691], Action: 0, state: 8\n",
      "Action prob: [0.8305342  0.16946577], Action: 0, state: 8\n",
      "Action prob: [0.7856471  0.21435286], Action: 1, state: 8\n",
      "Action prob: [0.84490407 0.1550959 ], Action: 0, state: 8\n",
      "Action prob: [0.830526 0.169474], Action: 0, state: 8\n",
      "Action prob: [0.8450234  0.15497667], Action: 0, state: 8\n",
      "Action prob: [0.8141453  0.18585473], Action: 0, state: 8\n",
      "Action prob: [0.8391795  0.16082048], Action: 0, state: 8\n",
      "Action prob: [0.8171488 0.1828512], Action: 0, state: 8\n",
      "Action prob: [0.8400723  0.15992771], Action: 0, state: 8\n",
      "Action prob: [0.843121   0.15687896], Action: 0, state: 8\n",
      "Action prob: [0.7862622  0.21373779], Action: 1, state: 8\n",
      "Action prob: [0.8421839  0.15781614], Action: 0, state: 8\n",
      "Action prob: [0.8399682  0.16003174], Action: 0, state: 8\n",
      "Action prob: [0.83360416 0.16639583], Action: 0, state: 8\n",
      "Action prob: [0.80214334 0.19785671], Action: 1, state: 8\n",
      "Action prob: [0.8374619  0.16253808], Action: 1, state: 8\n",
      "Reward for this episode -81200, loss is 0.05410381515657678\n",
      "Action prob: [0.8237052 0.1762948], Action: 0, state: 0\n",
      "Action prob: [0.81219846 0.18780152], Action: 0, state: 0\n",
      "Action prob: [0.8142847  0.18571523], Action: 0, state: 0\n",
      "Action prob: [0.819953   0.18004704], Action: 0, state: 0\n",
      "Action prob: [0.822316   0.17768404], Action: 0, state: 0\n",
      "Action prob: [0.82380164 0.17619836], Action: 0, state: 1\n",
      "Action prob: [0.8288169  0.17118311], Action: 0, state: 2\n",
      "Action prob: [0.8229957  0.17700425], Action: 0, state: 3\n",
      "Action prob: [0.8047019  0.19529806], Action: 0, state: 3\n",
      "Action prob: [0.8217862  0.17821382], Action: 0, state: 3\n",
      "Action prob: [0.8179394  0.18206063], Action: 0, state: 3\n",
      "Action prob: [0.82758796 0.172412  ], Action: 1, state: 3\n",
      "Action prob: [0.5260338  0.47396615], Action: 1, state: 7\n",
      "Action prob: [0.5260338  0.47396615], Action: 1, state: 7\n",
      "Action prob: [0.81929106 0.18070891], Action: 0, state: 2\n",
      "Action prob: [0.8291069 0.1708931], Action: 0, state: 2\n",
      "Action prob: [0.8173063  0.18269372], Action: 0, state: 2\n",
      "Action prob: [0.82527155 0.17472848], Action: 0, state: 2\n",
      "Action prob: [0.8260488  0.17395125], Action: 0, state: 3\n",
      "Action prob: [0.8195281  0.18047188], Action: 0, state: 3\n",
      "Action prob: [0.82353383 0.1764661 ], Action: 0, state: 3\n",
      "Action prob: [0.8240019  0.17599812], Action: 0, state: 3\n",
      "Action prob: [0.841826   0.15817398], Action: 0, state: 8\n",
      "Action prob: [0.80443025 0.19556981], Action: 0, state: 8\n",
      "Action prob: [0.85266274 0.14733727], Action: 0, state: 8\n",
      "Action prob: [0.86169916 0.13830084], Action: 0, state: 8\n",
      "Action prob: [0.79899716 0.20100282], Action: 0, state: 8\n",
      "Action prob: [0.83440584 0.16559416], Action: 0, state: 8\n",
      "Action prob: [0.846406   0.15359394], Action: 0, state: 8\n",
      "Action prob: [0.8009379  0.19906205], Action: 0, state: 8\n",
      "Action prob: [0.8413027  0.15869735], Action: 0, state: 8\n",
      "Action prob: [0.8479613  0.15203875], Action: 0, state: 8\n",
      "Action prob: [0.845142 0.154858], Action: 0, state: 8\n",
      "Action prob: [0.8499446  0.15005541], Action: 0, state: 8\n",
      "Action prob: [0.79577905 0.20422088], Action: 1, state: 8\n",
      "Reward for this episode -25600, loss is -0.05093401389707545\n",
      "Action prob: [0.8260358  0.17396428], Action: 1, state: 0\n",
      "Action prob: [0.52358276 0.47641727], Action: 0, state: 4\n",
      "Action prob: [0.52358276 0.47641727], Action: 1, state: 4\n",
      "Action prob: [0.52358276 0.47641727], Action: 1, state: 4\n",
      "Action prob: [0.52358276 0.47641727], Action: 1, state: 4\n",
      "Action prob: [0.8346333  0.16536666], Action: 0, state: 0\n",
      "Action prob: [0.82931006 0.17068993], Action: 0, state: 0\n",
      "Action prob: [0.84671456 0.15328538], Action: 0, state: 0\n",
      "Action prob: [0.8315585  0.16844144], Action: 0, state: 0\n",
      "Action prob: [0.8334391  0.16656092], Action: 0, state: 0\n",
      "Action prob: [0.82880783 0.17119212], Action: 0, state: 0\n",
      "Action prob: [0.8304805  0.16951951], Action: 0, state: 0\n",
      "Action prob: [0.8574709  0.14252904], Action: 0, state: 9\n",
      "Action prob: [0.8454862  0.15451379], Action: 0, state: 9\n",
      "Action prob: [0.8490296  0.15097032], Action: 0, state: 9\n",
      "Action prob: [0.838034 0.161966], Action: 0, state: 9\n",
      "Action prob: [0.859      0.14099997], Action: 1, state: 9\n",
      "Action prob: [0.86351424 0.13648577], Action: 0, state: 9\n",
      "Action prob: [0.846031   0.15396896], Action: 0, state: 9\n",
      "Action prob: [0.85216105 0.14783889], Action: 0, state: 9\n",
      "Action prob: [0.813894   0.18610604], Action: 1, state: 9\n",
      "Action prob: [0.8351996  0.16480042], Action: 1, state: 9\n",
      "Reward for this episode -4000, loss is 0.009499231817482932\n",
      "Action prob: [0.84035975 0.15964024], Action: 0, state: 0\n",
      "Action prob: [0.8408309  0.15916902], Action: 1, state: 1\n",
      "Action prob: [0.5165796  0.48342043], Action: 1, state: 5\n",
      "Action prob: [0.84065104 0.15934895], Action: 0, state: 0\n",
      "Action prob: [0.82989585 0.17010418], Action: 0, state: 0\n",
      "Action prob: [0.8373586  0.16264138], Action: 0, state: 0\n",
      "Action prob: [0.83276546 0.16723454], Action: 0, state: 1\n",
      "Action prob: [0.8449078  0.15509221], Action: 0, state: 2\n",
      "Action prob: [0.84446526 0.15553471], Action: 0, state: 2\n",
      "Action prob: [0.84208137 0.15791868], Action: 0, state: 2\n",
      "Action prob: [0.84511566 0.15488428], Action: 0, state: 2\n",
      "Action prob: [0.8417282  0.15827182], Action: 0, state: 3\n",
      "Action prob: [0.8625618  0.13743813], Action: 0, state: 9\n",
      "Action prob: [0.8287276  0.17127243], Action: 1, state: 9\n",
      "Action prob: [0.86515045 0.13484947], Action: 1, state: 9\n",
      "Action prob: [0.82104117 0.17895883], Action: 0, state: 9\n",
      "Action prob: [0.873376   0.12662402], Action: 0, state: 9\n",
      "Action prob: [0.8574639  0.14253612], Action: 0, state: 9\n",
      "Action prob: [0.8692179  0.13078208], Action: 0, state: 9\n",
      "Action prob: [0.87385076 0.12614924], Action: 0, state: 9\n",
      "Action prob: [0.84386075 0.15613924], Action: 0, state: 9\n",
      "Action prob: [0.8623509 0.1376491], Action: 0, state: 9\n",
      "Action prob: [0.8354986  0.16450146], Action: 0, state: 9\n",
      "Action prob: [0.8193662  0.18063383], Action: 0, state: 9\n",
      "Action prob: [0.8658649  0.13413507], Action: 0, state: 9\n",
      "Action prob: [0.8673959  0.13260415], Action: 0, state: 9\n",
      "Action prob: [0.86361706 0.13638297], Action: 0, state: 9\n",
      "Action prob: [0.8521828  0.14781725], Action: 0, state: 9\n",
      "Action prob: [0.82254934 0.17745064], Action: 0, state: 9\n",
      "Action prob: [0.8652821  0.13471787], Action: 0, state: 9\n",
      "Action prob: [0.8277859  0.17221405], Action: 0, state: 9\n",
      "Action prob: [0.8177222  0.18227783], Action: 0, state: 9\n",
      "Action prob: [0.8171172  0.18288279], Action: 0, state: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.8547701  0.14522988], Action: 0, state: 9\n",
      "Action prob: [0.8218496 0.1781504], Action: 0, state: 9\n",
      "Action prob: [0.8132692  0.18673082], Action: 0, state: 9\n",
      "Action prob: [0.8663796  0.13362044], Action: 0, state: 9\n",
      "Action prob: [0.8389516  0.16104838], Action: 0, state: 9\n",
      "Action prob: [0.86713874 0.1328613 ], Action: 0, state: 9\n",
      "Action prob: [0.84972256 0.15027747], Action: 0, state: 9\n",
      "Action prob: [0.82345796 0.17654204], Action: 1, state: 9\n",
      "Action prob: [0.8591732  0.14082679], Action: 0, state: 9\n",
      "Action prob: [0.87287825 0.1271217 ], Action: 0, state: 9\n",
      "Action prob: [0.81832033 0.1816797 ], Action: 0, state: 9\n",
      "Action prob: [0.8701974  0.12980257], Action: 0, state: 9\n",
      "Action prob: [0.82144517 0.17855477], Action: 0, state: 9\n",
      "Action prob: [0.86745095 0.13254903], Action: 1, state: 9\n",
      "Action prob: [0.85948247 0.14051759], Action: 0, state: 9\n",
      "Action prob: [0.86568457 0.13431546], Action: 0, state: 9\n",
      "Action prob: [0.848444   0.15155599], Action: 0, state: 9\n",
      "Reward for this episode -31000, loss is 0.05831658326036199\n",
      "Action prob: [0.8353337  0.16466631], Action: 0, state: 0\n",
      "Action prob: [0.85370356 0.14629647], Action: 1, state: 0\n",
      "Action prob: [0.50896937 0.49103063], Action: 1, state: 4\n",
      "Action prob: [0.845627   0.15437302], Action: 0, state: 0\n",
      "Action prob: [0.8399774  0.16002259], Action: 0, state: 1\n",
      "Action prob: [0.8428623  0.15713768], Action: 0, state: 1\n",
      "Action prob: [0.863865   0.13613494], Action: 0, state: 2\n",
      "Action prob: [0.84497035 0.15502965], Action: 0, state: 2\n",
      "Action prob: [0.8397334  0.16026658], Action: 0, state: 2\n",
      "Action prob: [0.8585821 0.1414179], Action: 0, state: 3\n",
      "Action prob: [0.8640327  0.13596736], Action: 0, state: 8\n",
      "Action prob: [0.85978925 0.14021075], Action: 0, state: 8\n",
      "Action prob: [0.8655637  0.13443628], Action: 0, state: 8\n",
      "Action prob: [0.8233584  0.17664157], Action: 1, state: 8\n",
      "Action prob: [0.86099154 0.13900845], Action: 0, state: 8\n",
      "Action prob: [0.8709152  0.12908481], Action: 0, state: 8\n",
      "Action prob: [0.8713947 0.1286053], Action: 0, state: 8\n",
      "Action prob: [0.82982355 0.17017648], Action: 0, state: 8\n",
      "Action prob: [0.8389992  0.16100073], Action: 0, state: 8\n",
      "Action prob: [0.8378453  0.16215461], Action: 0, state: 8\n",
      "Action prob: [0.8462472  0.15375279], Action: 0, state: 8\n",
      "Action prob: [0.82581294 0.1741871 ], Action: 0, state: 8\n",
      "Action prob: [0.8942833  0.10571671], Action: 0, state: 8\n",
      "Action prob: [0.8213519  0.17864813], Action: 0, state: 8\n",
      "Action prob: [0.8585013  0.14149864], Action: 0, state: 8\n",
      "Action prob: [0.8234362  0.17656384], Action: 1, state: 8\n",
      "Action prob: [0.8392492  0.16075076], Action: 0, state: 8\n",
      "Action prob: [0.82964885 0.17035116], Action: 0, state: 8\n",
      "Action prob: [0.860171   0.13982894], Action: 0, state: 8\n",
      "Action prob: [0.81995463 0.18004535], Action: 1, state: 8\n",
      "Action prob: [0.83020186 0.16979815], Action: 0, state: 8\n",
      "Action prob: [0.8868398  0.11316015], Action: 0, state: 8\n",
      "Action prob: [0.86213315 0.13786685], Action: 0, state: 8\n",
      "Action prob: [0.84006816 0.15993184], Action: 0, state: 8\n",
      "Action prob: [0.8800597  0.11994021], Action: 0, state: 8\n",
      "Action prob: [0.8082314  0.19176856], Action: 0, state: 8\n",
      "Action prob: [0.8198776 0.1801224], Action: 0, state: 8\n",
      "Action prob: [0.85175204 0.14824791], Action: 0, state: 8\n",
      "Action prob: [0.8209006  0.17909932], Action: 0, state: 8\n",
      "Action prob: [0.8737469  0.12625307], Action: 0, state: 8\n",
      "Action prob: [0.8707907  0.12920934], Action: 0, state: 8\n",
      "Action prob: [0.8644208  0.13557926], Action: 0, state: 8\n",
      "Action prob: [0.83191705 0.16808295], Action: 0, state: 8\n",
      "Action prob: [0.82388747 0.17611256], Action: 0, state: 8\n",
      "Action prob: [0.8731927  0.12680729], Action: 0, state: 8\n",
      "Action prob: [0.85505843 0.1449416 ], Action: 0, state: 8\n",
      "Action prob: [0.8617139  0.13828613], Action: 0, state: 8\n",
      "Action prob: [0.81411266 0.1858873 ], Action: 0, state: 8\n",
      "Action prob: [0.8274006  0.17259936], Action: 0, state: 8\n",
      "Action prob: [0.858778 0.141222], Action: 0, state: 8\n",
      "Reward for this episode -116800, loss is 0.01643092061042665\n",
      "Action prob: [0.84965825 0.15034173], Action: 0, state: 0\n",
      "Action prob: [0.8424422  0.15755777], Action: 0, state: 0\n",
      "Action prob: [0.8646143  0.13538569], Action: 0, state: 1\n",
      "Action prob: [0.85175776 0.14824222], Action: 0, state: 1\n",
      "Action prob: [0.8522869  0.14771308], Action: 0, state: 1\n",
      "Action prob: [0.85527134 0.14472869], Action: 0, state: 1\n",
      "Action prob: [0.84843254 0.15156741], Action: 1, state: 2\n",
      "Action prob: [0.50155485 0.4984452 ], Action: 0, state: 6\n",
      "Action prob: [0.85801226 0.14198777], Action: 0, state: 1\n",
      "Action prob: [0.84816825 0.15183176], Action: 0, state: 2\n",
      "Action prob: [0.8623941  0.13760594], Action: 0, state: 2\n",
      "Action prob: [0.8499866  0.15001334], Action: 0, state: 3\n",
      "Action prob: [0.8626814 0.1373186], Action: 0, state: 3\n",
      "Action prob: [0.8538417  0.14615831], Action: 0, state: 3\n",
      "Action prob: [0.84805274 0.1519472 ], Action: 1, state: 3\n",
      "Action prob: [0.50155485 0.4984452 ], Action: 1, state: 7\n",
      "Action prob: [0.50155485 0.4984452 ], Action: 1, state: 7\n",
      "Action prob: [0.50155485 0.4984452 ], Action: 0, state: 7\n",
      "Action prob: [0.50155485 0.4984452 ], Action: 0, state: 7\n",
      "Action prob: [0.50155485 0.4984452 ], Action: 1, state: 7\n",
      "Action prob: [0.86088985 0.13911012], Action: 0, state: 2\n",
      "Action prob: [0.84826463 0.1517353 ], Action: 0, state: 2\n",
      "Action prob: [0.8633194  0.13668056], Action: 0, state: 9\n",
      "Action prob: [0.8784786  0.12152137], Action: 0, state: 9\n",
      "Action prob: [0.88384825 0.11615174], Action: 1, state: 9\n",
      "Action prob: [0.901201   0.09879895], Action: 0, state: 9\n",
      "Action prob: [0.87540656 0.12459338], Action: 0, state: 9\n",
      "Action prob: [0.87741125 0.12258877], Action: 1, state: 9\n",
      "Action prob: [0.82630485 0.17369513], Action: 0, state: 9\n",
      "Action prob: [0.8726409  0.12735905], Action: 0, state: 9\n",
      "Action prob: [0.87015253 0.12984748], Action: 0, state: 9\n",
      "Action prob: [0.8232542  0.17674583], Action: 0, state: 9\n",
      "Action prob: [0.8340012  0.16599886], Action: 0, state: 9\n",
      "Action prob: [0.8593821  0.14061794], Action: 0, state: 9\n",
      "Action prob: [0.8685327  0.13146728], Action: 0, state: 9\n",
      "Action prob: [0.86365575 0.13634427], Action: 0, state: 9\n",
      "Action prob: [0.8369964  0.16300362], Action: 0, state: 9\n",
      "Action prob: [0.88222694 0.11777306], Action: 0, state: 9\n",
      "Action prob: [0.82729644 0.1727036 ], Action: 1, state: 9\n",
      "Action prob: [0.8209943  0.17900562], Action: 0, state: 9\n",
      "Action prob: [0.86432433 0.13567567], Action: 0, state: 9\n",
      "Action prob: [0.8281398  0.17186017], Action: 0, state: 9\n",
      "Action prob: [0.86985064 0.13014938], Action: 0, state: 9\n",
      "Action prob: [0.82311404 0.1768859 ], Action: 0, state: 9\n",
      "Action prob: [0.8554008  0.14459918], Action: 1, state: 9\n",
      "Reward for this episode -13500, loss is -0.10434781379817634\n",
      "Action prob: [0.8595094  0.14049058], Action: 0, state: 0\n",
      "Action prob: [0.8526145  0.14738552], Action: 1, state: 0\n",
      "Action prob: [0.49554813 0.5044518 ], Action: 0, state: 4\n",
      "Action prob: [0.49554813 0.5044518 ], Action: 0, state: 4\n",
      "Action prob: [0.87981004 0.12018991], Action: 0, state: 0\n",
      "Action prob: [0.8595286  0.14047144], Action: 0, state: 1\n",
      "Action prob: [0.8576098  0.14239024], Action: 0, state: 1\n",
      "Action prob: [0.8348397  0.16516027], Action: 0, state: 1\n",
      "Action prob: [0.8598863  0.14011367], Action: 0, state: 1\n",
      "Action prob: [0.8495137  0.15048628], Action: 0, state: 1\n",
      "Action prob: [0.8713116  0.12868838], Action: 0, state: 1\n",
      "Action prob: [0.8541437  0.14585634], Action: 0, state: 1\n",
      "Action prob: [0.86269546 0.1373046 ], Action: 0, state: 1\n",
      "Action prob: [0.8644737 0.1355263], Action: 0, state: 1\n",
      "Action prob: [0.85775965 0.14224033], Action: 0, state: 2\n",
      "Action prob: [0.8612031  0.13879691], Action: 1, state: 3\n",
      "Action prob: [0.49554813 0.5044518 ], Action: 0, state: 7\n",
      "Action prob: [0.8645636 0.1354364], Action: 1, state: 2\n",
      "Action prob: [0.49554813 0.5044518 ], Action: 1, state: 6\n",
      "Action prob: [0.49554813 0.5044518 ], Action: 1, state: 6\n",
      "Action prob: [0.49554813 0.5044518 ], Action: 1, state: 6\n",
      "Action prob: [0.49554813 0.5044518 ], Action: 1, state: 6\n",
      "Action prob: [0.49554813 0.5044518 ], Action: 0, state: 6\n",
      "Action prob: [0.8804401  0.11955983], Action: 0, state: 1\n",
      "Action prob: [0.86584324 0.1341567 ], Action: 0, state: 1\n",
      "Action prob: [0.8533891  0.14661092], Action: 0, state: 1\n",
      "Action prob: [0.85478336 0.14521663], Action: 0, state: 2\n",
      "Action prob: [0.85929275 0.14070727], Action: 1, state: 3\n",
      "Action prob: [0.49554813 0.5044518 ], Action: 0, state: 7\n",
      "Action prob: [0.49554813 0.5044518 ], Action: 1, state: 7\n",
      "Action prob: [0.8578891  0.14211084], Action: 0, state: 2\n",
      "Action prob: [0.85340154 0.14659847], Action: 0, state: 2\n",
      "Action prob: [0.8588885  0.14111145], Action: 0, state: 3\n",
      "Action prob: [0.8785647  0.12143526], Action: 0, state: 8\n",
      "Action prob: [0.86671287 0.13328709], Action: 0, state: 8\n",
      "Action prob: [0.83009535 0.16990468], Action: 0, state: 8\n",
      "Action prob: [0.8778629  0.12213715], Action: 0, state: 8\n",
      "Action prob: [0.87977433 0.1202257 ], Action: 0, state: 8\n",
      "Action prob: [0.8699065  0.13009353], Action: 0, state: 8\n",
      "Action prob: [0.8826923  0.11730772], Action: 0, state: 8\n",
      "Action prob: [0.88097477 0.11902524], Action: 0, state: 8\n",
      "Action prob: [0.8320832  0.16791679], Action: 1, state: 8\n",
      "Action prob: [0.8659978  0.13400216], Action: 1, state: 8\n",
      "Action prob: [0.89058244 0.10941754], Action: 0, state: 8\n",
      "Action prob: [0.84028524 0.15971479], Action: 0, state: 8\n",
      "Action prob: [0.88826144 0.11173855], Action: 0, state: 8\n",
      "Action prob: [0.8802837  0.11971628], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.80866534 0.19133465], Action: 0, state: 8\n",
      "Action prob: [0.87551    0.12448999], Action: 0, state: 8\n",
      "Action prob: [0.8894114  0.11058863], Action: 0, state: 8\n",
      "Reward for this episode -40700, loss is -0.005236349085091734\n",
      "Action prob: [0.86859137 0.13140859], Action: 0, state: 0\n",
      "Action prob: [0.8643074 0.1356926], Action: 0, state: 1\n",
      "Action prob: [0.86757565 0.13242435], Action: 0, state: 1\n",
      "Action prob: [0.8680572  0.13194281], Action: 0, state: 2\n",
      "Action prob: [0.871663   0.12833704], Action: 0, state: 3\n",
      "Action prob: [0.86571974 0.13428025], Action: 0, state: 3\n",
      "Action prob: [0.87006354 0.12993649], Action: 0, state: 3\n",
      "Action prob: [0.8812337  0.11876627], Action: 0, state: 3\n",
      "Action prob: [0.872927   0.12707298], Action: 0, state: 3\n",
      "Action prob: [0.8614194  0.13858056], Action: 0, state: 3\n",
      "Action prob: [0.88841224 0.1115877 ], Action: 0, state: 8\n",
      "Action prob: [0.8860684 0.1139316], Action: 0, state: 8\n",
      "Action prob: [0.9078782  0.09212176], Action: 0, state: 8\n",
      "Action prob: [0.8389319 0.1610681], Action: 0, state: 8\n",
      "Action prob: [0.8824067  0.11759334], Action: 0, state: 8\n",
      "Action prob: [0.9096657  0.09033423], Action: 0, state: 8\n",
      "Action prob: [0.8494007  0.15059936], Action: 0, state: 8\n",
      "Action prob: [0.8799162  0.12008378], Action: 0, state: 8\n",
      "Action prob: [0.8913266  0.10867345], Action: 0, state: 8\n",
      "Action prob: [0.8579876  0.14201246], Action: 1, state: 8\n",
      "Action prob: [0.8477143  0.15228564], Action: 1, state: 8\n",
      "Action prob: [0.86221766 0.13778235], Action: 0, state: 8\n",
      "Action prob: [0.8872375  0.11276248], Action: 0, state: 8\n",
      "Action prob: [0.87700236 0.12299769], Action: 0, state: 8\n",
      "Action prob: [0.8852922  0.11470783], Action: 0, state: 8\n",
      "Action prob: [0.89759797 0.10240196], Action: 0, state: 8\n",
      "Action prob: [0.85001993 0.14998002], Action: 1, state: 8\n",
      "Action prob: [0.87126154 0.12873851], Action: 0, state: 8\n",
      "Action prob: [0.88348633 0.11651373], Action: 0, state: 8\n",
      "Action prob: [0.87974125 0.12025879], Action: 0, state: 8\n",
      "Action prob: [0.8459852  0.15401477], Action: 0, state: 8\n",
      "Action prob: [0.8489761 0.1510239], Action: 0, state: 8\n",
      "Action prob: [0.8813642  0.11863579], Action: 0, state: 8\n",
      "Action prob: [0.86033535 0.13966459], Action: 0, state: 8\n",
      "Action prob: [0.8816669  0.11833313], Action: 0, state: 8\n",
      "Action prob: [0.8856467  0.11435337], Action: 0, state: 8\n",
      "Action prob: [0.86298335 0.13701668], Action: 0, state: 8\n",
      "Action prob: [0.8755418  0.12445824], Action: 0, state: 8\n",
      "Action prob: [0.84559375 0.1544063 ], Action: 0, state: 8\n",
      "Action prob: [0.88961047 0.11038945], Action: 0, state: 8\n",
      "Action prob: [0.8804193  0.11958068], Action: 0, state: 8\n",
      "Action prob: [0.83641243 0.16358751], Action: 0, state: 8\n",
      "Action prob: [0.8797782  0.12022178], Action: 0, state: 8\n",
      "Action prob: [0.8956662 0.1043338], Action: 0, state: 8\n",
      "Action prob: [0.8399324  0.16006762], Action: 0, state: 8\n",
      "Action prob: [0.8460028  0.15399717], Action: 1, state: 8\n",
      "Reward for this episode -101400, loss is 0.05853240413232946\n",
      "Action prob: [0.8867642  0.11323579], Action: 0, state: 0\n",
      "Action prob: [0.869908   0.13009205], Action: 0, state: 0\n",
      "Action prob: [0.87489593 0.12510411], Action: 0, state: 0\n",
      "Action prob: [0.8636716  0.13632841], Action: 0, state: 1\n",
      "Action prob: [0.8790387  0.12096131], Action: 0, state: 1\n",
      "Action prob: [0.85909456 0.14090548], Action: 0, state: 1\n",
      "Action prob: [0.8762151  0.12378488], Action: 0, state: 2\n",
      "Action prob: [0.86163145 0.13836853], Action: 0, state: 2\n",
      "Action prob: [0.87721825 0.12278173], Action: 0, state: 3\n",
      "Action prob: [0.8743711  0.12562887], Action: 0, state: 3\n",
      "Action prob: [0.86970544 0.13029453], Action: 0, state: 3\n",
      "Action prob: [0.8787733  0.12122668], Action: 1, state: 3\n",
      "Action prob: [0.4911443  0.50885576], Action: 0, state: 7\n",
      "Action prob: [0.4911443  0.50885576], Action: 1, state: 7\n",
      "Action prob: [0.4911443  0.50885576], Action: 1, state: 7\n",
      "Action prob: [0.4911443  0.50885576], Action: 0, state: 7\n",
      "Action prob: [0.4911443  0.50885576], Action: 1, state: 7\n",
      "Action prob: [0.4911443  0.50885576], Action: 0, state: 7\n",
      "Action prob: [0.8590304  0.14096962], Action: 0, state: 2\n",
      "Action prob: [0.8789612  0.12103876], Action: 1, state: 3\n",
      "Action prob: [0.4911443  0.50885576], Action: 0, state: 7\n",
      "Action prob: [0.8713396  0.12866035], Action: 0, state: 2\n",
      "Action prob: [0.87766075 0.1223392 ], Action: 0, state: 3\n",
      "Action prob: [0.8899349  0.11006508], Action: 0, state: 8\n",
      "Action prob: [0.8381931  0.16180693], Action: 0, state: 8\n",
      "Action prob: [0.85043764 0.14956234], Action: 0, state: 8\n",
      "Action prob: [0.8627754  0.13722461], Action: 0, state: 8\n",
      "Action prob: [0.8792693  0.12073067], Action: 0, state: 8\n",
      "Action prob: [0.88685143 0.11314853], Action: 0, state: 8\n",
      "Action prob: [0.89460486 0.10539514], Action: 0, state: 8\n",
      "Action prob: [0.8919344  0.10806563], Action: 0, state: 8\n",
      "Action prob: [0.88056 0.11944], Action: 0, state: 8\n",
      "Action prob: [0.84350896 0.15649109], Action: 0, state: 8\n",
      "Action prob: [0.88073903 0.11926094], Action: 0, state: 8\n",
      "Action prob: [0.88115054 0.11884947], Action: 0, state: 8\n",
      "Action prob: [0.8931614  0.10683857], Action: 0, state: 8\n",
      "Action prob: [0.846048   0.15395202], Action: 0, state: 8\n",
      "Action prob: [0.8653466  0.13465339], Action: 0, state: 8\n",
      "Action prob: [0.86495495 0.13504504], Action: 0, state: 8\n",
      "Action prob: [0.89101756 0.10898238], Action: 1, state: 8\n",
      "Reward for this episode -42600, loss is -0.11900488302939047\n",
      "Action prob: [0.8720575  0.12794246], Action: 0, state: 0\n",
      "Action prob: [0.8741445 0.1258555], Action: 0, state: 1\n",
      "Action prob: [0.86972934 0.13027065], Action: 0, state: 1\n",
      "Action prob: [0.87808007 0.12191998], Action: 0, state: 1\n",
      "Action prob: [0.88870716 0.11129289], Action: 0, state: 1\n",
      "Action prob: [0.8779176  0.12208237], Action: 0, state: 2\n",
      "Action prob: [0.8838867  0.11611332], Action: 0, state: 2\n",
      "Action prob: [0.87499905 0.12500091], Action: 0, state: 3\n",
      "Action prob: [0.8760845  0.12391549], Action: 0, state: 3\n",
      "Action prob: [0.87463987 0.12536016], Action: 0, state: 3\n",
      "Action prob: [0.87304807 0.12695196], Action: 0, state: 3\n",
      "Action prob: [0.8732464  0.12675363], Action: 0, state: 3\n",
      "Action prob: [0.8742787  0.12572132], Action: 0, state: 3\n",
      "Action prob: [0.85844415 0.14155585], Action: 0, state: 8\n",
      "Action prob: [0.91922075 0.08077925], Action: 0, state: 8\n",
      "Action prob: [0.8981427  0.10185727], Action: 1, state: 8\n",
      "Action prob: [0.90581316 0.09418679], Action: 0, state: 8\n",
      "Action prob: [0.8829734  0.11702667], Action: 0, state: 8\n",
      "Action prob: [0.88987136 0.11012868], Action: 0, state: 8\n",
      "Action prob: [0.8925597  0.10744032], Action: 0, state: 8\n",
      "Action prob: [0.9061694  0.09383058], Action: 0, state: 8\n",
      "Action prob: [0.8864322  0.11356783], Action: 0, state: 8\n",
      "Action prob: [0.8435939  0.15640618], Action: 0, state: 8\n",
      "Action prob: [0.89614266 0.1038573 ], Action: 0, state: 8\n",
      "Action prob: [0.894159   0.10584097], Action: 0, state: 8\n",
      "Action prob: [0.8422798  0.15772025], Action: 0, state: 8\n",
      "Action prob: [0.89053696 0.10946304], Action: 0, state: 8\n",
      "Action prob: [0.8697718  0.13022818], Action: 0, state: 8\n",
      "Action prob: [0.8828019  0.11719812], Action: 0, state: 8\n",
      "Action prob: [0.8646068  0.13539322], Action: 0, state: 8\n",
      "Action prob: [0.89634645 0.10365351], Action: 0, state: 8\n",
      "Action prob: [0.8548593  0.14514071], Action: 0, state: 8\n",
      "Action prob: [0.90000904 0.09999099], Action: 0, state: 8\n",
      "Action prob: [0.8947395  0.10526046], Action: 0, state: 8\n",
      "Action prob: [0.86853147 0.13146849], Action: 0, state: 8\n",
      "Action prob: [0.90157336 0.09842669], Action: 0, state: 8\n",
      "Action prob: [0.89651334 0.1034867 ], Action: 0, state: 8\n",
      "Action prob: [0.89501685 0.10498316], Action: 0, state: 8\n",
      "Action prob: [0.8598783  0.14012176], Action: 0, state: 8\n",
      "Action prob: [0.89443415 0.10556588], Action: 0, state: 8\n",
      "Action prob: [0.8869211  0.11307887], Action: 0, state: 8\n",
      "Action prob: [0.9034219  0.09657816], Action: 0, state: 8\n",
      "Action prob: [0.8952134  0.10478664], Action: 0, state: 8\n",
      "Action prob: [0.88902    0.11097997], Action: 0, state: 8\n",
      "Action prob: [0.8434558  0.15654427], Action: 0, state: 8\n",
      "Action prob: [0.89942724 0.10057271], Action: 0, state: 8\n",
      "Action prob: [0.8942833  0.10571666], Action: 0, state: 8\n",
      "Action prob: [0.84511286 0.15488717], Action: 0, state: 8\n",
      "Action prob: [0.8563612  0.14363877], Action: 0, state: 8\n",
      "Action prob: [0.8533322  0.14666778], Action: 0, state: 8\n",
      "Reward for this episode -105800, loss is -0.04266187890836384\n",
      "Action prob: [0.8889747  0.11102529], Action: 0, state: 0\n",
      "Action prob: [0.87345713 0.12654285], Action: 0, state: 1\n",
      "Action prob: [0.8811726  0.11882746], Action: 0, state: 2\n",
      "Action prob: [0.88719285 0.11280718], Action: 0, state: 2\n",
      "Action prob: [0.8806375  0.11936242], Action: 0, state: 2\n",
      "Action prob: [0.87316245 0.12683758], Action: 0, state: 2\n",
      "Action prob: [0.8853549  0.11464511], Action: 0, state: 2\n",
      "Action prob: [0.8602135  0.13978644], Action: 0, state: 2\n",
      "Action prob: [0.888494   0.11150601], Action: 1, state: 2\n",
      "Action prob: [0.4874304  0.51256955], Action: 1, state: 6\n",
      "Action prob: [0.4874304  0.51256955], Action: 0, state: 6\n",
      "Action prob: [0.4874304  0.51256955], Action: 0, state: 6\n",
      "Action prob: [0.8848992  0.11510083], Action: 0, state: 1\n",
      "Action prob: [0.88360906 0.116391  ], Action: 0, state: 1\n",
      "Action prob: [0.8759463  0.12405372], Action: 0, state: 1\n",
      "Action prob: [0.8819621  0.11803786], Action: 0, state: 2\n",
      "Action prob: [0.9024937  0.09750627], Action: 0, state: 3\n",
      "Action prob: [0.89137113 0.10862888], Action: 0, state: 3\n",
      "Action prob: [0.87797594 0.12202401], Action: 0, state: 3\n",
      "Action prob: [0.90839607 0.0916039 ], Action: 0, state: 8\n",
      "Action prob: [0.85820246 0.14179756], Action: 0, state: 8\n",
      "Action prob: [0.89858544 0.10141453], Action: 0, state: 8\n",
      "Action prob: [0.90182877 0.09817123], Action: 0, state: 8\n",
      "Action prob: [0.8912254  0.10877459], Action: 0, state: 8\n",
      "Action prob: [0.87664545 0.12335455], Action: 1, state: 8\n",
      "Action prob: [0.90001696 0.099983  ], Action: 0, state: 8\n",
      "Action prob: [0.9077048 0.0922952], Action: 0, state: 8\n",
      "Action prob: [0.8865603 0.1134397], Action: 0, state: 8\n",
      "Action prob: [0.90239227 0.0976077 ], Action: 0, state: 8\n",
      "Action prob: [0.89603585 0.10396411], Action: 1, state: 8\n",
      "Action prob: [0.89813215 0.10186788], Action: 1, state: 8\n",
      "Action prob: [0.8662589  0.13374107], Action: 1, state: 8\n",
      "Action prob: [0.89243674 0.10756329], Action: 0, state: 8\n",
      "Action prob: [0.87213194 0.1278681 ], Action: 0, state: 8\n",
      "Action prob: [0.88454396 0.11545605], Action: 0, state: 8\n",
      "Action prob: [0.86821544 0.13178456], Action: 0, state: 8\n",
      "Action prob: [0.8993142  0.10068578], Action: 0, state: 8\n",
      "Action prob: [0.86149424 0.1385058 ], Action: 0, state: 8\n",
      "Action prob: [0.9049513  0.09504868], Action: 0, state: 8\n",
      "Action prob: [0.9197818  0.08021817], Action: 0, state: 8\n",
      "Action prob: [0.89909774 0.10090221], Action: 0, state: 8\n",
      "Action prob: [0.86184627 0.13815375], Action: 0, state: 8\n",
      "Action prob: [0.89673436 0.10326564], Action: 0, state: 8\n",
      "Action prob: [0.89513975 0.10486023], Action: 0, state: 8\n",
      "Action prob: [0.9000413 0.0999587], Action: 0, state: 8\n",
      "Action prob: [0.86506313 0.13493682], Action: 0, state: 8\n",
      "Action prob: [0.8616392  0.13836086], Action: 0, state: 8\n",
      "Action prob: [0.851206   0.14879398], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.89614075 0.10385921], Action: 0, state: 8\n",
      "Action prob: [0.9171392  0.08286078], Action: 0, state: 8\n",
      "Reward for this episode -86000, loss is -0.0871622815294742\n",
      "Action prob: [0.88190305 0.11809696], Action: 0, state: 0\n",
      "Action prob: [0.8850044  0.11499558], Action: 0, state: 0\n",
      "Action prob: [0.88844794 0.11155207], Action: 1, state: 1\n",
      "Action prob: [0.48609877 0.51390123], Action: 0, state: 5\n",
      "Action prob: [0.48609877 0.51390123], Action: 0, state: 5\n",
      "Action prob: [0.8858865  0.11411349], Action: 0, state: 0\n",
      "Action prob: [0.8902503  0.10974965], Action: 0, state: 0\n",
      "Action prob: [0.89312893 0.10687106], Action: 0, state: 1\n",
      "Action prob: [0.8905277  0.10947227], Action: 0, state: 1\n",
      "Action prob: [0.8880617  0.11193823], Action: 0, state: 1\n",
      "Action prob: [0.8893767 0.1106233], Action: 0, state: 1\n",
      "Action prob: [0.8909081  0.10909192], Action: 0, state: 1\n",
      "Action prob: [0.88662046 0.11337952], Action: 0, state: 2\n",
      "Action prob: [0.881099   0.11890095], Action: 0, state: 2\n",
      "Action prob: [0.8835253 0.1164747], Action: 0, state: 3\n",
      "Action prob: [0.89952666 0.10047326], Action: 0, state: 8\n",
      "Action prob: [0.86721456 0.13278545], Action: 0, state: 8\n",
      "Action prob: [0.89478695 0.10521308], Action: 0, state: 8\n",
      "Action prob: [0.9088673  0.09113275], Action: 0, state: 8\n",
      "Action prob: [0.90804976 0.09195025], Action: 0, state: 8\n",
      "Action prob: [0.91101897 0.08898104], Action: 0, state: 8\n",
      "Action prob: [0.90983623 0.09016377], Action: 0, state: 8\n",
      "Action prob: [0.91262114 0.08737888], Action: 0, state: 8\n",
      "Action prob: [0.86905074 0.13094924], Action: 0, state: 8\n",
      "Action prob: [0.8993795  0.10062055], Action: 0, state: 8\n",
      "Action prob: [0.88954157 0.11045851], Action: 1, state: 8\n",
      "Action prob: [0.92105544 0.07894457], Action: 0, state: 8\n",
      "Action prob: [0.91160744 0.08839259], Action: 0, state: 8\n",
      "Action prob: [0.86879045 0.1312095 ], Action: 0, state: 8\n",
      "Action prob: [0.90485114 0.0951489 ], Action: 0, state: 8\n",
      "Action prob: [0.9104114  0.08958861], Action: 0, state: 8\n",
      "Action prob: [0.8617664 0.1382336], Action: 0, state: 8\n",
      "Action prob: [0.9049445  0.09505554], Action: 0, state: 8\n",
      "Action prob: [0.8594739  0.14052609], Action: 1, state: 8\n",
      "Action prob: [0.8656013  0.13439865], Action: 0, state: 8\n",
      "Action prob: [0.90701324 0.09298676], Action: 0, state: 8\n",
      "Action prob: [0.8564662  0.14353386], Action: 0, state: 8\n",
      "Action prob: [0.8947359  0.10526415], Action: 1, state: 8\n",
      "Reward for this episode -58500, loss is 0.07258208971714519\n",
      "Action prob: [0.88713324 0.11286668], Action: 0, state: 0\n",
      "Action prob: [0.89224803 0.10775197], Action: 0, state: 0\n",
      "Action prob: [0.8933864  0.10661359], Action: 0, state: 1\n",
      "Action prob: [0.885897   0.11410298], Action: 1, state: 1\n",
      "Action prob: [0.4869571 0.5130429], Action: 0, state: 5\n",
      "Action prob: [0.8855704  0.11442959], Action: 0, state: 0\n",
      "Action prob: [0.88201267 0.11798736], Action: 0, state: 0\n",
      "Action prob: [0.8912924  0.10870762], Action: 0, state: 0\n",
      "Action prob: [0.8915209  0.10847912], Action: 0, state: 1\n",
      "Action prob: [0.8998486  0.10015146], Action: 1, state: 1\n",
      "Action prob: [0.4869571 0.5130429], Action: 1, state: 5\n",
      "Action prob: [0.4869571 0.5130429], Action: 1, state: 5\n",
      "Action prob: [0.4869571 0.5130429], Action: 0, state: 5\n",
      "Action prob: [0.4869571 0.5130429], Action: 0, state: 5\n",
      "Action prob: [0.4869571 0.5130429], Action: 1, state: 5\n",
      "Action prob: [0.4869571 0.5130429], Action: 0, state: 5\n",
      "Action prob: [0.8947319  0.10526809], Action: 0, state: 0\n",
      "Action prob: [0.89560205 0.10439801], Action: 0, state: 9\n",
      "Action prob: [0.90146995 0.09853004], Action: 0, state: 9\n",
      "Action prob: [0.8650437  0.13495629], Action: 0, state: 9\n",
      "Action prob: [0.9059602  0.09403979], Action: 0, state: 9\n",
      "Action prob: [0.90877384 0.09122611], Action: 0, state: 9\n",
      "Action prob: [0.9138188  0.08618125], Action: 0, state: 9\n",
      "Action prob: [0.9157656  0.08423436], Action: 0, state: 9\n",
      "Action prob: [0.9127336  0.08726637], Action: 0, state: 9\n",
      "Action prob: [0.9173078  0.08269225], Action: 0, state: 9\n",
      "Action prob: [0.8683594  0.13164063], Action: 0, state: 9\n",
      "Action prob: [0.91382897 0.08617102], Action: 0, state: 9\n",
      "Action prob: [0.87845486 0.12154513], Action: 0, state: 9\n",
      "Action prob: [0.90166444 0.09833557], Action: 0, state: 9\n",
      "Action prob: [0.8767763  0.12322376], Action: 0, state: 9\n",
      "Action prob: [0.8976581  0.10234182], Action: 0, state: 9\n",
      "Action prob: [0.86699194 0.13300814], Action: 0, state: 9\n",
      "Action prob: [0.9167998  0.08320022], Action: 0, state: 9\n",
      "Action prob: [0.9094656  0.09053434], Action: 1, state: 9\n",
      "Action prob: [0.88274413 0.11725591], Action: 0, state: 9\n",
      "Action prob: [0.8648626  0.13513735], Action: 0, state: 9\n",
      "Action prob: [0.92369556 0.07630435], Action: 0, state: 9\n",
      "Action prob: [0.9038408  0.09615914], Action: 0, state: 9\n",
      "Action prob: [0.9125006  0.08749938], Action: 0, state: 9\n",
      "Action prob: [0.9037364  0.09626352], Action: 0, state: 9\n",
      "Action prob: [0.91260344 0.08739652], Action: 0, state: 9\n",
      "Action prob: [0.90974486 0.09025511], Action: 0, state: 9\n",
      "Action prob: [0.8779932  0.12200675], Action: 0, state: 9\n",
      "Action prob: [0.8663907 0.1336093], Action: 0, state: 9\n",
      "Action prob: [0.90971565 0.09028432], Action: 0, state: 9\n",
      "Action prob: [0.90414757 0.09585243], Action: 0, state: 9\n",
      "Action prob: [0.9108854  0.08911461], Action: 0, state: 9\n",
      "Action prob: [0.8686127  0.13138735], Action: 0, state: 9\n",
      "Action prob: [0.86502755 0.13497248], Action: 0, state: 9\n",
      "Reward for this episode -28900, loss is -0.03525717957080064\n",
      "Action prob: [0.89687616 0.10312386], Action: 0, state: 0\n",
      "Action prob: [0.9025756  0.09742438], Action: 0, state: 9\n",
      "Action prob: [0.87472284 0.12527709], Action: 0, state: 9\n",
      "Action prob: [0.92368835 0.07631165], Action: 0, state: 9\n",
      "Action prob: [0.91398853 0.08601145], Action: 0, state: 9\n",
      "Action prob: [0.9149795  0.08502048], Action: 0, state: 9\n",
      "Action prob: [0.91827023 0.08172981], Action: 0, state: 9\n",
      "Action prob: [0.8742186  0.12578146], Action: 0, state: 9\n",
      "Action prob: [0.91618526 0.08381468], Action: 0, state: 9\n",
      "Action prob: [0.9106048  0.08939523], Action: 0, state: 9\n",
      "Action prob: [0.86805874 0.13194123], Action: 0, state: 9\n",
      "Action prob: [0.87693816 0.12306187], Action: 0, state: 9\n",
      "Action prob: [0.86741114 0.1325889 ], Action: 1, state: 9\n",
      "Action prob: [0.90294033 0.09705967], Action: 0, state: 9\n",
      "Action prob: [0.91665494 0.08334509], Action: 0, state: 9\n",
      "Action prob: [0.91249436 0.0875056 ], Action: 0, state: 9\n",
      "Action prob: [0.9175419  0.08245801], Action: 0, state: 9\n",
      "Action prob: [0.9077924  0.09220757], Action: 1, state: 9\n",
      "Action prob: [0.9231911  0.07680891], Action: 0, state: 9\n",
      "Action prob: [0.90605    0.09394997], Action: 1, state: 9\n",
      "Action prob: [0.9105439  0.08945612], Action: 0, state: 9\n",
      "Action prob: [0.8765217  0.12347833], Action: 0, state: 9\n",
      "Action prob: [0.9131396  0.08686038], Action: 0, state: 9\n",
      "Action prob: [0.9142405  0.08575955], Action: 0, state: 9\n",
      "Action prob: [0.911794   0.08820596], Action: 0, state: 9\n",
      "Action prob: [0.8856962  0.11430382], Action: 0, state: 9\n",
      "Action prob: [0.87229836 0.12770166], Action: 0, state: 9\n",
      "Action prob: [0.9139536  0.08604642], Action: 0, state: 9\n",
      "Action prob: [0.88193774 0.11806227], Action: 1, state: 9\n",
      "Action prob: [0.91712046 0.08287954], Action: 0, state: 9\n",
      "Action prob: [0.92127067 0.07872928], Action: 0, state: 9\n",
      "Action prob: [0.92061913 0.0793808 ], Action: 0, state: 9\n",
      "Action prob: [0.8717752  0.12822483], Action: 0, state: 9\n",
      "Action prob: [0.919895   0.08010504], Action: 0, state: 9\n",
      "Action prob: [0.9199155 0.0800845], Action: 0, state: 9\n",
      "Action prob: [0.90239036 0.09760963], Action: 0, state: 9\n",
      "Action prob: [0.9098826  0.09011743], Action: 0, state: 9\n",
      "Action prob: [0.9132509  0.08674908], Action: 0, state: 9\n",
      "Action prob: [0.90754104 0.09245893], Action: 0, state: 9\n",
      "Action prob: [0.9094935  0.09050652], Action: 1, state: 9\n",
      "Action prob: [0.8938685  0.10613149], Action: 0, state: 9\n",
      "Action prob: [0.88486195 0.11513811], Action: 0, state: 9\n",
      "Action prob: [0.8731449  0.12685509], Action: 0, state: 9\n",
      "Action prob: [0.87889224 0.12110779], Action: 0, state: 9\n",
      "Action prob: [0.91780466 0.08219539], Action: 0, state: 9\n",
      "Action prob: [0.9080089  0.09199115], Action: 0, state: 9\n",
      "Action prob: [0.867184 0.132816], Action: 0, state: 9\n",
      "Action prob: [0.91516566 0.08483437], Action: 0, state: 9\n",
      "Action prob: [0.92463064 0.07536931], Action: 0, state: 9\n",
      "Action prob: [0.9150339  0.08496612], Action: 0, state: 9\n",
      "Reward for this episode -50000, loss is 0.06510443380260382\n",
      "Action prob: [0.89728445 0.1027156 ], Action: 0, state: 0\n",
      "Action prob: [0.90603507 0.09396496], Action: 0, state: 1\n",
      "Action prob: [0.90145594 0.09854408], Action: 0, state: 1\n",
      "Action prob: [0.8951513  0.10484874], Action: 0, state: 1\n",
      "Action prob: [0.9047009  0.09529913], Action: 1, state: 1\n",
      "Action prob: [0.48990628 0.5100937 ], Action: 0, state: 5\n",
      "Action prob: [0.48990628 0.5100937 ], Action: 1, state: 5\n",
      "Action prob: [0.89387333 0.10612665], Action: 0, state: 0\n",
      "Action prob: [0.9091022  0.09089773], Action: 0, state: 0\n",
      "Action prob: [0.90008986 0.09991013], Action: 0, state: 0\n",
      "Action prob: [0.89666283 0.10333718], Action: 0, state: 1\n",
      "Action prob: [0.8967459  0.10325405], Action: 0, state: 1\n",
      "Action prob: [0.8961898  0.10381018], Action: 0, state: 1\n",
      "Action prob: [0.9024382  0.09756181], Action: 1, state: 2\n",
      "Action prob: [0.48990628 0.5100937 ], Action: 0, state: 6\n",
      "Action prob: [0.48990628 0.5100937 ], Action: 0, state: 6\n",
      "Action prob: [0.48990628 0.5100937 ], Action: 1, state: 6\n",
      "Action prob: [0.48990628 0.5100937 ], Action: 1, state: 6\n",
      "Action prob: [0.88525075 0.11474917], Action: 0, state: 1\n",
      "Action prob: [0.90034753 0.0996525 ], Action: 0, state: 1\n",
      "Action prob: [0.89852196 0.10147809], Action: 0, state: 1\n",
      "Action prob: [0.8994622  0.10053772], Action: 0, state: 2\n",
      "Action prob: [0.89944905 0.10055093], Action: 0, state: 2\n",
      "Action prob: [0.89895785 0.10104216], Action: 0, state: 3\n",
      "Action prob: [0.8946625  0.10533751], Action: 0, state: 3\n",
      "Action prob: [0.9005792  0.09942081], Action: 0, state: 3\n",
      "Action prob: [0.8940718  0.10592819], Action: 0, state: 3\n",
      "Action prob: [0.9028998  0.09710018], Action: 0, state: 8\n",
      "Action prob: [0.90915984 0.09084011], Action: 0, state: 8\n",
      "Action prob: [0.9261966  0.07380337], Action: 0, state: 8\n",
      "Action prob: [0.92965734 0.07034259], Action: 0, state: 8\n",
      "Action prob: [0.91248196 0.08751806], Action: 0, state: 8\n",
      "Action prob: [0.88466614 0.11533381], Action: 0, state: 8\n",
      "Action prob: [0.91569066 0.08430935], Action: 0, state: 8\n",
      "Action prob: [0.8739499  0.12605013], Action: 0, state: 8\n",
      "Action prob: [0.87823945 0.12176057], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.86787766 0.13212231], Action: 0, state: 8\n",
      "Action prob: [0.9132046  0.08679545], Action: 0, state: 8\n",
      "Action prob: [0.8789328  0.12106724], Action: 0, state: 8\n",
      "Action prob: [0.8790019  0.12099811], Action: 0, state: 8\n",
      "Action prob: [0.9151701 0.0848299], Action: 0, state: 8\n",
      "Action prob: [0.91563064 0.0843693 ], Action: 0, state: 8\n",
      "Action prob: [0.91629016 0.08370982], Action: 0, state: 8\n",
      "Action prob: [0.880076   0.11992406], Action: 0, state: 8\n",
      "Action prob: [0.8748117  0.12518829], Action: 0, state: 8\n",
      "Action prob: [0.8779517  0.12204834], Action: 0, state: 8\n",
      "Action prob: [0.8973716  0.10262842], Action: 0, state: 8\n",
      "Action prob: [0.8698508  0.13014926], Action: 0, state: 8\n",
      "Action prob: [0.9154501  0.08454987], Action: 0, state: 8\n",
      "Action prob: [0.8707391  0.12926088], Action: 0, state: 8\n",
      "Reward for this episode -58600, loss is -0.003854362623120845\n",
      "Action prob: [0.90165514 0.09834493], Action: 0, state: 0\n",
      "Action prob: [0.8996688  0.10033121], Action: 0, state: 0\n",
      "Action prob: [0.89622426 0.10377572], Action: 0, state: 0\n",
      "Action prob: [0.90095496 0.09904505], Action: 0, state: 0\n",
      "Action prob: [0.91693157 0.08306843], Action: 0, state: 0\n",
      "Action prob: [0.88950175 0.11049829], Action: 0, state: 0\n",
      "Action prob: [0.9025579  0.09744205], Action: 0, state: 0\n",
      "Action prob: [0.89557964 0.10442037], Action: 1, state: 1\n",
      "Action prob: [0.49080274 0.5091973 ], Action: 1, state: 5\n",
      "Action prob: [0.49080274 0.5091973 ], Action: 1, state: 5\n",
      "Action prob: [0.49080274 0.5091973 ], Action: 1, state: 5\n",
      "Action prob: [0.9032585  0.09674147], Action: 0, state: 0\n",
      "Action prob: [0.90532386 0.09467611], Action: 0, state: 0\n",
      "Action prob: [0.90180147 0.0981985 ], Action: 0, state: 1\n",
      "Action prob: [0.9035353  0.09646472], Action: 0, state: 1\n",
      "Action prob: [0.90801895 0.09198105], Action: 0, state: 1\n",
      "Action prob: [0.9033936  0.09660632], Action: 0, state: 1\n",
      "Action prob: [0.9034524  0.09654763], Action: 0, state: 1\n",
      "Action prob: [0.9057904  0.09420962], Action: 0, state: 2\n",
      "Action prob: [0.90341204 0.09658793], Action: 0, state: 2\n",
      "Action prob: [0.8914559  0.10854413], Action: 0, state: 2\n",
      "Action prob: [0.8997739  0.10022618], Action: 0, state: 2\n",
      "Action prob: [0.8993854  0.10061461], Action: 0, state: 3\n",
      "Action prob: [0.9011131  0.09888686], Action: 0, state: 3\n",
      "Action prob: [0.89784384 0.10215613], Action: 1, state: 3\n",
      "Action prob: [0.49080274 0.5091973 ], Action: 0, state: 7\n",
      "Action prob: [0.49080274 0.5091973 ], Action: 1, state: 7\n",
      "Action prob: [0.899112   0.10088796], Action: 0, state: 2\n",
      "Action prob: [0.89765286 0.1023472 ], Action: 0, state: 2\n",
      "Action prob: [0.89456254 0.10543747], Action: 0, state: 2\n",
      "Action prob: [0.8955883  0.10441171], Action: 0, state: 2\n",
      "Action prob: [0.89132    0.10868002], Action: 0, state: 3\n",
      "Action prob: [0.8933625  0.10663743], Action: 0, state: 8\n",
      "Action prob: [0.91457915 0.08542088], Action: 1, state: 8\n",
      "Reward for this episode 14300, loss is -0.12247091164942984\n",
      "Action prob: [0.8931676  0.10683233], Action: 1, state: 0\n",
      "Action prob: [0.492182 0.507818], Action: 1, state: 4\n",
      "Action prob: [0.492182 0.507818], Action: 1, state: 4\n",
      "Action prob: [0.9037917  0.09620831], Action: 0, state: 0\n",
      "Action prob: [0.8963144  0.10368564], Action: 0, state: 0\n",
      "Action prob: [0.92091227 0.07908779], Action: 0, state: 0\n",
      "Action prob: [0.9008194  0.09918052], Action: 0, state: 0\n",
      "Action prob: [0.9397054  0.06029459], Action: 0, state: 9\n",
      "Action prob: [0.91115344 0.08884653], Action: 0, state: 9\n",
      "Action prob: [0.8827525  0.11724755], Action: 0, state: 9\n",
      "Action prob: [0.88724446 0.11275557], Action: 1, state: 9\n",
      "Action prob: [0.93412846 0.0658716 ], Action: 1, state: 9\n",
      "Action prob: [0.9081794  0.09182054], Action: 0, state: 9\n",
      "Action prob: [0.907405   0.09259499], Action: 0, state: 9\n",
      "Action prob: [0.8834857  0.11651433], Action: 0, state: 9\n",
      "Action prob: [0.87254095 0.12745903], Action: 0, state: 9\n",
      "Action prob: [0.9175984  0.08240154], Action: 0, state: 9\n",
      "Action prob: [0.8836162  0.11638378], Action: 0, state: 9\n",
      "Action prob: [0.883892   0.11610799], Action: 0, state: 9\n",
      "Action prob: [0.9224957  0.07750425], Action: 0, state: 9\n",
      "Action prob: [0.8789654 0.1210347], Action: 0, state: 9\n",
      "Action prob: [0.8861388  0.11386126], Action: 0, state: 9\n",
      "Action prob: [0.9154334  0.08456655], Action: 0, state: 9\n",
      "Action prob: [0.91741574 0.08258432], Action: 0, state: 9\n",
      "Action prob: [0.9122963  0.08770373], Action: 0, state: 9\n",
      "Action prob: [0.91640484 0.08359512], Action: 1, state: 9\n",
      "Action prob: [0.91306156 0.0869384 ], Action: 0, state: 9\n",
      "Action prob: [0.9243698 0.0756302], Action: 0, state: 9\n",
      "Action prob: [0.91672313 0.08327689], Action: 0, state: 9\n",
      "Action prob: [0.88702214 0.11297789], Action: 0, state: 9\n",
      "Action prob: [0.91890424 0.08109572], Action: 0, state: 9\n",
      "Action prob: [0.88664746 0.11335257], Action: 0, state: 9\n",
      "Action prob: [0.9220567  0.07794327], Action: 0, state: 9\n",
      "Action prob: [0.917703 0.082297], Action: 0, state: 9\n",
      "Action prob: [0.9149021  0.08509789], Action: 0, state: 9\n",
      "Action prob: [0.8896345  0.11036557], Action: 0, state: 9\n",
      "Action prob: [0.9190626  0.08093734], Action: 0, state: 9\n",
      "Action prob: [0.9282474  0.07175259], Action: 0, state: 9\n",
      "Action prob: [0.8854831  0.11451691], Action: 0, state: 9\n",
      "Action prob: [0.886792   0.11320797], Action: 0, state: 9\n",
      "Action prob: [0.911373   0.08862699], Action: 0, state: 9\n",
      "Action prob: [0.8768056  0.12319442], Action: 0, state: 9\n",
      "Action prob: [0.87689656 0.12310351], Action: 1, state: 9\n",
      "Action prob: [0.8854685  0.11453149], Action: 0, state: 9\n",
      "Action prob: [0.9211444  0.07885556], Action: 0, state: 9\n",
      "Action prob: [0.8801809  0.11981915], Action: 0, state: 9\n",
      "Action prob: [0.91902184 0.08097813], Action: 0, state: 9\n",
      "Action prob: [0.9238788 0.0761212], Action: 0, state: 9\n",
      "Action prob: [0.9036094  0.09639065], Action: 0, state: 9\n",
      "Action prob: [0.92449796 0.07550202], Action: 0, state: 9\n",
      "Reward for this episode -41000, loss is -0.05090580169715159\n",
      "Action prob: [0.90812093 0.09187907], Action: 0, state: 0\n",
      "Action prob: [0.9031812 0.0968188], Action: 0, state: 0\n",
      "Action prob: [0.91260386 0.08739617], Action: 1, state: 1\n",
      "Action prob: [0.49205685 0.5079431 ], Action: 1, state: 5\n",
      "Action prob: [0.90154195 0.09845811], Action: 0, state: 0\n",
      "Action prob: [0.9006919  0.09930802], Action: 0, state: 0\n",
      "Action prob: [0.9014004  0.09859961], Action: 0, state: 0\n",
      "Action prob: [0.9121312  0.08786877], Action: 0, state: 1\n",
      "Action prob: [0.9074585  0.09254154], Action: 0, state: 1\n",
      "Action prob: [0.9103393 0.0896607], Action: 0, state: 2\n",
      "Action prob: [0.9109858  0.08901419], Action: 0, state: 2\n",
      "Action prob: [0.9015627  0.09843728], Action: 0, state: 2\n",
      "Action prob: [0.9103281  0.08967189], Action: 0, state: 2\n",
      "Action prob: [0.89538264 0.10461741], Action: 0, state: 3\n",
      "Action prob: [0.89097744 0.10902259], Action: 0, state: 8\n",
      "Action prob: [0.9126538  0.08734621], Action: 0, state: 8\n",
      "Action prob: [0.91550857 0.08449147], Action: 0, state: 8\n",
      "Action prob: [0.92356074 0.07643928], Action: 0, state: 8\n",
      "Action prob: [0.92586404 0.07413595], Action: 0, state: 8\n",
      "Action prob: [0.8954613  0.10453869], Action: 0, state: 8\n",
      "Action prob: [0.91271526 0.08728472], Action: 0, state: 8\n",
      "Action prob: [0.9220535  0.07794643], Action: 1, state: 8\n",
      "Action prob: [0.91957724 0.08042277], Action: 0, state: 8\n",
      "Action prob: [0.9273442  0.07265586], Action: 0, state: 8\n",
      "Action prob: [0.93261594 0.06738409], Action: 0, state: 8\n",
      "Action prob: [0.9257526  0.07424743], Action: 0, state: 8\n",
      "Action prob: [0.8882962  0.11170379], Action: 0, state: 8\n",
      "Action prob: [0.92533666 0.0746633 ], Action: 1, state: 8\n",
      "Reward for this episode -31100, loss is 0.09616084178508956\n",
      "Action prob: [0.8997431 0.1002569], Action: 0, state: 0\n",
      "Action prob: [0.91531646 0.08468354], Action: 1, state: 1\n",
      "Action prob: [0.49016508 0.50983495], Action: 0, state: 5\n",
      "Action prob: [0.9035787 0.0964213], Action: 0, state: 0\n",
      "Action prob: [0.9133296  0.08667041], Action: 0, state: 0\n",
      "Action prob: [0.90579027 0.09420969], Action: 0, state: 1\n",
      "Action prob: [0.907597   0.09240298], Action: 0, state: 2\n",
      "Action prob: [0.9159874  0.08401265], Action: 0, state: 2\n",
      "Action prob: [0.9107422  0.08925776], Action: 0, state: 2\n",
      "Action prob: [0.9142555  0.08574452], Action: 0, state: 3\n",
      "Action prob: [0.91491205 0.08508793], Action: 0, state: 3\n",
      "Action prob: [0.909724   0.09027598], Action: 0, state: 3\n",
      "Action prob: [0.9242188  0.07578123], Action: 0, state: 8\n",
      "Action prob: [0.9148434 0.0851566], Action: 0, state: 8\n",
      "Action prob: [0.9446839  0.05531607], Action: 0, state: 8\n",
      "Action prob: [0.8909713  0.10902872], Action: 0, state: 8\n",
      "Action prob: [0.9349348  0.06506526], Action: 0, state: 8\n",
      "Action prob: [0.8909818  0.10901815], Action: 0, state: 8\n",
      "Action prob: [0.8911727  0.10882724], Action: 0, state: 8\n",
      "Action prob: [0.88874567 0.11125436], Action: 0, state: 8\n",
      "Action prob: [0.93066967 0.06933025], Action: 1, state: 8\n",
      "Action prob: [0.89118856 0.10881146], Action: 0, state: 8\n",
      "Action prob: [0.9316815  0.06831846], Action: 0, state: 8\n",
      "Action prob: [0.9269253  0.07307472], Action: 0, state: 8\n",
      "Action prob: [0.93005204 0.06994799], Action: 0, state: 8\n",
      "Action prob: [0.9195705  0.08042949], Action: 0, state: 8\n",
      "Action prob: [0.92826    0.07173992], Action: 0, state: 8\n",
      "Action prob: [0.8709583  0.12904173], Action: 1, state: 8\n",
      "Action prob: [0.9296687  0.07033135], Action: 0, state: 8\n",
      "Action prob: [0.9170689  0.08293112], Action: 0, state: 8\n",
      "Action prob: [0.887999   0.11200096], Action: 0, state: 8\n",
      "Action prob: [0.91613245 0.08386759], Action: 0, state: 8\n",
      "Action prob: [0.92925936 0.07074064], Action: 0, state: 8\n",
      "Action prob: [0.9228858  0.07711422], Action: 0, state: 8\n",
      "Action prob: [0.889639   0.11036105], Action: 0, state: 8\n",
      "Action prob: [0.9248568  0.07514323], Action: 0, state: 8\n",
      "Action prob: [0.9320138  0.06798623], Action: 0, state: 8\n",
      "Action prob: [0.9161879  0.08381215], Action: 0, state: 8\n",
      "Action prob: [0.88344556 0.11655444], Action: 0, state: 8\n",
      "Action prob: [0.9210398  0.07896017], Action: 0, state: 8\n",
      "Action prob: [0.88650185 0.11349817], Action: 0, state: 8\n",
      "Action prob: [0.8930555  0.10694444], Action: 0, state: 8\n",
      "Action prob: [0.9398745  0.06012549], Action: 0, state: 8\n",
      "Action prob: [0.9060663  0.09393378], Action: 0, state: 8\n",
      "Action prob: [0.9251041  0.07489589], Action: 0, state: 8\n",
      "Action prob: [0.92462075 0.07537928], Action: 0, state: 8\n",
      "Action prob: [0.88681775 0.11318223], Action: 0, state: 8\n",
      "Action prob: [0.9322196  0.06778044], Action: 0, state: 8\n",
      "Action prob: [0.93063706 0.06936298], Action: 1, state: 8\n",
      "Action prob: [0.8856385  0.11436152], Action: 0, state: 8\n",
      "Reward for this episode -109800, loss is 0.12071048102874944\n",
      "Action prob: [0.9219526  0.07804739], Action: 1, state: 0\n",
      "Action prob: [0.48930642 0.5106936 ], Action: 0, state: 4\n",
      "Action prob: [0.48930642 0.5106936 ], Action: 1, state: 4\n",
      "Action prob: [0.48930642 0.5106936 ], Action: 1, state: 4\n",
      "Action prob: [0.48930642 0.5106936 ], Action: 0, state: 4\n",
      "Action prob: [0.91727245 0.08272751], Action: 0, state: 0\n",
      "Action prob: [0.90946287 0.09053713], Action: 0, state: 1\n",
      "Action prob: [0.91070724 0.08929275], Action: 0, state: 1\n",
      "Action prob: [0.9111781  0.08882196], Action: 0, state: 1\n",
      "Action prob: [0.9203951  0.07960483], Action: 0, state: 9\n",
      "Action prob: [0.925345   0.07465493], Action: 1, state: 9\n",
      "Action prob: [0.94193906 0.05806088], Action: 0, state: 9\n",
      "Action prob: [0.9303123  0.06968777], Action: 0, state: 9\n",
      "Action prob: [0.88853776 0.11146221], Action: 0, state: 9\n",
      "Action prob: [0.907357   0.09264296], Action: 1, state: 9\n",
      "Action prob: [0.92854345 0.07145652], Action: 0, state: 9\n",
      "Action prob: [0.93135405 0.06864598], Action: 0, state: 9\n",
      "Action prob: [0.89316046 0.10683947], Action: 0, state: 9\n",
      "Action prob: [0.897695   0.10230502], Action: 0, state: 9\n",
      "Action prob: [0.88108635 0.11891371], Action: 0, state: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.9247096  0.07529039], Action: 0, state: 9\n",
      "Action prob: [0.8845755  0.11542453], Action: 0, state: 9\n",
      "Action prob: [0.9387768 0.0612232], Action: 1, state: 9\n",
      "Action prob: [0.92125934 0.07874063], Action: 0, state: 9\n",
      "Action prob: [0.9207335  0.07926647], Action: 0, state: 9\n",
      "Action prob: [0.9284205  0.07157943], Action: 1, state: 9\n",
      "Reward for this episode -14300, loss is -0.1581989112440043\n",
      "Action prob: [0.909335   0.09066499], Action: 0, state: 0\n",
      "Action prob: [0.91446114 0.08553886], Action: 0, state: 0\n",
      "Action prob: [0.9153806  0.08461948], Action: 0, state: 0\n",
      "Action prob: [0.91095    0.08904994], Action: 1, state: 0\n",
      "Action prob: [0.4887372  0.51126283], Action: 1, state: 4\n",
      "Action prob: [0.9039916  0.09600839], Action: 0, state: 0\n",
      "Action prob: [0.90492994 0.0950701 ], Action: 0, state: 0\n",
      "Action prob: [0.91495967 0.08504041], Action: 0, state: 0\n",
      "Action prob: [0.9059099  0.09409007], Action: 0, state: 1\n",
      "Action prob: [0.9118841  0.08811588], Action: 0, state: 1\n",
      "Action prob: [0.90959764 0.09040236], Action: 0, state: 1\n",
      "Action prob: [0.9022049  0.09779514], Action: 0, state: 1\n",
      "Action prob: [0.9148694  0.08513061], Action: 0, state: 1\n",
      "Action prob: [0.910729   0.08927107], Action: 0, state: 1\n",
      "Action prob: [0.9111668  0.08883318], Action: 0, state: 1\n",
      "Action prob: [0.92302847 0.07697151], Action: 0, state: 1\n",
      "Action prob: [0.9138408  0.08615918], Action: 0, state: 1\n",
      "Action prob: [0.91178656 0.08821344], Action: 0, state: 1\n",
      "Action prob: [0.9174393  0.08256076], Action: 0, state: 2\n",
      "Action prob: [0.91297084 0.08702917], Action: 0, state: 2\n",
      "Action prob: [0.9111962  0.08880378], Action: 0, state: 2\n",
      "Action prob: [0.91550326 0.08449674], Action: 0, state: 3\n",
      "Action prob: [0.91083604 0.08916388], Action: 0, state: 3\n",
      "Action prob: [0.92925954 0.07074048], Action: 0, state: 3\n",
      "Action prob: [0.92603636 0.07396363], Action: 0, state: 3\n",
      "Action prob: [0.9177014  0.08229855], Action: 0, state: 3\n",
      "Action prob: [0.9350635  0.06493645], Action: 0, state: 3\n",
      "Action prob: [0.9300709  0.06992912], Action: 0, state: 8\n",
      "Action prob: [0.9299416  0.07005844], Action: 0, state: 8\n",
      "Action prob: [0.89296854 0.10703152], Action: 0, state: 8\n",
      "Action prob: [0.8929297  0.10707035], Action: 0, state: 8\n",
      "Action prob: [0.9484887 0.0515113], Action: 0, state: 8\n",
      "Action prob: [0.8878254  0.11217451], Action: 0, state: 8\n",
      "Action prob: [0.93768746 0.06231262], Action: 0, state: 8\n",
      "Action prob: [0.932285   0.06771501], Action: 0, state: 8\n",
      "Action prob: [0.8874238  0.11257616], Action: 0, state: 8\n",
      "Action prob: [0.894232   0.10576802], Action: 0, state: 8\n",
      "Action prob: [0.93523383 0.06476618], Action: 0, state: 8\n",
      "Action prob: [0.93119526 0.06880473], Action: 0, state: 8\n",
      "Action prob: [0.9276621  0.07233792], Action: 0, state: 8\n",
      "Action prob: [0.93249196 0.06750805], Action: 0, state: 8\n",
      "Action prob: [0.8952808  0.10471919], Action: 1, state: 8\n",
      "Reward for this episode -24100, loss is 0.05577986343471663\n",
      "Action prob: [0.9206329  0.07936711], Action: 0, state: 0\n",
      "Action prob: [0.91291136 0.08708864], Action: 0, state: 0\n",
      "Action prob: [0.9102867  0.08971326], Action: 1, state: 1\n",
      "Action prob: [0.4870721  0.51292795], Action: 1, state: 5\n",
      "Action prob: [0.9160906  0.08390937], Action: 0, state: 0\n",
      "Action prob: [0.9120979  0.08790217], Action: 0, state: 0\n",
      "Action prob: [0.9136705  0.08632945], Action: 0, state: 0\n",
      "Action prob: [0.91783386 0.08216608], Action: 0, state: 0\n",
      "Action prob: [0.9079273  0.09207276], Action: 0, state: 0\n",
      "Action prob: [0.9125672  0.08743284], Action: 0, state: 1\n",
      "Action prob: [0.902404   0.09759593], Action: 0, state: 1\n",
      "Action prob: [0.90814805 0.09185192], Action: 0, state: 2\n",
      "Action prob: [0.91907316 0.08092685], Action: 0, state: 2\n",
      "Action prob: [0.90867317 0.09132685], Action: 0, state: 2\n",
      "Action prob: [0.9092926  0.09070736], Action: 0, state: 2\n",
      "Action prob: [0.9355879  0.06441209], Action: 0, state: 9\n",
      "Action prob: [0.9003195  0.09968052], Action: 0, state: 9\n",
      "Action prob: [0.88921803 0.11078202], Action: 0, state: 9\n",
      "Action prob: [0.89803463 0.10196531], Action: 0, state: 9\n",
      "Action prob: [0.92748064 0.07251929], Action: 0, state: 9\n",
      "Action prob: [0.89329904 0.1067009 ], Action: 0, state: 9\n",
      "Action prob: [0.93198895 0.06801104], Action: 0, state: 9\n",
      "Action prob: [0.92984974 0.0701502 ], Action: 0, state: 9\n",
      "Action prob: [0.92233133 0.07766871], Action: 0, state: 9\n",
      "Action prob: [0.93477166 0.06522833], Action: 0, state: 9\n",
      "Action prob: [0.93443614 0.06556381], Action: 0, state: 9\n",
      "Action prob: [0.93356013 0.0664399 ], Action: 0, state: 9\n",
      "Action prob: [0.9319758 0.0680242], Action: 0, state: 9\n",
      "Action prob: [0.93197    0.06802994], Action: 0, state: 9\n",
      "Action prob: [0.8880022  0.11199774], Action: 0, state: 9\n",
      "Action prob: [0.8444337 0.1555663], Action: 0, state: 9\n",
      "Action prob: [0.93070346 0.06929651], Action: 0, state: 9\n",
      "Action prob: [0.94541    0.05458992], Action: 0, state: 9\n",
      "Action prob: [0.93643564 0.06356441], Action: 0, state: 9\n",
      "Action prob: [0.9247554  0.07524463], Action: 0, state: 9\n",
      "Action prob: [0.88458544 0.11541449], Action: 0, state: 9\n",
      "Action prob: [0.93084896 0.06915106], Action: 0, state: 9\n",
      "Action prob: [0.93120813 0.06879184], Action: 0, state: 9\n",
      "Action prob: [0.92080116 0.07919885], Action: 0, state: 9\n",
      "Action prob: [0.93170244 0.06829759], Action: 0, state: 9\n",
      "Action prob: [0.8941799  0.10582018], Action: 0, state: 9\n",
      "Action prob: [0.9348177  0.06518236], Action: 0, state: 9\n",
      "Action prob: [0.93072194 0.06927803], Action: 0, state: 9\n",
      "Action prob: [0.92582697 0.07417308], Action: 0, state: 9\n",
      "Action prob: [0.93198997 0.06801004], Action: 0, state: 9\n",
      "Action prob: [0.9120524  0.08794763], Action: 0, state: 9\n",
      "Action prob: [0.93256515 0.06743489], Action: 0, state: 9\n",
      "Action prob: [0.9317259  0.06827413], Action: 0, state: 9\n",
      "Action prob: [0.9301385  0.06986149], Action: 0, state: 9\n",
      "Action prob: [0.88976735 0.11023264], Action: 0, state: 9\n",
      "Reward for this episode -24600, loss is 0.10649065636498625\n",
      "Action prob: [0.9216896  0.07831037], Action: 0, state: 0\n",
      "Action prob: [0.9134247  0.08657538], Action: 0, state: 1\n",
      "Action prob: [0.91099393 0.0890061 ], Action: 1, state: 1\n",
      "Action prob: [0.4838808  0.51611924], Action: 0, state: 5\n",
      "Action prob: [0.4838808  0.51611924], Action: 1, state: 5\n",
      "Action prob: [0.90723157 0.09276841], Action: 0, state: 0\n",
      "Action prob: [0.90787214 0.09212781], Action: 0, state: 0\n",
      "Action prob: [0.9309317  0.06906824], Action: 0, state: 0\n",
      "Action prob: [0.9158217  0.08417833], Action: 0, state: 0\n",
      "Action prob: [0.9301495  0.06985047], Action: 0, state: 0\n",
      "Action prob: [0.9163384  0.08366162], Action: 0, state: 1\n",
      "Action prob: [0.91517854 0.08482146], Action: 0, state: 2\n",
      "Action prob: [0.91483384 0.08516619], Action: 0, state: 2\n",
      "Action prob: [0.9174453  0.08255465], Action: 0, state: 2\n",
      "Action prob: [0.9126404  0.08735964], Action: 0, state: 2\n",
      "Action prob: [0.91501164 0.08498839], Action: 0, state: 3\n",
      "Action prob: [0.911043 0.088957], Action: 0, state: 3\n",
      "Action prob: [0.9374034  0.06259666], Action: 0, state: 3\n",
      "Action prob: [0.88784534 0.11215469], Action: 0, state: 3\n",
      "Action prob: [0.92576516 0.07423488], Action: 0, state: 3\n",
      "Action prob: [0.93805194 0.06194811], Action: 0, state: 8\n",
      "Action prob: [0.9318652  0.06813475], Action: 0, state: 8\n",
      "Action prob: [0.9298158  0.07018417], Action: 0, state: 8\n",
      "Action prob: [0.89378154 0.10621852], Action: 0, state: 8\n",
      "Action prob: [0.9335666  0.06643342], Action: 0, state: 8\n",
      "Action prob: [0.88881654 0.11118346], Action: 0, state: 8\n",
      "Action prob: [0.9321845  0.06781553], Action: 0, state: 8\n",
      "Action prob: [0.89571947 0.10428049], Action: 0, state: 8\n",
      "Action prob: [0.8783517 0.1216483], Action: 0, state: 8\n",
      "Action prob: [0.93558204 0.06441797], Action: 0, state: 8\n",
      "Action prob: [0.92614394 0.07385603], Action: 0, state: 8\n",
      "Action prob: [0.9302629  0.06973709], Action: 0, state: 8\n",
      "Action prob: [0.9282339  0.07176602], Action: 0, state: 8\n",
      "Action prob: [0.94764566 0.05235428], Action: 0, state: 8\n",
      "Action prob: [0.9023526  0.09764739], Action: 0, state: 8\n",
      "Action prob: [0.8988878  0.10111215], Action: 0, state: 8\n",
      "Action prob: [0.9351892  0.06481073], Action: 0, state: 8\n",
      "Action prob: [0.9386814  0.06131861], Action: 0, state: 8\n",
      "Action prob: [0.928731   0.07126892], Action: 0, state: 8\n",
      "Action prob: [0.93360937 0.06639063], Action: 0, state: 8\n",
      "Action prob: [0.9322487  0.06775123], Action: 0, state: 8\n",
      "Action prob: [0.89086854 0.10913146], Action: 0, state: 8\n",
      "Action prob: [0.8678872  0.13211279], Action: 0, state: 8\n",
      "Action prob: [0.8964481  0.10355195], Action: 0, state: 8\n",
      "Action prob: [0.8950138  0.10498621], Action: 0, state: 8\n",
      "Action prob: [0.93868405 0.06131594], Action: 0, state: 8\n",
      "Action prob: [0.9324025  0.06759754], Action: 0, state: 8\n",
      "Action prob: [0.90724796 0.09275202], Action: 0, state: 8\n",
      "Action prob: [0.9266405 0.0733595], Action: 0, state: 8\n",
      "Action prob: [0.92643106 0.07356893], Action: 0, state: 8\n",
      "Reward for this episode -80600, loss is 0.1058035010221786\n",
      "Action prob: [0.9192244  0.08077569], Action: 0, state: 0\n",
      "Action prob: [0.91094846 0.08905161], Action: 0, state: 1\n",
      "Action prob: [0.91389686 0.0861032 ], Action: 0, state: 1\n",
      "Action prob: [0.9073198  0.09268019], Action: 0, state: 1\n",
      "Action prob: [0.91981685 0.08018322], Action: 0, state: 1\n",
      "Action prob: [0.9141842 0.0858158], Action: 1, state: 2\n",
      "Action prob: [0.48047245 0.5195275 ], Action: 1, state: 6\n",
      "Action prob: [0.9047522  0.09524784], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.9105639  0.08943616], Action: 0, state: 2\n",
      "Action prob: [0.91353726 0.08646273], Action: 0, state: 3\n",
      "Action prob: [0.9319943  0.06800568], Action: 0, state: 3\n",
      "Action prob: [0.901727   0.09827293], Action: 0, state: 3\n",
      "Action prob: [0.92405385 0.07594611], Action: 0, state: 3\n",
      "Action prob: [0.9103141  0.08968589], Action: 0, state: 3\n",
      "Action prob: [0.9122369  0.08776311], Action: 0, state: 3\n",
      "Action prob: [0.9048136  0.09518642], Action: 0, state: 3\n",
      "Action prob: [0.90667933 0.09332065], Action: 0, state: 3\n",
      "Action prob: [0.9183613  0.08163869], Action: 0, state: 3\n",
      "Action prob: [0.92867255 0.07132747], Action: 0, state: 3\n",
      "Action prob: [0.90783495 0.0921651 ], Action: 0, state: 3\n",
      "Action prob: [0.917068   0.08293205], Action: 0, state: 3\n",
      "Action prob: [0.89495784 0.10504214], Action: 0, state: 8\n",
      "Action prob: [0.9283869  0.07161304], Action: 0, state: 8\n",
      "Action prob: [0.93402576 0.06597419], Action: 0, state: 8\n",
      "Action prob: [0.9332898  0.06671009], Action: 0, state: 8\n",
      "Action prob: [0.9264201  0.07357996], Action: 0, state: 8\n",
      "Action prob: [0.8999338  0.10006615], Action: 1, state: 8\n",
      "Reward for this episode -5400, loss is -0.03965317458015181\n",
      "Action prob: [0.91024977 0.08975018], Action: 0, state: 0\n",
      "Action prob: [0.91363376 0.08636625], Action: 0, state: 1\n",
      "Action prob: [0.9109225 0.0890775], Action: 1, state: 1\n",
      "Action prob: [0.47722375 0.5227762 ], Action: 0, state: 5\n",
      "Action prob: [0.47722375 0.5227762 ], Action: 0, state: 5\n",
      "Action prob: [0.92362213 0.0763778 ], Action: 0, state: 0\n",
      "Action prob: [0.9132557  0.08674429], Action: 0, state: 0\n",
      "Action prob: [0.9174783  0.08252168], Action: 0, state: 1\n",
      "Action prob: [0.90954846 0.09045154], Action: 0, state: 1\n",
      "Action prob: [0.90639216 0.0936078 ], Action: 0, state: 1\n",
      "Action prob: [0.91029894 0.089701  ], Action: 0, state: 2\n",
      "Action prob: [0.9066407  0.09335924], Action: 0, state: 3\n",
      "Action prob: [0.9249565  0.07504347], Action: 0, state: 3\n",
      "Action prob: [0.93344635 0.06655359], Action: 0, state: 8\n",
      "Action prob: [0.9334919  0.06650809], Action: 0, state: 8\n",
      "Action prob: [0.92779803 0.07220191], Action: 0, state: 8\n",
      "Action prob: [0.92675006 0.07324997], Action: 1, state: 8\n",
      "Action prob: [0.92629796 0.07370207], Action: 0, state: 0\n",
      "Action prob: [0.9119553  0.08804474], Action: 0, state: 0\n",
      "Action prob: [0.9129615  0.08703846], Action: 0, state: 0\n",
      "Action prob: [0.9089594 0.0910406], Action: 1, state: 1\n",
      "Action prob: [0.47722375 0.5227762 ], Action: 1, state: 5\n",
      "Action prob: [0.47722375 0.5227762 ], Action: 0, state: 5\n",
      "Reward for this episode -800, loss is 0.03659829104910391\n",
      "Action prob: [0.91415024 0.08584981], Action: 0, state: 0\n",
      "Action prob: [0.9168972  0.08310287], Action: 0, state: 0\n",
      "Action prob: [0.9123275  0.08767248], Action: 0, state: 0\n",
      "Action prob: [0.909647   0.09035306], Action: 0, state: 0\n",
      "Action prob: [0.9149027  0.08509734], Action: 0, state: 0\n",
      "Action prob: [0.91311437 0.08688565], Action: 1, state: 0\n",
      "Action prob: [0.47725192 0.52274805], Action: 0, state: 4\n",
      "Action prob: [0.47725192 0.52274805], Action: 0, state: 4\n",
      "Action prob: [0.9061677  0.09383237], Action: 0, state: 0\n",
      "Action prob: [0.9153549  0.08464512], Action: 0, state: 0\n",
      "Action prob: [0.9100421 0.0899579], Action: 0, state: 0\n",
      "Action prob: [0.90374917 0.09625085], Action: 0, state: 1\n",
      "Action prob: [0.9188417  0.08115829], Action: 0, state: 1\n",
      "Action prob: [0.917467   0.08253298], Action: 0, state: 2\n",
      "Action prob: [0.91660446 0.08339556], Action: 0, state: 2\n",
      "Action prob: [0.90685135 0.09314862], Action: 0, state: 2\n",
      "Action prob: [0.9096214  0.09037858], Action: 1, state: 2\n",
      "Action prob: [0.47725192 0.52274805], Action: 1, state: 6\n",
      "Action prob: [0.47725192 0.52274805], Action: 0, state: 6\n",
      "Action prob: [0.47725192 0.52274805], Action: 0, state: 6\n",
      "Action prob: [0.9139634  0.08603669], Action: 0, state: 1\n",
      "Action prob: [0.90967596 0.090324  ], Action: 1, state: 1\n",
      "Action prob: [0.47725192 0.52274805], Action: 1, state: 5\n",
      "Action prob: [0.47725192 0.52274805], Action: 1, state: 5\n",
      "Reward for this episode 12300, loss is -0.2204076609200275\n",
      "Action prob: [0.91319513 0.0868048 ], Action: 1, state: 0\n",
      "Action prob: [0.92520857 0.07479145], Action: 0, state: 9\n",
      "Action prob: [0.9394912  0.06050879], Action: 0, state: 9\n",
      "Action prob: [0.9318353  0.06816471], Action: 0, state: 9\n",
      "Action prob: [0.93322456 0.0667755 ], Action: 0, state: 9\n",
      "Action prob: [0.9386587  0.06134126], Action: 0, state: 9\n",
      "Action prob: [0.9301779  0.06982204], Action: 0, state: 9\n",
      "Action prob: [0.9007076  0.09929239], Action: 0, state: 9\n",
      "Action prob: [0.89615285 0.10384715], Action: 0, state: 9\n",
      "Action prob: [0.94299495 0.05700505], Action: 0, state: 9\n",
      "Action prob: [0.87498355 0.12501644], Action: 0, state: 9\n",
      "Action prob: [0.9325017  0.06749826], Action: 0, state: 9\n",
      "Action prob: [0.889707   0.11029299], Action: 0, state: 9\n",
      "Action prob: [0.9320586  0.06794149], Action: 0, state: 9\n",
      "Action prob: [0.8970286  0.10297141], Action: 0, state: 9\n",
      "Action prob: [0.9364021  0.06359796], Action: 0, state: 9\n",
      "Action prob: [0.92544335 0.07455663], Action: 0, state: 9\n",
      "Action prob: [0.8883969  0.11160313], Action: 0, state: 9\n",
      "Action prob: [0.89046663 0.10953339], Action: 0, state: 9\n",
      "Action prob: [0.9136944  0.08630566], Action: 0, state: 9\n",
      "Action prob: [0.92118293 0.07881702], Action: 0, state: 9\n",
      "Action prob: [0.9161899  0.08381011], Action: 0, state: 9\n",
      "Action prob: [0.8922085  0.10779145], Action: 0, state: 9\n",
      "Action prob: [0.89486915 0.10513087], Action: 1, state: 9\n",
      "Action prob: [0.8930623  0.10693771], Action: 1, state: 9\n",
      "Action prob: [0.9292023  0.07079766], Action: 1, state: 9\n",
      "Action prob: [0.9148099  0.08519008], Action: 0, state: 9\n",
      "Action prob: [0.8879222  0.11207771], Action: 0, state: 9\n",
      "Action prob: [0.9367099  0.06329007], Action: 0, state: 9\n",
      "Action prob: [0.9260094  0.07399058], Action: 0, state: 9\n",
      "Action prob: [0.8930361  0.10696385], Action: 0, state: 9\n",
      "Action prob: [0.9054009  0.09459914], Action: 0, state: 9\n",
      "Action prob: [0.9295253  0.07047473], Action: 0, state: 9\n",
      "Action prob: [0.9439823 0.0560177], Action: 0, state: 9\n",
      "Action prob: [0.9320597  0.06794032], Action: 0, state: 9\n",
      "Action prob: [0.93480664 0.0651934 ], Action: 0, state: 9\n",
      "Action prob: [0.9312071  0.06879284], Action: 1, state: 9\n",
      "Action prob: [0.9219682  0.07803179], Action: 0, state: 9\n",
      "Action prob: [0.8931899  0.10681014], Action: 0, state: 9\n",
      "Action prob: [0.9302094  0.06979065], Action: 0, state: 9\n",
      "Action prob: [0.89530885 0.10469117], Action: 0, state: 9\n",
      "Action prob: [0.8943134  0.10568652], Action: 0, state: 9\n",
      "Action prob: [0.9309941  0.06900591], Action: 0, state: 9\n",
      "Action prob: [0.8897172  0.11028276], Action: 1, state: 9\n",
      "Action prob: [0.8934748  0.10652519], Action: 0, state: 9\n",
      "Action prob: [0.91999036 0.08000962], Action: 0, state: 9\n",
      "Action prob: [0.9335972  0.06640285], Action: 0, state: 9\n",
      "Action prob: [0.9335059  0.06649414], Action: 0, state: 9\n",
      "Action prob: [0.89367527 0.10632476], Action: 0, state: 9\n",
      "Action prob: [0.9087968 0.0912032], Action: 0, state: 9\n",
      "Reward for this episode -50000, loss is -0.10496851673451656\n",
      "Action prob: [0.916146   0.08385404], Action: 0, state: 0\n",
      "Action prob: [0.92332214 0.07667782], Action: 0, state: 1\n",
      "Action prob: [0.91624284 0.0837572 ], Action: 0, state: 2\n",
      "Action prob: [0.92447716 0.07552277], Action: 0, state: 2\n",
      "Action prob: [0.92244655 0.07755344], Action: 0, state: 2\n",
      "Action prob: [0.9172248  0.08277516], Action: 0, state: 2\n",
      "Action prob: [0.91326344 0.08673657], Action: 1, state: 2\n",
      "Action prob: [0.48068956 0.5193104 ], Action: 1, state: 6\n",
      "Action prob: [0.91950077 0.08049925], Action: 0, state: 1\n",
      "Action prob: [0.90858805 0.09141196], Action: 0, state: 1\n",
      "Action prob: [0.9208638  0.07913617], Action: 0, state: 1\n",
      "Action prob: [0.91592866 0.08407126], Action: 0, state: 1\n",
      "Action prob: [0.9112123  0.08878762], Action: 0, state: 2\n",
      "Action prob: [0.91720194 0.08279799], Action: 0, state: 3\n",
      "Action prob: [0.91961396 0.08038606], Action: 0, state: 3\n",
      "Action prob: [0.91371804 0.08628188], Action: 0, state: 3\n",
      "Action prob: [0.88054407 0.11945596], Action: 0, state: 3\n",
      "Action prob: [0.9180937  0.08190632], Action: 0, state: 3\n",
      "Action prob: [0.93779415 0.06220586], Action: 0, state: 8\n",
      "Action prob: [0.89674115 0.10325887], Action: 0, state: 8\n",
      "Action prob: [0.9442594  0.05574064], Action: 0, state: 8\n",
      "Action prob: [0.9410207  0.05897931], Action: 0, state: 8\n",
      "Action prob: [0.89216584 0.10783412], Action: 0, state: 8\n",
      "Action prob: [0.8956421  0.10435796], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.8921404  0.10785957], Action: 0, state: 8\n",
      "Action prob: [0.9394144  0.06058554], Action: 0, state: 8\n",
      "Action prob: [0.85182834 0.1481716 ], Action: 0, state: 8\n",
      "Action prob: [0.9381846 0.0618154], Action: 0, state: 8\n",
      "Action prob: [0.9185148  0.08148524], Action: 0, state: 8\n",
      "Action prob: [0.9018712  0.09812883], Action: 0, state: 8\n",
      "Action prob: [0.89978004 0.10022   ], Action: 0, state: 8\n",
      "Action prob: [0.93125963 0.06874042], Action: 0, state: 8\n",
      "Action prob: [0.93633986 0.06366016], Action: 0, state: 8\n",
      "Action prob: [0.93601954 0.06398047], Action: 0, state: 8\n",
      "Action prob: [0.936122   0.06387801], Action: 0, state: 8\n",
      "Action prob: [0.92935157 0.07064839], Action: 0, state: 8\n",
      "Action prob: [0.9477536  0.05224639], Action: 0, state: 8\n",
      "Action prob: [0.9267985  0.07320153], Action: 0, state: 8\n",
      "Action prob: [0.9347363 0.0652637], Action: 0, state: 8\n",
      "Action prob: [0.9264324  0.07356767], Action: 0, state: 8\n",
      "Action prob: [0.94150054 0.0584995 ], Action: 0, state: 8\n",
      "Action prob: [0.8964979  0.10350215], Action: 0, state: 8\n",
      "Action prob: [0.898873   0.10112701], Action: 0, state: 8\n",
      "Action prob: [0.93857765 0.06142237], Action: 0, state: 8\n",
      "Action prob: [0.9119549 0.0880451], Action: 0, state: 8\n",
      "Action prob: [0.89450526 0.10549474], Action: 0, state: 8\n",
      "Action prob: [0.8963493  0.10365067], Action: 0, state: 8\n",
      "Action prob: [0.9289716  0.07102841], Action: 0, state: 8\n",
      "Action prob: [0.9495096  0.05049033], Action: 0, state: 8\n",
      "Action prob: [0.9278124  0.07218757], Action: 0, state: 8\n",
      "Reward for this episode -87700, loss is -0.004541821215228177\n",
      "Action prob: [0.91867864 0.08132138], Action: 0, state: 0\n",
      "Action prob: [0.9223471  0.07765289], Action: 0, state: 0\n",
      "Action prob: [0.9184122  0.08158784], Action: 0, state: 1\n",
      "Action prob: [0.9143959 0.0856041], Action: 0, state: 1\n",
      "Action prob: [0.9236166  0.07638339], Action: 0, state: 1\n",
      "Action prob: [0.9199285  0.08007154], Action: 0, state: 2\n",
      "Action prob: [0.91860944 0.08139057], Action: 0, state: 2\n",
      "Action prob: [0.9252656 0.0747344], Action: 0, state: 2\n",
      "Action prob: [0.93433654 0.06566344], Action: 0, state: 3\n",
      "Action prob: [0.9317544  0.06824564], Action: 0, state: 8\n",
      "Action prob: [0.9272937  0.07270624], Action: 1, state: 8\n",
      "Action prob: [0.9328213  0.06717877], Action: 0, state: 0\n",
      "Action prob: [0.9119713 0.0880288], Action: 0, state: 0\n",
      "Action prob: [0.9077526  0.09224742], Action: 0, state: 0\n",
      "Action prob: [0.9280064  0.07199364], Action: 0, state: 0\n",
      "Action prob: [0.9170977  0.08290235], Action: 0, state: 1\n",
      "Action prob: [0.9258042  0.07419584], Action: 0, state: 2\n",
      "Action prob: [0.9168473 0.0831527], Action: 0, state: 2\n",
      "Action prob: [0.91847545 0.0815246 ], Action: 0, state: 2\n",
      "Action prob: [0.91404444 0.08595563], Action: 1, state: 2\n",
      "Action prob: [0.48211443 0.51788557], Action: 0, state: 6\n",
      "Action prob: [0.92448604 0.07551395], Action: 1, state: 1\n",
      "Action prob: [0.48211443 0.51788557], Action: 0, state: 5\n",
      "Action prob: [0.48211443 0.51788557], Action: 0, state: 5\n",
      "Action prob: [0.48211443 0.51788557], Action: 1, state: 5\n",
      "Reward for this episode 8600, loss is -0.13413239873568072\n",
      "Action prob: [0.9376951  0.06230487], Action: 0, state: 0\n",
      "Action prob: [0.92492723 0.07507274], Action: 0, state: 1\n",
      "Action prob: [0.92624193 0.07375811], Action: 0, state: 1\n",
      "Action prob: [0.91533595 0.08466406], Action: 0, state: 1\n",
      "Action prob: [0.9434153  0.05658477], Action: 0, state: 1\n",
      "Action prob: [0.92092437 0.07907563], Action: 0, state: 1\n",
      "Action prob: [0.90065867 0.09934134], Action: 0, state: 9\n",
      "Action prob: [0.9432642  0.05673576], Action: 0, state: 9\n",
      "Action prob: [0.9352252  0.06477486], Action: 0, state: 9\n",
      "Action prob: [0.9299903  0.07000975], Action: 0, state: 9\n",
      "Action prob: [0.92615956 0.07384039], Action: 0, state: 9\n",
      "Action prob: [0.92196286 0.07803712], Action: 0, state: 9\n",
      "Action prob: [0.95266986 0.04733008], Action: 0, state: 9\n",
      "Action prob: [0.8997853  0.10021473], Action: 1, state: 9\n",
      "Action prob: [0.93635374 0.06364618], Action: 0, state: 9\n",
      "Action prob: [0.93898445 0.06101557], Action: 0, state: 9\n",
      "Action prob: [0.92388636 0.07611363], Action: 0, state: 9\n",
      "Action prob: [0.9341864  0.06581359], Action: 1, state: 9\n",
      "Action prob: [0.92778236 0.0722177 ], Action: 0, state: 9\n",
      "Action prob: [0.9405703  0.05942966], Action: 0, state: 9\n",
      "Action prob: [0.90892947 0.09107051], Action: 1, state: 9\n",
      "Action prob: [0.9387187  0.06128129], Action: 0, state: 9\n",
      "Action prob: [0.92553574 0.0744643 ], Action: 0, state: 9\n",
      "Action prob: [0.9420862  0.05791382], Action: 0, state: 9\n",
      "Action prob: [0.9308566  0.06914341], Action: 0, state: 9\n",
      "Action prob: [0.95039713 0.04960285], Action: 0, state: 9\n",
      "Action prob: [0.9405318  0.05946813], Action: 0, state: 9\n",
      "Action prob: [0.89764965 0.10235037], Action: 1, state: 9\n",
      "Action prob: [0.93684036 0.0631597 ], Action: 0, state: 9\n",
      "Action prob: [0.94177455 0.05822549], Action: 0, state: 9\n",
      "Action prob: [0.9000745  0.09992547], Action: 0, state: 9\n",
      "Action prob: [0.9109053  0.08909471], Action: 0, state: 9\n",
      "Action prob: [0.93442607 0.06557392], Action: 0, state: 9\n",
      "Action prob: [0.9080169  0.09198311], Action: 0, state: 9\n",
      "Action prob: [0.9317251  0.06827495], Action: 0, state: 9\n",
      "Action prob: [0.9373292  0.06267078], Action: 0, state: 9\n",
      "Action prob: [0.8955247  0.10447536], Action: 0, state: 9\n",
      "Action prob: [0.9352228  0.06477716], Action: 0, state: 9\n",
      "Action prob: [0.93022996 0.06977006], Action: 0, state: 9\n",
      "Action prob: [0.9381381  0.06186184], Action: 0, state: 9\n",
      "Action prob: [0.93594927 0.0640508 ], Action: 0, state: 9\n",
      "Action prob: [0.9461694  0.05383065], Action: 0, state: 9\n",
      "Action prob: [0.9437633  0.05623673], Action: 0, state: 9\n",
      "Action prob: [0.90770596 0.09229411], Action: 0, state: 9\n",
      "Action prob: [0.9028653  0.09713474], Action: 0, state: 9\n",
      "Action prob: [0.9387479  0.06125212], Action: 0, state: 9\n",
      "Action prob: [0.9242485  0.07575146], Action: 0, state: 9\n",
      "Action prob: [0.9361084  0.06389155], Action: 0, state: 9\n",
      "Action prob: [0.9170413  0.08295862], Action: 0, state: 9\n",
      "Action prob: [0.9362724  0.06372759], Action: 0, state: 9\n",
      "Reward for this episode -40500, loss is 0.00545908083677335\n",
      "Action prob: [0.92076135 0.07923868], Action: 0, state: 0\n",
      "Action prob: [0.9294863  0.07051372], Action: 0, state: 0\n",
      "Action prob: [0.9339741 0.0660259], Action: 0, state: 0\n",
      "Action prob: [0.92145294 0.07854709], Action: 1, state: 0\n",
      "Action prob: [0.48314464 0.5168554 ], Action: 1, state: 4\n",
      "Action prob: [0.48314464 0.5168554 ], Action: 1, state: 4\n",
      "Action prob: [0.48314464 0.5168554 ], Action: 0, state: 4\n",
      "Action prob: [0.9253454 0.0746546], Action: 0, state: 0\n",
      "Action prob: [0.9427133  0.05728666], Action: 0, state: 9\n",
      "Action prob: [0.9177392  0.08226082], Action: 0, state: 9\n",
      "Action prob: [0.9215585  0.07844149], Action: 1, state: 9\n",
      "Action prob: [0.93406373 0.06593624], Action: 0, state: 9\n",
      "Action prob: [0.91329855 0.08670148], Action: 0, state: 9\n",
      "Action prob: [0.93258226 0.06741773], Action: 0, state: 9\n",
      "Action prob: [0.9027714  0.09722855], Action: 0, state: 9\n",
      "Action prob: [0.89736325 0.10263678], Action: 1, state: 9\n",
      "Action prob: [0.89884794 0.10115203], Action: 0, state: 9\n",
      "Action prob: [0.9403831 0.059617 ], Action: 0, state: 9\n",
      "Action prob: [0.9424584  0.05754167], Action: 0, state: 9\n",
      "Action prob: [0.9449673  0.05503266], Action: 0, state: 9\n",
      "Action prob: [0.9170066  0.08299334], Action: 0, state: 9\n",
      "Action prob: [0.9026847 0.0973153], Action: 0, state: 9\n",
      "Action prob: [0.9022264 0.0977736], Action: 0, state: 9\n",
      "Action prob: [0.89074403 0.10925595], Action: 1, state: 9\n",
      "Action prob: [0.9140713  0.08592865], Action: 0, state: 9\n",
      "Action prob: [0.91389537 0.08610459], Action: 0, state: 9\n",
      "Action prob: [0.9398632  0.06013686], Action: 0, state: 9\n",
      "Action prob: [0.88773835 0.11226168], Action: 0, state: 9\n",
      "Action prob: [0.9431357  0.05686434], Action: 1, state: 9\n",
      "Action prob: [0.9407053  0.05929469], Action: 0, state: 9\n",
      "Action prob: [0.93704116 0.06295887], Action: 0, state: 9\n",
      "Action prob: [0.93996483 0.06003512], Action: 0, state: 9\n",
      "Action prob: [0.90109664 0.09890331], Action: 0, state: 9\n",
      "Action prob: [0.9340472  0.06595281], Action: 0, state: 9\n",
      "Action prob: [0.92579365 0.0742063 ], Action: 0, state: 9\n",
      "Action prob: [0.93900955 0.06099042], Action: 0, state: 9\n",
      "Action prob: [0.9381297  0.06187028], Action: 0, state: 9\n",
      "Action prob: [0.93741804 0.06258197], Action: 0, state: 9\n",
      "Action prob: [0.9367473  0.06325267], Action: 0, state: 9\n",
      "Action prob: [0.9027517  0.09724829], Action: 0, state: 9\n",
      "Action prob: [0.93797725 0.06202275], Action: 0, state: 9\n",
      "Action prob: [0.9477036  0.05229642], Action: 0, state: 9\n",
      "Action prob: [0.9437116  0.05628842], Action: 0, state: 9\n",
      "Action prob: [0.91421694 0.08578303], Action: 0, state: 9\n",
      "Action prob: [0.9415089  0.05849105], Action: 0, state: 9\n",
      "Action prob: [0.9461131  0.05388682], Action: 0, state: 9\n",
      "Action prob: [0.9394467  0.06055331], Action: 0, state: 9\n",
      "Action prob: [0.9129449  0.08705513], Action: 0, state: 9\n",
      "Action prob: [0.9419333  0.05806671], Action: 0, state: 9\n",
      "Action prob: [0.94111776 0.05888223], Action: 0, state: 9\n",
      "Reward for this episode -40500, loss is -0.24109498945021293\n",
      "Action prob: [0.93321854 0.06678149], Action: 0, state: 0\n",
      "Action prob: [0.9258182  0.07418177], Action: 0, state: 0\n",
      "Action prob: [0.92721164 0.07278838], Action: 0, state: 0\n",
      "Action prob: [0.9247397  0.07526031], Action: 0, state: 1\n",
      "Action prob: [0.930157   0.06984297], Action: 0, state: 1\n",
      "Action prob: [0.9357304  0.06426961], Action: 0, state: 1\n",
      "Action prob: [0.92904216 0.07095784], Action: 1, state: 1\n",
      "Action prob: [0.4857253 0.5142746], Action: 1, state: 5\n",
      "Action prob: [0.4857253 0.5142746], Action: 0, state: 5\n",
      "Action prob: [0.4857253 0.5142746], Action: 0, state: 5\n",
      "Action prob: [0.4857253 0.5142746], Action: 1, state: 5\n",
      "Action prob: [0.9155441  0.08445591], Action: 0, state: 0\n",
      "Action prob: [0.925667   0.07433306], Action: 0, state: 0\n",
      "Action prob: [0.93113095 0.06886905], Action: 0, state: 0\n",
      "Action prob: [0.9262178  0.07378224], Action: 0, state: 0\n",
      "Action prob: [0.9335516  0.06644844], Action: 0, state: 0\n",
      "Action prob: [0.9331966 0.0668034], Action: 0, state: 1\n",
      "Action prob: [0.9365261  0.06347383], Action: 0, state: 1\n",
      "Action prob: [0.9358035  0.06419647], Action: 0, state: 1\n",
      "Action prob: [0.9330207  0.06697926], Action: 0, state: 1\n",
      "Action prob: [0.9307148  0.06928518], Action: 0, state: 1\n",
      "Action prob: [0.9459739  0.05402607], Action: 0, state: 1\n",
      "Action prob: [0.93021584 0.06978417], Action: 0, state: 1\n",
      "Action prob: [0.93740284 0.06259719], Action: 0, state: 2\n",
      "Action prob: [0.9345095  0.06549051], Action: 1, state: 2\n",
      "Action prob: [0.4857253 0.5142746], Action: 0, state: 6\n",
      "Action prob: [0.94126993 0.0587301 ], Action: 0, state: 1\n",
      "Action prob: [0.9284132  0.07158683], Action: 0, state: 1\n",
      "Action prob: [0.94327617 0.05672381], Action: 0, state: 2\n",
      "Action prob: [0.92192584 0.07807419], Action: 0, state: 3\n",
      "Action prob: [0.9307566  0.06924336], Action: 0, state: 3\n",
      "Action prob: [0.92601234 0.07398768], Action: 0, state: 3\n",
      "Action prob: [0.93489903 0.06510096], Action: 0, state: 3\n",
      "Action prob: [0.9294254  0.07057464], Action: 0, state: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.92871964 0.0712804 ], Action: 0, state: 8\n",
      "Action prob: [0.92030865 0.07969136], Action: 0, state: 8\n",
      "Action prob: [0.9576335  0.04236647], Action: 0, state: 8\n",
      "Action prob: [0.916034   0.08396598], Action: 1, state: 8\n",
      "Action prob: [0.9460261  0.05397398], Action: 0, state: 8\n",
      "Action prob: [0.9106484  0.08935158], Action: 0, state: 8\n",
      "Action prob: [0.9444816  0.05551835], Action: 0, state: 8\n",
      "Action prob: [0.93985885 0.06014108], Action: 1, state: 8\n",
      "Action prob: [0.9572164  0.04278357], Action: 0, state: 8\n",
      "Action prob: [0.9230258  0.07697425], Action: 0, state: 8\n",
      "Action prob: [0.9410122 0.0589878], Action: 0, state: 8\n",
      "Action prob: [0.9120453  0.08795463], Action: 0, state: 8\n",
      "Action prob: [0.9408439  0.05915614], Action: 0, state: 8\n",
      "Action prob: [0.9134235  0.08657648], Action: 0, state: 8\n",
      "Action prob: [0.94593793 0.05406203], Action: 0, state: 8\n",
      "Action prob: [0.91058373 0.08941624], Action: 0, state: 8\n",
      "Reward for this episode -29900, loss is -0.08806525791710317\n",
      "Action prob: [0.9334321  0.06656788], Action: 0, state: 0\n",
      "Action prob: [0.92651814 0.07348189], Action: 1, state: 1\n",
      "Action prob: [0.48816842 0.5118316 ], Action: 0, state: 5\n",
      "Action prob: [0.48816842 0.5118316 ], Action: 0, state: 5\n",
      "Action prob: [0.9329913  0.06700866], Action: 0, state: 0\n",
      "Action prob: [0.9385978  0.06140223], Action: 0, state: 0\n",
      "Action prob: [0.9338169 0.0661831], Action: 0, state: 1\n",
      "Action prob: [0.94068336 0.05931659], Action: 0, state: 1\n",
      "Action prob: [0.9333479  0.06665211], Action: 0, state: 1\n",
      "Action prob: [0.93261105 0.06738894], Action: 0, state: 1\n",
      "Action prob: [0.93364435 0.06635565], Action: 0, state: 2\n",
      "Action prob: [0.93200946 0.06799051], Action: 0, state: 2\n",
      "Action prob: [0.93475235 0.06524761], Action: 0, state: 2\n",
      "Action prob: [0.9321205 0.0678795], Action: 0, state: 2\n",
      "Action prob: [0.9336973  0.06630277], Action: 0, state: 2\n",
      "Action prob: [0.9384394 0.0615605], Action: 0, state: 2\n",
      "Action prob: [0.9356963 0.0643037], Action: 0, state: 3\n",
      "Action prob: [0.914435   0.08556495], Action: 0, state: 8\n",
      "Action prob: [0.9503775  0.04962241], Action: 0, state: 8\n",
      "Action prob: [0.9466079  0.05339216], Action: 0, state: 8\n",
      "Action prob: [0.9523695  0.04763051], Action: 0, state: 8\n",
      "Action prob: [0.9526568  0.04734317], Action: 0, state: 8\n",
      "Action prob: [0.9459389  0.05406108], Action: 0, state: 8\n",
      "Action prob: [0.9490152  0.05098487], Action: 0, state: 8\n",
      "Action prob: [0.91610736 0.08389268], Action: 0, state: 8\n",
      "Action prob: [0.9604354  0.03956459], Action: 0, state: 8\n",
      "Action prob: [0.94678766 0.05321227], Action: 0, state: 8\n",
      "Action prob: [0.94513667 0.05486331], Action: 0, state: 8\n",
      "Action prob: [0.94524235 0.05475766], Action: 0, state: 8\n",
      "Action prob: [0.91751176 0.08248829], Action: 0, state: 8\n",
      "Action prob: [0.91404265 0.08595735], Action: 0, state: 8\n",
      "Action prob: [0.9460322 0.0539677], Action: 0, state: 8\n",
      "Action prob: [0.95338917 0.0466108 ], Action: 0, state: 8\n",
      "Action prob: [0.94338346 0.05661658], Action: 0, state: 8\n",
      "Action prob: [0.91834134 0.08165872], Action: 0, state: 8\n",
      "Action prob: [0.9166248  0.08337523], Action: 0, state: 8\n",
      "Action prob: [0.9524703  0.04752963], Action: 0, state: 8\n",
      "Action prob: [0.92093754 0.07906254], Action: 0, state: 8\n",
      "Action prob: [0.9106919  0.08930809], Action: 0, state: 8\n",
      "Action prob: [0.9555833  0.04441672], Action: 0, state: 8\n",
      "Action prob: [0.9463072  0.05369278], Action: 0, state: 8\n",
      "Action prob: [0.9457789  0.05422108], Action: 0, state: 8\n",
      "Action prob: [0.95202464 0.04797535], Action: 0, state: 8\n",
      "Action prob: [0.9144241  0.08557582], Action: 0, state: 8\n",
      "Action prob: [0.91724056 0.0827594 ], Action: 1, state: 8\n",
      "Action prob: [0.95498204 0.04501802], Action: 0, state: 8\n",
      "Action prob: [0.9519651  0.04803492], Action: 0, state: 8\n",
      "Action prob: [0.9461209  0.05387905], Action: 0, state: 8\n",
      "Action prob: [0.92205364 0.07794631], Action: 0, state: 8\n",
      "Action prob: [0.962074   0.03792595], Action: 0, state: 8\n",
      "Reward for this episode -91200, loss is 0.14097088193387125\n",
      "Action prob: [0.9428658  0.05713426], Action: 0, state: 0\n",
      "Action prob: [0.9399599  0.06004013], Action: 0, state: 1\n",
      "Action prob: [0.9450909  0.05490907], Action: 0, state: 1\n",
      "Action prob: [0.942972   0.05702802], Action: 0, state: 1\n",
      "Action prob: [0.94027627 0.05972373], Action: 0, state: 1\n",
      "Action prob: [0.93337977 0.06662026], Action: 0, state: 2\n",
      "Action prob: [0.9459983  0.05400166], Action: 0, state: 2\n",
      "Action prob: [0.93586385 0.06413612], Action: 0, state: 2\n",
      "Action prob: [0.9353812  0.06461877], Action: 0, state: 3\n",
      "Action prob: [0.9434259 0.0565741], Action: 0, state: 3\n",
      "Action prob: [0.9439087  0.05609135], Action: 0, state: 3\n",
      "Action prob: [0.9518677  0.04813232], Action: 0, state: 8\n",
      "Action prob: [0.95141804 0.04858195], Action: 0, state: 8\n",
      "Action prob: [0.9632634  0.03673657], Action: 0, state: 8\n",
      "Action prob: [0.91986704 0.08013293], Action: 0, state: 8\n",
      "Action prob: [0.9488943  0.05110576], Action: 0, state: 8\n",
      "Action prob: [0.9141105  0.08588956], Action: 0, state: 8\n",
      "Action prob: [0.9221258  0.07787422], Action: 0, state: 8\n",
      "Action prob: [0.9298253  0.07017464], Action: 0, state: 8\n",
      "Action prob: [0.9627357  0.03726433], Action: 0, state: 8\n",
      "Action prob: [0.92131025 0.07868972], Action: 0, state: 8\n",
      "Action prob: [0.9186048  0.08139525], Action: 0, state: 8\n",
      "Action prob: [0.9128366  0.08716341], Action: 0, state: 8\n",
      "Action prob: [0.949693   0.05030698], Action: 0, state: 8\n",
      "Action prob: [0.92489195 0.07510806], Action: 0, state: 8\n",
      "Action prob: [0.9520468  0.04795324], Action: 0, state: 8\n",
      "Action prob: [0.94192916 0.05807085], Action: 0, state: 8\n",
      "Action prob: [0.91807276 0.08192722], Action: 0, state: 8\n",
      "Action prob: [0.95320594 0.04679401], Action: 0, state: 8\n",
      "Action prob: [0.948796   0.05120397], Action: 0, state: 8\n",
      "Action prob: [0.91973966 0.08026029], Action: 0, state: 8\n",
      "Action prob: [0.9395496  0.06045039], Action: 0, state: 8\n",
      "Action prob: [0.95521224 0.0447877 ], Action: 0, state: 8\n",
      "Action prob: [0.94232094 0.05767903], Action: 0, state: 8\n",
      "Action prob: [0.91409004 0.08590992], Action: 0, state: 8\n",
      "Action prob: [0.9609293  0.03907068], Action: 0, state: 8\n",
      "Action prob: [0.9496587  0.05034123], Action: 0, state: 8\n",
      "Action prob: [0.9558007  0.04419927], Action: 1, state: 8\n",
      "Action prob: [0.9539107  0.04608929], Action: 0, state: 8\n",
      "Action prob: [0.9512621  0.04873789], Action: 0, state: 8\n",
      "Action prob: [0.9217425  0.07825752], Action: 0, state: 8\n",
      "Action prob: [0.91513574 0.08486434], Action: 0, state: 8\n",
      "Action prob: [0.91414416 0.08585583], Action: 0, state: 8\n",
      "Action prob: [0.94930893 0.05069113], Action: 0, state: 8\n",
      "Action prob: [0.9537999  0.04620007], Action: 0, state: 8\n",
      "Action prob: [0.944662   0.05533801], Action: 0, state: 8\n",
      "Action prob: [0.9247532  0.07524681], Action: 0, state: 8\n",
      "Action prob: [0.9180987  0.08190136], Action: 0, state: 8\n",
      "Action prob: [0.95111275 0.04888723], Action: 0, state: 8\n",
      "Action prob: [0.94460905 0.05539099], Action: 0, state: 8\n",
      "Reward for this episode -112500, loss is 0.003749757810942264\n",
      "Action prob: [0.9447355  0.05526452], Action: 0, state: 0\n",
      "Action prob: [0.94373155 0.05626841], Action: 0, state: 0\n",
      "Action prob: [0.9409079  0.05909206], Action: 0, state: 0\n",
      "Action prob: [0.9430238  0.05697621], Action: 1, state: 0\n",
      "Action prob: [0.49783513 0.5021649 ], Action: 0, state: 4\n",
      "Action prob: [0.93902457 0.06097537], Action: 0, state: 0\n",
      "Action prob: [0.9402274  0.05977267], Action: 0, state: 1\n",
      "Action prob: [0.9462146  0.05378542], Action: 0, state: 1\n",
      "Action prob: [0.9380361  0.06196389], Action: 0, state: 2\n",
      "Action prob: [0.9422224  0.05777754], Action: 0, state: 2\n",
      "Action prob: [0.93896717 0.06103279], Action: 0, state: 2\n",
      "Action prob: [0.941503   0.05849698], Action: 0, state: 2\n",
      "Action prob: [0.9477189  0.05228104], Action: 0, state: 2\n",
      "Action prob: [0.92936206 0.07063787], Action: 0, state: 3\n",
      "Action prob: [0.95444036 0.04555962], Action: 0, state: 3\n",
      "Action prob: [0.95188147 0.04811849], Action: 0, state: 8\n",
      "Action prob: [0.96124333 0.03875665], Action: 0, state: 8\n",
      "Action prob: [0.971492   0.02850805], Action: 0, state: 8\n",
      "Action prob: [0.9423364  0.05766364], Action: 0, state: 8\n",
      "Action prob: [0.95195884 0.04804116], Action: 0, state: 8\n",
      "Action prob: [0.9233233  0.07667673], Action: 0, state: 8\n",
      "Action prob: [0.9521181 0.0478819], Action: 0, state: 8\n",
      "Action prob: [0.94729114 0.05270885], Action: 0, state: 8\n",
      "Action prob: [0.9548254  0.04517459], Action: 0, state: 8\n",
      "Action prob: [0.9572859  0.04271409], Action: 0, state: 8\n",
      "Action prob: [0.9697114  0.03028852], Action: 0, state: 8\n",
      "Action prob: [0.95312613 0.04687387], Action: 0, state: 8\n",
      "Action prob: [0.96490544 0.03509456], Action: 0, state: 8\n",
      "Action prob: [0.9541314  0.04586859], Action: 0, state: 8\n",
      "Action prob: [0.9247647  0.07523534], Action: 0, state: 8\n",
      "Action prob: [0.95078224 0.04921776], Action: 0, state: 8\n",
      "Action prob: [0.95262617 0.04737379], Action: 0, state: 8\n",
      "Action prob: [0.9604847  0.03951538], Action: 1, state: 8\n",
      "Reward for this episode -42700, loss is 0.05355607836373678\n",
      "Action prob: [0.9451941  0.05480596], Action: 0, state: 0\n",
      "Action prob: [0.942615   0.05738503], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.94929236 0.05070769], Action: 0, state: 0\n",
      "Action prob: [0.93762887 0.06237118], Action: 0, state: 1\n",
      "Action prob: [0.9419688  0.05803123], Action: 0, state: 1\n",
      "Action prob: [0.9447099  0.05529018], Action: 0, state: 1\n",
      "Action prob: [0.93719476 0.06280527], Action: 0, state: 1\n",
      "Action prob: [0.94946516 0.0505349 ], Action: 0, state: 1\n",
      "Action prob: [0.942326   0.05767393], Action: 0, state: 1\n",
      "Action prob: [0.9415444  0.05845558], Action: 0, state: 2\n",
      "Action prob: [0.940203   0.05979694], Action: 0, state: 3\n",
      "Action prob: [0.93588537 0.06411461], Action: 0, state: 3\n",
      "Action prob: [0.95915616 0.04084384], Action: 0, state: 3\n",
      "Action prob: [0.95239407 0.04760595], Action: 0, state: 8\n",
      "Action prob: [0.95767075 0.04232923], Action: 0, state: 8\n",
      "Action prob: [0.95913893 0.04086109], Action: 0, state: 8\n",
      "Action prob: [0.92535144 0.07464857], Action: 0, state: 8\n",
      "Action prob: [0.9544241  0.04557586], Action: 0, state: 8\n",
      "Action prob: [0.95344347 0.04655657], Action: 0, state: 8\n",
      "Action prob: [0.9236384  0.07636156], Action: 0, state: 8\n",
      "Action prob: [0.95779246 0.04220753], Action: 0, state: 8\n",
      "Action prob: [0.9607127  0.03928732], Action: 0, state: 8\n",
      "Action prob: [0.9268624  0.07313763], Action: 0, state: 8\n",
      "Action prob: [0.95403147 0.04596852], Action: 0, state: 8\n",
      "Action prob: [0.9290862  0.07091375], Action: 0, state: 8\n",
      "Action prob: [0.9270392 0.0729608], Action: 0, state: 8\n",
      "Action prob: [0.9292505  0.07074951], Action: 1, state: 8\n",
      "Reward for this episode -31300, loss is -0.018089633882304015\n",
      "Action prob: [0.94110847 0.05889152], Action: 0, state: 0\n",
      "Action prob: [0.940168 0.059832], Action: 0, state: 1\n",
      "Action prob: [0.94742477 0.05257525], Action: 0, state: 1\n",
      "Action prob: [0.94763637 0.05236365], Action: 0, state: 2\n",
      "Action prob: [0.94728667 0.05271335], Action: 0, state: 3\n",
      "Action prob: [0.9424703  0.05752963], Action: 1, state: 3\n",
      "Action prob: [0.5069467  0.49305332], Action: 1, state: 7\n",
      "Action prob: [0.5069467  0.49305332], Action: 1, state: 7\n",
      "Action prob: [0.9424428  0.05755715], Action: 0, state: 2\n",
      "Action prob: [0.94578874 0.05421127], Action: 0, state: 3\n",
      "Action prob: [0.9556867  0.04431331], Action: 0, state: 3\n",
      "Action prob: [0.91893816 0.08106181], Action: 0, state: 8\n",
      "Action prob: [0.9227569 0.0772431], Action: 1, state: 8\n",
      "Action prob: [0.95372355 0.04627643], Action: 0, state: 8\n",
      "Action prob: [0.9547573  0.04524275], Action: 0, state: 8\n",
      "Action prob: [0.9612211  0.03877898], Action: 0, state: 8\n",
      "Action prob: [0.9260435  0.07395645], Action: 0, state: 8\n",
      "Action prob: [0.9260455  0.07395456], Action: 0, state: 8\n",
      "Action prob: [0.9667485  0.03325158], Action: 0, state: 8\n",
      "Action prob: [0.9689761  0.03102396], Action: 0, state: 8\n",
      "Action prob: [0.9591111  0.04088887], Action: 0, state: 8\n",
      "Action prob: [0.9536264  0.04637365], Action: 0, state: 8\n",
      "Action prob: [0.93207127 0.06792875], Action: 0, state: 8\n",
      "Action prob: [0.929276 0.070724], Action: 0, state: 8\n",
      "Action prob: [0.9253576  0.07464238], Action: 0, state: 8\n",
      "Action prob: [0.97092485 0.02907521], Action: 0, state: 8\n",
      "Action prob: [0.9568977 0.0431023], Action: 0, state: 8\n",
      "Action prob: [0.9564247  0.04357523], Action: 0, state: 8\n",
      "Action prob: [0.9589569  0.04104311], Action: 0, state: 8\n",
      "Action prob: [0.9540252 0.0459748], Action: 0, state: 8\n",
      "Action prob: [0.9228038  0.07719617], Action: 0, state: 8\n",
      "Action prob: [0.93064356 0.06935645], Action: 0, state: 8\n",
      "Action prob: [0.95330256 0.04669743], Action: 0, state: 8\n",
      "Action prob: [0.9566946  0.04330547], Action: 0, state: 8\n",
      "Action prob: [0.9540812  0.04591877], Action: 0, state: 8\n",
      "Action prob: [0.9533973  0.04660273], Action: 1, state: 8\n",
      "Action prob: [0.9470792  0.05292082], Action: 1, state: 8\n",
      "Action prob: [0.92587686 0.07412314], Action: 0, state: 8\n",
      "Action prob: [0.9559172  0.04408282], Action: 0, state: 8\n",
      "Action prob: [0.9249055  0.07509453], Action: 0, state: 8\n",
      "Action prob: [0.92842215 0.07157781], Action: 0, state: 8\n",
      "Action prob: [0.92652684 0.07347313], Action: 0, state: 8\n",
      "Action prob: [0.9533162  0.04668378], Action: 0, state: 8\n",
      "Action prob: [0.9207698  0.07923014], Action: 0, state: 8\n",
      "Action prob: [0.924612   0.07538802], Action: 0, state: 8\n",
      "Action prob: [0.9304043  0.06959571], Action: 0, state: 8\n",
      "Action prob: [0.9579852  0.04201477], Action: 0, state: 8\n",
      "Action prob: [0.95343184 0.04656811], Action: 0, state: 8\n",
      "Action prob: [0.9260285  0.07397144], Action: 0, state: 8\n",
      "Action prob: [0.9599718  0.04002817], Action: 0, state: 8\n",
      "Reward for this episode -115600, loss is -0.1742649942861936\n",
      "Action prob: [0.9497908 0.0502092], Action: 0, state: 0\n",
      "Action prob: [0.9469753  0.05302479], Action: 0, state: 1\n",
      "Action prob: [0.95100266 0.04899738], Action: 0, state: 1\n",
      "Action prob: [0.94594646 0.05405349], Action: 0, state: 1\n",
      "Action prob: [0.9525826  0.04741743], Action: 0, state: 2\n",
      "Action prob: [0.94282997 0.05717007], Action: 0, state: 3\n",
      "Action prob: [0.9501498 0.0498503], Action: 1, state: 3\n",
      "Action prob: [0.5131891  0.48681092], Action: 1, state: 7\n",
      "Action prob: [0.948605 0.051395], Action: 0, state: 2\n",
      "Action prob: [0.9492711  0.05072889], Action: 0, state: 2\n",
      "Action prob: [0.942601   0.05739899], Action: 0, state: 2\n",
      "Action prob: [0.9454517  0.05454833], Action: 1, state: 2\n",
      "Action prob: [0.5131891  0.48681092], Action: 0, state: 6\n",
      "Action prob: [0.5131891  0.48681092], Action: 0, state: 6\n",
      "Action prob: [0.5131891  0.48681092], Action: 1, state: 6\n",
      "Action prob: [0.9371965  0.06280343], Action: 1, state: 1\n",
      "Action prob: [0.5131891  0.48681092], Action: 1, state: 5\n",
      "Action prob: [0.9529936  0.04700644], Action: 0, state: 0\n",
      "Action prob: [0.94576526 0.05423472], Action: 1, state: 1\n",
      "Action prob: [0.5131891  0.48681092], Action: 1, state: 5\n",
      "Action prob: [0.94762224 0.05237778], Action: 0, state: 0\n",
      "Action prob: [0.9517967  0.04820327], Action: 0, state: 1\n",
      "Action prob: [0.9451401  0.05485993], Action: 0, state: 1\n",
      "Action prob: [0.9469853  0.05301474], Action: 0, state: 1\n",
      "Action prob: [0.94368625 0.0563138 ], Action: 0, state: 2\n",
      "Action prob: [0.9481551 0.0518449], Action: 0, state: 2\n",
      "Action prob: [0.9451462  0.05485382], Action: 0, state: 3\n",
      "Action prob: [0.9467805  0.05321952], Action: 0, state: 3\n",
      "Action prob: [0.94717073 0.05282932], Action: 0, state: 3\n",
      "Action prob: [0.9510865  0.04891345], Action: 0, state: 3\n",
      "Action prob: [0.95814735 0.04185259], Action: 0, state: 9\n",
      "Action prob: [0.9444243  0.05557567], Action: 0, state: 9\n",
      "Action prob: [0.95989317 0.04010679], Action: 0, state: 9\n",
      "Action prob: [0.9306551  0.06934488], Action: 0, state: 9\n",
      "Action prob: [0.9577575  0.04224253], Action: 0, state: 9\n",
      "Action prob: [0.9556666  0.04433342], Action: 0, state: 9\n",
      "Action prob: [0.93138546 0.06861457], Action: 1, state: 9\n",
      "Action prob: [0.9585312  0.04146875], Action: 0, state: 9\n",
      "Action prob: [0.9366242  0.06337573], Action: 0, state: 9\n",
      "Action prob: [0.9344226 0.0655774], Action: 1, state: 9\n",
      "Action prob: [0.9626539  0.03734615], Action: 1, state: 9\n",
      "Action prob: [0.96979773 0.03020227], Action: 0, state: 9\n",
      "Action prob: [0.9304963  0.06950375], Action: 0, state: 9\n",
      "Action prob: [0.93419063 0.06580935], Action: 0, state: 9\n",
      "Action prob: [0.93527865 0.06472134], Action: 0, state: 9\n",
      "Action prob: [0.9594571  0.04054295], Action: 0, state: 9\n",
      "Action prob: [0.96043783 0.03956214], Action: 1, state: 9\n",
      "Action prob: [0.961767   0.03823292], Action: 0, state: 9\n",
      "Action prob: [0.9544278  0.04557221], Action: 0, state: 9\n",
      "Action prob: [0.9200418  0.07995818], Action: 0, state: 9\n",
      "Reward for this episode -6200, loss is -0.16117894046838108\n",
      "Action prob: [0.94882584 0.05117417], Action: 0, state: 0\n",
      "Action prob: [0.9541641  0.04583596], Action: 0, state: 0\n",
      "Action prob: [0.9497869  0.05021315], Action: 1, state: 0\n",
      "Action prob: [0.5191671  0.48083284], Action: 0, state: 4\n",
      "Action prob: [0.9505241  0.04947596], Action: 0, state: 0\n",
      "Action prob: [0.9484751 0.0515249], Action: 0, state: 0\n",
      "Action prob: [0.9465113  0.05348863], Action: 1, state: 0\n",
      "Action prob: [0.5191671  0.48083284], Action: 1, state: 4\n",
      "Action prob: [0.9502174 0.0497825], Action: 0, state: 0\n",
      "Action prob: [0.9485257  0.05147427], Action: 0, state: 0\n",
      "Action prob: [0.9519366  0.04806346], Action: 0, state: 0\n",
      "Action prob: [0.95141405 0.04858593], Action: 1, state: 0\n",
      "Action prob: [0.5191671  0.48083284], Action: 1, state: 4\n",
      "Action prob: [0.96010166 0.03989829], Action: 0, state: 0\n",
      "Action prob: [0.9501128  0.04988717], Action: 0, state: 1\n",
      "Action prob: [0.9520927  0.04790732], Action: 0, state: 2\n",
      "Action prob: [0.94692844 0.05307159], Action: 0, state: 2\n",
      "Action prob: [0.9461476  0.05385243], Action: 0, state: 2\n",
      "Action prob: [0.9521809  0.04781909], Action: 0, state: 2\n",
      "Action prob: [0.9457878  0.05421219], Action: 0, state: 2\n",
      "Action prob: [0.95102    0.04898002], Action: 0, state: 2\n",
      "Action prob: [0.9565305  0.04346947], Action: 0, state: 3\n",
      "Action prob: [0.96109045 0.03890957], Action: 0, state: 3\n",
      "Action prob: [0.93791485 0.06208512], Action: 0, state: 3\n",
      "Action prob: [0.952519   0.04748101], Action: 0, state: 3\n",
      "Action prob: [0.9512657  0.04873433], Action: 0, state: 3\n",
      "Action prob: [0.9526763 0.0473237], Action: 0, state: 8\n",
      "Action prob: [0.9613679  0.03863204], Action: 0, state: 8\n",
      "Action prob: [0.95419794 0.045802  ], Action: 0, state: 8\n",
      "Action prob: [0.9607159 0.0392841], Action: 0, state: 8\n",
      "Action prob: [0.9445484  0.05545157], Action: 0, state: 8\n",
      "Action prob: [0.93324304 0.06675699], Action: 0, state: 8\n",
      "Action prob: [0.95738214 0.04261791], Action: 0, state: 8\n",
      "Action prob: [0.9649263  0.03507374], Action: 0, state: 8\n",
      "Action prob: [0.955151   0.04484897], Action: 0, state: 8\n",
      "Action prob: [0.9557965 0.0442035], Action: 0, state: 8\n",
      "Action prob: [0.9516968  0.04830322], Action: 0, state: 8\n",
      "Action prob: [0.9615064  0.03849361], Action: 0, state: 8\n",
      "Action prob: [0.93732136 0.06267869], Action: 0, state: 8\n",
      "Action prob: [0.9379882  0.06201178], Action: 0, state: 8\n",
      "Action prob: [0.9588003  0.04119971], Action: 0, state: 8\n",
      "Action prob: [0.95530754 0.04469243], Action: 0, state: 8\n",
      "Action prob: [0.9548903  0.04510969], Action: 0, state: 8\n",
      "Action prob: [0.9393699 0.0606301], Action: 0, state: 8\n",
      "Action prob: [0.9616444  0.03835562], Action: 0, state: 8\n",
      "Action prob: [0.9720196  0.02798039], Action: 0, state: 8\n",
      "Action prob: [0.96757644 0.03242358], Action: 1, state: 8\n",
      "Reward for this episode -45300, loss is 0.11662311372983625\n",
      "Action prob: [0.96190673 0.03809322], Action: 0, state: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.9527095  0.04729052], Action: 0, state: 1\n",
      "Action prob: [0.9559176 0.0440824], Action: 0, state: 2\n",
      "Action prob: [0.9539493  0.04605076], Action: 0, state: 3\n",
      "Action prob: [0.9536874  0.04631258], Action: 0, state: 3\n",
      "Action prob: [0.9527935  0.04720649], Action: 0, state: 3\n",
      "Action prob: [0.9526872  0.04731284], Action: 0, state: 3\n",
      "Action prob: [0.93783295 0.06216703], Action: 1, state: 3\n",
      "Action prob: [0.52502686 0.4749732 ], Action: 0, state: 7\n",
      "Action prob: [0.9514419  0.04855813], Action: 0, state: 2\n",
      "Action prob: [0.9528758 0.0471242], Action: 0, state: 2\n",
      "Action prob: [0.9497753  0.05022476], Action: 0, state: 2\n",
      "Action prob: [0.9640077  0.03599235], Action: 0, state: 3\n",
      "Action prob: [0.9534869  0.04651306], Action: 0, state: 3\n",
      "Action prob: [0.9628963  0.03710374], Action: 0, state: 3\n",
      "Action prob: [0.96641356 0.03358646], Action: 0, state: 8\n",
      "Action prob: [0.9631069  0.03689311], Action: 0, state: 8\n",
      "Action prob: [0.9691574  0.03084258], Action: 0, state: 8\n",
      "Action prob: [0.93433625 0.06566382], Action: 0, state: 8\n",
      "Action prob: [0.9648224  0.03517755], Action: 0, state: 8\n",
      "Action prob: [0.96431166 0.03568831], Action: 0, state: 8\n",
      "Action prob: [0.9620825  0.03791752], Action: 0, state: 8\n",
      "Action prob: [0.96380204 0.03619796], Action: 0, state: 8\n",
      "Action prob: [0.9645424  0.03545757], Action: 1, state: 8\n",
      "Reward for this episode -18400, loss is -0.0813078563077688\n",
      "Action prob: [0.9561002  0.04389979], Action: 0, state: 0\n",
      "Action prob: [0.9548218  0.04517816], Action: 0, state: 1\n",
      "Action prob: [0.94765145 0.05234853], Action: 1, state: 1\n",
      "Action prob: [0.53024095 0.46975905], Action: 0, state: 5\n",
      "Action prob: [0.9529211  0.04707896], Action: 0, state: 0\n",
      "Action prob: [0.9614132  0.03858685], Action: 0, state: 0\n",
      "Action prob: [0.95202905 0.04797099], Action: 0, state: 0\n",
      "Action prob: [0.9548552  0.04514483], Action: 0, state: 0\n",
      "Action prob: [0.9554097  0.04459035], Action: 0, state: 0\n",
      "Action prob: [0.95144707 0.04855299], Action: 0, state: 1\n",
      "Action prob: [0.9561595  0.04384053], Action: 0, state: 1\n",
      "Action prob: [0.9555079  0.04449215], Action: 0, state: 1\n",
      "Action prob: [0.9554674  0.04453265], Action: 0, state: 1\n",
      "Action prob: [0.9557354  0.04426465], Action: 0, state: 1\n",
      "Action prob: [0.95227504 0.04772498], Action: 0, state: 1\n",
      "Action prob: [0.9540802  0.04591981], Action: 0, state: 1\n",
      "Action prob: [0.9541054  0.04589459], Action: 0, state: 2\n",
      "Action prob: [0.9493182  0.05068183], Action: 0, state: 2\n",
      "Action prob: [0.95634717 0.04365283], Action: 0, state: 2\n",
      "Action prob: [0.96613556 0.03386442], Action: 0, state: 3\n",
      "Action prob: [0.9489837 0.0510163], Action: 0, state: 3\n",
      "Action prob: [0.93789387 0.06210619], Action: 0, state: 3\n",
      "Action prob: [0.9325249  0.06747513], Action: 0, state: 3\n",
      "Action prob: [0.96724516 0.03275486], Action: 0, state: 3\n",
      "Action prob: [0.9389795  0.06102049], Action: 0, state: 3\n",
      "Action prob: [0.9630722  0.03692778], Action: 0, state: 3\n",
      "Action prob: [0.95889324 0.04110678], Action: 0, state: 3\n",
      "Action prob: [0.9468057  0.05319423], Action: 0, state: 8\n",
      "Action prob: [0.9655613  0.03443875], Action: 0, state: 8\n",
      "Action prob: [0.95942336 0.04057658], Action: 0, state: 8\n",
      "Action prob: [0.96216667 0.03783326], Action: 1, state: 8\n",
      "Action prob: [0.939829 0.060171], Action: 0, state: 8\n",
      "Action prob: [0.9764424  0.02355753], Action: 0, state: 8\n",
      "Action prob: [0.96804214 0.03195782], Action: 0, state: 8\n",
      "Action prob: [0.9395634  0.06043656], Action: 0, state: 8\n",
      "Action prob: [0.9635664  0.03643361], Action: 0, state: 8\n",
      "Action prob: [0.9599057  0.04009435], Action: 1, state: 8\n",
      "Action prob: [0.9718888  0.02811129], Action: 0, state: 8\n",
      "Action prob: [0.96614254 0.03385745], Action: 0, state: 8\n",
      "Action prob: [0.9645699  0.03543009], Action: 0, state: 8\n",
      "Action prob: [0.966113   0.03388707], Action: 1, state: 8\n",
      "Action prob: [0.9412844  0.05871557], Action: 0, state: 8\n",
      "Action prob: [0.94045    0.05955001], Action: 0, state: 8\n",
      "Action prob: [0.9588486  0.04115142], Action: 0, state: 8\n",
      "Action prob: [0.93792564 0.06207432], Action: 0, state: 8\n",
      "Action prob: [0.96366507 0.03633492], Action: 0, state: 8\n",
      "Action prob: [0.9654178  0.03458215], Action: 0, state: 8\n",
      "Action prob: [0.9710959  0.02890414], Action: 0, state: 8\n",
      "Action prob: [0.9546789  0.04532105], Action: 0, state: 8\n",
      "Action prob: [0.9429809  0.05701913], Action: 0, state: 8\n",
      "Reward for this episode -53000, loss is 0.03955969341899519\n",
      "Action prob: [0.95621115 0.04378889], Action: 1, state: 0\n",
      "Action prob: [0.5359048 0.4640952], Action: 1, state: 4\n",
      "Action prob: [0.5359048 0.4640952], Action: 0, state: 4\n",
      "Action prob: [0.95509934 0.0449006 ], Action: 0, state: 0\n",
      "Action prob: [0.96096057 0.03903947], Action: 0, state: 0\n",
      "Action prob: [0.9547531  0.04524691], Action: 0, state: 0\n",
      "Action prob: [0.9651221  0.03487792], Action: 0, state: 0\n",
      "Action prob: [0.9548238  0.04517624], Action: 0, state: 1\n",
      "Action prob: [0.9567583  0.04324172], Action: 0, state: 1\n",
      "Action prob: [0.9576976  0.04230241], Action: 1, state: 1\n",
      "Action prob: [0.5359048 0.4640952], Action: 1, state: 5\n",
      "Action prob: [0.9587299  0.04127009], Action: 0, state: 0\n",
      "Action prob: [0.9495795  0.05042048], Action: 0, state: 0\n",
      "Action prob: [0.9637101  0.03628989], Action: 0, state: 0\n",
      "Action prob: [0.9566086  0.04339143], Action: 0, state: 0\n",
      "Action prob: [0.9540481  0.04595191], Action: 0, state: 0\n",
      "Action prob: [0.9528373  0.04716275], Action: 0, state: 0\n",
      "Action prob: [0.9634808  0.03651926], Action: 1, state: 0\n",
      "Action prob: [0.5359048 0.4640952], Action: 1, state: 4\n",
      "Action prob: [0.9657962  0.03420384], Action: 0, state: 0\n",
      "Action prob: [0.95504713 0.04495279], Action: 0, state: 1\n",
      "Action prob: [0.9576216  0.04237837], Action: 0, state: 1\n",
      "Action prob: [0.9479466  0.05205341], Action: 0, state: 2\n",
      "Action prob: [0.95427394 0.04572605], Action: 0, state: 2\n",
      "Action prob: [0.95856345 0.04143661], Action: 0, state: 2\n",
      "Action prob: [0.9585966  0.04140343], Action: 0, state: 3\n",
      "Action prob: [0.96559215 0.03440781], Action: 0, state: 3\n",
      "Action prob: [0.9689801  0.03101993], Action: 0, state: 8\n",
      "Action prob: [0.96568644 0.03431358], Action: 0, state: 8\n",
      "Action prob: [0.969835   0.03016498], Action: 0, state: 8\n",
      "Action prob: [0.9732329  0.02676713], Action: 0, state: 8\n",
      "Action prob: [0.9361729  0.06382717], Action: 0, state: 8\n",
      "Action prob: [0.9410862  0.05891385], Action: 0, state: 8\n",
      "Action prob: [0.93726134 0.06273868], Action: 0, state: 8\n",
      "Action prob: [0.9742604  0.02573964], Action: 0, state: 8\n",
      "Action prob: [0.9514776  0.04852239], Action: 0, state: 8\n",
      "Action prob: [0.93854046 0.06145951], Action: 0, state: 8\n",
      "Action prob: [0.94466084 0.05533921], Action: 1, state: 8\n",
      "Action prob: [0.94373155 0.05626846], Action: 0, state: 8\n",
      "Action prob: [0.9397044  0.06029556], Action: 0, state: 8\n",
      "Action prob: [0.9422801  0.05771989], Action: 0, state: 8\n",
      "Action prob: [0.9675397  0.03246023], Action: 0, state: 8\n",
      "Action prob: [0.96458256 0.03541747], Action: 0, state: 8\n",
      "Action prob: [0.9663527  0.03364731], Action: 0, state: 8\n",
      "Action prob: [0.93663806 0.06336197], Action: 0, state: 8\n",
      "Action prob: [0.9496472  0.05035274], Action: 0, state: 8\n",
      "Action prob: [0.9530014  0.04699865], Action: 0, state: 8\n",
      "Action prob: [0.9670925  0.03290745], Action: 0, state: 8\n",
      "Action prob: [0.9363132  0.06368677], Action: 0, state: 8\n",
      "Action prob: [0.9672377  0.03276233], Action: 0, state: 8\n",
      "Reward for this episode -54100, loss is 0.1534064309842974\n",
      "Action prob: [0.9515999  0.04840009], Action: 0, state: 0\n",
      "Action prob: [0.9591387  0.04086126], Action: 0, state: 0\n",
      "Action prob: [0.95817125 0.0418288 ], Action: 0, state: 0\n",
      "Action prob: [0.9576347  0.04236531], Action: 0, state: 1\n",
      "Action prob: [0.9577447  0.04225526], Action: 1, state: 1\n",
      "Action prob: [0.540799   0.45920098], Action: 0, state: 5\n",
      "Action prob: [0.540799   0.45920098], Action: 1, state: 5\n",
      "Action prob: [0.540799   0.45920098], Action: 1, state: 5\n",
      "Action prob: [0.95660466 0.04339536], Action: 0, state: 0\n",
      "Action prob: [0.9574255  0.04257447], Action: 0, state: 1\n",
      "Action prob: [0.9557018  0.04429812], Action: 0, state: 2\n",
      "Action prob: [0.9635876  0.03641242], Action: 0, state: 3\n",
      "Action prob: [0.9652587  0.03474131], Action: 0, state: 8\n",
      "Action prob: [0.97261107 0.02738893], Action: 0, state: 8\n",
      "Action prob: [0.95435685 0.04564309], Action: 0, state: 8\n",
      "Action prob: [0.9679851  0.03201497], Action: 0, state: 8\n",
      "Action prob: [0.96806866 0.03193138], Action: 0, state: 8\n",
      "Action prob: [0.93466675 0.06533329], Action: 0, state: 8\n",
      "Action prob: [0.94641155 0.05358838], Action: 0, state: 8\n",
      "Action prob: [0.9703831  0.02961692], Action: 0, state: 8\n",
      "Action prob: [0.94198984 0.05801017], Action: 0, state: 8\n",
      "Action prob: [0.9673786  0.03262145], Action: 0, state: 8\n",
      "Action prob: [0.9484232  0.05157675], Action: 0, state: 8\n",
      "Action prob: [0.9686788  0.03132122], Action: 0, state: 8\n",
      "Action prob: [0.96443516 0.03556487], Action: 0, state: 8\n",
      "Action prob: [0.9661414  0.03385858], Action: 0, state: 8\n",
      "Action prob: [0.96412617 0.03587383], Action: 0, state: 8\n",
      "Action prob: [0.96763325 0.03236682], Action: 0, state: 8\n",
      "Action prob: [0.96817464 0.03182537], Action: 0, state: 8\n",
      "Action prob: [0.9681644  0.03183562], Action: 0, state: 8\n",
      "Action prob: [0.96787816 0.03212178], Action: 0, state: 8\n",
      "Action prob: [0.96753746 0.03246249], Action: 0, state: 8\n",
      "Action prob: [0.96529835 0.03470166], Action: 0, state: 8\n",
      "Action prob: [0.9692338  0.03076618], Action: 0, state: 8\n",
      "Action prob: [0.94490427 0.05509567], Action: 0, state: 8\n",
      "Action prob: [0.9731426  0.02685743], Action: 0, state: 8\n",
      "Action prob: [0.9406052  0.05939475], Action: 0, state: 8\n",
      "Action prob: [0.9408176  0.05918248], Action: 1, state: 8\n",
      "Action prob: [0.9653939  0.03460608], Action: 0, state: 8\n",
      "Action prob: [0.96070445 0.03929553], Action: 0, state: 8\n",
      "Action prob: [0.97127455 0.02872548], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.96962804 0.03037201], Action: 0, state: 8\n",
      "Action prob: [0.9439136  0.05608646], Action: 0, state: 8\n",
      "Action prob: [0.9446089  0.05539105], Action: 0, state: 8\n",
      "Action prob: [0.9413497 0.0586503], Action: 0, state: 8\n",
      "Action prob: [0.9673093  0.03269073], Action: 0, state: 8\n",
      "Action prob: [0.9427063  0.05729366], Action: 0, state: 8\n",
      "Action prob: [0.96655387 0.0334461 ], Action: 0, state: 8\n",
      "Action prob: [0.9727216  0.02727835], Action: 0, state: 8\n",
      "Action prob: [0.9682151  0.03178493], Action: 0, state: 8\n",
      "Reward for this episode -111500, loss is -0.17109360281285124\n",
      "Action prob: [0.95722085 0.0427791 ], Action: 0, state: 0\n",
      "Action prob: [0.96349305 0.03650695], Action: 0, state: 0\n",
      "Action prob: [0.958806   0.04119401], Action: 0, state: 0\n",
      "Action prob: [0.96054417 0.03945588], Action: 0, state: 0\n",
      "Action prob: [0.95739055 0.04260951], Action: 0, state: 0\n",
      "Action prob: [0.9611126  0.03888744], Action: 0, state: 0\n",
      "Action prob: [0.9586193  0.04138075], Action: 0, state: 0\n",
      "Action prob: [0.9625009  0.03749916], Action: 0, state: 1\n",
      "Action prob: [0.95988864 0.04011139], Action: 0, state: 1\n",
      "Action prob: [0.9608398 0.0391602], Action: 0, state: 1\n",
      "Action prob: [0.95352626 0.04647376], Action: 0, state: 1\n",
      "Action prob: [0.9632814  0.03671863], Action: 0, state: 1\n",
      "Action prob: [0.9540228  0.04597721], Action: 0, state: 1\n",
      "Action prob: [0.9598961  0.04010391], Action: 0, state: 2\n",
      "Action prob: [0.9571857  0.04281427], Action: 0, state: 2\n",
      "Action prob: [0.95494825 0.04505176], Action: 0, state: 2\n",
      "Action prob: [0.9598275  0.04017258], Action: 0, state: 2\n",
      "Action prob: [0.9576981  0.04230189], Action: 0, state: 2\n",
      "Action prob: [0.96411294 0.0358871 ], Action: 0, state: 2\n",
      "Action prob: [0.96139604 0.03860404], Action: 0, state: 2\n",
      "Action prob: [0.9567178  0.04328217], Action: 0, state: 2\n",
      "Action prob: [0.9604166 0.0395834], Action: 0, state: 2\n",
      "Action prob: [0.96923447 0.03076552], Action: 0, state: 3\n",
      "Action prob: [0.9749258  0.02507412], Action: 0, state: 8\n",
      "Action prob: [0.9721344  0.02786561], Action: 0, state: 8\n",
      "Action prob: [0.94421095 0.05578903], Action: 0, state: 8\n",
      "Action prob: [0.9436855  0.05631453], Action: 0, state: 8\n",
      "Action prob: [0.9452581  0.05474194], Action: 0, state: 8\n",
      "Action prob: [0.93953466 0.06046531], Action: 0, state: 8\n",
      "Action prob: [0.9659887  0.03401136], Action: 0, state: 8\n",
      "Action prob: [0.9530929  0.04690712], Action: 0, state: 8\n",
      "Action prob: [0.96524304 0.03475692], Action: 0, state: 8\n",
      "Action prob: [0.96731335 0.0326867 ], Action: 0, state: 8\n",
      "Action prob: [0.9494317  0.05056833], Action: 0, state: 8\n",
      "Action prob: [0.9688098  0.03119026], Action: 0, state: 8\n",
      "Action prob: [0.96936494 0.03063508], Action: 0, state: 8\n",
      "Action prob: [0.9708021  0.02919788], Action: 0, state: 8\n",
      "Action prob: [0.95949715 0.04050292], Action: 0, state: 8\n",
      "Action prob: [0.96872 0.03128], Action: 0, state: 8\n",
      "Action prob: [0.9628837  0.03711635], Action: 0, state: 8\n",
      "Action prob: [0.9694705  0.03052955], Action: 0, state: 8\n",
      "Action prob: [0.9682514 0.0317486], Action: 0, state: 8\n",
      "Action prob: [0.9731482  0.02685177], Action: 0, state: 8\n",
      "Action prob: [0.97004515 0.02995486], Action: 0, state: 8\n",
      "Action prob: [0.9693851  0.03061486], Action: 0, state: 8\n",
      "Action prob: [0.9721048  0.02789523], Action: 0, state: 8\n",
      "Action prob: [0.9678509  0.03214904], Action: 0, state: 8\n",
      "Action prob: [0.9701605  0.02983951], Action: 0, state: 8\n",
      "Action prob: [0.9451274  0.05487259], Action: 0, state: 8\n",
      "Action prob: [0.9481649  0.05183517], Action: 0, state: 8\n",
      "Reward for this episode -64900, loss is -0.022528802783837013\n",
      "Action prob: [0.9641382 0.0358618], Action: 0, state: 0\n",
      "Action prob: [0.9616035  0.03839643], Action: 0, state: 0\n",
      "Action prob: [0.97167116 0.0283289 ], Action: 0, state: 0\n",
      "Action prob: [0.96105194 0.0389481 ], Action: 0, state: 0\n",
      "Action prob: [0.9595178  0.04048223], Action: 0, state: 0\n",
      "Action prob: [0.958758   0.04124196], Action: 0, state: 1\n",
      "Action prob: [0.9589519  0.04104808], Action: 0, state: 2\n",
      "Action prob: [0.9606064  0.03939363], Action: 0, state: 2\n",
      "Action prob: [0.9606447  0.03935534], Action: 0, state: 2\n",
      "Action prob: [0.9651644  0.03483555], Action: 0, state: 3\n",
      "Action prob: [0.94795895 0.0520411 ], Action: 0, state: 9\n",
      "Action prob: [0.9724132  0.02758682], Action: 0, state: 9\n",
      "Action prob: [0.9683262  0.03167377], Action: 0, state: 9\n",
      "Action prob: [0.94793063 0.05206933], Action: 0, state: 9\n",
      "Action prob: [0.97244656 0.02755348], Action: 0, state: 9\n",
      "Action prob: [0.97565234 0.02434764], Action: 0, state: 9\n",
      "Action prob: [0.97260225 0.02739769], Action: 0, state: 9\n",
      "Action prob: [0.94890225 0.05109781], Action: 0, state: 9\n",
      "Action prob: [0.9642811  0.03571894], Action: 0, state: 9\n",
      "Action prob: [0.9719368  0.02806311], Action: 0, state: 9\n",
      "Action prob: [0.965966   0.03403405], Action: 0, state: 9\n",
      "Action prob: [0.94904494 0.05095506], Action: 0, state: 9\n",
      "Action prob: [0.9673273  0.03267275], Action: 0, state: 9\n",
      "Action prob: [0.9472996  0.05270038], Action: 0, state: 9\n",
      "Action prob: [0.9732281  0.02677197], Action: 0, state: 9\n",
      "Action prob: [0.9738104  0.02618964], Action: 0, state: 9\n",
      "Action prob: [0.96757686 0.03242316], Action: 0, state: 9\n",
      "Action prob: [0.9381671  0.06183295], Action: 0, state: 9\n",
      "Action prob: [0.96647906 0.03352093], Action: 0, state: 9\n",
      "Action prob: [0.9543292  0.04567077], Action: 0, state: 9\n",
      "Action prob: [0.9715432  0.02845679], Action: 0, state: 9\n",
      "Action prob: [0.9700815  0.02991856], Action: 0, state: 9\n",
      "Action prob: [0.97251725 0.02748278], Action: 0, state: 9\n",
      "Action prob: [0.9414226  0.05857744], Action: 1, state: 9\n",
      "Action prob: [0.944272   0.05572806], Action: 0, state: 9\n",
      "Action prob: [0.9461347  0.05386527], Action: 0, state: 9\n",
      "Action prob: [0.97247416 0.02752584], Action: 0, state: 9\n",
      "Action prob: [0.9807812  0.01921883], Action: 1, state: 9\n",
      "Action prob: [0.9731559  0.02684409], Action: 0, state: 9\n",
      "Action prob: [0.95707554 0.0429245 ], Action: 0, state: 9\n",
      "Action prob: [0.96906304 0.03093691], Action: 0, state: 9\n",
      "Action prob: [0.97244847 0.02755147], Action: 0, state: 9\n",
      "Action prob: [0.94438636 0.0556136 ], Action: 0, state: 9\n",
      "Action prob: [0.9690442  0.03095572], Action: 0, state: 9\n",
      "Action prob: [0.94513446 0.05486557], Action: 0, state: 9\n",
      "Action prob: [0.9646439  0.03535613], Action: 0, state: 9\n",
      "Action prob: [0.9729478  0.02705226], Action: 0, state: 9\n",
      "Action prob: [0.96709776 0.03290227], Action: 0, state: 9\n",
      "Action prob: [0.9733097  0.02669027], Action: 0, state: 9\n",
      "Action prob: [0.9653046  0.03469535], Action: 1, state: 9\n",
      "Reward for this episode -33200, loss is -0.049742574831675664\n",
      "Action prob: [0.96114707 0.03885293], Action: 0, state: 0\n",
      "Action prob: [0.96036744 0.03963258], Action: 0, state: 1\n",
      "Action prob: [0.9571901  0.04280992], Action: 0, state: 1\n",
      "Action prob: [0.95938873 0.0406113 ], Action: 0, state: 2\n",
      "Action prob: [0.9590475  0.04095252], Action: 0, state: 3\n",
      "Action prob: [0.96657056 0.03342937], Action: 0, state: 8\n",
      "Action prob: [0.9700677  0.02993234], Action: 0, state: 8\n",
      "Action prob: [0.97049934 0.02950063], Action: 0, state: 8\n",
      "Action prob: [0.97124106 0.02875894], Action: 0, state: 8\n",
      "Action prob: [0.94807965 0.05192034], Action: 0, state: 8\n",
      "Action prob: [0.97212267 0.02787729], Action: 0, state: 8\n",
      "Action prob: [0.9499963  0.05000364], Action: 0, state: 8\n",
      "Action prob: [0.9465483  0.05345172], Action: 0, state: 8\n",
      "Action prob: [0.96695054 0.03304948], Action: 0, state: 8\n",
      "Action prob: [0.9484083  0.05159169], Action: 1, state: 8\n",
      "Action prob: [0.9730732  0.02692684], Action: 0, state: 8\n",
      "Action prob: [0.97105193 0.02894801], Action: 0, state: 8\n",
      "Action prob: [0.9699047  0.03009527], Action: 0, state: 8\n",
      "Action prob: [0.9696916  0.03030846], Action: 0, state: 8\n",
      "Action prob: [0.97069216 0.02930783], Action: 0, state: 8\n",
      "Action prob: [0.97278804 0.02721197], Action: 0, state: 8\n",
      "Action prob: [0.97907317 0.02092681], Action: 0, state: 8\n",
      "Action prob: [0.96935564 0.03064439], Action: 0, state: 8\n",
      "Action prob: [0.9717003  0.02829965], Action: 0, state: 8\n",
      "Action prob: [0.95810795 0.04189204], Action: 0, state: 8\n",
      "Action prob: [0.9476486  0.05235147], Action: 0, state: 8\n",
      "Action prob: [0.97287095 0.0271291 ], Action: 1, state: 8\n",
      "Action prob: [0.9721443  0.02785568], Action: 0, state: 8\n",
      "Action prob: [0.9471896 0.0528104], Action: 0, state: 8\n",
      "Action prob: [0.9703434  0.02965663], Action: 0, state: 8\n",
      "Action prob: [0.9467701 0.05323  ], Action: 0, state: 8\n",
      "Action prob: [0.9457995 0.0542005], Action: 0, state: 8\n",
      "Action prob: [0.9670532  0.03294679], Action: 0, state: 8\n",
      "Action prob: [0.97053266 0.02946731], Action: 0, state: 8\n",
      "Action prob: [0.97022074 0.02977926], Action: 0, state: 8\n",
      "Action prob: [0.94899905 0.05100095], Action: 0, state: 8\n",
      "Action prob: [0.97291756 0.02708242], Action: 1, state: 8\n",
      "Action prob: [0.9693486  0.03065135], Action: 0, state: 8\n",
      "Action prob: [0.97471833 0.02528165], Action: 0, state: 8\n",
      "Action prob: [0.9709147  0.02908533], Action: 0, state: 8\n",
      "Action prob: [0.9488796 0.0511204], Action: 0, state: 8\n",
      "Action prob: [0.9455408  0.05445925], Action: 0, state: 8\n",
      "Action prob: [0.96515477 0.03484526], Action: 0, state: 8\n",
      "Action prob: [0.9688959  0.03110406], Action: 0, state: 8\n",
      "Action prob: [0.97806084 0.02193908], Action: 0, state: 8\n",
      "Action prob: [0.97428054 0.02571946], Action: 0, state: 8\n",
      "Action prob: [0.9593252  0.04067487], Action: 0, state: 8\n",
      "Action prob: [0.9474496  0.05255042], Action: 0, state: 8\n",
      "Action prob: [0.9472995  0.05270052], Action: 0, state: 8\n",
      "Action prob: [0.9502098  0.04979015], Action: 0, state: 8\n",
      "Reward for this episode -134900, loss is 0.06777663327824482\n",
      "Action prob: [0.9600642  0.03993579], Action: 0, state: 0\n",
      "Action prob: [0.96704245 0.03295757], Action: 0, state: 1\n",
      "Action prob: [0.9623559 0.0376441], Action: 0, state: 2\n",
      "Action prob: [0.9650654  0.03493466], Action: 0, state: 3\n",
      "Action prob: [0.96110225 0.03889773], Action: 0, state: 3\n",
      "Action prob: [0.96224993 0.03775012], Action: 0, state: 3\n",
      "Action prob: [0.9626741  0.03732589], Action: 0, state: 3\n",
      "Action prob: [0.97400385 0.0259962 ], Action: 0, state: 8\n",
      "Action prob: [0.95339185 0.04660809], Action: 0, state: 8\n",
      "Action prob: [0.9595923  0.04040774], Action: 0, state: 8\n",
      "Action prob: [0.9437428  0.05625717], Action: 0, state: 8\n",
      "Action prob: [0.97009224 0.0299077 ], Action: 0, state: 8\n",
      "Action prob: [0.96943    0.03056992], Action: 0, state: 8\n",
      "Action prob: [0.97394174 0.02605825], Action: 0, state: 8\n",
      "Action prob: [0.9532372  0.04676288], Action: 0, state: 8\n",
      "Action prob: [0.95793325 0.0420667 ], Action: 0, state: 8\n",
      "Action prob: [0.9469732  0.05302674], Action: 0, state: 8\n",
      "Action prob: [0.97146094 0.02853909], Action: 0, state: 8\n",
      "Action prob: [0.9420746  0.05792546], Action: 0, state: 8\n",
      "Action prob: [0.97077596 0.02922402], Action: 0, state: 8\n",
      "Action prob: [0.97232765 0.02767237], Action: 0, state: 8\n",
      "Action prob: [0.97708035 0.02291966], Action: 0, state: 8\n",
      "Action prob: [0.9501677  0.04983228], Action: 0, state: 8\n",
      "Action prob: [0.96932095 0.03067908], Action: 0, state: 8\n",
      "Action prob: [0.9666236  0.03337646], Action: 0, state: 8\n",
      "Action prob: [0.9716697  0.02833035], Action: 0, state: 8\n",
      "Action prob: [0.9704553  0.02954473], Action: 0, state: 8\n",
      "Action prob: [0.9736997 0.0263003], Action: 0, state: 8\n",
      "Action prob: [0.97263193 0.02736803], Action: 0, state: 8\n",
      "Action prob: [0.9708591  0.02914089], Action: 0, state: 8\n",
      "Action prob: [0.97201633 0.02798366], Action: 0, state: 8\n",
      "Action prob: [0.97035205 0.02964796], Action: 0, state: 8\n",
      "Action prob: [0.9478829  0.05211708], Action: 0, state: 8\n",
      "Action prob: [0.95195615 0.04804382], Action: 0, state: 8\n",
      "Action prob: [0.9667847  0.03321534], Action: 0, state: 8\n",
      "Action prob: [0.9747576  0.02524238], Action: 0, state: 8\n",
      "Action prob: [0.9708664  0.02913364], Action: 0, state: 8\n",
      "Action prob: [0.97538495 0.02461502], Action: 0, state: 8\n",
      "Action prob: [0.94047415 0.05952587], Action: 0, state: 8\n",
      "Action prob: [0.9426797  0.05732029], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.97088844 0.02911156], Action: 0, state: 8\n",
      "Action prob: [0.9707254  0.02927455], Action: 0, state: 8\n",
      "Action prob: [0.9711421  0.02885794], Action: 0, state: 8\n",
      "Action prob: [0.95343727 0.04656275], Action: 0, state: 8\n",
      "Action prob: [0.9536935  0.04630654], Action: 0, state: 8\n",
      "Action prob: [0.9815059  0.01849413], Action: 0, state: 8\n",
      "Action prob: [0.9635754  0.03642457], Action: 0, state: 8\n",
      "Action prob: [0.9762339  0.02376608], Action: 0, state: 8\n",
      "Action prob: [0.9738733  0.02612662], Action: 0, state: 8\n",
      "Action prob: [0.9638892 0.0361108], Action: 0, state: 8\n",
      "Reward for this episode -128300, loss is -0.025173247650255665\n",
      "Action prob: [0.9634644  0.03653561], Action: 0, state: 0\n",
      "Action prob: [0.960667   0.03933297], Action: 0, state: 1\n",
      "Action prob: [0.96073693 0.03926311], Action: 0, state: 2\n",
      "Action prob: [0.9597595  0.04024046], Action: 0, state: 2\n",
      "Action prob: [0.9625673  0.03743262], Action: 0, state: 2\n",
      "Action prob: [0.97045386 0.02954612], Action: 0, state: 3\n",
      "Action prob: [0.96563387 0.03436619], Action: 0, state: 3\n",
      "Action prob: [0.9621999  0.03780011], Action: 0, state: 3\n",
      "Action prob: [0.96213615 0.03786385], Action: 0, state: 3\n",
      "Action prob: [0.96332663 0.03667337], Action: 0, state: 3\n",
      "Action prob: [0.97948414 0.02051581], Action: 0, state: 8\n",
      "Action prob: [0.94741684 0.05258314], Action: 0, state: 8\n",
      "Action prob: [0.9771378  0.02286224], Action: 0, state: 8\n",
      "Action prob: [0.9723609  0.02763916], Action: 0, state: 8\n",
      "Action prob: [0.97134125 0.0286588 ], Action: 0, state: 8\n",
      "Action prob: [0.97278905 0.02721092], Action: 0, state: 8\n",
      "Action prob: [0.97269475 0.02730521], Action: 0, state: 8\n",
      "Action prob: [0.96895057 0.03104949], Action: 0, state: 8\n",
      "Action prob: [0.9452008  0.05479924], Action: 0, state: 8\n",
      "Action prob: [0.94786465 0.05213529], Action: 0, state: 8\n",
      "Action prob: [0.9726898  0.02731027], Action: 0, state: 8\n",
      "Action prob: [0.94991016 0.05008985], Action: 1, state: 8\n",
      "Action prob: [0.94301313 0.05698685], Action: 0, state: 8\n",
      "Action prob: [0.97153777 0.02846219], Action: 0, state: 8\n",
      "Action prob: [0.973188   0.02681205], Action: 0, state: 8\n",
      "Action prob: [0.9443963  0.05560361], Action: 0, state: 8\n",
      "Action prob: [0.97180253 0.02819744], Action: 0, state: 8\n",
      "Action prob: [0.97253233 0.0274676 ], Action: 0, state: 8\n",
      "Action prob: [0.94909775 0.0509023 ], Action: 0, state: 8\n",
      "Action prob: [0.94948363 0.05051637], Action: 0, state: 8\n",
      "Action prob: [0.96115524 0.03884481], Action: 0, state: 8\n",
      "Action prob: [0.97127783 0.02872213], Action: 0, state: 8\n",
      "Action prob: [0.97613496 0.02386504], Action: 1, state: 8\n",
      "Reward for this episode -62200, loss is 0.1121976952265029\n",
      "Action prob: [0.9629083  0.03709169], Action: 0, state: 0\n",
      "Action prob: [0.9620812  0.03791879], Action: 0, state: 1\n",
      "Action prob: [0.962047   0.03795298], Action: 0, state: 2\n",
      "Action prob: [0.96208173 0.03791822], Action: 0, state: 3\n",
      "Action prob: [0.9461987  0.05380123], Action: 0, state: 8\n",
      "Action prob: [0.97088504 0.02911495], Action: 0, state: 8\n",
      "Action prob: [0.9745078  0.02549215], Action: 0, state: 8\n",
      "Action prob: [0.9502818  0.04971821], Action: 0, state: 8\n",
      "Action prob: [0.9718874  0.02811257], Action: 0, state: 8\n",
      "Action prob: [0.96900505 0.03099497], Action: 0, state: 8\n",
      "Action prob: [0.95442104 0.04557898], Action: 0, state: 8\n",
      "Action prob: [0.94944805 0.05055192], Action: 0, state: 8\n",
      "Action prob: [0.97551244 0.0244876 ], Action: 0, state: 8\n",
      "Action prob: [0.94971186 0.05028822], Action: 0, state: 8\n",
      "Action prob: [0.94077325 0.05922678], Action: 0, state: 8\n",
      "Action prob: [0.95875627 0.04124381], Action: 0, state: 8\n",
      "Action prob: [0.9512878  0.04871222], Action: 0, state: 8\n",
      "Action prob: [0.97061825 0.02938171], Action: 0, state: 8\n",
      "Action prob: [0.97239447 0.0276055 ], Action: 0, state: 8\n",
      "Action prob: [0.97773975 0.02226031], Action: 0, state: 8\n",
      "Action prob: [0.97135127 0.02864878], Action: 0, state: 8\n",
      "Action prob: [0.97268367 0.02731635], Action: 0, state: 8\n",
      "Action prob: [0.9708028  0.02919723], Action: 0, state: 8\n",
      "Action prob: [0.97210467 0.02789533], Action: 0, state: 8\n",
      "Action prob: [0.9699893  0.03001066], Action: 1, state: 8\n",
      "Reward for this episode -59800, loss is 0.09694669219538543\n",
      "Action prob: [0.9793817  0.02061824], Action: 0, state: 0\n",
      "Action prob: [0.9637912  0.03620883], Action: 0, state: 1\n",
      "Action prob: [0.95765054 0.04234945], Action: 0, state: 1\n",
      "Action prob: [0.964104   0.03589604], Action: 0, state: 1\n",
      "Action prob: [0.95963204 0.04036796], Action: 1, state: 2\n",
      "Action prob: [0.5661733 0.4338267], Action: 0, state: 6\n",
      "Action prob: [0.5661733 0.4338267], Action: 0, state: 6\n",
      "Action prob: [0.5661733 0.4338267], Action: 1, state: 6\n",
      "Action prob: [0.9611332  0.03886684], Action: 0, state: 1\n",
      "Action prob: [0.9605578 0.0394422], Action: 0, state: 2\n",
      "Action prob: [0.95975465 0.04024537], Action: 0, state: 2\n",
      "Action prob: [0.96270144 0.0372985 ], Action: 0, state: 3\n",
      "Action prob: [0.9686811  0.03131882], Action: 0, state: 8\n",
      "Action prob: [0.95177823 0.0482217 ], Action: 0, state: 8\n",
      "Action prob: [0.96955484 0.03044513], Action: 0, state: 8\n",
      "Action prob: [0.97380596 0.02619408], Action: 0, state: 8\n",
      "Action prob: [0.9686252  0.03137475], Action: 0, state: 8\n",
      "Action prob: [0.97445256 0.02554749], Action: 0, state: 8\n",
      "Action prob: [0.96909964 0.03090033], Action: 0, state: 8\n",
      "Action prob: [0.94823563 0.05176439], Action: 0, state: 8\n",
      "Action prob: [0.9420472  0.05795286], Action: 0, state: 8\n",
      "Action prob: [0.9473805  0.05261947], Action: 0, state: 8\n",
      "Action prob: [0.975023   0.02497706], Action: 0, state: 8\n",
      "Action prob: [0.91132015 0.0886799 ], Action: 0, state: 8\n",
      "Action prob: [0.97895426 0.02104571], Action: 0, state: 8\n",
      "Action prob: [0.9484123  0.05158767], Action: 1, state: 8\n",
      "Action prob: [0.96809614 0.03190391], Action: 0, state: 8\n",
      "Action prob: [0.97260827 0.0273917 ], Action: 0, state: 8\n",
      "Action prob: [0.9681457  0.03185431], Action: 0, state: 8\n",
      "Action prob: [0.95831025 0.0416898 ], Action: 0, state: 8\n",
      "Action prob: [0.9711575  0.02884246], Action: 0, state: 8\n",
      "Action prob: [0.9699756  0.03002436], Action: 0, state: 8\n",
      "Action prob: [0.9709071  0.02909298], Action: 0, state: 8\n",
      "Action prob: [0.9265807  0.07341925], Action: 0, state: 8\n",
      "Action prob: [0.9410723  0.05892772], Action: 0, state: 8\n",
      "Action prob: [0.973006   0.02699397], Action: 0, state: 8\n",
      "Action prob: [0.97803783 0.02196215], Action: 1, state: 8\n",
      "Action prob: [0.9785098  0.02149022], Action: 0, state: 8\n",
      "Action prob: [0.9450858  0.05491417], Action: 0, state: 8\n",
      "Action prob: [0.9451271  0.05487291], Action: 0, state: 8\n",
      "Action prob: [0.97545755 0.02454243], Action: 0, state: 8\n",
      "Action prob: [0.97189504 0.0281049 ], Action: 0, state: 8\n",
      "Action prob: [0.9494459  0.05055414], Action: 0, state: 8\n",
      "Action prob: [0.94909024 0.05090979], Action: 0, state: 8\n",
      "Action prob: [0.9450462  0.05495375], Action: 0, state: 8\n",
      "Action prob: [0.96765476 0.03234518], Action: 0, state: 8\n",
      "Action prob: [0.9686378 0.0313622], Action: 0, state: 8\n",
      "Action prob: [0.9727137  0.02728626], Action: 0, state: 8\n",
      "Action prob: [0.97147655 0.02852345], Action: 0, state: 8\n",
      "Action prob: [0.97806746 0.02193247], Action: 0, state: 8\n",
      "Reward for this episode -112000, loss is -0.14109687675341862\n",
      "Action prob: [0.95481765 0.04518227], Action: 0, state: 0\n",
      "Action prob: [0.9609038  0.03909612], Action: 0, state: 0\n",
      "Action prob: [0.959627   0.04037298], Action: 0, state: 1\n",
      "Action prob: [0.95931804 0.04068199], Action: 0, state: 1\n",
      "Action prob: [0.9610695  0.03893043], Action: 0, state: 1\n",
      "Action prob: [0.95693076 0.04306925], Action: 0, state: 1\n",
      "Action prob: [0.95104504 0.04895493], Action: 1, state: 1\n",
      "Action prob: [0.97183573 0.02816426], Action: 0, state: 9\n",
      "Action prob: [0.9461599  0.05384016], Action: 1, state: 9\n",
      "Action prob: [0.95954496 0.040455  ], Action: 1, state: 0\n",
      "Action prob: [0.567431   0.43256897], Action: 1, state: 4\n",
      "Action prob: [0.96040547 0.0395945 ], Action: 0, state: 0\n",
      "Action prob: [0.94069445 0.05930553], Action: 0, state: 0\n",
      "Action prob: [0.96214956 0.03785039], Action: 0, state: 1\n",
      "Action prob: [0.9634302  0.03656974], Action: 0, state: 2\n",
      "Action prob: [0.94053584 0.05946415], Action: 0, state: 3\n",
      "Action prob: [0.96524405 0.03475598], Action: 0, state: 3\n",
      "Action prob: [0.95975304 0.04024693], Action: 0, state: 3\n",
      "Action prob: [0.96313196 0.03686804], Action: 0, state: 3\n",
      "Action prob: [0.94233733 0.05766264], Action: 0, state: 3\n",
      "Action prob: [0.9563988  0.04360121], Action: 0, state: 3\n",
      "Action prob: [0.9601276 0.0398724], Action: 1, state: 3\n",
      "Action prob: [0.567431   0.43256897], Action: 1, state: 7\n",
      "Action prob: [0.9626935  0.03730649], Action: 0, state: 2\n",
      "Action prob: [0.9598572  0.04014271], Action: 1, state: 2\n",
      "Action prob: [0.567431   0.43256897], Action: 0, state: 6\n",
      "Action prob: [0.9617374  0.03826261], Action: 0, state: 1\n",
      "Action prob: [0.9603776  0.03962249], Action: 0, state: 1\n",
      "Action prob: [0.95905024 0.04094977], Action: 0, state: 1\n",
      "Action prob: [0.9564882  0.04351182], Action: 0, state: 1\n",
      "Action prob: [0.9574822  0.04251774], Action: 0, state: 1\n",
      "Action prob: [0.9649205  0.03507948], Action: 0, state: 2\n",
      "Action prob: [0.95791835 0.04208158], Action: 0, state: 2\n",
      "Action prob: [0.96029645 0.03970362], Action: 0, state: 2\n",
      "Action prob: [0.96915597 0.03084398], Action: 0, state: 9\n",
      "Action prob: [0.96721363 0.03278643], Action: 0, state: 9\n",
      "Action prob: [0.9652215  0.03477843], Action: 0, state: 9\n",
      "Action prob: [0.96827644 0.03172356], Action: 0, state: 9\n",
      "Action prob: [0.9726438  0.02735627], Action: 0, state: 9\n",
      "Action prob: [0.9684456  0.03155437], Action: 0, state: 9\n",
      "Action prob: [0.9700141  0.02998588], Action: 0, state: 9\n",
      "Action prob: [0.9363124  0.06368761], Action: 0, state: 9\n",
      "Action prob: [0.94813424 0.05186577], Action: 0, state: 9\n",
      "Action prob: [0.9625931  0.03740689], Action: 0, state: 9\n",
      "Action prob: [0.9710486  0.02895143], Action: 0, state: 9\n",
      "Action prob: [0.9745695  0.02543049], Action: 0, state: 9\n",
      "Action prob: [0.971901   0.02809892], Action: 1, state: 9\n",
      "Action prob: [0.9444713  0.05552868], Action: 0, state: 9\n",
      "Action prob: [0.9748902  0.02510988], Action: 0, state: 9\n",
      "Action prob: [0.96805334 0.03194669], Action: 0, state: 9\n",
      "Reward for this episode 1700, loss is -0.09073349268467629\n",
      "Action prob: [0.95889366 0.04110636], Action: 0, state: 0\n",
      "Action prob: [0.9606194  0.03938055], Action: 0, state: 1\n",
      "Action prob: [0.96153384 0.03846608], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.95862156 0.04137845], Action: 0, state: 1\n",
      "Action prob: [0.9605175  0.03948243], Action: 0, state: 1\n",
      "Action prob: [0.9594582  0.04054181], Action: 0, state: 1\n",
      "Action prob: [0.9572792  0.04272084], Action: 0, state: 2\n",
      "Action prob: [0.9362831  0.06371683], Action: 0, state: 3\n",
      "Action prob: [0.96744746 0.03255256], Action: 0, state: 8\n",
      "Action prob: [0.94692034 0.05307966], Action: 0, state: 8\n",
      "Action prob: [0.9428421  0.05715783], Action: 0, state: 8\n",
      "Action prob: [0.9673708 0.0326292], Action: 0, state: 8\n",
      "Action prob: [0.94611305 0.05388694], Action: 0, state: 8\n",
      "Action prob: [0.9714659  0.02853408], Action: 0, state: 8\n",
      "Action prob: [0.9693443  0.03065563], Action: 0, state: 8\n",
      "Action prob: [0.9713741  0.02862591], Action: 0, state: 8\n",
      "Action prob: [0.9470314  0.05296864], Action: 0, state: 8\n",
      "Action prob: [0.9474498  0.05255013], Action: 0, state: 8\n",
      "Action prob: [0.9674548  0.03254518], Action: 0, state: 8\n",
      "Action prob: [0.9401044  0.05989556], Action: 0, state: 8\n",
      "Action prob: [0.9434694  0.05653064], Action: 0, state: 8\n",
      "Action prob: [0.96804684 0.0319531 ], Action: 0, state: 8\n",
      "Action prob: [0.97216403 0.02783596], Action: 0, state: 8\n",
      "Action prob: [0.96739095 0.03260903], Action: 1, state: 8\n",
      "Action prob: [0.97221315 0.02778684], Action: 0, state: 8\n",
      "Action prob: [0.97664577 0.02335421], Action: 0, state: 8\n",
      "Action prob: [0.93784815 0.06215188], Action: 0, state: 8\n",
      "Action prob: [0.96717256 0.03282743], Action: 0, state: 8\n",
      "Action prob: [0.95422757 0.04577245], Action: 0, state: 8\n",
      "Action prob: [0.97260725 0.02739275], Action: 0, state: 8\n",
      "Action prob: [0.9460811  0.05391888], Action: 0, state: 8\n",
      "Action prob: [0.9760391  0.02396087], Action: 0, state: 8\n",
      "Action prob: [0.9666426  0.03335734], Action: 0, state: 8\n",
      "Action prob: [0.9720409  0.02795913], Action: 0, state: 8\n",
      "Action prob: [0.9438492  0.05615075], Action: 0, state: 8\n",
      "Action prob: [0.9794796  0.02052036], Action: 0, state: 8\n",
      "Action prob: [0.9688593  0.03114062], Action: 0, state: 8\n",
      "Action prob: [0.9434704  0.05652953], Action: 0, state: 8\n",
      "Action prob: [0.97002083 0.0299792 ], Action: 0, state: 8\n",
      "Action prob: [0.9713302  0.02866971], Action: 0, state: 8\n",
      "Action prob: [0.97438043 0.02561951], Action: 0, state: 8\n",
      "Action prob: [0.9599507  0.04004926], Action: 0, state: 8\n",
      "Action prob: [0.9737959  0.02620412], Action: 0, state: 8\n",
      "Action prob: [0.9735075  0.02649253], Action: 0, state: 8\n",
      "Action prob: [0.94722974 0.05277024], Action: 0, state: 8\n",
      "Action prob: [0.9697291  0.03027083], Action: 1, state: 8\n",
      "Action prob: [0.97883373 0.02116623], Action: 0, state: 8\n",
      "Action prob: [0.95212716 0.04787279], Action: 0, state: 8\n",
      "Action prob: [0.97169375 0.02830618], Action: 0, state: 8\n",
      "Action prob: [0.965538   0.03446201], Action: 0, state: 8\n",
      "Reward for this episode -123200, loss is 0.04995182010630825\n",
      "Action prob: [0.96111006 0.03888993], Action: 0, state: 0\n",
      "Action prob: [0.956855   0.04314505], Action: 0, state: 0\n",
      "Action prob: [0.9624663  0.03753369], Action: 0, state: 0\n",
      "Action prob: [0.9556096  0.04439036], Action: 0, state: 0\n",
      "Action prob: [0.95785886 0.04214119], Action: 0, state: 1\n",
      "Action prob: [0.96204275 0.03795721], Action: 0, state: 2\n",
      "Action prob: [0.96834624 0.03165381], Action: 0, state: 2\n",
      "Action prob: [0.9578189 0.0421811], Action: 0, state: 2\n",
      "Action prob: [0.96248364 0.03751639], Action: 0, state: 3\n",
      "Action prob: [0.952736   0.04726405], Action: 0, state: 3\n",
      "Action prob: [0.95920473 0.04079531], Action: 0, state: 3\n",
      "Action prob: [0.9416521  0.05834785], Action: 0, state: 3\n",
      "Action prob: [0.9728099  0.02719012], Action: 0, state: 3\n",
      "Action prob: [0.96070755 0.03929251], Action: 0, state: 3\n",
      "Action prob: [0.9586358  0.04136421], Action: 0, state: 3\n",
      "Action prob: [0.96962345 0.0303766 ], Action: 0, state: 8\n",
      "Action prob: [0.9654889  0.03451112], Action: 0, state: 8\n",
      "Action prob: [0.94479257 0.05520743], Action: 0, state: 8\n",
      "Action prob: [0.96836174 0.03163819], Action: 0, state: 8\n",
      "Action prob: [0.94520944 0.05479055], Action: 0, state: 8\n",
      "Action prob: [0.9236457  0.07635433], Action: 0, state: 8\n",
      "Action prob: [0.9533198  0.04668018], Action: 1, state: 8\n",
      "Action prob: [0.944286   0.05571403], Action: 0, state: 8\n",
      "Action prob: [0.9691873  0.03081266], Action: 0, state: 8\n",
      "Action prob: [0.9699599  0.03004012], Action: 0, state: 8\n",
      "Action prob: [0.9711454  0.02885468], Action: 0, state: 8\n",
      "Action prob: [0.9708827 0.0291173], Action: 0, state: 8\n",
      "Action prob: [0.9642994  0.03570064], Action: 0, state: 8\n",
      "Action prob: [0.969634   0.03036604], Action: 0, state: 8\n",
      "Action prob: [0.9676416  0.03235844], Action: 0, state: 8\n",
      "Action prob: [0.97935313 0.02064689], Action: 0, state: 8\n",
      "Action prob: [0.94195926 0.05804077], Action: 0, state: 8\n",
      "Action prob: [0.9677913  0.03220874], Action: 0, state: 8\n",
      "Action prob: [0.9474252  0.05257482], Action: 0, state: 8\n",
      "Action prob: [0.9653196 0.0346804], Action: 0, state: 8\n",
      "Action prob: [0.9712932  0.02870678], Action: 0, state: 8\n",
      "Action prob: [0.94925445 0.05074555], Action: 1, state: 8\n",
      "Action prob: [0.967967   0.03203304], Action: 0, state: 8\n",
      "Action prob: [0.9655573  0.03444277], Action: 0, state: 8\n",
      "Action prob: [0.9475352  0.05246475], Action: 0, state: 8\n",
      "Action prob: [0.9718421  0.02815781], Action: 0, state: 8\n",
      "Action prob: [0.9718346  0.02816538], Action: 0, state: 8\n",
      "Action prob: [0.9672409  0.03275907], Action: 0, state: 8\n",
      "Action prob: [0.9696063  0.03039373], Action: 0, state: 8\n",
      "Action prob: [0.96647    0.03353001], Action: 0, state: 8\n",
      "Action prob: [0.96725833 0.03274164], Action: 0, state: 8\n",
      "Action prob: [0.9787724  0.02122754], Action: 0, state: 8\n",
      "Action prob: [0.94618195 0.05381801], Action: 0, state: 8\n",
      "Action prob: [0.96877384 0.0312261 ], Action: 0, state: 8\n",
      "Action prob: [0.9528727  0.04712733], Action: 0, state: 8\n",
      "Reward for this episode -98200, loss is -0.04470260215523962\n",
      "Action prob: [0.9600029  0.03999707], Action: 0, state: 0\n",
      "Action prob: [0.9603557  0.03964429], Action: 0, state: 0\n",
      "Action prob: [0.9585462  0.04145382], Action: 0, state: 0\n",
      "Action prob: [0.9569716  0.04302848], Action: 0, state: 0\n",
      "Action prob: [0.952469   0.04753098], Action: 0, state: 0\n",
      "Action prob: [0.9631029  0.03689712], Action: 0, state: 0\n",
      "Action prob: [0.95659804 0.04340199], Action: 0, state: 1\n",
      "Action prob: [0.9583131  0.04168688], Action: 0, state: 2\n",
      "Action prob: [0.95900756 0.04099248], Action: 0, state: 2\n",
      "Action prob: [0.9587385  0.04126154], Action: 0, state: 2\n",
      "Action prob: [0.95952964 0.04047039], Action: 0, state: 2\n",
      "Action prob: [0.95928854 0.04071152], Action: 1, state: 3\n",
      "Action prob: [0.57038933 0.42961067], Action: 1, state: 7\n",
      "Action prob: [0.57038933 0.42961067], Action: 1, state: 7\n",
      "Action prob: [0.57038933 0.42961067], Action: 1, state: 7\n",
      "Action prob: [0.57038933 0.42961067], Action: 1, state: 7\n",
      "Action prob: [0.95726585 0.04273407], Action: 0, state: 2\n",
      "Action prob: [0.960073   0.03992701], Action: 0, state: 3\n",
      "Action prob: [0.96647716 0.0335229 ], Action: 0, state: 3\n",
      "Action prob: [0.955765   0.04423494], Action: 0, state: 8\n",
      "Action prob: [0.9385887  0.06141131], Action: 0, state: 8\n",
      "Action prob: [0.9477298  0.05227016], Action: 0, state: 8\n",
      "Action prob: [0.96677476 0.0332252 ], Action: 0, state: 8\n",
      "Action prob: [0.94403976 0.05596026], Action: 0, state: 8\n",
      "Action prob: [0.94555205 0.05444792], Action: 0, state: 8\n",
      "Action prob: [0.9438726  0.05612747], Action: 0, state: 8\n",
      "Action prob: [0.95840746 0.04159251], Action: 0, state: 8\n",
      "Action prob: [0.9420454  0.05795464], Action: 0, state: 8\n",
      "Action prob: [0.9582819  0.04171811], Action: 0, state: 8\n",
      "Action prob: [0.9554113  0.04458869], Action: 0, state: 8\n",
      "Action prob: [0.95535386 0.04464611], Action: 0, state: 8\n",
      "Action prob: [0.96099776 0.03900225], Action: 0, state: 8\n",
      "Action prob: [0.9650684  0.03493166], Action: 0, state: 8\n",
      "Action prob: [0.96846783 0.03153216], Action: 0, state: 8\n",
      "Action prob: [0.9687918  0.03120825], Action: 0, state: 8\n",
      "Action prob: [0.9667446  0.03325538], Action: 0, state: 8\n",
      "Action prob: [0.9615525  0.03844748], Action: 0, state: 8\n",
      "Action prob: [0.95528793 0.04471208], Action: 0, state: 8\n",
      "Action prob: [0.9627528  0.03724711], Action: 0, state: 8\n",
      "Action prob: [0.9625889  0.03741116], Action: 0, state: 8\n",
      "Action prob: [0.9706998  0.02930026], Action: 0, state: 8\n",
      "Action prob: [0.9453878 0.0546122], Action: 0, state: 8\n",
      "Action prob: [0.95058614 0.04941392], Action: 0, state: 8\n",
      "Action prob: [0.9413054  0.05869454], Action: 0, state: 8\n",
      "Action prob: [0.94104356 0.05895643], Action: 0, state: 8\n",
      "Action prob: [0.94492036 0.05507962], Action: 0, state: 8\n",
      "Action prob: [0.9593062  0.04069377], Action: 0, state: 8\n",
      "Action prob: [0.9705724  0.02942754], Action: 0, state: 8\n",
      "Action prob: [0.96796876 0.03203126], Action: 0, state: 8\n",
      "Action prob: [0.96587723 0.03412272], Action: 0, state: 8\n",
      "Reward for this episode -86600, loss is -0.09691905427558128\n",
      "Action prob: [0.96170086 0.03829912], Action: 0, state: 0\n",
      "Action prob: [0.95983064 0.04016932], Action: 0, state: 0\n",
      "Action prob: [0.9584968  0.04150316], Action: 0, state: 1\n",
      "Action prob: [0.95564336 0.04435667], Action: 0, state: 2\n",
      "Action prob: [0.95750254 0.04249744], Action: 0, state: 2\n",
      "Action prob: [0.9615411  0.03845885], Action: 0, state: 2\n",
      "Action prob: [0.9439213  0.05607868], Action: 0, state: 3\n",
      "Action prob: [0.9698738  0.03012623], Action: 0, state: 8\n",
      "Action prob: [0.948206   0.05179394], Action: 0, state: 8\n",
      "Action prob: [0.9519914  0.04800866], Action: 0, state: 8\n",
      "Action prob: [0.96984476 0.03015529], Action: 1, state: 8\n",
      "Action prob: [0.9482833  0.05171673], Action: 0, state: 8\n",
      "Action prob: [0.968959   0.03104102], Action: 0, state: 8\n",
      "Action prob: [0.9629369  0.03706317], Action: 0, state: 8\n",
      "Action prob: [0.9655149  0.03448503], Action: 0, state: 8\n",
      "Action prob: [0.9537025  0.04629745], Action: 0, state: 8\n",
      "Action prob: [0.9672231  0.03277687], Action: 0, state: 8\n",
      "Action prob: [0.96637726 0.03362269], Action: 0, state: 8\n",
      "Action prob: [0.96979845 0.03020161], Action: 0, state: 8\n",
      "Action prob: [0.97230464 0.02769535], Action: 0, state: 8\n",
      "Action prob: [0.96658975 0.03341022], Action: 0, state: 8\n",
      "Action prob: [0.9621954  0.03780458], Action: 1, state: 8\n",
      "Action prob: [0.9697776  0.03022238], Action: 0, state: 8\n",
      "Action prob: [0.96563786 0.03436211], Action: 0, state: 8\n",
      "Action prob: [0.9724344  0.02756558], Action: 0, state: 8\n",
      "Action prob: [0.9667291  0.03327087], Action: 0, state: 8\n",
      "Action prob: [0.9662044  0.03379562], Action: 1, state: 8\n",
      "Reward for this episode -54200, loss is 0.17032404183145664\n",
      "Action prob: [0.95673627 0.0432637 ], Action: 0, state: 0\n",
      "Action prob: [0.9534435  0.04655644], Action: 0, state: 0\n",
      "Action prob: [0.953359   0.04664099], Action: 0, state: 1\n",
      "Action prob: [0.95685315 0.04314684], Action: 0, state: 1\n",
      "Action prob: [0.95705414 0.04294592], Action: 0, state: 2\n",
      "Action prob: [0.9588141  0.04118592], Action: 0, state: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.95624036 0.04375966], Action: 0, state: 2\n",
      "Action prob: [0.95544213 0.04455791], Action: 0, state: 3\n",
      "Action prob: [0.95927525 0.04072476], Action: 0, state: 3\n",
      "Action prob: [0.9495686 0.0504314], Action: 0, state: 3\n",
      "Action prob: [0.95394945 0.04605053], Action: 0, state: 3\n",
      "Action prob: [0.94017637 0.05982362], Action: 0, state: 3\n",
      "Action prob: [0.943778   0.05622205], Action: 0, state: 3\n",
      "Action prob: [0.96624136 0.03375863], Action: 0, state: 3\n",
      "Action prob: [0.95668495 0.04331505], Action: 0, state: 3\n",
      "Action prob: [0.9665639  0.03343615], Action: 0, state: 3\n",
      "Action prob: [0.9356819 0.0643181], Action: 0, state: 3\n",
      "Action prob: [0.9625636  0.03743637], Action: 0, state: 8\n",
      "Action prob: [0.9599805  0.04001946], Action: 0, state: 8\n",
      "Action prob: [0.9755096  0.02449045], Action: 0, state: 8\n",
      "Action prob: [0.9699421  0.03005791], Action: 0, state: 8\n",
      "Action prob: [0.9439299  0.05607002], Action: 0, state: 8\n",
      "Action prob: [0.96467084 0.0353291 ], Action: 0, state: 8\n",
      "Action prob: [0.9656144 0.0343856], Action: 0, state: 8\n",
      "Action prob: [0.9694828  0.03051717], Action: 0, state: 8\n",
      "Action prob: [0.9748156  0.02518441], Action: 0, state: 8\n",
      "Action prob: [0.94104   0.0589601], Action: 0, state: 8\n",
      "Action prob: [0.9667027  0.03329729], Action: 0, state: 8\n",
      "Action prob: [0.9687037  0.03129623], Action: 0, state: 8\n",
      "Action prob: [0.9665945  0.03340549], Action: 0, state: 8\n",
      "Action prob: [0.9472708  0.05272916], Action: 0, state: 8\n",
      "Action prob: [0.96760637 0.03239366], Action: 0, state: 8\n",
      "Action prob: [0.9728942 0.0271058], Action: 0, state: 8\n",
      "Action prob: [0.9402046  0.05979536], Action: 0, state: 8\n",
      "Action prob: [0.9676638  0.03233619], Action: 0, state: 8\n",
      "Action prob: [0.9657549  0.03424513], Action: 0, state: 8\n",
      "Action prob: [0.93991226 0.06008767], Action: 0, state: 8\n",
      "Action prob: [0.9688006  0.03119937], Action: 0, state: 8\n",
      "Action prob: [0.94292706 0.05707299], Action: 0, state: 8\n",
      "Action prob: [0.94593775 0.05406228], Action: 0, state: 8\n",
      "Action prob: [0.9348682  0.06513181], Action: 0, state: 8\n",
      "Action prob: [0.9659968  0.03400325], Action: 0, state: 8\n",
      "Action prob: [0.96125644 0.0387436 ], Action: 0, state: 8\n",
      "Action prob: [0.9387293  0.06127066], Action: 0, state: 8\n",
      "Action prob: [0.9490389  0.05096111], Action: 0, state: 8\n",
      "Action prob: [0.9435373  0.05646273], Action: 0, state: 8\n",
      "Action prob: [0.93817645 0.06182353], Action: 1, state: 8\n",
      "Action prob: [0.96680176 0.03319831], Action: 0, state: 8\n",
      "Action prob: [0.96646893 0.0335311 ], Action: 0, state: 8\n",
      "Action prob: [0.97231674 0.02768332], Action: 0, state: 8\n",
      "Reward for this episode -91800, loss is -0.03121828954142611\n",
      "Action prob: [0.9562768  0.04372321], Action: 0, state: 0\n",
      "Action prob: [0.9545378  0.04546218], Action: 0, state: 1\n",
      "Action prob: [0.9579131 0.0420869], Action: 0, state: 1\n",
      "Action prob: [0.9559568 0.0440432], Action: 0, state: 1\n",
      "Action prob: [0.9507521  0.04924797], Action: 0, state: 2\n",
      "Action prob: [0.95223475 0.04776527], Action: 0, state: 3\n",
      "Action prob: [0.96246487 0.03753509], Action: 0, state: 3\n",
      "Action prob: [0.963458   0.03654207], Action: 0, state: 3\n",
      "Action prob: [0.9365555  0.06344447], Action: 0, state: 8\n",
      "Action prob: [0.93674797 0.063252  ], Action: 0, state: 8\n",
      "Action prob: [0.96342355 0.03657641], Action: 0, state: 8\n",
      "Action prob: [0.9635531  0.03644701], Action: 0, state: 8\n",
      "Action prob: [0.9470342  0.05296583], Action: 0, state: 8\n",
      "Action prob: [0.9689173 0.0310827], Action: 0, state: 8\n",
      "Action prob: [0.9690271  0.03097285], Action: 0, state: 8\n",
      "Action prob: [0.9690085  0.03099152], Action: 0, state: 8\n",
      "Action prob: [0.93513024 0.06486975], Action: 0, state: 8\n",
      "Action prob: [0.96582705 0.0341729 ], Action: 0, state: 8\n",
      "Action prob: [0.9662831  0.03371693], Action: 0, state: 8\n",
      "Action prob: [0.93956393 0.0604361 ], Action: 0, state: 8\n",
      "Action prob: [0.9661983  0.03380166], Action: 0, state: 8\n",
      "Action prob: [0.9392233  0.06077675], Action: 0, state: 8\n",
      "Action prob: [0.94183207 0.05816801], Action: 0, state: 8\n",
      "Action prob: [0.94252497 0.05747508], Action: 0, state: 8\n",
      "Action prob: [0.96943194 0.03056801], Action: 0, state: 8\n",
      "Action prob: [0.9542848  0.04571527], Action: 0, state: 8\n",
      "Action prob: [0.9657379  0.03426216], Action: 0, state: 8\n",
      "Action prob: [0.96376646 0.03623347], Action: 0, state: 8\n",
      "Action prob: [0.9468263  0.05317373], Action: 0, state: 8\n",
      "Action prob: [0.94534767 0.05465232], Action: 0, state: 8\n",
      "Action prob: [0.96058434 0.03941572], Action: 0, state: 8\n",
      "Action prob: [0.9646856  0.03531442], Action: 0, state: 8\n",
      "Action prob: [0.93219495 0.06780504], Action: 0, state: 8\n",
      "Action prob: [0.947481   0.05251909], Action: 0, state: 8\n",
      "Action prob: [0.9638098  0.03619028], Action: 0, state: 8\n",
      "Action prob: [0.9351744  0.06482554], Action: 0, state: 8\n",
      "Action prob: [0.9663689  0.03363108], Action: 0, state: 8\n",
      "Action prob: [0.9639648  0.03603517], Action: 0, state: 8\n",
      "Action prob: [0.96201783 0.03798216], Action: 0, state: 8\n",
      "Action prob: [0.9660483  0.03395164], Action: 0, state: 8\n",
      "Action prob: [0.96771526 0.03228476], Action: 0, state: 8\n",
      "Action prob: [0.94056123 0.05943877], Action: 0, state: 8\n",
      "Action prob: [0.9386262  0.06137372], Action: 1, state: 8\n",
      "Action prob: [0.9630704  0.03692961], Action: 0, state: 8\n",
      "Action prob: [0.95346934 0.04653068], Action: 0, state: 8\n",
      "Action prob: [0.96578103 0.0342189 ], Action: 0, state: 8\n",
      "Action prob: [0.9655358  0.03446421], Action: 0, state: 8\n",
      "Action prob: [0.9522976  0.04770237], Action: 0, state: 8\n",
      "Action prob: [0.9716229  0.02837715], Action: 0, state: 8\n",
      "Action prob: [0.9665933  0.03340668], Action: 1, state: 8\n",
      "Reward for this episode -124000, loss is 0.05326669994195565\n",
      "Action prob: [0.95332265 0.04667735], Action: 0, state: 0\n",
      "Action prob: [0.9459849  0.05401514], Action: 0, state: 0\n",
      "Action prob: [0.95620567 0.04379432], Action: 0, state: 0\n",
      "Action prob: [0.9524277  0.04757227], Action: 0, state: 1\n",
      "Action prob: [0.95507205 0.04492792], Action: 0, state: 1\n",
      "Action prob: [0.95297694 0.04702308], Action: 0, state: 1\n",
      "Action prob: [0.9520615  0.04793847], Action: 0, state: 1\n",
      "Action prob: [0.9546979  0.04530203], Action: 0, state: 1\n",
      "Action prob: [0.9649133 0.0350867], Action: 0, state: 1\n",
      "Action prob: [0.95037395 0.04962598], Action: 0, state: 1\n",
      "Action prob: [0.9544447  0.04555526], Action: 0, state: 1\n",
      "Action prob: [0.95362216 0.04637785], Action: 0, state: 1\n",
      "Action prob: [0.95519507 0.04480495], Action: 0, state: 1\n",
      "Action prob: [0.9517319  0.04826805], Action: 0, state: 1\n",
      "Action prob: [0.9523194  0.04768068], Action: 0, state: 1\n",
      "Action prob: [0.953629   0.04637099], Action: 0, state: 1\n",
      "Action prob: [0.948053   0.05194701], Action: 0, state: 2\n",
      "Action prob: [0.953729   0.04627102], Action: 0, state: 2\n",
      "Action prob: [0.95291436 0.04708568], Action: 0, state: 2\n",
      "Action prob: [0.95587415 0.04412588], Action: 0, state: 2\n",
      "Action prob: [0.9538154  0.04618459], Action: 0, state: 2\n",
      "Action prob: [0.9527172  0.04728285], Action: 0, state: 2\n",
      "Action prob: [0.95084906 0.04915101], Action: 0, state: 3\n",
      "Action prob: [0.96682346 0.03317657], Action: 0, state: 3\n",
      "Action prob: [0.95826066 0.0417393 ], Action: 0, state: 3\n",
      "Action prob: [0.9498316  0.05016838], Action: 0, state: 3\n",
      "Action prob: [0.9542196  0.04578046], Action: 0, state: 3\n",
      "Action prob: [0.94897854 0.0510214 ], Action: 0, state: 3\n",
      "Action prob: [0.9633098  0.03669011], Action: 0, state: 3\n",
      "Action prob: [0.96256095 0.03743909], Action: 0, state: 8\n",
      "Action prob: [0.9603078 0.0396922], Action: 0, state: 8\n",
      "Action prob: [0.96134114 0.03865881], Action: 0, state: 8\n",
      "Action prob: [0.9677585  0.03224153], Action: 0, state: 8\n",
      "Action prob: [0.95970076 0.04029929], Action: 0, state: 8\n",
      "Action prob: [0.942976   0.05702397], Action: 0, state: 8\n",
      "Action prob: [0.96710414 0.03289586], Action: 0, state: 8\n",
      "Action prob: [0.94272506 0.05727492], Action: 0, state: 8\n",
      "Action prob: [0.96339625 0.0366038 ], Action: 0, state: 8\n",
      "Action prob: [0.96025807 0.03974195], Action: 0, state: 8\n",
      "Action prob: [0.93975717 0.06024283], Action: 0, state: 8\n",
      "Action prob: [0.9653845  0.03461558], Action: 0, state: 8\n",
      "Action prob: [0.95943105 0.04056898], Action: 0, state: 8\n",
      "Action prob: [0.96032965 0.03967038], Action: 0, state: 8\n",
      "Action prob: [0.93715566 0.06284431], Action: 0, state: 8\n",
      "Action prob: [0.9594656  0.04053436], Action: 0, state: 8\n",
      "Action prob: [0.96369207 0.03630798], Action: 0, state: 8\n",
      "Action prob: [0.9430977 0.0569023], Action: 0, state: 8\n",
      "Action prob: [0.93815166 0.06184837], Action: 0, state: 8\n",
      "Action prob: [0.96684384 0.03315619], Action: 0, state: 8\n",
      "Action prob: [0.9625351  0.03746487], Action: 0, state: 8\n",
      "Reward for this episode -44000, loss is -0.02058329607798685\n",
      "Action prob: [0.9479569 0.0520431], Action: 0, state: 0\n",
      "Action prob: [0.9538318  0.04616823], Action: 0, state: 0\n",
      "Action prob: [0.9534065  0.04659348], Action: 0, state: 0\n",
      "Action prob: [0.9600094  0.03999066], Action: 0, state: 0\n",
      "Action prob: [0.95196134 0.0480387 ], Action: 0, state: 1\n",
      "Action prob: [0.9485979 0.0514021], Action: 0, state: 1\n",
      "Action prob: [0.95174    0.04825999], Action: 0, state: 1\n",
      "Action prob: [0.9531578  0.04684228], Action: 0, state: 1\n",
      "Action prob: [0.9453789  0.05462114], Action: 0, state: 1\n",
      "Action prob: [0.95217633 0.04782366], Action: 0, state: 2\n",
      "Action prob: [0.9505744  0.04942556], Action: 0, state: 3\n",
      "Action prob: [0.93645066 0.06354934], Action: 0, state: 8\n",
      "Action prob: [0.97394717 0.0260528 ], Action: 0, state: 8\n",
      "Action prob: [0.93405896 0.06594102], Action: 0, state: 8\n",
      "Action prob: [0.93578523 0.06421474], Action: 0, state: 8\n",
      "Action prob: [0.95837265 0.0416274 ], Action: 0, state: 8\n",
      "Action prob: [0.962697   0.03730294], Action: 0, state: 8\n",
      "Action prob: [0.9292338  0.07076617], Action: 0, state: 8\n",
      "Action prob: [0.93437016 0.06562989], Action: 0, state: 8\n",
      "Action prob: [0.9310182 0.0689818], Action: 0, state: 8\n",
      "Action prob: [0.9616881  0.03831194], Action: 0, state: 8\n",
      "Action prob: [0.9595418  0.04045821], Action: 0, state: 8\n",
      "Action prob: [0.94908863 0.05091134], Action: 0, state: 8\n",
      "Action prob: [0.9676514  0.03234852], Action: 0, state: 8\n",
      "Action prob: [0.93380195 0.06619804], Action: 0, state: 8\n",
      "Action prob: [0.96182704 0.03817299], Action: 0, state: 8\n",
      "Action prob: [0.96204555 0.03795452], Action: 0, state: 8\n",
      "Action prob: [0.9307525  0.06924751], Action: 0, state: 8\n",
      "Action prob: [0.9645933  0.03540671], Action: 1, state: 8\n",
      "Action prob: [0.96285    0.03714998], Action: 0, state: 8\n",
      "Action prob: [0.9691738  0.03082629], Action: 0, state: 8\n",
      "Action prob: [0.96377003 0.03623001], Action: 0, state: 8\n",
      "Action prob: [0.9621966  0.03780342], Action: 0, state: 8\n",
      "Action prob: [0.9616488  0.03835115], Action: 0, state: 8\n",
      "Action prob: [0.9748273  0.02517275], Action: 0, state: 8\n",
      "Action prob: [0.9581642  0.04183573], Action: 0, state: 8\n",
      "Action prob: [0.9311832 0.0688168], Action: 0, state: 8\n",
      "Action prob: [0.9500571  0.04994291], Action: 0, state: 8\n",
      "Action prob: [0.95801485 0.04198513], Action: 0, state: 8\n",
      "Action prob: [0.93903446 0.06096552], Action: 0, state: 8\n",
      "Action prob: [0.9638964  0.03610364], Action: 0, state: 8\n",
      "Action prob: [0.93784887 0.06215117], Action: 0, state: 8\n",
      "Action prob: [0.93267226 0.06732774], Action: 0, state: 8\n",
      "Action prob: [0.9681151  0.03188488], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.9441804  0.05581952], Action: 0, state: 8\n",
      "Action prob: [0.96746475 0.03253533], Action: 0, state: 8\n",
      "Action prob: [0.96173406 0.03826595], Action: 0, state: 8\n",
      "Action prob: [0.9612493  0.03875074], Action: 0, state: 8\n",
      "Action prob: [0.9634787  0.03652132], Action: 0, state: 8\n",
      "Action prob: [0.9312427  0.06875732], Action: 1, state: 8\n",
      "Reward for this episode -111200, loss is 0.006691933623446139\n",
      "Action prob: [0.95597667 0.04402339], Action: 0, state: 0\n",
      "Action prob: [0.9467613  0.05323872], Action: 0, state: 0\n",
      "Action prob: [0.952012   0.04798798], Action: 0, state: 0\n",
      "Action prob: [0.94396305 0.05603696], Action: 0, state: 1\n",
      "Action prob: [0.956053   0.04394697], Action: 0, state: 1\n",
      "Action prob: [0.9469825  0.05301743], Action: 0, state: 1\n",
      "Action prob: [0.95008624 0.0499137 ], Action: 0, state: 2\n",
      "Action prob: [0.94656676 0.05343325], Action: 0, state: 2\n",
      "Action prob: [0.9383964  0.06160364], Action: 0, state: 3\n",
      "Action prob: [0.94982433 0.0501757 ], Action: 0, state: 3\n",
      "Action prob: [0.9356531  0.06434694], Action: 0, state: 8\n",
      "Action prob: [0.95969427 0.04030569], Action: 1, state: 8\n",
      "Action prob: [0.9656555 0.0343445], Action: 1, state: 8\n",
      "Action prob: [0.9423531  0.05764692], Action: 0, state: 0\n",
      "Action prob: [0.948965   0.05103498], Action: 0, state: 1\n",
      "Action prob: [0.94873935 0.05126066], Action: 0, state: 1\n",
      "Action prob: [0.94575953 0.05424048], Action: 0, state: 2\n",
      "Action prob: [0.9540767  0.04592324], Action: 0, state: 2\n",
      "Action prob: [0.954775   0.04522503], Action: 0, state: 3\n",
      "Action prob: [0.94477284 0.0552271 ], Action: 0, state: 3\n",
      "Action prob: [0.9491082  0.05089189], Action: 0, state: 3\n",
      "Action prob: [0.94830775 0.05169229], Action: 0, state: 3\n",
      "Action prob: [0.9556096  0.04439037], Action: 0, state: 3\n",
      "Action prob: [0.9426182  0.05738183], Action: 1, state: 3\n",
      "Action prob: [0.57686865 0.42313135], Action: 0, state: 7\n",
      "Action prob: [0.57686865 0.42313135], Action: 1, state: 7\n",
      "Action prob: [0.9485394  0.05146062], Action: 0, state: 2\n",
      "Action prob: [0.9366206  0.06337947], Action: 0, state: 3\n",
      "Action prob: [0.9484522  0.05154779], Action: 1, state: 3\n",
      "Action prob: [0.57686865 0.42313135], Action: 0, state: 7\n",
      "Action prob: [0.57686865 0.42313135], Action: 0, state: 7\n",
      "Action prob: [0.57686865 0.42313135], Action: 0, state: 7\n",
      "Action prob: [0.57686865 0.42313135], Action: 0, state: 7\n",
      "Action prob: [0.94880146 0.05119855], Action: 0, state: 2\n",
      "Action prob: [0.9514965  0.04850357], Action: 0, state: 3\n",
      "Action prob: [0.9458305  0.05416947], Action: 0, state: 3\n",
      "Action prob: [0.9481729  0.05182712], Action: 0, state: 3\n",
      "Action prob: [0.9486243  0.05137572], Action: 0, state: 3\n",
      "Action prob: [0.95740724 0.04259278], Action: 1, state: 9\n",
      "Action prob: [0.93028224 0.06971773], Action: 0, state: 9\n",
      "Action prob: [0.9570243  0.04297573], Action: 0, state: 9\n",
      "Action prob: [0.9322213  0.06777869], Action: 0, state: 9\n",
      "Action prob: [0.9372969  0.06270305], Action: 0, state: 9\n",
      "Action prob: [0.95451665 0.04548343], Action: 0, state: 9\n",
      "Action prob: [0.9727842  0.02721586], Action: 0, state: 9\n",
      "Action prob: [0.9593825  0.04061754], Action: 0, state: 9\n",
      "Action prob: [0.96470714 0.03529282], Action: 0, state: 9\n",
      "Action prob: [0.93289536 0.0671047 ], Action: 0, state: 9\n",
      "Action prob: [0.96038723 0.03961279], Action: 0, state: 9\n",
      "Action prob: [0.9617644  0.03823562], Action: 0, state: 9\n",
      "Reward for this episode -5700, loss is -0.06557553759301353\n",
      "Action prob: [0.95120496 0.04879503], Action: 0, state: 0\n",
      "Action prob: [0.94677025 0.05322967], Action: 0, state: 1\n",
      "Action prob: [0.9493013  0.05069877], Action: 0, state: 1\n",
      "Action prob: [0.9428406  0.05715943], Action: 0, state: 1\n",
      "Action prob: [0.94138485 0.05861519], Action: 0, state: 2\n",
      "Action prob: [0.96899295 0.03100705], Action: 0, state: 3\n",
      "Action prob: [0.9508901  0.04910994], Action: 0, state: 8\n",
      "Action prob: [0.92872804 0.07127191], Action: 0, state: 8\n",
      "Action prob: [0.93491405 0.0650859 ], Action: 0, state: 8\n",
      "Action prob: [0.93222326 0.06777681], Action: 0, state: 8\n",
      "Action prob: [0.9725937  0.02740632], Action: 0, state: 8\n",
      "Action prob: [0.9593661  0.04063385], Action: 0, state: 8\n",
      "Action prob: [0.95911866 0.04088141], Action: 0, state: 8\n",
      "Action prob: [0.9340365  0.06596347], Action: 1, state: 8\n",
      "Action prob: [0.9597309  0.04026901], Action: 0, state: 8\n",
      "Action prob: [0.9563519  0.04364811], Action: 0, state: 8\n",
      "Action prob: [0.9295777 0.0704223], Action: 0, state: 8\n",
      "Action prob: [0.95851487 0.04148512], Action: 0, state: 8\n",
      "Action prob: [0.95492345 0.04507655], Action: 0, state: 8\n",
      "Action prob: [0.9572743  0.04272573], Action: 0, state: 8\n",
      "Action prob: [0.9593638  0.04063623], Action: 1, state: 8\n",
      "Reward for this episode -40000, loss is 0.2434914913761972\n",
      "Action prob: [0.9422749  0.05772506], Action: 0, state: 0\n",
      "Action prob: [0.9393987  0.06060129], Action: 0, state: 1\n",
      "Action prob: [0.9386835  0.06131648], Action: 0, state: 1\n",
      "Action prob: [0.94608366 0.05391632], Action: 0, state: 2\n",
      "Action prob: [0.9551004  0.04489958], Action: 0, state: 3\n",
      "Action prob: [0.9419381  0.05806187], Action: 0, state: 3\n",
      "Action prob: [0.92936474 0.07063521], Action: 0, state: 3\n",
      "Action prob: [0.95700943 0.04299055], Action: 0, state: 8\n",
      "Action prob: [0.96100533 0.03899468], Action: 0, state: 8\n",
      "Action prob: [0.96073484 0.03926514], Action: 0, state: 8\n",
      "Action prob: [0.9226451  0.07735489], Action: 0, state: 8\n",
      "Action prob: [0.95918894 0.040811  ], Action: 0, state: 8\n",
      "Action prob: [0.94680476 0.0531952 ], Action: 0, state: 8\n",
      "Action prob: [0.9556128  0.04438724], Action: 0, state: 8\n",
      "Action prob: [0.9520444  0.04795562], Action: 0, state: 8\n",
      "Action prob: [0.94886094 0.05113913], Action: 1, state: 8\n",
      "Action prob: [0.95147955 0.04852051], Action: 0, state: 8\n",
      "Action prob: [0.9560566  0.04394335], Action: 0, state: 8\n",
      "Action prob: [0.92791307 0.07208692], Action: 0, state: 8\n",
      "Action prob: [0.9245986  0.07540142], Action: 0, state: 8\n",
      "Action prob: [0.9602703  0.03972968], Action: 0, state: 8\n",
      "Action prob: [0.926595   0.07340498], Action: 0, state: 8\n",
      "Action prob: [0.9341942  0.06580581], Action: 0, state: 8\n",
      "Action prob: [0.92625344 0.07374651], Action: 0, state: 8\n",
      "Action prob: [0.9284978  0.07150217], Action: 0, state: 8\n",
      "Action prob: [0.9493132  0.05068683], Action: 0, state: 8\n",
      "Action prob: [0.9217584  0.07824154], Action: 1, state: 8\n",
      "Action prob: [0.9243208  0.07567916], Action: 0, state: 8\n",
      "Action prob: [0.92661107 0.0733889 ], Action: 0, state: 8\n",
      "Action prob: [0.9559117  0.04408831], Action: 0, state: 8\n",
      "Action prob: [0.93178564 0.06821432], Action: 0, state: 8\n",
      "Action prob: [0.91123176 0.08876824], Action: 0, state: 8\n",
      "Action prob: [0.9568251  0.04317487], Action: 0, state: 8\n",
      "Action prob: [0.9268542  0.07314581], Action: 0, state: 8\n",
      "Action prob: [0.91899216 0.08100782], Action: 1, state: 8\n",
      "Reward for this episode -78900, loss is 0.13027796646569148\n",
      "Action prob: [0.94763243 0.05236762], Action: 0, state: 0\n",
      "Action prob: [0.9383308  0.06166922], Action: 0, state: 0\n",
      "Action prob: [0.9381294  0.06187059], Action: 0, state: 1\n",
      "Action prob: [0.93723947 0.06276055], Action: 0, state: 2\n",
      "Action prob: [0.94484705 0.055153  ], Action: 0, state: 2\n",
      "Action prob: [0.9414855  0.05851441], Action: 0, state: 2\n",
      "Action prob: [0.9518411  0.04815889], Action: 0, state: 3\n",
      "Action prob: [0.94716877 0.05283122], Action: 1, state: 8\n",
      "Action prob: [0.91845435 0.0815457 ], Action: 0, state: 8\n",
      "Action prob: [0.94781595 0.05218407], Action: 0, state: 8\n",
      "Action prob: [0.91494596 0.08505403], Action: 0, state: 8\n",
      "Action prob: [0.93353766 0.06646235], Action: 0, state: 8\n",
      "Action prob: [0.9164506  0.08354943], Action: 0, state: 8\n",
      "Action prob: [0.95264685 0.04735312], Action: 0, state: 8\n",
      "Action prob: [0.9284267  0.07157333], Action: 1, state: 8\n",
      "Action prob: [0.9133766  0.08662343], Action: 0, state: 8\n",
      "Action prob: [0.94736767 0.05263236], Action: 0, state: 8\n",
      "Action prob: [0.9464613  0.05353866], Action: 0, state: 8\n",
      "Action prob: [0.9228682  0.07713182], Action: 1, state: 8\n",
      "Action prob: [0.93750507 0.06249493], Action: 0, state: 0\n",
      "Action prob: [0.9365943  0.06340563], Action: 0, state: 0\n",
      "Action prob: [0.93209916 0.0679009 ], Action: 0, state: 1\n",
      "Action prob: [0.9368573  0.06314266], Action: 0, state: 1\n",
      "Action prob: [0.93751985 0.06248013], Action: 0, state: 1\n",
      "Action prob: [0.93877155 0.06122845], Action: 0, state: 2\n",
      "Action prob: [0.93629533 0.0637047 ], Action: 0, state: 3\n",
      "Action prob: [0.9392095  0.06079053], Action: 0, state: 3\n",
      "Action prob: [0.9370953  0.06290471], Action: 0, state: 3\n",
      "Action prob: [0.91748303 0.08251701], Action: 0, state: 3\n",
      "Action prob: [0.93480176 0.06519824], Action: 1, state: 3\n",
      "Action prob: [0.5749464  0.42505363], Action: 0, state: 7\n",
      "Action prob: [0.5749464  0.42505363], Action: 0, state: 7\n",
      "Action prob: [0.93317163 0.0668284 ], Action: 0, state: 2\n",
      "Action prob: [0.9363196  0.06368037], Action: 0, state: 2\n",
      "Action prob: [0.9380966  0.06190336], Action: 0, state: 3\n",
      "Action prob: [0.9380667  0.06193331], Action: 0, state: 3\n",
      "Action prob: [0.91167384 0.08832616], Action: 1, state: 8\n",
      "Reward for this episode -23600, loss is 0.021850435366584434\n",
      "Action prob: [0.924005 0.075995], Action: 0, state: 0\n",
      "Action prob: [0.9344152  0.06558473], Action: 0, state: 0\n",
      "Action prob: [0.9238316  0.07616837], Action: 0, state: 0\n",
      "Action prob: [0.9317526  0.06824735], Action: 0, state: 0\n",
      "Action prob: [0.93302834 0.06697163], Action: 0, state: 0\n",
      "Action prob: [0.92733145 0.07266858], Action: 0, state: 1\n",
      "Action prob: [0.9342196  0.06578045], Action: 0, state: 2\n",
      "Action prob: [0.9327379  0.06726216], Action: 0, state: 2\n",
      "Action prob: [0.9284913  0.07150865], Action: 0, state: 2\n",
      "Action prob: [0.9276343  0.07236569], Action: 0, state: 2\n",
      "Action prob: [0.92716944 0.07283054], Action: 0, state: 2\n",
      "Action prob: [0.9291638  0.07083616], Action: 0, state: 2\n",
      "Action prob: [0.94554853 0.05445144], Action: 0, state: 3\n",
      "Action prob: [0.9497812  0.05021879], Action: 0, state: 8\n",
      "Action prob: [0.94462436 0.0553757 ], Action: 0, state: 8\n",
      "Action prob: [0.9422186  0.05778141], Action: 0, state: 8\n",
      "Action prob: [0.94242543 0.05757457], Action: 0, state: 8\n",
      "Action prob: [0.9422563  0.05774367], Action: 1, state: 8\n",
      "Action prob: [0.9379806  0.06201946], Action: 0, state: 8\n",
      "Action prob: [0.94609267 0.05390736], Action: 0, state: 8\n",
      "Action prob: [0.94125926 0.05874075], Action: 0, state: 8\n",
      "Action prob: [0.94288474 0.05711529], Action: 0, state: 8\n",
      "Action prob: [0.9065914 0.0934086], Action: 0, state: 8\n",
      "Action prob: [0.9414865  0.05851346], Action: 0, state: 8\n",
      "Action prob: [0.93896854 0.06103146], Action: 0, state: 8\n",
      "Action prob: [0.9386393  0.06136066], Action: 1, state: 8\n",
      "Reward for this episode -27800, loss is -0.05142891677760932\n",
      "Action prob: [0.92607635 0.07392367], Action: 0, state: 0\n",
      "Action prob: [0.92673904 0.07326103], Action: 0, state: 0\n",
      "Action prob: [0.9303161  0.06968393], Action: 0, state: 1\n",
      "Action prob: [0.9210698  0.07893024], Action: 0, state: 2\n",
      "Action prob: [0.9275308  0.07246922], Action: 0, state: 2\n",
      "Action prob: [0.9240224 0.0759776], Action: 0, state: 2\n",
      "Action prob: [0.9203639  0.07963607], Action: 0, state: 2\n",
      "Action prob: [0.9308152 0.0691848], Action: 0, state: 2\n",
      "Action prob: [0.9405903  0.05940967], Action: 0, state: 3\n",
      "Action prob: [0.92231965 0.07768039], Action: 0, state: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.9513713  0.04862872], Action: 0, state: 8\n",
      "Action prob: [0.90917474 0.09082528], Action: 0, state: 8\n",
      "Action prob: [0.9432942 0.0567058], Action: 0, state: 8\n",
      "Action prob: [0.92345136 0.07654863], Action: 0, state: 8\n",
      "Action prob: [0.9334014  0.06659865], Action: 0, state: 8\n",
      "Action prob: [0.94103223 0.05896781], Action: 0, state: 8\n",
      "Action prob: [0.8987029  0.10129708], Action: 0, state: 8\n",
      "Action prob: [0.94184875 0.05815127], Action: 0, state: 8\n",
      "Action prob: [0.9384566  0.06154346], Action: 0, state: 8\n",
      "Action prob: [0.9525022  0.04749781], Action: 0, state: 8\n",
      "Action prob: [0.94064647 0.0593535 ], Action: 0, state: 8\n",
      "Action prob: [0.9418773  0.05812264], Action: 0, state: 8\n",
      "Action prob: [0.90745044 0.09254953], Action: 0, state: 8\n",
      "Action prob: [0.9443569  0.05564312], Action: 0, state: 8\n",
      "Action prob: [0.90873146 0.09126861], Action: 0, state: 8\n",
      "Action prob: [0.95093095 0.04906905], Action: 0, state: 8\n",
      "Action prob: [0.93797606 0.06202393], Action: 0, state: 8\n",
      "Action prob: [0.90872973 0.09127019], Action: 0, state: 8\n",
      "Action prob: [0.9373456  0.06265431], Action: 0, state: 8\n",
      "Action prob: [0.8977568  0.10224325], Action: 0, state: 8\n",
      "Action prob: [0.9374236 0.0625764], Action: 0, state: 8\n",
      "Action prob: [0.9449373  0.05506268], Action: 0, state: 8\n",
      "Action prob: [0.9335677  0.06643228], Action: 0, state: 8\n",
      "Action prob: [0.947886   0.05211407], Action: 0, state: 8\n",
      "Action prob: [0.9059248  0.09407522], Action: 0, state: 8\n",
      "Action prob: [0.9414297  0.05857039], Action: 0, state: 8\n",
      "Action prob: [0.9330924  0.06690764], Action: 0, state: 8\n",
      "Action prob: [0.9360633  0.06393669], Action: 0, state: 8\n",
      "Action prob: [0.9393999  0.06060015], Action: 0, state: 8\n",
      "Action prob: [0.93121666 0.06878337], Action: 0, state: 8\n",
      "Action prob: [0.9381294  0.06187053], Action: 0, state: 8\n",
      "Action prob: [0.903337   0.09666298], Action: 0, state: 8\n",
      "Action prob: [0.93158543 0.0684146 ], Action: 0, state: 8\n",
      "Action prob: [0.93729997 0.0627    ], Action: 0, state: 8\n",
      "Action prob: [0.94065714 0.05934292], Action: 0, state: 8\n",
      "Action prob: [0.9414788  0.05852125], Action: 0, state: 8\n",
      "Action prob: [0.9410229  0.05897713], Action: 0, state: 8\n",
      "Action prob: [0.9370114  0.06298859], Action: 0, state: 8\n",
      "Action prob: [0.9107604  0.08923963], Action: 0, state: 8\n",
      "Action prob: [0.90373176 0.09626823], Action: 0, state: 8\n",
      "Reward for this episode -116100, loss is -0.017498802515846384\n",
      "Action prob: [0.9341624  0.06583761], Action: 0, state: 0\n",
      "Action prob: [0.9194623  0.08053768], Action: 0, state: 0\n",
      "Action prob: [0.9227738  0.07722621], Action: 0, state: 0\n",
      "Action prob: [0.9260462  0.07395379], Action: 0, state: 0\n",
      "Action prob: [0.9250079  0.07499212], Action: 0, state: 1\n",
      "Action prob: [0.9152016  0.08479844], Action: 0, state: 2\n",
      "Action prob: [0.922852   0.07714808], Action: 0, state: 3\n",
      "Action prob: [0.8999924  0.10000759], Action: 0, state: 8\n",
      "Action prob: [0.9331682  0.06683183], Action: 0, state: 8\n",
      "Action prob: [0.93496335 0.06503662], Action: 0, state: 8\n",
      "Action prob: [0.9273448  0.07265522], Action: 0, state: 8\n",
      "Action prob: [0.90101147 0.09898853], Action: 0, state: 8\n",
      "Action prob: [0.95108247 0.04891758], Action: 0, state: 8\n",
      "Action prob: [0.93288463 0.06711531], Action: 0, state: 8\n",
      "Action prob: [0.93580985 0.06419015], Action: 1, state: 8\n",
      "Action prob: [0.93292004 0.06708001], Action: 0, state: 8\n",
      "Action prob: [0.93961895 0.06038099], Action: 0, state: 8\n",
      "Action prob: [0.9412972  0.05870282], Action: 0, state: 8\n",
      "Action prob: [0.9324108  0.06758916], Action: 1, state: 8\n",
      "Action prob: [0.95082504 0.04917497], Action: 0, state: 8\n",
      "Action prob: [0.9046767  0.09532335], Action: 0, state: 8\n",
      "Action prob: [0.91160315 0.08839678], Action: 0, state: 8\n",
      "Action prob: [0.92982256 0.07017741], Action: 0, state: 8\n",
      "Action prob: [0.9316392  0.06836074], Action: 0, state: 8\n",
      "Action prob: [0.92691106 0.07308897], Action: 0, state: 8\n",
      "Action prob: [0.897388   0.10261198], Action: 0, state: 8\n",
      "Action prob: [0.93029875 0.06970122], Action: 0, state: 8\n",
      "Action prob: [0.89445865 0.10554139], Action: 0, state: 8\n",
      "Action prob: [0.9364489  0.06355111], Action: 0, state: 8\n",
      "Action prob: [0.8952722  0.10472783], Action: 0, state: 8\n",
      "Action prob: [0.93372273 0.06627724], Action: 0, state: 8\n",
      "Action prob: [0.93084145 0.06915859], Action: 0, state: 8\n",
      "Action prob: [0.9357455 0.0642546], Action: 0, state: 8\n",
      "Action prob: [0.9342565  0.06574349], Action: 0, state: 8\n",
      "Action prob: [0.9371558  0.06284416], Action: 0, state: 8\n",
      "Action prob: [0.9443858  0.05561417], Action: 0, state: 8\n",
      "Action prob: [0.9270197  0.07298031], Action: 0, state: 8\n",
      "Action prob: [0.917169   0.08283106], Action: 0, state: 8\n",
      "Action prob: [0.9319943  0.06800568], Action: 0, state: 8\n",
      "Action prob: [0.9078456  0.09215438], Action: 0, state: 8\n",
      "Action prob: [0.94645363 0.0535464 ], Action: 0, state: 8\n",
      "Action prob: [0.9046001  0.09539992], Action: 0, state: 8\n",
      "Action prob: [0.9231803  0.07681967], Action: 0, state: 8\n",
      "Action prob: [0.9045552  0.09544477], Action: 0, state: 8\n",
      "Action prob: [0.906441   0.09355909], Action: 0, state: 8\n",
      "Action prob: [0.93812305 0.06187699], Action: 0, state: 8\n",
      "Action prob: [0.93391216 0.06608792], Action: 0, state: 8\n",
      "Action prob: [0.9258469  0.07415313], Action: 0, state: 8\n",
      "Action prob: [0.90487444 0.09512559], Action: 0, state: 8\n",
      "Action prob: [0.92964655 0.07035345], Action: 0, state: 8\n",
      "Reward for this episode -126800, loss is 0.0026590905030270673\n",
      "Action prob: [0.90963995 0.09035999], Action: 0, state: 0\n",
      "Action prob: [0.91766804 0.08233196], Action: 0, state: 1\n",
      "Action prob: [0.9234667  0.07653333], Action: 0, state: 1\n",
      "Action prob: [0.9199962  0.08000377], Action: 0, state: 1\n",
      "Action prob: [0.91037405 0.08962591], Action: 0, state: 2\n",
      "Action prob: [0.9150981  0.08490188], Action: 0, state: 2\n",
      "Action prob: [0.9136128  0.08638722], Action: 0, state: 2\n",
      "Action prob: [0.9188855  0.08111449], Action: 1, state: 3\n",
      "Action prob: [0.57308143 0.42691863], Action: 0, state: 7\n",
      "Action prob: [0.57308143 0.42691863], Action: 0, state: 7\n",
      "Action prob: [0.9189957 0.0810043], Action: 0, state: 2\n",
      "Action prob: [0.9148745  0.08512552], Action: 1, state: 2\n",
      "Action prob: [0.57308143 0.42691863], Action: 0, state: 6\n",
      "Action prob: [0.91349053 0.08650944], Action: 0, state: 1\n",
      "Action prob: [0.91788995 0.08211012], Action: 0, state: 2\n",
      "Action prob: [0.9157216  0.08427837], Action: 0, state: 2\n",
      "Action prob: [0.9126531  0.08734691], Action: 0, state: 2\n",
      "Action prob: [0.91304296 0.08695707], Action: 0, state: 2\n",
      "Action prob: [0.9206913 0.0793087], Action: 0, state: 2\n",
      "Action prob: [0.9090835 0.0909165], Action: 0, state: 2\n",
      "Action prob: [0.93831885 0.06168111], Action: 0, state: 3\n",
      "Action prob: [0.9231847  0.07681537], Action: 0, state: 3\n",
      "Action prob: [0.9186639  0.08133601], Action: 0, state: 3\n",
      "Action prob: [0.9059747  0.09402528], Action: 1, state: 3\n",
      "Action prob: [0.57308143 0.42691863], Action: 1, state: 7\n",
      "Action prob: [0.57308143 0.42691863], Action: 1, state: 7\n",
      "Action prob: [0.57308143 0.42691863], Action: 0, state: 7\n",
      "Action prob: [0.57308143 0.42691863], Action: 1, state: 7\n",
      "Action prob: [0.57308143 0.42691863], Action: 0, state: 7\n",
      "Action prob: [0.92075706 0.0792429 ], Action: 0, state: 2\n",
      "Action prob: [0.9229193 0.0770807], Action: 1, state: 3\n",
      "Action prob: [0.57308143 0.42691863], Action: 0, state: 7\n",
      "Action prob: [0.57308143 0.42691863], Action: 1, state: 7\n",
      "Action prob: [0.57308143 0.42691863], Action: 0, state: 7\n",
      "Action prob: [0.916239   0.08376095], Action: 0, state: 2\n",
      "Action prob: [0.92052156 0.07947847], Action: 0, state: 2\n",
      "Action prob: [0.9148818  0.08511817], Action: 0, state: 2\n",
      "Action prob: [0.9283053  0.07169465], Action: 0, state: 3\n",
      "Action prob: [0.9279721  0.07202788], Action: 1, state: 8\n",
      "Action prob: [0.91516817 0.08483189], Action: 0, state: 8\n",
      "Action prob: [0.8942413  0.10575879], Action: 0, state: 8\n",
      "Action prob: [0.93948764 0.06051235], Action: 0, state: 8\n",
      "Action prob: [0.9370129  0.06298713], Action: 0, state: 8\n",
      "Action prob: [0.930496   0.06950402], Action: 0, state: 8\n",
      "Action prob: [0.9360395  0.06396046], Action: 0, state: 8\n",
      "Action prob: [0.8980175  0.10198247], Action: 0, state: 8\n",
      "Action prob: [0.92128617 0.07871383], Action: 0, state: 8\n",
      "Action prob: [0.92467    0.07533004], Action: 0, state: 8\n",
      "Action prob: [0.9334301  0.06656993], Action: 0, state: 8\n",
      "Action prob: [0.90015554 0.09984447], Action: 0, state: 8\n",
      "Reward for this episode -25400, loss is -0.11823584193981104\n",
      "Action prob: [0.9114654  0.08853456], Action: 0, state: 0\n",
      "Action prob: [0.91269755 0.08730242], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.9172341  0.08276588], Action: 0, state: 2\n",
      "Action prob: [0.91335934 0.08664073], Action: 0, state: 2\n",
      "Action prob: [0.9133835  0.08661656], Action: 0, state: 3\n",
      "Action prob: [0.93303365 0.06696635], Action: 0, state: 3\n",
      "Action prob: [0.9143252  0.08567479], Action: 0, state: 3\n",
      "Action prob: [0.917286   0.08271401], Action: 0, state: 3\n",
      "Action prob: [0.9050195  0.09498041], Action: 0, state: 3\n",
      "Action prob: [0.8823961  0.11760387], Action: 0, state: 8\n",
      "Action prob: [0.93215173 0.06784828], Action: 0, state: 8\n",
      "Action prob: [0.9257464  0.07425362], Action: 0, state: 8\n",
      "Action prob: [0.93175304 0.06824695], Action: 0, state: 8\n",
      "Action prob: [0.8936274  0.10637267], Action: 0, state: 8\n",
      "Action prob: [0.88563603 0.11436393], Action: 0, state: 8\n",
      "Action prob: [0.8913253  0.10867476], Action: 0, state: 8\n",
      "Action prob: [0.88304913 0.11695087], Action: 0, state: 8\n",
      "Action prob: [0.92253125 0.07746872], Action: 0, state: 8\n",
      "Action prob: [0.9288535  0.07114646], Action: 1, state: 8\n",
      "Action prob: [0.9300576 0.0699424], Action: 0, state: 8\n",
      "Action prob: [0.9268156  0.07318444], Action: 0, state: 8\n",
      "Action prob: [0.9234753  0.07652463], Action: 0, state: 8\n",
      "Action prob: [0.88581944 0.11418059], Action: 0, state: 8\n",
      "Action prob: [0.88955307 0.110447  ], Action: 0, state: 8\n",
      "Action prob: [0.92464453 0.07535551], Action: 0, state: 8\n",
      "Action prob: [0.8930307  0.10696927], Action: 0, state: 8\n",
      "Action prob: [0.9354103  0.06458969], Action: 0, state: 8\n",
      "Action prob: [0.89134914 0.1086508 ], Action: 0, state: 8\n",
      "Action prob: [0.89386183 0.10613814], Action: 0, state: 8\n",
      "Action prob: [0.9266289  0.07337109], Action: 0, state: 8\n",
      "Action prob: [0.9208533  0.07914667], Action: 0, state: 8\n",
      "Action prob: [0.887795   0.11220506], Action: 0, state: 8\n",
      "Action prob: [0.9228871  0.07711286], Action: 0, state: 8\n",
      "Action prob: [0.9276535  0.07234652], Action: 0, state: 8\n",
      "Action prob: [0.9319757  0.06802428], Action: 0, state: 8\n",
      "Action prob: [0.8946566  0.10534345], Action: 0, state: 8\n",
      "Action prob: [0.8879183  0.11208176], Action: 0, state: 8\n",
      "Action prob: [0.92666274 0.07333726], Action: 0, state: 8\n",
      "Action prob: [0.9271638  0.07283617], Action: 0, state: 8\n",
      "Action prob: [0.92477345 0.07522657], Action: 0, state: 8\n",
      "Action prob: [0.939191   0.06080899], Action: 0, state: 8\n",
      "Action prob: [0.92593753 0.07406242], Action: 0, state: 8\n",
      "Action prob: [0.9282816  0.07171836], Action: 0, state: 8\n",
      "Action prob: [0.8931177  0.10688226], Action: 0, state: 8\n",
      "Action prob: [0.9247554  0.07524455], Action: 0, state: 8\n",
      "Action prob: [0.93885934 0.06114059], Action: 0, state: 8\n",
      "Action prob: [0.9247971 0.0752029], Action: 0, state: 8\n",
      "Action prob: [0.928982   0.07101797], Action: 1, state: 8\n",
      "Action prob: [0.89368504 0.10631488], Action: 0, state: 8\n",
      "Action prob: [0.9250441  0.07495591], Action: 0, state: 8\n",
      "Reward for this episode -121000, loss is 0.030218872548469104\n",
      "Action prob: [0.9116275  0.08837258], Action: 0, state: 0\n",
      "Action prob: [0.90361464 0.0963854 ], Action: 0, state: 1\n",
      "Action prob: [0.9102577 0.0897423], Action: 0, state: 2\n",
      "Action prob: [0.9185303  0.08146975], Action: 0, state: 2\n",
      "Action prob: [0.90970886 0.09029114], Action: 0, state: 2\n",
      "Action prob: [0.915818 0.084182], Action: 0, state: 3\n",
      "Action prob: [0.91736126 0.08263879], Action: 0, state: 3\n",
      "Action prob: [0.91411406 0.0858859 ], Action: 0, state: 3\n",
      "Action prob: [0.8780126  0.12198741], Action: 0, state: 8\n",
      "Action prob: [0.92692906 0.07307094], Action: 0, state: 8\n",
      "Action prob: [0.93793327 0.06206669], Action: 0, state: 8\n",
      "Action prob: [0.9316528 0.0683472], Action: 0, state: 8\n",
      "Action prob: [0.9230519  0.07694814], Action: 0, state: 8\n",
      "Action prob: [0.92243314 0.07756682], Action: 0, state: 8\n",
      "Action prob: [0.8889782  0.11102185], Action: 0, state: 8\n",
      "Action prob: [0.8950342  0.10496573], Action: 0, state: 8\n",
      "Action prob: [0.9271008  0.07289921], Action: 0, state: 8\n",
      "Action prob: [0.88621974 0.11378027], Action: 0, state: 8\n",
      "Action prob: [0.9063455  0.09365452], Action: 0, state: 8\n",
      "Action prob: [0.89130783 0.10869219], Action: 0, state: 8\n",
      "Action prob: [0.89032495 0.10967498], Action: 0, state: 8\n",
      "Action prob: [0.9150948  0.08490527], Action: 1, state: 8\n",
      "Action prob: [0.8864599  0.11354014], Action: 0, state: 8\n",
      "Action prob: [0.87876683 0.12123322], Action: 1, state: 8\n",
      "Action prob: [0.8916542 0.1083458], Action: 1, state: 8\n",
      "Action prob: [0.89308625 0.10691376], Action: 0, state: 8\n",
      "Action prob: [0.9295856  0.07041448], Action: 0, state: 8\n",
      "Action prob: [0.923995   0.07600496], Action: 0, state: 8\n",
      "Action prob: [0.89435154 0.10564845], Action: 0, state: 8\n",
      "Action prob: [0.92084783 0.07915214], Action: 1, state: 8\n",
      "Action prob: [0.92594165 0.07405834], Action: 0, state: 8\n",
      "Action prob: [0.93653774 0.06346221], Action: 0, state: 8\n",
      "Action prob: [0.92243975 0.07756022], Action: 0, state: 8\n",
      "Action prob: [0.9289392 0.0710608], Action: 0, state: 8\n",
      "Action prob: [0.91077423 0.08922571], Action: 0, state: 8\n",
      "Action prob: [0.9216366  0.07836339], Action: 0, state: 8\n",
      "Action prob: [0.92877245 0.07122751], Action: 0, state: 8\n",
      "Action prob: [0.9169842  0.08301578], Action: 0, state: 8\n",
      "Action prob: [0.92378366 0.07621631], Action: 0, state: 8\n",
      "Action prob: [0.92695886 0.07304108], Action: 0, state: 8\n",
      "Action prob: [0.87864333 0.12135672], Action: 0, state: 8\n",
      "Action prob: [0.9299933 0.0700067], Action: 0, state: 8\n",
      "Action prob: [0.92807084 0.07192911], Action: 0, state: 8\n",
      "Action prob: [0.92001957 0.07998038], Action: 0, state: 8\n",
      "Action prob: [0.924096   0.07590399], Action: 0, state: 8\n",
      "Action prob: [0.9199983  0.08000172], Action: 0, state: 8\n",
      "Action prob: [0.9230106  0.07698947], Action: 0, state: 8\n",
      "Action prob: [0.9221595  0.07784057], Action: 0, state: 8\n",
      "Action prob: [0.88394386 0.11605608], Action: 0, state: 8\n",
      "Action prob: [0.88579994 0.11420005], Action: 0, state: 8\n",
      "Reward for this episode -124200, loss is 0.08256599763713345\n",
      "Action prob: [0.9032948  0.09670514], Action: 0, state: 0\n",
      "Action prob: [0.9140336  0.08596645], Action: 0, state: 0\n",
      "Action prob: [0.9096441  0.09035593], Action: 0, state: 0\n",
      "Action prob: [0.9044796  0.09552042], Action: 0, state: 0\n",
      "Action prob: [0.9226275  0.07737242], Action: 0, state: 0\n",
      "Action prob: [0.9113249  0.08867515], Action: 0, state: 1\n",
      "Action prob: [0.8987999  0.10120008], Action: 0, state: 1\n",
      "Action prob: [0.9061308  0.09386919], Action: 0, state: 2\n",
      "Action prob: [0.9095025  0.09049749], Action: 0, state: 3\n",
      "Action prob: [0.90137386 0.09862611], Action: 0, state: 3\n",
      "Action prob: [0.8995009  0.10049909], Action: 0, state: 3\n",
      "Action prob: [0.93020177 0.06979817], Action: 0, state: 3\n",
      "Action prob: [0.90465176 0.09534823], Action: 0, state: 3\n",
      "Action prob: [0.8974271  0.10257289], Action: 0, state: 3\n",
      "Action prob: [0.9110537  0.08894626], Action: 0, state: 3\n",
      "Action prob: [0.88128203 0.11871803], Action: 0, state: 8\n",
      "Action prob: [0.9207115  0.07928845], Action: 0, state: 8\n",
      "Action prob: [0.8719698 0.1280302], Action: 0, state: 8\n",
      "Action prob: [0.89128655 0.1087135 ], Action: 0, state: 8\n",
      "Action prob: [0.88077605 0.11922389], Action: 0, state: 8\n",
      "Action prob: [0.8856621  0.11433785], Action: 0, state: 8\n",
      "Action prob: [0.9192824  0.08071765], Action: 0, state: 8\n",
      "Action prob: [0.91943604 0.08056394], Action: 0, state: 8\n",
      "Action prob: [0.921061   0.07893903], Action: 0, state: 8\n",
      "Action prob: [0.880096   0.11990401], Action: 0, state: 8\n",
      "Action prob: [0.8868037  0.11319631], Action: 1, state: 8\n",
      "Action prob: [0.92636794 0.07363207], Action: 0, state: 8\n",
      "Action prob: [0.88102144 0.11897853], Action: 0, state: 8\n",
      "Action prob: [0.92000085 0.07999923], Action: 1, state: 8\n",
      "Action prob: [0.9374395  0.06256045], Action: 0, state: 8\n",
      "Action prob: [0.922398   0.07760203], Action: 0, state: 8\n",
      "Action prob: [0.912526   0.08747394], Action: 1, state: 8\n",
      "Action prob: [0.9246654  0.07533456], Action: 0, state: 8\n",
      "Action prob: [0.88056415 0.11943588], Action: 0, state: 8\n",
      "Action prob: [0.9264862  0.07351378], Action: 0, state: 8\n",
      "Action prob: [0.880447   0.11955301], Action: 0, state: 8\n",
      "Action prob: [0.9279858  0.07201422], Action: 0, state: 8\n",
      "Action prob: [0.88162065 0.11837938], Action: 1, state: 8\n",
      "Reward for this episode -57900, loss is -0.04798485542514923\n",
      "Action prob: [0.8988606  0.10113942], Action: 0, state: 0\n",
      "Action prob: [0.89500606 0.10499399], Action: 1, state: 1\n",
      "Action prob: [0.57375526 0.42624477], Action: 1, state: 5\n",
      "Action prob: [0.57375526 0.42624477], Action: 1, state: 5\n",
      "Action prob: [0.8963771  0.10362286], Action: 0, state: 0\n",
      "Action prob: [0.89701873 0.10298128], Action: 0, state: 1\n",
      "Action prob: [0.90140635 0.09859365], Action: 0, state: 1\n",
      "Action prob: [0.90337145 0.09662855], Action: 0, state: 1\n",
      "Action prob: [0.89859945 0.1014006 ], Action: 0, state: 1\n",
      "Action prob: [0.90287423 0.09712584], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.89865303 0.10134695], Action: 0, state: 1\n",
      "Action prob: [0.9028893  0.09711076], Action: 0, state: 2\n",
      "Action prob: [0.8967421 0.1032579], Action: 0, state: 3\n",
      "Action prob: [0.8995887  0.10041134], Action: 0, state: 3\n",
      "Action prob: [0.9210895  0.07891053], Action: 0, state: 3\n",
      "Action prob: [0.92348844 0.0765116 ], Action: 0, state: 8\n",
      "Action prob: [0.91671455 0.08328552], Action: 0, state: 8\n",
      "Action prob: [0.8842285  0.11577151], Action: 0, state: 8\n",
      "Action prob: [0.92676336 0.07323667], Action: 0, state: 8\n",
      "Action prob: [0.8904661  0.10953395], Action: 0, state: 8\n",
      "Action prob: [0.8977008  0.10229924], Action: 0, state: 8\n",
      "Action prob: [0.8961671  0.10383295], Action: 0, state: 8\n",
      "Action prob: [0.91864294 0.08135712], Action: 0, state: 8\n",
      "Action prob: [0.8826219 0.1173781], Action: 0, state: 8\n",
      "Action prob: [0.8988983  0.10110167], Action: 0, state: 8\n",
      "Action prob: [0.91921854 0.08078147], Action: 0, state: 8\n",
      "Action prob: [0.9290047  0.07099529], Action: 0, state: 8\n",
      "Action prob: [0.9147681  0.08523194], Action: 0, state: 8\n",
      "Action prob: [0.91847825 0.08152172], Action: 0, state: 8\n",
      "Action prob: [0.9194575  0.08054247], Action: 0, state: 8\n",
      "Action prob: [0.89552706 0.10447295], Action: 0, state: 8\n",
      "Action prob: [0.90738195 0.09261809], Action: 0, state: 8\n",
      "Action prob: [0.9167556  0.08324438], Action: 0, state: 8\n",
      "Action prob: [0.88113993 0.11886008], Action: 0, state: 8\n",
      "Action prob: [0.9161556  0.08384449], Action: 0, state: 8\n",
      "Action prob: [0.8752511  0.12474894], Action: 0, state: 8\n",
      "Action prob: [0.9153577  0.08464225], Action: 0, state: 8\n",
      "Action prob: [0.87546223 0.12453775], Action: 1, state: 8\n",
      "Action prob: [0.8956948  0.10430519], Action: 0, state: 8\n",
      "Action prob: [0.91278684 0.08721312], Action: 0, state: 8\n",
      "Action prob: [0.91768074 0.08231924], Action: 0, state: 8\n",
      "Action prob: [0.9207136  0.07928634], Action: 0, state: 8\n",
      "Action prob: [0.86886334 0.13113664], Action: 0, state: 8\n",
      "Action prob: [0.9198709  0.08012909], Action: 0, state: 8\n",
      "Action prob: [0.9339474  0.06605256], Action: 0, state: 8\n",
      "Action prob: [0.86660725 0.13339278], Action: 0, state: 8\n",
      "Action prob: [0.8981352  0.10186483], Action: 0, state: 8\n",
      "Action prob: [0.916782   0.08321793], Action: 0, state: 8\n",
      "Action prob: [0.91938937 0.08061059], Action: 0, state: 8\n",
      "Action prob: [0.9279969  0.07200313], Action: 0, state: 8\n",
      "Reward for this episode -99400, loss is 0.13571427535264843\n",
      "Action prob: [0.8972409  0.10275916], Action: 1, state: 0\n",
      "Action prob: [0.5694638  0.43053624], Action: 1, state: 4\n",
      "Action prob: [0.5694638  0.43053624], Action: 0, state: 4\n",
      "Action prob: [0.88701487 0.11298515], Action: 0, state: 0\n",
      "Action prob: [0.89416337 0.10583664], Action: 0, state: 0\n",
      "Action prob: [0.89671344 0.1032866 ], Action: 0, state: 1\n",
      "Action prob: [0.90274507 0.09725488], Action: 0, state: 2\n",
      "Action prob: [0.91489536 0.08510461], Action: 0, state: 3\n",
      "Action prob: [0.90014684 0.09985311], Action: 0, state: 3\n",
      "Action prob: [0.8907802  0.10921983], Action: 0, state: 3\n",
      "Action prob: [0.868688 0.131312], Action: 0, state: 8\n",
      "Action prob: [0.9033956  0.09660446], Action: 0, state: 8\n",
      "Action prob: [0.9076752  0.09232483], Action: 0, state: 8\n",
      "Action prob: [0.9067158  0.09328425], Action: 0, state: 8\n",
      "Action prob: [0.8454311  0.15456893], Action: 0, state: 8\n",
      "Action prob: [0.87707305 0.12292694], Action: 0, state: 8\n",
      "Action prob: [0.9193047  0.08069526], Action: 0, state: 8\n",
      "Action prob: [0.9182815  0.08171852], Action: 0, state: 8\n",
      "Action prob: [0.8703545  0.12964553], Action: 0, state: 8\n",
      "Action prob: [0.9142399  0.08576013], Action: 0, state: 8\n",
      "Action prob: [0.92657197 0.07342807], Action: 0, state: 8\n",
      "Action prob: [0.87606317 0.12393685], Action: 0, state: 8\n",
      "Action prob: [0.9082495  0.09175046], Action: 1, state: 8\n",
      "Action prob: [0.87305015 0.12694983], Action: 0, state: 8\n",
      "Action prob: [0.8599323  0.14006767], Action: 0, state: 8\n",
      "Action prob: [0.91420054 0.08579946], Action: 0, state: 8\n",
      "Action prob: [0.9062285  0.09377157], Action: 0, state: 8\n",
      "Action prob: [0.90471345 0.09528653], Action: 0, state: 8\n",
      "Action prob: [0.8780833  0.12191667], Action: 0, state: 8\n",
      "Action prob: [0.90754783 0.09245218], Action: 0, state: 8\n",
      "Action prob: [0.8709095  0.12909055], Action: 1, state: 8\n",
      "Reward for this episode -57800, loss is 0.11325710433105679\n",
      "Action prob: [0.8901733  0.10982669], Action: 0, state: 0\n",
      "Action prob: [0.8873145  0.11268551], Action: 0, state: 1\n",
      "Action prob: [0.89334995 0.10665006], Action: 0, state: 2\n",
      "Action prob: [0.89187276 0.10812723], Action: 0, state: 2\n",
      "Action prob: [0.88318306 0.11681696], Action: 0, state: 2\n",
      "Action prob: [0.9113564  0.08864359], Action: 0, state: 3\n",
      "Action prob: [0.89453983 0.10546021], Action: 0, state: 3\n",
      "Action prob: [0.8957641  0.10423585], Action: 1, state: 3\n",
      "Action prob: [0.5654942  0.43450582], Action: 0, state: 7\n",
      "Action prob: [0.8900111  0.10998891], Action: 0, state: 2\n",
      "Action prob: [0.88471055 0.11528948], Action: 0, state: 2\n",
      "Action prob: [0.89811856 0.10188145], Action: 1, state: 3\n",
      "Action prob: [0.5654942  0.43450582], Action: 1, state: 7\n",
      "Action prob: [0.5654942  0.43450582], Action: 0, state: 7\n",
      "Action prob: [0.5654942  0.43450582], Action: 0, state: 7\n",
      "Action prob: [0.8841567  0.11584334], Action: 0, state: 2\n",
      "Action prob: [0.89391285 0.10608712], Action: 0, state: 2\n",
      "Action prob: [0.9083387 0.0916613], Action: 0, state: 3\n",
      "Action prob: [0.8919262  0.10807379], Action: 0, state: 3\n",
      "Action prob: [0.9221331  0.07786685], Action: 0, state: 8\n",
      "Action prob: [0.8675955  0.13240454], Action: 0, state: 8\n",
      "Action prob: [0.90250295 0.09749709], Action: 0, state: 8\n",
      "Action prob: [0.86213464 0.13786535], Action: 0, state: 8\n",
      "Action prob: [0.9091711  0.09082893], Action: 0, state: 8\n",
      "Action prob: [0.862266   0.13773407], Action: 0, state: 8\n",
      "Action prob: [0.8713036  0.12869641], Action: 0, state: 8\n",
      "Action prob: [0.90199584 0.09800421], Action: 0, state: 8\n",
      "Action prob: [0.88942665 0.11057334], Action: 0, state: 8\n",
      "Action prob: [0.89834625 0.10165379], Action: 0, state: 8\n",
      "Action prob: [0.89700246 0.10299757], Action: 0, state: 8\n",
      "Action prob: [0.90349084 0.09650911], Action: 0, state: 8\n",
      "Action prob: [0.8591031  0.14089692], Action: 0, state: 8\n",
      "Action prob: [0.8536613  0.14633872], Action: 0, state: 8\n",
      "Action prob: [0.902445 0.097555], Action: 1, state: 8\n",
      "Reward for this episode -36500, loss is -0.11293641002743861\n",
      "Action prob: [0.8821508  0.11784919], Action: 0, state: 0\n",
      "Action prob: [0.88092977 0.11907028], Action: 1, state: 0\n",
      "Action prob: [0.5619334  0.43806657], Action: 1, state: 4\n",
      "Action prob: [0.8831135  0.11688647], Action: 0, state: 0\n",
      "Action prob: [0.8806987  0.11930133], Action: 0, state: 0\n",
      "Action prob: [0.88413805 0.11586191], Action: 0, state: 0\n",
      "Action prob: [0.8770046  0.12299535], Action: 0, state: 1\n",
      "Action prob: [0.87420857 0.1257915 ], Action: 0, state: 1\n",
      "Action prob: [0.89358795 0.10641205], Action: 1, state: 1\n",
      "Action prob: [0.5619334  0.43806657], Action: 0, state: 5\n",
      "Action prob: [0.5619334  0.43806657], Action: 0, state: 5\n",
      "Action prob: [0.8840335  0.11596654], Action: 0, state: 0\n",
      "Action prob: [0.8822841 0.1177159], Action: 0, state: 0\n",
      "Action prob: [0.8814335  0.11856649], Action: 0, state: 1\n",
      "Action prob: [0.88893014 0.11106981], Action: 0, state: 1\n",
      "Action prob: [0.88985133 0.11014865], Action: 0, state: 1\n",
      "Action prob: [0.8767962  0.12320385], Action: 0, state: 2\n",
      "Action prob: [0.88301665 0.11698335], Action: 0, state: 2\n",
      "Action prob: [0.88605756 0.11394246], Action: 0, state: 3\n",
      "Action prob: [0.88890266 0.11109742], Action: 0, state: 3\n",
      "Action prob: [0.88378185 0.11621819], Action: 0, state: 3\n",
      "Action prob: [0.8849492  0.11505076], Action: 0, state: 3\n",
      "Action prob: [0.90202993 0.09797   ], Action: 0, state: 8\n",
      "Action prob: [0.8992691  0.10073084], Action: 0, state: 8\n",
      "Action prob: [0.8893435  0.11065652], Action: 1, state: 8\n",
      "Action prob: [0.8954478  0.10455221], Action: 0, state: 8\n",
      "Action prob: [0.8954767  0.10452334], Action: 1, state: 8\n",
      "Action prob: [0.8960737  0.10392634], Action: 0, state: 8\n",
      "Action prob: [0.8941366  0.10586338], Action: 0, state: 8\n",
      "Action prob: [0.91055727 0.08944276], Action: 0, state: 8\n",
      "Action prob: [0.85689145 0.14310855], Action: 0, state: 8\n",
      "Action prob: [0.8907926  0.10920742], Action: 0, state: 8\n",
      "Action prob: [0.84410167 0.15589838], Action: 0, state: 8\n",
      "Action prob: [0.86633253 0.13366744], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.90844625 0.09155381], Action: 0, state: 8\n",
      "Action prob: [0.85210276 0.14789724], Action: 0, state: 8\n",
      "Action prob: [0.8699594  0.13004054], Action: 0, state: 8\n",
      "Action prob: [0.85335416 0.14664578], Action: 0, state: 8\n",
      "Action prob: [0.8525151  0.14748488], Action: 0, state: 8\n",
      "Action prob: [0.91416216 0.08583787], Action: 0, state: 8\n",
      "Action prob: [0.88959134 0.11040866], Action: 0, state: 8\n",
      "Action prob: [0.9063974  0.09360263], Action: 1, state: 8\n",
      "Action prob: [0.9177624  0.08223756], Action: 0, state: 8\n",
      "Action prob: [0.86146665 0.13853334], Action: 0, state: 8\n",
      "Action prob: [0.8545939  0.14540611], Action: 0, state: 8\n",
      "Action prob: [0.8593829  0.14061707], Action: 0, state: 8\n",
      "Action prob: [0.85484016 0.14515981], Action: 0, state: 8\n",
      "Action prob: [0.91191596 0.08808409], Action: 0, state: 8\n",
      "Action prob: [0.8966308  0.10336917], Action: 0, state: 8\n",
      "Action prob: [0.9046315  0.09536847], Action: 0, state: 8\n",
      "Reward for this episode -73500, loss is 0.08113958629506401\n",
      "Action prob: [0.8754019  0.12459805], Action: 0, state: 0\n",
      "Action prob: [0.8745247  0.12547527], Action: 0, state: 1\n",
      "Action prob: [0.8804665  0.11953347], Action: 0, state: 2\n",
      "Action prob: [0.8771548  0.12284519], Action: 0, state: 3\n",
      "Action prob: [0.85201645 0.14798352], Action: 0, state: 8\n",
      "Action prob: [0.90025824 0.09974182], Action: 0, state: 8\n",
      "Action prob: [0.903211   0.09678905], Action: 0, state: 8\n",
      "Action prob: [0.897768   0.10223197], Action: 0, state: 8\n",
      "Action prob: [0.8393755  0.16062455], Action: 1, state: 8\n",
      "Action prob: [0.85170275 0.14829724], Action: 0, state: 8\n",
      "Action prob: [0.8644166  0.13558339], Action: 0, state: 8\n",
      "Action prob: [0.8863543  0.11364572], Action: 0, state: 8\n",
      "Action prob: [0.90467453 0.09532548], Action: 0, state: 8\n",
      "Action prob: [0.8910173  0.10898272], Action: 0, state: 8\n",
      "Action prob: [0.8408268  0.15917315], Action: 0, state: 8\n",
      "Action prob: [0.8492844  0.15071557], Action: 1, state: 8\n",
      "Action prob: [0.89398557 0.10601443], Action: 1, state: 8\n",
      "Action prob: [0.8538169 0.146183 ], Action: 0, state: 8\n",
      "Action prob: [0.81839126 0.18160868], Action: 1, state: 8\n",
      "Action prob: [0.8754129  0.12458713], Action: 0, state: 0\n",
      "Action prob: [0.87772596 0.12227397], Action: 0, state: 0\n",
      "Reward for this episode -39800, loss is 0.23414325888460646\n",
      "Action prob: [0.86069167 0.1393084 ], Action: 0, state: 0\n",
      "Action prob: [0.8638604  0.13613963], Action: 1, state: 0\n",
      "Action prob: [0.5498057  0.45019424], Action: 0, state: 4\n",
      "Action prob: [0.85987943 0.14012052], Action: 0, state: 0\n",
      "Action prob: [0.86755025 0.13244973], Action: 0, state: 0\n",
      "Action prob: [0.86927533 0.13072467], Action: 0, state: 0\n",
      "Action prob: [0.887271   0.11272899], Action: 0, state: 0\n",
      "Action prob: [0.8673909 0.1326091], Action: 0, state: 1\n",
      "Action prob: [0.87098056 0.12901947], Action: 0, state: 2\n",
      "Action prob: [0.8686629 0.1313371], Action: 0, state: 2\n",
      "Action prob: [0.87959105 0.12040896], Action: 0, state: 3\n",
      "Action prob: [0.8827682 0.1172318], Action: 0, state: 3\n",
      "Action prob: [0.87960804 0.120392  ], Action: 0, state: 3\n",
      "Action prob: [0.833275   0.16672495], Action: 0, state: 3\n",
      "Action prob: [0.8458954  0.15410458], Action: 0, state: 8\n",
      "Action prob: [0.893934   0.10606594], Action: 0, state: 8\n",
      "Action prob: [0.8354568  0.16454323], Action: 0, state: 8\n",
      "Action prob: [0.83553445 0.1644655 ], Action: 0, state: 8\n",
      "Action prob: [0.82946867 0.17053133], Action: 0, state: 8\n",
      "Action prob: [0.87597764 0.12402235], Action: 0, state: 8\n",
      "Action prob: [0.8848699  0.11513011], Action: 1, state: 8\n",
      "Action prob: [0.87441176 0.12558821], Action: 0, state: 8\n",
      "Action prob: [0.8965694  0.10343067], Action: 0, state: 8\n",
      "Action prob: [0.8327494  0.16725053], Action: 0, state: 8\n",
      "Action prob: [0.8715486  0.12845145], Action: 0, state: 8\n",
      "Action prob: [0.8893765  0.11062346], Action: 0, state: 8\n",
      "Action prob: [0.8402585  0.15974154], Action: 0, state: 8\n",
      "Action prob: [0.8368308  0.16316918], Action: 1, state: 8\n",
      "Action prob: [0.8923878  0.10761221], Action: 0, state: 8\n",
      "Action prob: [0.86765164 0.13234836], Action: 0, state: 8\n",
      "Action prob: [0.88026375 0.11973625], Action: 0, state: 8\n",
      "Action prob: [0.83506566 0.16493428], Action: 0, state: 8\n",
      "Action prob: [0.8551373  0.14486268], Action: 0, state: 8\n",
      "Action prob: [0.8429422  0.15705784], Action: 0, state: 8\n",
      "Action prob: [0.8413385  0.15866141], Action: 0, state: 8\n",
      "Action prob: [0.8981307  0.10186932], Action: 0, state: 8\n",
      "Action prob: [0.8816222  0.11837775], Action: 0, state: 8\n",
      "Action prob: [0.8838882 0.1161118], Action: 0, state: 8\n",
      "Action prob: [0.85395646 0.14604354], Action: 1, state: 8\n",
      "Action prob: [0.83017814 0.16982187], Action: 0, state: 8\n",
      "Action prob: [0.8380119  0.16198808], Action: 0, state: 8\n",
      "Action prob: [0.88849825 0.11150175], Action: 1, state: 8\n",
      "Action prob: [0.7884978  0.21150224], Action: 0, state: 8\n",
      "Action prob: [0.82217145 0.17782857], Action: 0, state: 8\n",
      "Action prob: [0.8859658  0.11403418], Action: 0, state: 8\n",
      "Action prob: [0.83554983 0.1644501 ], Action: 1, state: 8\n",
      "Action prob: [0.8890563  0.11094373], Action: 0, state: 8\n",
      "Action prob: [0.83674425 0.16325574], Action: 1, state: 8\n",
      "Reward for this episode -92000, loss is 0.09544207360623952\n",
      "Action prob: [0.8502344  0.14976561], Action: 0, state: 0\n",
      "Action prob: [0.84939605 0.15060394], Action: 1, state: 0\n",
      "Action prob: [0.54509616 0.4549038 ], Action: 0, state: 4\n",
      "Action prob: [0.8420167  0.15798338], Action: 0, state: 0\n",
      "Action prob: [0.86515987 0.13484016], Action: 0, state: 0\n",
      "Action prob: [0.841736   0.15826404], Action: 0, state: 1\n",
      "Action prob: [0.8398622  0.16013771], Action: 0, state: 1\n",
      "Action prob: [0.85910773 0.1408923 ], Action: 0, state: 1\n",
      "Action prob: [0.8408295  0.15917052], Action: 0, state: 2\n",
      "Action prob: [0.85460126 0.1453987 ], Action: 0, state: 2\n",
      "Action prob: [0.8454414  0.15455867], Action: 0, state: 2\n",
      "Action prob: [0.85112536 0.14887461], Action: 0, state: 3\n",
      "Action prob: [0.85399514 0.14600492], Action: 0, state: 3\n",
      "Action prob: [0.85793877 0.14206123], Action: 0, state: 3\n",
      "Action prob: [0.8417992 0.1582008], Action: 0, state: 3\n",
      "Action prob: [0.81771743 0.18228255], Action: 0, state: 3\n",
      "Action prob: [0.8457706  0.15422948], Action: 0, state: 3\n",
      "Action prob: [0.797816   0.20218402], Action: 1, state: 8\n",
      "Action prob: [0.86264586 0.13735415], Action: 0, state: 0\n",
      "Action prob: [0.8515041  0.14849594], Action: 0, state: 0\n",
      "Action prob: [0.84286785 0.15713215], Action: 1, state: 1\n",
      "Action prob: [0.54509616 0.4549038 ], Action: 1, state: 5\n",
      "Reward for this episode 11000, loss is 0.03729593006676712\n",
      "Action prob: [0.8458109  0.15418908], Action: 0, state: 0\n",
      "Action prob: [0.83241665 0.16758333], Action: 0, state: 1\n",
      "Action prob: [0.82513005 0.17486997], Action: 0, state: 1\n",
      "Action prob: [0.8371551  0.16284491], Action: 0, state: 2\n",
      "Action prob: [0.8506905 0.1493095], Action: 0, state: 2\n",
      "Action prob: [0.8369414  0.16305852], Action: 1, state: 2\n",
      "Action prob: [0.5439907  0.45600927], Action: 1, state: 6\n",
      "Action prob: [0.83032656 0.16967344], Action: 0, state: 1\n",
      "Action prob: [0.8317359  0.16826409], Action: 1, state: 2\n",
      "Action prob: [0.5439907  0.45600927], Action: 1, state: 6\n",
      "Action prob: [0.8390926  0.16090736], Action: 1, state: 1\n",
      "Action prob: [0.5439907  0.45600927], Action: 0, state: 5\n",
      "Action prob: [0.5439907  0.45600927], Action: 1, state: 5\n",
      "Action prob: [0.83311325 0.16688676], Action: 0, state: 0\n",
      "Action prob: [0.838556   0.16144402], Action: 1, state: 0\n",
      "Action prob: [0.5439907  0.45600927], Action: 0, state: 4\n",
      "Action prob: [0.8340629  0.16593717], Action: 0, state: 0\n",
      "Action prob: [0.8357129  0.16428705], Action: 0, state: 0\n",
      "Action prob: [0.8376756  0.16232443], Action: 1, state: 0\n",
      "Action prob: [0.5439907  0.45600927], Action: 1, state: 4\n",
      "Action prob: [0.83811516 0.1618849 ], Action: 0, state: 0\n",
      "Reward for this episode 10800, loss is -0.26002668806171403\n",
      "Action prob: [0.83887345 0.16112652], Action: 0, state: 0\n",
      "Action prob: [0.8294676  0.17053246], Action: 0, state: 0\n",
      "Action prob: [0.8372884  0.16271159], Action: 0, state: 0\n",
      "Action prob: [0.8326375  0.16736251], Action: 0, state: 0\n",
      "Action prob: [0.8418571  0.15814292], Action: 0, state: 0\n",
      "Action prob: [0.8317231  0.16827686], Action: 0, state: 1\n",
      "Action prob: [0.83471984 0.1652802 ], Action: 0, state: 2\n",
      "Action prob: [0.8318316  0.16816846], Action: 0, state: 2\n",
      "Action prob: [0.82738185 0.17261814], Action: 0, state: 2\n",
      "Action prob: [0.82844615 0.17155385], Action: 0, state: 2\n",
      "Action prob: [0.83582705 0.16417295], Action: 0, state: 2\n",
      "Action prob: [0.8256018  0.17439815], Action: 0, state: 3\n",
      "Action prob: [0.83855355 0.16144647], Action: 0, state: 3\n",
      "Action prob: [0.83694637 0.16305359], Action: 0, state: 3\n",
      "Action prob: [0.82821614 0.1717838 ], Action: 0, state: 3\n",
      "Action prob: [0.83012587 0.16987406], Action: 0, state: 3\n",
      "Action prob: [0.8368208 0.1631792], Action: 0, state: 3\n",
      "Action prob: [0.82719946 0.17280053], Action: 1, state: 3\n",
      "Action prob: [0.5452149  0.45478514], Action: 0, state: 7\n",
      "Action prob: [0.5452149  0.45478514], Action: 1, state: 7\n",
      "Action prob: [0.83369935 0.16630062], Action: 0, state: 2\n",
      "Action prob: [0.83020264 0.16979738], Action: 0, state: 2\n",
      "Action prob: [0.8360106  0.16398944], Action: 0, state: 2\n",
      "Action prob: [0.83181626 0.16818379], Action: 0, state: 3\n",
      "Action prob: [0.8104898  0.18951026], Action: 0, state: 8\n",
      "Action prob: [0.8480943  0.15190575], Action: 1, state: 8\n",
      "Reward for this episode 9300, loss is -0.10855755040226804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [0.8342569  0.16574317], Action: 1, state: 0\n",
      "Action prob: [0.54688823 0.45311183], Action: 0, state: 4\n",
      "Action prob: [0.8323728  0.16762722], Action: 1, state: 0\n",
      "Action prob: [0.54688823 0.45311183], Action: 1, state: 4\n",
      "Action prob: [0.54688823 0.45311183], Action: 1, state: 4\n",
      "Action prob: [0.8227956  0.17720436], Action: 0, state: 0\n",
      "Action prob: [0.8234804  0.17651962], Action: 1, state: 0\n",
      "Action prob: [0.54688823 0.45311183], Action: 0, state: 4\n",
      "Action prob: [0.54688823 0.45311183], Action: 1, state: 4\n",
      "Action prob: [0.8289602  0.17103982], Action: 0, state: 0\n",
      "Action prob: [0.82933664 0.17066336], Action: 1, state: 1\n",
      "Action prob: [0.54688823 0.45311183], Action: 0, state: 5\n",
      "Action prob: [0.83831805 0.16168192], Action: 0, state: 0\n",
      "Action prob: [0.8362256  0.16377437], Action: 0, state: 0\n",
      "Action prob: [0.83145684 0.16854316], Action: 0, state: 1\n",
      "Action prob: [0.8364826  0.16351742], Action: 0, state: 2\n",
      "Action prob: [0.8356802 0.1643198], Action: 0, state: 2\n",
      "Action prob: [0.83001214 0.16998784], Action: 1, state: 2\n",
      "Action prob: [0.54688823 0.45311183], Action: 0, state: 6\n",
      "Action prob: [0.54688823 0.45311183], Action: 0, state: 6\n",
      "Action prob: [0.8270265  0.17297357], Action: 1, state: 1\n",
      "Action prob: [0.54688823 0.45311183], Action: 0, state: 5\n",
      "Action prob: [0.54688823 0.45311183], Action: 1, state: 5\n",
      "Reward for this episode 7100, loss is 0.029391540702191885\n",
      "Action prob: [0.82258373 0.17741622], Action: 0, state: 0\n",
      "Action prob: [0.8295086  0.17049138], Action: 0, state: 1\n",
      "Action prob: [0.82469463 0.1753054 ], Action: 0, state: 1\n",
      "Action prob: [0.8262281 0.1737719], Action: 0, state: 2\n",
      "Action prob: [0.83275956 0.16724041], Action: 0, state: 2\n",
      "Action prob: [0.8264949  0.17350513], Action: 1, state: 2\n",
      "Action prob: [0.5446861  0.45531395], Action: 0, state: 6\n",
      "Action prob: [0.8120822  0.18791789], Action: 0, state: 1\n",
      "Action prob: [0.8269443 0.1730557], Action: 1, state: 2\n",
      "Action prob: [0.5446861  0.45531395], Action: 0, state: 6\n",
      "Action prob: [0.82572323 0.17427681], Action: 0, state: 1\n",
      "Action prob: [0.8312976  0.16870242], Action: 0, state: 1\n",
      "Action prob: [0.8301742 0.1698258], Action: 0, state: 1\n",
      "Action prob: [0.82925904 0.17074098], Action: 0, state: 1\n",
      "Action prob: [0.83358246 0.1664175 ], Action: 1, state: 1\n",
      "Action prob: [0.5446861  0.45531395], Action: 1, state: 5\n",
      "Action prob: [0.5446861  0.45531395], Action: 1, state: 5\n",
      "Action prob: [0.5446861  0.45531395], Action: 0, state: 5\n",
      "Action prob: [0.5446861  0.45531395], Action: 1, state: 5\n",
      "Action prob: [0.5446861  0.45531395], Action: 1, state: 5\n",
      "Action prob: [0.825895   0.17410505], Action: 0, state: 0\n",
      "Reward for this episode 8900, loss is -0.18493055928035798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-78-d3c55bf3464c>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  actions = np.array(results[1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "machine1 = Machine_env()\n",
    "pol = policy_estimator(machine1)\n",
    "\n",
    "#Parameters\n",
    "episodes = 100\n",
    "gamma = 0.8\n",
    "lr= 0.01\n",
    "entropy_coeff = 0.01\n",
    "\n",
    "\n",
    "#writer = SummaryWriter(f\"runs/entropy/lr_{lr}gamma_{gamma}episode_{episodes}_mu_{mu0}_entropy_reg_{entropy_coeff}\")\n",
    "\n",
    "results = reinforce_entropy_regularised(machine1,pol,episodes,batchsize,gamma,lr,entropy_coeff)\n",
    "rewards = results[0]\n",
    "actions = np.array(results[1])\n",
    "states = results[2]\n",
    "\n",
    "episode = [i for i in range(episodes)]\n",
    "\n",
    "#Moving average we will use a window size of 50\n",
    "\n",
    "moving_averages = []\n",
    "window_size = 10\n",
    "\n",
    "df = pd.DataFrame(rewards,columns = ['r'])\n",
    "moving_ave = df.r.rolling(window_size,min_periods=1).mean().values\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.plot(episode,rewards,label = 'Episodic Reward')\n",
    "plt.plot(episode,moving_ave,label = f'Moving Average Window {window_size}')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Rewards')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Case"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class policy_estimator(nn.Module): #neural network\n",
    "    def __init__(self, env):\n",
    "        super(policy_estimator, self).__init__()\n",
    "        self.n_inputs = env.observation_space\n",
    "        self.n_outputs = len(env.action_space)\n",
    "        \n",
    "        self.layer1 = nn.Linear(env.observation_space,128)\n",
    "        \n",
    "        self.layer2 = nn.Linear(128,len(env.action_space))\n",
    "        \n",
    "            \n",
    "    \n",
    "    def forward(self, x):#prediction is raw value\n",
    "        x = torch.FloatTensor(x)\n",
    "    \n",
    "        x = self.layer1(x)\n",
    "        x  = F.relu(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        return F.softmax(x,dim = -1)\n",
    "\n",
    "class StateValueNetwork(nn.Module):\n",
    "    \n",
    "    #Takes in state\n",
    "    def __init__(self, observation_space):\n",
    "        super(StateValueNetwork, self).__init__()\n",
    "        \n",
    "        self.input_layer = nn.Linear(observation_space, 128)\n",
    "        self.output_layer = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #input layer\n",
    "        x = self.input_layer(x)\n",
    "        \n",
    "        #activiation relu\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #get state value\n",
    "        state_value = self.output_layer(x)\n",
    "        \n",
    "        return state_value\n",
    "    \n",
    "def train_value(G, state_vals, optimizer):\n",
    "    ''' Update state-value network parameters\n",
    "    Args:\n",
    "    - G (Array): trajectory of cumulative discounted rewards \n",
    "    - state_vals (Array): trajectory of predicted state-value at each step\n",
    "    - optimizer (Pytorch optimizer): optimizer to update state-value network parameters\n",
    "    '''\n",
    "    \n",
    "    G = G.to(torch.float32)\n",
    "    state_vals = state_vals.to(torch.float32)\n",
    "    #calculate MSE loss\n",
    "    val_loss = F.mse_loss(state_vals, G)\n",
    "        \n",
    "    #Backpropagate\n",
    "    optimizer.zero_grad()\n",
    "    val_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "def stack_state_value(states,stateval_network): #input is a list of observations/states that will be used to train the nn for statevalue network\n",
    "    state_vals = []\n",
    "    for state in states:\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "        state_vals.append(stateval_network(state))\n",
    "    return torch.stack(state_vals).squeeze()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce_baseline(machine,baseline_net,policy_estimator,num_episodes,gamma,lr): #Learning algo\n",
    "    # Set up lists to hold results\n",
    "    # Set up lists to hold results\n",
    "    total_rewards = [] #Total actual reward for each episode\n",
    "    batch_rewards = []  #Discounted expected future rewards for each batch\n",
    "    batch_actions = []\n",
    "    batch_observation = []\n",
    "    state_seq = []\n",
    "    \n",
    "    # Define optimizer\n",
    "    optimizer = torch.optim.Adam(policy_estimator.parameters(),lr=lr)\n",
    "    state_val_optimizer = torch.optim.Adam(baseline_net.parameters(),lr=0.01)\n",
    "    \n",
    "    action_space = machine.action_space\n",
    "    \n",
    "    for ep in range(num_episodes):\n",
    "        machine.reset()\n",
    "        observation = []\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        \n",
    "        while(not machine.done):\n",
    "            obs = machine.sensor(machine.state).tolist() #observation\n",
    "            \n",
    "            action_probs = policy_estimator(obs).detach().numpy() #convert to numpy and get action prob\n",
    "            print(action_probs)\n",
    "            action = np.random.choice(action_space, p=action_probs) #select weighted actions based on NN output prob\n",
    "            print(f\"Action prob: {action_probs}, Action: {action}, state: {machine.state}\")\n",
    "            \n",
    "            r = machine.step(action) #receive reward and update machine to the next state after doing the sampled action\n",
    "            \n",
    "            observation.append(obs)\n",
    "            rewards.append(r)\n",
    "            actions.append(action)\n",
    "        \n",
    "        discount_r = normalized_discount_reward(rewards,gamma) #normalised future rewards\n",
    "        \n",
    "        total_rewards.append(sum(rewards)) #Cumulative reward for this episode\n",
    "        \n",
    "        #After batch complete time,store the parameters\n",
    "        batch_rewards.append(discount_r)\n",
    "        batch_observation.append(observation)\n",
    "        batch_actions.append(actions)\n",
    "        state_seq.append(machine.state_seq)\n",
    "        \n",
    "        print(actions)\n",
    "        obs_tensor = torch.FloatTensor(observation)\n",
    "        action_tensor = torch.LongTensor(actions)\n",
    "        reward_tensor = torch.from_numpy(np.array(discount_r).copy()) #discounted reward G\n",
    "        \n",
    "        #calculate state values \n",
    "        state_value_tensor = stack_state_value(np.array(observation),baseline_net)\n",
    "        \n",
    "        #train state value network\n",
    "        train_value(reward_tensor,state_value_tensor,state_val_optimizer)\n",
    "        \n",
    "        #calculate delta or advantage \n",
    "        deltas = [gt - val for gt, val in zip(reward_tensor, state_value_tensor)]\n",
    "        deltas = torch.tensor(deltas)\n",
    "\n",
    "        \n",
    "        #update policy\n",
    "        logprob = torch.log(policy_estimator(obs_tensor))\n",
    "#         print(logprob)\n",
    "#         print(action_tensor)\n",
    "        #print(logprob[np.arange(len(action_tensor)), action_tensor])\n",
    "        selected_logprobs = deltas * logprob[np.arange(len(action_tensor)), action_tensor]\n",
    "        print(selected_logprobs)\n",
    "        \n",
    "        \n",
    "        loss = -selected_logprobs.mean()\n",
    "        \n",
    "        print(f\"Reward for this episode {total_rewards[-1]}, loss is {loss}\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        # Apply gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Tensorboard params\n",
    "#         writer.add_scalar(\"Loss\", loss, ep)\n",
    "#         writer.add_scalar('Rewards',sum(rewards),ep)\n",
    "#         for name, weight in policy_estimator.named_parameters():\n",
    "#             try:\n",
    "#                 writer.add_histogram(name,weight, ep)\n",
    "#             except:\n",
    "#                 continue\n",
    "#             if weight.grad != None:\n",
    "#                 writer.add_histogram(f\"{name}.grad\",weight.grad, ep)\n",
    "    \n",
    "#     writer.add_graph(policy_estimator,torch.FloatTensor(machine.sensor(0))) #draw graph\n",
    "#     writer.flush()\n",
    "#     writer.close()\n",
    "    \n",
    "    return (total_rewards,batch_actions,state_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\overl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator GaussianMixture from version 0.20.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1000, 1: 900, 2: 800, 3: 500, 4: -500, 5: -500, 6: -500, 7: -500, 8: -3000, 9: -1000}\n",
      "[0.4611752 0.5388248]\n",
      "Action prob: [0.4611752 0.5388248], Action: 1, state: 0\n",
      "[0.39640832 0.6035917 ]\n",
      "Action prob: [0.39640832 0.6035917 ], Action: 0, state: 4\n",
      "[0.4592543  0.54074574]\n",
      "Action prob: [0.4592543  0.54074574], Action: 1, state: 0\n",
      "[0.39640832 0.6035917 ]\n",
      "Action prob: [0.39640832 0.6035917 ], Action: 0, state: 4\n",
      "[0.45694298 0.5430571 ]\n",
      "Action prob: [0.45694298 0.5430571 ], Action: 0, state: 0\n",
      "[0.45458794 0.54541206]\n",
      "Action prob: [0.45458794 0.54541206], Action: 0, state: 1\n",
      "[0.4594201  0.54057986]\n",
      "Action prob: [0.4594201  0.54057986], Action: 0, state: 2\n",
      "[0.45798266 0.54201734]\n",
      "Action prob: [0.45798266 0.54201734], Action: 1, state: 2\n",
      "[0.39640832 0.6035917 ]\n",
      "Action prob: [0.39640832 0.6035917 ], Action: 1, state: 6\n",
      "[0.45892373 0.54107624]\n",
      "Action prob: [0.45892373 0.54107624], Action: 0, state: 1\n",
      "[0.45994315 0.54005694]\n",
      "Action prob: [0.45994315 0.54005694], Action: 0, state: 1\n",
      "[0.458051 0.541949]\n",
      "Action prob: [0.458051 0.541949], Action: 0, state: 1\n",
      "[0.4596717 0.5403283]\n",
      "Action prob: [0.4596717 0.5403283], Action: 1, state: 1\n",
      "[0.39640832 0.6035917 ]\n",
      "Action prob: [0.39640832 0.6035917 ], Action: 1, state: 5\n",
      "[0.4580725 0.5419275]\n",
      "Action prob: [0.4580725 0.5419275], Action: 1, state: 0\n",
      "[0.39640832 0.6035917 ]\n",
      "Action prob: [0.39640832 0.6035917 ], Action: 1, state: 4\n",
      "[0.39640832 0.6035917 ]\n",
      "Action prob: [0.39640832 0.6035917 ], Action: 1, state: 4\n",
      "[0.39640832 0.6035917 ]\n",
      "Action prob: [0.39640832 0.6035917 ], Action: 0, state: 4\n",
      "[0.39640832 0.6035917 ]\n",
      "Action prob: [0.39640832 0.6035917 ], Action: 0, state: 4\n",
      "[0.4580131 0.5419868]\n",
      "Action prob: [0.4580131 0.5419868], Action: 1, state: 0\n",
      "[0.39640832 0.6035917 ]\n",
      "Action prob: [0.39640832 0.6035917 ], Action: 0, state: 4\n",
      "[0.39640832 0.6035917 ]\n",
      "Action prob: [0.39640832 0.6035917 ], Action: 1, state: 4\n",
      "[0.39640832 0.6035917 ]\n",
      "Action prob: [0.39640832 0.6035917 ], Action: 1, state: 4\n",
      "[0.39640832 0.6035917 ]\n",
      "Action prob: [0.39640832 0.6035917 ], Action: 1, state: 4\n",
      "[1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1]\n",
      "tensor([-1.4111, -2.1821, -1.2059, -1.8048, -1.3225, -0.9548, -0.6297, -0.2908,\n",
      "        -0.1621, -0.2678, -0.0454,  0.1589,  0.2628,  0.3332,  0.3225,  0.3914,\n",
      "         0.3486,  0.5682,  0.5047,  0.2012,  0.5676,  0.2844,  0.2616,  0.2412],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode 5100, loss is 0.24295961309076095\n",
      "[0.99033886 0.00966112]\n",
      "Action prob: [0.99033886 0.00966112], Action: 0, state: 0\n",
      "[0.99021333 0.00978673]\n",
      "Action prob: [0.99021333 0.00978673], Action: 0, state: 0\n",
      "[0.9901065  0.00989348]\n",
      "Action prob: [0.9901065  0.00989348], Action: 0, state: 0\n",
      "[0.98892725 0.01107281]\n",
      "Action prob: [0.98892725 0.01107281], Action: 0, state: 0\n",
      "[0.98872197 0.01127802]\n",
      "Action prob: [0.98872197 0.01127802], Action: 0, state: 0\n",
      "[0.9900197  0.00998031]\n",
      "Action prob: [0.9900197  0.00998031], Action: 0, state: 1\n",
      "[0.98985296 0.01014703]\n",
      "Action prob: [0.98985296 0.01014703], Action: 0, state: 2\n",
      "[0.98944175 0.01055821]\n",
      "Action prob: [0.98944175 0.01055821], Action: 0, state: 3\n",
      "[0.9900401  0.00995983]\n",
      "Action prob: [0.9900401  0.00995983], Action: 0, state: 3\n",
      "[0.98889136 0.01110872]\n",
      "Action prob: [0.98889136 0.01110872], Action: 0, state: 3\n",
      "[0.9905027  0.00949725]\n",
      "Action prob: [0.9905027  0.00949725], Action: 0, state: 3\n",
      "[0.9901522  0.00984775]\n",
      "Action prob: [0.9901522  0.00984775], Action: 0, state: 3\n",
      "[0.990131 0.009869]\n",
      "Action prob: [0.990131 0.009869], Action: 0, state: 3\n",
      "[0.98927015 0.01072983]\n",
      "Action prob: [0.98927015 0.01072983], Action: 0, state: 3\n",
      "[0.99129945 0.00870051]\n",
      "Action prob: [0.99129945 0.00870051], Action: 0, state: 8\n",
      "[0.9918806  0.00811939]\n",
      "Action prob: [0.9918806  0.00811939], Action: 0, state: 8\n",
      "[0.9921882  0.00781177]\n",
      "Action prob: [0.9921882  0.00781177], Action: 0, state: 8\n",
      "[0.9926979  0.00730207]\n",
      "Action prob: [0.9926979  0.00730207], Action: 0, state: 8\n",
      "[0.9890744  0.01092557]\n",
      "Action prob: [0.9890744  0.01092557], Action: 0, state: 8\n",
      "[0.9923098  0.00769026]\n",
      "Action prob: [0.9923098  0.00769026], Action: 0, state: 8\n",
      "[0.9912374  0.00876264]\n",
      "Action prob: [0.9912374  0.00876264], Action: 0, state: 8\n",
      "[0.9926795  0.00732051]\n",
      "Action prob: [0.9926795  0.00732051], Action: 0, state: 8\n",
      "[0.99209154 0.00790846]\n",
      "Action prob: [0.99209154 0.00790846], Action: 0, state: 8\n",
      "[0.9922575  0.00774257]\n",
      "Action prob: [0.9922575  0.00774257], Action: 0, state: 8\n",
      "[0.9916698  0.00833017]\n",
      "Action prob: [0.9916698  0.00833017], Action: 0, state: 8\n",
      "[0.98975325 0.01024673]\n",
      "Action prob: [0.98975325 0.01024673], Action: 0, state: 8\n",
      "[0.99137294 0.00862708]\n",
      "Action prob: [0.99137294 0.00862708], Action: 0, state: 8\n",
      "[0.991659   0.00834099]\n",
      "Action prob: [0.991659   0.00834099], Action: 0, state: 8\n",
      "[0.9907217  0.00927826]\n",
      "Action prob: [0.9907217  0.00927826], Action: 0, state: 8\n",
      "[0.99312043 0.00687961]\n",
      "Action prob: [0.99312043 0.00687961], Action: 0, state: 8\n",
      "[0.99408025 0.0059197 ]\n",
      "Action prob: [0.99408025 0.0059197 ], Action: 0, state: 8\n",
      "[0.98869085 0.01130914]\n",
      "Action prob: [0.98869085 0.01130914], Action: 0, state: 8\n",
      "[0.9888679  0.01113208]\n",
      "Action prob: [0.9888679  0.01113208], Action: 0, state: 8\n",
      "[0.99194616 0.00805389]\n",
      "Action prob: [0.99194616 0.00805389], Action: 0, state: 8\n",
      "[0.98951274 0.01048732]\n",
      "Action prob: [0.98951274 0.01048732], Action: 0, state: 8\n",
      "[0.9918059  0.00819405]\n",
      "Action prob: [0.9918059  0.00819405], Action: 0, state: 8\n",
      "[0.9892201  0.01077996]\n",
      "Action prob: [0.9892201  0.01077996], Action: 0, state: 8\n",
      "[0.9928706  0.00712939]\n",
      "Action prob: [0.9928706  0.00712939], Action: 0, state: 8\n",
      "[0.9906702  0.00932984]\n",
      "Action prob: [0.9906702  0.00932984], Action: 0, state: 8\n",
      "[0.98966646 0.01033357]\n",
      "Action prob: [0.98966646 0.01033357], Action: 0, state: 8\n",
      "[0.99399453 0.00600549]\n",
      "Action prob: [0.99399453 0.00600549], Action: 0, state: 8\n",
      "[0.99247473 0.0075253 ]\n",
      "Action prob: [0.99247473 0.0075253 ], Action: 0, state: 8\n",
      "[0.99139106 0.00860887]\n",
      "Action prob: [0.99139106 0.00860887], Action: 0, state: 8\n",
      "[0.99125767 0.00874234]\n",
      "Action prob: [0.99125767 0.00874234], Action: 0, state: 8\n",
      "[0.9883852  0.01161476]\n",
      "Action prob: [0.9883852  0.01161476], Action: 0, state: 8\n",
      "[0.9896891 0.0103109]\n",
      "Action prob: [0.9896891 0.0103109], Action: 0, state: 8\n",
      "[0.9930247  0.00697523]\n",
      "Action prob: [0.9930247  0.00697523], Action: 0, state: 8\n",
      "[0.99093366 0.00906642]\n",
      "Action prob: [0.99093366 0.00906642], Action: 0, state: 8\n",
      "[0.99158806 0.00841196]\n",
      "Action prob: [0.99158806 0.00841196], Action: 0, state: 8\n",
      "[0.991882   0.00811796]\n",
      "Action prob: [0.991882   0.00811796], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-6.1443e-03, -2.2587e-03,  1.1903e-03,  4.9769e-03,  8.3630e-03,\n",
      "         9.9614e-03,  1.1955e-02,  1.3444e-02,  1.3634e-02,  1.6610e-02,\n",
      "         1.4681e-02,  1.5771e-02,  1.6535e-02,  1.8608e-02,  1.3027e-02,\n",
      "         9.2565e-03,  7.0203e-03,  5.1483e-03,  5.8219e-03,  2.4757e-03,\n",
      "         1.0944e-03, -6.0715e-06, -8.8928e-04, -1.3667e-03, -3.1268e-03,\n",
      "        -4.0402e-03, -4.3943e-03, -5.2601e-03, -6.5277e-03, -5.0258e-03,\n",
      "        -4.6904e-03, -9.2961e-03, -9.6352e-03, -7.6982e-03, -9.7709e-03,\n",
      "        -8.3652e-03, -1.0820e-02, -7.5490e-03, -1.0369e-02, -1.1205e-02,\n",
      "        -6.7576e-03, -8.6054e-03, -9.6876e-03, -1.0538e-02, -1.3570e-02,\n",
      "        -1.2028e-02, -8.3835e-03, -1.1237e-02, -1.0420e-02, -9.5305e-03],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -101800, loss is 0.0007924790791256304\n",
      "[9.9985135e-01 1.4866544e-04]\n",
      "Action prob: [9.9985135e-01 1.4866544e-04], Action: 0, state: 0\n",
      "[9.998839e-01 1.161022e-04]\n",
      "Action prob: [9.998839e-01 1.161022e-04], Action: 0, state: 1\n",
      "[9.9984908e-01 1.5095022e-04]\n",
      "Action prob: [9.9984908e-01 1.5095022e-04], Action: 0, state: 1\n",
      "[9.9985671e-01 1.4322162e-04]\n",
      "Action prob: [9.9985671e-01 1.4322162e-04], Action: 0, state: 1\n",
      "[9.9985087e-01 1.4916669e-04]\n",
      "Action prob: [9.9985087e-01 1.4916669e-04], Action: 0, state: 1\n",
      "[9.9985027e-01 1.4973414e-04]\n",
      "Action prob: [9.9985027e-01 1.4973414e-04], Action: 0, state: 1\n",
      "[9.9988997e-01 1.1002943e-04]\n",
      "Action prob: [9.9988997e-01 1.1002943e-04], Action: 0, state: 2\n",
      "[9.9983215e-01 1.6786756e-04]\n",
      "Action prob: [9.9983215e-01 1.6786756e-04], Action: 0, state: 2\n",
      "[9.9985099e-01 1.4894652e-04]\n",
      "Action prob: [9.9985099e-01 1.4894652e-04], Action: 0, state: 3\n",
      "[9.9992836e-01 7.1614675e-05]\n",
      "Action prob: [9.9992836e-01 7.1614675e-05], Action: 0, state: 8\n",
      "[9.999621e-01 3.785635e-05]\n",
      "Action prob: [9.999621e-01 3.785635e-05], Action: 0, state: 8\n",
      "[9.9993026e-01 6.9791262e-05]\n",
      "Action prob: [9.9993026e-01 6.9791262e-05], Action: 0, state: 8\n",
      "[9.9992716e-01 7.2793155e-05]\n",
      "Action prob: [9.9992716e-01 7.2793155e-05], Action: 0, state: 8\n",
      "[9.9992645e-01 7.3529824e-05]\n",
      "Action prob: [9.9992645e-01 7.3529824e-05], Action: 0, state: 8\n",
      "[9.9983239e-01 1.6753112e-04]\n",
      "Action prob: [9.9983239e-01 1.6753112e-04], Action: 0, state: 8\n",
      "[9.9991989e-01 8.0082194e-05]\n",
      "Action prob: [9.9991989e-01 8.0082194e-05], Action: 0, state: 8\n",
      "[9.999348e-01 6.524072e-05]\n",
      "Action prob: [9.999348e-01 6.524072e-05], Action: 0, state: 8\n",
      "[9.9993980e-01 6.0236453e-05]\n",
      "Action prob: [9.9993980e-01 6.0236453e-05], Action: 0, state: 8\n",
      "[9.9981135e-01 1.8873178e-04]\n",
      "Action prob: [9.9981135e-01 1.8873178e-04], Action: 0, state: 8\n",
      "[9.9982738e-01 1.7258455e-04]\n",
      "Action prob: [9.9982738e-01 1.7258455e-04], Action: 0, state: 8\n",
      "[9.9984527e-01 1.5467395e-04]\n",
      "Action prob: [9.9984527e-01 1.5467395e-04], Action: 0, state: 8\n",
      "[9.9992526e-01 7.4705538e-05]\n",
      "Action prob: [9.9992526e-01 7.4705538e-05], Action: 0, state: 8\n",
      "[9.9981922e-01 1.8084282e-04]\n",
      "Action prob: [9.9981922e-01 1.8084282e-04], Action: 0, state: 8\n",
      "[9.9981993e-01 1.8005376e-04]\n",
      "Action prob: [9.9981993e-01 1.8005376e-04], Action: 0, state: 8\n",
      "[9.9989522e-01 1.0481529e-04]\n",
      "Action prob: [9.9989522e-01 1.0481529e-04], Action: 0, state: 8\n",
      "[9.9992776e-01 7.2267503e-05]\n",
      "Action prob: [9.9992776e-01 7.2267503e-05], Action: 0, state: 8\n",
      "[9.9992204e-01 7.7920056e-05]\n",
      "Action prob: [9.9992204e-01 7.7920056e-05], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9991655e-01 8.3450905e-05]\n",
      "Action prob: [9.9991655e-01 8.3450905e-05], Action: 0, state: 8\n",
      "[9.9994040e-01 5.9552316e-05]\n",
      "Action prob: [9.9994040e-01 5.9552316e-05], Action: 0, state: 8\n",
      "[9.9979645e-01 2.0351894e-04]\n",
      "Action prob: [9.9979645e-01 2.0351894e-04], Action: 0, state: 8\n",
      "[9.9980384e-01 1.9621410e-04]\n",
      "Action prob: [9.9980384e-01 1.9621410e-04], Action: 0, state: 8\n",
      "[9.9997175e-01 2.8253173e-05]\n",
      "Action prob: [9.9997175e-01 2.8253173e-05], Action: 0, state: 8\n",
      "[9.9996686e-01 3.3195833e-05]\n",
      "Action prob: [9.9996686e-01 3.3195833e-05], Action: 0, state: 8\n",
      "[9.9979001e-01 2.1005266e-04]\n",
      "Action prob: [9.9979001e-01 2.1005266e-04], Action: 0, state: 8\n",
      "[9.9981505e-01 1.8496790e-04]\n",
      "Action prob: [9.9981505e-01 1.8496790e-04], Action: 0, state: 8\n",
      "[9.9994087e-01 5.9089303e-05]\n",
      "Action prob: [9.9994087e-01 5.9089303e-05], Action: 0, state: 8\n",
      "[9.9979502e-01 2.0496937e-04]\n",
      "Action prob: [9.9979502e-01 2.0496937e-04], Action: 0, state: 8\n",
      "[9.9981171e-01 1.8827092e-04]\n",
      "Action prob: [9.9981171e-01 1.8827092e-04], Action: 0, state: 8\n",
      "[9.999249e-01 7.507211e-05]\n",
      "Action prob: [9.999249e-01 7.507211e-05], Action: 0, state: 8\n",
      "[9.999192e-01 8.080851e-05]\n",
      "Action prob: [9.999192e-01 8.080851e-05], Action: 0, state: 8\n",
      "[9.9983132e-01 1.6867768e-04]\n",
      "Action prob: [9.9983132e-01 1.6867768e-04], Action: 0, state: 8\n",
      "[9.9991167e-01 8.8348483e-05]\n",
      "Action prob: [9.9991167e-01 8.8348483e-05], Action: 0, state: 8\n",
      "[9.9982041e-01 1.7965607e-04]\n",
      "Action prob: [9.9982041e-01 1.7965607e-04], Action: 0, state: 8\n",
      "[9.9993932e-01 6.0714596e-05]\n",
      "Action prob: [9.9993932e-01 6.0714596e-05], Action: 0, state: 8\n",
      "[9.99899268e-01 1.00673285e-04]\n",
      "Action prob: [9.99899268e-01 1.00673285e-04], Action: 0, state: 8\n",
      "[9.9983692e-01 1.6308359e-04]\n",
      "Action prob: [9.9983692e-01 1.6308359e-04], Action: 0, state: 8\n",
      "[9.998109e-01 1.891979e-04]\n",
      "Action prob: [9.998109e-01 1.891979e-04], Action: 0, state: 8\n",
      "[9.999294e-01 7.051072e-05]\n",
      "Action prob: [9.999294e-01 7.051072e-05], Action: 0, state: 8\n",
      "[9.9991703e-01 8.2992054e-05]\n",
      "Action prob: [9.9991703e-01 8.2992054e-05], Action: 0, state: 8\n",
      "[9.999242e-01 7.577407e-05]\n",
      "Action prob: [9.999242e-01 7.577407e-05], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 1.4928e-04,  1.4133e-04,  2.1180e-04,  2.2899e-04,  2.5917e-04,\n",
      "         2.8094e-04,  2.2027e-04,  3.5149e-04,  3.1834e-04,  1.3501e-04,\n",
      "         6.1899e-05,  9.3316e-05,  8.3005e-05,  6.7998e-05,  1.2663e-04,\n",
      "         4.5546e-05,  3.4171e-05,  1.9372e-05,  3.6307e-05,  1.5431e-05,\n",
      "         8.4181e-07, -4.8963e-06, -3.1862e-05, -3.7047e-05, -3.2990e-05,\n",
      "        -2.5096e-05, -3.3182e-05, -3.8193e-05, -2.7019e-05, -1.1016e-04,\n",
      "        -1.1213e-04, -1.6457e-05, -2.0525e-05, -1.3733e-04, -1.2396e-04,\n",
      "        -4.0576e-05, -1.4665e-04, -1.3646e-04, -5.6911e-05, -5.6964e-05,\n",
      "        -1.2735e-04, -7.0173e-05, -1.4006e-04, -4.6858e-05, -8.2794e-05,\n",
      "        -1.3037e-04, -1.5464e-04, -5.8797e-05, -6.7871e-05, -6.1267e-05],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -119400, loss is -1.5050745040687083e-05\n",
      "[9.999975e-01 2.517210e-06]\n",
      "Action prob: [9.999975e-01 2.517210e-06], Action: 0, state: 0\n",
      "[9.9999654e-01 3.4547136e-06]\n",
      "Action prob: [9.9999654e-01 3.4547136e-06], Action: 0, state: 0\n",
      "[9.9999690e-01 3.0411554e-06]\n",
      "Action prob: [9.9999690e-01 3.0411554e-06], Action: 0, state: 0\n",
      "[9.9999642e-01 3.6136094e-06]\n",
      "Action prob: [9.9999642e-01 3.6136094e-06], Action: 0, state: 0\n",
      "[9.9999738e-01 2.6476587e-06]\n",
      "Action prob: [9.9999738e-01 2.6476587e-06], Action: 0, state: 0\n",
      "[9.9999726e-01 2.7682072e-06]\n",
      "Action prob: [9.9999726e-01 2.7682072e-06], Action: 0, state: 1\n",
      "[9.9999809e-01 1.9132958e-06]\n",
      "Action prob: [9.9999809e-01 1.9132958e-06], Action: 0, state: 1\n",
      "[9.999968e-01 3.202691e-06]\n",
      "Action prob: [9.999968e-01 3.202691e-06], Action: 0, state: 2\n",
      "[9.9999797e-01 2.0658756e-06]\n",
      "Action prob: [9.9999797e-01 2.0658756e-06], Action: 0, state: 2\n",
      "[9.9999785e-01 2.1148621e-06]\n",
      "Action prob: [9.9999785e-01 2.1148621e-06], Action: 0, state: 2\n",
      "[9.9999774e-01 2.2246786e-06]\n",
      "Action prob: [9.9999774e-01 2.2246786e-06], Action: 0, state: 3\n",
      "[9.9999738e-01 2.5664167e-06]\n",
      "Action prob: [9.9999738e-01 2.5664167e-06], Action: 0, state: 3\n",
      "[9.9999857e-01 1.4605988e-06]\n",
      "Action prob: [9.9999857e-01 1.4605988e-06], Action: 0, state: 3\n",
      "[9.9999917e-01 8.3639384e-07]\n",
      "Action prob: [9.9999917e-01 8.3639384e-07], Action: 0, state: 8\n",
      "[9.9999452e-01 5.4624425e-06]\n",
      "Action prob: [9.9999452e-01 5.4624425e-06], Action: 0, state: 8\n",
      "[9.9999523e-01 4.7824210e-06]\n",
      "Action prob: [9.9999523e-01 4.7824210e-06], Action: 0, state: 8\n",
      "[9.9999905e-01 9.4069128e-07]\n",
      "Action prob: [9.9999905e-01 9.4069128e-07], Action: 0, state: 8\n",
      "[9.9999905e-01 9.5788812e-07]\n",
      "Action prob: [9.9999905e-01 9.5788812e-07], Action: 0, state: 8\n",
      "[9.9999928e-01 6.6303363e-07]\n",
      "Action prob: [9.9999928e-01 6.6303363e-07], Action: 0, state: 8\n",
      "[9.9999928e-01 7.6172546e-07]\n",
      "Action prob: [9.9999928e-01 7.6172546e-07], Action: 0, state: 8\n",
      "[9.9999869e-01 1.3459081e-06]\n",
      "Action prob: [9.9999869e-01 1.3459081e-06], Action: 0, state: 8\n",
      "[9.9999952e-01 4.7263842e-07]\n",
      "Action prob: [9.9999952e-01 4.7263842e-07], Action: 0, state: 8\n",
      "[9.999964e-01 3.635476e-06]\n",
      "Action prob: [9.999964e-01 3.635476e-06], Action: 0, state: 8\n",
      "[9.9999607e-01 3.9465040e-06]\n",
      "Action prob: [9.9999607e-01 3.9465040e-06], Action: 0, state: 8\n",
      "[9.9999917e-01 7.8685156e-07]\n",
      "Action prob: [9.9999917e-01 7.8685156e-07], Action: 0, state: 8\n",
      "[9.9999917e-01 8.3398680e-07]\n",
      "Action prob: [9.9999917e-01 8.3398680e-07], Action: 0, state: 8\n",
      "[9.999958e-01 4.191730e-06]\n",
      "Action prob: [9.999958e-01 4.191730e-06], Action: 0, state: 8\n",
      "[9.9999964e-01 3.2815262e-07]\n",
      "Action prob: [9.9999964e-01 3.2815262e-07], Action: 0, state: 8\n",
      "[9.9999917e-01 8.1013980e-07]\n",
      "Action prob: [9.9999917e-01 8.1013980e-07], Action: 0, state: 8\n",
      "[9.9999905e-01 9.8089936e-07]\n",
      "Action prob: [9.9999905e-01 9.8089936e-07], Action: 0, state: 8\n",
      "[9.9999785e-01 2.1562059e-06]\n",
      "Action prob: [9.9999785e-01 2.1562059e-06], Action: 0, state: 8\n",
      "[9.9999928e-01 7.1472505e-07]\n",
      "Action prob: [9.9999928e-01 7.1472505e-07], Action: 0, state: 8\n",
      "[9.9999976e-01 2.3331883e-07]\n",
      "Action prob: [9.9999976e-01 2.3331883e-07], Action: 0, state: 8\n",
      "[9.9999547e-01 4.5518750e-06]\n",
      "Action prob: [9.9999547e-01 4.5518750e-06], Action: 0, state: 8\n",
      "[9.9999547e-01 4.5844440e-06]\n",
      "Action prob: [9.9999547e-01 4.5844440e-06], Action: 0, state: 8\n",
      "[9.9999619e-01 3.7986003e-06]\n",
      "Action prob: [9.9999619e-01 3.7986003e-06], Action: 0, state: 8\n",
      "[9.9999917e-01 8.5286416e-07]\n",
      "Action prob: [9.9999917e-01 8.5286416e-07], Action: 0, state: 8\n",
      "[9.9999940e-01 6.4114363e-07]\n",
      "Action prob: [9.9999940e-01 6.4114363e-07], Action: 0, state: 8\n",
      "[9.999993e-01 6.589884e-07]\n",
      "Action prob: [9.999993e-01 6.589884e-07], Action: 0, state: 8\n",
      "[9.99997e-01 3.00498e-06]\n",
      "Action prob: [9.99997e-01 3.00498e-06], Action: 0, state: 8\n",
      "[9.999964e-01 3.579878e-06]\n",
      "Action prob: [9.999964e-01 3.579878e-06], Action: 0, state: 8\n",
      "[9.999982e-01 1.759900e-06]\n",
      "Action prob: [9.999982e-01 1.759900e-06], Action: 0, state: 8\n",
      "[9.9999630e-01 3.7373165e-06]\n",
      "Action prob: [9.9999630e-01 3.7373165e-06], Action: 0, state: 8\n",
      "[9.9999988e-01 1.4082117e-07]\n",
      "Action prob: [9.9999988e-01 1.4082117e-07], Action: 0, state: 8\n",
      "[9.9999726e-01 2.7586984e-06]\n",
      "Action prob: [9.9999726e-01 2.7586984e-06], Action: 0, state: 8\n",
      "[9.9999917e-01 8.3467586e-07]\n",
      "Action prob: [9.9999917e-01 8.3467586e-07], Action: 0, state: 8\n",
      "[9.9999964e-01 3.0809744e-07]\n",
      "Action prob: [9.9999964e-01 3.0809744e-07], Action: 0, state: 8\n",
      "[9.9999845e-01 1.6005259e-06]\n",
      "Action prob: [9.9999845e-01 1.6005259e-06], Action: 0, state: 8\n",
      "[9.999994e-01 6.211422e-07]\n",
      "Action prob: [9.999994e-01 6.211422e-07], Action: 0, state: 8\n",
      "[9.9999952e-01 5.0079115e-07]\n",
      "Action prob: [9.9999952e-01 5.0079115e-07], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-2.8802e-07,  8.2736e-07,  1.7951e-06,  3.0912e-06,  2.9863e-06,\n",
      "         3.7225e-06,  2.9649e-06,  5.4749e-06,  3.7454e-06,  4.2258e-06,\n",
      "         4.6454e-06,  5.5226e-06,  3.1281e-06,  1.5770e-06,  8.7396e-06,\n",
      "         6.4464e-06,  1.0797e-06,  8.7990e-07,  5.4581e-07,  4.2905e-07,\n",
      "         5.5579e-07,  1.4478e-07,  6.4024e-07,  2.8376e-07, -2.2137e-08,\n",
      "        -8.7840e-08, -7.4529e-07, -7.9903e-08, -2.6602e-07, -3.7349e-07,\n",
      "        -8.8287e-07, -3.2795e-07, -1.1166e-07, -2.5553e-06, -2.7328e-06,\n",
      "        -2.3603e-06, -5.3335e-07, -3.9242e-07, -5.0051e-07, -2.1111e-06,\n",
      "        -2.6149e-06, -1.2677e-06, -2.8229e-06, -8.6058e-08, -2.0869e-06,\n",
      "        -6.5623e-07, -2.7944e-07, -1.1922e-06, -4.7955e-07, -3.8803e-07],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -104300, loss is -7.441324916601261e-07\n",
      "[1.000000e+00 5.250609e-08]\n",
      "Action prob: [1.000000e+00 5.250609e-08], Action: 0, state: 0\n",
      "[9.999999e-01 8.736675e-08]\n",
      "Action prob: [9.999999e-01 8.736675e-08], Action: 0, state: 1\n",
      "[1.000000e+00 3.264657e-08]\n",
      "Action prob: [1.000000e+00 3.264657e-08], Action: 0, state: 1\n",
      "[1.0000000e+00 4.4666002e-08]\n",
      "Action prob: [1.0000000e+00 4.4666002e-08], Action: 0, state: 1\n",
      "[1.000000e+00 5.807373e-08]\n",
      "Action prob: [1.000000e+00 5.807373e-08], Action: 0, state: 2\n",
      "[9.999999e-01 9.713468e-08]\n",
      "Action prob: [9.999999e-01 9.713468e-08], Action: 0, state: 3\n",
      "[1.0000000e+00 1.4959925e-08]\n",
      "Action prob: [1.0000000e+00 1.4959925e-08], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1161422e-08]\n",
      "Action prob: [1.0000000e+00 1.1161422e-08], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1392225e-08]\n",
      "Action prob: [1.0000000e+00 2.1392225e-08], Action: 0, state: 8\n",
      "[1.000000e+00 7.000377e-09]\n",
      "Action prob: [1.000000e+00 7.000377e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9432461e-08]\n",
      "Action prob: [1.0000000e+00 1.9432461e-08], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6050964e-08]\n",
      "Action prob: [1.0000000e+00 2.6050964e-08], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1637502e-08]\n",
      "Action prob: [1.0000000e+00 4.1637502e-08], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0619674e-08]\n",
      "Action prob: [1.0000000e+00 1.0619674e-08], Action: 0, state: 8\n",
      "[9.9999988e-01 1.2202955e-07]\n",
      "Action prob: [9.9999988e-01 1.2202955e-07], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2336955e-08]\n",
      "Action prob: [1.0000000e+00 1.2336955e-08], Action: 0, state: 8\n",
      "[1.000000e+00 8.755155e-09]\n",
      "Action prob: [1.000000e+00 8.755155e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9420233e-08]\n",
      "Action prob: [1.0000000e+00 1.9420233e-08], Action: 0, state: 8\n",
      "[1.000000e+00 1.531317e-08]\n",
      "Action prob: [1.000000e+00 1.531317e-08], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0705598e-08]\n",
      "Action prob: [1.0000000e+00 1.0705598e-08], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9331536e-08]\n",
      "Action prob: [1.0000000e+00 2.9331536e-08], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6262897e-08]\n",
      "Action prob: [1.0000000e+00 1.6262897e-08], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1537665e-08]\n",
      "Action prob: [1.0000000e+00 1.1537665e-08], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1987849e-08]\n",
      "Action prob: [1.0000000e+00 1.1987849e-08], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4974399e-08]\n",
      "Action prob: [1.0000000e+00 1.4974399e-08], Action: 0, state: 8\n",
      "[9.99999881e-01 1.15200336e-07]\n",
      "Action prob: [9.99999881e-01 1.15200336e-07], Action: 0, state: 8\n",
      "[1.000000e+00 1.107348e-09]\n",
      "Action prob: [1.000000e+00 1.107348e-09], Action: 0, state: 8\n",
      "[1.000000e+00 8.049336e-09]\n",
      "Action prob: [1.000000e+00 8.049336e-09], Action: 0, state: 8\n",
      "[9.999999e-01 9.738586e-08]\n",
      "Action prob: [9.999999e-01 9.738586e-08], Action: 0, state: 8\n",
      "[9.999999e-01 1.378055e-07]\n",
      "Action prob: [9.999999e-01 1.378055e-07], Action: 0, state: 8\n",
      "[9.9999988e-01 1.6255989e-07]\n",
      "Action prob: [9.9999988e-01 1.6255989e-07], Action: 0, state: 8\n",
      "[1.000000e+00 3.127941e-08]\n",
      "Action prob: [1.000000e+00 3.127941e-08], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1912359e-08]\n",
      "Action prob: [1.0000000e+00 1.1912359e-08], Action: 0, state: 8\n",
      "[1.000000e+00 9.942448e-09]\n",
      "Action prob: [1.000000e+00 9.942448e-09], Action: 0, state: 8\n",
      "[9.9999988e-01 1.4242407e-07]\n",
      "Action prob: [9.9999988e-01 1.4242407e-07], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2460369e-09]\n",
      "Action prob: [1.0000000e+00 1.2460369e-09], Action: 0, state: 8\n",
      "[9.999999e-01 9.827499e-08]\n",
      "Action prob: [9.999999e-01 9.827499e-08], Action: 0, state: 8\n",
      "[9.999999e-01 9.567217e-08]\n",
      "Action prob: [9.999999e-01 9.567217e-08], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 9.971656e-09]\n",
      "Action prob: [1.000000e+00 9.971656e-09], Action: 0, state: 8\n",
      "[1.00000000e+00 1.22522525e-08]\n",
      "Action prob: [1.00000000e+00 1.22522525e-08], Action: 0, state: 8\n",
      "[9.999999e-01 1.158760e-07]\n",
      "Action prob: [9.999999e-01 1.158760e-07], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0512901e-08]\n",
      "Action prob: [1.0000000e+00 1.0512901e-08], Action: 0, state: 8\n",
      "[1.000000e+00 9.940816e-09]\n",
      "Action prob: [1.000000e+00 9.940816e-09], Action: 0, state: 8\n",
      "[9.9999976e-01 1.7882233e-07]\n",
      "Action prob: [9.9999976e-01 1.7882233e-07], Action: 0, state: 8\n",
      "[9.9999988e-01 1.2396282e-07]\n",
      "Action prob: [9.9999988e-01 1.2396282e-07], Action: 0, state: 8\n",
      "[9.999999e-01 8.809633e-08]\n",
      "Action prob: [9.999999e-01 8.809633e-08], Action: 0, state: 8\n",
      "[9.9999988e-01 1.2429689e-07]\n",
      "Action prob: [9.9999988e-01 1.2429689e-07], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9356688e-09]\n",
      "Action prob: [1.0000000e+00 4.9356688e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0886431e-08]\n",
      "Action prob: [1.0000000e+00 1.0886431e-08], Action: 0, state: 8\n",
      "[1.00000000e+00 1.13963985e-08]\n",
      "Action prob: [1.00000000e+00 1.13963985e-08], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0.0000e+00,  2.3247e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         2.8569e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  6.3710e-08,\n",
      "        -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -3.4452e-08,  0.0000e+00,  0.0000e+00, -4.6662e-08, -5.0109e-08,\n",
      "        -5.4098e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00, -6.4349e-08,\n",
      "         0.0000e+00, -5.5407e-08, -6.5138e-08,  0.0000e+00,  0.0000e+00,\n",
      "        -7.0910e-08,  0.0000e+00,  0.0000e+00, -1.5087e-07, -7.1352e-08,\n",
      "        -7.3622e-08, -7.3505e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -131000, loss is 4.571916906610018e-09\n",
      "[1.0000000e+00 9.1039504e-10]\n",
      "Action prob: [1.0000000e+00 9.1039504e-10], Action: 0, state: 0\n",
      "[1.0000000e+00 1.4584968e-09]\n",
      "Action prob: [1.0000000e+00 1.4584968e-09], Action: 0, state: 1\n",
      "[1.000000e+00 1.698741e-09]\n",
      "Action prob: [1.000000e+00 1.698741e-09], Action: 0, state: 1\n",
      "[1.000000e+00 1.394008e-09]\n",
      "Action prob: [1.000000e+00 1.394008e-09], Action: 0, state: 1\n",
      "[1.0000000e+00 2.5834765e-09]\n",
      "Action prob: [1.0000000e+00 2.5834765e-09], Action: 0, state: 1\n",
      "[1.000000e+00 2.369678e-09]\n",
      "Action prob: [1.000000e+00 2.369678e-09], Action: 0, state: 2\n",
      "[1.000000e+00 5.030614e-10]\n",
      "Action prob: [1.000000e+00 5.030614e-10], Action: 0, state: 2\n",
      "[1.0000000e+00 1.8635895e-09]\n",
      "Action prob: [1.0000000e+00 1.8635895e-09], Action: 0, state: 2\n",
      "[1.0000000e+00 6.8444217e-10]\n",
      "Action prob: [1.0000000e+00 6.8444217e-10], Action: 0, state: 2\n",
      "[1.0000000e+00 1.7148488e-09]\n",
      "Action prob: [1.0000000e+00 1.7148488e-09], Action: 0, state: 2\n",
      "[1.0000000e+00 1.1985009e-09]\n",
      "Action prob: [1.0000000e+00 1.1985009e-09], Action: 0, state: 2\n",
      "[1.0000000e+00 1.4296371e-10]\n",
      "Action prob: [1.0000000e+00 1.4296371e-10], Action: 0, state: 3\n",
      "[1.0000000e+00 1.8808145e-10]\n",
      "Action prob: [1.0000000e+00 1.8808145e-10], Action: 0, state: 3\n",
      "[1.0000000e+00 1.3341374e-10]\n",
      "Action prob: [1.0000000e+00 1.3341374e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1492267e-09]\n",
      "Action prob: [1.0000000e+00 3.1492267e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0529466e-09]\n",
      "Action prob: [1.0000000e+00 3.0529466e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2821146e-10]\n",
      "Action prob: [1.0000000e+00 2.2821146e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2342107e-10]\n",
      "Action prob: [1.0000000e+00 3.2342107e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2974686e-09]\n",
      "Action prob: [1.0000000e+00 4.2974686e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8359529e-10]\n",
      "Action prob: [1.0000000e+00 1.8359529e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9570663e-09]\n",
      "Action prob: [1.0000000e+00 4.9570663e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1382777e-09]\n",
      "Action prob: [1.0000000e+00 4.1382777e-09], Action: 0, state: 8\n",
      "[1.000000e+00 4.487006e-09]\n",
      "Action prob: [1.000000e+00 4.487006e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3235152e-10]\n",
      "Action prob: [1.0000000e+00 1.3235152e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2868875e-10]\n",
      "Action prob: [1.0000000e+00 1.2868875e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8055092e-09]\n",
      "Action prob: [1.0000000e+00 3.8055092e-09], Action: 0, state: 8\n",
      "[1.000000e+00 9.774903e-10]\n",
      "Action prob: [1.000000e+00 9.774903e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9587303e-09]\n",
      "Action prob: [1.0000000e+00 4.9587303e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9340434e-11]\n",
      "Action prob: [1.0000000e+00 1.9340434e-11], Action: 0, state: 8\n",
      "[1.000000e+00 3.774231e-09]\n",
      "Action prob: [1.000000e+00 3.774231e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4907954e-10]\n",
      "Action prob: [1.0000000e+00 1.4907954e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8829467e-10]\n",
      "Action prob: [1.0000000e+00 1.8829467e-10], Action: 0, state: 8\n",
      "[1.000000e+00 6.027708e-09]\n",
      "Action prob: [1.000000e+00 6.027708e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 5.8552403e-09]\n",
      "Action prob: [1.0000000e+00 5.8552403e-09], Action: 0, state: 8\n",
      "[1.000000e+00 4.812679e-09]\n",
      "Action prob: [1.000000e+00 4.812679e-09], Action: 0, state: 8\n",
      "[1.000000e+00 4.805983e-09]\n",
      "Action prob: [1.000000e+00 4.805983e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2398889e-10]\n",
      "Action prob: [1.0000000e+00 1.2398889e-10], Action: 0, state: 8\n",
      "[1.000000e+00 4.101555e-10]\n",
      "Action prob: [1.000000e+00 4.101555e-10], Action: 0, state: 8\n",
      "[1.000000e+00 3.113919e-10]\n",
      "Action prob: [1.000000e+00 3.113919e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0891051e-10]\n",
      "Action prob: [1.0000000e+00 1.0891051e-10], Action: 0, state: 8\n",
      "[1.000000e+00 3.970947e-09]\n",
      "Action prob: [1.000000e+00 3.970947e-09], Action: 0, state: 8\n",
      "[1.000000e+00 6.139189e-09]\n",
      "Action prob: [1.000000e+00 6.139189e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1351328e-10]\n",
      "Action prob: [1.0000000e+00 1.1351328e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0553424e-10]\n",
      "Action prob: [1.0000000e+00 2.0553424e-10], Action: 0, state: 8\n",
      "[1.000000e+00 4.636667e-09]\n",
      "Action prob: [1.000000e+00 4.636667e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 6.4787897e-12]\n",
      "Action prob: [1.0000000e+00 6.4787897e-12], Action: 0, state: 8\n",
      "[1.00000e+00 4.53256e-09]\n",
      "Action prob: [1.00000e+00 4.53256e-09], Action: 0, state: 8\n",
      "[1.000000e+00 4.697214e-09]\n",
      "Action prob: [1.000000e+00 4.697214e-09], Action: 0, state: 8\n",
      "[1.000000e+00 4.544333e-09]\n",
      "Action prob: [1.000000e+00 4.544333e-09], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2384945e-10]\n",
      "Action prob: [1.0000000e+00 3.2384945e-10], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -104600, loss is -0.0\n",
      "[1.0000000e+00 2.7116073e-11]\n",
      "Action prob: [1.0000000e+00 2.7116073e-11], Action: 0, state: 0\n",
      "[1.000000e+00 2.824696e-11]\n",
      "Action prob: [1.000000e+00 2.824696e-11], Action: 0, state: 0\n",
      "[1.0000000e+00 3.4747934e-11]\n",
      "Action prob: [1.0000000e+00 3.4747934e-11], Action: 0, state: 0\n",
      "[1.0000000e+00 2.1424983e-11]\n",
      "Action prob: [1.0000000e+00 2.1424983e-11], Action: 0, state: 0\n",
      "[1.0000000e+00 1.7735934e-11]\n",
      "Action prob: [1.0000000e+00 1.7735934e-11], Action: 0, state: 0\n",
      "[1.0000000e+00 2.4088296e-11]\n",
      "Action prob: [1.0000000e+00 2.4088296e-11], Action: 0, state: 1\n",
      "[1.0000000e+00 2.8254073e-11]\n",
      "Action prob: [1.0000000e+00 2.8254073e-11], Action: 0, state: 1\n",
      "[1.000000e+00 7.290961e-11]\n",
      "Action prob: [1.000000e+00 7.290961e-11], Action: 0, state: 1\n",
      "[1.000000e+00 5.412955e-11]\n",
      "Action prob: [1.000000e+00 5.412955e-11], Action: 0, state: 2\n",
      "[1.0000000e+00 1.1100881e-10]\n",
      "Action prob: [1.0000000e+00 1.1100881e-10], Action: 0, state: 3\n",
      "[1.0000000e+00 1.9397706e-10]\n",
      "Action prob: [1.0000000e+00 1.9397706e-10], Action: 0, state: 8\n",
      "[1.000000e+00 5.476968e-12]\n",
      "Action prob: [1.000000e+00 5.476968e-12], Action: 0, state: 8\n",
      "[1.00000e+00 1.50956e-10]\n",
      "Action prob: [1.00000e+00 1.50956e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5327579e-12]\n",
      "Action prob: [1.0000000e+00 3.5327579e-12], Action: 0, state: 8\n",
      "[1.000000e+00 4.656672e-12]\n",
      "Action prob: [1.000000e+00 4.656672e-12], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0922139e-10]\n",
      "Action prob: [1.0000000e+00 2.0922139e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3798112e-12]\n",
      "Action prob: [1.0000000e+00 2.3798112e-12], Action: 0, state: 8\n",
      "[1.00000e+00 2.05429e-12]\n",
      "Action prob: [1.00000e+00 2.05429e-12], Action: 0, state: 8\n",
      "[1.000000e+00 7.821552e-11]\n",
      "Action prob: [1.000000e+00 7.821552e-11], Action: 0, state: 8\n",
      "[1.000000e+00 6.895097e-12]\n",
      "Action prob: [1.000000e+00 6.895097e-12], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9572805e-12]\n",
      "Action prob: [1.0000000e+00 2.9572805e-12], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7294849e-10]\n",
      "Action prob: [1.0000000e+00 1.7294849e-10], Action: 0, state: 8\n",
      "[1.00000e+00 6.82764e-14]\n",
      "Action prob: [1.00000e+00 6.82764e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9113122e-13]\n",
      "Action prob: [1.0000000e+00 1.9113122e-13], Action: 0, state: 8\n",
      "[1.000000e+00 2.157071e-11]\n",
      "Action prob: [1.000000e+00 2.157071e-11], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5876523e-10]\n",
      "Action prob: [1.0000000e+00 2.5876523e-10], Action: 0, state: 8\n",
      "[1.000000e+00 8.197682e-11]\n",
      "Action prob: [1.000000e+00 8.197682e-11], Action: 0, state: 8\n",
      "[1.00e+00 8.37e-13]\n",
      "Action prob: [1.00e+00 8.37e-13], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0415194e-10]\n",
      "Action prob: [1.0000000e+00 1.0415194e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7090522e-12]\n",
      "Action prob: [1.0000000e+00 2.7090522e-12], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1452881e-10]\n",
      "Action prob: [1.0000000e+00 2.1452881e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 5.6434736e-14]\n",
      "Action prob: [1.0000000e+00 5.6434736e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6736162e-10]\n",
      "Action prob: [1.0000000e+00 1.6736162e-10], Action: 0, state: 8\n",
      "[1.000000e+00 2.550984e-12]\n",
      "Action prob: [1.000000e+00 2.550984e-12], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6234034e-10]\n",
      "Action prob: [1.0000000e+00 2.6234034e-10], Action: 0, state: 8\n",
      "[1.000000e+00 9.395158e-11]\n",
      "Action prob: [1.000000e+00 9.395158e-11], Action: 0, state: 8\n",
      "[1.000000e+00 6.162973e-12]\n",
      "Action prob: [1.000000e+00 6.162973e-12], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9000546e-10]\n",
      "Action prob: [1.0000000e+00 1.9000546e-10], Action: 0, state: 8\n",
      "[1.000000e+00 9.802007e-11]\n",
      "Action prob: [1.000000e+00 9.802007e-11], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2553804e-10]\n",
      "Action prob: [1.0000000e+00 1.2553804e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2184995e-14]\n",
      "Action prob: [1.0000000e+00 3.2184995e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4837737e-14]\n",
      "Action prob: [1.0000000e+00 3.4837737e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3891848e-12]\n",
      "Action prob: [1.0000000e+00 2.3891848e-12], Action: 0, state: 8\n",
      "[1.000000e+00 5.876505e-14]\n",
      "Action prob: [1.000000e+00 5.876505e-14], Action: 0, state: 8\n",
      "[1.000000e+00 3.307231e-12]\n",
      "Action prob: [1.000000e+00 3.307231e-12], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6488017e-12]\n",
      "Action prob: [1.0000000e+00 3.6488017e-12], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4271112e-12]\n",
      "Action prob: [1.0000000e+00 3.4271112e-12], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2109429e-10]\n",
      "Action prob: [1.0000000e+00 1.2109429e-10], Action: 0, state: 8\n",
      "[1.000000e+00 2.383366e-10]\n",
      "Action prob: [1.000000e+00 2.383366e-10], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1535532e-10]\n",
      "Action prob: [1.0000000e+00 2.1535532e-10], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -115000, loss is -0.0\n",
      "[1.00000e+00 2.31201e-12]\n",
      "Action prob: [1.00000e+00 2.31201e-12], Action: 0, state: 0\n",
      "[1.000000e+00 5.782412e-13]\n",
      "Action prob: [1.000000e+00 5.782412e-13], Action: 0, state: 1\n",
      "[1.0000000e+00 8.5809024e-13]\n",
      "Action prob: [1.0000000e+00 8.5809024e-13], Action: 0, state: 1\n",
      "[1.0000000e+00 8.2322864e-13]\n",
      "Action prob: [1.0000000e+00 8.2322864e-13], Action: 0, state: 1\n",
      "[1.000000e+00 2.385774e-12]\n",
      "Action prob: [1.000000e+00 2.385774e-12], Action: 0, state: 1\n",
      "[1.000000e+00 8.659179e-13]\n",
      "Action prob: [1.000000e+00 8.659179e-13], Action: 0, state: 1\n",
      "[1.0000000e+00 1.2088163e-12]\n",
      "Action prob: [1.0000000e+00 1.2088163e-12], Action: 0, state: 2\n",
      "[1.0000000e+00 1.5266594e-12]\n",
      "Action prob: [1.0000000e+00 1.5266594e-12], Action: 0, state: 2\n",
      "[1.00000e+00 5.90487e-12]\n",
      "Action prob: [1.00000e+00 5.90487e-12], Action: 0, state: 2\n",
      "[1.0000000e+00 4.5953506e-12]\n",
      "Action prob: [1.0000000e+00 4.5953506e-12], Action: 0, state: 2\n",
      "[1.0000000e+00 1.9443533e-13]\n",
      "Action prob: [1.0000000e+00 1.9443533e-13], Action: 0, state: 3\n",
      "[1.0000000e+00 1.1092425e-12]\n",
      "Action prob: [1.0000000e+00 1.1092425e-12], Action: 0, state: 3\n",
      "[1.0000000e+00 6.9441036e-15]\n",
      "Action prob: [1.0000000e+00 6.9441036e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7250232e-11]\n",
      "Action prob: [1.0000000e+00 1.7250232e-11], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0897887e-14]\n",
      "Action prob: [1.0000000e+00 1.0897887e-14], Action: 0, state: 8\n",
      "[1.000000e+00 7.422169e-14]\n",
      "Action prob: [1.000000e+00 7.422169e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4317866e-11]\n",
      "Action prob: [1.0000000e+00 1.4317866e-11], Action: 0, state: 8\n",
      "[1.00000e+00 9.79902e-14]\n",
      "Action prob: [1.00000e+00 9.79902e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 7.0017214e-14]\n",
      "Action prob: [1.0000000e+00 7.0017214e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0286342e-12]\n",
      "Action prob: [1.0000000e+00 2.0286342e-12], Action: 0, state: 8\n",
      "[1.000000e+00 1.354508e-11]\n",
      "Action prob: [1.000000e+00 1.354508e-11], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 3.8626417e-14]\n",
      "Action prob: [1.0000000e+00 3.8626417e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 6.1212727e-14]\n",
      "Action prob: [1.0000000e+00 6.1212727e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6019476e-11]\n",
      "Action prob: [1.0000000e+00 1.6019476e-11], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0866335e-11]\n",
      "Action prob: [1.0000000e+00 2.0866335e-11], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4416138e-13]\n",
      "Action prob: [1.0000000e+00 2.4416138e-13], Action: 0, state: 8\n",
      "[1.000000e+00 2.808685e-12]\n",
      "Action prob: [1.000000e+00 2.808685e-12], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3935148e-11]\n",
      "Action prob: [1.0000000e+00 1.3935148e-11], Action: 0, state: 8\n",
      "[1.000000e+00 1.065117e-13]\n",
      "Action prob: [1.000000e+00 1.065117e-13], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8283253e-14]\n",
      "Action prob: [1.0000000e+00 2.8283253e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0905627e-13]\n",
      "Action prob: [1.0000000e+00 1.0905627e-13], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5404302e-12]\n",
      "Action prob: [1.0000000e+00 1.5404302e-12], Action: 0, state: 8\n",
      "[1.00000000e+00 1.10287505e-13]\n",
      "Action prob: [1.00000000e+00 1.10287505e-13], Action: 0, state: 8\n",
      "[1.0000000e+00 5.5227043e-12]\n",
      "Action prob: [1.0000000e+00 5.5227043e-12], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3465986e-12]\n",
      "Action prob: [1.0000000e+00 3.3465986e-12], Action: 0, state: 8\n",
      "[1.000000e+00 7.482436e-14]\n",
      "Action prob: [1.000000e+00 7.482436e-14], Action: 0, state: 8\n",
      "[1.000000e+00 9.571542e-12]\n",
      "Action prob: [1.000000e+00 9.571542e-12], Action: 0, state: 8\n",
      "[1.000000e+00 1.523629e-11]\n",
      "Action prob: [1.000000e+00 1.523629e-11], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9569363e-13]\n",
      "Action prob: [1.0000000e+00 1.9569363e-13], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0028698e-13]\n",
      "Action prob: [1.0000000e+00 2.0028698e-13], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0377346e-14]\n",
      "Action prob: [1.0000000e+00 4.0377346e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 4.5768365e-14]\n",
      "Action prob: [1.0000000e+00 4.5768365e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 4.6403866e-15]\n",
      "Action prob: [1.0000000e+00 4.6403866e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1541729e-13]\n",
      "Action prob: [1.0000000e+00 1.1541729e-13], Action: 0, state: 8\n",
      "[1.000000e+00 6.051937e-12]\n",
      "Action prob: [1.000000e+00 6.051937e-12], Action: 0, state: 8\n",
      "[1.0000000e+00 8.0281566e-14]\n",
      "Action prob: [1.0000000e+00 8.0281566e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0501392e-14]\n",
      "Action prob: [1.0000000e+00 5.0501392e-14], Action: 0, state: 8\n",
      "[1.000000e+00 6.142354e-12]\n",
      "Action prob: [1.000000e+00 6.142354e-12], Action: 0, state: 8\n",
      "[1.000000e+00 8.064938e-12]\n",
      "Action prob: [1.000000e+00 8.064938e-12], Action: 0, state: 8\n",
      "[1.000000e+00 6.460536e-13]\n",
      "Action prob: [1.000000e+00 6.460536e-13], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -108300, loss is -0.0\n",
      "[1.000000e+00 6.555803e-14]\n",
      "Action prob: [1.000000e+00 6.555803e-14], Action: 0, state: 0\n",
      "[1.000000e+00 8.416822e-14]\n",
      "Action prob: [1.000000e+00 8.416822e-14], Action: 0, state: 0\n",
      "[1.0000000e+00 3.2027617e-14]\n",
      "Action prob: [1.0000000e+00 3.2027617e-14], Action: 0, state: 0\n",
      "[1.0000000e+00 3.5316226e-14]\n",
      "Action prob: [1.0000000e+00 3.5316226e-14], Action: 0, state: 0\n",
      "[1.0000000e+00 2.9211147e-13]\n",
      "Action prob: [1.0000000e+00 2.9211147e-13], Action: 0, state: 0\n",
      "[1.00000e+00 5.80242e-13]\n",
      "Action prob: [1.00000e+00 5.80242e-13], Action: 0, state: 1\n",
      "[1.000000e+00 3.676848e-14]\n",
      "Action prob: [1.000000e+00 3.676848e-14], Action: 0, state: 1\n",
      "[1.0000000e+00 1.0275574e-13]\n",
      "Action prob: [1.0000000e+00 1.0275574e-13], Action: 0, state: 1\n",
      "[1.0000000e+00 1.2701644e-13]\n",
      "Action prob: [1.0000000e+00 1.2701644e-13], Action: 0, state: 2\n",
      "[1.000000e+00 1.130324e-13]\n",
      "Action prob: [1.000000e+00 1.130324e-13], Action: 0, state: 2\n",
      "[1.0000000e+00 5.2948023e-14]\n",
      "Action prob: [1.0000000e+00 5.2948023e-14], Action: 0, state: 2\n",
      "[1.0000000e+00 5.4940478e-14]\n",
      "Action prob: [1.0000000e+00 5.4940478e-14], Action: 0, state: 3\n",
      "[1.0000000e+00 1.2097751e-13]\n",
      "Action prob: [1.0000000e+00 1.2097751e-13], Action: 0, state: 3\n",
      "[1.000000e+00 4.540509e-14]\n",
      "Action prob: [1.000000e+00 4.540509e-14], Action: 0, state: 3\n",
      "[1.0000000e+00 4.1260295e-13]\n",
      "Action prob: [1.0000000e+00 4.1260295e-13], Action: 0, state: 3\n",
      "[1.000000e+00 1.162698e-12]\n",
      "Action prob: [1.000000e+00 1.162698e-12], Action: 0, state: 8\n",
      "[1.0000000e+00 5.6407217e-13]\n",
      "Action prob: [1.0000000e+00 5.6407217e-13], Action: 0, state: 8\n",
      "[1.000000e+00 9.207562e-13]\n",
      "Action prob: [1.000000e+00 9.207562e-13], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0165855e-14]\n",
      "Action prob: [1.0000000e+00 1.0165855e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6563616e-15]\n",
      "Action prob: [1.0000000e+00 1.6563616e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6690102e-17]\n",
      "Action prob: [1.0000000e+00 3.6690102e-17], Action: 0, state: 8\n",
      "[1.00000000e+00 1.41844375e-14]\n",
      "Action prob: [1.00000000e+00 1.41844375e-14], Action: 0, state: 8\n",
      "[1.00000e+00 5.34542e-13]\n",
      "Action prob: [1.00000e+00 5.34542e-13], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4461184e-13]\n",
      "Action prob: [1.0000000e+00 3.4461184e-13], Action: 0, state: 8\n",
      "[1.0000000e+00 5.5042717e-15]\n",
      "Action prob: [1.0000000e+00 5.5042717e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3314236e-15]\n",
      "Action prob: [1.0000000e+00 5.3314236e-15], Action: 0, state: 8\n",
      "[1.000000e+00 9.172141e-16]\n",
      "Action prob: [1.000000e+00 9.172141e-16], Action: 0, state: 8\n",
      "[1.000000e+00 5.844798e-16]\n",
      "Action prob: [1.000000e+00 5.844798e-16], Action: 0, state: 8\n",
      "[1.000000e+00 8.655566e-16]\n",
      "Action prob: [1.000000e+00 8.655566e-16], Action: 0, state: 8\n",
      "[1.000000e+00 2.041335e-15]\n",
      "Action prob: [1.000000e+00 2.041335e-15], Action: 0, state: 8\n",
      "[1.000000e+00 5.899047e-13]\n",
      "Action prob: [1.000000e+00 5.899047e-13], Action: 0, state: 8\n",
      "[1.000000e+00 9.869659e-18]\n",
      "Action prob: [1.000000e+00 9.869659e-18], Action: 0, state: 8\n",
      "[1.000000e+00 1.780749e-15]\n",
      "Action prob: [1.000000e+00 1.780749e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1053994e-18]\n",
      "Action prob: [1.0000000e+00 1.1053994e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1144337e-15]\n",
      "Action prob: [1.0000000e+00 4.1144337e-15], Action: 0, state: 8\n",
      "[1.000000e+00 9.927835e-13]\n",
      "Action prob: [1.000000e+00 9.927835e-13], Action: 0, state: 8\n",
      "[1.000000e+00 5.277121e-13]\n",
      "Action prob: [1.000000e+00 5.277121e-13], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3809676e-15]\n",
      "Action prob: [1.0000000e+00 1.3809676e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1138823e-16]\n",
      "Action prob: [1.0000000e+00 4.1138823e-16], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5813667e-13]\n",
      "Action prob: [1.0000000e+00 3.5813667e-13], Action: 0, state: 8\n",
      "[1.000000e+00 4.253842e-15]\n",
      "Action prob: [1.000000e+00 4.253842e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 8.1066576e-15]\n",
      "Action prob: [1.0000000e+00 8.1066576e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1473406e-13]\n",
      "Action prob: [1.0000000e+00 4.1473406e-13], Action: 0, state: 8\n",
      "[1.000000e+00 1.732417e-17]\n",
      "Action prob: [1.000000e+00 1.732417e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4661908e-13]\n",
      "Action prob: [1.0000000e+00 2.4661908e-13], Action: 0, state: 8\n",
      "[1.000000e+00 1.891444e-15]\n",
      "Action prob: [1.000000e+00 1.891444e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 7.3410906e-13]\n",
      "Action prob: [1.0000000e+00 7.3410906e-13], Action: 0, state: 8\n",
      "[1.000000e+00 5.476897e-15]\n",
      "Action prob: [1.000000e+00 5.476897e-15], Action: 0, state: 8\n",
      "[1.000000e+00 6.537488e-13]\n",
      "Action prob: [1.000000e+00 6.537488e-13], Action: 0, state: 8\n",
      "[1.00000e+00 5.81413e-13]\n",
      "Action prob: [1.00000e+00 5.81413e-13], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -96900, loss is -0.0\n",
      "[1.0000000e+00 5.3170846e-15]\n",
      "Action prob: [1.0000000e+00 5.3170846e-15], Action: 0, state: 0\n",
      "[1.000000e+00 9.861056e-15]\n",
      "Action prob: [1.000000e+00 9.861056e-15], Action: 0, state: 0\n",
      "[1.000000e+00 5.026209e-15]\n",
      "Action prob: [1.000000e+00 5.026209e-15], Action: 0, state: 1\n",
      "[1.0000000e+00 2.8586193e-15]\n",
      "Action prob: [1.0000000e+00 2.8586193e-15], Action: 0, state: 1\n",
      "[1.000000e+00 7.539565e-15]\n",
      "Action prob: [1.000000e+00 7.539565e-15], Action: 0, state: 1\n",
      "[1.0000000e+00 1.4512608e-15]\n",
      "Action prob: [1.0000000e+00 1.4512608e-15], Action: 0, state: 2\n",
      "[1.0000000e+00 2.9620234e-15]\n",
      "Action prob: [1.0000000e+00 2.9620234e-15], Action: 0, state: 2\n",
      "[1.0000000e+00 9.1160905e-15]\n",
      "Action prob: [1.0000000e+00 9.1160905e-15], Action: 0, state: 2\n",
      "[1.0000000e+00 1.4596166e-15]\n",
      "Action prob: [1.0000000e+00 1.4596166e-15], Action: 0, state: 2\n",
      "[1.000000e+00 2.915868e-15]\n",
      "Action prob: [1.000000e+00 2.915868e-15], Action: 0, state: 2\n",
      "[1.0000000e+00 2.5453092e-18]\n",
      "Action prob: [1.0000000e+00 2.5453092e-18], Action: 0, state: 3\n",
      "[1.000000e+00 8.438112e-16]\n",
      "Action prob: [1.000000e+00 8.438112e-16], Action: 0, state: 3\n",
      "[1.0000000e+00 1.6576304e-17]\n",
      "Action prob: [1.0000000e+00 1.6576304e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2290688e-15]\n",
      "Action prob: [1.0000000e+00 1.2290688e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 7.8627636e-14]\n",
      "Action prob: [1.0000000e+00 7.8627636e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3645473e-18]\n",
      "Action prob: [1.0000000e+00 2.3645473e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5235148e-14]\n",
      "Action prob: [1.0000000e+00 3.5235148e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5426419e-17]\n",
      "Action prob: [1.0000000e+00 2.5426419e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3041427e-16]\n",
      "Action prob: [1.0000000e+00 2.3041427e-16], Action: 0, state: 8\n",
      "[1.000000e+00 6.122839e-17]\n",
      "Action prob: [1.000000e+00 6.122839e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 5.1064457e-17]\n",
      "Action prob: [1.0000000e+00 5.1064457e-17], Action: 0, state: 8\n",
      "[1.00000000e+00 1.01166366e-16]\n",
      "Action prob: [1.00000000e+00 1.01166366e-16], Action: 0, state: 8\n",
      "[1.000000e+00 6.318113e-14]\n",
      "Action prob: [1.000000e+00 6.318113e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 5.8514744e-14]\n",
      "Action prob: [1.0000000e+00 5.8514744e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1934142e-16]\n",
      "Action prob: [1.0000000e+00 1.1934142e-16], Action: 0, state: 8\n",
      "[1.0000000e+00 7.6931286e-14]\n",
      "Action prob: [1.0000000e+00 7.6931286e-14], Action: 0, state: 8\n",
      "[1.000000e+00 8.419973e-17]\n",
      "Action prob: [1.000000e+00 8.419973e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6384772e-14]\n",
      "Action prob: [1.0000000e+00 1.6384772e-14], Action: 0, state: 8\n",
      "[1.000000e+00 4.054941e-16]\n",
      "Action prob: [1.000000e+00 4.054941e-16], Action: 0, state: 8\n",
      "[1.0000000e+00 8.1435336e-17]\n",
      "Action prob: [1.0000000e+00 8.1435336e-17], Action: 0, state: 8\n",
      "[1.000000e+00 7.004099e-14]\n",
      "Action prob: [1.000000e+00 7.004099e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 3.7199285e-17]\n",
      "Action prob: [1.0000000e+00 3.7199285e-17], Action: 0, state: 8\n",
      "[1.000000e+00 9.472482e-21]\n",
      "Action prob: [1.000000e+00 9.472482e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0838758e-16]\n",
      "Action prob: [1.0000000e+00 2.0838758e-16], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6433378e-14]\n",
      "Action prob: [1.0000000e+00 1.6433378e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 5.1544316e-14]\n",
      "Action prob: [1.0000000e+00 5.1544316e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7945487e-14]\n",
      "Action prob: [1.0000000e+00 1.7945487e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9564596e-17]\n",
      "Action prob: [1.0000000e+00 4.9564596e-17], Action: 0, state: 8\n",
      "[1.00000e+00 7.01964e-14]\n",
      "Action prob: [1.00000e+00 7.01964e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6418167e-16]\n",
      "Action prob: [1.0000000e+00 1.6418167e-16], Action: 0, state: 8\n",
      "[1.000000e+00 8.117988e-14]\n",
      "Action prob: [1.000000e+00 8.117988e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7753412e-17]\n",
      "Action prob: [1.0000000e+00 1.7753412e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1531898e-17]\n",
      "Action prob: [1.0000000e+00 4.1531898e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3062608e-17]\n",
      "Action prob: [1.0000000e+00 2.3062608e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 6.0119996e-17]\n",
      "Action prob: [1.0000000e+00 6.0119996e-17], Action: 0, state: 8\n",
      "[1.000000e+00 7.244224e-17]\n",
      "Action prob: [1.000000e+00 7.244224e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4128357e-14]\n",
      "Action prob: [1.0000000e+00 2.4128357e-14], Action: 0, state: 8\n",
      "[1.000000e+00 5.415438e-17]\n",
      "Action prob: [1.000000e+00 5.415438e-17], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 7.4614014e-14]\n",
      "Action prob: [1.0000000e+00 7.4614014e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 5.2916646e-17]\n",
      "Action prob: [1.0000000e+00 5.2916646e-17], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -108300, loss is -0.0\n",
      "[1.0000000e+00 2.2452276e-16]\n",
      "Action prob: [1.0000000e+00 2.2452276e-16], Action: 0, state: 0\n",
      "[1.0000000e+00 1.4503864e-15]\n",
      "Action prob: [1.0000000e+00 1.4503864e-15], Action: 0, state: 0\n",
      "[1.0000000e+00 1.7302648e-16]\n",
      "Action prob: [1.0000000e+00 1.7302648e-16], Action: 0, state: 1\n",
      "[1.0000000e+00 2.1959209e-16]\n",
      "Action prob: [1.0000000e+00 2.1959209e-16], Action: 0, state: 2\n",
      "[1.0000000e+00 2.9006233e-16]\n",
      "Action prob: [1.0000000e+00 2.9006233e-16], Action: 0, state: 2\n",
      "[1.000000e+00 9.618557e-16]\n",
      "Action prob: [1.000000e+00 9.618557e-16], Action: 0, state: 2\n",
      "[1.0000000e+00 8.5948285e-16]\n",
      "Action prob: [1.0000000e+00 8.5948285e-16], Action: 0, state: 2\n",
      "[1.0000000e+00 1.9964592e-16]\n",
      "Action prob: [1.0000000e+00 1.9964592e-16], Action: 0, state: 3\n",
      "[1.000000e+00 4.268632e-16]\n",
      "Action prob: [1.000000e+00 4.268632e-16], Action: 0, state: 3\n",
      "[1.000000e+00 8.200046e-18]\n",
      "Action prob: [1.000000e+00 8.200046e-18], Action: 0, state: 3\n",
      "[1.0000000e+00 3.4376148e-18]\n",
      "Action prob: [1.0000000e+00 3.4376148e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1289826e-18]\n",
      "Action prob: [1.0000000e+00 2.1289826e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5323897e-18]\n",
      "Action prob: [1.0000000e+00 2.5323897e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4842465e-17]\n",
      "Action prob: [1.0000000e+00 3.4842465e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1893227e-15]\n",
      "Action prob: [1.0000000e+00 2.1893227e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7988166e-17]\n",
      "Action prob: [1.0000000e+00 2.7988166e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 4.4223106e-18]\n",
      "Action prob: [1.0000000e+00 4.4223106e-18], Action: 0, state: 8\n",
      "[1.000000e+00 7.140212e-18]\n",
      "Action prob: [1.000000e+00 7.140212e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4061669e-18]\n",
      "Action prob: [1.0000000e+00 2.4061669e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8176907e-18]\n",
      "Action prob: [1.0000000e+00 2.8176907e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 6.1691167e-18]\n",
      "Action prob: [1.0000000e+00 6.1691167e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3219638e-18]\n",
      "Action prob: [1.0000000e+00 2.3219638e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9790245e-19]\n",
      "Action prob: [1.0000000e+00 4.9790245e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 7.0802535e-15]\n",
      "Action prob: [1.0000000e+00 7.0802535e-15], Action: 0, state: 8\n",
      "[1.00000e+00 3.48671e-15]\n",
      "Action prob: [1.00000e+00 3.48671e-15], Action: 0, state: 8\n",
      "[1.000000e+00 3.570798e-15]\n",
      "Action prob: [1.000000e+00 3.570798e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3457444e-21]\n",
      "Action prob: [1.0000000e+00 5.3457444e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 4.6479514e-15]\n",
      "Action prob: [1.0000000e+00 4.6479514e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7319166e-15]\n",
      "Action prob: [1.0000000e+00 1.7319166e-15], Action: 0, state: 8\n",
      "[1.000000e+00 9.042094e-19]\n",
      "Action prob: [1.000000e+00 9.042094e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0030875e-14]\n",
      "Action prob: [1.0000000e+00 1.0030875e-14], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1259128e-17]\n",
      "Action prob: [1.0000000e+00 1.1259128e-17], Action: 0, state: 8\n",
      "[1.000000e+00 9.876906e-15]\n",
      "Action prob: [1.000000e+00 9.876906e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2277455e-17]\n",
      "Action prob: [1.0000000e+00 2.2277455e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0354481e-18]\n",
      "Action prob: [1.0000000e+00 1.0354481e-18], Action: 0, state: 8\n",
      "[1.000000e+00 8.655128e-18]\n",
      "Action prob: [1.000000e+00 8.655128e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5366994e-17]\n",
      "Action prob: [1.0000000e+00 1.5366994e-17], Action: 0, state: 8\n",
      "[1.000000e+00 5.602023e-18]\n",
      "Action prob: [1.000000e+00 5.602023e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0593083e-17]\n",
      "Action prob: [1.0000000e+00 1.0593083e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9499752e-14]\n",
      "Action prob: [1.0000000e+00 1.9499752e-14], Action: 0, state: 8\n",
      "[1.00000e+00 4.14646e-18]\n",
      "Action prob: [1.00000e+00 4.14646e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7525784e-16]\n",
      "Action prob: [1.0000000e+00 1.7525784e-16], Action: 0, state: 8\n",
      "[1.000000e+00 6.084173e-15]\n",
      "Action prob: [1.000000e+00 6.084173e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5108328e-18]\n",
      "Action prob: [1.0000000e+00 1.5108328e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6066478e-15]\n",
      "Action prob: [1.0000000e+00 2.6066478e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 5.8534805e-15]\n",
      "Action prob: [1.0000000e+00 5.8534805e-15], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8916432e-18]\n",
      "Action prob: [1.0000000e+00 1.8916432e-18], Action: 0, state: 8\n",
      "[1.000000e+00 2.825431e-17]\n",
      "Action prob: [1.000000e+00 2.825431e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4733825e-17]\n",
      "Action prob: [1.0000000e+00 1.4733825e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8300325e-19]\n",
      "Action prob: [1.0000000e+00 1.8300325e-19], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -116400, loss is -0.0\n",
      "[1.0000000e+00 5.4102552e-17]\n",
      "Action prob: [1.0000000e+00 5.4102552e-17], Action: 0, state: 0\n",
      "[1.000000e+00 6.701905e-18]\n",
      "Action prob: [1.000000e+00 6.701905e-18], Action: 0, state: 0\n",
      "[1.0000000e+00 2.5209211e-17]\n",
      "Action prob: [1.0000000e+00 2.5209211e-17], Action: 0, state: 1\n",
      "[1.000000e+00 9.092222e-17]\n",
      "Action prob: [1.000000e+00 9.092222e-17], Action: 0, state: 1\n",
      "[1.000000e+00 6.030282e-17]\n",
      "Action prob: [1.000000e+00 6.030282e-17], Action: 0, state: 1\n",
      "[1.0000000e+00 2.0886976e-17]\n",
      "Action prob: [1.0000000e+00 2.0886976e-17], Action: 0, state: 2\n",
      "[1.0000000e+00 3.2478343e-18]\n",
      "Action prob: [1.0000000e+00 3.2478343e-18], Action: 0, state: 2\n",
      "[1.0000000e+00 1.1311785e-16]\n",
      "Action prob: [1.0000000e+00 1.1311785e-16], Action: 0, state: 2\n",
      "[1.0000000e+00 5.4655582e-17]\n",
      "Action prob: [1.0000000e+00 5.4655582e-17], Action: 0, state: 3\n",
      "[1.0000000e+00 1.4089501e-17]\n",
      "Action prob: [1.0000000e+00 1.4089501e-17], Action: 0, state: 3\n",
      "[1.000000e+00 4.450102e-16]\n",
      "Action prob: [1.000000e+00 4.450102e-16], Action: 0, state: 3\n",
      "[1.000000e+00 1.154099e-19]\n",
      "Action prob: [1.000000e+00 1.154099e-19], Action: 0, state: 8\n",
      "[1.000000e+00 4.869515e-19]\n",
      "Action prob: [1.000000e+00 4.869515e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0495247e-19]\n",
      "Action prob: [1.0000000e+00 4.0495247e-19], Action: 0, state: 8\n",
      "[1.000000e+00 3.474745e-16]\n",
      "Action prob: [1.000000e+00 3.474745e-16], Action: 0, state: 8\n",
      "[1.000000e+00 9.388129e-20]\n",
      "Action prob: [1.000000e+00 9.388129e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8811883e-20]\n",
      "Action prob: [1.0000000e+00 3.8811883e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0797723e-18]\n",
      "Action prob: [1.0000000e+00 1.0797723e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3225154e-16]\n",
      "Action prob: [1.0000000e+00 2.3225154e-16], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9370351e-19]\n",
      "Action prob: [1.0000000e+00 3.9370351e-19], Action: 0, state: 8\n",
      "[1.000000e+00 9.874987e-22]\n",
      "Action prob: [1.000000e+00 9.874987e-22], Action: 0, state: 8\n",
      "[1.000000e+00 5.059599e-17]\n",
      "Action prob: [1.000000e+00 5.059599e-17], Action: 0, state: 8\n",
      "[1.000000e+00 2.647541e-18]\n",
      "Action prob: [1.000000e+00 2.647541e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0050289e-15]\n",
      "Action prob: [1.0000000e+00 1.0050289e-15], Action: 0, state: 8\n",
      "[1.000000e+00 6.731572e-19]\n",
      "Action prob: [1.000000e+00 6.731572e-19], Action: 0, state: 8\n",
      "[1.000000e+00 6.387901e-20]\n",
      "Action prob: [1.000000e+00 6.387901e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 5.1765175e-19]\n",
      "Action prob: [1.0000000e+00 5.1765175e-19], Action: 0, state: 8\n",
      "[1.000000e+00 8.489869e-16]\n",
      "Action prob: [1.000000e+00 8.489869e-16], Action: 0, state: 8\n",
      "[1.000000e+00 2.776853e-19]\n",
      "Action prob: [1.000000e+00 2.776853e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0242385e-21]\n",
      "Action prob: [1.0000000e+00 1.0242385e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3443377e-20]\n",
      "Action prob: [1.0000000e+00 4.3443377e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3745667e-22]\n",
      "Action prob: [1.0000000e+00 4.3745667e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 8.9704434e-23]\n",
      "Action prob: [1.0000000e+00 8.9704434e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0542882e-19]\n",
      "Action prob: [1.0000000e+00 1.0542882e-19], Action: 0, state: 8\n",
      "[1.000000e+00 3.670298e-17]\n",
      "Action prob: [1.000000e+00 3.670298e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3684263e-19]\n",
      "Action prob: [1.0000000e+00 1.3684263e-19], Action: 0, state: 8\n",
      "[1.00000e+00 4.96034e-16]\n",
      "Action prob: [1.00000e+00 4.96034e-16], Action: 0, state: 8\n",
      "[1.000000e+00 7.613269e-21]\n",
      "Action prob: [1.000000e+00 7.613269e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1278622e-18]\n",
      "Action prob: [1.0000000e+00 2.1278622e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1397405e-18]\n",
      "Action prob: [1.0000000e+00 1.1397405e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3214665e-20]\n",
      "Action prob: [1.0000000e+00 3.3214665e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8987044e-20]\n",
      "Action prob: [1.0000000e+00 1.8987044e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 9.0564154e-20]\n",
      "Action prob: [1.0000000e+00 9.0564154e-20], Action: 0, state: 8\n",
      "[1.000000e+00 5.806375e-16]\n",
      "Action prob: [1.000000e+00 5.806375e-16], Action: 0, state: 8\n",
      "[1.000000e+00 1.028013e-19]\n",
      "Action prob: [1.000000e+00 1.028013e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1384803e-19]\n",
      "Action prob: [1.0000000e+00 2.1384803e-19], Action: 0, state: 8\n",
      "[1.00000e+00 8.79538e-19]\n",
      "Action prob: [1.00000e+00 8.79538e-19], Action: 0, state: 8\n",
      "[1.000000e+00 4.817428e-20]\n",
      "Action prob: [1.000000e+00 4.817428e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8628814e-21]\n",
      "Action prob: [1.0000000e+00 1.8628814e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6649498e-19]\n",
      "Action prob: [1.0000000e+00 3.6649498e-19], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -112400, loss is -0.0\n",
      "[1.0000000e+00 5.3476495e-18]\n",
      "Action prob: [1.0000000e+00 5.3476495e-18], Action: 0, state: 0\n",
      "[1.000000e+00 4.514802e-17]\n",
      "Action prob: [1.000000e+00 4.514802e-17], Action: 0, state: 1\n",
      "[1.0000000e+00 1.2487738e-19]\n",
      "Action prob: [1.0000000e+00 1.2487738e-19], Action: 0, state: 1\n",
      "[1.0000000e+00 4.0022414e-18]\n",
      "Action prob: [1.0000000e+00 4.0022414e-18], Action: 0, state: 1\n",
      "[1.000000e+00 2.423337e-18]\n",
      "Action prob: [1.000000e+00 2.423337e-18], Action: 0, state: 1\n",
      "[1.00000e+00 5.29358e-18]\n",
      "Action prob: [1.00000e+00 5.29358e-18], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 3.5029027e-18]\n",
      "Action prob: [1.0000000e+00 3.5029027e-18], Action: 0, state: 1\n",
      "[1.000000e+00 9.816224e-19]\n",
      "Action prob: [1.000000e+00 9.816224e-19], Action: 0, state: 1\n",
      "[1.000000e+00 9.346896e-19]\n",
      "Action prob: [1.000000e+00 9.346896e-19], Action: 0, state: 1\n",
      "[1.0000000e+00 4.7004906e-18]\n",
      "Action prob: [1.0000000e+00 4.7004906e-18], Action: 0, state: 2\n",
      "[1.000000e+00 4.648636e-18]\n",
      "Action prob: [1.000000e+00 4.648636e-18], Action: 0, state: 2\n",
      "[1.0000000e+00 1.0533682e-18]\n",
      "Action prob: [1.0000000e+00 1.0533682e-18], Action: 0, state: 2\n",
      "[1.0000000e+00 4.7692703e-18]\n",
      "Action prob: [1.0000000e+00 4.7692703e-18], Action: 0, state: 2\n",
      "[1.00000000e+00 1.12458645e-17]\n",
      "Action prob: [1.00000000e+00 1.12458645e-17], Action: 0, state: 2\n",
      "[1.0000000e+00 2.5741437e-18]\n",
      "Action prob: [1.0000000e+00 2.5741437e-18], Action: 0, state: 3\n",
      "[1.0000000e+00 1.3706767e-21]\n",
      "Action prob: [1.0000000e+00 1.3706767e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8671725e-20]\n",
      "Action prob: [1.0000000e+00 1.8671725e-20], Action: 0, state: 8\n",
      "[1.000000e+00 6.717778e-17]\n",
      "Action prob: [1.000000e+00 6.717778e-17], Action: 0, state: 8\n",
      "[1.000000e+00 7.778995e-20]\n",
      "Action prob: [1.000000e+00 7.778995e-20], Action: 0, state: 8\n",
      "[1.000000e+00 3.483829e-20]\n",
      "Action prob: [1.000000e+00 3.483829e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1181278e-16]\n",
      "Action prob: [1.0000000e+00 1.1181278e-16], Action: 0, state: 8\n",
      "[1.0000000e+00 5.6239725e-17]\n",
      "Action prob: [1.0000000e+00 5.6239725e-17], Action: 0, state: 8\n",
      "[1.0000e+00 8.1383e-21]\n",
      "Action prob: [1.0000e+00 8.1383e-21], Action: 0, state: 8\n",
      "[1.000000e+00 6.776667e-17]\n",
      "Action prob: [1.000000e+00 6.776667e-17], Action: 0, state: 8\n",
      "[1.000000e+00 6.751499e-20]\n",
      "Action prob: [1.000000e+00 6.751499e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9151645e-17]\n",
      "Action prob: [1.0000000e+00 2.9151645e-17], Action: 0, state: 8\n",
      "[1.0000e+00 6.0557e-20]\n",
      "Action prob: [1.0000e+00 6.0557e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3223446e-21]\n",
      "Action prob: [1.0000000e+00 5.3223446e-21], Action: 0, state: 8\n",
      "[1.00000e+00 3.01071e-24]\n",
      "Action prob: [1.00000e+00 3.01071e-24], Action: 0, state: 8\n",
      "[1.000000e+00 3.560071e-20]\n",
      "Action prob: [1.000000e+00 3.560071e-20], Action: 0, state: 8\n",
      "[1.00000e+00 4.90598e-21]\n",
      "Action prob: [1.00000e+00 4.90598e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 4.6395405e-21]\n",
      "Action prob: [1.0000000e+00 4.6395405e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2602001e-21]\n",
      "Action prob: [1.0000000e+00 2.2602001e-21], Action: 0, state: 8\n",
      "[1.000000e+00 6.423703e-19]\n",
      "Action prob: [1.000000e+00 6.423703e-19], Action: 0, state: 8\n",
      "[1.000000e+00 5.985776e-24]\n",
      "Action prob: [1.000000e+00 5.985776e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 7.6129426e-23]\n",
      "Action prob: [1.0000000e+00 7.6129426e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5689078e-20]\n",
      "Action prob: [1.0000000e+00 1.5689078e-20], Action: 0, state: 8\n",
      "[1.000000e+00 5.461777e-20]\n",
      "Action prob: [1.000000e+00 5.461777e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0551522e-21]\n",
      "Action prob: [1.0000000e+00 1.0551522e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 9.1442924e-17]\n",
      "Action prob: [1.0000000e+00 9.1442924e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0954379e-21]\n",
      "Action prob: [1.0000000e+00 3.0954379e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7250829e-18]\n",
      "Action prob: [1.0000000e+00 1.7250829e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3458227e-21]\n",
      "Action prob: [1.0000000e+00 1.3458227e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1398655e-20]\n",
      "Action prob: [1.0000000e+00 1.1398655e-20], Action: 0, state: 8\n",
      "[1.000000e+00 6.182162e-20]\n",
      "Action prob: [1.000000e+00 6.182162e-20], Action: 0, state: 8\n",
      "[1.000000e+00 3.978495e-18]\n",
      "Action prob: [1.000000e+00 3.978495e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3023623e-21]\n",
      "Action prob: [1.0000000e+00 3.3023623e-21], Action: 0, state: 8\n",
      "[1.000000e+00 7.985989e-18]\n",
      "Action prob: [1.000000e+00 7.985989e-18], Action: 0, state: 8\n",
      "[1.000000e+00 1.375541e-16]\n",
      "Action prob: [1.000000e+00 1.375541e-16], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3793137e-16]\n",
      "Action prob: [1.0000000e+00 1.3793137e-16], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -96300, loss is -0.0\n",
      "[1.0000000e+00 6.4253694e-19]\n",
      "Action prob: [1.0000000e+00 6.4253694e-19], Action: 0, state: 0\n",
      "[1.0000000e+00 3.2741424e-19]\n",
      "Action prob: [1.0000000e+00 3.2741424e-19], Action: 0, state: 1\n",
      "[1.000000e+00 4.979649e-20]\n",
      "Action prob: [1.000000e+00 4.979649e-20], Action: 0, state: 1\n",
      "[1.0000000e+00 2.8353845e-18]\n",
      "Action prob: [1.0000000e+00 2.8353845e-18], Action: 0, state: 1\n",
      "[1.000000e+00 4.392935e-19]\n",
      "Action prob: [1.000000e+00 4.392935e-19], Action: 0, state: 2\n",
      "[1.0000000e+00 1.9324877e-18]\n",
      "Action prob: [1.0000000e+00 1.9324877e-18], Action: 0, state: 3\n",
      "[1.0000000e+00 5.8337123e-21]\n",
      "Action prob: [1.0000000e+00 5.8337123e-21], Action: 0, state: 3\n",
      "[1.0000000e+00 2.2236388e-22]\n",
      "Action prob: [1.0000000e+00 2.2236388e-22], Action: 0, state: 3\n",
      "[1.0000000e+00 6.1333093e-18]\n",
      "Action prob: [1.0000000e+00 6.1333093e-18], Action: 0, state: 3\n",
      "[1.000000e+00 4.577516e-22]\n",
      "Action prob: [1.000000e+00 4.577516e-22], Action: 0, state: 3\n",
      "[1.000000e+00 3.168823e-19]\n",
      "Action prob: [1.000000e+00 3.168823e-19], Action: 0, state: 3\n",
      "[1.0000000e+00 2.1743834e-22]\n",
      "Action prob: [1.0000000e+00 2.1743834e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0262112e-18]\n",
      "Action prob: [1.0000000e+00 1.0262112e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6507829e-18]\n",
      "Action prob: [1.0000000e+00 1.6507829e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 5.9687843e-18]\n",
      "Action prob: [1.0000000e+00 5.9687843e-18], Action: 0, state: 8\n",
      "[1.000000e+00 3.707391e-17]\n",
      "Action prob: [1.000000e+00 3.707391e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 8.6838875e-21]\n",
      "Action prob: [1.0000000e+00 8.6838875e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6243055e-24]\n",
      "Action prob: [1.0000000e+00 2.6243055e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3626948e-21]\n",
      "Action prob: [1.0000000e+00 1.3626948e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9831724e-18]\n",
      "Action prob: [1.0000000e+00 3.9831724e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 6.0512724e-18]\n",
      "Action prob: [1.0000000e+00 6.0512724e-18], Action: 0, state: 8\n",
      "[1.000000e+00 5.897446e-18]\n",
      "Action prob: [1.000000e+00 5.897446e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7485706e-17]\n",
      "Action prob: [1.0000000e+00 1.7485706e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2206339e-17]\n",
      "Action prob: [1.0000000e+00 1.2206339e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8732666e-17]\n",
      "Action prob: [1.0000000e+00 3.8732666e-17], Action: 0, state: 8\n",
      "[1.000000e+00 7.706522e-18]\n",
      "Action prob: [1.000000e+00 7.706522e-18], Action: 0, state: 8\n",
      "[1.000000e+00 4.476018e-22]\n",
      "Action prob: [1.000000e+00 4.476018e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8910765e-22]\n",
      "Action prob: [1.0000000e+00 1.8910765e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 8.2572056e-18]\n",
      "Action prob: [1.0000000e+00 8.2572056e-18], Action: 0, state: 8\n",
      "[1.00000e+00 8.64091e-18]\n",
      "Action prob: [1.00000e+00 8.64091e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6546633e-22]\n",
      "Action prob: [1.0000000e+00 1.6546633e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3682496e-18]\n",
      "Action prob: [1.0000000e+00 1.3682496e-18], Action: 0, state: 8\n",
      "[1.000000e+00 7.252086e-22]\n",
      "Action prob: [1.000000e+00 7.252086e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 8.0373163e-22]\n",
      "Action prob: [1.0000000e+00 8.0373163e-22], Action: 0, state: 8\n",
      "[1.000000e+00 1.148196e-21]\n",
      "Action prob: [1.000000e+00 1.148196e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9227874e-20]\n",
      "Action prob: [1.0000000e+00 2.9227874e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1486537e-18]\n",
      "Action prob: [1.0000000e+00 3.1486537e-18], Action: 0, state: 8\n",
      "[1.00000000e+00 1.24973105e-20]\n",
      "Action prob: [1.00000000e+00 1.24973105e-20], Action: 0, state: 8\n",
      "[1.000000e+00 7.034895e-21]\n",
      "Action prob: [1.000000e+00 7.034895e-21], Action: 0, state: 8\n",
      "[1.000000e+00 6.676992e-20]\n",
      "Action prob: [1.000000e+00 6.676992e-20], Action: 0, state: 8\n",
      "[1.000000e+00 9.160954e-23]\n",
      "Action prob: [1.000000e+00 9.160954e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5978711e-22]\n",
      "Action prob: [1.0000000e+00 3.5978711e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8129381e-22]\n",
      "Action prob: [1.0000000e+00 2.8129381e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0806577e-17]\n",
      "Action prob: [1.0000000e+00 2.0806577e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3456565e-18]\n",
      "Action prob: [1.0000000e+00 3.3456565e-18], Action: 0, state: 8\n",
      "[1.000000e+00 8.430896e-18]\n",
      "Action prob: [1.000000e+00 8.430896e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1059871e-17]\n",
      "Action prob: [1.0000000e+00 2.1059871e-17], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6296106e-21]\n",
      "Action prob: [1.0000000e+00 2.6296106e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5430203e-24]\n",
      "Action prob: [1.0000000e+00 1.5430203e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 7.7658825e-22]\n",
      "Action prob: [1.0000000e+00 7.7658825e-22], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -113500, loss is -0.0\n",
      "[1.0000000e+00 4.8636646e-20]\n",
      "Action prob: [1.0000000e+00 4.8636646e-20], Action: 0, state: 0\n",
      "[1.0000000e+00 1.6522996e-20]\n",
      "Action prob: [1.0000000e+00 1.6522996e-20], Action: 0, state: 1\n",
      "[1.0000000e+00 1.4053356e-20]\n",
      "Action prob: [1.0000000e+00 1.4053356e-20], Action: 0, state: 1\n",
      "[1.0000000e+00 2.3902098e-20]\n",
      "Action prob: [1.0000000e+00 2.3902098e-20], Action: 0, state: 2\n",
      "[1.0000000e+00 5.7719314e-21]\n",
      "Action prob: [1.0000000e+00 5.7719314e-21], Action: 0, state: 2\n",
      "[1.0000000e+00 1.1768436e-19]\n",
      "Action prob: [1.0000000e+00 1.1768436e-19], Action: 0, state: 2\n",
      "[1.000000e+00 1.761901e-18]\n",
      "Action prob: [1.000000e+00 1.761901e-18], Action: 0, state: 2\n",
      "[1.0000000e+00 6.0278383e-19]\n",
      "Action prob: [1.0000000e+00 6.0278383e-19], Action: 0, state: 2\n",
      "[1.0000000e+00 7.6744783e-20]\n",
      "Action prob: [1.0000000e+00 7.6744783e-20], Action: 0, state: 2\n",
      "[1.0000000e+00 1.5229836e-19]\n",
      "Action prob: [1.0000000e+00 1.5229836e-19], Action: 0, state: 2\n",
      "[1.0000000e+00 2.5584777e-20]\n",
      "Action prob: [1.0000000e+00 2.5584777e-20], Action: 0, state: 2\n",
      "[1.0000000e+00 1.3834588e-19]\n",
      "Action prob: [1.0000000e+00 1.3834588e-19], Action: 0, state: 3\n",
      "[1.000000e+00 1.825229e-19]\n",
      "Action prob: [1.000000e+00 1.825229e-19], Action: 0, state: 3\n",
      "[1.0000000e+00 4.4568524e-21]\n",
      "Action prob: [1.0000000e+00 4.4568524e-21], Action: 0, state: 3\n",
      "[1.0000000e+00 8.2897725e-19]\n",
      "Action prob: [1.0000000e+00 8.2897725e-19], Action: 0, state: 3\n",
      "[1.0000000e+00 1.1123276e-19]\n",
      "Action prob: [1.0000000e+00 1.1123276e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1470364e-20]\n",
      "Action prob: [1.0000000e+00 1.1470364e-20], Action: 0, state: 8\n",
      "[1.000000e+00 3.981896e-18]\n",
      "Action prob: [1.000000e+00 3.981896e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8238816e-23]\n",
      "Action prob: [1.0000000e+00 2.8238816e-23], Action: 0, state: 8\n",
      "[1.000000e+00 4.294261e-22]\n",
      "Action prob: [1.000000e+00 4.294261e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 5.1254773e-23]\n",
      "Action prob: [1.0000000e+00 5.1254773e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1485527e-21]\n",
      "Action prob: [1.0000000e+00 3.1485527e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5830432e-18]\n",
      "Action prob: [1.0000000e+00 1.5830432e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1538924e-22]\n",
      "Action prob: [1.0000000e+00 4.1538924e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6529048e-20]\n",
      "Action prob: [1.0000000e+00 1.6529048e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2590967e-21]\n",
      "Action prob: [1.0000000e+00 2.2590967e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2871202e-22]\n",
      "Action prob: [1.0000000e+00 1.2871202e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7908246e-22]\n",
      "Action prob: [1.0000000e+00 1.7908246e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 3.7359097e-26]\n",
      "Action prob: [1.0000000e+00 3.7359097e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2146969e-18]\n",
      "Action prob: [1.0000000e+00 1.2146969e-18], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3797807e-24]\n",
      "Action prob: [1.0000000e+00 3.3797807e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3219876e-21]\n",
      "Action prob: [1.0000000e+00 4.3219876e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 6.2851324e-25]\n",
      "Action prob: [1.0000000e+00 6.2851324e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 3.7383227e-24]\n",
      "Action prob: [1.0000000e+00 3.7383227e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2151354e-21]\n",
      "Action prob: [1.0000000e+00 1.2151354e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 7.8330975e-21]\n",
      "Action prob: [1.0000000e+00 7.8330975e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 6.6843573e-20]\n",
      "Action prob: [1.0000000e+00 6.6843573e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8301066e-22]\n",
      "Action prob: [1.0000000e+00 1.8301066e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3382006e-20]\n",
      "Action prob: [1.0000000e+00 1.3382006e-20], Action: 0, state: 8\n",
      "[1.000000e+00 1.145307e-24]\n",
      "Action prob: [1.000000e+00 1.145307e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9553517e-23]\n",
      "Action prob: [1.0000000e+00 1.9553517e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9930995e-19]\n",
      "Action prob: [1.0000000e+00 4.9930995e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3047392e-23]\n",
      "Action prob: [1.0000000e+00 4.3047392e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1646031e-18]\n",
      "Action prob: [1.0000000e+00 1.1646031e-18], Action: 0, state: 8\n",
      "[1.000000e+00 3.762173e-23]\n",
      "Action prob: [1.000000e+00 3.762173e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 5.4407786e-26]\n",
      "Action prob: [1.0000000e+00 5.4407786e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4970405e-18]\n",
      "Action prob: [1.0000000e+00 2.4970405e-18], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 3.1885046e-18]\n",
      "Action prob: [1.0000000e+00 3.1885046e-18], Action: 0, state: 8\n",
      "[1.000000e+00 4.065281e-19]\n",
      "Action prob: [1.000000e+00 4.065281e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3700086e-24]\n",
      "Action prob: [1.0000000e+00 4.3700086e-24], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -97800, loss is -0.0\n",
      "[1.0000000e+00 2.0120896e-21]\n",
      "Action prob: [1.0000000e+00 2.0120896e-21], Action: 0, state: 0\n",
      "[1.0000000e+00 6.3490276e-21]\n",
      "Action prob: [1.0000000e+00 6.3490276e-21], Action: 0, state: 1\n",
      "[1.000000e+00 2.863469e-20]\n",
      "Action prob: [1.000000e+00 2.863469e-20], Action: 0, state: 1\n",
      "[1.0000000e+00 7.9093936e-21]\n",
      "Action prob: [1.0000000e+00 7.9093936e-21], Action: 0, state: 1\n",
      "[1.0000000e+00 3.8886132e-20]\n",
      "Action prob: [1.0000000e+00 3.8886132e-20], Action: 0, state: 1\n",
      "[1.000000e+00 5.985554e-22]\n",
      "Action prob: [1.000000e+00 5.985554e-22], Action: 0, state: 2\n",
      "[1.0000000e+00 2.5561753e-20]\n",
      "Action prob: [1.0000000e+00 2.5561753e-20], Action: 0, state: 2\n",
      "[1.000000e+00 9.712664e-21]\n",
      "Action prob: [1.000000e+00 9.712664e-21], Action: 0, state: 2\n",
      "[1.0000000e+00 3.1761916e-20]\n",
      "Action prob: [1.0000000e+00 3.1761916e-20], Action: 0, state: 3\n",
      "[1.000000e+00 8.506104e-25]\n",
      "Action prob: [1.000000e+00 8.506104e-25], Action: 0, state: 8\n",
      "[1.000000e+00 1.546053e-26]\n",
      "Action prob: [1.000000e+00 1.546053e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5854815e-25]\n",
      "Action prob: [1.0000000e+00 2.5854815e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4672002e-22]\n",
      "Action prob: [1.0000000e+00 3.4672002e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8774643e-19]\n",
      "Action prob: [1.0000000e+00 2.8774643e-19], Action: 0, state: 8\n",
      "[1.000000e+00 8.537348e-24]\n",
      "Action prob: [1.000000e+00 8.537348e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0745142e-23]\n",
      "Action prob: [1.0000000e+00 1.0745142e-23], Action: 0, state: 8\n",
      "[1.0000e+00 8.6059e-20]\n",
      "Action prob: [1.0000e+00 8.6059e-20], Action: 0, state: 8\n",
      "[1.00000e+00 6.81491e-23]\n",
      "Action prob: [1.00000e+00 6.81491e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 5.7021974e-24]\n",
      "Action prob: [1.0000000e+00 5.7021974e-24], Action: 0, state: 8\n",
      "[1.000000e+00 6.503557e-29]\n",
      "Action prob: [1.000000e+00 6.503557e-29], Action: 0, state: 8\n",
      "[1.000000e+00 4.475977e-25]\n",
      "Action prob: [1.000000e+00 4.475977e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8950368e-19]\n",
      "Action prob: [1.0000000e+00 1.8950368e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3234006e-23]\n",
      "Action prob: [1.0000000e+00 3.3234006e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7610236e-23]\n",
      "Action prob: [1.0000000e+00 4.7610236e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 6.0191867e-23]\n",
      "Action prob: [1.0000000e+00 6.0191867e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 4.4757424e-23]\n",
      "Action prob: [1.0000000e+00 4.4757424e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0193996e-24]\n",
      "Action prob: [1.0000000e+00 1.0193996e-24], Action: 0, state: 8\n",
      "[1.000000e+00 5.753786e-24]\n",
      "Action prob: [1.000000e+00 5.753786e-24], Action: 0, state: 8\n",
      "[1.000000e+00 9.701975e-26]\n",
      "Action prob: [1.000000e+00 9.701975e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5964293e-20]\n",
      "Action prob: [1.0000000e+00 2.5964293e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 5.6618106e-26]\n",
      "Action prob: [1.0000000e+00 5.6618106e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8343053e-19]\n",
      "Action prob: [1.0000000e+00 3.8343053e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8831865e-22]\n",
      "Action prob: [1.0000000e+00 1.8831865e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0455703e-20]\n",
      "Action prob: [1.0000000e+00 2.0455703e-20], Action: 0, state: 8\n",
      "[1.000000e+00 4.323467e-23]\n",
      "Action prob: [1.000000e+00 4.323467e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 4.8583353e-23]\n",
      "Action prob: [1.0000000e+00 4.8583353e-23], Action: 0, state: 8\n",
      "[1.000000e+00 7.208555e-24]\n",
      "Action prob: [1.000000e+00 7.208555e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 5.2247343e-23]\n",
      "Action prob: [1.0000000e+00 5.2247343e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1854857e-19]\n",
      "Action prob: [1.0000000e+00 1.1854857e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5644076e-19]\n",
      "Action prob: [1.0000000e+00 3.5644076e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3190743e-22]\n",
      "Action prob: [1.0000000e+00 5.3190743e-22], Action: 0, state: 8\n",
      "[1.000000e+00 9.873739e-23]\n",
      "Action prob: [1.000000e+00 9.873739e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6655265e-19]\n",
      "Action prob: [1.0000000e+00 1.6655265e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2569612e-28]\n",
      "Action prob: [1.0000000e+00 2.2569612e-28], Action: 0, state: 8\n",
      "[1.00000e+00 3.01848e-19]\n",
      "Action prob: [1.00000e+00 3.01848e-19], Action: 0, state: 8\n",
      "[1.000000e+00 4.352767e-19]\n",
      "Action prob: [1.000000e+00 4.352767e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1012772e-24]\n",
      "Action prob: [1.0000000e+00 2.1012772e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0280849e-24]\n",
      "Action prob: [1.0000000e+00 1.0280849e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3949236e-23]\n",
      "Action prob: [1.0000000e+00 1.3949236e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 4.6057587e-19]\n",
      "Action prob: [1.0000000e+00 4.6057587e-19], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -119500, loss is -0.0\n",
      "[1.0000000e+00 7.8759735e-21]\n",
      "Action prob: [1.0000000e+00 7.8759735e-21], Action: 0, state: 0\n",
      "[1.0000000e+00 4.4741914e-22]\n",
      "Action prob: [1.0000000e+00 4.4741914e-22], Action: 0, state: 1\n",
      "[1.0000000e+00 1.3677309e-21]\n",
      "Action prob: [1.0000000e+00 1.3677309e-21], Action: 0, state: 2\n",
      "[1.00000e+00 1.02418e-21]\n",
      "Action prob: [1.00000e+00 1.02418e-21], Action: 0, state: 3\n",
      "[1.00000e+00 4.89807e-21]\n",
      "Action prob: [1.00000e+00 4.89807e-21], Action: 0, state: 3\n",
      "[1.0000000e+00 5.4937844e-22]\n",
      "Action prob: [1.0000000e+00 5.4937844e-22], Action: 0, state: 3\n",
      "[1.0000000e+00 4.2878344e-19]\n",
      "Action prob: [1.0000000e+00 4.2878344e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 6.1534996e-29]\n",
      "Action prob: [1.0000000e+00 6.1534996e-29], Action: 0, state: 8\n",
      "[1.000000e+00 2.258602e-24]\n",
      "Action prob: [1.000000e+00 2.258602e-24], Action: 0, state: 8\n",
      "[1.000000e+00 5.466923e-21]\n",
      "Action prob: [1.000000e+00 5.466923e-21], Action: 0, state: 8\n",
      "[1.000000e+00 9.922987e-21]\n",
      "Action prob: [1.000000e+00 9.922987e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 5.4194803e-20]\n",
      "Action prob: [1.0000000e+00 5.4194803e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1560172e-24]\n",
      "Action prob: [1.0000000e+00 1.1560172e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7432696e-24]\n",
      "Action prob: [1.0000000e+00 1.7432696e-24], Action: 0, state: 8\n",
      "[1.000000e+00 6.618274e-24]\n",
      "Action prob: [1.000000e+00 6.618274e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8067214e-24]\n",
      "Action prob: [1.0000000e+00 1.8067214e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1223593e-24]\n",
      "Action prob: [1.0000000e+00 2.1223593e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0163097e-23]\n",
      "Action prob: [1.0000000e+00 3.0163097e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4695778e-23]\n",
      "Action prob: [1.0000000e+00 1.4695778e-23], Action: 0, state: 8\n",
      "[1.000000e+00 1.268664e-23]\n",
      "Action prob: [1.000000e+00 1.268664e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9388683e-25]\n",
      "Action prob: [1.0000000e+00 4.9388683e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5230212e-23]\n",
      "Action prob: [1.0000000e+00 1.5230212e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0511492e-24]\n",
      "Action prob: [1.0000000e+00 1.0511492e-24], Action: 0, state: 8\n",
      "[1.000000e+00 2.869377e-25]\n",
      "Action prob: [1.000000e+00 2.869377e-25], Action: 0, state: 8\n",
      "[1.000000e+00 6.112416e-22]\n",
      "Action prob: [1.000000e+00 6.112416e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 8.2696594e-25]\n",
      "Action prob: [1.0000000e+00 8.2696594e-25], Action: 0, state: 8\n",
      "[1.00000e+00 5.31412e-24]\n",
      "Action prob: [1.00000e+00 5.31412e-24], Action: 0, state: 8\n",
      "[1.000000e+00 1.478244e-28]\n",
      "Action prob: [1.000000e+00 1.478244e-28], Action: 0, state: 8\n",
      "[1.000000e+00 6.001244e-20]\n",
      "Action prob: [1.000000e+00 6.001244e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2197207e-24]\n",
      "Action prob: [1.0000000e+00 4.2197207e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3880453e-26]\n",
      "Action prob: [1.0000000e+00 4.3880453e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 6.7110313e-20]\n",
      "Action prob: [1.0000000e+00 6.7110313e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 8.1929895e-23]\n",
      "Action prob: [1.0000000e+00 8.1929895e-23], Action: 0, state: 8\n",
      "[1.00000e+00 6.04144e-20]\n",
      "Action prob: [1.00000e+00 6.04144e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6721535e-19]\n",
      "Action prob: [1.0000000e+00 1.6721535e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 4.6311874e-24]\n",
      "Action prob: [1.0000000e+00 4.6311874e-24], Action: 0, state: 8\n",
      "[1.00000e+00 7.10473e-25]\n",
      "Action prob: [1.00000e+00 7.10473e-25], Action: 0, state: 8\n",
      "[1.000000e+00 5.521425e-25]\n",
      "Action prob: [1.000000e+00 5.521425e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2398833e-19]\n",
      "Action prob: [1.0000000e+00 1.2398833e-19], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8462722e-20]\n",
      "Action prob: [1.0000000e+00 3.8462722e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6689574e-23]\n",
      "Action prob: [1.0000000e+00 1.6689574e-23], Action: 0, state: 8\n",
      "[1.000000e+00 8.410184e-24]\n",
      "Action prob: [1.000000e+00 8.410184e-24], Action: 0, state: 8\n",
      "[1.000000e+00 1.019129e-21]\n",
      "Action prob: [1.000000e+00 1.019129e-21], Action: 0, state: 8\n",
      "[1.000000e+00 7.121934e-25]\n",
      "Action prob: [1.000000e+00 7.121934e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4507283e-24]\n",
      "Action prob: [1.0000000e+00 1.4507283e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3013102e-25]\n",
      "Action prob: [1.0000000e+00 3.3013102e-25], Action: 0, state: 8\n",
      "[1.000000e+00 9.106139e-25]\n",
      "Action prob: [1.000000e+00 9.106139e-25], Action: 0, state: 8\n",
      "[1.00000e+00 9.00782e-23]\n",
      "Action prob: [1.00000e+00 9.00782e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5212536e-20]\n",
      "Action prob: [1.0000000e+00 3.5212536e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2583917e-20]\n",
      "Action prob: [1.0000000e+00 3.2583917e-20], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -131800, loss is -0.0\n",
      "[1.0000000e+00 2.5742367e-22]\n",
      "Action prob: [1.0000000e+00 2.5742367e-22], Action: 0, state: 0\n",
      "[1.0000000e+00 2.9227382e-23]\n",
      "Action prob: [1.0000000e+00 2.9227382e-23], Action: 0, state: 0\n",
      "[1.0000000e+00 1.9254859e-22]\n",
      "Action prob: [1.0000000e+00 1.9254859e-22], Action: 0, state: 0\n",
      "[1.000000e+00 2.432427e-22]\n",
      "Action prob: [1.000000e+00 2.432427e-22], Action: 0, state: 0\n",
      "[1.000000e+00 1.002808e-22]\n",
      "Action prob: [1.000000e+00 1.002808e-22], Action: 0, state: 1\n",
      "[1.0000000e+00 6.8973398e-25]\n",
      "Action prob: [1.0000000e+00 6.8973398e-25], Action: 0, state: 2\n",
      "[1.000000e+00 3.351217e-23]\n",
      "Action prob: [1.000000e+00 3.351217e-23], Action: 0, state: 2\n",
      "[1.0000000e+00 1.1726339e-22]\n",
      "Action prob: [1.0000000e+00 1.1726339e-22], Action: 0, state: 2\n",
      "[1.000000e+00 3.228014e-23]\n",
      "Action prob: [1.000000e+00 3.228014e-23], Action: 0, state: 2\n",
      "[1.0000000e+00 2.9283965e-23]\n",
      "Action prob: [1.0000000e+00 2.9283965e-23], Action: 0, state: 2\n",
      "[1.000000e+00 9.553256e-22]\n",
      "Action prob: [1.000000e+00 9.553256e-22], Action: 0, state: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 5.039897e-23]\n",
      "Action prob: [1.000000e+00 5.039897e-23], Action: 0, state: 2\n",
      "[1.0000000e+00 1.3747605e-22]\n",
      "Action prob: [1.0000000e+00 1.3747605e-22], Action: 0, state: 2\n",
      "[1.0000000e+00 7.9351077e-22]\n",
      "Action prob: [1.0000000e+00 7.9351077e-22], Action: 0, state: 3\n",
      "[1.0000000e+00 1.2841586e-21]\n",
      "Action prob: [1.0000000e+00 1.2841586e-21], Action: 0, state: 3\n",
      "[1.000000e+00 4.073238e-22]\n",
      "Action prob: [1.000000e+00 4.073238e-22], Action: 0, state: 3\n",
      "[1.000000e+00 7.296223e-25]\n",
      "Action prob: [1.000000e+00 7.296223e-25], Action: 0, state: 3\n",
      "[1.0000000e+00 1.3861177e-24]\n",
      "Action prob: [1.0000000e+00 1.3861177e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7498492e-20]\n",
      "Action prob: [1.0000000e+00 1.7498492e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3734564e-24]\n",
      "Action prob: [1.0000000e+00 3.3734564e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0939875e-24]\n",
      "Action prob: [1.0000000e+00 2.0939875e-24], Action: 0, state: 8\n",
      "[1.000000e+00 7.632112e-21]\n",
      "Action prob: [1.000000e+00 7.632112e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6623421e-24]\n",
      "Action prob: [1.0000000e+00 1.6623421e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 5.7711635e-20]\n",
      "Action prob: [1.0000000e+00 5.7711635e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0475285e-28]\n",
      "Action prob: [1.0000000e+00 1.0475285e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2782218e-19]\n",
      "Action prob: [1.0000000e+00 1.2782218e-19], Action: 0, state: 8\n",
      "[1.000000e+00 1.804824e-20]\n",
      "Action prob: [1.000000e+00 1.804824e-20], Action: 0, state: 8\n",
      "[1.000000e+00 6.740331e-20]\n",
      "Action prob: [1.000000e+00 6.740331e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1222277e-20]\n",
      "Action prob: [1.0000000e+00 1.1222277e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2317975e-20]\n",
      "Action prob: [1.0000000e+00 1.2317975e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8402415e-24]\n",
      "Action prob: [1.0000000e+00 1.8402415e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1900603e-25]\n",
      "Action prob: [1.0000000e+00 4.1900603e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1890132e-20]\n",
      "Action prob: [1.0000000e+00 1.1890132e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6316444e-20]\n",
      "Action prob: [1.0000000e+00 3.6316444e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 8.1886236e-21]\n",
      "Action prob: [1.0000000e+00 8.1886236e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1326803e-20]\n",
      "Action prob: [1.0000000e+00 3.1326803e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6019855e-25]\n",
      "Action prob: [1.0000000e+00 3.6019855e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5531785e-24]\n",
      "Action prob: [1.0000000e+00 2.5531785e-24], Action: 0, state: 8\n",
      "[1.000000e+00 5.029499e-26]\n",
      "Action prob: [1.000000e+00 5.029499e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 6.1546385e-25]\n",
      "Action prob: [1.0000000e+00 6.1546385e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5400773e-20]\n",
      "Action prob: [1.0000000e+00 1.5400773e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0120455e-24]\n",
      "Action prob: [1.0000000e+00 1.0120455e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 6.1496633e-25]\n",
      "Action prob: [1.0000000e+00 6.1496633e-25], Action: 0, state: 8\n",
      "[1.000000e+00 7.289157e-25]\n",
      "Action prob: [1.000000e+00 7.289157e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2512463e-25]\n",
      "Action prob: [1.0000000e+00 2.2512463e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9847267e-24]\n",
      "Action prob: [1.0000000e+00 1.9847267e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0895816e-20]\n",
      "Action prob: [1.0000000e+00 1.0895816e-20], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2020702e-26]\n",
      "Action prob: [1.0000000e+00 3.2020702e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5568564e-26]\n",
      "Action prob: [1.0000000e+00 3.5568564e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 8.8474066e-26]\n",
      "Action prob: [1.0000000e+00 8.8474066e-26], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -89700, loss is -0.0\n",
      "[1.0000000e+00 2.8738947e-22]\n",
      "Action prob: [1.0000000e+00 2.8738947e-22], Action: 0, state: 0\n",
      "[1.0000000e+00 1.1030173e-22]\n",
      "Action prob: [1.0000000e+00 1.1030173e-22], Action: 0, state: 0\n",
      "[1.0000000e+00 4.7754708e-21]\n",
      "Action prob: [1.0000000e+00 4.7754708e-21], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2373705e-25]\n",
      "Action prob: [1.0000000e+00 1.2373705e-25], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3347107e-24]\n",
      "Action prob: [1.0000000e+00 1.3347107e-24], Action: 0, state: 9\n",
      "[1.000000e+00 8.771259e-26]\n",
      "Action prob: [1.000000e+00 8.771259e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2406654e-24]\n",
      "Action prob: [1.0000000e+00 1.2406654e-24], Action: 0, state: 9\n",
      "[1.000000e+00 4.604797e-32]\n",
      "Action prob: [1.000000e+00 4.604797e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.8993492e-20]\n",
      "Action prob: [1.0000000e+00 1.8993492e-20], Action: 0, state: 9\n",
      "[1.000000e+00 4.940241e-26]\n",
      "Action prob: [1.000000e+00 4.940241e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 5.3865894e-26]\n",
      "Action prob: [1.0000000e+00 5.3865894e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 2.3095693e-26]\n",
      "Action prob: [1.0000000e+00 2.3095693e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 2.8853643e-21]\n",
      "Action prob: [1.0000000e+00 2.8853643e-21], Action: 0, state: 9\n",
      "[1.0000000e+00 3.9599157e-26]\n",
      "Action prob: [1.0000000e+00 3.9599157e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.5899844e-26]\n",
      "Action prob: [1.0000000e+00 1.5899844e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3987268e-25]\n",
      "Action prob: [1.0000000e+00 1.3987268e-25], Action: 0, state: 9\n",
      "[1.000000e+00 4.100227e-28]\n",
      "Action prob: [1.000000e+00 4.100227e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 3.6614367e-22]\n",
      "Action prob: [1.0000000e+00 3.6614367e-22], Action: 0, state: 9\n",
      "[1.00000e+00 8.97257e-22]\n",
      "Action prob: [1.00000e+00 8.97257e-22], Action: 0, state: 9\n",
      "[1.000000e+00 4.687237e-27]\n",
      "Action prob: [1.000000e+00 4.687237e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 5.0959505e-27]\n",
      "Action prob: [1.0000000e+00 5.0959505e-27], Action: 0, state: 9\n",
      "[1.000000e+00 8.337226e-24]\n",
      "Action prob: [1.000000e+00 8.337226e-24], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1862421e-25]\n",
      "Action prob: [1.0000000e+00 1.1862421e-25], Action: 0, state: 9\n",
      "[1.0000000e+00 1.6266309e-23]\n",
      "Action prob: [1.0000000e+00 1.6266309e-23], Action: 0, state: 9\n",
      "[1.0000000e+00 2.1547583e-20]\n",
      "Action prob: [1.0000000e+00 2.1547583e-20], Action: 0, state: 9\n",
      "[1.0000000e+00 3.2901318e-26]\n",
      "Action prob: [1.0000000e+00 3.2901318e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2520654e-26]\n",
      "Action prob: [1.0000000e+00 1.2520654e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 6.2167396e-34]\n",
      "Action prob: [1.0000000e+00 6.2167396e-34], Action: 0, state: 9\n",
      "[1.000000e+00 3.869495e-20]\n",
      "Action prob: [1.000000e+00 3.869495e-20], Action: 0, state: 9\n",
      "[1.000000e+00 5.367097e-21]\n",
      "Action prob: [1.000000e+00 5.367097e-21], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1281332e-21]\n",
      "Action prob: [1.0000000e+00 1.1281332e-21], Action: 0, state: 9\n",
      "[1.000000e+00 5.845892e-23]\n",
      "Action prob: [1.000000e+00 5.845892e-23], Action: 0, state: 9\n",
      "[1.0000000e+00 1.4255944e-20]\n",
      "Action prob: [1.0000000e+00 1.4255944e-20], Action: 0, state: 9\n",
      "[1.0000000e+00 1.5280468e-26]\n",
      "Action prob: [1.0000000e+00 1.5280468e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 2.0821235e-20]\n",
      "Action prob: [1.0000000e+00 2.0821235e-20], Action: 0, state: 9\n",
      "[1.0000000e+00 2.9098033e-21]\n",
      "Action prob: [1.0000000e+00 2.9098033e-21], Action: 0, state: 9\n",
      "[1.000000e+00 8.802516e-22]\n",
      "Action prob: [1.000000e+00 8.802516e-22], Action: 0, state: 9\n",
      "[1.0000000e+00 3.1010163e-21]\n",
      "Action prob: [1.0000000e+00 3.1010163e-21], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2179942e-21]\n",
      "Action prob: [1.0000000e+00 1.2179942e-21], Action: 0, state: 9\n",
      "[1.000000e+00 2.268028e-26]\n",
      "Action prob: [1.000000e+00 2.268028e-26], Action: 0, state: 9\n",
      "[1.000000e+00 6.770675e-24]\n",
      "Action prob: [1.000000e+00 6.770675e-24], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1858922e-20]\n",
      "Action prob: [1.0000000e+00 1.1858922e-20], Action: 0, state: 9\n",
      "[1.0000000e+00 3.4463277e-21]\n",
      "Action prob: [1.0000000e+00 3.4463277e-21], Action: 0, state: 9\n",
      "[1.0000000e+00 4.5561707e-24]\n",
      "Action prob: [1.0000000e+00 4.5561707e-24], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2665714e-21]\n",
      "Action prob: [1.0000000e+00 1.2665714e-21], Action: 0, state: 9\n",
      "[1.000000e+00 5.437925e-30]\n",
      "Action prob: [1.000000e+00 5.437925e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 2.3485274e-26]\n",
      "Action prob: [1.0000000e+00 2.3485274e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2956284e-21]\n",
      "Action prob: [1.0000000e+00 1.2956284e-21], Action: 0, state: 9\n",
      "[1.000000e+00 4.609712e-27]\n",
      "Action prob: [1.000000e+00 4.609712e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7852202e-27]\n",
      "Action prob: [1.0000000e+00 1.7852202e-27], Action: 0, state: 9\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., -0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -48000, loss is -0.0\n",
      "[1.000000e+00 1.029215e-24]\n",
      "Action prob: [1.000000e+00 1.029215e-24], Action: 0, state: 0\n",
      "[1.0000000e+00 2.4760594e-25]\n",
      "Action prob: [1.0000000e+00 2.4760594e-25], Action: 0, state: 0\n",
      "[1.0000000e+00 1.6344183e-23]\n",
      "Action prob: [1.0000000e+00 1.6344183e-23], Action: 0, state: 0\n",
      "[1.000000e+00 5.640327e-23]\n",
      "Action prob: [1.000000e+00 5.640327e-23], Action: 0, state: 0\n",
      "[1.000000e+00 4.868425e-24]\n",
      "Action prob: [1.000000e+00 4.868425e-24], Action: 0, state: 1\n",
      "[1.0000000e+00 1.6979838e-23]\n",
      "Action prob: [1.0000000e+00 1.6979838e-23], Action: 0, state: 1\n",
      "[1.0000000e+00 2.6619045e-23]\n",
      "Action prob: [1.0000000e+00 2.6619045e-23], Action: 0, state: 1\n",
      "[1.0000000e+00 2.7135036e-24]\n",
      "Action prob: [1.0000000e+00 2.7135036e-24], Action: 0, state: 1\n",
      "[1.0000000e+00 2.1746145e-23]\n",
      "Action prob: [1.0000000e+00 2.1746145e-23], Action: 0, state: 2\n",
      "[1.0000000e+00 1.4672196e-23]\n",
      "Action prob: [1.0000000e+00 1.4672196e-23], Action: 0, state: 2\n",
      "[1.0000000e+00 1.6432778e-22]\n",
      "Action prob: [1.0000000e+00 1.6432778e-22], Action: 0, state: 2\n",
      "[1.0000000e+00 3.2870992e-24]\n",
      "Action prob: [1.0000000e+00 3.2870992e-24], Action: 0, state: 3\n",
      "[1.000000e+00 9.172784e-28]\n",
      "Action prob: [1.000000e+00 9.172784e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 6.5635076e-26]\n",
      "Action prob: [1.0000000e+00 6.5635076e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1933467e-27]\n",
      "Action prob: [1.0000000e+00 3.1933467e-27], Action: 0, state: 8\n",
      "[1.000000e+00 5.405094e-26]\n",
      "Action prob: [1.000000e+00 5.405094e-26], Action: 0, state: 8\n",
      "[1.000000e+00 9.729767e-27]\n",
      "Action prob: [1.000000e+00 9.729767e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 6.7951327e-22]\n",
      "Action prob: [1.0000000e+00 6.7951327e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7996575e-31]\n",
      "Action prob: [1.0000000e+00 1.7996575e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 3.7976815e-26]\n",
      "Action prob: [1.0000000e+00 3.7976815e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0829581e-27]\n",
      "Action prob: [1.0000000e+00 2.0829581e-27], Action: 0, state: 8\n",
      "[1.000000e+00 8.208078e-28]\n",
      "Action prob: [1.000000e+00 8.208078e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 7.3535284e-26]\n",
      "Action prob: [1.0000000e+00 7.3535284e-26], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 1.8389143e-25]\n",
      "Action prob: [1.0000000e+00 1.8389143e-25], Action: 0, state: 8\n",
      "[1.000000e+00 6.803251e-22]\n",
      "Action prob: [1.000000e+00 6.803251e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2079127e-26]\n",
      "Action prob: [1.0000000e+00 2.2079127e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2050393e-29]\n",
      "Action prob: [1.0000000e+00 4.2050393e-29], Action: 0, state: 8\n",
      "[1.000000e+00 1.753219e-25]\n",
      "Action prob: [1.000000e+00 1.753219e-25], Action: 0, state: 8\n",
      "[1.000000e+00 1.853843e-21]\n",
      "Action prob: [1.000000e+00 1.853843e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8993317e-23]\n",
      "Action prob: [1.0000000e+00 1.8993317e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5186743e-25]\n",
      "Action prob: [1.0000000e+00 1.5186743e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3977403e-22]\n",
      "Action prob: [1.0000000e+00 4.3977403e-22], Action: 0, state: 8\n",
      "[1.000000e+00 9.137821e-29]\n",
      "Action prob: [1.000000e+00 9.137821e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 4.4076413e-33]\n",
      "Action prob: [1.0000000e+00 4.4076413e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9140614e-22]\n",
      "Action prob: [1.0000000e+00 1.9140614e-22], Action: 0, state: 8\n",
      "[1.000000e+00 1.085325e-21]\n",
      "Action prob: [1.000000e+00 1.085325e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5054618e-22]\n",
      "Action prob: [1.0000000e+00 3.5054618e-22], Action: 0, state: 8\n",
      "[1.00000000e+00 1.01949535e-27]\n",
      "Action prob: [1.00000000e+00 1.01949535e-27], Action: 0, state: 8\n",
      "[1.000000e+00 3.109266e-25]\n",
      "Action prob: [1.000000e+00 3.109266e-25], Action: 0, state: 8\n",
      "[1.000000e+00 3.958353e-22]\n",
      "Action prob: [1.000000e+00 3.958353e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3992097e-26]\n",
      "Action prob: [1.0000000e+00 2.3992097e-26], Action: 0, state: 8\n",
      "[1.000000e+00 6.336058e-29]\n",
      "Action prob: [1.000000e+00 6.336058e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3078515e-27]\n",
      "Action prob: [1.0000000e+00 4.3078515e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4187915e-27]\n",
      "Action prob: [1.0000000e+00 1.4187915e-27], Action: 0, state: 8\n",
      "[1.000000e+00 8.023144e-27]\n",
      "Action prob: [1.000000e+00 8.023144e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0558846e-21]\n",
      "Action prob: [1.0000000e+00 5.0558846e-21], Action: 0, state: 8\n",
      "[1.000000e+00 4.625343e-24]\n",
      "Action prob: [1.000000e+00 4.625343e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9705647e-25]\n",
      "Action prob: [1.0000000e+00 4.9705647e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 5.1541083e-21]\n",
      "Action prob: [1.0000000e+00 5.1541083e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3787684e-21]\n",
      "Action prob: [1.0000000e+00 1.3787684e-21], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -107500, loss is -0.0\n",
      "[1.00000e+00 3.11518e-24]\n",
      "Action prob: [1.00000e+00 3.11518e-24], Action: 0, state: 0\n",
      "[1.0000000e+00 1.9125769e-25]\n",
      "Action prob: [1.0000000e+00 1.9125769e-25], Action: 0, state: 1\n",
      "[1.0000000e+00 5.0023717e-24]\n",
      "Action prob: [1.0000000e+00 5.0023717e-24], Action: 0, state: 1\n",
      "[1.0000000e+00 2.8890826e-24]\n",
      "Action prob: [1.0000000e+00 2.8890826e-24], Action: 0, state: 1\n",
      "[1.0000000e+00 2.0781924e-23]\n",
      "Action prob: [1.0000000e+00 2.0781924e-23], Action: 0, state: 1\n",
      "[1.0000000e+00 1.0913972e-24]\n",
      "Action prob: [1.0000000e+00 1.0913972e-24], Action: 0, state: 2\n",
      "[1.0000000e+00 2.1497047e-24]\n",
      "Action prob: [1.0000000e+00 2.1497047e-24], Action: 0, state: 2\n",
      "[1.0000000e+00 6.1640167e-24]\n",
      "Action prob: [1.0000000e+00 6.1640167e-24], Action: 0, state: 2\n",
      "[1.0000000e+00 3.2064387e-23]\n",
      "Action prob: [1.0000000e+00 3.2064387e-23], Action: 0, state: 2\n",
      "[1.00000000e+00 1.30796735e-23]\n",
      "Action prob: [1.00000000e+00 1.30796735e-23], Action: 0, state: 2\n",
      "[1.000000e+00 6.337355e-24]\n",
      "Action prob: [1.000000e+00 6.337355e-24], Action: 0, state: 2\n",
      "[1.0000000e+00 4.4812047e-25]\n",
      "Action prob: [1.0000000e+00 4.4812047e-25], Action: 0, state: 2\n",
      "[1.0000000e+00 1.9666624e-23]\n",
      "Action prob: [1.0000000e+00 1.9666624e-23], Action: 0, state: 2\n",
      "[1.000000e+00 8.498587e-23]\n",
      "Action prob: [1.000000e+00 8.498587e-23], Action: 0, state: 2\n",
      "[1.000000e+00 8.747752e-22]\n",
      "Action prob: [1.000000e+00 8.747752e-22], Action: 0, state: 3\n",
      "[1.0000000e+00 6.5497444e-28]\n",
      "Action prob: [1.0000000e+00 6.5497444e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.4337236e-23]\n",
      "Action prob: [1.0000000e+00 1.4337236e-23], Action: 0, state: 3\n",
      "[1.000000e+00 1.477746e-23]\n",
      "Action prob: [1.000000e+00 1.477746e-23], Action: 0, state: 3\n",
      "[1.000000e+00 2.802757e-26]\n",
      "Action prob: [1.000000e+00 2.802757e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1178088e-22]\n",
      "Action prob: [1.0000000e+00 1.1178088e-22], Action: 0, state: 8\n",
      "[1.000000e+00 7.683811e-23]\n",
      "Action prob: [1.000000e+00 7.683811e-23], Action: 0, state: 8\n",
      "[1.00000e+00 3.25617e-26]\n",
      "Action prob: [1.00000e+00 3.25617e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 6.6786923e-22]\n",
      "Action prob: [1.0000000e+00 6.6786923e-22], Action: 0, state: 8\n",
      "[1.000000e+00 8.591655e-22]\n",
      "Action prob: [1.000000e+00 8.591655e-22], Action: 0, state: 8\n",
      "[1.00000e+00 8.94725e-28]\n",
      "Action prob: [1.00000e+00 8.94725e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7977882e-27]\n",
      "Action prob: [1.0000000e+00 2.7977882e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.294828e-22]\n",
      "Action prob: [1.000000e+00 9.294828e-22], Action: 0, state: 8\n",
      "[1.00000e+00 9.92355e-22]\n",
      "Action prob: [1.00000e+00 9.92355e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 5.7659643e-22]\n",
      "Action prob: [1.0000000e+00 5.7659643e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4210166e-21]\n",
      "Action prob: [1.0000000e+00 1.4210166e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3327032e-21]\n",
      "Action prob: [1.0000000e+00 1.3327032e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 6.2448244e-22]\n",
      "Action prob: [1.0000000e+00 6.2448244e-22], Action: 0, state: 8\n",
      "[1.000000e+00 1.408378e-28]\n",
      "Action prob: [1.000000e+00 1.408378e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8928388e-27]\n",
      "Action prob: [1.0000000e+00 2.8928388e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.7621605e-22]\n",
      "Action prob: [1.0000000e+00 3.7621605e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1125921e-24]\n",
      "Action prob: [1.0000000e+00 1.1125921e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0548182e-21]\n",
      "Action prob: [1.0000000e+00 1.0548182e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 6.2727856e-21]\n",
      "Action prob: [1.0000000e+00 6.2727856e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 6.1437685e-28]\n",
      "Action prob: [1.0000000e+00 6.1437685e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0991484e-28]\n",
      "Action prob: [1.0000000e+00 3.0991484e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 6.3042606e-28]\n",
      "Action prob: [1.0000000e+00 6.3042606e-28], Action: 0, state: 8\n",
      "[1.000000e+00 7.319186e-27]\n",
      "Action prob: [1.000000e+00 7.319186e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5317546e-23]\n",
      "Action prob: [1.0000000e+00 3.5317546e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4895015e-22]\n",
      "Action prob: [1.0000000e+00 1.4895015e-22], Action: 0, state: 8\n",
      "[1.000000e+00 1.044002e-28]\n",
      "Action prob: [1.000000e+00 1.044002e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 6.6500783e-26]\n",
      "Action prob: [1.0000000e+00 6.6500783e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4091617e-25]\n",
      "Action prob: [1.0000000e+00 2.4091617e-25], Action: 0, state: 8\n",
      "[1.000000e+00 5.924977e-26]\n",
      "Action prob: [1.000000e+00 5.924977e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 5.6556734e-21]\n",
      "Action prob: [1.0000000e+00 5.6556734e-21], Action: 0, state: 8\n",
      "[1.000000e+00 5.802017e-22]\n",
      "Action prob: [1.000000e+00 5.802017e-22], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -86200, loss is -0.0\n",
      "[1.000000e+00 6.297564e-25]\n",
      "Action prob: [1.000000e+00 6.297564e-25], Action: 0, state: 0\n",
      "[1.000000e+00 4.796509e-26]\n",
      "Action prob: [1.000000e+00 4.796509e-26], Action: 0, state: 1\n",
      "[1.0000000e+00 1.3633427e-24]\n",
      "Action prob: [1.0000000e+00 1.3633427e-24], Action: 0, state: 1\n",
      "[1.0000000e+00 1.3075926e-24]\n",
      "Action prob: [1.0000000e+00 1.3075926e-24], Action: 0, state: 1\n",
      "[1.000000e+00 4.795782e-24]\n",
      "Action prob: [1.000000e+00 4.795782e-24], Action: 0, state: 2\n",
      "[1.0000000e+00 1.0087121e-23]\n",
      "Action prob: [1.0000000e+00 1.0087121e-23], Action: 0, state: 3\n",
      "[1.0000000e+00 4.0998754e-24]\n",
      "Action prob: [1.0000000e+00 4.0998754e-24], Action: 0, state: 3\n",
      "[1.000000e+00 2.166964e-22]\n",
      "Action prob: [1.000000e+00 2.166964e-22], Action: 0, state: 8\n",
      "[1.000000e+00 7.059435e-22]\n",
      "Action prob: [1.000000e+00 7.059435e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2887515e-23]\n",
      "Action prob: [1.0000000e+00 2.2887515e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2763123e-29]\n",
      "Action prob: [1.0000000e+00 3.2763123e-29], Action: 0, state: 8\n",
      "[1.00000000e+00 1.28436116e-26]\n",
      "Action prob: [1.00000000e+00 1.28436116e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6575667e-27]\n",
      "Action prob: [1.0000000e+00 2.6575667e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 6.5978575e-31]\n",
      "Action prob: [1.0000000e+00 6.5978575e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8003683e-23]\n",
      "Action prob: [1.0000000e+00 3.8003683e-23], Action: 0, state: 8\n",
      "[1.000000e+00 2.496467e-27]\n",
      "Action prob: [1.000000e+00 2.496467e-27], Action: 0, state: 8\n",
      "[1.00000000e+00 1.04478196e-22]\n",
      "Action prob: [1.00000000e+00 1.04478196e-22], Action: 0, state: 8\n",
      "[1.000000e+00 9.172983e-23]\n",
      "Action prob: [1.000000e+00 9.172983e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2731117e-23]\n",
      "Action prob: [1.0000000e+00 3.2731117e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7891358e-32]\n",
      "Action prob: [1.0000000e+00 1.7891358e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7780044e-29]\n",
      "Action prob: [1.0000000e+00 2.7780044e-29], Action: 0, state: 8\n",
      "[1.000000e+00 1.101056e-26]\n",
      "Action prob: [1.000000e+00 1.101056e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 8.1899274e-23]\n",
      "Action prob: [1.0000000e+00 8.1899274e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2107952e-26]\n",
      "Action prob: [1.0000000e+00 2.2107952e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2486595e-28]\n",
      "Action prob: [1.0000000e+00 2.2486595e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8848348e-27]\n",
      "Action prob: [1.0000000e+00 1.8848348e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9115465e-27]\n",
      "Action prob: [1.0000000e+00 1.9115465e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 6.5431437e-23]\n",
      "Action prob: [1.0000000e+00 6.5431437e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7782987e-22]\n",
      "Action prob: [1.0000000e+00 1.7782987e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7740445e-21]\n",
      "Action prob: [1.0000000e+00 1.7740445e-21], Action: 0, state: 8\n",
      "[1.000000e+00 6.614845e-23]\n",
      "Action prob: [1.000000e+00 6.614845e-23], Action: 0, state: 8\n",
      "[1.000000e+00 9.579713e-22]\n",
      "Action prob: [1.000000e+00 9.579713e-22], Action: 0, state: 8\n",
      "[1.000000e+00 6.782633e-27]\n",
      "Action prob: [1.000000e+00 6.782633e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1782583e-27]\n",
      "Action prob: [1.0000000e+00 1.1782583e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 8.6676635e-30]\n",
      "Action prob: [1.0000000e+00 8.6676635e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 5.4649644e-28]\n",
      "Action prob: [1.0000000e+00 5.4649644e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7231992e-21]\n",
      "Action prob: [1.0000000e+00 1.7231992e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0236136e-21]\n",
      "Action prob: [1.0000000e+00 1.0236136e-21], Action: 0, state: 8\n",
      "[1.0000000e+00 7.6040996e-28]\n",
      "Action prob: [1.0000000e+00 7.6040996e-28], Action: 0, state: 8\n",
      "[1.000000e+00 1.146328e-27]\n",
      "Action prob: [1.000000e+00 1.146328e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 5.8698093e-28]\n",
      "Action prob: [1.0000000e+00 5.8698093e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2078851e-27]\n",
      "Action prob: [1.0000000e+00 1.2078851e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3952003e-22]\n",
      "Action prob: [1.0000000e+00 3.3952003e-22], Action: 0, state: 8\n",
      "[1.000000e+00 8.883288e-26]\n",
      "Action prob: [1.000000e+00 8.883288e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7124319e-22]\n",
      "Action prob: [1.0000000e+00 1.7124319e-22], Action: 0, state: 8\n",
      "[1.000000e+00 9.486505e-30]\n",
      "Action prob: [1.000000e+00 9.486505e-30], Action: 0, state: 8\n",
      "[1.000000e+00 5.053722e-22]\n",
      "Action prob: [1.000000e+00 5.053722e-22], Action: 0, state: 8\n",
      "[1.000000e+00 8.917299e-28]\n",
      "Action prob: [1.000000e+00 8.917299e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0855618e-27]\n",
      "Action prob: [1.0000000e+00 1.0855618e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0065626e-29]\n",
      "Action prob: [1.0000000e+00 2.0065626e-29], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for this episode -127500, loss is -0.0\n",
      "[1.000000e+00 3.845118e-25]\n",
      "Action prob: [1.000000e+00 3.845118e-25], Action: 0, state: 0\n",
      "[1.0000000e+00 1.1789609e-25]\n",
      "Action prob: [1.0000000e+00 1.1789609e-25], Action: 0, state: 0\n",
      "[1.0000000e+00 1.3708374e-23]\n",
      "Action prob: [1.0000000e+00 1.3708374e-23], Action: 0, state: 0\n",
      "[1.0000000e+00 1.5161621e-25]\n",
      "Action prob: [1.0000000e+00 1.5161621e-25], Action: 0, state: 1\n",
      "[1.0000000e+00 1.0175032e-25]\n",
      "Action prob: [1.0000000e+00 1.0175032e-25], Action: 0, state: 1\n",
      "[1.0000000e+00 1.9128187e-24]\n",
      "Action prob: [1.0000000e+00 1.9128187e-24], Action: 0, state: 1\n",
      "[1.000000e+00 4.800813e-25]\n",
      "Action prob: [1.000000e+00 4.800813e-25], Action: 0, state: 1\n",
      "[1.0000000e+00 4.7635257e-25]\n",
      "Action prob: [1.0000000e+00 4.7635257e-25], Action: 0, state: 2\n",
      "[1.000000e+00 5.549803e-26]\n",
      "Action prob: [1.000000e+00 5.549803e-26], Action: 0, state: 3\n",
      "[1.000000e+00 1.640234e-22]\n",
      "Action prob: [1.000000e+00 1.640234e-22], Action: 0, state: 8\n",
      "[1.000000e+00 8.184397e-31]\n",
      "Action prob: [1.000000e+00 8.184397e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 4.4424875e-23]\n",
      "Action prob: [1.0000000e+00 4.4424875e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7645364e-29]\n",
      "Action prob: [1.0000000e+00 2.7645364e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4276526e-30]\n",
      "Action prob: [1.0000000e+00 2.4276526e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5318146e-22]\n",
      "Action prob: [1.0000000e+00 2.5318146e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1780176e-30]\n",
      "Action prob: [1.0000000e+00 3.1780176e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8111133e-28]\n",
      "Action prob: [1.0000000e+00 1.8111133e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0373412e-27]\n",
      "Action prob: [1.0000000e+00 3.0373412e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9426986e-22]\n",
      "Action prob: [1.0000000e+00 1.9426986e-22], Action: 0, state: 8\n",
      "[1.000000e+00 7.298897e-32]\n",
      "Action prob: [1.000000e+00 7.298897e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1631448e-29]\n",
      "Action prob: [1.0000000e+00 1.1631448e-29], Action: 0, state: 8\n",
      "[1.000000e+00 9.969602e-24]\n",
      "Action prob: [1.000000e+00 9.969602e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2228178e-28]\n",
      "Action prob: [1.0000000e+00 2.2228178e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4657639e-27]\n",
      "Action prob: [1.0000000e+00 2.4657639e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1658599e-35]\n",
      "Action prob: [1.0000000e+00 1.1658599e-35], Action: 0, state: 8\n",
      "[1.000000e+00 8.065856e-28]\n",
      "Action prob: [1.000000e+00 8.065856e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7321977e-23]\n",
      "Action prob: [1.0000000e+00 4.7321977e-23], Action: 0, state: 8\n",
      "[1.000000e+00 3.500011e-29]\n",
      "Action prob: [1.000000e+00 3.500011e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5572885e-25]\n",
      "Action prob: [1.0000000e+00 1.5572885e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5862372e-28]\n",
      "Action prob: [1.0000000e+00 2.5862372e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6243603e-28]\n",
      "Action prob: [1.0000000e+00 2.6243603e-28], Action: 0, state: 8\n",
      "[1.000000e+00 5.312805e-23]\n",
      "Action prob: [1.000000e+00 5.312805e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9619887e-23]\n",
      "Action prob: [1.0000000e+00 2.9619887e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6896761e-21]\n",
      "Action prob: [1.0000000e+00 1.6896761e-21], Action: 0, state: 8\n",
      "[1.000000e+00 3.718557e-22]\n",
      "Action prob: [1.000000e+00 3.718557e-22], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6591445e-30]\n",
      "Action prob: [1.0000000e+00 2.6591445e-30], Action: 0, state: 8\n",
      "[1.000000e+00 2.365734e-29]\n",
      "Action prob: [1.000000e+00 2.365734e-29], Action: 0, state: 8\n",
      "[1.000000e+00 4.231463e-28]\n",
      "Action prob: [1.000000e+00 4.231463e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1140253e-28]\n",
      "Action prob: [1.0000000e+00 1.1140253e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7556783e-29]\n",
      "Action prob: [1.0000000e+00 1.7556783e-29], Action: 0, state: 8\n",
      "[1.000000e+00 4.385435e-26]\n",
      "Action prob: [1.000000e+00 4.385435e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8888474e-29]\n",
      "Action prob: [1.0000000e+00 3.8888474e-29], Action: 0, state: 8\n",
      "[1.000000e+00 3.599105e-23]\n",
      "Action prob: [1.000000e+00 3.599105e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 7.3261937e-28]\n",
      "Action prob: [1.0000000e+00 7.3261937e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0859067e-29]\n",
      "Action prob: [1.0000000e+00 4.0859067e-29], Action: 0, state: 8\n",
      "[1.000000e+00 9.093866e-29]\n",
      "Action prob: [1.000000e+00 9.093866e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5676339e-27]\n",
      "Action prob: [1.0000000e+00 1.5676339e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4971007e-22]\n",
      "Action prob: [1.0000000e+00 1.4971007e-22], Action: 0, state: 8\n",
      "[1.00000000e+00 1.14425345e-26]\n",
      "Action prob: [1.00000000e+00 1.14425345e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0635214e-28]\n",
      "Action prob: [1.0000000e+00 1.0635214e-28], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -119100, loss is -0.0\n",
      "[1.0000000e+00 3.0249488e-25]\n",
      "Action prob: [1.0000000e+00 3.0249488e-25], Action: 0, state: 0\n",
      "[1.0000000e+00 2.1432596e-25]\n",
      "Action prob: [1.0000000e+00 2.1432596e-25], Action: 0, state: 0\n",
      "[1.0000000e+00 2.0223264e-26]\n",
      "Action prob: [1.0000000e+00 2.0223264e-26], Action: 0, state: 1\n",
      "[1.0000000e+00 3.9750373e-25]\n",
      "Action prob: [1.0000000e+00 3.9750373e-25], Action: 0, state: 2\n",
      "[1.000000e+00 3.417141e-25]\n",
      "Action prob: [1.000000e+00 3.417141e-25], Action: 0, state: 2\n",
      "[1.000000e+00 1.184361e-25]\n",
      "Action prob: [1.000000e+00 1.184361e-25], Action: 0, state: 2\n",
      "[1.000000e+00 9.575163e-26]\n",
      "Action prob: [1.000000e+00 9.575163e-26], Action: 0, state: 2\n",
      "[1.0000000e+00 2.1944024e-26]\n",
      "Action prob: [1.0000000e+00 2.1944024e-26], Action: 0, state: 2\n",
      "[1.0000000e+00 2.9373887e-25]\n",
      "Action prob: [1.0000000e+00 2.9373887e-25], Action: 0, state: 2\n",
      "[1.000000e+00 6.244029e-25]\n",
      "Action prob: [1.000000e+00 6.244029e-25], Action: 0, state: 2\n",
      "[1.0000000e+00 2.2056315e-26]\n",
      "Action prob: [1.0000000e+00 2.2056315e-26], Action: 0, state: 2\n",
      "[1.000000e+00 7.518302e-25]\n",
      "Action prob: [1.000000e+00 7.518302e-25], Action: 0, state: 2\n",
      "[1.0000000e+00 7.9959545e-26]\n",
      "Action prob: [1.0000000e+00 7.9959545e-26], Action: 0, state: 3\n",
      "[1.0000000e+00 2.4462044e-25]\n",
      "Action prob: [1.0000000e+00 2.4462044e-25], Action: 0, state: 3\n",
      "[1.000000e+00 2.088761e-25]\n",
      "Action prob: [1.000000e+00 2.088761e-25], Action: 0, state: 3\n",
      "[1.0000000e+00 2.0047483e-30]\n",
      "Action prob: [1.0000000e+00 2.0047483e-30], Action: 0, state: 8\n",
      "[1.000000e+00 3.857978e-23]\n",
      "Action prob: [1.000000e+00 3.857978e-23], Action: 0, state: 8\n",
      "[1.000000e+00 8.702148e-31]\n",
      "Action prob: [1.000000e+00 8.702148e-31], Action: 0, state: 8\n",
      "[1.000000e+00 9.067441e-28]\n",
      "Action prob: [1.000000e+00 9.067441e-28], Action: 0, state: 8\n",
      "[1.000000e+00 3.011341e-32]\n",
      "Action prob: [1.000000e+00 3.011341e-32], Action: 0, state: 8\n",
      "[1.000000e+00 4.395106e-30]\n",
      "Action prob: [1.000000e+00 4.395106e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 8.0572724e-29]\n",
      "Action prob: [1.0000000e+00 8.0572724e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2356164e-24]\n",
      "Action prob: [1.0000000e+00 1.2356164e-24], Action: 0, state: 8\n",
      "[1.000000e+00 8.460207e-27]\n",
      "Action prob: [1.000000e+00 8.460207e-27], Action: 0, state: 8\n",
      "[1.000000e+00 2.725404e-23]\n",
      "Action prob: [1.000000e+00 2.725404e-23], Action: 0, state: 8\n",
      "[1.000000e+00 9.083246e-24]\n",
      "Action prob: [1.000000e+00 9.083246e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 6.4514395e-23]\n",
      "Action prob: [1.0000000e+00 6.4514395e-23], Action: 0, state: 8\n",
      "[1.000000e+00 3.106886e-23]\n",
      "Action prob: [1.000000e+00 3.106886e-23], Action: 0, state: 8\n",
      "[1.000000e+00 3.658422e-29]\n",
      "Action prob: [1.000000e+00 3.658422e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 6.5048476e-29]\n",
      "Action prob: [1.0000000e+00 6.5048476e-29], Action: 0, state: 8\n",
      "[1.000000e+00 3.418285e-27]\n",
      "Action prob: [1.000000e+00 3.418285e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.856826e-26]\n",
      "Action prob: [1.000000e+00 9.856826e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9305357e-25]\n",
      "Action prob: [1.0000000e+00 1.9305357e-25], Action: 0, state: 8\n",
      "[1.00000e+00 3.94471e-30]\n",
      "Action prob: [1.00000e+00 3.94471e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1021503e-23]\n",
      "Action prob: [1.0000000e+00 1.1021503e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5348103e-22]\n",
      "Action prob: [1.0000000e+00 2.5348103e-22], Action: 0, state: 8\n",
      "[1.000000e+00 5.757169e-31]\n",
      "Action prob: [1.000000e+00 5.757169e-31], Action: 0, state: 8\n",
      "[1.00000e+00 2.89523e-30]\n",
      "Action prob: [1.00000e+00 2.89523e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9758944e-32]\n",
      "Action prob: [1.0000000e+00 2.9758944e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 5.5604987e-28]\n",
      "Action prob: [1.0000000e+00 5.5604987e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1522741e-23]\n",
      "Action prob: [1.0000000e+00 2.1522741e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 8.4249655e-29]\n",
      "Action prob: [1.0000000e+00 8.4249655e-29], Action: 0, state: 8\n",
      "[1.000000e+00 2.413075e-29]\n",
      "Action prob: [1.000000e+00 2.413075e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9790254e-27]\n",
      "Action prob: [1.0000000e+00 2.9790254e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3332184e-29]\n",
      "Action prob: [1.0000000e+00 2.3332184e-29], Action: 0, state: 8\n",
      "[1.000000e+00 6.150261e-29]\n",
      "Action prob: [1.000000e+00 6.150261e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6201556e-23]\n",
      "Action prob: [1.0000000e+00 2.6201556e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8008612e-23]\n",
      "Action prob: [1.0000000e+00 3.8008612e-23], Action: 0, state: 8\n",
      "[1.000000e+00 2.624941e-28]\n",
      "Action prob: [1.000000e+00 2.624941e-28], Action: 0, state: 8\n",
      "[1.000000e+00 4.904906e-24]\n",
      "Action prob: [1.000000e+00 4.904906e-24], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -97400, loss is -0.0\n",
      "[1.0000000e+00 1.4598312e-26]\n",
      "Action prob: [1.0000000e+00 1.4598312e-26], Action: 0, state: 0\n",
      "[1.0000000e+00 1.3200153e-26]\n",
      "Action prob: [1.0000000e+00 1.3200153e-26], Action: 0, state: 1\n",
      "[1.0000000e+00 2.0860126e-26]\n",
      "Action prob: [1.0000000e+00 2.0860126e-26], Action: 0, state: 1\n",
      "[1.0000000e+00 1.3149048e-25]\n",
      "Action prob: [1.0000000e+00 1.3149048e-25], Action: 0, state: 1\n",
      "[1.000000e+00 6.113476e-26]\n",
      "Action prob: [1.000000e+00 6.113476e-26], Action: 0, state: 1\n",
      "[1.0000000e+00 9.2386034e-26]\n",
      "Action prob: [1.0000000e+00 9.2386034e-26], Action: 0, state: 1\n",
      "[1.000000e+00 7.912784e-26]\n",
      "Action prob: [1.000000e+00 7.912784e-26], Action: 0, state: 2\n",
      "[1.0000000e+00 2.3729284e-29]\n",
      "Action prob: [1.0000000e+00 2.3729284e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.9555781e-28]\n",
      "Action prob: [1.0000000e+00 1.9555781e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7389348e-29]\n",
      "Action prob: [1.0000000e+00 1.7389348e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9059746e-29]\n",
      "Action prob: [1.0000000e+00 3.9059746e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2845907e-23]\n",
      "Action prob: [1.0000000e+00 2.2845907e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7821407e-24]\n",
      "Action prob: [1.0000000e+00 1.7821407e-24], Action: 0, state: 8\n",
      "[1.000000e+00 6.788934e-24]\n",
      "Action prob: [1.000000e+00 6.788934e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 7.4158576e-29]\n",
      "Action prob: [1.0000000e+00 7.4158576e-29], Action: 0, state: 8\n",
      "[1.000000e+00 1.844935e-26]\n",
      "Action prob: [1.000000e+00 1.844935e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1352639e-23]\n",
      "Action prob: [1.0000000e+00 1.1352639e-23], Action: 0, state: 8\n",
      "[1.000000e+00 7.489744e-30]\n",
      "Action prob: [1.000000e+00 7.489744e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 5.5364025e-24]\n",
      "Action prob: [1.0000000e+00 5.5364025e-24], Action: 0, state: 8\n",
      "[1.000000e+00 4.861561e-23]\n",
      "Action prob: [1.000000e+00 4.861561e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0443153e-34]\n",
      "Action prob: [1.0000000e+00 2.0443153e-34], Action: 0, state: 8\n",
      "[1.000000e+00 5.600517e-29]\n",
      "Action prob: [1.000000e+00 5.600517e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 5.9476995e-23]\n",
      "Action prob: [1.0000000e+00 5.9476995e-23], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 8.774485e-23]\n",
      "Action prob: [1.000000e+00 8.774485e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 7.5552276e-30]\n",
      "Action prob: [1.0000000e+00 7.5552276e-30], Action: 0, state: 8\n",
      "[1.000000e+00 1.351233e-23]\n",
      "Action prob: [1.000000e+00 1.351233e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5146972e-28]\n",
      "Action prob: [1.0000000e+00 1.5146972e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3287448e-29]\n",
      "Action prob: [1.0000000e+00 3.3287448e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3397274e-28]\n",
      "Action prob: [1.0000000e+00 1.3397274e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5390102e-23]\n",
      "Action prob: [1.0000000e+00 3.5390102e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7043334e-27]\n",
      "Action prob: [1.0000000e+00 2.7043334e-27], Action: 0, state: 8\n",
      "[1.000000e+00 5.530281e-24]\n",
      "Action prob: [1.000000e+00 5.530281e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2634398e-24]\n",
      "Action prob: [1.0000000e+00 4.2634398e-24], Action: 0, state: 8\n",
      "[1.000000e+00 3.881213e-30]\n",
      "Action prob: [1.000000e+00 3.881213e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7452915e-25]\n",
      "Action prob: [1.0000000e+00 1.7452915e-25], Action: 0, state: 8\n",
      "[1.00000000e+00 1.25512306e-23]\n",
      "Action prob: [1.00000000e+00 1.25512306e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2395969e-23]\n",
      "Action prob: [1.0000000e+00 1.2395969e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6477655e-30]\n",
      "Action prob: [1.0000000e+00 1.6477655e-30], Action: 0, state: 8\n",
      "[1.000000e+00 9.691627e-24]\n",
      "Action prob: [1.000000e+00 9.691627e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1857821e-30]\n",
      "Action prob: [1.0000000e+00 1.1857821e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3867352e-30]\n",
      "Action prob: [1.0000000e+00 2.3867352e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8046336e-30]\n",
      "Action prob: [1.0000000e+00 2.8046336e-30], Action: 0, state: 8\n",
      "[1.000000e+00 6.459566e-23]\n",
      "Action prob: [1.000000e+00 6.459566e-23], Action: 0, state: 8\n",
      "[1.000000e+00 4.546736e-27]\n",
      "Action prob: [1.000000e+00 4.546736e-27], Action: 0, state: 8\n",
      "[1.000000e+00 6.469827e-30]\n",
      "Action prob: [1.000000e+00 6.469827e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3183621e-30]\n",
      "Action prob: [1.0000000e+00 1.3183621e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0604714e-27]\n",
      "Action prob: [1.0000000e+00 1.0604714e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.197079e-29]\n",
      "Action prob: [1.000000e+00 7.197079e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6095343e-29]\n",
      "Action prob: [1.0000000e+00 2.6095343e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2437471e-29]\n",
      "Action prob: [1.0000000e+00 1.2437471e-29], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -123200, loss is -0.0\n",
      "[1.000000e+00 3.814538e-26]\n",
      "Action prob: [1.000000e+00 3.814538e-26], Action: 0, state: 0\n",
      "[1.000000e+00 9.922654e-27]\n",
      "Action prob: [1.000000e+00 9.922654e-27], Action: 0, state: 0\n",
      "[1.0000000e+00 2.0951839e-26]\n",
      "Action prob: [1.0000000e+00 2.0951839e-26], Action: 0, state: 1\n",
      "[1.000000e+00 8.469867e-26]\n",
      "Action prob: [1.000000e+00 8.469867e-26], Action: 0, state: 1\n",
      "[1.000000e+00 6.040296e-25]\n",
      "Action prob: [1.000000e+00 6.040296e-25], Action: 0, state: 1\n",
      "[1.0000000e+00 1.4324642e-26]\n",
      "Action prob: [1.0000000e+00 1.4324642e-26], Action: 0, state: 1\n",
      "[1.0000000e+00 2.1641508e-26]\n",
      "Action prob: [1.0000000e+00 2.1641508e-26], Action: 0, state: 2\n",
      "[1.0000000e+00 2.3968025e-27]\n",
      "Action prob: [1.0000000e+00 2.3968025e-27], Action: 0, state: 2\n",
      "[1.000000e+00 8.328826e-26]\n",
      "Action prob: [1.000000e+00 8.328826e-26], Action: 0, state: 2\n",
      "[1.0000000e+00 1.0483895e-25]\n",
      "Action prob: [1.0000000e+00 1.0483895e-25], Action: 0, state: 2\n",
      "[1.0000000e+00 3.6047485e-25]\n",
      "Action prob: [1.0000000e+00 3.6047485e-25], Action: 0, state: 2\n",
      "[1.000000e+00 6.578375e-25]\n",
      "Action prob: [1.000000e+00 6.578375e-25], Action: 0, state: 2\n",
      "[1.0000000e+00 1.2748579e-25]\n",
      "Action prob: [1.0000000e+00 1.2748579e-25], Action: 0, state: 3\n",
      "[1.0000000e+00 1.5005747e-25]\n",
      "Action prob: [1.0000000e+00 1.5005747e-25], Action: 0, state: 3\n",
      "[1.0000000e+00 4.6880417e-27]\n",
      "Action prob: [1.0000000e+00 4.6880417e-27], Action: 0, state: 3\n",
      "[1.0000000e+00 1.5248684e-25]\n",
      "Action prob: [1.0000000e+00 1.5248684e-25], Action: 0, state: 3\n",
      "[1.0000000e+00 3.6315382e-25]\n",
      "Action prob: [1.0000000e+00 3.6315382e-25], Action: 0, state: 3\n",
      "[1.0000000e+00 1.1476956e-23]\n",
      "Action prob: [1.0000000e+00 1.1476956e-23], Action: 0, state: 9\n",
      "[1.0000000e+00 1.4899782e-23]\n",
      "Action prob: [1.0000000e+00 1.4899782e-23], Action: 0, state: 9\n",
      "[1.0000000e+00 1.5827164e-34]\n",
      "Action prob: [1.0000000e+00 1.5827164e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 6.4613504e-35]\n",
      "Action prob: [1.0000000e+00 6.4613504e-35], Action: 0, state: 9\n",
      "[1.000000e+00 7.300086e-27]\n",
      "Action prob: [1.000000e+00 7.300086e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0748715e-22]\n",
      "Action prob: [1.0000000e+00 1.0748715e-22], Action: 0, state: 9\n",
      "[1.0000000e+00 2.8460563e-27]\n",
      "Action prob: [1.0000000e+00 2.8460563e-27], Action: 0, state: 9\n",
      "[1.00000e+00 6.83574e-23]\n",
      "Action prob: [1.00000e+00 6.83574e-23], Action: 0, state: 9\n",
      "[1.000000e+00 9.273217e-31]\n",
      "Action prob: [1.000000e+00 9.273217e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 7.3806517e-25]\n",
      "Action prob: [1.0000000e+00 7.3806517e-25], Action: 0, state: 9\n",
      "[1.0000000e+00 3.1623342e-29]\n",
      "Action prob: [1.0000000e+00 3.1623342e-29], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0852695e-24]\n",
      "Action prob: [1.0000000e+00 1.0852695e-24], Action: 0, state: 9\n",
      "[1.000000e+00 1.127313e-26]\n",
      "Action prob: [1.000000e+00 1.127313e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.8978693e-30]\n",
      "Action prob: [1.0000000e+00 1.8978693e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 6.2360483e-27]\n",
      "Action prob: [1.0000000e+00 6.2360483e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1570236e-23]\n",
      "Action prob: [1.0000000e+00 1.1570236e-23], Action: 0, state: 9\n",
      "[1.0000000e+00 5.7706015e-24]\n",
      "Action prob: [1.0000000e+00 5.7706015e-24], Action: 0, state: 9\n",
      "[1.000000e+00 5.912726e-23]\n",
      "Action prob: [1.000000e+00 5.912726e-23], Action: 0, state: 9\n",
      "[1.0000000e+00 5.2044458e-30]\n",
      "Action prob: [1.0000000e+00 5.2044458e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 7.0250727e-23]\n",
      "Action prob: [1.0000000e+00 7.0250727e-23], Action: 0, state: 9\n",
      "[1.000000e+00 6.655833e-28]\n",
      "Action prob: [1.000000e+00 6.655833e-28], Action: 0, state: 9\n",
      "[1.000000e+00 6.941088e-29]\n",
      "Action prob: [1.000000e+00 6.941088e-29], Action: 0, state: 9\n",
      "[1.0000000e+00 2.2055584e-31]\n",
      "Action prob: [1.0000000e+00 2.2055584e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 3.1263045e-28]\n",
      "Action prob: [1.0000000e+00 3.1263045e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 1.6210548e-32]\n",
      "Action prob: [1.0000000e+00 1.6210548e-32], Action: 0, state: 9\n",
      "[1.00000e+00 5.52625e-25]\n",
      "Action prob: [1.00000e+00 5.52625e-25], Action: 0, state: 9\n",
      "[1.0000000e+00 6.7088676e-24]\n",
      "Action prob: [1.0000000e+00 6.7088676e-24], Action: 0, state: 9\n",
      "[1.00000000e+00 1.24253694e-23]\n",
      "Action prob: [1.00000000e+00 1.24253694e-23], Action: 0, state: 9\n",
      "[1.000000e+00 8.330056e-28]\n",
      "Action prob: [1.000000e+00 8.330056e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 3.8070895e-29]\n",
      "Action prob: [1.0000000e+00 3.8070895e-29], Action: 0, state: 9\n",
      "[1.000000e+00 6.635739e-25]\n",
      "Action prob: [1.000000e+00 6.635739e-25], Action: 0, state: 9\n",
      "[1.000000e+00 6.538813e-27]\n",
      "Action prob: [1.000000e+00 6.538813e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 4.2825764e-24]\n",
      "Action prob: [1.0000000e+00 4.2825764e-24], Action: 0, state: 9\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., -0., -0., -0., -0., 0., 0., -0.,\n",
      "        -0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -22100, loss is -0.0\n",
      "[1.0000000e+00 2.2032936e-26]\n",
      "Action prob: [1.0000000e+00 2.2032936e-26], Action: 0, state: 0\n",
      "[1.0000000e+00 4.4362826e-26]\n",
      "Action prob: [1.0000000e+00 4.4362826e-26], Action: 0, state: 0\n",
      "[1.000000e+00 7.233639e-27]\n",
      "Action prob: [1.000000e+00 7.233639e-27], Action: 0, state: 0\n",
      "[1.0000000e+00 3.2113424e-26]\n",
      "Action prob: [1.0000000e+00 3.2113424e-26], Action: 0, state: 0\n",
      "[1.0000000e+00 1.7701193e-26]\n",
      "Action prob: [1.0000000e+00 1.7701193e-26], Action: 0, state: 0\n",
      "[1.0000000e+00 2.3290768e-27]\n",
      "Action prob: [1.0000000e+00 2.3290768e-27], Action: 0, state: 0\n",
      "[1.0000000e+00 2.5999894e-26]\n",
      "Action prob: [1.0000000e+00 2.5999894e-26], Action: 0, state: 0\n",
      "[1.0000000e+00 2.3838011e-26]\n",
      "Action prob: [1.0000000e+00 2.3838011e-26], Action: 0, state: 0\n",
      "[1.000000e+00 1.918686e-25]\n",
      "Action prob: [1.000000e+00 1.918686e-25], Action: 0, state: 1\n",
      "[1.0000000e+00 4.3148742e-27]\n",
      "Action prob: [1.0000000e+00 4.3148742e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 4.8424156e-26]\n",
      "Action prob: [1.0000000e+00 4.8424156e-26], Action: 0, state: 2\n",
      "[1.0000000e+00 2.4516681e-26]\n",
      "Action prob: [1.0000000e+00 2.4516681e-26], Action: 0, state: 2\n",
      "[1.0000000e+00 1.5775562e-27]\n",
      "Action prob: [1.0000000e+00 1.5775562e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 3.1457714e-26]\n",
      "Action prob: [1.0000000e+00 3.1457714e-26], Action: 0, state: 2\n",
      "[1.0000000e+00 1.0133309e-26]\n",
      "Action prob: [1.0000000e+00 1.0133309e-26], Action: 0, state: 2\n",
      "[1.0000000e+00 7.0921816e-28]\n",
      "Action prob: [1.0000000e+00 7.0921816e-28], Action: 0, state: 2\n",
      "[1.0000000e+00 6.6667375e-27]\n",
      "Action prob: [1.0000000e+00 6.6667375e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 2.5005298e-25]\n",
      "Action prob: [1.0000000e+00 2.5005298e-25], Action: 0, state: 2\n",
      "[1.0000000e+00 1.3375942e-26]\n",
      "Action prob: [1.0000000e+00 1.3375942e-26], Action: 0, state: 2\n",
      "[1.0000000e+00 1.7982209e-26]\n",
      "Action prob: [1.0000000e+00 1.7982209e-26], Action: 0, state: 3\n",
      "[1.0000000e+00 1.9097326e-26]\n",
      "Action prob: [1.0000000e+00 1.9097326e-26], Action: 0, state: 3\n",
      "[1.000000e+00 4.120494e-31]\n",
      "Action prob: [1.000000e+00 4.120494e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 8.2507994e-29]\n",
      "Action prob: [1.0000000e+00 8.2507994e-29], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7555327e-27]\n",
      "Action prob: [1.0000000e+00 1.7555327e-27], Action: 0, state: 9\n",
      "[1.000000e+00 3.907793e-29]\n",
      "Action prob: [1.000000e+00 3.907793e-29], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0525298e-31]\n",
      "Action prob: [1.0000000e+00 1.0525298e-31], Action: 0, state: 9\n",
      "[1.000000e+00 3.571953e-24]\n",
      "Action prob: [1.000000e+00 3.571953e-24], Action: 0, state: 9\n",
      "[1.0000000e+00 3.4476945e-29]\n",
      "Action prob: [1.0000000e+00 3.4476945e-29], Action: 0, state: 9\n",
      "[1.0000000e+00 3.7976341e-28]\n",
      "Action prob: [1.0000000e+00 3.7976341e-28], Action: 0, state: 9\n",
      "[1.000000e+00 4.314285e-33]\n",
      "Action prob: [1.000000e+00 4.314285e-33], Action: 0, state: 9\n",
      "[1.000000e+00 1.884461e-27]\n",
      "Action prob: [1.000000e+00 1.884461e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 5.4199655e-24]\n",
      "Action prob: [1.0000000e+00 5.4199655e-24], Action: 0, state: 9\n",
      "[1.0000000e+00 2.9701007e-31]\n",
      "Action prob: [1.0000000e+00 2.9701007e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 5.7973034e-30]\n",
      "Action prob: [1.0000000e+00 5.7973034e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3051361e-31]\n",
      "Action prob: [1.0000000e+00 1.3051361e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 6.3318265e-30]\n",
      "Action prob: [1.0000000e+00 6.3318265e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 2.2078073e-30]\n",
      "Action prob: [1.0000000e+00 2.2078073e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2048415e-30]\n",
      "Action prob: [1.0000000e+00 1.2048415e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 3.0422724e-25]\n",
      "Action prob: [1.0000000e+00 3.0422724e-25], Action: 0, state: 9\n",
      "[1.0000000e+00 2.2509053e-23]\n",
      "Action prob: [1.0000000e+00 2.2509053e-23], Action: 0, state: 9\n",
      "[1.0000000e+00 2.0938214e-30]\n",
      "Action prob: [1.0000000e+00 2.0938214e-30], Action: 0, state: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 8.9897324e-30]\n",
      "Action prob: [1.0000000e+00 8.9897324e-30], Action: 0, state: 9\n",
      "[1.000000e+00 7.471351e-34]\n",
      "Action prob: [1.000000e+00 7.471351e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7334113e-29]\n",
      "Action prob: [1.0000000e+00 1.7334113e-29], Action: 0, state: 9\n",
      "[1.0000000e+00 3.7388773e-25]\n",
      "Action prob: [1.0000000e+00 3.7388773e-25], Action: 0, state: 9\n",
      "[1.000000e+00 3.425419e-23]\n",
      "Action prob: [1.000000e+00 3.425419e-23], Action: 0, state: 9\n",
      "[1.000000e+00 7.944883e-24]\n",
      "Action prob: [1.000000e+00 7.944883e-24], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0538164e-29]\n",
      "Action prob: [1.0000000e+00 1.0538164e-29], Action: 0, state: 9\n",
      "[1.0000000e+00 2.9780187e-24]\n",
      "Action prob: [1.0000000e+00 2.9780187e-24], Action: 0, state: 9\n",
      "[1.0000000e+00 5.0317682e-24]\n",
      "Action prob: [1.0000000e+00 5.0317682e-24], Action: 0, state: 9\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -13100, loss is -0.0\n",
      "[1.0000000e+00 6.4359374e-28]\n",
      "Action prob: [1.0000000e+00 6.4359374e-28], Action: 0, state: 0\n",
      "[1.000000e+00 2.473001e-25]\n",
      "Action prob: [1.000000e+00 2.473001e-25], Action: 0, state: 1\n",
      "[1.0000000e+00 1.1197783e-26]\n",
      "Action prob: [1.0000000e+00 1.1197783e-26], Action: 0, state: 2\n",
      "[1.0000000e+00 3.0828798e-26]\n",
      "Action prob: [1.0000000e+00 3.0828798e-26], Action: 0, state: 2\n",
      "[1.000000e+00 3.095678e-26]\n",
      "Action prob: [1.000000e+00 3.095678e-26], Action: 0, state: 2\n",
      "[1.0000000e+00 6.6209946e-26]\n",
      "Action prob: [1.0000000e+00 6.6209946e-26], Action: 0, state: 2\n",
      "[1.000000e+00 7.558917e-30]\n",
      "Action prob: [1.000000e+00 7.558917e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 5.1925185e-26]\n",
      "Action prob: [1.0000000e+00 5.1925185e-26], Action: 0, state: 3\n",
      "[1.000000e+00 6.534571e-28]\n",
      "Action prob: [1.000000e+00 6.534571e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8559063e-24]\n",
      "Action prob: [1.0000000e+00 1.8559063e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9208391e-25]\n",
      "Action prob: [1.0000000e+00 1.9208391e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5040604e-26]\n",
      "Action prob: [1.0000000e+00 2.5040604e-26], Action: 0, state: 8\n",
      "[1.000000e+00 7.381787e-30]\n",
      "Action prob: [1.000000e+00 7.381787e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2357673e-24]\n",
      "Action prob: [1.0000000e+00 1.2357673e-24], Action: 0, state: 8\n",
      "[1.00000e+00 8.43811e-24]\n",
      "Action prob: [1.00000e+00 8.43811e-24], Action: 0, state: 8\n",
      "[1.000000e+00 3.501369e-24]\n",
      "Action prob: [1.000000e+00 3.501369e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9848353e-29]\n",
      "Action prob: [1.0000000e+00 1.9848353e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1462187e-24]\n",
      "Action prob: [1.0000000e+00 3.1462187e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9359042e-29]\n",
      "Action prob: [1.0000000e+00 2.9359042e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7316854e-30]\n",
      "Action prob: [1.0000000e+00 1.7316854e-30], Action: 0, state: 8\n",
      "[1.000000e+00 3.490659e-32]\n",
      "Action prob: [1.000000e+00 3.490659e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0333286e-31]\n",
      "Action prob: [1.0000000e+00 3.0333286e-31], Action: 0, state: 8\n",
      "[1.000000e+00 2.677913e-32]\n",
      "Action prob: [1.000000e+00 2.677913e-32], Action: 0, state: 8\n",
      "[1.000000e+00 7.794808e-25]\n",
      "Action prob: [1.000000e+00 7.794808e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1522933e-30]\n",
      "Action prob: [1.0000000e+00 1.1522933e-30], Action: 0, state: 8\n",
      "[1.000000e+00 8.236083e-29]\n",
      "Action prob: [1.000000e+00 8.236083e-29], Action: 0, state: 8\n",
      "[1.000000e+00 6.389623e-30]\n",
      "Action prob: [1.000000e+00 6.389623e-30], Action: 0, state: 8\n",
      "[1.000000e+00 1.342783e-34]\n",
      "Action prob: [1.000000e+00 1.342783e-34], Action: 0, state: 8\n",
      "[1.000000e+00 1.185605e-31]\n",
      "Action prob: [1.000000e+00 1.185605e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9805987e-24]\n",
      "Action prob: [1.0000000e+00 2.9805987e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4659657e-24]\n",
      "Action prob: [1.0000000e+00 1.4659657e-24], Action: 0, state: 8\n",
      "[1.000000e+00 8.630081e-31]\n",
      "Action prob: [1.000000e+00 8.630081e-31], Action: 0, state: 8\n",
      "[1.000000e+00 6.061208e-25]\n",
      "Action prob: [1.000000e+00 6.061208e-25], Action: 0, state: 8\n",
      "[1.000000e+00 2.888614e-28]\n",
      "Action prob: [1.000000e+00 2.888614e-28], Action: 0, state: 8\n",
      "[1.000000e+00 8.663697e-30]\n",
      "Action prob: [1.000000e+00 8.663697e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4693114e-27]\n",
      "Action prob: [1.0000000e+00 1.4693114e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8579445e-25]\n",
      "Action prob: [1.0000000e+00 3.8579445e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 6.2206428e-30]\n",
      "Action prob: [1.0000000e+00 6.2206428e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1119184e-30]\n",
      "Action prob: [1.0000000e+00 2.1119184e-30], Action: 0, state: 8\n",
      "[1.000000e+00 9.281633e-25]\n",
      "Action prob: [1.000000e+00 9.281633e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2136187e-29]\n",
      "Action prob: [1.0000000e+00 2.2136187e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1066144e-24]\n",
      "Action prob: [1.0000000e+00 2.1066144e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8971724e-32]\n",
      "Action prob: [1.0000000e+00 1.8971724e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1063787e-29]\n",
      "Action prob: [1.0000000e+00 3.1063787e-29], Action: 0, state: 8\n",
      "[1.00000000e+00 1.25990666e-29]\n",
      "Action prob: [1.00000000e+00 1.25990666e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 4.8321226e-32]\n",
      "Action prob: [1.0000000e+00 4.8321226e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8618916e-31]\n",
      "Action prob: [1.0000000e+00 1.8618916e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 9.6698025e-24]\n",
      "Action prob: [1.0000000e+00 9.6698025e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2795563e-30]\n",
      "Action prob: [1.0000000e+00 1.2795563e-30], Action: 0, state: 8\n",
      "[1.000000e+00 7.061552e-25]\n",
      "Action prob: [1.000000e+00 7.061552e-25], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -123900, loss is -0.0\n",
      "[1.000000e+00 7.980511e-32]\n",
      "Action prob: [1.000000e+00 7.980511e-32], Action: 0, state: 0\n",
      "[1.0000000e+00 1.7177465e-27]\n",
      "Action prob: [1.0000000e+00 1.7177465e-27], Action: 0, state: 1\n",
      "[1.000000e+00 5.492031e-27]\n",
      "Action prob: [1.000000e+00 5.492031e-27], Action: 0, state: 2\n",
      "[1.000000e+00 8.713327e-27]\n",
      "Action prob: [1.000000e+00 8.713327e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 7.4723997e-28]\n",
      "Action prob: [1.0000000e+00 7.4723997e-28], Action: 0, state: 2\n",
      "[1.0000000e+00 1.3403262e-27]\n",
      "Action prob: [1.0000000e+00 1.3403262e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 2.5410677e-27]\n",
      "Action prob: [1.0000000e+00 2.5410677e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 1.1525694e-24]\n",
      "Action prob: [1.0000000e+00 1.1525694e-24], Action: 0, state: 3\n",
      "[1.0000000e+00 1.5089105e-31]\n",
      "Action prob: [1.0000000e+00 1.5089105e-31], Action: 0, state: 3\n",
      "[1.0000000e+00 1.2486055e-29]\n",
      "Action prob: [1.0000000e+00 1.2486055e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6100303e-31]\n",
      "Action prob: [1.0000000e+00 1.6100303e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1092103e-24]\n",
      "Action prob: [1.0000000e+00 1.1092103e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 6.8999366e-35]\n",
      "Action prob: [1.0000000e+00 6.8999366e-35], Action: 0, state: 8\n",
      "[1.000000e+00 1.681463e-31]\n",
      "Action prob: [1.000000e+00 1.681463e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6383814e-24]\n",
      "Action prob: [1.0000000e+00 1.6383814e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4527668e-26]\n",
      "Action prob: [1.0000000e+00 3.4527668e-26], Action: 0, state: 8\n",
      "[1.000000e+00 1.569152e-29]\n",
      "Action prob: [1.000000e+00 1.569152e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4479175e-27]\n",
      "Action prob: [1.0000000e+00 1.4479175e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9596769e-29]\n",
      "Action prob: [1.0000000e+00 1.9596769e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3179745e-31]\n",
      "Action prob: [1.0000000e+00 5.3179745e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8370017e-31]\n",
      "Action prob: [1.0000000e+00 1.8370017e-31], Action: 0, state: 8\n",
      "[1.000000e+00 3.455956e-26]\n",
      "Action prob: [1.000000e+00 3.455956e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2767332e-24]\n",
      "Action prob: [1.0000000e+00 3.2767332e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 4.8108866e-29]\n",
      "Action prob: [1.0000000e+00 4.8108866e-29], Action: 0, state: 8\n",
      "[1.000000e+00 9.560678e-25]\n",
      "Action prob: [1.000000e+00 9.560678e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 9.7889836e-30]\n",
      "Action prob: [1.0000000e+00 9.7889836e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2217292e-31]\n",
      "Action prob: [1.0000000e+00 1.2217292e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0666848e-31]\n",
      "Action prob: [1.0000000e+00 1.0666848e-31], Action: 0, state: 8\n",
      "[1.000000e+00 6.851478e-24]\n",
      "Action prob: [1.000000e+00 6.851478e-24], Action: 0, state: 8\n",
      "[1.000000e+00 6.915839e-24]\n",
      "Action prob: [1.000000e+00 6.915839e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3062319e-31]\n",
      "Action prob: [1.0000000e+00 1.3062319e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5127993e-24]\n",
      "Action prob: [1.0000000e+00 2.5127993e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0826673e-24]\n",
      "Action prob: [1.0000000e+00 2.0826673e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0595756e-27]\n",
      "Action prob: [1.0000000e+00 3.0595756e-27], Action: 0, state: 8\n",
      "[1.000000e+00 1.027721e-30]\n",
      "Action prob: [1.000000e+00 1.027721e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2219816e-36]\n",
      "Action prob: [1.0000000e+00 4.2219816e-36], Action: 0, state: 8\n",
      "[1.00000e+00 1.99187e-33]\n",
      "Action prob: [1.00000e+00 1.99187e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9857715e-33]\n",
      "Action prob: [1.0000000e+00 3.9857715e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8001863e-30]\n",
      "Action prob: [1.0000000e+00 2.8001863e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9389355e-24]\n",
      "Action prob: [1.0000000e+00 1.9389355e-24], Action: 0, state: 8\n",
      "[1.000000e+00 2.472186e-28]\n",
      "Action prob: [1.000000e+00 2.472186e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7373435e-29]\n",
      "Action prob: [1.0000000e+00 1.7373435e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8447982e-31]\n",
      "Action prob: [1.0000000e+00 3.8447982e-31], Action: 0, state: 8\n",
      "[1.000000e+00 3.484869e-26]\n",
      "Action prob: [1.000000e+00 3.484869e-26], Action: 0, state: 8\n",
      "[1.000000e+00 6.663608e-35]\n",
      "Action prob: [1.000000e+00 6.663608e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0076114e-31]\n",
      "Action prob: [1.0000000e+00 3.0076114e-31], Action: 0, state: 8\n",
      "[1.000000e+00 2.015244e-31]\n",
      "Action prob: [1.000000e+00 2.015244e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 9.4133054e-27]\n",
      "Action prob: [1.0000000e+00 9.4133054e-27], Action: 0, state: 8\n",
      "[1.000000e+00 3.642936e-29]\n",
      "Action prob: [1.000000e+00 3.642936e-29], Action: 0, state: 8\n",
      "[1.000000e+00 2.534242e-28]\n",
      "Action prob: [1.000000e+00 2.534242e-28], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -120100, loss is -0.0\n",
      "[1.000000e+00 2.285936e-28]\n",
      "Action prob: [1.000000e+00 2.285936e-28], Action: 0, state: 0\n",
      "[1.000000e+00 5.988107e-31]\n",
      "Action prob: [1.000000e+00 5.988107e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 5.8337835e-27]\n",
      "Action prob: [1.0000000e+00 5.8337835e-27], Action: 0, state: 2\n",
      "[1.000000e+00 5.277886e-28]\n",
      "Action prob: [1.000000e+00 5.277886e-28], Action: 0, state: 2\n",
      "[1.00000000e+00 1.52716615e-27]\n",
      "Action prob: [1.00000000e+00 1.52716615e-27], Action: 0, state: 2\n",
      "[1.000000e+00 8.134116e-27]\n",
      "Action prob: [1.000000e+00 8.134116e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 1.9029477e-26]\n",
      "Action prob: [1.0000000e+00 1.9029477e-26], Action: 0, state: 2\n",
      "[1.000000e+00 8.538019e-27]\n",
      "Action prob: [1.000000e+00 8.538019e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 1.6532079e-27]\n",
      "Action prob: [1.0000000e+00 1.6532079e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 1.0990574e-28]\n",
      "Action prob: [1.0000000e+00 1.0990574e-28], Action: 0, state: 2\n",
      "[1.0000000e+00 2.0197274e-27]\n",
      "Action prob: [1.0000000e+00 2.0197274e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 1.3361766e-26]\n",
      "Action prob: [1.0000000e+00 1.3361766e-26], Action: 0, state: 2\n",
      "[1.000000e+00 3.682003e-27]\n",
      "Action prob: [1.000000e+00 3.682003e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 3.7847522e-26]\n",
      "Action prob: [1.0000000e+00 3.7847522e-26], Action: 0, state: 2\n",
      "[1.0000000e+00 5.9335463e-27]\n",
      "Action prob: [1.0000000e+00 5.9335463e-27], Action: 0, state: 2\n",
      "[1.000000e+00 1.397494e-26]\n",
      "Action prob: [1.000000e+00 1.397494e-26], Action: 0, state: 3\n",
      "[1.000000e+00 5.535541e-30]\n",
      "Action prob: [1.000000e+00 5.535541e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 4.4862994e-26]\n",
      "Action prob: [1.0000000e+00 4.4862994e-26], Action: 0, state: 3\n",
      "[1.0000000e+00 4.8354358e-27]\n",
      "Action prob: [1.0000000e+00 4.8354358e-27], Action: 0, state: 3\n",
      "[1.000000e+00 5.285338e-29]\n",
      "Action prob: [1.000000e+00 5.285338e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1433114e-30]\n",
      "Action prob: [1.0000000e+00 2.1433114e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 8.1156536e-32]\n",
      "Action prob: [1.0000000e+00 8.1156536e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3235317e-25]\n",
      "Action prob: [1.0000000e+00 5.3235317e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0140442e-30]\n",
      "Action prob: [1.0000000e+00 1.0140442e-30], Action: 0, state: 8\n",
      "[1.000000e+00 1.191508e-24]\n",
      "Action prob: [1.000000e+00 1.191508e-24], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 1.052405e-24]\n",
      "Action prob: [1.000000e+00 1.052405e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6498488e-30]\n",
      "Action prob: [1.0000000e+00 2.6498488e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1201896e-24]\n",
      "Action prob: [1.0000000e+00 1.1201896e-24], Action: 0, state: 8\n",
      "[1.000000e+00 3.383624e-32]\n",
      "Action prob: [1.000000e+00 3.383624e-32], Action: 0, state: 8\n",
      "[1.000000e+00 1.057496e-31]\n",
      "Action prob: [1.000000e+00 1.057496e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9476671e-25]\n",
      "Action prob: [1.0000000e+00 1.9476671e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 6.0818213e-25]\n",
      "Action prob: [1.0000000e+00 6.0818213e-25], Action: 0, state: 8\n",
      "[1.000000e+00 8.533108e-33]\n",
      "Action prob: [1.000000e+00 8.533108e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2668592e-32]\n",
      "Action prob: [1.0000000e+00 1.2668592e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2014124e-31]\n",
      "Action prob: [1.0000000e+00 1.2014124e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0407029e-33]\n",
      "Action prob: [1.0000000e+00 1.0407029e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3495912e-29]\n",
      "Action prob: [1.0000000e+00 4.3495912e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4751491e-31]\n",
      "Action prob: [1.0000000e+00 1.4751491e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 4.8593326e-32]\n",
      "Action prob: [1.0000000e+00 4.8593326e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3693576e-24]\n",
      "Action prob: [1.0000000e+00 1.3693576e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 7.1869758e-31]\n",
      "Action prob: [1.0000000e+00 7.1869758e-31], Action: 0, state: 8\n",
      "[1.000000e+00 6.170579e-32]\n",
      "Action prob: [1.000000e+00 6.170579e-32], Action: 0, state: 8\n",
      "[1.00000e+00 3.96503e-31]\n",
      "Action prob: [1.00000e+00 3.96503e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 6.6856645e-33]\n",
      "Action prob: [1.0000000e+00 6.6856645e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0808742e-30]\n",
      "Action prob: [1.0000000e+00 2.0808742e-30], Action: 0, state: 8\n",
      "[1.000000e+00 7.104103e-26]\n",
      "Action prob: [1.000000e+00 7.104103e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3613025e-25]\n",
      "Action prob: [1.0000000e+00 3.3613025e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3824854e-24]\n",
      "Action prob: [1.0000000e+00 2.3824854e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0545883e-34]\n",
      "Action prob: [1.0000000e+00 2.0545883e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 7.5688353e-32]\n",
      "Action prob: [1.0000000e+00 7.5688353e-32], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -82700, loss is -0.0\n",
      "[1.0000000e+00 1.7798075e-27]\n",
      "Action prob: [1.0000000e+00 1.7798075e-27], Action: 0, state: 0\n",
      "[1.0000000e+00 1.2006091e-26]\n",
      "Action prob: [1.0000000e+00 1.2006091e-26], Action: 0, state: 1\n",
      "[1.000000e+00 8.317963e-27]\n",
      "Action prob: [1.000000e+00 8.317963e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 3.4502503e-27]\n",
      "Action prob: [1.0000000e+00 3.4502503e-27], Action: 0, state: 3\n",
      "[1.0000000e+00 2.7234208e-29]\n",
      "Action prob: [1.0000000e+00 2.7234208e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8565298e-31]\n",
      "Action prob: [1.0000000e+00 1.8565298e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9772926e-31]\n",
      "Action prob: [1.0000000e+00 2.9772926e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0895057e-25]\n",
      "Action prob: [1.0000000e+00 5.0895057e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2716783e-31]\n",
      "Action prob: [1.0000000e+00 4.2716783e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6237429e-33]\n",
      "Action prob: [1.0000000e+00 2.6237429e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6965718e-23]\n",
      "Action prob: [1.0000000e+00 2.6965718e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4872783e-32]\n",
      "Action prob: [1.0000000e+00 3.4872783e-32], Action: 0, state: 8\n",
      "[1.000000e+00 4.004796e-31]\n",
      "Action prob: [1.000000e+00 4.004796e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 8.7673114e-26]\n",
      "Action prob: [1.0000000e+00 8.7673114e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2913285e-30]\n",
      "Action prob: [1.0000000e+00 4.2913285e-30], Action: 0, state: 8\n",
      "[1.000000e+00 5.744946e-32]\n",
      "Action prob: [1.000000e+00 5.744946e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2289273e-24]\n",
      "Action prob: [1.0000000e+00 1.2289273e-24], Action: 0, state: 8\n",
      "[1.000000e+00 4.405091e-31]\n",
      "Action prob: [1.000000e+00 4.405091e-31], Action: 0, state: 8\n",
      "[1.000000e+00 6.976704e-24]\n",
      "Action prob: [1.000000e+00 6.976704e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7320726e-33]\n",
      "Action prob: [1.0000000e+00 1.7320726e-33], Action: 0, state: 8\n",
      "[1.000000e+00 3.221727e-31]\n",
      "Action prob: [1.000000e+00 3.221727e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1722215e-31]\n",
      "Action prob: [1.0000000e+00 1.1722215e-31], Action: 0, state: 8\n",
      "[1.000000e+00 3.888974e-25]\n",
      "Action prob: [1.000000e+00 3.888974e-25], Action: 0, state: 8\n",
      "[1.00000e+00 2.19588e-30]\n",
      "Action prob: [1.00000e+00 2.19588e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3231871e-25]\n",
      "Action prob: [1.0000000e+00 1.3231871e-25], Action: 0, state: 8\n",
      "[1.000000e+00 6.069652e-33]\n",
      "Action prob: [1.000000e+00 6.069652e-33], Action: 0, state: 8\n",
      "[1.000000e+00 9.693538e-34]\n",
      "Action prob: [1.000000e+00 9.693538e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2571804e-32]\n",
      "Action prob: [1.0000000e+00 2.2571804e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 9.8085905e-26]\n",
      "Action prob: [1.0000000e+00 9.8085905e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6455917e-26]\n",
      "Action prob: [1.0000000e+00 2.6455917e-26], Action: 0, state: 8\n",
      "[1.000000e+00 9.654305e-35]\n",
      "Action prob: [1.000000e+00 9.654305e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0694884e-33]\n",
      "Action prob: [1.0000000e+00 5.0694884e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4659716e-31]\n",
      "Action prob: [1.0000000e+00 1.4659716e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6509172e-38]\n",
      "Action prob: [1.0000000e+00 1.6509172e-38], Action: 0, state: 8\n",
      "[1.000000e+00 2.178699e-31]\n",
      "Action prob: [1.000000e+00 2.178699e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0419943e-25]\n",
      "Action prob: [1.0000000e+00 2.0419943e-25], Action: 0, state: 8\n",
      "[1.00000000e+00 1.11015996e-29]\n",
      "Action prob: [1.00000000e+00 1.11015996e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7624064e-24]\n",
      "Action prob: [1.0000000e+00 1.7624064e-24], Action: 0, state: 8\n",
      "[1.000000e+00 9.566391e-28]\n",
      "Action prob: [1.000000e+00 9.566391e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2861416e-25]\n",
      "Action prob: [1.0000000e+00 1.2861416e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3516667e-37]\n",
      "Action prob: [1.0000000e+00 1.3516667e-37], Action: 0, state: 8\n",
      "[1.00000e+00 8.03335e-25]\n",
      "Action prob: [1.00000e+00 8.03335e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0368585e-32]\n",
      "Action prob: [1.0000000e+00 3.0368585e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0628749e-31]\n",
      "Action prob: [1.0000000e+00 1.0628749e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4953414e-29]\n",
      "Action prob: [1.0000000e+00 3.4953414e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3603968e-30]\n",
      "Action prob: [1.0000000e+00 3.3603968e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3131408e-32]\n",
      "Action prob: [1.0000000e+00 1.3131408e-32], Action: 0, state: 8\n",
      "[1.000000e+00 2.326365e-30]\n",
      "Action prob: [1.000000e+00 2.326365e-30], Action: 0, state: 8\n",
      "[1.000000e+00 4.040395e-24]\n",
      "Action prob: [1.000000e+00 4.040395e-24], Action: 0, state: 8\n",
      "[1.000000e+00 4.021377e-30]\n",
      "Action prob: [1.000000e+00 4.021377e-30], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., -0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -138800, loss is -0.0\n",
      "[1.000000e+00 8.368344e-27]\n",
      "Action prob: [1.000000e+00 8.368344e-27], Action: 0, state: 0\n",
      "[1.000000e+00 7.081318e-27]\n",
      "Action prob: [1.000000e+00 7.081318e-27], Action: 0, state: 0\n",
      "[1.0000000e+00 2.3287403e-26]\n",
      "Action prob: [1.0000000e+00 2.3287403e-26], Action: 0, state: 0\n",
      "[1.0000000e+00 1.4161697e-26]\n",
      "Action prob: [1.0000000e+00 1.4161697e-26], Action: 0, state: 0\n",
      "[1.0000000e+00 3.2396776e-27]\n",
      "Action prob: [1.0000000e+00 3.2396776e-27], Action: 0, state: 0\n",
      "[1.000000e+00 1.740004e-28]\n",
      "Action prob: [1.000000e+00 1.740004e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 3.3665348e-27]\n",
      "Action prob: [1.0000000e+00 3.3665348e-27], Action: 0, state: 1\n",
      "[1.000000e+00 2.210246e-27]\n",
      "Action prob: [1.000000e+00 2.210246e-27], Action: 0, state: 1\n",
      "[1.0000000e+00 1.0914456e-27]\n",
      "Action prob: [1.0000000e+00 1.0914456e-27], Action: 0, state: 2\n",
      "[1.000000e+00 3.871044e-28]\n",
      "Action prob: [1.000000e+00 3.871044e-28], Action: 0, state: 2\n",
      "[1.0000000e+00 2.8957535e-27]\n",
      "Action prob: [1.0000000e+00 2.8957535e-27], Action: 0, state: 2\n",
      "[1.000000e+00 8.420322e-33]\n",
      "Action prob: [1.000000e+00 8.420322e-33], Action: 0, state: 3\n",
      "[1.0000000e+00 5.2932826e-31]\n",
      "Action prob: [1.0000000e+00 5.2932826e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4955587e-30]\n",
      "Action prob: [1.0000000e+00 2.4955587e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7477015e-27]\n",
      "Action prob: [1.0000000e+00 1.7477015e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9095435e-26]\n",
      "Action prob: [1.0000000e+00 3.9095435e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.8227627e-34]\n",
      "Action prob: [1.0000000e+00 4.8227627e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6270162e-30]\n",
      "Action prob: [1.0000000e+00 1.6270162e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4962656e-24]\n",
      "Action prob: [1.0000000e+00 1.4962656e-24], Action: 0, state: 8\n",
      "[1.000000e+00 2.081441e-27]\n",
      "Action prob: [1.000000e+00 2.081441e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8319168e-24]\n",
      "Action prob: [1.0000000e+00 2.8319168e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1257376e-32]\n",
      "Action prob: [1.0000000e+00 3.1257376e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7903933e-23]\n",
      "Action prob: [1.0000000e+00 1.7903933e-23], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3715915e-32]\n",
      "Action prob: [1.0000000e+00 4.3715915e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5689153e-33]\n",
      "Action prob: [1.0000000e+00 2.5689153e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3363516e-31]\n",
      "Action prob: [1.0000000e+00 1.3363516e-31], Action: 0, state: 8\n",
      "[1.000000e+00 8.717697e-31]\n",
      "Action prob: [1.000000e+00 8.717697e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0173565e-31]\n",
      "Action prob: [1.0000000e+00 1.0173565e-31], Action: 0, state: 8\n",
      "[1.000000e+00 5.956141e-32]\n",
      "Action prob: [1.000000e+00 5.956141e-32], Action: 0, state: 8\n",
      "[1.000000e+00 1.569197e-25]\n",
      "Action prob: [1.000000e+00 1.569197e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 8.6422985e-32]\n",
      "Action prob: [1.0000000e+00 8.6422985e-32], Action: 0, state: 8\n",
      "[1.000000e+00 6.883283e-31]\n",
      "Action prob: [1.000000e+00 6.883283e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0387947e-33]\n",
      "Action prob: [1.0000000e+00 5.0387947e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6751562e-32]\n",
      "Action prob: [1.0000000e+00 2.6751562e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7840089e-34]\n",
      "Action prob: [1.0000000e+00 1.7840089e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 9.4809244e-32]\n",
      "Action prob: [1.0000000e+00 9.4809244e-32], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 4.0686818e-25]\n",
      "Action prob: [1.0000000e+00 4.0686818e-25], Action: 0, state: 8\n",
      "[1.000000e+00 9.863414e-25]\n",
      "Action prob: [1.000000e+00 9.863414e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 7.9975695e-34]\n",
      "Action prob: [1.0000000e+00 7.9975695e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 5.5347554e-24]\n",
      "Action prob: [1.0000000e+00 5.5347554e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 3.7859988e-31]\n",
      "Action prob: [1.0000000e+00 3.7859988e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 7.8482174e-32]\n",
      "Action prob: [1.0000000e+00 7.8482174e-32], Action: 0, state: 8\n",
      "[1.00000000e+00 1.49709465e-30]\n",
      "Action prob: [1.00000000e+00 1.49709465e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8865659e-35]\n",
      "Action prob: [1.0000000e+00 2.8865659e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.8437915e-32]\n",
      "Action prob: [1.0000000e+00 5.8437915e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6686765e-30]\n",
      "Action prob: [1.0000000e+00 2.6686765e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6799994e-33]\n",
      "Action prob: [1.0000000e+00 1.6799994e-33], Action: 0, state: 8\n",
      "[1.000000e+00 1.037188e-32]\n",
      "Action prob: [1.000000e+00 1.037188e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1049694e-33]\n",
      "Action prob: [1.0000000e+00 1.1049694e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2253888e-38]\n",
      "Action prob: [1.0000000e+00 1.2253888e-38], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -107300, loss is -0.0\n",
      "[1.000000e+00 6.642738e-30]\n",
      "Action prob: [1.000000e+00 6.642738e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 1.1910381e-27]\n",
      "Action prob: [1.0000000e+00 1.1910381e-27], Action: 0, state: 0\n",
      "[1.000000e+00 6.479756e-30]\n",
      "Action prob: [1.000000e+00 6.479756e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.5720758e-29]\n",
      "Action prob: [1.0000000e+00 1.5720758e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 2.5745746e-34]\n",
      "Action prob: [1.0000000e+00 2.5745746e-34], Action: 0, state: 9\n",
      "[1.00000e+00 3.39185e-28]\n",
      "Action prob: [1.00000e+00 3.39185e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 3.0555236e-30]\n",
      "Action prob: [1.0000000e+00 3.0555236e-30], Action: 0, state: 9\n",
      "[1.000000e+00 3.590107e-32]\n",
      "Action prob: [1.000000e+00 3.590107e-32], Action: 0, state: 9\n",
      "[1.000000e+00 8.785495e-25]\n",
      "Action prob: [1.000000e+00 8.785495e-25], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2753395e-25]\n",
      "Action prob: [1.0000000e+00 1.2753395e-25], Action: 0, state: 9\n",
      "[1.0000000e+00 1.8311569e-34]\n",
      "Action prob: [1.0000000e+00 1.8311569e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 3.9098426e-33]\n",
      "Action prob: [1.0000000e+00 3.9098426e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 6.5246855e-27]\n",
      "Action prob: [1.0000000e+00 6.5246855e-27], Action: 0, state: 9\n",
      "[1.000000e+00 5.005983e-30]\n",
      "Action prob: [1.000000e+00 5.005983e-30], Action: 0, state: 9\n",
      "[1.000000e+00 4.079647e-36]\n",
      "Action prob: [1.000000e+00 4.079647e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 2.3525821e-32]\n",
      "Action prob: [1.0000000e+00 2.3525821e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 4.6832146e-35]\n",
      "Action prob: [1.0000000e+00 4.6832146e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7759437e-25]\n",
      "Action prob: [1.0000000e+00 1.7759437e-25], Action: 0, state: 9\n",
      "[1.000000e+00 3.914273e-34]\n",
      "Action prob: [1.000000e+00 3.914273e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.4543843e-33]\n",
      "Action prob: [1.0000000e+00 1.4543843e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.6085987e-25]\n",
      "Action prob: [1.0000000e+00 1.6085987e-25], Action: 0, state: 9\n",
      "[1.000000e+00 6.199357e-34]\n",
      "Action prob: [1.000000e+00 6.199357e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7610403e-26]\n",
      "Action prob: [1.0000000e+00 1.7610403e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7076217e-25]\n",
      "Action prob: [1.0000000e+00 1.7076217e-25], Action: 0, state: 9\n",
      "[1.000000e+00 2.351103e-31]\n",
      "Action prob: [1.000000e+00 2.351103e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 5.1786727e-33]\n",
      "Action prob: [1.0000000e+00 5.1786727e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.4204999e-31]\n",
      "Action prob: [1.0000000e+00 1.4204999e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3298974e-32]\n",
      "Action prob: [1.0000000e+00 1.3298974e-32], Action: 0, state: 9\n",
      "[1.00000e+00 3.65914e-33]\n",
      "Action prob: [1.00000e+00 3.65914e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 3.0244087e-31]\n",
      "Action prob: [1.0000000e+00 3.0244087e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 2.0094161e-25]\n",
      "Action prob: [1.0000000e+00 2.0094161e-25], Action: 0, state: 9\n",
      "[1.0000000e+00 1.6351904e-32]\n",
      "Action prob: [1.0000000e+00 1.6351904e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 3.8361078e-25]\n",
      "Action prob: [1.0000000e+00 3.8361078e-25], Action: 0, state: 9\n",
      "[1.0000000e+00 1.9058736e-28]\n",
      "Action prob: [1.0000000e+00 1.9058736e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 1.9847405e-33]\n",
      "Action prob: [1.0000000e+00 1.9847405e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 3.2853168e-33]\n",
      "Action prob: [1.0000000e+00 3.2853168e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0217168e-30]\n",
      "Action prob: [1.0000000e+00 1.0217168e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7989002e-26]\n",
      "Action prob: [1.0000000e+00 1.7989002e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7069522e-31]\n",
      "Action prob: [1.0000000e+00 1.7069522e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 5.1835335e-26]\n",
      "Action prob: [1.0000000e+00 5.1835335e-26], Action: 0, state: 9\n",
      "[1.000000e+00 5.580526e-32]\n",
      "Action prob: [1.000000e+00 5.580526e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 3.0099919e-28]\n",
      "Action prob: [1.0000000e+00 3.0099919e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 3.1919517e-31]\n",
      "Action prob: [1.0000000e+00 3.1919517e-31], Action: 0, state: 9\n",
      "[1.000000e+00 9.613962e-33]\n",
      "Action prob: [1.000000e+00 9.613962e-33], Action: 0, state: 9\n",
      "[1.000000e+00 5.588212e-26]\n",
      "Action prob: [1.000000e+00 5.588212e-26], Action: 0, state: 9\n",
      "[1.000000e+00 8.645556e-26]\n",
      "Action prob: [1.000000e+00 8.645556e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 3.8717875e-33]\n",
      "Action prob: [1.0000000e+00 3.8717875e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7187919e-31]\n",
      "Action prob: [1.0000000e+00 1.7187919e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 1.4291998e-34]\n",
      "Action prob: [1.0000000e+00 1.4291998e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 4.7526053e-30]\n",
      "Action prob: [1.0000000e+00 4.7526053e-30], Action: 0, state: 9\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -44200, loss is -0.0\n",
      "[1.0000000e+00 1.9371794e-28]\n",
      "Action prob: [1.0000000e+00 1.9371794e-28], Action: 0, state: 0\n",
      "[1.000000e+00 8.808565e-29]\n",
      "Action prob: [1.000000e+00 8.808565e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 5.4554277e-27]\n",
      "Action prob: [1.0000000e+00 5.4554277e-27], Action: 0, state: 1\n",
      "[1.0000000e+00 2.1297434e-28]\n",
      "Action prob: [1.0000000e+00 2.1297434e-28], Action: 0, state: 2\n",
      "[1.0000000e+00 6.4126106e-27]\n",
      "Action prob: [1.0000000e+00 6.4126106e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 5.8751217e-27]\n",
      "Action prob: [1.0000000e+00 5.8751217e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 3.7506853e-28]\n",
      "Action prob: [1.0000000e+00 3.7506853e-28], Action: 0, state: 2\n",
      "[1.0000000e+00 2.5389477e-33]\n",
      "Action prob: [1.0000000e+00 2.5389477e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7447657e-25]\n",
      "Action prob: [1.0000000e+00 1.7447657e-25], Action: 0, state: 9\n",
      "[1.0000000e+00 3.1003484e-32]\n",
      "Action prob: [1.0000000e+00 3.1003484e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 2.3062948e-33]\n",
      "Action prob: [1.0000000e+00 2.3062948e-33], Action: 0, state: 9\n",
      "[1.000000e+00 9.539696e-32]\n",
      "Action prob: [1.000000e+00 9.539696e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 2.1907073e-32]\n",
      "Action prob: [1.0000000e+00 2.1907073e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2547499e-30]\n",
      "Action prob: [1.0000000e+00 1.2547499e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 7.8210745e-26]\n",
      "Action prob: [1.0000000e+00 7.8210745e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0324566e-29]\n",
      "Action prob: [1.0000000e+00 1.0324566e-29], Action: 0, state: 9\n",
      "[1.0000000e+00 3.7932848e-31]\n",
      "Action prob: [1.0000000e+00 3.7932848e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 2.0995299e-32]\n",
      "Action prob: [1.0000000e+00 2.0995299e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 3.4551914e-26]\n",
      "Action prob: [1.0000000e+00 3.4551914e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 3.0282515e-32]\n",
      "Action prob: [1.0000000e+00 3.0282515e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 3.4515704e-25]\n",
      "Action prob: [1.0000000e+00 3.4515704e-25], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2390445e-37]\n",
      "Action prob: [1.0000000e+00 1.2390445e-37], Action: 0, state: 9\n",
      "[1.000000e+00 4.177007e-32]\n",
      "Action prob: [1.000000e+00 4.177007e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 7.1035935e-32]\n",
      "Action prob: [1.0000000e+00 7.1035935e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 3.7909954e-33]\n",
      "Action prob: [1.0000000e+00 3.7909954e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3890498e-32]\n",
      "Action prob: [1.0000000e+00 1.3890498e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2651688e-32]\n",
      "Action prob: [1.0000000e+00 1.2651688e-32], Action: 0, state: 9\n",
      "[1.000000e+00 5.319841e-31]\n",
      "Action prob: [1.000000e+00 5.319841e-31], Action: 0, state: 9\n",
      "[1.000000e+00 4.653824e-30]\n",
      "Action prob: [1.000000e+00 4.653824e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 4.7750604e-25]\n",
      "Action prob: [1.0000000e+00 4.7750604e-25], Action: 0, state: 9\n",
      "[1.000000e+00 2.741668e-25]\n",
      "Action prob: [1.000000e+00 2.741668e-25], Action: 0, state: 9\n",
      "[1.0000000e+00 2.0193025e-28]\n",
      "Action prob: [1.0000000e+00 2.0193025e-28], Action: 0, state: 9\n",
      "[1.000000e+00 1.101661e-26]\n",
      "Action prob: [1.000000e+00 1.101661e-26], Action: 0, state: 9\n",
      "[1.000000e+00 3.494264e-35]\n",
      "Action prob: [1.000000e+00 3.494264e-35], Action: 0, state: 9\n",
      "[1.000000e+00 4.853436e-34]\n",
      "Action prob: [1.000000e+00 4.853436e-34], Action: 0, state: 9\n",
      "[1.000000e+00 7.966696e-26]\n",
      "Action prob: [1.000000e+00 7.966696e-26], Action: 0, state: 9\n",
      "[1.000000e+00 7.968161e-32]\n",
      "Action prob: [1.000000e+00 7.968161e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1193979e-34]\n",
      "Action prob: [1.0000000e+00 1.1193979e-34], Action: 0, state: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 9.028558e-32]\n",
      "Action prob: [1.000000e+00 9.028558e-32], Action: 0, state: 9\n",
      "[1.000000e+00 8.112338e-33]\n",
      "Action prob: [1.000000e+00 8.112338e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 2.1574534e-30]\n",
      "Action prob: [1.0000000e+00 2.1574534e-30], Action: 0, state: 9\n",
      "[1.000000e+00 4.802826e-26]\n",
      "Action prob: [1.000000e+00 4.802826e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 2.1325162e-35]\n",
      "Action prob: [1.0000000e+00 2.1325162e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 2.6878636e-30]\n",
      "Action prob: [1.0000000e+00 2.6878636e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 5.7586185e-31]\n",
      "Action prob: [1.0000000e+00 5.7586185e-31], Action: 0, state: 9\n",
      "[1.000000e+00 8.537415e-31]\n",
      "Action prob: [1.000000e+00 8.537415e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 7.6719083e-26]\n",
      "Action prob: [1.0000000e+00 7.6719083e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.5670479e-27]\n",
      "Action prob: [1.0000000e+00 1.5670479e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 2.6926171e-36]\n",
      "Action prob: [1.0000000e+00 2.6926171e-36], Action: 0, state: 9\n",
      "[1.000000e+00 8.372095e-31]\n",
      "Action prob: [1.000000e+00 8.372095e-31], Action: 0, state: 9\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., -0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -38900, loss is -0.0\n",
      "[1.0000000e+00 2.4428156e-28]\n",
      "Action prob: [1.0000000e+00 2.4428156e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 9.6216126e-29]\n",
      "Action prob: [1.0000000e+00 9.6216126e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.6250275e-27]\n",
      "Action prob: [1.0000000e+00 1.6250275e-27], Action: 0, state: 0\n",
      "[1.0000000e+00 1.9358876e-27]\n",
      "Action prob: [1.0000000e+00 1.9358876e-27], Action: 0, state: 0\n",
      "[1.0000000e+00 2.7039931e-27]\n",
      "Action prob: [1.0000000e+00 2.7039931e-27], Action: 0, state: 1\n",
      "[1.0000000e+00 1.4773646e-28]\n",
      "Action prob: [1.0000000e+00 1.4773646e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 2.2035436e-28]\n",
      "Action prob: [1.0000000e+00 2.2035436e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 1.0255133e-28]\n",
      "Action prob: [1.0000000e+00 1.0255133e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 7.9146173e-28]\n",
      "Action prob: [1.0000000e+00 7.9146173e-28], Action: 0, state: 2\n",
      "[1.0000000e+00 2.1538302e-27]\n",
      "Action prob: [1.0000000e+00 2.1538302e-27], Action: 0, state: 2\n",
      "[1.000000e+00 3.469498e-32]\n",
      "Action prob: [1.000000e+00 3.469498e-32], Action: 0, state: 3\n",
      "[1.000000e+00 3.012306e-32]\n",
      "Action prob: [1.000000e+00 3.012306e-32], Action: 0, state: 3\n",
      "[1.000000e+00 5.159488e-25]\n",
      "Action prob: [1.000000e+00 5.159488e-25], Action: 0, state: 3\n",
      "[1.0000000e+00 4.0282864e-30]\n",
      "Action prob: [1.0000000e+00 4.0282864e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 3.5365584e-28]\n",
      "Action prob: [1.0000000e+00 3.5365584e-28], Action: 0, state: 3\n",
      "[1.000000e+00 8.533013e-25]\n",
      "Action prob: [1.000000e+00 8.533013e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5544228e-26]\n",
      "Action prob: [1.0000000e+00 2.5544228e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.7449923e-37]\n",
      "Action prob: [1.0000000e+00 3.7449923e-37], Action: 0, state: 8\n",
      "[1.000000e+00 5.564812e-26]\n",
      "Action prob: [1.000000e+00 5.564812e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8137263e-32]\n",
      "Action prob: [1.0000000e+00 3.8137263e-32], Action: 0, state: 8\n",
      "[1.000000e+00 8.150001e-31]\n",
      "Action prob: [1.000000e+00 8.150001e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5666076e-32]\n",
      "Action prob: [1.0000000e+00 1.5666076e-32], Action: 0, state: 8\n",
      "[1.000000e+00 4.194841e-33]\n",
      "Action prob: [1.000000e+00 4.194841e-33], Action: 0, state: 8\n",
      "[1.000000e+00 7.079548e-31]\n",
      "Action prob: [1.000000e+00 7.079548e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5665358e-25]\n",
      "Action prob: [1.0000000e+00 2.5665358e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2726108e-24]\n",
      "Action prob: [1.0000000e+00 3.2726108e-24], Action: 0, state: 8\n",
      "[1.000000e+00 7.985471e-33]\n",
      "Action prob: [1.000000e+00 7.985471e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1534264e-25]\n",
      "Action prob: [1.0000000e+00 1.1534264e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2672844e-32]\n",
      "Action prob: [1.0000000e+00 1.2672844e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2397641e-28]\n",
      "Action prob: [1.0000000e+00 1.2397641e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4089398e-26]\n",
      "Action prob: [1.0000000e+00 2.4089398e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3053352e-31]\n",
      "Action prob: [1.0000000e+00 1.3053352e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9397562e-31]\n",
      "Action prob: [1.0000000e+00 2.9397562e-31], Action: 0, state: 8\n",
      "[1.000000e+00 1.371809e-25]\n",
      "Action prob: [1.000000e+00 1.371809e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6639332e-25]\n",
      "Action prob: [1.0000000e+00 2.6639332e-25], Action: 0, state: 8\n",
      "[1.000000e+00 8.633562e-33]\n",
      "Action prob: [1.000000e+00 8.633562e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6620727e-33]\n",
      "Action prob: [1.0000000e+00 3.6620727e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5275858e-31]\n",
      "Action prob: [1.0000000e+00 2.5275858e-31], Action: 0, state: 8\n",
      "[1.000000e+00 6.724618e-26]\n",
      "Action prob: [1.000000e+00 6.724618e-26], Action: 0, state: 8\n",
      "[1.000000e+00 2.102206e-25]\n",
      "Action prob: [1.000000e+00 2.102206e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8647917e-31]\n",
      "Action prob: [1.0000000e+00 1.8647917e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3841376e-26]\n",
      "Action prob: [1.0000000e+00 2.3841376e-26], Action: 0, state: 8\n",
      "[1.000000e+00 6.568913e-35]\n",
      "Action prob: [1.000000e+00 6.568913e-35], Action: 0, state: 8\n",
      "[1.000000e+00 6.397777e-35]\n",
      "Action prob: [1.000000e+00 6.397777e-35], Action: 0, state: 8\n",
      "[1.000000e+00 4.835294e-32]\n",
      "Action prob: [1.000000e+00 4.835294e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3491821e-33]\n",
      "Action prob: [1.0000000e+00 2.3491821e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1887476e-26]\n",
      "Action prob: [1.0000000e+00 4.1887476e-26], Action: 0, state: 8\n",
      "[1.000000e+00 2.295253e-26]\n",
      "Action prob: [1.000000e+00 2.295253e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 7.2862654e-25]\n",
      "Action prob: [1.0000000e+00 7.2862654e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6428287e-33]\n",
      "Action prob: [1.0000000e+00 2.6428287e-33], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0.,\n",
      "        0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -97300, loss is -0.0\n",
      "[1.000000e+00 6.400852e-28]\n",
      "Action prob: [1.000000e+00 6.400852e-28], Action: 0, state: 0\n",
      "[1.00000e+00 9.96376e-29]\n",
      "Action prob: [1.00000e+00 9.96376e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 2.0628112e-26]\n",
      "Action prob: [1.0000000e+00 2.0628112e-26], Action: 0, state: 0\n",
      "[1.000000e+00 5.960199e-28]\n",
      "Action prob: [1.000000e+00 5.960199e-28], Action: 0, state: 0\n",
      "[1.000000e+00 2.888603e-28]\n",
      "Action prob: [1.000000e+00 2.888603e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 1.3081138e-28]\n",
      "Action prob: [1.0000000e+00 1.3081138e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 5.2332986e-28]\n",
      "Action prob: [1.0000000e+00 5.2332986e-28], Action: 0, state: 2\n",
      "[1.000000e+00 4.522514e-29]\n",
      "Action prob: [1.000000e+00 4.522514e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 1.3139194e-29]\n",
      "Action prob: [1.0000000e+00 1.3139194e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.0608315e-27]\n",
      "Action prob: [1.0000000e+00 1.0608315e-27], Action: 0, state: 3\n",
      "[1.0000000e+00 1.7450426e-28]\n",
      "Action prob: [1.0000000e+00 1.7450426e-28], Action: 0, state: 3\n",
      "[1.000000e+00 8.056573e-27]\n",
      "Action prob: [1.000000e+00 8.056573e-27], Action: 0, state: 3\n",
      "[1.0000000e+00 1.2834629e-29]\n",
      "Action prob: [1.0000000e+00 1.2834629e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1034518e-30]\n",
      "Action prob: [1.0000000e+00 3.1034518e-30], Action: 0, state: 8\n",
      "[1.000000e+00 6.656398e-26]\n",
      "Action prob: [1.000000e+00 6.656398e-26], Action: 0, state: 8\n",
      "[1.000000e+00 4.448693e-31]\n",
      "Action prob: [1.000000e+00 4.448693e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8356195e-35]\n",
      "Action prob: [1.0000000e+00 2.8356195e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3835182e-32]\n",
      "Action prob: [1.0000000e+00 1.3835182e-32], Action: 0, state: 8\n",
      "[1.000000e+00 3.925923e-26]\n",
      "Action prob: [1.000000e+00 3.925923e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9795619e-32]\n",
      "Action prob: [1.0000000e+00 1.9795619e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5110079e-34]\n",
      "Action prob: [1.0000000e+00 3.5110079e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7180258e-30]\n",
      "Action prob: [1.0000000e+00 1.7180258e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 5.1390266e-30]\n",
      "Action prob: [1.0000000e+00 5.1390266e-30], Action: 0, state: 8\n",
      "[1.000000e+00 1.409192e-32]\n",
      "Action prob: [1.000000e+00 1.409192e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6045612e-31]\n",
      "Action prob: [1.0000000e+00 1.6045612e-31], Action: 0, state: 8\n",
      "[1.000000e+00 9.974964e-32]\n",
      "Action prob: [1.000000e+00 9.974964e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9384317e-25]\n",
      "Action prob: [1.0000000e+00 1.9384317e-25], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 1.8704685e-25]\n",
      "Action prob: [1.0000000e+00 1.8704685e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 7.0097534e-25]\n",
      "Action prob: [1.0000000e+00 7.0097534e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0673892e-25]\n",
      "Action prob: [1.0000000e+00 2.0673892e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4968756e-25]\n",
      "Action prob: [1.0000000e+00 1.4968756e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 7.1031815e-26]\n",
      "Action prob: [1.0000000e+00 7.1031815e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4472877e-32]\n",
      "Action prob: [1.0000000e+00 2.4472877e-32], Action: 0, state: 8\n",
      "[1.000000e+00 8.602274e-31]\n",
      "Action prob: [1.000000e+00 8.602274e-31], Action: 0, state: 8\n",
      "[1.000000e+00 2.735028e-30]\n",
      "Action prob: [1.000000e+00 2.735028e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1334886e-28]\n",
      "Action prob: [1.0000000e+00 4.1334886e-28], Action: 0, state: 8\n",
      "[1.00000000e+00 1.16527916e-32]\n",
      "Action prob: [1.00000000e+00 1.16527916e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4574516e-31]\n",
      "Action prob: [1.0000000e+00 1.4574516e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7228863e-25]\n",
      "Action prob: [1.0000000e+00 2.7228863e-25], Action: 0, state: 8\n",
      "[1.000000e+00 6.892234e-26]\n",
      "Action prob: [1.000000e+00 6.892234e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0584157e-27]\n",
      "Action prob: [1.0000000e+00 5.0584157e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2732466e-32]\n",
      "Action prob: [1.0000000e+00 3.2732466e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9502686e-33]\n",
      "Action prob: [1.0000000e+00 2.9502686e-33], Action: 0, state: 8\n",
      "[1.000000e+00 6.297695e-29]\n",
      "Action prob: [1.000000e+00 6.297695e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4039427e-27]\n",
      "Action prob: [1.0000000e+00 1.4039427e-27], Action: 0, state: 8\n",
      "[1.000000e+00 6.406457e-32]\n",
      "Action prob: [1.000000e+00 6.406457e-32], Action: 0, state: 8\n",
      "[1.000000e+00 4.822915e-32]\n",
      "Action prob: [1.000000e+00 4.822915e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8729994e-27]\n",
      "Action prob: [1.0000000e+00 2.8729994e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.336673e-33]\n",
      "Action prob: [1.000000e+00 9.336673e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2036773e-33]\n",
      "Action prob: [1.0000000e+00 1.2036773e-33], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -108600, loss is -0.0\n",
      "[1.0000000e+00 1.6699658e-28]\n",
      "Action prob: [1.0000000e+00 1.6699658e-28], Action: 0, state: 0\n",
      "[1.000000e+00 7.376531e-28]\n",
      "Action prob: [1.000000e+00 7.376531e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 9.4794975e-28]\n",
      "Action prob: [1.0000000e+00 9.4794975e-28], Action: 0, state: 1\n",
      "[1.000000e+00 9.461465e-29]\n",
      "Action prob: [1.000000e+00 9.461465e-29], Action: 0, state: 1\n",
      "[1.000000e+00 5.085403e-28]\n",
      "Action prob: [1.000000e+00 5.085403e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 1.7387491e-29]\n",
      "Action prob: [1.0000000e+00 1.7387491e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 3.1784054e-30]\n",
      "Action prob: [1.0000000e+00 3.1784054e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 2.9880264e-28]\n",
      "Action prob: [1.0000000e+00 2.9880264e-28], Action: 0, state: 2\n",
      "[1.00000e+00 5.52607e-29]\n",
      "Action prob: [1.00000e+00 5.52607e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 3.4854927e-34]\n",
      "Action prob: [1.0000000e+00 3.4854927e-34], Action: 0, state: 3\n",
      "[1.000000e+00 9.418801e-27]\n",
      "Action prob: [1.000000e+00 9.418801e-27], Action: 0, state: 3\n",
      "[1.0000000e+00 3.7694467e-28]\n",
      "Action prob: [1.0000000e+00 3.7694467e-28], Action: 0, state: 3\n",
      "[1.000000e+00 4.317313e-26]\n",
      "Action prob: [1.000000e+00 4.317313e-26], Action: 0, state: 3\n",
      "[1.000000e+00 4.340551e-32]\n",
      "Action prob: [1.000000e+00 4.340551e-32], Action: 0, state: 3\n",
      "[1.0000000e+00 6.0311858e-30]\n",
      "Action prob: [1.0000000e+00 6.0311858e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 1.2682089e-31]\n",
      "Action prob: [1.0000000e+00 1.2682089e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 6.7105226e-34]\n",
      "Action prob: [1.0000000e+00 6.7105226e-34], Action: 0, state: 8\n",
      "[1.000000e+00 9.531909e-25]\n",
      "Action prob: [1.000000e+00 9.531909e-25], Action: 0, state: 8\n",
      "[1.000000e+00 9.698758e-33]\n",
      "Action prob: [1.000000e+00 9.698758e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0088342e-32]\n",
      "Action prob: [1.0000000e+00 2.0088342e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 4.6145528e-26]\n",
      "Action prob: [1.0000000e+00 4.6145528e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0461592e-27]\n",
      "Action prob: [1.0000000e+00 1.0461592e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.447493e-32]\n",
      "Action prob: [1.000000e+00 9.447493e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4829142e-34]\n",
      "Action prob: [1.0000000e+00 3.4829142e-34], Action: 0, state: 8\n",
      "[1.000000e+00 5.229658e-31]\n",
      "Action prob: [1.000000e+00 5.229658e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 6.7148246e-34]\n",
      "Action prob: [1.0000000e+00 6.7148246e-34], Action: 0, state: 8\n",
      "[1.00000000e+00 1.16964095e-29]\n",
      "Action prob: [1.00000000e+00 1.16964095e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 5.1180257e-26]\n",
      "Action prob: [1.0000000e+00 5.1180257e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7897227e-33]\n",
      "Action prob: [1.0000000e+00 2.7897227e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6192372e-25]\n",
      "Action prob: [1.0000000e+00 1.6192372e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6409088e-31]\n",
      "Action prob: [1.0000000e+00 1.6409088e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9828036e-25]\n",
      "Action prob: [1.0000000e+00 2.9828036e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5254379e-30]\n",
      "Action prob: [1.0000000e+00 2.5254379e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0746035e-32]\n",
      "Action prob: [1.0000000e+00 1.0746035e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 7.3257464e-28]\n",
      "Action prob: [1.0000000e+00 7.3257464e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5753965e-27]\n",
      "Action prob: [1.0000000e+00 3.5753965e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 5.9134823e-34]\n",
      "Action prob: [1.0000000e+00 5.9134823e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 7.4760265e-34]\n",
      "Action prob: [1.0000000e+00 7.4760265e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3925348e-33]\n",
      "Action prob: [1.0000000e+00 4.3925348e-33], Action: 0, state: 8\n",
      "[1.000000e+00 6.861838e-31]\n",
      "Action prob: [1.000000e+00 6.861838e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3893572e-32]\n",
      "Action prob: [1.0000000e+00 1.3893572e-32], Action: 0, state: 8\n",
      "[1.000000e+00 6.883066e-33]\n",
      "Action prob: [1.000000e+00 6.883066e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7043524e-31]\n",
      "Action prob: [1.0000000e+00 4.7043524e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3762492e-32]\n",
      "Action prob: [1.0000000e+00 2.3762492e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9967866e-31]\n",
      "Action prob: [1.0000000e+00 1.9967866e-31], Action: 0, state: 8\n",
      "[1.000000e+00 5.706175e-33]\n",
      "Action prob: [1.000000e+00 5.706175e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1583827e-25]\n",
      "Action prob: [1.0000000e+00 1.1583827e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7827512e-33]\n",
      "Action prob: [1.0000000e+00 1.7827512e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5034453e-25]\n",
      "Action prob: [1.0000000e+00 1.5034453e-25], Action: 0, state: 8\n",
      "[1.000000e+00 3.398653e-26]\n",
      "Action prob: [1.000000e+00 3.398653e-26], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -98500, loss is -0.0\n",
      "[1.0000000e+00 1.8177579e-28]\n",
      "Action prob: [1.0000000e+00 1.8177579e-28], Action: 0, state: 0\n",
      "[1.000000e+00 2.169207e-28]\n",
      "Action prob: [1.000000e+00 2.169207e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 2.0317431e-35]\n",
      "Action prob: [1.0000000e+00 2.0317431e-35], Action: 0, state: 0\n",
      "[1.0000000e+00 6.8750726e-30]\n",
      "Action prob: [1.0000000e+00 6.8750726e-30], Action: 0, state: 1\n",
      "[1.000000e+00 7.064825e-29]\n",
      "Action prob: [1.000000e+00 7.064825e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.2426008e-27]\n",
      "Action prob: [1.0000000e+00 1.2426008e-27], Action: 0, state: 1\n",
      "[1.0000000e+00 1.9415951e-29]\n",
      "Action prob: [1.0000000e+00 1.9415951e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 1.5698824e-29]\n",
      "Action prob: [1.0000000e+00 1.5698824e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 3.5701592e-29]\n",
      "Action prob: [1.0000000e+00 3.5701592e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 4.2275705e-30]\n",
      "Action prob: [1.0000000e+00 4.2275705e-30], Action: 0, state: 2\n",
      "[1.000000e+00 7.487719e-29]\n",
      "Action prob: [1.000000e+00 7.487719e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 1.0175915e-27]\n",
      "Action prob: [1.0000000e+00 1.0175915e-27], Action: 0, state: 3\n",
      "[1.000000e+00 5.558624e-31]\n",
      "Action prob: [1.000000e+00 5.558624e-31], Action: 0, state: 3\n",
      "[1.0000000e+00 2.6879866e-30]\n",
      "Action prob: [1.0000000e+00 2.6879866e-30], Action: 0, state: 3\n",
      "[1.000000e+00 1.797884e-27]\n",
      "Action prob: [1.000000e+00 1.797884e-27], Action: 0, state: 3\n",
      "[1.000000e+00 4.133574e-25]\n",
      "Action prob: [1.000000e+00 4.133574e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 6.9009206e-32]\n",
      "Action prob: [1.0000000e+00 6.9009206e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4536624e-25]\n",
      "Action prob: [1.0000000e+00 2.4536624e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 8.7257604e-36]\n",
      "Action prob: [1.0000000e+00 8.7257604e-36], Action: 0, state: 8\n",
      "[1.000000e+00 1.684704e-25]\n",
      "Action prob: [1.000000e+00 1.684704e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2721182e-31]\n",
      "Action prob: [1.0000000e+00 2.2721182e-31], Action: 0, state: 8\n",
      "[1.000000e+00 8.544648e-31]\n",
      "Action prob: [1.000000e+00 8.544648e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3074118e-32]\n",
      "Action prob: [1.0000000e+00 3.3074118e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 9.3988524e-33]\n",
      "Action prob: [1.0000000e+00 9.3988524e-33], Action: 0, state: 8\n",
      "[1.000000e+00 1.806754e-26]\n",
      "Action prob: [1.000000e+00 1.806754e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7736214e-36]\n",
      "Action prob: [1.0000000e+00 2.7736214e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3604565e-25]\n",
      "Action prob: [1.0000000e+00 3.3604565e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9020134e-34]\n",
      "Action prob: [1.0000000e+00 2.9020134e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5375612e-27]\n",
      "Action prob: [1.0000000e+00 2.5375612e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3207257e-31]\n",
      "Action prob: [1.0000000e+00 3.3207257e-31], Action: 0, state: 8\n",
      "[1.0000e+00 1.1805e-25]\n",
      "Action prob: [1.0000e+00 1.1805e-25], Action: 0, state: 8\n",
      "[1.000000e+00 7.977459e-34]\n",
      "Action prob: [1.000000e+00 7.977459e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1489756e-33]\n",
      "Action prob: [1.0000000e+00 4.1489756e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.2554672e-27]\n",
      "Action prob: [1.0000000e+00 5.2554672e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 9.6714526e-26]\n",
      "Action prob: [1.0000000e+00 9.6714526e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2314061e-32]\n",
      "Action prob: [1.0000000e+00 4.2314061e-32], Action: 0, state: 8\n",
      "[1.000000e+00 7.315418e-27]\n",
      "Action prob: [1.000000e+00 7.315418e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.997325e-34]\n",
      "Action prob: [1.000000e+00 7.997325e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2847966e-25]\n",
      "Action prob: [1.0000000e+00 4.2847966e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9278845e-34]\n",
      "Action prob: [1.0000000e+00 3.9278845e-34], Action: 0, state: 8\n",
      "[1.00000e+00 2.13411e-40]\n",
      "Action prob: [1.00000e+00 2.13411e-40], Action: 0, state: 8\n",
      "[1.000000e+00 4.094479e-26]\n",
      "Action prob: [1.000000e+00 4.094479e-26], Action: 0, state: 8\n",
      "[1.000000e+00 8.345455e-27]\n",
      "Action prob: [1.000000e+00 8.345455e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.010197e-28]\n",
      "Action prob: [1.000000e+00 7.010197e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 8.0775876e-28]\n",
      "Action prob: [1.0000000e+00 8.0775876e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0116694e-34]\n",
      "Action prob: [1.0000000e+00 2.0116694e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8736798e-34]\n",
      "Action prob: [1.0000000e+00 2.8736798e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 5.2111725e-33]\n",
      "Action prob: [1.0000000e+00 5.2111725e-33], Action: 0, state: 8\n",
      "[1.0000e+00 3.7023e-40]\n",
      "Action prob: [1.0000e+00 3.7023e-40], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0262624e-25]\n",
      "Action prob: [1.0000000e+00 1.0262624e-25], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., -0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for this episode -97300, loss is -0.0\n",
      "[1.000000e+00 6.665764e-29]\n",
      "Action prob: [1.000000e+00 6.665764e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.8043534e-30]\n",
      "Action prob: [1.0000000e+00 1.8043534e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 1.1516655e-29]\n",
      "Action prob: [1.0000000e+00 1.1516655e-29], Action: 0, state: 0\n",
      "[1.000000e+00 1.522337e-29]\n",
      "Action prob: [1.000000e+00 1.522337e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.3879025e-29]\n",
      "Action prob: [1.0000000e+00 1.3879025e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 3.0086028e-28]\n",
      "Action prob: [1.0000000e+00 3.0086028e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 1.4870982e-32]\n",
      "Action prob: [1.0000000e+00 1.4870982e-32], Action: 0, state: 1\n",
      "[1.0000000e+00 2.2296968e-28]\n",
      "Action prob: [1.0000000e+00 2.2296968e-28], Action: 0, state: 2\n",
      "[1.0000000e+00 2.8997757e-28]\n",
      "Action prob: [1.0000000e+00 2.8997757e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.2486792e-33]\n",
      "Action prob: [1.0000000e+00 1.2486792e-33], Action: 0, state: 8\n",
      "[1.000000e+00 3.584519e-27]\n",
      "Action prob: [1.000000e+00 3.584519e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7691337e-26]\n",
      "Action prob: [1.0000000e+00 1.7691337e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9245337e-32]\n",
      "Action prob: [1.0000000e+00 3.9245337e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5255478e-27]\n",
      "Action prob: [1.0000000e+00 2.5255478e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0279236e-25]\n",
      "Action prob: [1.0000000e+00 1.0279236e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1660487e-31]\n",
      "Action prob: [1.0000000e+00 3.1660487e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3023392e-33]\n",
      "Action prob: [1.0000000e+00 2.3023392e-33], Action: 0, state: 8\n",
      "[1.000000e+00 7.675979e-33]\n",
      "Action prob: [1.000000e+00 7.675979e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5950201e-34]\n",
      "Action prob: [1.0000000e+00 1.5950201e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8070746e-37]\n",
      "Action prob: [1.0000000e+00 2.8070746e-37], Action: 0, state: 8\n",
      "[1.000000e+00 9.958451e-27]\n",
      "Action prob: [1.000000e+00 9.958451e-27], Action: 0, state: 8\n",
      "[1.00000e+00 4.91198e-33]\n",
      "Action prob: [1.00000e+00 4.91198e-33], Action: 0, state: 8\n",
      "[1.000000e+00 3.137937e-31]\n",
      "Action prob: [1.000000e+00 3.137937e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2476409e-26]\n",
      "Action prob: [1.0000000e+00 1.2476409e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2720166e-36]\n",
      "Action prob: [1.0000000e+00 3.2720166e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3702703e-34]\n",
      "Action prob: [1.0000000e+00 1.3702703e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0386754e-36]\n",
      "Action prob: [1.0000000e+00 4.0386754e-36], Action: 0, state: 8\n",
      "[1.000000e+00 4.345573e-31]\n",
      "Action prob: [1.000000e+00 4.345573e-31], Action: 0, state: 8\n",
      "[1.000000e+00 9.561512e-26]\n",
      "Action prob: [1.000000e+00 9.561512e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8909813e-31]\n",
      "Action prob: [1.0000000e+00 1.8909813e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 5.6622917e-24]\n",
      "Action prob: [1.0000000e+00 5.6622917e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0249228e-31]\n",
      "Action prob: [1.0000000e+00 2.0249228e-31], Action: 0, state: 8\n",
      "[1.000000e+00 4.732916e-32]\n",
      "Action prob: [1.000000e+00 4.732916e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4204927e-26]\n",
      "Action prob: [1.0000000e+00 1.4204927e-26], Action: 0, state: 8\n",
      "[1.00000e+00 9.97031e-27]\n",
      "Action prob: [1.00000e+00 9.97031e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0847101e-25]\n",
      "Action prob: [1.0000000e+00 1.0847101e-25], Action: 0, state: 8\n",
      "[1.000000e+00 1.770801e-34]\n",
      "Action prob: [1.000000e+00 1.770801e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.000393e-27]\n",
      "Action prob: [1.000000e+00 7.000393e-27], Action: 0, state: 8\n",
      "[1.000000e+00 3.867308e-29]\n",
      "Action prob: [1.000000e+00 3.867308e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5107942e-26]\n",
      "Action prob: [1.0000000e+00 2.5107942e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 7.8669994e-35]\n",
      "Action prob: [1.0000000e+00 7.8669994e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9109157e-26]\n",
      "Action prob: [1.0000000e+00 3.9109157e-26], Action: 0, state: 8\n",
      "[1.000000e+00 9.766661e-26]\n",
      "Action prob: [1.000000e+00 9.766661e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5284732e-25]\n",
      "Action prob: [1.0000000e+00 1.5284732e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9501363e-35]\n",
      "Action prob: [1.0000000e+00 3.9501363e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4916726e-31]\n",
      "Action prob: [1.0000000e+00 1.4916726e-31], Action: 0, state: 8\n",
      "[1.0000e+00 1.1675e-31]\n",
      "Action prob: [1.0000e+00 1.1675e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5386817e-25]\n",
      "Action prob: [1.0000000e+00 1.5386817e-25], Action: 0, state: 8\n",
      "[1.00000e+00 1.90861e-27]\n",
      "Action prob: [1.00000e+00 1.90861e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6485045e-26]\n",
      "Action prob: [1.0000000e+00 1.6485045e-26], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -119000, loss is -0.0\n",
      "[1.0000000e+00 2.0604723e-29]\n",
      "Action prob: [1.0000000e+00 2.0604723e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.7684941e-32]\n",
      "Action prob: [1.0000000e+00 1.7684941e-32], Action: 0, state: 0\n",
      "[1.0000000e+00 1.6896177e-29]\n",
      "Action prob: [1.0000000e+00 1.6896177e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.5001947e-28]\n",
      "Action prob: [1.0000000e+00 1.5001947e-28], Action: 0, state: 2\n",
      "[1.000000e+00 6.392305e-30]\n",
      "Action prob: [1.000000e+00 6.392305e-30], Action: 0, state: 2\n",
      "[1.000000e+00 6.594829e-26]\n",
      "Action prob: [1.000000e+00 6.594829e-26], Action: 0, state: 3\n",
      "[1.0000000e+00 3.0735767e-28]\n",
      "Action prob: [1.0000000e+00 3.0735767e-28], Action: 0, state: 3\n",
      "[1.000000e+00 8.600588e-34]\n",
      "Action prob: [1.000000e+00 8.600588e-34], Action: 0, state: 3\n",
      "[1.0000000e+00 2.5434327e-28]\n",
      "Action prob: [1.0000000e+00 2.5434327e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.2622777e-30]\n",
      "Action prob: [1.0000000e+00 1.2622777e-30], Action: 0, state: 3\n",
      "[1.000000e+00 3.437695e-32]\n",
      "Action prob: [1.000000e+00 3.437695e-32], Action: 0, state: 8\n",
      "[1.000000e+00 6.542075e-29]\n",
      "Action prob: [1.000000e+00 6.542075e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9296213e-34]\n",
      "Action prob: [1.0000000e+00 1.9296213e-34], Action: 0, state: 8\n",
      "[1.000000e+00 1.440789e-33]\n",
      "Action prob: [1.000000e+00 1.440789e-33], Action: 0, state: 8\n",
      "[1.000000e+00 8.352398e-27]\n",
      "Action prob: [1.000000e+00 8.352398e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0996688e-33]\n",
      "Action prob: [1.0000000e+00 4.0996688e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4335086e-33]\n",
      "Action prob: [1.0000000e+00 1.4335086e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1568133e-28]\n",
      "Action prob: [1.0000000e+00 1.1568133e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 6.0008594e-26]\n",
      "Action prob: [1.0000000e+00 6.0008594e-26], Action: 0, state: 8\n",
      "[1.000000e+00 1.578943e-32]\n",
      "Action prob: [1.000000e+00 1.578943e-32], Action: 0, state: 8\n",
      "[1.000000e+00 3.652645e-31]\n",
      "Action prob: [1.000000e+00 3.652645e-31], Action: 0, state: 8\n",
      "[1.000000e+00 2.347508e-32]\n",
      "Action prob: [1.000000e+00 2.347508e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1573596e-33]\n",
      "Action prob: [1.0000000e+00 2.1573596e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2196419e-33]\n",
      "Action prob: [1.0000000e+00 1.2196419e-33], Action: 0, state: 8\n",
      "[1.000000e+00 3.774808e-31]\n",
      "Action prob: [1.000000e+00 3.774808e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8304177e-26]\n",
      "Action prob: [1.0000000e+00 3.8304177e-26], Action: 0, state: 8\n",
      "[1.000000e+00 4.625162e-26]\n",
      "Action prob: [1.000000e+00 4.625162e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1142055e-32]\n",
      "Action prob: [1.0000000e+00 2.1142055e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8945746e-26]\n",
      "Action prob: [1.0000000e+00 1.8945746e-26], Action: 0, state: 8\n",
      "[1.000000e+00 3.795266e-32]\n",
      "Action prob: [1.000000e+00 3.795266e-32], Action: 0, state: 8\n",
      "[1.000000e+00 9.605425e-32]\n",
      "Action prob: [1.000000e+00 9.605425e-32], Action: 0, state: 8\n",
      "[1.000000e+00 6.304363e-26]\n",
      "Action prob: [1.000000e+00 6.304363e-26], Action: 0, state: 8\n",
      "[1.00000e+00 4.11873e-33]\n",
      "Action prob: [1.00000e+00 4.11873e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9354826e-26]\n",
      "Action prob: [1.0000000e+00 1.9354826e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0278052e-34]\n",
      "Action prob: [1.0000000e+00 1.0278052e-34], Action: 0, state: 8\n",
      "[1.000000e+00 6.428166e-26]\n",
      "Action prob: [1.000000e+00 6.428166e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 6.9912434e-26]\n",
      "Action prob: [1.0000000e+00 6.9912434e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3907871e-27]\n",
      "Action prob: [1.0000000e+00 1.3907871e-27], Action: 0, state: 8\n",
      "[1.000000e+00 8.247105e-32]\n",
      "Action prob: [1.000000e+00 8.247105e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0558619e-34]\n",
      "Action prob: [1.0000000e+00 1.0558619e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.906749e-26]\n",
      "Action prob: [1.000000e+00 7.906749e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7698979e-32]\n",
      "Action prob: [1.0000000e+00 1.7698979e-32], Action: 0, state: 8\n",
      "[1.000000e+00 8.462985e-34]\n",
      "Action prob: [1.000000e+00 8.462985e-34], Action: 0, state: 8\n",
      "[1.000000e+00 1.077666e-32]\n",
      "Action prob: [1.000000e+00 1.077666e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 8.2549385e-33]\n",
      "Action prob: [1.0000000e+00 8.2549385e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.7416176e-32]\n",
      "Action prob: [1.0000000e+00 3.7416176e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2384972e-31]\n",
      "Action prob: [1.0000000e+00 2.2384972e-31], Action: 0, state: 8\n",
      "[1.000000e+00 5.175925e-34]\n",
      "Action prob: [1.000000e+00 5.175925e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4637744e-25]\n",
      "Action prob: [1.0000000e+00 1.4637744e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 4.5484906e-26]\n",
      "Action prob: [1.0000000e+00 4.5484906e-26], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -117000, loss is -0.0\n",
      "[1.0000000e+00 2.2023564e-30]\n",
      "Action prob: [1.0000000e+00 2.2023564e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 1.0287296e-29]\n",
      "Action prob: [1.0000000e+00 1.0287296e-29], Action: 0, state: 1\n",
      "[1.000000e+00 4.514725e-28]\n",
      "Action prob: [1.000000e+00 4.514725e-28], Action: 0, state: 1\n",
      "[1.00000e+00 7.09161e-29]\n",
      "Action prob: [1.00000e+00 7.09161e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.1583019e-27]\n",
      "Action prob: [1.0000000e+00 1.1583019e-27], Action: 0, state: 2\n",
      "[1.000000e+00 9.384684e-29]\n",
      "Action prob: [1.000000e+00 9.384684e-29], Action: 0, state: 2\n",
      "[1.000000e+00 5.577236e-29]\n",
      "Action prob: [1.000000e+00 5.577236e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 1.3127234e-27]\n",
      "Action prob: [1.0000000e+00 1.3127234e-27], Action: 0, state: 3\n",
      "[1.0000000e+00 1.3093935e-33]\n",
      "Action prob: [1.0000000e+00 1.3093935e-33], Action: 0, state: 8\n",
      "[1.000000e+00 7.232072e-33]\n",
      "Action prob: [1.000000e+00 7.232072e-33], Action: 0, state: 8\n",
      "[1.000000e+00 2.889137e-32]\n",
      "Action prob: [1.000000e+00 2.889137e-32], Action: 0, state: 8\n",
      "[1.000000e+00 6.434787e-27]\n",
      "Action prob: [1.000000e+00 6.434787e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6153135e-25]\n",
      "Action prob: [1.0000000e+00 1.6153135e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3583222e-25]\n",
      "Action prob: [1.0000000e+00 1.3583222e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0645421e-32]\n",
      "Action prob: [1.0000000e+00 1.0645421e-32], Action: 0, state: 8\n",
      "[1.000000e+00 7.902946e-27]\n",
      "Action prob: [1.000000e+00 7.902946e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 6.9767006e-25]\n",
      "Action prob: [1.0000000e+00 6.9767006e-25], Action: 0, state: 8\n",
      "[1.00000000e+00 1.19991685e-35]\n",
      "Action prob: [1.00000000e+00 1.19991685e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3558228e-31]\n",
      "Action prob: [1.0000000e+00 1.3558228e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2491213e-27]\n",
      "Action prob: [1.0000000e+00 1.2491213e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.613062e-37]\n",
      "Action prob: [1.000000e+00 9.613062e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 3.7416297e-33]\n",
      "Action prob: [1.0000000e+00 3.7416297e-33], Action: 0, state: 8\n",
      "[1.000000e+00 4.109014e-34]\n",
      "Action prob: [1.000000e+00 4.109014e-34], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 9.020973e-27]\n",
      "Action prob: [1.000000e+00 9.020973e-27], Action: 0, state: 8\n",
      "[1.000000e+00 6.008151e-31]\n",
      "Action prob: [1.000000e+00 6.008151e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1272141e-26]\n",
      "Action prob: [1.0000000e+00 1.1272141e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 6.6535854e-32]\n",
      "Action prob: [1.0000000e+00 6.6535854e-32], Action: 0, state: 8\n",
      "[1.000000e+00 8.865344e-34]\n",
      "Action prob: [1.000000e+00 8.865344e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8495913e-34]\n",
      "Action prob: [1.0000000e+00 3.8495913e-34], Action: 0, state: 8\n",
      "[1.000000e+00 4.676271e-27]\n",
      "Action prob: [1.000000e+00 4.676271e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2966908e-33]\n",
      "Action prob: [1.0000000e+00 3.2966908e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1932783e-36]\n",
      "Action prob: [1.0000000e+00 2.1932783e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7724504e-26]\n",
      "Action prob: [1.0000000e+00 1.7724504e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 7.9818506e-32]\n",
      "Action prob: [1.0000000e+00 7.9818506e-32], Action: 0, state: 8\n",
      "[1.000000e+00 2.030306e-31]\n",
      "Action prob: [1.000000e+00 2.030306e-31], Action: 0, state: 8\n",
      "[1.000000e+00 1.895348e-26]\n",
      "Action prob: [1.000000e+00 1.895348e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4519575e-34]\n",
      "Action prob: [1.0000000e+00 2.4519575e-34], Action: 0, state: 8\n",
      "[1.000000e+00 9.464798e-34]\n",
      "Action prob: [1.000000e+00 9.464798e-34], Action: 0, state: 8\n",
      "[1.000000e+00 4.901534e-26]\n",
      "Action prob: [1.000000e+00 4.901534e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8716683e-26]\n",
      "Action prob: [1.0000000e+00 3.8716683e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8009057e-33]\n",
      "Action prob: [1.0000000e+00 1.8009057e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8931659e-26]\n",
      "Action prob: [1.0000000e+00 1.8931659e-26], Action: 0, state: 8\n",
      "[1.000000e+00 1.557778e-37]\n",
      "Action prob: [1.000000e+00 1.557778e-37], Action: 0, state: 8\n",
      "[1.000000e+00 5.186025e-26]\n",
      "Action prob: [1.000000e+00 5.186025e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4760536e-33]\n",
      "Action prob: [1.0000000e+00 3.4760536e-33], Action: 0, state: 8\n",
      "[1.000000e+00 7.797062e-34]\n",
      "Action prob: [1.000000e+00 7.797062e-34], Action: 0, state: 8\n",
      "[1.000000e+00 2.401889e-29]\n",
      "Action prob: [1.000000e+00 2.401889e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5972734e-26]\n",
      "Action prob: [1.0000000e+00 2.5972734e-26], Action: 0, state: 8\n",
      "[1.000000e+00 5.506484e-35]\n",
      "Action prob: [1.000000e+00 5.506484e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5339503e-31]\n",
      "Action prob: [1.0000000e+00 3.5339503e-31], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -123400, loss is -0.0\n",
      "[1.0000000e+00 1.5414287e-28]\n",
      "Action prob: [1.0000000e+00 1.5414287e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 6.9639797e-28]\n",
      "Action prob: [1.0000000e+00 6.9639797e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 3.0256452e-30]\n",
      "Action prob: [1.0000000e+00 3.0256452e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 7.7755735e-30]\n",
      "Action prob: [1.0000000e+00 7.7755735e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 4.6085472e-29]\n",
      "Action prob: [1.0000000e+00 4.6085472e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 4.5942264e-28]\n",
      "Action prob: [1.0000000e+00 4.5942264e-28], Action: 0, state: 3\n",
      "[1.000000e+00 8.952606e-29]\n",
      "Action prob: [1.000000e+00 8.952606e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.6026489e-28]\n",
      "Action prob: [1.0000000e+00 1.6026489e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.6541823e-31]\n",
      "Action prob: [1.0000000e+00 1.6541823e-31], Action: 0, state: 8\n",
      "[1.000000e+00 5.249319e-26]\n",
      "Action prob: [1.000000e+00 5.249319e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3605624e-26]\n",
      "Action prob: [1.0000000e+00 4.3605624e-26], Action: 0, state: 8\n",
      "[1.000000e+00 3.080318e-33]\n",
      "Action prob: [1.000000e+00 3.080318e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 6.9376924e-31]\n",
      "Action prob: [1.0000000e+00 6.9376924e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 6.2395255e-26]\n",
      "Action prob: [1.0000000e+00 6.2395255e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3814937e-25]\n",
      "Action prob: [1.0000000e+00 2.3814937e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6865733e-33]\n",
      "Action prob: [1.0000000e+00 3.6865733e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7234947e-29]\n",
      "Action prob: [1.0000000e+00 1.7234947e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0104839e-30]\n",
      "Action prob: [1.0000000e+00 1.0104839e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2297953e-26]\n",
      "Action prob: [1.0000000e+00 3.2297953e-26], Action: 0, state: 8\n",
      "[1.000000e+00 4.603537e-30]\n",
      "Action prob: [1.000000e+00 4.603537e-30], Action: 0, state: 8\n",
      "[1.000000e+00 5.243595e-26]\n",
      "Action prob: [1.000000e+00 5.243595e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2962773e-34]\n",
      "Action prob: [1.0000000e+00 1.2962773e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2541831e-26]\n",
      "Action prob: [1.0000000e+00 1.2541831e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.7140054e-30]\n",
      "Action prob: [1.0000000e+00 3.7140054e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8328448e-33]\n",
      "Action prob: [1.0000000e+00 3.8328448e-33], Action: 0, state: 8\n",
      "[1.000000e+00 9.616424e-32]\n",
      "Action prob: [1.000000e+00 9.616424e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1003702e-36]\n",
      "Action prob: [1.0000000e+00 1.1003702e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2772415e-34]\n",
      "Action prob: [1.0000000e+00 3.2772415e-34], Action: 0, state: 8\n",
      "[1.000000e+00 4.369071e-26]\n",
      "Action prob: [1.000000e+00 4.369071e-26], Action: 0, state: 8\n",
      "[1.000000e+00 3.845029e-33]\n",
      "Action prob: [1.000000e+00 3.845029e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6743708e-34]\n",
      "Action prob: [1.0000000e+00 3.6743708e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.119226e-30]\n",
      "Action prob: [1.000000e+00 7.119226e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0853045e-26]\n",
      "Action prob: [1.0000000e+00 2.0853045e-26], Action: 0, state: 8\n",
      "[1.000000e+00 1.902956e-39]\n",
      "Action prob: [1.000000e+00 1.902956e-39], Action: 0, state: 8\n",
      "[1.000000e+00 2.475963e-34]\n",
      "Action prob: [1.000000e+00 2.475963e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3188134e-32]\n",
      "Action prob: [1.0000000e+00 1.3188134e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8524032e-26]\n",
      "Action prob: [1.0000000e+00 1.8524032e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2073984e-32]\n",
      "Action prob: [1.0000000e+00 1.2073984e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2415822e-27]\n",
      "Action prob: [1.0000000e+00 4.2415822e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9226804e-32]\n",
      "Action prob: [1.0000000e+00 2.9226804e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 5.5609924e-26]\n",
      "Action prob: [1.0000000e+00 5.5609924e-26], Action: 0, state: 8\n",
      "[1.000000e+00 4.747336e-36]\n",
      "Action prob: [1.000000e+00 4.747336e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9742965e-26]\n",
      "Action prob: [1.0000000e+00 1.9742965e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2567309e-26]\n",
      "Action prob: [1.0000000e+00 2.2567309e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0593613e-27]\n",
      "Action prob: [1.0000000e+00 5.0593613e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9689942e-36]\n",
      "Action prob: [1.0000000e+00 2.9689942e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5672345e-33]\n",
      "Action prob: [1.0000000e+00 1.5672345e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0471468e-35]\n",
      "Action prob: [1.0000000e+00 3.0471468e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0259271e-31]\n",
      "Action prob: [1.0000000e+00 2.0259271e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4181266e-26]\n",
      "Action prob: [1.0000000e+00 1.4181266e-26], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., 0., 0., 0., -0.,\n",
      "        0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -123800, loss is -0.0\n",
      "[1.0000000e+00 4.3590924e-29]\n",
      "Action prob: [1.0000000e+00 4.3590924e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 3.1698225e-29]\n",
      "Action prob: [1.0000000e+00 3.1698225e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 4.6782802e-30]\n",
      "Action prob: [1.0000000e+00 4.6782802e-30], Action: 0, state: 1\n",
      "[1.000000e+00 2.059875e-29]\n",
      "Action prob: [1.000000e+00 2.059875e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 3.0169781e-30]\n",
      "Action prob: [1.0000000e+00 3.0169781e-30], Action: 0, state: 2\n",
      "[1.000000e+00 7.448348e-29]\n",
      "Action prob: [1.000000e+00 7.448348e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 3.9382017e-29]\n",
      "Action prob: [1.0000000e+00 3.9382017e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 2.7095144e-29]\n",
      "Action prob: [1.0000000e+00 2.7095144e-29], Action: 0, state: 3\n",
      "[1.000000e+00 8.501942e-27]\n",
      "Action prob: [1.000000e+00 8.501942e-27], Action: 0, state: 3\n",
      "[1.000000e+00 2.565219e-29]\n",
      "Action prob: [1.000000e+00 2.565219e-29], Action: 0, state: 3\n",
      "[1.000000e+00 2.926534e-29]\n",
      "Action prob: [1.000000e+00 2.926534e-29], Action: 0, state: 3\n",
      "[1.000000e+00 7.412068e-29]\n",
      "Action prob: [1.000000e+00 7.412068e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.7140828e-25]\n",
      "Action prob: [1.0000000e+00 1.7140828e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3368104e-32]\n",
      "Action prob: [1.0000000e+00 4.3368104e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3186707e-33]\n",
      "Action prob: [1.0000000e+00 3.3186707e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3226364e-26]\n",
      "Action prob: [1.0000000e+00 1.3226364e-26], Action: 0, state: 8\n",
      "[1.000000e+00 4.533608e-27]\n",
      "Action prob: [1.000000e+00 4.533608e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1784072e-26]\n",
      "Action prob: [1.0000000e+00 1.1784072e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7784772e-32]\n",
      "Action prob: [1.0000000e+00 2.7784772e-32], Action: 0, state: 8\n",
      "[1.000000e+00 9.678061e-33]\n",
      "Action prob: [1.000000e+00 9.678061e-33], Action: 0, state: 8\n",
      "[1.000000e+00 7.302208e-33]\n",
      "Action prob: [1.000000e+00 7.302208e-33], Action: 0, state: 8\n",
      "[1.000000e+00 4.321203e-33]\n",
      "Action prob: [1.000000e+00 4.321203e-33], Action: 0, state: 8\n",
      "[1.000000e+00 5.928486e-32]\n",
      "Action prob: [1.000000e+00 5.928486e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7002626e-31]\n",
      "Action prob: [1.0000000e+00 4.7002626e-31], Action: 0, state: 8\n",
      "[1.000000e+00 2.528895e-33]\n",
      "Action prob: [1.000000e+00 2.528895e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2107952e-26]\n",
      "Action prob: [1.0000000e+00 2.2107952e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2410166e-32]\n",
      "Action prob: [1.0000000e+00 3.2410166e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3451629e-25]\n",
      "Action prob: [1.0000000e+00 1.3451629e-25], Action: 0, state: 8\n",
      "[1.000000e+00 1.706463e-32]\n",
      "Action prob: [1.000000e+00 1.706463e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2233976e-33]\n",
      "Action prob: [1.0000000e+00 1.2233976e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9304625e-32]\n",
      "Action prob: [1.0000000e+00 1.9304625e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 6.6187673e-35]\n",
      "Action prob: [1.0000000e+00 6.6187673e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 6.6310055e-33]\n",
      "Action prob: [1.0000000e+00 6.6310055e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9051626e-34]\n",
      "Action prob: [1.0000000e+00 1.9051626e-34], Action: 0, state: 8\n",
      "[1.000e+00 9.167e-42]\n",
      "Action prob: [1.000e+00 9.167e-42], Action: 0, state: 8\n",
      "[1.000000e+00 7.679166e-27]\n",
      "Action prob: [1.000000e+00 7.679166e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2681743e-32]\n",
      "Action prob: [1.0000000e+00 1.2681743e-32], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 4.1613073e-33]\n",
      "Action prob: [1.0000000e+00 4.1613073e-33], Action: 0, state: 8\n",
      "[1.000000e+00 1.789401e-33]\n",
      "Action prob: [1.000000e+00 1.789401e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 7.2879816e-27]\n",
      "Action prob: [1.0000000e+00 7.2879816e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.729736e-37]\n",
      "Action prob: [1.000000e+00 7.729736e-37], Action: 0, state: 8\n",
      "[1.00000e+00 2.24614e-27]\n",
      "Action prob: [1.00000e+00 2.24614e-27], Action: 0, state: 8\n",
      "[1.000000e+00 6.738151e-26]\n",
      "Action prob: [1.000000e+00 6.738151e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1566118e-33]\n",
      "Action prob: [1.0000000e+00 1.1566118e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3883947e-27]\n",
      "Action prob: [1.0000000e+00 4.3883947e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0391963e-34]\n",
      "Action prob: [1.0000000e+00 3.0391963e-34], Action: 0, state: 8\n",
      "[1.000000e+00 9.274439e-27]\n",
      "Action prob: [1.000000e+00 9.274439e-27], Action: 0, state: 8\n",
      "[1.00000000e+00 1.25332695e-26]\n",
      "Action prob: [1.00000000e+00 1.25332695e-26], Action: 0, state: 8\n",
      "[1.000000e+00 1.187228e-34]\n",
      "Action prob: [1.000000e+00 1.187228e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8796814e-26]\n",
      "Action prob: [1.0000000e+00 3.8796814e-26], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -109500, loss is -0.0\n",
      "[1.0000000e+00 2.5131667e-29]\n",
      "Action prob: [1.0000000e+00 2.5131667e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 9.9601446e-30]\n",
      "Action prob: [1.0000000e+00 9.9601446e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.4638559e-28]\n",
      "Action prob: [1.0000000e+00 1.4638559e-28], Action: 0, state: 2\n",
      "[1.000000e+00 5.522783e-29]\n",
      "Action prob: [1.000000e+00 5.522783e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 1.8533272e-28]\n",
      "Action prob: [1.0000000e+00 1.8533272e-28], Action: 0, state: 2\n",
      "[1.000000e+00 2.336792e-35]\n",
      "Action prob: [1.000000e+00 2.336792e-35], Action: 0, state: 3\n",
      "[1.000000e+00 5.547918e-34]\n",
      "Action prob: [1.000000e+00 5.547918e-34], Action: 0, state: 3\n",
      "[1.0000000e+00 2.1645026e-29]\n",
      "Action prob: [1.0000000e+00 2.1645026e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 2.9561613e-25]\n",
      "Action prob: [1.0000000e+00 2.9561613e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6841404e-26]\n",
      "Action prob: [1.0000000e+00 3.6841404e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 6.4161995e-37]\n",
      "Action prob: [1.0000000e+00 6.4161995e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 5.9087473e-34]\n",
      "Action prob: [1.0000000e+00 5.9087473e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5217599e-32]\n",
      "Action prob: [1.0000000e+00 1.5217599e-32], Action: 0, state: 8\n",
      "[1.000000e+00 8.393155e-34]\n",
      "Action prob: [1.000000e+00 8.393155e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0358821e-34]\n",
      "Action prob: [1.0000000e+00 1.0358821e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.5387497e-26]\n",
      "Action prob: [1.0000000e+00 4.5387497e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5546958e-31]\n",
      "Action prob: [1.0000000e+00 1.5546958e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4807518e-33]\n",
      "Action prob: [1.0000000e+00 1.4807518e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1665872e-34]\n",
      "Action prob: [1.0000000e+00 2.1665872e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.5054564e-26]\n",
      "Action prob: [1.0000000e+00 4.5054564e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7122642e-27]\n",
      "Action prob: [1.0000000e+00 1.7122642e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4482028e-32]\n",
      "Action prob: [1.0000000e+00 2.4482028e-32], Action: 0, state: 8\n",
      "[1.000000e+00 9.020631e-34]\n",
      "Action prob: [1.000000e+00 9.020631e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4032699e-32]\n",
      "Action prob: [1.0000000e+00 1.4032699e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9011113e-26]\n",
      "Action prob: [1.0000000e+00 3.9011113e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7024023e-36]\n",
      "Action prob: [1.0000000e+00 1.7024023e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5601037e-32]\n",
      "Action prob: [1.0000000e+00 3.5601037e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4458971e-35]\n",
      "Action prob: [1.0000000e+00 1.4458971e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4700234e-27]\n",
      "Action prob: [1.0000000e+00 1.4700234e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0295435e-31]\n",
      "Action prob: [1.0000000e+00 5.0295435e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9454156e-31]\n",
      "Action prob: [1.0000000e+00 3.9454156e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6529781e-27]\n",
      "Action prob: [1.0000000e+00 2.6529781e-27], Action: 0, state: 8\n",
      "[1.000000e+00 8.534372e-27]\n",
      "Action prob: [1.000000e+00 8.534372e-27], Action: 0, state: 8\n",
      "[1.000000e+00 6.578979e-32]\n",
      "Action prob: [1.000000e+00 6.578979e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0088884e-32]\n",
      "Action prob: [1.0000000e+00 1.0088884e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4913862e-26]\n",
      "Action prob: [1.0000000e+00 1.4913862e-26], Action: 0, state: 8\n",
      "[1.00000000e+00 1.08603534e-32]\n",
      "Action prob: [1.00000000e+00 1.08603534e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1451308e-34]\n",
      "Action prob: [1.0000000e+00 1.1451308e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 6.5242596e-28]\n",
      "Action prob: [1.0000000e+00 6.5242596e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3695851e-35]\n",
      "Action prob: [1.0000000e+00 1.3695851e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6105798e-27]\n",
      "Action prob: [1.0000000e+00 3.6105798e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7425103e-33]\n",
      "Action prob: [1.0000000e+00 4.7425103e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0967076e-35]\n",
      "Action prob: [1.0000000e+00 5.0967076e-35], Action: 0, state: 8\n",
      "[1.00000e+00 7.18209e-33]\n",
      "Action prob: [1.00000e+00 7.18209e-33], Action: 0, state: 8\n",
      "[1.000000e+00 4.318218e-34]\n",
      "Action prob: [1.000000e+00 4.318218e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7795447e-32]\n",
      "Action prob: [1.0000000e+00 4.7795447e-32], Action: 0, state: 8\n",
      "[1.000000e+00 5.112397e-37]\n",
      "Action prob: [1.000000e+00 5.112397e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7098048e-33]\n",
      "Action prob: [1.0000000e+00 1.7098048e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3212465e-33]\n",
      "Action prob: [1.0000000e+00 2.3212465e-33], Action: 0, state: 8\n",
      "[1.000000e+00 9.525647e-27]\n",
      "Action prob: [1.000000e+00 9.525647e-27], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., -0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -124200, loss is -0.0\n",
      "[1.0000000e+00 3.2750878e-29]\n",
      "Action prob: [1.0000000e+00 3.2750878e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.8688528e-29]\n",
      "Action prob: [1.0000000e+00 1.8688528e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 8.6363754e-30]\n",
      "Action prob: [1.0000000e+00 8.6363754e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 1.2261807e-28]\n",
      "Action prob: [1.0000000e+00 1.2261807e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 1.2449582e-28]\n",
      "Action prob: [1.0000000e+00 1.2449582e-28], Action: 0, state: 0\n",
      "[1.000000e+00 3.747249e-30]\n",
      "Action prob: [1.000000e+00 3.747249e-30], Action: 0, state: 1\n",
      "[1.000000e+00 1.361702e-29]\n",
      "Action prob: [1.000000e+00 1.361702e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.2799439e-27]\n",
      "Action prob: [1.0000000e+00 1.2799439e-27], Action: 0, state: 1\n",
      "[1.0000000e+00 1.7066747e-28]\n",
      "Action prob: [1.0000000e+00 1.7066747e-28], Action: 0, state: 1\n",
      "[1.000000e+00 6.507655e-28]\n",
      "Action prob: [1.000000e+00 6.507655e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 1.8585866e-29]\n",
      "Action prob: [1.0000000e+00 1.8585866e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 5.8859987e-28]\n",
      "Action prob: [1.0000000e+00 5.8859987e-28], Action: 0, state: 2\n",
      "[1.000000e+00 8.132583e-30]\n",
      "Action prob: [1.000000e+00 8.132583e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 2.2760416e-29]\n",
      "Action prob: [1.0000000e+00 2.2760416e-29], Action: 0, state: 2\n",
      "[1.000000e+00 2.176577e-27]\n",
      "Action prob: [1.000000e+00 2.176577e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 1.3768136e-28]\n",
      "Action prob: [1.0000000e+00 1.3768136e-28], Action: 0, state: 2\n",
      "[1.000000e+00 9.058581e-30]\n",
      "Action prob: [1.000000e+00 9.058581e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 1.5548353e-27]\n",
      "Action prob: [1.0000000e+00 1.5548353e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 5.4519604e-32]\n",
      "Action prob: [1.0000000e+00 5.4519604e-32], Action: 0, state: 3\n",
      "[1.0000000e+00 1.6487695e-25]\n",
      "Action prob: [1.0000000e+00 1.6487695e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1802427e-26]\n",
      "Action prob: [1.0000000e+00 1.1802427e-26], Action: 0, state: 8\n",
      "[1.00000e+00 1.29566e-33]\n",
      "Action prob: [1.00000e+00 1.29566e-33], Action: 0, state: 8\n",
      "[1.000000e+00 4.768197e-33]\n",
      "Action prob: [1.000000e+00 4.768197e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2619536e-32]\n",
      "Action prob: [1.0000000e+00 3.2619536e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2912784e-33]\n",
      "Action prob: [1.0000000e+00 1.2912784e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 7.6265886e-27]\n",
      "Action prob: [1.0000000e+00 7.6265886e-27], Action: 0, state: 8\n",
      "[1.000000e+00 1.639518e-33]\n",
      "Action prob: [1.000000e+00 1.639518e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5510519e-32]\n",
      "Action prob: [1.0000000e+00 1.5510519e-32], Action: 0, state: 8\n",
      "[1.00000e+00 5.66801e-27]\n",
      "Action prob: [1.00000e+00 5.66801e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 7.8317926e-26]\n",
      "Action prob: [1.0000000e+00 7.8317926e-26], Action: 0, state: 8\n",
      "[1.000000e+00 8.509405e-27]\n",
      "Action prob: [1.000000e+00 8.509405e-27], Action: 0, state: 8\n",
      "[1.000000e+00 4.363339e-27]\n",
      "Action prob: [1.000000e+00 4.363339e-27], Action: 0, state: 8\n",
      "[1.000000e+00 8.667644e-27]\n",
      "Action prob: [1.000000e+00 8.667644e-27], Action: 0, state: 8\n",
      "[1.000000e+00 6.795361e-31]\n",
      "Action prob: [1.000000e+00 6.795361e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7839065e-31]\n",
      "Action prob: [1.0000000e+00 4.7839065e-31], Action: 0, state: 8\n",
      "[1.000000e+00 7.855486e-27]\n",
      "Action prob: [1.000000e+00 7.855486e-27], Action: 0, state: 8\n",
      "[1.0000e+00 3.3072e-38]\n",
      "Action prob: [1.0000e+00 3.3072e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9562814e-26]\n",
      "Action prob: [1.0000000e+00 1.9562814e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8577366e-26]\n",
      "Action prob: [1.0000000e+00 3.8577366e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8914368e-30]\n",
      "Action prob: [1.0000000e+00 1.8914368e-30], Action: 0, state: 8\n",
      "[1.000000e+00 8.686447e-34]\n",
      "Action prob: [1.000000e+00 8.686447e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.5833035e-28]\n",
      "Action prob: [1.0000000e+00 4.5833035e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3464952e-33]\n",
      "Action prob: [1.0000000e+00 2.3464952e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3114124e-30]\n",
      "Action prob: [1.0000000e+00 4.3114124e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0850688e-33]\n",
      "Action prob: [1.0000000e+00 3.0850688e-33], Action: 0, state: 8\n",
      "[1.000000e+00 2.636505e-33]\n",
      "Action prob: [1.000000e+00 2.636505e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7025526e-35]\n",
      "Action prob: [1.0000000e+00 1.7025526e-35], Action: 0, state: 8\n",
      "[1.000000e+00 9.562932e-34]\n",
      "Action prob: [1.000000e+00 9.562932e-34], Action: 0, state: 8\n",
      "[1.000000e+00 6.098522e-26]\n",
      "Action prob: [1.000000e+00 6.098522e-26], Action: 0, state: 8\n",
      "[1.00000000e+00 1.05708005e-32]\n",
      "Action prob: [1.00000000e+00 1.05708005e-32], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., 0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -80600, loss is -0.0\n",
      "[1.000000e+00 6.832017e-29]\n",
      "Action prob: [1.000000e+00 6.832017e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 5.9932123e-28]\n",
      "Action prob: [1.0000000e+00 5.9932123e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 6.1679024e-30]\n",
      "Action prob: [1.0000000e+00 6.1679024e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 9.8533904e-29]\n",
      "Action prob: [1.0000000e+00 9.8533904e-29], Action: 0, state: 2\n",
      "[1.000000e+00 9.627844e-31]\n",
      "Action prob: [1.000000e+00 9.627844e-31], Action: 0, state: 3\n",
      "[1.0000000e+00 3.0516462e-29]\n",
      "Action prob: [1.0000000e+00 3.0516462e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.6303873e-33]\n",
      "Action prob: [1.0000000e+00 1.6303873e-33], Action: 0, state: 3\n",
      "[1.000000e+00 7.807088e-35]\n",
      "Action prob: [1.000000e+00 7.807088e-35], Action: 0, state: 3\n",
      "[1.0000000e+00 5.6794508e-30]\n",
      "Action prob: [1.0000000e+00 5.6794508e-30], Action: 0, state: 3\n",
      "[1.000000e+00 1.262348e-33]\n",
      "Action prob: [1.000000e+00 1.262348e-33], Action: 0, state: 3\n",
      "[1.000000e+00 3.332364e-30]\n",
      "Action prob: [1.000000e+00 3.332364e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 1.7326576e-29]\n",
      "Action prob: [1.0000000e+00 1.7326576e-29], Action: 0, state: 3\n",
      "[1.00000000e+00 1.21532514e-29]\n",
      "Action prob: [1.00000000e+00 1.21532514e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 7.4899223e-28]\n",
      "Action prob: [1.0000000e+00 7.4899223e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 2.0733083e-29]\n",
      "Action prob: [1.0000000e+00 2.0733083e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.5713855e-30]\n",
      "Action prob: [1.0000000e+00 1.5713855e-30], Action: 0, state: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 3.466414e-33]\n",
      "Action prob: [1.000000e+00 3.466414e-33], Action: 0, state: 8\n",
      "[1.000000e+00 4.295776e-26]\n",
      "Action prob: [1.000000e+00 4.295776e-26], Action: 0, state: 8\n",
      "[1.00000e+00 3.21453e-33]\n",
      "Action prob: [1.00000e+00 3.21453e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9196457e-27]\n",
      "Action prob: [1.0000000e+00 2.9196457e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0199522e-31]\n",
      "Action prob: [1.0000000e+00 1.0199522e-31], Action: 0, state: 8\n",
      "[1.00000e+00 8.08954e-31]\n",
      "Action prob: [1.00000e+00 8.08954e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 7.7978974e-26]\n",
      "Action prob: [1.0000000e+00 7.7978974e-26], Action: 0, state: 8\n",
      "[1.000000e+00 1.751174e-32]\n",
      "Action prob: [1.000000e+00 1.751174e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3354143e-32]\n",
      "Action prob: [1.0000000e+00 2.3354143e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0620148e-25]\n",
      "Action prob: [1.0000000e+00 1.0620148e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6262906e-33]\n",
      "Action prob: [1.0000000e+00 3.6262906e-33], Action: 0, state: 8\n",
      "[1.00000e+00 8.49763e-27]\n",
      "Action prob: [1.00000e+00 8.49763e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 5.1709514e-34]\n",
      "Action prob: [1.0000000e+00 5.1709514e-34], Action: 0, state: 8\n",
      "[1.00000e+00 9.73521e-30]\n",
      "Action prob: [1.00000e+00 9.73521e-30], Action: 0, state: 8\n",
      "[1.000000e+00 2.491577e-27]\n",
      "Action prob: [1.000000e+00 2.491577e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5240871e-35]\n",
      "Action prob: [1.0000000e+00 1.5240871e-35], Action: 0, state: 8\n",
      "[1.000000e+00 3.804146e-27]\n",
      "Action prob: [1.000000e+00 3.804146e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3401425e-34]\n",
      "Action prob: [1.0000000e+00 1.3401425e-34], Action: 0, state: 8\n",
      "[1.000000e+00 4.835952e-27]\n",
      "Action prob: [1.000000e+00 4.835952e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5748207e-26]\n",
      "Action prob: [1.0000000e+00 2.5748207e-26], Action: 0, state: 8\n",
      "[1.000000e+00 8.087921e-27]\n",
      "Action prob: [1.000000e+00 8.087921e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3975635e-34]\n",
      "Action prob: [1.0000000e+00 3.3975635e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2538096e-34]\n",
      "Action prob: [1.0000000e+00 1.2538096e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2843985e-35]\n",
      "Action prob: [1.0000000e+00 4.2843985e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2535635e-30]\n",
      "Action prob: [1.0000000e+00 1.2535635e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1279643e-27]\n",
      "Action prob: [1.0000000e+00 3.1279643e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3003884e-26]\n",
      "Action prob: [1.0000000e+00 1.3003884e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2089608e-38]\n",
      "Action prob: [1.0000000e+00 2.2089608e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 4.8093357e-33]\n",
      "Action prob: [1.0000000e+00 4.8093357e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2179504e-27]\n",
      "Action prob: [1.0000000e+00 3.2179504e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5747121e-34]\n",
      "Action prob: [1.0000000e+00 2.5747121e-34], Action: 0, state: 8\n",
      "[1.000000e+00 9.778397e-35]\n",
      "Action prob: [1.000000e+00 9.778397e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4182593e-32]\n",
      "Action prob: [1.0000000e+00 2.4182593e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2478871e-31]\n",
      "Action prob: [1.0000000e+00 3.2478871e-31], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -96300, loss is -0.0\n",
      "[1.0000000e+00 4.9523284e-29]\n",
      "Action prob: [1.0000000e+00 4.9523284e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.6959533e-28]\n",
      "Action prob: [1.0000000e+00 1.6959533e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 2.5980127e-29]\n",
      "Action prob: [1.0000000e+00 2.5980127e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.0033516e-29]\n",
      "Action prob: [1.0000000e+00 1.0033516e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 4.5653628e-29]\n",
      "Action prob: [1.0000000e+00 4.5653628e-29], Action: 0, state: 1\n",
      "[1.000000e+00 3.826842e-32]\n",
      "Action prob: [1.000000e+00 3.826842e-32], Action: 0, state: 2\n",
      "[1.000000e+00 1.139677e-30]\n",
      "Action prob: [1.000000e+00 1.139677e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 3.9069285e-29]\n",
      "Action prob: [1.0000000e+00 3.9069285e-29], Action: 0, state: 2\n",
      "[1.000000e+00 9.242955e-30]\n",
      "Action prob: [1.000000e+00 9.242955e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 2.3601453e-29]\n",
      "Action prob: [1.0000000e+00 2.3601453e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 2.6827342e-28]\n",
      "Action prob: [1.0000000e+00 2.6827342e-28], Action: 0, state: 3\n",
      "[1.000000e+00 2.926094e-32]\n",
      "Action prob: [1.000000e+00 2.926094e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6689744e-33]\n",
      "Action prob: [1.0000000e+00 1.6689744e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.2779115e-26]\n",
      "Action prob: [1.0000000e+00 5.2779115e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1304075e-29]\n",
      "Action prob: [1.0000000e+00 1.1304075e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0509214e-36]\n",
      "Action prob: [1.0000000e+00 2.0509214e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0239031e-35]\n",
      "Action prob: [1.0000000e+00 1.0239031e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8244605e-26]\n",
      "Action prob: [1.0000000e+00 3.8244605e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0770717e-26]\n",
      "Action prob: [1.0000000e+00 2.0770717e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4973117e-31]\n",
      "Action prob: [1.0000000e+00 3.4973117e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1623668e-32]\n",
      "Action prob: [1.0000000e+00 1.1623668e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3869387e-35]\n",
      "Action prob: [1.0000000e+00 2.3869387e-35], Action: 0, state: 8\n",
      "[1.000000e+00 6.942451e-33]\n",
      "Action prob: [1.000000e+00 6.942451e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3637885e-34]\n",
      "Action prob: [1.0000000e+00 2.3637885e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2057545e-33]\n",
      "Action prob: [1.0000000e+00 1.2057545e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 9.1038347e-35]\n",
      "Action prob: [1.0000000e+00 9.1038347e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3227872e-26]\n",
      "Action prob: [1.0000000e+00 2.3227872e-26], Action: 0, state: 8\n",
      "[1.00000e+00 4.35832e-40]\n",
      "Action prob: [1.00000e+00 4.35832e-40], Action: 0, state: 8\n",
      "[1.000000e+00 4.130197e-27]\n",
      "Action prob: [1.000000e+00 4.130197e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.181469e-35]\n",
      "Action prob: [1.000000e+00 9.181469e-35], Action: 0, state: 8\n",
      "[1.000000e+00 1.386655e-27]\n",
      "Action prob: [1.000000e+00 1.386655e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 8.0154855e-37]\n",
      "Action prob: [1.0000000e+00 8.0154855e-37], Action: 0, state: 8\n",
      "[1.000000e+00 7.888763e-26]\n",
      "Action prob: [1.000000e+00 7.888763e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2865442e-32]\n",
      "Action prob: [1.0000000e+00 1.2865442e-32], Action: 0, state: 8\n",
      "[1.00000000e+00 1.16471926e-32]\n",
      "Action prob: [1.00000000e+00 1.16471926e-32], Action: 0, state: 8\n",
      "[1.000000e+00 5.673599e-32]\n",
      "Action prob: [1.000000e+00 5.673599e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9479549e-27]\n",
      "Action prob: [1.0000000e+00 1.9479549e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3941201e-31]\n",
      "Action prob: [1.0000000e+00 1.3941201e-31], Action: 0, state: 8\n",
      "[1.000000e+00 4.421012e-33]\n",
      "Action prob: [1.000000e+00 4.421012e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4227541e-26]\n",
      "Action prob: [1.0000000e+00 1.4227541e-26], Action: 0, state: 8\n",
      "[1.00000e+00 1.22371e-26]\n",
      "Action prob: [1.00000e+00 1.22371e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8152605e-27]\n",
      "Action prob: [1.0000000e+00 2.8152605e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.148195e-26]\n",
      "Action prob: [1.000000e+00 7.148195e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4494675e-31]\n",
      "Action prob: [1.0000000e+00 1.4494675e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4941602e-26]\n",
      "Action prob: [1.0000000e+00 3.4941602e-26], Action: 0, state: 8\n",
      "[1.000000e+00 4.817373e-35]\n",
      "Action prob: [1.000000e+00 4.817373e-35], Action: 0, state: 8\n",
      "[1.000000e+00 7.866674e-34]\n",
      "Action prob: [1.000000e+00 7.866674e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 8.7014465e-32]\n",
      "Action prob: [1.0000000e+00 8.7014465e-32], Action: 0, state: 8\n",
      "[1.00000000e+00 1.11268346e-35]\n",
      "Action prob: [1.00000000e+00 1.11268346e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3511364e-33]\n",
      "Action prob: [1.0000000e+00 3.3511364e-33], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -112200, loss is -0.0\n",
      "[1.000000e+00 8.646227e-31]\n",
      "Action prob: [1.000000e+00 8.646227e-31], Action: 0, state: 0\n",
      "[1.000000e+00 5.767374e-29]\n",
      "Action prob: [1.000000e+00 5.767374e-29], Action: 0, state: 0\n",
      "[1.000000e+00 7.572778e-28]\n",
      "Action prob: [1.000000e+00 7.572778e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 1.5998672e-31]\n",
      "Action prob: [1.0000000e+00 1.5998672e-31], Action: 0, state: 1\n",
      "[1.000000e+00 1.149892e-29]\n",
      "Action prob: [1.000000e+00 1.149892e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 4.1264306e-28]\n",
      "Action prob: [1.0000000e+00 4.1264306e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.8425197e-29]\n",
      "Action prob: [1.0000000e+00 1.8425197e-29], Action: 0, state: 3\n",
      "[1.00000000e+00 1.11932814e-29]\n",
      "Action prob: [1.00000000e+00 1.11932814e-29], Action: 0, state: 3\n",
      "[1.000000e+00 5.576087e-29]\n",
      "Action prob: [1.000000e+00 5.576087e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.1515413e-31]\n",
      "Action prob: [1.0000000e+00 1.1515413e-31], Action: 0, state: 3\n",
      "[1.0000000e+00 1.9182742e-27]\n",
      "Action prob: [1.0000000e+00 1.9182742e-27], Action: 0, state: 3\n",
      "[1.0000000e+00 2.6032506e-29]\n",
      "Action prob: [1.0000000e+00 2.6032506e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 6.2097364e-30]\n",
      "Action prob: [1.0000000e+00 6.2097364e-30], Action: 0, state: 3\n",
      "[1.000000e+00 9.354756e-39]\n",
      "Action prob: [1.000000e+00 9.354756e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8301652e-34]\n",
      "Action prob: [1.0000000e+00 1.8301652e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.360148e-27]\n",
      "Action prob: [1.000000e+00 7.360148e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5412512e-35]\n",
      "Action prob: [1.0000000e+00 2.5412512e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5592209e-34]\n",
      "Action prob: [1.0000000e+00 2.5592209e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6374287e-26]\n",
      "Action prob: [1.0000000e+00 3.6374287e-26], Action: 0, state: 8\n",
      "[1.000000e+00 7.750326e-27]\n",
      "Action prob: [1.000000e+00 7.750326e-27], Action: 0, state: 8\n",
      "[1.00000000e+00 1.19629436e-32]\n",
      "Action prob: [1.00000000e+00 1.19629436e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0373756e-29]\n",
      "Action prob: [1.0000000e+00 1.0373756e-29], Action: 0, state: 8\n",
      "[1.000000e+00 8.156612e-27]\n",
      "Action prob: [1.000000e+00 8.156612e-27], Action: 0, state: 8\n",
      "[1.000000e+00 1.873634e-38]\n",
      "Action prob: [1.000000e+00 1.873634e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 9.3444696e-27]\n",
      "Action prob: [1.0000000e+00 9.3444696e-27], Action: 0, state: 8\n",
      "[1.000000e+00 1.661846e-26]\n",
      "Action prob: [1.000000e+00 1.661846e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2832935e-26]\n",
      "Action prob: [1.0000000e+00 1.2832935e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4983565e-31]\n",
      "Action prob: [1.0000000e+00 1.4983565e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7437614e-32]\n",
      "Action prob: [1.0000000e+00 1.7437614e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3666002e-27]\n",
      "Action prob: [1.0000000e+00 1.3666002e-27], Action: 0, state: 8\n",
      "[1.000000e+00 6.012403e-35]\n",
      "Action prob: [1.000000e+00 6.012403e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8040469e-34]\n",
      "Action prob: [1.0000000e+00 1.8040469e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1001995e-26]\n",
      "Action prob: [1.0000000e+00 1.1001995e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5426593e-34]\n",
      "Action prob: [1.0000000e+00 1.5426593e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7690635e-37]\n",
      "Action prob: [1.0000000e+00 2.7690635e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1366175e-33]\n",
      "Action prob: [1.0000000e+00 3.1366175e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5414115e-31]\n",
      "Action prob: [1.0000000e+00 2.5414115e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9986502e-27]\n",
      "Action prob: [1.0000000e+00 1.9986502e-27], Action: 0, state: 8\n",
      "[1.000000e+00 2.032682e-34]\n",
      "Action prob: [1.000000e+00 2.032682e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0123515e-35]\n",
      "Action prob: [1.0000000e+00 2.0123515e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8172966e-32]\n",
      "Action prob: [1.0000000e+00 1.8172966e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9344132e-25]\n",
      "Action prob: [1.0000000e+00 1.9344132e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9050541e-30]\n",
      "Action prob: [1.0000000e+00 2.9050541e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1467443e-26]\n",
      "Action prob: [1.0000000e+00 2.1467443e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.8843993e-26]\n",
      "Action prob: [1.0000000e+00 4.8843993e-26], Action: 0, state: 8\n",
      "[1.000000e+00 9.063431e-35]\n",
      "Action prob: [1.000000e+00 9.063431e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 8.9728276e-33]\n",
      "Action prob: [1.0000000e+00 8.9728276e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5135913e-27]\n",
      "Action prob: [1.0000000e+00 2.5135913e-27], Action: 0, state: 8\n",
      "[1.000000e+00 5.170322e-26]\n",
      "Action prob: [1.000000e+00 5.170322e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7092366e-34]\n",
      "Action prob: [1.0000000e+00 1.7092366e-34], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -106300, loss is -0.0\n",
      "[1.0000000e+00 1.3672356e-28]\n",
      "Action prob: [1.0000000e+00 1.3672356e-28], Action: 0, state: 0\n",
      "[1.000000e+00 2.816548e-28]\n",
      "Action prob: [1.000000e+00 2.816548e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 8.9044365e-31]\n",
      "Action prob: [1.0000000e+00 8.9044365e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 1.4421556e-29]\n",
      "Action prob: [1.0000000e+00 1.4421556e-29], Action: 0, state: 2\n",
      "[1.000000e+00 3.597133e-28]\n",
      "Action prob: [1.000000e+00 3.597133e-28], Action: 0, state: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 4.4557292e-29]\n",
      "Action prob: [1.0000000e+00 4.4557292e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 2.1571828e-29]\n",
      "Action prob: [1.0000000e+00 2.1571828e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 3.5979445e-27]\n",
      "Action prob: [1.0000000e+00 3.5979445e-27], Action: 0, state: 8\n",
      "[1.000000e+00 5.232122e-35]\n",
      "Action prob: [1.000000e+00 5.232122e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0453866e-32]\n",
      "Action prob: [1.0000000e+00 1.0453866e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 6.8809885e-34]\n",
      "Action prob: [1.0000000e+00 6.8809885e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9169616e-34]\n",
      "Action prob: [1.0000000e+00 3.9169616e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3717447e-35]\n",
      "Action prob: [1.0000000e+00 2.3717447e-35], Action: 0, state: 8\n",
      "[1.000000e+00 8.920093e-27]\n",
      "Action prob: [1.000000e+00 8.920093e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3113584e-26]\n",
      "Action prob: [1.0000000e+00 2.3113584e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5858056e-34]\n",
      "Action prob: [1.0000000e+00 3.5858056e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7241483e-26]\n",
      "Action prob: [1.0000000e+00 1.7241483e-26], Action: 0, state: 8\n",
      "[1.00000000e+00 1.22599895e-27]\n",
      "Action prob: [1.00000000e+00 1.22599895e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 8.1658274e-27]\n",
      "Action prob: [1.0000000e+00 8.1658274e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 7.1120766e-33]\n",
      "Action prob: [1.0000000e+00 7.1120766e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5238324e-26]\n",
      "Action prob: [1.0000000e+00 1.5238324e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6232852e-31]\n",
      "Action prob: [1.0000000e+00 2.6232852e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3388076e-27]\n",
      "Action prob: [1.0000000e+00 3.3388076e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0220631e-27]\n",
      "Action prob: [1.0000000e+00 2.0220631e-27], Action: 0, state: 8\n",
      "[1.00000e+00 7.78402e-33]\n",
      "Action prob: [1.00000e+00 7.78402e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7115795e-26]\n",
      "Action prob: [1.0000000e+00 1.7115795e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1763209e-30]\n",
      "Action prob: [1.0000000e+00 1.1763209e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 5.2926065e-27]\n",
      "Action prob: [1.0000000e+00 5.2926065e-27], Action: 0, state: 8\n",
      "[1.000000e+00 8.987245e-34]\n",
      "Action prob: [1.000000e+00 8.987245e-34], Action: 0, state: 8\n",
      "[1.000000e+00 2.643281e-34]\n",
      "Action prob: [1.000000e+00 2.643281e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4442448e-33]\n",
      "Action prob: [1.0000000e+00 1.4442448e-33], Action: 0, state: 8\n",
      "[1.000000e+00 1.476708e-32]\n",
      "Action prob: [1.000000e+00 1.476708e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6593086e-30]\n",
      "Action prob: [1.0000000e+00 1.6593086e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0762763e-34]\n",
      "Action prob: [1.0000000e+00 1.0762763e-34], Action: 0, state: 8\n",
      "[1.000000e+00 2.850371e-26]\n",
      "Action prob: [1.000000e+00 2.850371e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3687675e-35]\n",
      "Action prob: [1.0000000e+00 4.3687675e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4078814e-35]\n",
      "Action prob: [1.0000000e+00 2.4078814e-35], Action: 0, state: 8\n",
      "[1.000000e+00 1.954788e-35]\n",
      "Action prob: [1.000000e+00 1.954788e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 9.2547514e-35]\n",
      "Action prob: [1.0000000e+00 9.2547514e-35], Action: 0, state: 8\n",
      "[1.000000e+00 5.926876e-26]\n",
      "Action prob: [1.000000e+00 5.926876e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0949497e-31]\n",
      "Action prob: [1.0000000e+00 3.0949497e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 6.0200468e-27]\n",
      "Action prob: [1.0000000e+00 6.0200468e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9953161e-32]\n",
      "Action prob: [1.0000000e+00 1.9953161e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5465564e-31]\n",
      "Action prob: [1.0000000e+00 1.5465564e-31], Action: 0, state: 8\n",
      "[1.000000e+00 8.401558e-39]\n",
      "Action prob: [1.000000e+00 8.401558e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 6.9186934e-30]\n",
      "Action prob: [1.0000000e+00 6.9186934e-30], Action: 0, state: 8\n",
      "[1.000000e+00 8.902924e-35]\n",
      "Action prob: [1.000000e+00 8.902924e-35], Action: 0, state: 8\n",
      "[1.000000e+00 1.962081e-26]\n",
      "Action prob: [1.000000e+00 1.962081e-26], Action: 0, state: 8\n",
      "[1.000000e+00 4.463288e-34]\n",
      "Action prob: [1.000000e+00 4.463288e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1560334e-34]\n",
      "Action prob: [1.0000000e+00 1.1560334e-34], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., 0., 0.,\n",
      "        -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -127300, loss is -0.0\n",
      "[1.000000e+00 6.478795e-29]\n",
      "Action prob: [1.000000e+00 6.478795e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.3268381e-30]\n",
      "Action prob: [1.0000000e+00 1.3268381e-30], Action: 0, state: 0\n",
      "[1.00000e+00 1.22119e-29]\n",
      "Action prob: [1.00000e+00 1.22119e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.0015739e-28]\n",
      "Action prob: [1.0000000e+00 1.0015739e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 1.1689273e-29]\n",
      "Action prob: [1.0000000e+00 1.1689273e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.2915527e-28]\n",
      "Action prob: [1.0000000e+00 1.2915527e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 1.2338894e-29]\n",
      "Action prob: [1.0000000e+00 1.2338894e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 2.4448561e-29]\n",
      "Action prob: [1.0000000e+00 2.4448561e-29], Action: 0, state: 2\n",
      "[1.000000e+00 7.579541e-28]\n",
      "Action prob: [1.000000e+00 7.579541e-28], Action: 0, state: 2\n",
      "[1.000000e+00 4.575909e-30]\n",
      "Action prob: [1.000000e+00 4.575909e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 6.0109737e-30]\n",
      "Action prob: [1.0000000e+00 6.0109737e-30], Action: 0, state: 3\n",
      "[1.000000e+00 3.247399e-34]\n",
      "Action prob: [1.000000e+00 3.247399e-34], Action: 0, state: 3\n",
      "[1.0000000e+00 3.1804222e-28]\n",
      "Action prob: [1.0000000e+00 3.1804222e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.2089954e-28]\n",
      "Action prob: [1.0000000e+00 1.2089954e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 5.4643394e-28]\n",
      "Action prob: [1.0000000e+00 5.4643394e-28], Action: 0, state: 3\n",
      "[1.000000e+00 9.818271e-29]\n",
      "Action prob: [1.000000e+00 9.818271e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 3.1392007e-27]\n",
      "Action prob: [1.0000000e+00 3.1392007e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3536095e-36]\n",
      "Action prob: [1.0000000e+00 4.3536095e-36], Action: 0, state: 8\n",
      "[1.000000e+00 6.433206e-30]\n",
      "Action prob: [1.000000e+00 6.433206e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2201648e-32]\n",
      "Action prob: [1.0000000e+00 3.2201648e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 9.6752977e-32]\n",
      "Action prob: [1.0000000e+00 9.6752977e-32], Action: 0, state: 8\n",
      "[1.000000e+00 7.569174e-34]\n",
      "Action prob: [1.000000e+00 7.569174e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2194924e-33]\n",
      "Action prob: [1.0000000e+00 4.2194924e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5881772e-27]\n",
      "Action prob: [1.0000000e+00 1.5881772e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6180435e-26]\n",
      "Action prob: [1.0000000e+00 2.6180435e-26], Action: 0, state: 8\n",
      "[1.000000e+00 1.339136e-26]\n",
      "Action prob: [1.000000e+00 1.339136e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2959185e-26]\n",
      "Action prob: [1.0000000e+00 2.2959185e-26], Action: 0, state: 8\n",
      "[1.000000e+00 7.032222e-33]\n",
      "Action prob: [1.000000e+00 7.032222e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4950549e-33]\n",
      "Action prob: [1.0000000e+00 1.4950549e-33], Action: 0, state: 8\n",
      "[1.00000000e+00 1.17499576e-26]\n",
      "Action prob: [1.00000000e+00 1.17499576e-26], Action: 0, state: 8\n",
      "[1.000000e+00 5.407486e-26]\n",
      "Action prob: [1.000000e+00 5.407486e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 5.5480023e-34]\n",
      "Action prob: [1.0000000e+00 5.5480023e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6483357e-28]\n",
      "Action prob: [1.0000000e+00 2.6483357e-28], Action: 0, state: 8\n",
      "[1.000000e+00 7.876969e-35]\n",
      "Action prob: [1.000000e+00 7.876969e-35], Action: 0, state: 8\n",
      "[1.000000e+00 1.797995e-33]\n",
      "Action prob: [1.000000e+00 1.797995e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4829559e-26]\n",
      "Action prob: [1.0000000e+00 1.4829559e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 7.5494556e-25]\n",
      "Action prob: [1.0000000e+00 7.5494556e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7687304e-26]\n",
      "Action prob: [1.0000000e+00 2.7687304e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9536325e-28]\n",
      "Action prob: [1.0000000e+00 3.9536325e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2996154e-32]\n",
      "Action prob: [1.0000000e+00 4.2996154e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0350454e-37]\n",
      "Action prob: [1.0000000e+00 2.0350454e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6702997e-27]\n",
      "Action prob: [1.0000000e+00 2.6702997e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4843803e-29]\n",
      "Action prob: [1.0000000e+00 2.4843803e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7344328e-32]\n",
      "Action prob: [1.0000000e+00 4.7344328e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1863947e-27]\n",
      "Action prob: [1.0000000e+00 1.1863947e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8586783e-26]\n",
      "Action prob: [1.0000000e+00 3.8586783e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4532773e-26]\n",
      "Action prob: [1.0000000e+00 2.4532773e-26], Action: 0, state: 8\n",
      "[1.000000e+00 2.038319e-27]\n",
      "Action prob: [1.000000e+00 2.038319e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1135023e-26]\n",
      "Action prob: [1.0000000e+00 2.1135023e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0250453e-33]\n",
      "Action prob: [1.0000000e+00 1.0250453e-33], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -93700, loss is -0.0\n",
      "[1.000000e+00 1.828747e-28]\n",
      "Action prob: [1.000000e+00 1.828747e-28], Action: 0, state: 0\n",
      "[1.000000e+00 4.591681e-30]\n",
      "Action prob: [1.000000e+00 4.591681e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 1.5771522e-28]\n",
      "Action prob: [1.0000000e+00 1.5771522e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 1.0113753e-29]\n",
      "Action prob: [1.0000000e+00 1.0113753e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 6.2326618e-30]\n",
      "Action prob: [1.0000000e+00 6.2326618e-30], Action: 0, state: 3\n",
      "[1.000000e+00 9.007734e-27]\n",
      "Action prob: [1.000000e+00 9.007734e-27], Action: 0, state: 3\n",
      "[1.0000000e+00 1.3661557e-29]\n",
      "Action prob: [1.0000000e+00 1.3661557e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.3470749e-30]\n",
      "Action prob: [1.0000000e+00 1.3470749e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 1.3234324e-28]\n",
      "Action prob: [1.0000000e+00 1.3234324e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 3.2230136e-26]\n",
      "Action prob: [1.0000000e+00 3.2230136e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5391224e-32]\n",
      "Action prob: [1.0000000e+00 1.5391224e-32], Action: 0, state: 8\n",
      "[1.000000e+00 4.739208e-30]\n",
      "Action prob: [1.000000e+00 4.739208e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2968794e-36]\n",
      "Action prob: [1.0000000e+00 1.2968794e-36], Action: 0, state: 8\n",
      "[1.00000e+00 1.56047e-40]\n",
      "Action prob: [1.00000e+00 1.56047e-40], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3857233e-35]\n",
      "Action prob: [1.0000000e+00 3.3857233e-35], Action: 0, state: 8\n",
      "[1.000000e+00 8.009379e-28]\n",
      "Action prob: [1.000000e+00 8.009379e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3748433e-33]\n",
      "Action prob: [1.0000000e+00 2.3748433e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 6.5649264e-36]\n",
      "Action prob: [1.0000000e+00 6.5649264e-36], Action: 0, state: 8\n",
      "[1.000000e+00 3.576878e-30]\n",
      "Action prob: [1.000000e+00 3.576878e-30], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 3.388049e-35]\n",
      "Action prob: [1.000000e+00 3.388049e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1744552e-32]\n",
      "Action prob: [1.0000000e+00 2.1744552e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0902932e-34]\n",
      "Action prob: [1.0000000e+00 1.0902932e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0966585e-34]\n",
      "Action prob: [1.0000000e+00 1.0966585e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0860627e-35]\n",
      "Action prob: [1.0000000e+00 1.0860627e-35], Action: 0, state: 8\n",
      "[1.000000e+00 7.360017e-32]\n",
      "Action prob: [1.000000e+00 7.360017e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 9.3559905e-27]\n",
      "Action prob: [1.0000000e+00 9.3559905e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7466727e-32]\n",
      "Action prob: [1.0000000e+00 2.7466727e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3692935e-26]\n",
      "Action prob: [1.0000000e+00 1.3692935e-26], Action: 0, state: 8\n",
      "[1.000000e+00 5.144413e-33]\n",
      "Action prob: [1.000000e+00 5.144413e-33], Action: 0, state: 8\n",
      "[1.000000e+00 7.563773e-35]\n",
      "Action prob: [1.000000e+00 7.563773e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1493068e-28]\n",
      "Action prob: [1.0000000e+00 2.1493068e-28], Action: 0, state: 8\n",
      "[1.000000e+00 5.579199e-27]\n",
      "Action prob: [1.000000e+00 5.579199e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8332503e-36]\n",
      "Action prob: [1.0000000e+00 2.8332503e-36], Action: 0, state: 8\n",
      "[1.000000e+00 2.810003e-27]\n",
      "Action prob: [1.000000e+00 2.810003e-27], Action: 0, state: 8\n",
      "[1.000000e+00 2.329845e-39]\n",
      "Action prob: [1.000000e+00 2.329845e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4949735e-35]\n",
      "Action prob: [1.0000000e+00 1.4949735e-35], Action: 0, state: 8\n",
      "[1.000000e+00 9.697214e-31]\n",
      "Action prob: [1.000000e+00 9.697214e-31], Action: 0, state: 8\n",
      "[1.000000e+00 7.416375e-27]\n",
      "Action prob: [1.000000e+00 7.416375e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5853021e-27]\n",
      "Action prob: [1.0000000e+00 1.5853021e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1130322e-30]\n",
      "Action prob: [1.0000000e+00 3.1130322e-30], Action: 0, state: 8\n",
      "[1.000000e+00 5.505055e-35]\n",
      "Action prob: [1.000000e+00 5.505055e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5316253e-35]\n",
      "Action prob: [1.0000000e+00 3.5316253e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4477972e-33]\n",
      "Action prob: [1.0000000e+00 1.4477972e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4222113e-35]\n",
      "Action prob: [1.0000000e+00 3.4222113e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0224879e-34]\n",
      "Action prob: [1.0000000e+00 2.0224879e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6441832e-34]\n",
      "Action prob: [1.0000000e+00 1.6441832e-34], Action: 0, state: 8\n",
      "[1.000000e+00 3.244255e-26]\n",
      "Action prob: [1.000000e+00 3.244255e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1302855e-31]\n",
      "Action prob: [1.0000000e+00 1.1302855e-31], Action: 0, state: 8\n",
      "[1.00000e+00 4.62636e-27]\n",
      "Action prob: [1.00000e+00 4.62636e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.052066e-27]\n",
      "Action prob: [1.000000e+00 9.052066e-27], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., 0.,\n",
      "        -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -120800, loss is -0.0\n",
      "[1.0000000e+00 4.0450133e-28]\n",
      "Action prob: [1.0000000e+00 4.0450133e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 1.6202604e-28]\n",
      "Action prob: [1.0000000e+00 1.6202604e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 1.8093653e-29]\n",
      "Action prob: [1.0000000e+00 1.8093653e-29], Action: 0, state: 1\n",
      "[1.000000e+00 5.841594e-29]\n",
      "Action prob: [1.000000e+00 5.841594e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 2.1236578e-29]\n",
      "Action prob: [1.0000000e+00 2.1236578e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.9943309e-28]\n",
      "Action prob: [1.0000000e+00 1.9943309e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.1726843e-35]\n",
      "Action prob: [1.0000000e+00 1.1726843e-35], Action: 0, state: 3\n",
      "[1.000000e+00 7.831231e-32]\n",
      "Action prob: [1.000000e+00 7.831231e-32], Action: 0, state: 3\n",
      "[1.000000e+00 5.967271e-29]\n",
      "Action prob: [1.000000e+00 5.967271e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.0983628e-26]\n",
      "Action prob: [1.0000000e+00 1.0983628e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1414949e-32]\n",
      "Action prob: [1.0000000e+00 2.1414949e-32], Action: 0, state: 8\n",
      "[1.000000e+00 4.452774e-36]\n",
      "Action prob: [1.000000e+00 4.452774e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3186424e-32]\n",
      "Action prob: [1.0000000e+00 1.3186424e-32], Action: 0, state: 8\n",
      "[1.000000e+00 1.636406e-26]\n",
      "Action prob: [1.000000e+00 1.636406e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 5.6338844e-35]\n",
      "Action prob: [1.0000000e+00 5.6338844e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2000098e-26]\n",
      "Action prob: [1.0000000e+00 2.2000098e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9793338e-26]\n",
      "Action prob: [1.0000000e+00 2.9793338e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0766176e-33]\n",
      "Action prob: [1.0000000e+00 1.0766176e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6807614e-34]\n",
      "Action prob: [1.0000000e+00 1.6807614e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3598513e-33]\n",
      "Action prob: [1.0000000e+00 1.3598513e-33], Action: 0, state: 8\n",
      "[1.000000e+00 5.727241e-33]\n",
      "Action prob: [1.000000e+00 5.727241e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1261655e-27]\n",
      "Action prob: [1.0000000e+00 4.1261655e-27], Action: 0, state: 8\n",
      "[1.000000e+00 1.320247e-26]\n",
      "Action prob: [1.000000e+00 1.320247e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0877787e-36]\n",
      "Action prob: [1.0000000e+00 4.0877787e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0269941e-26]\n",
      "Action prob: [1.0000000e+00 1.0269941e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4225483e-33]\n",
      "Action prob: [1.0000000e+00 1.4225483e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3454315e-35]\n",
      "Action prob: [1.0000000e+00 4.3454315e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3927593e-31]\n",
      "Action prob: [1.0000000e+00 1.3927593e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8817087e-34]\n",
      "Action prob: [1.0000000e+00 3.8817087e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3258124e-32]\n",
      "Action prob: [1.0000000e+00 2.3258124e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0921283e-30]\n",
      "Action prob: [1.0000000e+00 4.0921283e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5734405e-33]\n",
      "Action prob: [1.0000000e+00 1.5734405e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 6.5514604e-38]\n",
      "Action prob: [1.0000000e+00 6.5514604e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9015831e-33]\n",
      "Action prob: [1.0000000e+00 2.9015831e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2375813e-35]\n",
      "Action prob: [1.0000000e+00 1.2375813e-35], Action: 0, state: 8\n",
      "[1.000000e+00 2.002741e-27]\n",
      "Action prob: [1.000000e+00 2.002741e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.930185e-27]\n",
      "Action prob: [1.000000e+00 7.930185e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9476909e-31]\n",
      "Action prob: [1.0000000e+00 1.9476909e-31], Action: 0, state: 8\n",
      "[1.000000e+00 1.173853e-34]\n",
      "Action prob: [1.000000e+00 1.173853e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2413977e-34]\n",
      "Action prob: [1.0000000e+00 1.2413977e-34], Action: 0, state: 8\n",
      "[1.000000e+00 8.067862e-34]\n",
      "Action prob: [1.000000e+00 8.067862e-34], Action: 0, state: 8\n",
      "[1.000000e+00 8.919104e-35]\n",
      "Action prob: [1.000000e+00 8.919104e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5959692e-27]\n",
      "Action prob: [1.0000000e+00 1.5959692e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3392475e-35]\n",
      "Action prob: [1.0000000e+00 1.3392475e-35], Action: 0, state: 8\n",
      "[1.000000e+00 2.904845e-29]\n",
      "Action prob: [1.000000e+00 2.904845e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7429404e-28]\n",
      "Action prob: [1.0000000e+00 1.7429404e-28], Action: 0, state: 8\n",
      "[1.000000e+00 7.121586e-31]\n",
      "Action prob: [1.000000e+00 7.121586e-31], Action: 0, state: 8\n",
      "[1.00000000e+00 1.42639545e-33]\n",
      "Action prob: [1.00000000e+00 1.42639545e-33], Action: 0, state: 8\n",
      "[1.e+00 6.e-44]\n",
      "Action prob: [1.e+00 6.e-44], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1500101e-37]\n",
      "Action prob: [1.0000000e+00 1.1500101e-37], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -120900, loss is -0.0\n",
      "[1.0000000e+00 6.1511727e-30]\n",
      "Action prob: [1.0000000e+00 6.1511727e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 5.6566742e-33]\n",
      "Action prob: [1.0000000e+00 5.6566742e-33], Action: 0, state: 0\n",
      "[1.000000e+00 7.207292e-31]\n",
      "Action prob: [1.000000e+00 7.207292e-31], Action: 0, state: 0\n",
      "[1.000000e+00 6.256435e-30]\n",
      "Action prob: [1.000000e+00 6.256435e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 5.1148535e-30]\n",
      "Action prob: [1.0000000e+00 5.1148535e-30], Action: 0, state: 1\n",
      "[1.000000e+00 1.228511e-30]\n",
      "Action prob: [1.000000e+00 1.228511e-30], Action: 0, state: 1\n",
      "[1.00000000e+00 1.08302925e-29]\n",
      "Action prob: [1.00000000e+00 1.08302925e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.0813254e-27]\n",
      "Action prob: [1.0000000e+00 1.0813254e-27], Action: 0, state: 1\n",
      "[1.000000e+00 9.221362e-31]\n",
      "Action prob: [1.000000e+00 9.221362e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 4.4296638e-29]\n",
      "Action prob: [1.0000000e+00 4.4296638e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 7.5374043e-31]\n",
      "Action prob: [1.0000000e+00 7.5374043e-31], Action: 0, state: 2\n",
      "[1.0000000e+00 1.8323106e-33]\n",
      "Action prob: [1.0000000e+00 1.8323106e-33], Action: 0, state: 3\n",
      "[1.000000e+00 8.255837e-29]\n",
      "Action prob: [1.000000e+00 8.255837e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.1462984e-33]\n",
      "Action prob: [1.0000000e+00 1.1462984e-33], Action: 0, state: 3\n",
      "[1.0000000e+00 1.9415907e-26]\n",
      "Action prob: [1.0000000e+00 1.9415907e-26], Action: 0, state: 3\n",
      "[1.000000e+00 1.087473e-26]\n",
      "Action prob: [1.000000e+00 1.087473e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 7.1295916e-27]\n",
      "Action prob: [1.0000000e+00 7.1295916e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 5.9959596e-27]\n",
      "Action prob: [1.0000000e+00 5.9959596e-27], Action: 0, state: 8\n",
      "[1.000000e+00 4.697154e-34]\n",
      "Action prob: [1.000000e+00 4.697154e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8297095e-27]\n",
      "Action prob: [1.0000000e+00 2.8297095e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.470463e-35]\n",
      "Action prob: [1.000000e+00 9.470463e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0568334e-27]\n",
      "Action prob: [1.0000000e+00 5.0568334e-27], Action: 0, state: 8\n",
      "[1.000000e+00 1.575378e-36]\n",
      "Action prob: [1.000000e+00 1.575378e-36], Action: 0, state: 8\n",
      "[1.00000e+00 1.34314e-29]\n",
      "Action prob: [1.00000e+00 1.34314e-29], Action: 0, state: 8\n",
      "[1.000000e+00 1.237617e-39]\n",
      "Action prob: [1.000000e+00 1.237617e-39], Action: 0, state: 8\n",
      "[1.000e+00 4.962e-33]\n",
      "Action prob: [1.000e+00 4.962e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.4036986e-30]\n",
      "Action prob: [1.0000000e+00 4.4036986e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3424665e-25]\n",
      "Action prob: [1.0000000e+00 1.3424665e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 6.6574885e-34]\n",
      "Action prob: [1.0000000e+00 6.6574885e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2015048e-33]\n",
      "Action prob: [1.0000000e+00 2.2015048e-33], Action: 0, state: 8\n",
      "[1.000000e+00 5.052003e-31]\n",
      "Action prob: [1.000000e+00 5.052003e-31], Action: 0, state: 8\n",
      "[1.000000e+00 6.989773e-27]\n",
      "Action prob: [1.000000e+00 6.989773e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5142465e-28]\n",
      "Action prob: [1.0000000e+00 1.5142465e-28], Action: 0, state: 8\n",
      "[1.0000e+00 7.5521e-34]\n",
      "Action prob: [1.0000e+00 7.5521e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3609684e-26]\n",
      "Action prob: [1.0000000e+00 2.3609684e-26], Action: 0, state: 8\n",
      "[1.000000e+00 5.904331e-34]\n",
      "Action prob: [1.000000e+00 5.904331e-34], Action: 0, state: 8\n",
      "[1.000000e+00 5.213808e-29]\n",
      "Action prob: [1.000000e+00 5.213808e-29], Action: 0, state: 8\n",
      "[1.000000e+00 9.906922e-34]\n",
      "Action prob: [1.000000e+00 9.906922e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 7.3629353e-25]\n",
      "Action prob: [1.0000000e+00 7.3629353e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6933305e-26]\n",
      "Action prob: [1.0000000e+00 1.6933305e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6316312e-26]\n",
      "Action prob: [1.0000000e+00 1.6316312e-26], Action: 0, state: 8\n",
      "[1.000000e+00 3.217962e-35]\n",
      "Action prob: [1.000000e+00 3.217962e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2611101e-32]\n",
      "Action prob: [1.0000000e+00 2.2611101e-32], Action: 0, state: 8\n",
      "[1.000000e+00 6.362189e-37]\n",
      "Action prob: [1.000000e+00 6.362189e-37], Action: 0, state: 8\n",
      "[1.000000e+00 4.721315e-27]\n",
      "Action prob: [1.000000e+00 4.721315e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6178124e-27]\n",
      "Action prob: [1.0000000e+00 2.6178124e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.161284e-27]\n",
      "Action prob: [1.000000e+00 9.161284e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1728913e-33]\n",
      "Action prob: [1.0000000e+00 1.1728913e-33], Action: 0, state: 8\n",
      "[1.000e+00 1.888e-42]\n",
      "Action prob: [1.000e+00 1.888e-42], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1274214e-32]\n",
      "Action prob: [1.0000000e+00 1.1274214e-32], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., 0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -96900, loss is -0.0\n",
      "[1.0000000e+00 2.1434678e-29]\n",
      "Action prob: [1.0000000e+00 2.1434678e-29], Action: 0, state: 0\n",
      "[1.000000e+00 6.201951e-29]\n",
      "Action prob: [1.000000e+00 6.201951e-29], Action: 0, state: 1\n",
      "[1.000000e+00 1.589321e-29]\n",
      "Action prob: [1.000000e+00 1.589321e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 8.2669303e-29]\n",
      "Action prob: [1.0000000e+00 8.2669303e-29], Action: 0, state: 3\n",
      "[1.000000e+00 6.972069e-33]\n",
      "Action prob: [1.000000e+00 6.972069e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0096529e-35]\n",
      "Action prob: [1.0000000e+00 1.0096529e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1362107e-34]\n",
      "Action prob: [1.0000000e+00 1.1362107e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6224701e-26]\n",
      "Action prob: [1.0000000e+00 1.6224701e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0800563e-26]\n",
      "Action prob: [1.0000000e+00 1.0800563e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1770148e-33]\n",
      "Action prob: [1.0000000e+00 1.1770148e-33], Action: 0, state: 8\n",
      "[1.e+00 7.e-45]\n",
      "Action prob: [1.e+00 7.e-45], Action: 0, state: 8\n",
      "[1.000000e+00 9.173007e-33]\n",
      "Action prob: [1.000000e+00 9.173007e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8007467e-34]\n",
      "Action prob: [1.0000000e+00 1.8007467e-34], Action: 0, state: 8\n",
      "[1.000000e+00 2.557818e-32]\n",
      "Action prob: [1.000000e+00 2.557818e-32], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+00 1.25032805e-26]\n",
      "Action prob: [1.00000000e+00 1.25032805e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3526749e-26]\n",
      "Action prob: [1.0000000e+00 1.3526749e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7859432e-26]\n",
      "Action prob: [1.0000000e+00 1.7859432e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1494984e-27]\n",
      "Action prob: [1.0000000e+00 1.1494984e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5964326e-25]\n",
      "Action prob: [1.0000000e+00 2.5964326e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4777095e-34]\n",
      "Action prob: [1.0000000e+00 1.4777095e-34], Action: 0, state: 8\n",
      "[1.00000e+00 3.72707e-26]\n",
      "Action prob: [1.00000e+00 3.72707e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6894747e-38]\n",
      "Action prob: [1.0000000e+00 1.6894747e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6967376e-34]\n",
      "Action prob: [1.0000000e+00 1.6967376e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.8235933e-33]\n",
      "Action prob: [1.0000000e+00 4.8235933e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7124424e-28]\n",
      "Action prob: [1.0000000e+00 2.7124424e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9389233e-33]\n",
      "Action prob: [1.0000000e+00 4.9389233e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3375361e-29]\n",
      "Action prob: [1.0000000e+00 1.3375361e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1975397e-36]\n",
      "Action prob: [1.0000000e+00 4.1975397e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7609025e-35]\n",
      "Action prob: [1.0000000e+00 2.7609025e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4920338e-34]\n",
      "Action prob: [1.0000000e+00 2.4920338e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8874968e-31]\n",
      "Action prob: [1.0000000e+00 2.8874968e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0298636e-32]\n",
      "Action prob: [1.0000000e+00 2.0298636e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8432274e-32]\n",
      "Action prob: [1.0000000e+00 3.8432274e-32], Action: 0, state: 8\n",
      "[1.000000e+00 5.764541e-35]\n",
      "Action prob: [1.000000e+00 5.764541e-35], Action: 0, state: 8\n",
      "[1.000000e+00 1.777042e-32]\n",
      "Action prob: [1.000000e+00 1.777042e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8619324e-33]\n",
      "Action prob: [1.0000000e+00 1.8619324e-33], Action: 0, state: 8\n",
      "[1.000000e+00 5.448444e-33]\n",
      "Action prob: [1.000000e+00 5.448444e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1104071e-34]\n",
      "Action prob: [1.0000000e+00 1.1104071e-34], Action: 0, state: 8\n",
      "[1.000000e+00 1.103334e-35]\n",
      "Action prob: [1.000000e+00 1.103334e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3227218e-27]\n",
      "Action prob: [1.0000000e+00 3.3227218e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.207005e-27]\n",
      "Action prob: [1.000000e+00 7.207005e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.380639e-36]\n",
      "Action prob: [1.000000e+00 7.380639e-36], Action: 0, state: 8\n",
      "[1.000000e+00 1.801738e-39]\n",
      "Action prob: [1.000000e+00 1.801738e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6326348e-32]\n",
      "Action prob: [1.0000000e+00 1.6326348e-32], Action: 0, state: 8\n",
      "[1.00000e+00 1.15387e-40]\n",
      "Action prob: [1.00000e+00 1.15387e-40], Action: 0, state: 8\n",
      "[1.000000e+00 9.164671e-28]\n",
      "Action prob: [1.000000e+00 9.164671e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4334078e-33]\n",
      "Action prob: [1.0000000e+00 3.4334078e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0652095e-25]\n",
      "Action prob: [1.0000000e+00 3.0652095e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8150574e-36]\n",
      "Action prob: [1.0000000e+00 3.8150574e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8891906e-33]\n",
      "Action prob: [1.0000000e+00 2.8891906e-33], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -138800, loss is -0.0\n",
      "[1.0000000e+00 1.7578908e-28]\n",
      "Action prob: [1.0000000e+00 1.7578908e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 1.6948522e-30]\n",
      "Action prob: [1.0000000e+00 1.6948522e-30], Action: 0, state: 1\n",
      "[1.000000e+00 6.679684e-30]\n",
      "Action prob: [1.000000e+00 6.679684e-30], Action: 0, state: 1\n",
      "[1.000000e+00 8.348503e-29]\n",
      "Action prob: [1.000000e+00 8.348503e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 2.9467204e-29]\n",
      "Action prob: [1.0000000e+00 2.9467204e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 2.5350817e-29]\n",
      "Action prob: [1.0000000e+00 2.5350817e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.1153956e-26]\n",
      "Action prob: [1.0000000e+00 1.1153956e-26], Action: 0, state: 2\n",
      "[1.0000000e+00 2.2536477e-29]\n",
      "Action prob: [1.0000000e+00 2.2536477e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 4.2648115e-29]\n",
      "Action prob: [1.0000000e+00 4.2648115e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 3.9306206e-30]\n",
      "Action prob: [1.0000000e+00 3.9306206e-30], Action: 0, state: 3\n",
      "[1.000000e+00 8.756159e-31]\n",
      "Action prob: [1.000000e+00 8.756159e-31], Action: 0, state: 3\n",
      "[1.0000000e+00 1.9779315e-32]\n",
      "Action prob: [1.0000000e+00 1.9779315e-32], Action: 0, state: 3\n",
      "[1.0000000e+00 1.1866265e-33]\n",
      "Action prob: [1.0000000e+00 1.1866265e-33], Action: 0, state: 3\n",
      "[1.0000000e+00 1.4975139e-27]\n",
      "Action prob: [1.0000000e+00 1.4975139e-27], Action: 0, state: 3\n",
      "[1.0000000e+00 2.8016638e-28]\n",
      "Action prob: [1.0000000e+00 2.8016638e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.4761526e-29]\n",
      "Action prob: [1.0000000e+00 1.4761526e-29], Action: 0, state: 3\n",
      "[1.000000e+00 6.627478e-29]\n",
      "Action prob: [1.000000e+00 6.627478e-29], Action: 0, state: 3\n",
      "[1.000000e+00 7.499611e-29]\n",
      "Action prob: [1.000000e+00 7.499611e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 2.6813223e-28]\n",
      "Action prob: [1.0000000e+00 2.6813223e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.8223143e-26]\n",
      "Action prob: [1.0000000e+00 1.8223143e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3438677e-29]\n",
      "Action prob: [1.0000000e+00 1.3438677e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5382458e-27]\n",
      "Action prob: [1.0000000e+00 1.5382458e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4402798e-30]\n",
      "Action prob: [1.0000000e+00 2.4402798e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2123777e-33]\n",
      "Action prob: [1.0000000e+00 1.2123777e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9468124e-33]\n",
      "Action prob: [1.0000000e+00 1.9468124e-33], Action: 0, state: 8\n",
      "[1.000000e+00 9.082823e-33]\n",
      "Action prob: [1.000000e+00 9.082823e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2839267e-32]\n",
      "Action prob: [1.0000000e+00 2.2839267e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2285575e-36]\n",
      "Action prob: [1.0000000e+00 4.2285575e-36], Action: 0, state: 8\n",
      "[1.000000e+00 2.232119e-31]\n",
      "Action prob: [1.000000e+00 2.232119e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3699104e-33]\n",
      "Action prob: [1.0000000e+00 1.3699104e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.4308345e-27]\n",
      "Action prob: [1.0000000e+00 4.4308345e-27], Action: 0, state: 8\n",
      "[1.000000e+00 4.282941e-29]\n",
      "Action prob: [1.000000e+00 4.282941e-29], Action: 0, state: 8\n",
      "[1.000000e+00 1.170537e-39]\n",
      "Action prob: [1.000000e+00 1.170537e-39], Action: 0, state: 8\n",
      "[1.000000e+00 2.495609e-28]\n",
      "Action prob: [1.000000e+00 2.495609e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8516864e-34]\n",
      "Action prob: [1.0000000e+00 2.8516864e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0666637e-25]\n",
      "Action prob: [1.0000000e+00 1.0666637e-25], Action: 0, state: 8\n",
      "[1.000000e+00 2.737955e-27]\n",
      "Action prob: [1.000000e+00 2.737955e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 6.6211407e-35]\n",
      "Action prob: [1.0000000e+00 6.6211407e-35], Action: 0, state: 8\n",
      "[1.000000e+00 1.040857e-27]\n",
      "Action prob: [1.000000e+00 1.040857e-27], Action: 0, state: 8\n",
      "[1.000000e+00 2.688022e-34]\n",
      "Action prob: [1.000000e+00 2.688022e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4153397e-31]\n",
      "Action prob: [1.0000000e+00 1.4153397e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2844146e-32]\n",
      "Action prob: [1.0000000e+00 2.2844146e-32], Action: 0, state: 8\n",
      "[1.00000e+00 7.41878e-27]\n",
      "Action prob: [1.00000e+00 7.41878e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6116091e-34]\n",
      "Action prob: [1.0000000e+00 2.6116091e-34], Action: 0, state: 8\n",
      "[1.000000e+00 8.289865e-27]\n",
      "Action prob: [1.000000e+00 8.289865e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4976702e-32]\n",
      "Action prob: [1.0000000e+00 3.4976702e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2559169e-25]\n",
      "Action prob: [1.0000000e+00 1.2559169e-25], Action: 0, state: 8\n",
      "[1.000000e+00 5.030136e-32]\n",
      "Action prob: [1.000000e+00 5.030136e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3532245e-30]\n",
      "Action prob: [1.0000000e+00 1.3532245e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5411704e-35]\n",
      "Action prob: [1.0000000e+00 1.5411704e-35], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., 0., -0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -84100, loss is -0.0\n",
      "[1.000000e+00 6.308082e-29]\n",
      "Action prob: [1.000000e+00 6.308082e-29], Action: 0, state: 0\n",
      "[1.000000e+00 5.752232e-30]\n",
      "Action prob: [1.000000e+00 5.752232e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 7.8047817e-31]\n",
      "Action prob: [1.0000000e+00 7.8047817e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 1.6884562e-31]\n",
      "Action prob: [1.0000000e+00 1.6884562e-31], Action: 0, state: 1\n",
      "[1.000000e+00 3.165714e-29]\n",
      "Action prob: [1.000000e+00 3.165714e-29], Action: 0, state: 1\n",
      "[1.000000e+00 8.443888e-28]\n",
      "Action prob: [1.000000e+00 8.443888e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 2.6043916e-30]\n",
      "Action prob: [1.0000000e+00 2.6043916e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.6891426e-27]\n",
      "Action prob: [1.0000000e+00 1.6891426e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 2.4393492e-30]\n",
      "Action prob: [1.0000000e+00 2.4393492e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 1.4695678e-29]\n",
      "Action prob: [1.0000000e+00 1.4695678e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 3.2682234e-29]\n",
      "Action prob: [1.0000000e+00 3.2682234e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 2.1571598e-35]\n",
      "Action prob: [1.0000000e+00 2.1571598e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0163007e-31]\n",
      "Action prob: [1.0000000e+00 4.0163007e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7041324e-34]\n",
      "Action prob: [1.0000000e+00 1.7041324e-34], Action: 0, state: 8\n",
      "[1.000000e+00 3.673643e-26]\n",
      "Action prob: [1.000000e+00 3.673643e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4897081e-27]\n",
      "Action prob: [1.0000000e+00 1.4897081e-27], Action: 0, state: 8\n",
      "[1.000000e+00 5.693067e-32]\n",
      "Action prob: [1.000000e+00 5.693067e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 8.3434835e-34]\n",
      "Action prob: [1.0000000e+00 8.3434835e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 8.6158926e-26]\n",
      "Action prob: [1.0000000e+00 8.6158926e-26], Action: 0, state: 8\n",
      "[1.000000e+00 1.252295e-33]\n",
      "Action prob: [1.000000e+00 1.252295e-33], Action: 0, state: 8\n",
      "[1.00000000e+00 1.09238754e-26]\n",
      "Action prob: [1.00000000e+00 1.09238754e-26], Action: 0, state: 8\n",
      "[1.000000e+00 4.421079e-33]\n",
      "Action prob: [1.000000e+00 4.421079e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2288233e-26]\n",
      "Action prob: [1.0000000e+00 2.2288233e-26], Action: 0, state: 8\n",
      "[1.000000e+00 2.298022e-33]\n",
      "Action prob: [1.000000e+00 2.298022e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.4269476e-35]\n",
      "Action prob: [1.0000000e+00 4.4269476e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1137922e-30]\n",
      "Action prob: [1.0000000e+00 3.1137922e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7775506e-35]\n",
      "Action prob: [1.0000000e+00 4.7775506e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.4008384e-37]\n",
      "Action prob: [1.0000000e+00 5.4008384e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 8.1619655e-27]\n",
      "Action prob: [1.0000000e+00 8.1619655e-27], Action: 0, state: 8\n",
      "[1.00000000e+00 1.12789716e-35]\n",
      "Action prob: [1.00000000e+00 1.12789716e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7619062e-27]\n",
      "Action prob: [1.0000000e+00 1.7619062e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 6.9635867e-34]\n",
      "Action prob: [1.0000000e+00 6.9635867e-34], Action: 0, state: 8\n",
      "[1.00e+00 2.72e-43]\n",
      "Action prob: [1.00e+00 2.72e-43], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7385979e-35]\n",
      "Action prob: [1.0000000e+00 1.7385979e-35], Action: 0, state: 8\n",
      "[1.000000e+00 4.030755e-33]\n",
      "Action prob: [1.000000e+00 4.030755e-33], Action: 0, state: 8\n",
      "[1.0000e+00 4.7491e-41]\n",
      "Action prob: [1.0000e+00 4.7491e-41], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6418692e-27]\n",
      "Action prob: [1.0000000e+00 2.6418692e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2918598e-33]\n",
      "Action prob: [1.0000000e+00 1.2918598e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.8892413e-28]\n",
      "Action prob: [1.0000000e+00 4.8892413e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0951176e-31]\n",
      "Action prob: [1.0000000e+00 1.0951176e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 5.8422253e-34]\n",
      "Action prob: [1.0000000e+00 5.8422253e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 6.3578776e-35]\n",
      "Action prob: [1.0000000e+00 6.3578776e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 7.9906063e-29]\n",
      "Action prob: [1.0000000e+00 7.9906063e-29], Action: 0, state: 8\n",
      "[1.000000e+00 3.859973e-34]\n",
      "Action prob: [1.000000e+00 3.859973e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3671988e-27]\n",
      "Action prob: [1.0000000e+00 2.3671988e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 6.9943627e-34]\n",
      "Action prob: [1.0000000e+00 6.9943627e-34], Action: 0, state: 8\n",
      "[1.000000e+00 8.278489e-27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prob: [1.000000e+00 8.278489e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4281081e-36]\n",
      "Action prob: [1.0000000e+00 2.4281081e-36], Action: 0, state: 8\n",
      "[1.000000e+00 6.891757e-27]\n",
      "Action prob: [1.000000e+00 6.891757e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4180748e-32]\n",
      "Action prob: [1.0000000e+00 2.4180748e-32], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -111700, loss is -0.0\n",
      "[1.000000e+00 4.909833e-30]\n",
      "Action prob: [1.000000e+00 4.909833e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 4.0005684e-30]\n",
      "Action prob: [1.0000000e+00 4.0005684e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 1.4739244e-29]\n",
      "Action prob: [1.0000000e+00 1.4739244e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 3.8417488e-31]\n",
      "Action prob: [1.0000000e+00 3.8417488e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 1.8579973e-30]\n",
      "Action prob: [1.0000000e+00 1.8579973e-30], Action: 0, state: 1\n",
      "[1.000000e+00 9.386188e-29]\n",
      "Action prob: [1.000000e+00 9.386188e-29], Action: 0, state: 1\n",
      "[1.000000e+00 1.520034e-28]\n",
      "Action prob: [1.000000e+00 1.520034e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 2.7179617e-29]\n",
      "Action prob: [1.0000000e+00 2.7179617e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 2.3850322e-31]\n",
      "Action prob: [1.0000000e+00 2.3850322e-31], Action: 0, state: 1\n",
      "[1.000000e+00 4.696434e-28]\n",
      "Action prob: [1.000000e+00 4.696434e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 9.7119155e-30]\n",
      "Action prob: [1.0000000e+00 9.7119155e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.7491272e-29]\n",
      "Action prob: [1.0000000e+00 1.7491272e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 3.1665352e-29]\n",
      "Action prob: [1.0000000e+00 3.1665352e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 2.9084472e-30]\n",
      "Action prob: [1.0000000e+00 2.9084472e-30], Action: 0, state: 2\n",
      "[1.000000e+00 4.993836e-29]\n",
      "Action prob: [1.000000e+00 4.993836e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 2.2235886e-29]\n",
      "Action prob: [1.0000000e+00 2.2235886e-29], Action: 0, state: 3\n",
      "[1.00000e+00 1.54273e-34]\n",
      "Action prob: [1.00000e+00 1.54273e-34], Action: 0, state: 8\n",
      "[1.000000e+00 9.536848e-34]\n",
      "Action prob: [1.000000e+00 9.536848e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7452935e-37]\n",
      "Action prob: [1.0000000e+00 2.7452935e-37], Action: 0, state: 8\n",
      "[1.00000e+00 2.20563e-40]\n",
      "Action prob: [1.00000e+00 2.20563e-40], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3997349e-26]\n",
      "Action prob: [1.0000000e+00 1.3997349e-26], Action: 0, state: 8\n",
      "[1.0000e+00 6.3416e-35]\n",
      "Action prob: [1.0000e+00 6.3416e-35], Action: 0, state: 8\n",
      "[1.00000e+00 8.95289e-34]\n",
      "Action prob: [1.00000e+00 8.95289e-34], Action: 0, state: 8\n",
      "[1.000000e+00 2.939215e-33]\n",
      "Action prob: [1.000000e+00 2.939215e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6194294e-28]\n",
      "Action prob: [1.0000000e+00 2.6194294e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5476813e-34]\n",
      "Action prob: [1.0000000e+00 1.5476813e-34], Action: 0, state: 8\n",
      "[1.000000e+00 9.436431e-33]\n",
      "Action prob: [1.000000e+00 9.436431e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1398623e-33]\n",
      "Action prob: [1.0000000e+00 1.1398623e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3486558e-34]\n",
      "Action prob: [1.0000000e+00 1.3486558e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8766647e-33]\n",
      "Action prob: [1.0000000e+00 3.8766647e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2528188e-33]\n",
      "Action prob: [1.0000000e+00 3.2528188e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1454454e-34]\n",
      "Action prob: [1.0000000e+00 1.1454454e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 8.5228455e-29]\n",
      "Action prob: [1.0000000e+00 8.5228455e-29], Action: 0, state: 8\n",
      "[1.000000e+00 5.624436e-35]\n",
      "Action prob: [1.000000e+00 5.624436e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5400421e-35]\n",
      "Action prob: [1.0000000e+00 1.5400421e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 4.6883637e-27]\n",
      "Action prob: [1.0000000e+00 4.6883637e-27], Action: 0, state: 8\n",
      "[1.00000000e+00 1.01837815e-30]\n",
      "Action prob: [1.00000000e+00 1.01837815e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 8.1132143e-38]\n",
      "Action prob: [1.0000000e+00 8.1132143e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 7.3011956e-28]\n",
      "Action prob: [1.0000000e+00 7.3011956e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4788813e-28]\n",
      "Action prob: [1.0000000e+00 2.4788813e-28], Action: 0, state: 8\n",
      "[1.000e+00 3.338e-42]\n",
      "Action prob: [1.000e+00 3.338e-42], Action: 0, state: 8\n",
      "[1.000000e+00 8.150172e-35]\n",
      "Action prob: [1.000000e+00 8.150172e-35], Action: 0, state: 8\n",
      "[1.000000e+00 4.395935e-34]\n",
      "Action prob: [1.000000e+00 4.395935e-34], Action: 0, state: 8\n",
      "[1.000000e+00 1.177985e-33]\n",
      "Action prob: [1.000000e+00 1.177985e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8340389e-32]\n",
      "Action prob: [1.0000000e+00 1.8340389e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9924334e-33]\n",
      "Action prob: [1.0000000e+00 2.9924334e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 6.8433755e-33]\n",
      "Action prob: [1.0000000e+00 6.8433755e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4483877e-26]\n",
      "Action prob: [1.0000000e+00 2.4483877e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4131585e-26]\n",
      "Action prob: [1.0000000e+00 1.4131585e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2952094e-27]\n",
      "Action prob: [1.0000000e+00 1.2952094e-27], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -92200, loss is -0.0\n",
      "[1.0000000e+00 2.8038205e-30]\n",
      "Action prob: [1.0000000e+00 2.8038205e-30], Action: 0, state: 0\n",
      "[1.000000e+00 2.807888e-30]\n",
      "Action prob: [1.000000e+00 2.807888e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.3896235e-30]\n",
      "Action prob: [1.0000000e+00 1.3896235e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.9241059e-29]\n",
      "Action prob: [1.0000000e+00 1.9241059e-29], Action: 0, state: 1\n",
      "[1.000000e+00 4.810221e-31]\n",
      "Action prob: [1.000000e+00 4.810221e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 4.8393058e-29]\n",
      "Action prob: [1.0000000e+00 4.8393058e-29], Action: 0, state: 1\n",
      "[1.000000e+00 2.673078e-30]\n",
      "Action prob: [1.000000e+00 2.673078e-30], Action: 0, state: 1\n",
      "[1.000000e+00 4.729203e-30]\n",
      "Action prob: [1.000000e+00 4.729203e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.0575847e-31]\n",
      "Action prob: [1.0000000e+00 1.0575847e-31], Action: 0, state: 1\n",
      "[1.000000e+00 2.697766e-30]\n",
      "Action prob: [1.000000e+00 2.697766e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 1.7995692e-30]\n",
      "Action prob: [1.0000000e+00 1.7995692e-30], Action: 0, state: 2\n",
      "[1.000000e+00 7.686066e-31]\n",
      "Action prob: [1.000000e+00 7.686066e-31], Action: 0, state: 3\n",
      "[1.0000000e+00 2.7121562e-33]\n",
      "Action prob: [1.0000000e+00 2.7121562e-33], Action: 0, state: 3\n",
      "[1.0000000e+00 1.0655079e-34]\n",
      "Action prob: [1.0000000e+00 1.0655079e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 6.0914275e-27]\n",
      "Action prob: [1.0000000e+00 6.0914275e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4271156e-32]\n",
      "Action prob: [1.0000000e+00 3.4271156e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4800695e-28]\n",
      "Action prob: [1.0000000e+00 3.4800695e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 6.0274213e-35]\n",
      "Action prob: [1.0000000e+00 6.0274213e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6712532e-28]\n",
      "Action prob: [1.0000000e+00 1.6712532e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4779279e-27]\n",
      "Action prob: [1.0000000e+00 2.4779279e-27], Action: 0, state: 8\n",
      "[1.000000e+00 6.847308e-36]\n",
      "Action prob: [1.000000e+00 6.847308e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5969265e-33]\n",
      "Action prob: [1.0000000e+00 1.5969265e-33], Action: 0, state: 8\n",
      "[1.00000e+00 6.74162e-34]\n",
      "Action prob: [1.00000e+00 6.74162e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7597707e-34]\n",
      "Action prob: [1.0000000e+00 1.7597707e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 5.1221455e-34]\n",
      "Action prob: [1.0000000e+00 5.1221455e-34], Action: 0, state: 8\n",
      "[1.00000e+00 5.70491e-40]\n",
      "Action prob: [1.00000e+00 5.70491e-40], Action: 0, state: 8\n",
      "[1.000000e+00 8.945446e-27]\n",
      "Action prob: [1.000000e+00 8.945446e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2124514e-26]\n",
      "Action prob: [1.0000000e+00 1.2124514e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0130944e-35]\n",
      "Action prob: [1.0000000e+00 1.0130944e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3145036e-30]\n",
      "Action prob: [1.0000000e+00 2.3145036e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3456814e-25]\n",
      "Action prob: [1.0000000e+00 2.3456814e-25], Action: 0, state: 8\n",
      "[1.000000e+00 1.277944e-34]\n",
      "Action prob: [1.000000e+00 1.277944e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8225647e-26]\n",
      "Action prob: [1.0000000e+00 1.8225647e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7631172e-26]\n",
      "Action prob: [1.0000000e+00 2.7631172e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6107836e-33]\n",
      "Action prob: [1.0000000e+00 2.6107836e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.1270104e-35]\n",
      "Action prob: [1.0000000e+00 5.1270104e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.1146296e-26]\n",
      "Action prob: [1.0000000e+00 5.1146296e-26], Action: 0, state: 8\n",
      "[1.000000e+00 2.136254e-27]\n",
      "Action prob: [1.000000e+00 2.136254e-27], Action: 0, state: 8\n",
      "[1.000000e+00 4.131571e-33]\n",
      "Action prob: [1.000000e+00 4.131571e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3444232e-27]\n",
      "Action prob: [1.0000000e+00 5.3444232e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2665066e-27]\n",
      "Action prob: [1.0000000e+00 3.2665066e-27], Action: 0, state: 8\n",
      "[1.000000e+00 3.936847e-38]\n",
      "Action prob: [1.000000e+00 3.936847e-38], Action: 0, state: 8\n",
      "[1.000000e+00 7.441648e-36]\n",
      "Action prob: [1.000000e+00 7.441648e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9834517e-33]\n",
      "Action prob: [1.0000000e+00 2.9834517e-33], Action: 0, state: 8\n",
      "[1.000000e+00 8.396769e-35]\n",
      "Action prob: [1.000000e+00 8.396769e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1937351e-35]\n",
      "Action prob: [1.0000000e+00 1.1937351e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.7451095e-36]\n",
      "Action prob: [1.0000000e+00 5.7451095e-36], Action: 0, state: 8\n",
      "[1.000000e+00 7.069178e-33]\n",
      "Action prob: [1.000000e+00 7.069178e-33], Action: 0, state: 8\n",
      "[1.000000e+00 9.834842e-36]\n",
      "Action prob: [1.000000e+00 9.834842e-36], Action: 0, state: 8\n",
      "[1.00000e+00 5.82918e-34]\n",
      "Action prob: [1.00000e+00 5.82918e-34], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0.,\n",
      "        0., -0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for this episode -104200, loss is -0.0\n",
      "[1.0000000e+00 1.3586763e-30]\n",
      "Action prob: [1.0000000e+00 1.3586763e-30], Action: 0, state: 0\n",
      "[1.000000e+00 9.190508e-28]\n",
      "Action prob: [1.000000e+00 9.190508e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 5.3298255e-27]\n",
      "Action prob: [1.0000000e+00 5.3298255e-27], Action: 0, state: 2\n",
      "[1.0000000e+00 1.2270978e-28]\n",
      "Action prob: [1.0000000e+00 1.2270978e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.5718806e-33]\n",
      "Action prob: [1.0000000e+00 1.5718806e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5807907e-35]\n",
      "Action prob: [1.0000000e+00 1.5807907e-35], Action: 0, state: 8\n",
      "[1.000000e+00 4.019222e-34]\n",
      "Action prob: [1.000000e+00 4.019222e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8186282e-32]\n",
      "Action prob: [1.0000000e+00 1.8186282e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 4.6648388e-32]\n",
      "Action prob: [1.0000000e+00 4.6648388e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4505444e-35]\n",
      "Action prob: [1.0000000e+00 2.4505444e-35], Action: 0, state: 8\n",
      "[1.00000e+00 7.58284e-35]\n",
      "Action prob: [1.00000e+00 7.58284e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2714828e-26]\n",
      "Action prob: [1.0000000e+00 2.2714828e-26], Action: 0, state: 8\n",
      "[1.000000e+00 4.272051e-32]\n",
      "Action prob: [1.000000e+00 4.272051e-32], Action: 0, state: 8\n",
      "[1.000000e+00 9.831326e-34]\n",
      "Action prob: [1.000000e+00 9.831326e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 8.7041624e-26]\n",
      "Action prob: [1.0000000e+00 8.7041624e-26], Action: 0, state: 8\n",
      "[1.000000e+00 4.475748e-28]\n",
      "Action prob: [1.000000e+00 4.475748e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8704118e-32]\n",
      "Action prob: [1.0000000e+00 1.8704118e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1020948e-32]\n",
      "Action prob: [1.0000000e+00 1.1020948e-32], Action: 0, state: 8\n",
      "[1.000000e+00 3.014957e-35]\n",
      "Action prob: [1.000000e+00 3.014957e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6557127e-34]\n",
      "Action prob: [1.0000000e+00 2.6557127e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1973343e-26]\n",
      "Action prob: [1.0000000e+00 2.1973343e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8707159e-35]\n",
      "Action prob: [1.0000000e+00 1.8707159e-35], Action: 0, state: 8\n",
      "[1.000000e+00 3.766157e-27]\n",
      "Action prob: [1.000000e+00 3.766157e-27], Action: 0, state: 8\n",
      "[1.000000e+00 5.545782e-26]\n",
      "Action prob: [1.000000e+00 5.545782e-26], Action: 0, state: 8\n",
      "[1.000000e+00 9.597717e-28]\n",
      "Action prob: [1.000000e+00 9.597717e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5174338e-34]\n",
      "Action prob: [1.0000000e+00 1.5174338e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1151869e-34]\n",
      "Action prob: [1.0000000e+00 1.1151869e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8798896e-33]\n",
      "Action prob: [1.0000000e+00 3.8798896e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5911684e-25]\n",
      "Action prob: [1.0000000e+00 1.5911684e-25], Action: 0, state: 8\n",
      "[1.000000e+00 3.111601e-34]\n",
      "Action prob: [1.000000e+00 3.111601e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.543117e-34]\n",
      "Action prob: [1.000000e+00 7.543117e-34], Action: 0, state: 8\n",
      "[1.000000e+00 9.670415e-27]\n",
      "Action prob: [1.000000e+00 9.670415e-27], Action: 0, state: 8\n",
      "[1.000000e+00 5.891153e-32]\n",
      "Action prob: [1.000000e+00 5.891153e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7339028e-34]\n",
      "Action prob: [1.0000000e+00 1.7339028e-34], Action: 0, state: 8\n",
      "[1.000000e+00 2.421941e-26]\n",
      "Action prob: [1.000000e+00 2.421941e-26], Action: 0, state: 8\n",
      "[1.000000e+00 1.161436e-32]\n",
      "Action prob: [1.000000e+00 1.161436e-32], Action: 0, state: 8\n",
      "[1.000000e+00 1.842211e-36]\n",
      "Action prob: [1.000000e+00 1.842211e-36], Action: 0, state: 8\n",
      "[1.000000e+00 8.435368e-33]\n",
      "Action prob: [1.000000e+00 8.435368e-33], Action: 0, state: 8\n",
      "[1.000000e+00 5.111376e-32]\n",
      "Action prob: [1.000000e+00 5.111376e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4181221e-31]\n",
      "Action prob: [1.0000000e+00 2.4181221e-31], Action: 0, state: 8\n",
      "[1.000000e+00 7.959604e-37]\n",
      "Action prob: [1.000000e+00 7.959604e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2198785e-33]\n",
      "Action prob: [1.0000000e+00 4.2198785e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9911316e-26]\n",
      "Action prob: [1.0000000e+00 2.9911316e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1298198e-34]\n",
      "Action prob: [1.0000000e+00 4.1298198e-34], Action: 0, state: 8\n",
      "[1.000000e+00 5.649331e-37]\n",
      "Action prob: [1.000000e+00 5.649331e-37], Action: 0, state: 8\n",
      "[1.000000e+00 7.125816e-26]\n",
      "Action prob: [1.000000e+00 7.125816e-26], Action: 0, state: 8\n",
      "[1.000000e+00 4.125464e-31]\n",
      "Action prob: [1.000000e+00 4.125464e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2559256e-31]\n",
      "Action prob: [1.0000000e+00 3.2559256e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 6.2932093e-35]\n",
      "Action prob: [1.0000000e+00 6.2932093e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4581334e-34]\n",
      "Action prob: [1.0000000e+00 1.4581334e-34], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -138800, loss is -0.0\n",
      "[1.0000000e+00 2.2696702e-28]\n",
      "Action prob: [1.0000000e+00 2.2696702e-28], Action: 0, state: 0\n",
      "[1.000000e+00 5.439982e-29]\n",
      "Action prob: [1.000000e+00 5.439982e-29], Action: 0, state: 0\n",
      "[1.000000e+00 5.253578e-29]\n",
      "Action prob: [1.000000e+00 5.253578e-29], Action: 0, state: 0\n",
      "[1.00000e+00 5.70163e-32]\n",
      "Action prob: [1.00000e+00 5.70163e-32], Action: 0, state: 0\n",
      "[1.0000000e+00 1.2763888e-28]\n",
      "Action prob: [1.0000000e+00 1.2763888e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 1.3271577e-29]\n",
      "Action prob: [1.0000000e+00 1.3271577e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 2.5521314e-28]\n",
      "Action prob: [1.0000000e+00 2.5521314e-28], Action: 0, state: 1\n",
      "[1.000000e+00 4.023942e-29]\n",
      "Action prob: [1.000000e+00 4.023942e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 1.3104928e-33]\n",
      "Action prob: [1.0000000e+00 1.3104928e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0778576e-35]\n",
      "Action prob: [1.0000000e+00 1.0778576e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 3.0466254e-34]\n",
      "Action prob: [1.0000000e+00 3.0466254e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 3.9883306e-31]\n",
      "Action prob: [1.0000000e+00 3.9883306e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3913397e-26]\n",
      "Action prob: [1.0000000e+00 1.3913397e-26], Action: 0, state: 9\n",
      "[1.000000e+00 7.594807e-32]\n",
      "Action prob: [1.000000e+00 7.594807e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7051009e-27]\n",
      "Action prob: [1.0000000e+00 1.7051009e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2083933e-25]\n",
      "Action prob: [1.0000000e+00 1.2083933e-25], Action: 0, state: 9\n",
      "[1.000000e+00 2.907474e-28]\n",
      "Action prob: [1.000000e+00 2.907474e-28], Action: 0, state: 9\n",
      "[1.000000e+00 8.293599e-34]\n",
      "Action prob: [1.000000e+00 8.293599e-34], Action: 0, state: 9\n",
      "[1.000000e+00 4.703954e-25]\n",
      "Action prob: [1.000000e+00 4.703954e-25], Action: 0, state: 9\n",
      "[1.0000000e+00 1.4062633e-35]\n",
      "Action prob: [1.0000000e+00 1.4062633e-35], Action: 0, state: 9\n",
      "[1.000000e+00 6.763612e-36]\n",
      "Action prob: [1.000000e+00 6.763612e-36], Action: 0, state: 9\n",
      "[1.000000e+00 7.325221e-34]\n",
      "Action prob: [1.000000e+00 7.325221e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0028335e-32]\n",
      "Action prob: [1.0000000e+00 1.0028335e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.4904231e-36]\n",
      "Action prob: [1.0000000e+00 1.4904231e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 5.1615104e-27]\n",
      "Action prob: [1.0000000e+00 5.1615104e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0759194e-26]\n",
      "Action prob: [1.0000000e+00 1.0759194e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 2.2846116e-35]\n",
      "Action prob: [1.0000000e+00 2.2846116e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 3.5669093e-27]\n",
      "Action prob: [1.0000000e+00 3.5669093e-27], Action: 0, state: 9\n",
      "[1.00000e+00 3.21204e-34]\n",
      "Action prob: [1.00000e+00 3.21204e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.9247402e-26]\n",
      "Action prob: [1.0000000e+00 1.9247402e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 3.2890635e-27]\n",
      "Action prob: [1.0000000e+00 3.2890635e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 3.1283214e-35]\n",
      "Action prob: [1.0000000e+00 3.1283214e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 1.5961892e-26]\n",
      "Action prob: [1.0000000e+00 1.5961892e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3392955e-32]\n",
      "Action prob: [1.0000000e+00 1.3392955e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.6088441e-25]\n",
      "Action prob: [1.0000000e+00 1.6088441e-25], Action: 0, state: 9\n",
      "[1.0000000e+00 3.5016565e-35]\n",
      "Action prob: [1.0000000e+00 3.5016565e-35], Action: 0, state: 9\n",
      "[1.000000e+00 2.579158e-32]\n",
      "Action prob: [1.000000e+00 2.579158e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 5.7938868e-34]\n",
      "Action prob: [1.0000000e+00 5.7938868e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1868616e-26]\n",
      "Action prob: [1.0000000e+00 1.1868616e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 2.5883703e-27]\n",
      "Action prob: [1.0000000e+00 2.5883703e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 2.6649653e-36]\n",
      "Action prob: [1.0000000e+00 2.6649653e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 2.4546496e-29]\n",
      "Action prob: [1.0000000e+00 2.4546496e-29], Action: 0, state: 9\n",
      "[1.000000e+00 5.840373e-35]\n",
      "Action prob: [1.000000e+00 5.840373e-35], Action: 0, state: 9\n",
      "[1.000000e+00 6.175518e-34]\n",
      "Action prob: [1.000000e+00 6.175518e-34], Action: 0, state: 9\n",
      "[1.00000e+00 7.09944e-27]\n",
      "Action prob: [1.00000e+00 7.09944e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 7.7804556e-26]\n",
      "Action prob: [1.0000000e+00 7.7804556e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 8.8696716e-27]\n",
      "Action prob: [1.0000000e+00 8.8696716e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 4.4499448e-33]\n",
      "Action prob: [1.0000000e+00 4.4499448e-33], Action: 0, state: 9\n",
      "[1.000000e+00 1.935681e-27]\n",
      "Action prob: [1.000000e+00 1.935681e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 3.4366662e-28]\n",
      "Action prob: [1.0000000e+00 3.4366662e-28], Action: 0, state: 9\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0.,\n",
      "        -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -36500, loss is -0.0\n",
      "[1.0000000e+00 1.2870476e-28]\n",
      "Action prob: [1.0000000e+00 1.2870476e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 2.2850543e-29]\n",
      "Action prob: [1.0000000e+00 2.2850543e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 2.2546108e-29]\n",
      "Action prob: [1.0000000e+00 2.2546108e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 2.4270148e-29]\n",
      "Action prob: [1.0000000e+00 2.4270148e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 2.6183692e-29]\n",
      "Action prob: [1.0000000e+00 2.6183692e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.0821998e-28]\n",
      "Action prob: [1.0000000e+00 1.0821998e-28], Action: 0, state: 1\n",
      "[1.00000000e+00 1.00285414e-29]\n",
      "Action prob: [1.00000000e+00 1.00285414e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 1.1330891e-28]\n",
      "Action prob: [1.0000000e+00 1.1330891e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.6932456e-27]\n",
      "Action prob: [1.0000000e+00 1.6932456e-27], Action: 0, state: 8\n",
      "[1.000000e+00 1.947517e-34]\n",
      "Action prob: [1.000000e+00 1.947517e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6092483e-27]\n",
      "Action prob: [1.0000000e+00 2.6092483e-27], Action: 0, state: 8\n",
      "[1.000000e+00 3.778604e-35]\n",
      "Action prob: [1.000000e+00 3.778604e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2470376e-32]\n",
      "Action prob: [1.0000000e+00 1.2470376e-32], Action: 0, state: 8\n",
      "[1.00000000e+00 1.10385606e-35]\n",
      "Action prob: [1.00000000e+00 1.10385606e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5996507e-27]\n",
      "Action prob: [1.0000000e+00 1.5996507e-27], Action: 0, state: 8\n",
      "[1.000000e+00 3.391474e-36]\n",
      "Action prob: [1.000000e+00 3.391474e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6928663e-34]\n",
      "Action prob: [1.0000000e+00 2.6928663e-34], Action: 0, state: 8\n",
      "[1.000000e+00 1.639888e-32]\n",
      "Action prob: [1.000000e+00 1.639888e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2815421e-26]\n",
      "Action prob: [1.0000000e+00 1.2815421e-26], Action: 0, state: 8\n",
      "[1.000000e+00 3.070075e-34]\n",
      "Action prob: [1.000000e+00 3.070075e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0513925e-34]\n",
      "Action prob: [1.0000000e+00 1.0513925e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3580103e-34]\n",
      "Action prob: [1.0000000e+00 1.3580103e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5595395e-35]\n",
      "Action prob: [1.0000000e+00 1.5595395e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1298979e-27]\n",
      "Action prob: [1.0000000e+00 3.1298979e-27], Action: 0, state: 8\n",
      "[1.00000e+00 6.42449e-33]\n",
      "Action prob: [1.00000e+00 6.42449e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5120946e-33]\n",
      "Action prob: [1.0000000e+00 3.5120946e-33], Action: 0, state: 8\n",
      "[1.000000e+00 3.404116e-26]\n",
      "Action prob: [1.000000e+00 3.404116e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 7.3224034e-33]\n",
      "Action prob: [1.0000000e+00 7.3224034e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3838707e-36]\n",
      "Action prob: [1.0000000e+00 5.3838707e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6095656e-36]\n",
      "Action prob: [1.0000000e+00 1.6095656e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3734794e-30]\n",
      "Action prob: [1.0000000e+00 2.3734794e-30], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 1.2023006e-33]\n",
      "Action prob: [1.0000000e+00 1.2023006e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0412243e-33]\n",
      "Action prob: [1.0000000e+00 4.0412243e-33], Action: 0, state: 8\n",
      "[1.000000e+00 6.649822e-27]\n",
      "Action prob: [1.000000e+00 6.649822e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1021822e-26]\n",
      "Action prob: [1.0000000e+00 1.1021822e-26], Action: 0, state: 8\n",
      "[1.00000000e+00 1.03426436e-32]\n",
      "Action prob: [1.00000000e+00 1.03426436e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3557059e-28]\n",
      "Action prob: [1.0000000e+00 1.3557059e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5610815e-27]\n",
      "Action prob: [1.0000000e+00 1.5610815e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1587654e-28]\n",
      "Action prob: [1.0000000e+00 1.1587654e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0550014e-32]\n",
      "Action prob: [1.0000000e+00 1.0550014e-32], Action: 0, state: 8\n",
      "[1.00000e+00 1.13592e-27]\n",
      "Action prob: [1.00000e+00 1.13592e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9527147e-27]\n",
      "Action prob: [1.0000000e+00 3.9527147e-27], Action: 0, state: 8\n",
      "[1.0000e+00 3.2079e-40]\n",
      "Action prob: [1.0000e+00 3.2079e-40], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0959891e-27]\n",
      "Action prob: [1.0000000e+00 1.0959891e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.545613e-28]\n",
      "Action prob: [1.000000e+00 9.545613e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5856847e-28]\n",
      "Action prob: [1.0000000e+00 2.5856847e-28], Action: 0, state: 8\n",
      "[1.000000e+00 6.213474e-32]\n",
      "Action prob: [1.000000e+00 6.213474e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9143792e-33]\n",
      "Action prob: [1.0000000e+00 1.9143792e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4064274e-38]\n",
      "Action prob: [1.0000000e+00 1.4064274e-38], Action: 0, state: 8\n",
      "[1.000000e+00 3.990731e-33]\n",
      "Action prob: [1.000000e+00 3.990731e-33], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -123000, loss is -0.0\n",
      "[1.000000e+00 5.037399e-30]\n",
      "Action prob: [1.000000e+00 5.037399e-30], Action: 0, state: 0\n",
      "[1.000000e+00 8.538364e-30]\n",
      "Action prob: [1.000000e+00 8.538364e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 3.5681134e-31]\n",
      "Action prob: [1.0000000e+00 3.5681134e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 2.8330117e-29]\n",
      "Action prob: [1.0000000e+00 2.8330117e-29], Action: 0, state: 1\n",
      "[1.000000e+00 7.027463e-29]\n",
      "Action prob: [1.000000e+00 7.027463e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 2.4319718e-30]\n",
      "Action prob: [1.0000000e+00 2.4319718e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 2.1884282e-31]\n",
      "Action prob: [1.0000000e+00 2.1884282e-31], Action: 0, state: 2\n",
      "[1.0000000e+00 6.0008926e-30]\n",
      "Action prob: [1.0000000e+00 6.0008926e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 2.2109795e-27]\n",
      "Action prob: [1.0000000e+00 2.2109795e-27], Action: 0, state: 2\n",
      "[1.000000e+00 4.147135e-28]\n",
      "Action prob: [1.000000e+00 4.147135e-28], Action: 0, state: 3\n",
      "[1.000000e+00 2.206886e-33]\n",
      "Action prob: [1.000000e+00 2.206886e-33], Action: 0, state: 3\n",
      "[1.0000000e+00 6.7872335e-29]\n",
      "Action prob: [1.0000000e+00 6.7872335e-29], Action: 0, state: 3\n",
      "[1.000000e+00 1.629758e-27]\n",
      "Action prob: [1.000000e+00 1.629758e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0846654e-35]\n",
      "Action prob: [1.0000000e+00 3.0846654e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 4.6949485e-35]\n",
      "Action prob: [1.0000000e+00 4.6949485e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.2480747e-27]\n",
      "Action prob: [1.0000000e+00 5.2480747e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2213913e-35]\n",
      "Action prob: [1.0000000e+00 1.2213913e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2841896e-26]\n",
      "Action prob: [1.0000000e+00 4.2841896e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5562648e-38]\n",
      "Action prob: [1.0000000e+00 3.5562648e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2641022e-27]\n",
      "Action prob: [1.0000000e+00 2.2641022e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0419028e-33]\n",
      "Action prob: [1.0000000e+00 4.0419028e-33], Action: 0, state: 8\n",
      "[1.000000e+00 4.134148e-37]\n",
      "Action prob: [1.000000e+00 4.134148e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2821821e-27]\n",
      "Action prob: [1.0000000e+00 1.2821821e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6306253e-31]\n",
      "Action prob: [1.0000000e+00 1.6306253e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0209203e-35]\n",
      "Action prob: [1.0000000e+00 3.0209203e-35], Action: 0, state: 8\n",
      "[1.00000000e+00 1.03505684e-26]\n",
      "Action prob: [1.00000000e+00 1.03505684e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4681449e-36]\n",
      "Action prob: [1.0000000e+00 1.4681449e-36], Action: 0, state: 8\n",
      "[1.000000e+00 8.869374e-33]\n",
      "Action prob: [1.000000e+00 8.869374e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.5260855e-37]\n",
      "Action prob: [1.0000000e+00 4.5260855e-37], Action: 0, state: 8\n",
      "[1.000000e+00 6.711752e-34]\n",
      "Action prob: [1.000000e+00 6.711752e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9537242e-35]\n",
      "Action prob: [1.0000000e+00 3.9537242e-35], Action: 0, state: 8\n",
      "[1.000000e+00 6.371981e-36]\n",
      "Action prob: [1.000000e+00 6.371981e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 4.5105478e-33]\n",
      "Action prob: [1.0000000e+00 4.5105478e-33], Action: 0, state: 8\n",
      "[1.000000e+00 1.580925e-33]\n",
      "Action prob: [1.000000e+00 1.580925e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0096298e-26]\n",
      "Action prob: [1.0000000e+00 2.0096298e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8368214e-29]\n",
      "Action prob: [1.0000000e+00 1.8368214e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5454159e-34]\n",
      "Action prob: [1.0000000e+00 1.5454159e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.843746e-35]\n",
      "Action prob: [1.000000e+00 7.843746e-35], Action: 0, state: 8\n",
      "[1.000000e+00 6.230848e-32]\n",
      "Action prob: [1.000000e+00 6.230848e-32], Action: 0, state: 8\n",
      "[1.000000e+00 7.566393e-29]\n",
      "Action prob: [1.000000e+00 7.566393e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7113108e-35]\n",
      "Action prob: [1.0000000e+00 4.7113108e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0558175e-28]\n",
      "Action prob: [1.0000000e+00 2.0558175e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 5.8872813e-27]\n",
      "Action prob: [1.0000000e+00 5.8872813e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.720937e-27]\n",
      "Action prob: [1.000000e+00 9.720937e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7678677e-31]\n",
      "Action prob: [1.0000000e+00 1.7678677e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2212751e-27]\n",
      "Action prob: [1.0000000e+00 1.2212751e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.273532e-29]\n",
      "Action prob: [1.000000e+00 7.273532e-29], Action: 0, state: 8\n",
      "[1.000000e+00 2.987411e-28]\n",
      "Action prob: [1.000000e+00 2.987411e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5630735e-35]\n",
      "Action prob: [1.0000000e+00 3.5630735e-35], Action: 0, state: 8\n",
      "[1.000000e+00 7.169438e-27]\n",
      "Action prob: [1.000000e+00 7.169438e-27], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0.,\n",
      "        -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -108500, loss is -0.0\n",
      "[1.0000000e+00 1.2686844e-29]\n",
      "Action prob: [1.0000000e+00 1.2686844e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.3562632e-30]\n",
      "Action prob: [1.0000000e+00 1.3562632e-30], Action: 0, state: 0\n",
      "[1.000000e+00 4.198129e-30]\n",
      "Action prob: [1.000000e+00 4.198129e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 5.5065003e-29]\n",
      "Action prob: [1.0000000e+00 5.5065003e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 5.1164537e-30]\n",
      "Action prob: [1.0000000e+00 5.1164537e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 1.4357819e-30]\n",
      "Action prob: [1.0000000e+00 1.4357819e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.7459065e-30]\n",
      "Action prob: [1.0000000e+00 1.7459065e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 1.6350547e-30]\n",
      "Action prob: [1.0000000e+00 1.6350547e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 1.5865262e-32]\n",
      "Action prob: [1.0000000e+00 1.5865262e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1434508e-33]\n",
      "Action prob: [1.0000000e+00 1.1434508e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5937294e-33]\n",
      "Action prob: [1.0000000e+00 2.5937294e-33], Action: 0, state: 8\n",
      "[1.000000e+00 2.758992e-31]\n",
      "Action prob: [1.000000e+00 2.758992e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5933712e-27]\n",
      "Action prob: [1.0000000e+00 2.5933712e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3408216e-28]\n",
      "Action prob: [1.0000000e+00 1.3408216e-28], Action: 0, state: 8\n",
      "[1.000000e+00 5.555474e-28]\n",
      "Action prob: [1.000000e+00 5.555474e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4350653e-29]\n",
      "Action prob: [1.0000000e+00 1.4350653e-29], Action: 0, state: 8\n",
      "[1.000000e+00 2.494145e-34]\n",
      "Action prob: [1.000000e+00 2.494145e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3796586e-27]\n",
      "Action prob: [1.0000000e+00 1.3796586e-27], Action: 0, state: 8\n",
      "[1.000000e+00 4.092142e-31]\n",
      "Action prob: [1.000000e+00 4.092142e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9782309e-27]\n",
      "Action prob: [1.0000000e+00 1.9782309e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3793042e-26]\n",
      "Action prob: [1.0000000e+00 2.3793042e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3626866e-33]\n",
      "Action prob: [1.0000000e+00 1.3626866e-33], Action: 0, state: 8\n",
      "[1.000000e+00 5.775786e-36]\n",
      "Action prob: [1.000000e+00 5.775786e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5459087e-35]\n",
      "Action prob: [1.0000000e+00 2.5459087e-35], Action: 0, state: 8\n",
      "[1.000000e+00 5.298004e-33]\n",
      "Action prob: [1.000000e+00 5.298004e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1705033e-35]\n",
      "Action prob: [1.0000000e+00 1.1705033e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6593596e-36]\n",
      "Action prob: [1.0000000e+00 2.6593596e-36], Action: 0, state: 8\n",
      "[1.00000e+00 6.42875e-35]\n",
      "Action prob: [1.00000e+00 6.42875e-35], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 1.3659175e-27]\n",
      "Action prob: [1.0000000e+00 1.3659175e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4079605e-26]\n",
      "Action prob: [1.0000000e+00 1.4079605e-26], Action: 0, state: 8\n",
      "[1.000000e+00 6.571419e-35]\n",
      "Action prob: [1.000000e+00 6.571419e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7491827e-34]\n",
      "Action prob: [1.0000000e+00 1.7491827e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 8.4096644e-33]\n",
      "Action prob: [1.0000000e+00 8.4096644e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9451283e-34]\n",
      "Action prob: [1.0000000e+00 2.9451283e-34], Action: 0, state: 8\n",
      "[1.00000e+00 1.15794e-34]\n",
      "Action prob: [1.00000e+00 1.15794e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1433909e-31]\n",
      "Action prob: [1.0000000e+00 1.1433909e-31], Action: 0, state: 8\n",
      "[1.000000e+00 5.169294e-27]\n",
      "Action prob: [1.000000e+00 5.169294e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 5.7991627e-37]\n",
      "Action prob: [1.0000000e+00 5.7991627e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4304082e-27]\n",
      "Action prob: [1.0000000e+00 2.4304082e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4935956e-33]\n",
      "Action prob: [1.0000000e+00 1.4935956e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 8.3107945e-27]\n",
      "Action prob: [1.0000000e+00 8.3107945e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.609039e-35]\n",
      "Action prob: [1.000000e+00 9.609039e-35], Action: 0, state: 8\n",
      "[1.000000e+00 1.759759e-32]\n",
      "Action prob: [1.000000e+00 1.759759e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9758793e-36]\n",
      "Action prob: [1.0000000e+00 3.9758793e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4822607e-28]\n",
      "Action prob: [1.0000000e+00 3.4822607e-28], Action: 0, state: 8\n",
      "[1.000000e+00 1.725538e-39]\n",
      "Action prob: [1.000000e+00 1.725538e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8511978e-26]\n",
      "Action prob: [1.0000000e+00 2.8511978e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8405552e-34]\n",
      "Action prob: [1.0000000e+00 1.8405552e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5595939e-34]\n",
      "Action prob: [1.0000000e+00 1.5595939e-34], Action: 0, state: 8\n",
      "[1.000000e+00 1.583363e-26]\n",
      "Action prob: [1.000000e+00 1.583363e-26], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -122800, loss is -0.0\n",
      "[1.000000e+00 2.766559e-31]\n",
      "Action prob: [1.000000e+00 2.766559e-31], Action: 0, state: 0\n",
      "[1.0000000e+00 2.8611423e-28]\n",
      "Action prob: [1.0000000e+00 2.8611423e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 1.6259931e-29]\n",
      "Action prob: [1.0000000e+00 1.6259931e-29], Action: 0, state: 9\n",
      "[1.000000e+00 3.128704e-27]\n",
      "Action prob: [1.000000e+00 3.128704e-27], Action: 0, state: 9\n",
      "[1.000000e+00 1.126396e-36]\n",
      "Action prob: [1.000000e+00 1.126396e-36], Action: 0, state: 9\n",
      "[1.000000e+00 6.886053e-35]\n",
      "Action prob: [1.000000e+00 6.886053e-35], Action: 0, state: 9\n",
      "[1.00000000e+00 1.15822746e-26]\n",
      "Action prob: [1.00000000e+00 1.15822746e-26], Action: 0, state: 9\n",
      "[1.000000e+00 8.735325e-27]\n",
      "Action prob: [1.000000e+00 8.735325e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3445476e-32]\n",
      "Action prob: [1.0000000e+00 1.3445476e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2634011e-36]\n",
      "Action prob: [1.0000000e+00 1.2634011e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 1.4608673e-26]\n",
      "Action prob: [1.0000000e+00 1.4608673e-26], Action: 0, state: 9\n",
      "[1.000000e+00 9.626912e-34]\n",
      "Action prob: [1.000000e+00 9.626912e-34], Action: 0, state: 9\n",
      "[1.000000e+00 2.850682e-29]\n",
      "Action prob: [1.000000e+00 2.850682e-29], Action: 0, state: 9\n",
      "[1.0000000e+00 1.6960647e-34]\n",
      "Action prob: [1.0000000e+00 1.6960647e-34], Action: 0, state: 9\n",
      "[1.00000e+00 1.25514e-34]\n",
      "Action prob: [1.00000e+00 1.25514e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.6926588e-26]\n",
      "Action prob: [1.0000000e+00 1.6926588e-26], Action: 0, state: 9\n",
      "[1.000000e+00 6.989783e-39]\n",
      "Action prob: [1.000000e+00 6.989783e-39], Action: 0, state: 9\n",
      "[1.0000000e+00 2.8009925e-34]\n",
      "Action prob: [1.0000000e+00 2.8009925e-34], Action: 0, state: 9\n",
      "[1.000000e+00 9.950033e-32]\n",
      "Action prob: [1.000000e+00 9.950033e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1717605e-32]\n",
      "Action prob: [1.0000000e+00 1.1717605e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2423261e-34]\n",
      "Action prob: [1.0000000e+00 1.2423261e-34], Action: 0, state: 9\n",
      "[1.0000e+00 4.2675e-35]\n",
      "Action prob: [1.0000e+00 4.2675e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 1.9659238e-34]\n",
      "Action prob: [1.0000000e+00 1.9659238e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 5.2556863e-35]\n",
      "Action prob: [1.0000000e+00 5.2556863e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 7.7194306e-35]\n",
      "Action prob: [1.0000000e+00 7.7194306e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 3.7191016e-34]\n",
      "Action prob: [1.0000000e+00 3.7191016e-34], Action: 0, state: 9\n",
      "[1.00000e+00 9.90076e-35]\n",
      "Action prob: [1.00000e+00 9.90076e-35], Action: 0, state: 9\n",
      "[1.000000e+00 9.993461e-27]\n",
      "Action prob: [1.000000e+00 9.993461e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 4.4958054e-27]\n",
      "Action prob: [1.0000000e+00 4.4958054e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 3.5616485e-34]\n",
      "Action prob: [1.0000000e+00 3.5616485e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2874643e-29]\n",
      "Action prob: [1.0000000e+00 1.2874643e-29], Action: 0, state: 9\n",
      "[1.000000e+00 8.138679e-27]\n",
      "Action prob: [1.000000e+00 8.138679e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 2.6718199e-33]\n",
      "Action prob: [1.0000000e+00 2.6718199e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.9551688e-27]\n",
      "Action prob: [1.0000000e+00 1.9551688e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 6.7640605e-33]\n",
      "Action prob: [1.0000000e+00 6.7640605e-33], Action: 0, state: 9\n",
      "[1.000000e+00 6.170317e-33]\n",
      "Action prob: [1.000000e+00 6.170317e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 4.1896595e-33]\n",
      "Action prob: [1.0000000e+00 4.1896595e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 7.4317486e-28]\n",
      "Action prob: [1.0000000e+00 7.4317486e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7872235e-27]\n",
      "Action prob: [1.0000000e+00 1.7872235e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.9577729e-35]\n",
      "Action prob: [1.0000000e+00 1.9577729e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1575601e-34]\n",
      "Action prob: [1.0000000e+00 1.1575601e-34], Action: 0, state: 9\n",
      "[1.00000e+00 1.01935e-40]\n",
      "Action prob: [1.00000e+00 1.01935e-40], Action: 0, state: 9\n",
      "[1.0000000e+00 7.4318076e-35]\n",
      "Action prob: [1.0000000e+00 7.4318076e-35], Action: 0, state: 9\n",
      "[1.000000e+00 5.818046e-28]\n",
      "Action prob: [1.000000e+00 5.818046e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 2.6497334e-33]\n",
      "Action prob: [1.0000000e+00 2.6497334e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1878118e-35]\n",
      "Action prob: [1.0000000e+00 1.1878118e-35], Action: 0, state: 9\n",
      "[1.000000e+00 6.165627e-28]\n",
      "Action prob: [1.000000e+00 6.165627e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 4.3927795e-36]\n",
      "Action prob: [1.0000000e+00 4.3927795e-36], Action: 0, state: 9\n",
      "[1.000000e+00 4.373255e-34]\n",
      "Action prob: [1.000000e+00 4.373255e-34], Action: 0, state: 9\n",
      "[1.000000e+00 8.823999e-37]\n",
      "Action prob: [1.000000e+00 8.823999e-37], Action: 0, state: 9\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0., -0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        -0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -50000, loss is -0.0\n",
      "[1.0000000e+00 5.6535117e-30]\n",
      "Action prob: [1.0000000e+00 5.6535117e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 3.5576244e-29]\n",
      "Action prob: [1.0000000e+00 3.5576244e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.1783665e-34]\n",
      "Action prob: [1.0000000e+00 1.1783665e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.8967213e-27]\n",
      "Action prob: [1.0000000e+00 1.8967213e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 4.9196297e-26]\n",
      "Action prob: [1.0000000e+00 4.9196297e-26], Action: 0, state: 9\n",
      "[1.000000e+00 6.920399e-33]\n",
      "Action prob: [1.000000e+00 6.920399e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 3.4131528e-26]\n",
      "Action prob: [1.0000000e+00 3.4131528e-26], Action: 0, state: 9\n",
      "[1.000000e+00 6.586404e-27]\n",
      "Action prob: [1.000000e+00 6.586404e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 2.5289702e-27]\n",
      "Action prob: [1.0000000e+00 2.5289702e-27], Action: 0, state: 9\n",
      "[1.000000e+00 9.166911e-35]\n",
      "Action prob: [1.000000e+00 9.166911e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2035672e-33]\n",
      "Action prob: [1.0000000e+00 1.2035672e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 2.7128274e-34]\n",
      "Action prob: [1.0000000e+00 2.7128274e-34], Action: 0, state: 9\n",
      "[1.000000e+00 7.683766e-27]\n",
      "Action prob: [1.000000e+00 7.683766e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 4.6430496e-27]\n",
      "Action prob: [1.0000000e+00 4.6430496e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 2.6315927e-32]\n",
      "Action prob: [1.0000000e+00 2.6315927e-32], Action: 0, state: 9\n",
      "[1.00000e+00 2.43541e-35]\n",
      "Action prob: [1.00000e+00 2.43541e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 2.2477242e-36]\n",
      "Action prob: [1.0000000e+00 2.2477242e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1932576e-34]\n",
      "Action prob: [1.0000000e+00 1.1932576e-34], Action: 0, state: 9\n",
      "[1.000000e+00 6.621622e-27]\n",
      "Action prob: [1.000000e+00 6.621622e-27], Action: 0, state: 9\n",
      "[1.000000e+00 7.186782e-39]\n",
      "Action prob: [1.000000e+00 7.186782e-39], Action: 0, state: 9\n",
      "[1.0000000e+00 1.5204867e-35]\n",
      "Action prob: [1.0000000e+00 1.5204867e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 8.3154244e-27]\n",
      "Action prob: [1.0000000e+00 8.3154244e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 2.4045146e-26]\n",
      "Action prob: [1.0000000e+00 2.4045146e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3935444e-33]\n",
      "Action prob: [1.0000000e+00 1.3935444e-33], Action: 0, state: 9\n",
      "[1.000000e+00 6.422034e-35]\n",
      "Action prob: [1.000000e+00 6.422034e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 4.0371382e-27]\n",
      "Action prob: [1.0000000e+00 4.0371382e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.6477546e-28]\n",
      "Action prob: [1.0000000e+00 1.6477546e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 2.4212026e-33]\n",
      "Action prob: [1.0000000e+00 2.4212026e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7329238e-27]\n",
      "Action prob: [1.0000000e+00 1.7329238e-27], Action: 0, state: 9\n",
      "[1.000000e+00 8.087705e-27]\n",
      "Action prob: [1.000000e+00 8.087705e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1502506e-31]\n",
      "Action prob: [1.0000000e+00 1.1502506e-31], Action: 0, state: 9\n",
      "[1.000000e+00 1.896135e-35]\n",
      "Action prob: [1.000000e+00 1.896135e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 2.7356901e-34]\n",
      "Action prob: [1.0000000e+00 2.7356901e-34], Action: 0, state: 9\n",
      "[1.00000e+00 1.52074e-39]\n",
      "Action prob: [1.00000e+00 1.52074e-39], Action: 0, state: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 3.7054747e-36]\n",
      "Action prob: [1.0000000e+00 3.7054747e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 2.5224456e-36]\n",
      "Action prob: [1.0000000e+00 2.5224456e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 1.9767156e-26]\n",
      "Action prob: [1.0000000e+00 1.9767156e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2627279e-34]\n",
      "Action prob: [1.0000000e+00 1.2627279e-34], Action: 0, state: 9\n",
      "[1.00000e+00 5.04782e-32]\n",
      "Action prob: [1.00000e+00 5.04782e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 2.5896561e-33]\n",
      "Action prob: [1.0000000e+00 2.5896561e-33], Action: 0, state: 9\n",
      "[1.00000e+00 1.95064e-34]\n",
      "Action prob: [1.00000e+00 1.95064e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 3.0967418e-33]\n",
      "Action prob: [1.0000000e+00 3.0967418e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 2.9718497e-36]\n",
      "Action prob: [1.0000000e+00 2.9718497e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 5.0923877e-37]\n",
      "Action prob: [1.0000000e+00 5.0923877e-37], Action: 0, state: 9\n",
      "[1.000000e+00 5.637274e-30]\n",
      "Action prob: [1.000000e+00 5.637274e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 2.9633074e-33]\n",
      "Action prob: [1.0000000e+00 2.9633074e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 2.3392584e-31]\n",
      "Action prob: [1.0000000e+00 2.3392584e-31], Action: 0, state: 9\n",
      "[1.000000e+00 2.738641e-37]\n",
      "Action prob: [1.000000e+00 2.738641e-37], Action: 0, state: 9\n",
      "[1.0000000e+00 2.3444552e-33]\n",
      "Action prob: [1.0000000e+00 2.3444552e-33], Action: 0, state: 9\n",
      "[1.00000e+00 4.25552e-27]\n",
      "Action prob: [1.00000e+00 4.25552e-27], Action: 0, state: 9\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0., 0., 0., -0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -48000, loss is -0.0\n",
      "[1.0000000e+00 6.6275793e-29]\n",
      "Action prob: [1.0000000e+00 6.6275793e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 6.0203363e-30]\n",
      "Action prob: [1.0000000e+00 6.0203363e-30], Action: 0, state: 1\n",
      "[1.000000e+00 7.234128e-29]\n",
      "Action prob: [1.000000e+00 7.234128e-29], Action: 0, state: 2\n",
      "[1.00000e+00 7.57259e-32]\n",
      "Action prob: [1.00000e+00 7.57259e-32], Action: 0, state: 2\n",
      "[1.0000000e+00 2.8215795e-29]\n",
      "Action prob: [1.0000000e+00 2.8215795e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 1.0836114e-30]\n",
      "Action prob: [1.0000000e+00 1.0836114e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 3.9585675e-28]\n",
      "Action prob: [1.0000000e+00 3.9585675e-28], Action: 0, state: 2\n",
      "[1.000000e+00 3.748268e-28]\n",
      "Action prob: [1.000000e+00 3.748268e-28], Action: 0, state: 2\n",
      "[1.0000000e+00 2.5105306e-30]\n",
      "Action prob: [1.0000000e+00 2.5105306e-30], Action: 0, state: 2\n",
      "[1.000000e+00 6.290822e-31]\n",
      "Action prob: [1.000000e+00 6.290822e-31], Action: 0, state: 2\n",
      "[1.00000e+00 7.80416e-30]\n",
      "Action prob: [1.00000e+00 7.80416e-30], Action: 0, state: 3\n",
      "[1.000000e+00 1.405342e-26]\n",
      "Action prob: [1.000000e+00 1.405342e-26], Action: 0, state: 8\n",
      "[1.000000e+00 1.460015e-26]\n",
      "Action prob: [1.000000e+00 1.460015e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1916886e-26]\n",
      "Action prob: [1.0000000e+00 1.1916886e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2529333e-30]\n",
      "Action prob: [1.0000000e+00 4.2529333e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8025217e-32]\n",
      "Action prob: [1.0000000e+00 1.8025217e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6244841e-32]\n",
      "Action prob: [1.0000000e+00 1.6244841e-32], Action: 0, state: 8\n",
      "[1.000000e+00 4.255572e-33]\n",
      "Action prob: [1.000000e+00 4.255572e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5545688e-34]\n",
      "Action prob: [1.0000000e+00 1.5545688e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 6.8524053e-28]\n",
      "Action prob: [1.0000000e+00 6.8524053e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7934315e-27]\n",
      "Action prob: [1.0000000e+00 1.7934315e-27], Action: 0, state: 8\n",
      "[1.000000e+00 1.451645e-27]\n",
      "Action prob: [1.000000e+00 1.451645e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7881496e-36]\n",
      "Action prob: [1.0000000e+00 1.7881496e-36], Action: 0, state: 8\n",
      "[1.000000e+00 2.911505e-34]\n",
      "Action prob: [1.000000e+00 2.911505e-34], Action: 0, state: 8\n",
      "[1.000000e+00 8.490424e-30]\n",
      "Action prob: [1.000000e+00 8.490424e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3806968e-33]\n",
      "Action prob: [1.0000000e+00 1.3806968e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3531346e-33]\n",
      "Action prob: [1.0000000e+00 1.3531346e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3064173e-26]\n",
      "Action prob: [1.0000000e+00 2.3064173e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4212945e-34]\n",
      "Action prob: [1.0000000e+00 1.4212945e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4231561e-33]\n",
      "Action prob: [1.0000000e+00 1.4231561e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6585655e-27]\n",
      "Action prob: [1.0000000e+00 3.6585655e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1332473e-31]\n",
      "Action prob: [1.0000000e+00 1.1332473e-31], Action: 0, state: 8\n",
      "[1.000000e+00 8.787363e-27]\n",
      "Action prob: [1.000000e+00 8.787363e-27], Action: 0, state: 8\n",
      "[1.000000e+00 2.503437e-28]\n",
      "Action prob: [1.000000e+00 2.503437e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1997207e-34]\n",
      "Action prob: [1.0000000e+00 1.1997207e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8291243e-35]\n",
      "Action prob: [1.0000000e+00 1.8291243e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3055098e-38]\n",
      "Action prob: [1.0000000e+00 3.3055098e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0999555e-27]\n",
      "Action prob: [1.0000000e+00 1.0999555e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 9.6088506e-36]\n",
      "Action prob: [1.0000000e+00 9.6088506e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0041654e-25]\n",
      "Action prob: [1.0000000e+00 1.0041654e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3429973e-26]\n",
      "Action prob: [1.0000000e+00 2.3429973e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9733692e-36]\n",
      "Action prob: [1.0000000e+00 2.9733692e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 6.5860756e-35]\n",
      "Action prob: [1.0000000e+00 6.5860756e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6590956e-35]\n",
      "Action prob: [1.0000000e+00 1.6590956e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0368534e-31]\n",
      "Action prob: [1.0000000e+00 2.0368534e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8382476e-33]\n",
      "Action prob: [1.0000000e+00 1.8382476e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5522948e-32]\n",
      "Action prob: [1.0000000e+00 1.5522948e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2120078e-33]\n",
      "Action prob: [1.0000000e+00 1.2120078e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0469525e-27]\n",
      "Action prob: [1.0000000e+00 2.0469525e-27], Action: 0, state: 8\n",
      "[1.0000e+00 2.6569e-41]\n",
      "Action prob: [1.0000e+00 2.6569e-41], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -112200, loss is -0.0\n",
      "[1.0000000e+00 2.1674843e-30]\n",
      "Action prob: [1.0000000e+00 2.1674843e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 2.3520718e-31]\n",
      "Action prob: [1.0000000e+00 2.3520718e-31], Action: 0, state: 0\n",
      "[1.000000e+00 5.995427e-29]\n",
      "Action prob: [1.000000e+00 5.995427e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 5.2976536e-28]\n",
      "Action prob: [1.0000000e+00 5.2976536e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 1.5503282e-27]\n",
      "Action prob: [1.0000000e+00 1.5503282e-27], Action: 0, state: 0\n",
      "[1.000000e+00 1.089813e-30]\n",
      "Action prob: [1.000000e+00 1.089813e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 2.5350128e-30]\n",
      "Action prob: [1.0000000e+00 2.5350128e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.1460034e-29]\n",
      "Action prob: [1.0000000e+00 1.1460034e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 3.4070336e-29]\n",
      "Action prob: [1.0000000e+00 3.4070336e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.7824342e-30]\n",
      "Action prob: [1.0000000e+00 1.7824342e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 2.9422724e-29]\n",
      "Action prob: [1.0000000e+00 2.9422724e-29], Action: 0, state: 2\n",
      "[1.000000e+00 1.720833e-30]\n",
      "Action prob: [1.000000e+00 1.720833e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 2.9810004e-29]\n",
      "Action prob: [1.0000000e+00 2.9810004e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 1.4923685e-29]\n",
      "Action prob: [1.0000000e+00 1.4923685e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 6.3178116e-29]\n",
      "Action prob: [1.0000000e+00 6.3178116e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 2.5486737e-31]\n",
      "Action prob: [1.0000000e+00 2.5486737e-31], Action: 0, state: 2\n",
      "[1.000000e+00 8.977866e-32]\n",
      "Action prob: [1.000000e+00 8.977866e-32], Action: 0, state: 3\n",
      "[1.000e+00 2.293e-42]\n",
      "Action prob: [1.000e+00 2.293e-42], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2483455e-26]\n",
      "Action prob: [1.0000000e+00 1.2483455e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2962111e-37]\n",
      "Action prob: [1.0000000e+00 1.2962111e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 7.7659774e-28]\n",
      "Action prob: [1.0000000e+00 7.7659774e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9597028e-33]\n",
      "Action prob: [1.0000000e+00 1.9597028e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1691517e-34]\n",
      "Action prob: [1.0000000e+00 1.1691517e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0333833e-35]\n",
      "Action prob: [1.0000000e+00 1.0333833e-35], Action: 0, state: 8\n",
      "[1.00000e+00 3.19309e-35]\n",
      "Action prob: [1.00000e+00 3.19309e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3227678e-33]\n",
      "Action prob: [1.0000000e+00 1.3227678e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4755191e-33]\n",
      "Action prob: [1.0000000e+00 1.4755191e-33], Action: 0, state: 8\n",
      "[1.000000e+00 9.874636e-32]\n",
      "Action prob: [1.000000e+00 9.874636e-32], Action: 0, state: 8\n",
      "[1.000000e+00 5.374969e-27]\n",
      "Action prob: [1.000000e+00 5.374969e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3542298e-28]\n",
      "Action prob: [1.0000000e+00 2.3542298e-28], Action: 0, state: 8\n",
      "[1.000000e+00 5.778548e-26]\n",
      "Action prob: [1.000000e+00 5.778548e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9683643e-33]\n",
      "Action prob: [1.0000000e+00 4.9683643e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2792963e-32]\n",
      "Action prob: [1.0000000e+00 2.2792963e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4071981e-26]\n",
      "Action prob: [1.0000000e+00 1.4071981e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7096832e-34]\n",
      "Action prob: [1.0000000e+00 2.7096832e-34], Action: 0, state: 8\n",
      "[1.000000e+00 6.300305e-32]\n",
      "Action prob: [1.000000e+00 6.300305e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5625884e-35]\n",
      "Action prob: [1.0000000e+00 1.5625884e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7399191e-34]\n",
      "Action prob: [1.0000000e+00 1.7399191e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7788849e-34]\n",
      "Action prob: [1.0000000e+00 1.7788849e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1952072e-27]\n",
      "Action prob: [1.0000000e+00 1.1952072e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.630661e-35]\n",
      "Action prob: [1.000000e+00 7.630661e-35], Action: 0, state: 8\n",
      "[1.00000e+00 7.28765e-34]\n",
      "Action prob: [1.00000e+00 7.28765e-34], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 1.215684e-26]\n",
      "Action prob: [1.000000e+00 1.215684e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 6.5019283e-34]\n",
      "Action prob: [1.0000000e+00 6.5019283e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 6.6834414e-27]\n",
      "Action prob: [1.0000000e+00 6.6834414e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 6.9930585e-33]\n",
      "Action prob: [1.0000000e+00 6.9930585e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5866819e-34]\n",
      "Action prob: [1.0000000e+00 1.5866819e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3751254e-32]\n",
      "Action prob: [1.0000000e+00 2.3751254e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4287484e-33]\n",
      "Action prob: [1.0000000e+00 3.4287484e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9354264e-38]\n",
      "Action prob: [1.0000000e+00 4.9354264e-38], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -88200, loss is -0.0\n",
      "[1.0000000e+00 5.4386716e-30]\n",
      "Action prob: [1.0000000e+00 5.4386716e-30], Action: 0, state: 0\n",
      "[1.00000e+00 2.32927e-29]\n",
      "Action prob: [1.00000e+00 2.32927e-29], Action: 0, state: 1\n",
      "[1.000000e+00 1.964422e-29]\n",
      "Action prob: [1.000000e+00 1.964422e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 4.7566267e-32]\n",
      "Action prob: [1.0000000e+00 4.7566267e-32], Action: 0, state: 3\n",
      "[1.0000000e+00 1.8270281e-32]\n",
      "Action prob: [1.0000000e+00 1.8270281e-32], Action: 0, state: 3\n",
      "[1.000000e+00 5.697989e-28]\n",
      "Action prob: [1.000000e+00 5.697989e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0878033e-34]\n",
      "Action prob: [1.0000000e+00 2.0878033e-34], Action: 0, state: 8\n",
      "[1.000000e+00 3.162439e-39]\n",
      "Action prob: [1.000000e+00 3.162439e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9278552e-34]\n",
      "Action prob: [1.0000000e+00 2.9278552e-34], Action: 0, state: 8\n",
      "[1.000000e+00 6.023427e-26]\n",
      "Action prob: [1.000000e+00 6.023427e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3856824e-34]\n",
      "Action prob: [1.0000000e+00 1.3856824e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 5.5131295e-26]\n",
      "Action prob: [1.0000000e+00 5.5131295e-26], Action: 0, state: 8\n",
      "[1.000000e+00 2.319218e-27]\n",
      "Action prob: [1.000000e+00 2.319218e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3453843e-34]\n",
      "Action prob: [1.0000000e+00 4.3453843e-34], Action: 0, state: 8\n",
      "[1.00000e+00 1.74336e-27]\n",
      "Action prob: [1.00000e+00 1.74336e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.791608e-28]\n",
      "Action prob: [1.000000e+00 9.791608e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1184028e-35]\n",
      "Action prob: [1.0000000e+00 1.1184028e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1639794e-34]\n",
      "Action prob: [1.0000000e+00 3.1639794e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6077352e-35]\n",
      "Action prob: [1.0000000e+00 2.6077352e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0453616e-34]\n",
      "Action prob: [1.0000000e+00 1.0453616e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2392122e-33]\n",
      "Action prob: [1.0000000e+00 2.2392122e-33], Action: 0, state: 8\n",
      "[1.000000e+00 3.369507e-32]\n",
      "Action prob: [1.000000e+00 3.369507e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4791822e-37]\n",
      "Action prob: [1.0000000e+00 2.4791822e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5729165e-33]\n",
      "Action prob: [1.0000000e+00 2.5729165e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4333708e-27]\n",
      "Action prob: [1.0000000e+00 1.4333708e-27], Action: 0, state: 8\n",
      "[1.0000e+00 3.6037e-27]\n",
      "Action prob: [1.0000e+00 3.6037e-27], Action: 0, state: 8\n",
      "[1.000000e+00 2.195277e-30]\n",
      "Action prob: [1.000000e+00 2.195277e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0441341e-34]\n",
      "Action prob: [1.0000000e+00 1.0441341e-34], Action: 0, state: 8\n",
      "[1.000000e+00 1.674975e-27]\n",
      "Action prob: [1.000000e+00 1.674975e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.225422e-34]\n",
      "Action prob: [1.000000e+00 7.225422e-34], Action: 0, state: 8\n",
      "[1.000000e+00 5.934046e-34]\n",
      "Action prob: [1.000000e+00 5.934046e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0148501e-28]\n",
      "Action prob: [1.0000000e+00 1.0148501e-28], Action: 0, state: 8\n",
      "[1.000000e+00 6.326405e-34]\n",
      "Action prob: [1.000000e+00 6.326405e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.804238e-33]\n",
      "Action prob: [1.000000e+00 7.804238e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2576044e-30]\n",
      "Action prob: [1.0000000e+00 3.2576044e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0268032e-35]\n",
      "Action prob: [1.0000000e+00 3.0268032e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 8.1271415e-26]\n",
      "Action prob: [1.0000000e+00 8.1271415e-26], Action: 0, state: 8\n",
      "[1.0000e+00 6.5834e-41]\n",
      "Action prob: [1.0000e+00 6.5834e-41], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0672116e-28]\n",
      "Action prob: [1.0000000e+00 1.0672116e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0473914e-34]\n",
      "Action prob: [1.0000000e+00 5.0473914e-34], Action: 0, state: 8\n",
      "[1.000000e+00 2.120443e-30]\n",
      "Action prob: [1.000000e+00 2.120443e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2342191e-27]\n",
      "Action prob: [1.0000000e+00 2.2342191e-27], Action: 0, state: 8\n",
      "[1.000000e+00 2.726832e-28]\n",
      "Action prob: [1.000000e+00 2.726832e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3847725e-35]\n",
      "Action prob: [1.0000000e+00 2.3847725e-35], Action: 0, state: 8\n",
      "[1.000000e+00 6.380187e-33]\n",
      "Action prob: [1.000000e+00 6.380187e-33], Action: 0, state: 8\n",
      "[1.00000e+00 3.43867e-40]\n",
      "Action prob: [1.00000e+00 3.43867e-40], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1461322e-33]\n",
      "Action prob: [1.0000000e+00 1.1461322e-33], Action: 0, state: 8\n",
      "[1.000000e+00 4.914421e-31]\n",
      "Action prob: [1.000000e+00 4.914421e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1079474e-34]\n",
      "Action prob: [1.0000000e+00 3.1079474e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0741104e-26]\n",
      "Action prob: [1.0000000e+00 2.0741104e-26], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0., 0., 0., -0., -0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -135300, loss is -0.0\n",
      "[1.0000000e+00 3.2179364e-28]\n",
      "Action prob: [1.0000000e+00 3.2179364e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 6.8773515e-31]\n",
      "Action prob: [1.0000000e+00 6.8773515e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 2.2115425e-29]\n",
      "Action prob: [1.0000000e+00 2.2115425e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 2.8044624e-30]\n",
      "Action prob: [1.0000000e+00 2.8044624e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 3.2881544e-38]\n",
      "Action prob: [1.0000000e+00 3.2881544e-38], Action: 0, state: 3\n",
      "[1.0000000e+00 1.0447477e-34]\n",
      "Action prob: [1.0000000e+00 1.0447477e-34], Action: 0, state: 8\n",
      "[1.000000e+00 2.834087e-33]\n",
      "Action prob: [1.000000e+00 2.834087e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2222492e-27]\n",
      "Action prob: [1.0000000e+00 1.2222492e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5603909e-27]\n",
      "Action prob: [1.0000000e+00 1.5603909e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.6479394e-35]\n",
      "Action prob: [1.0000000e+00 4.6479394e-35], Action: 0, state: 8\n",
      "[1.000000e+00 1.178766e-35]\n",
      "Action prob: [1.000000e+00 1.178766e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4152627e-26]\n",
      "Action prob: [1.0000000e+00 3.4152627e-26], Action: 0, state: 8\n",
      "[1.000000e+00 1.441532e-32]\n",
      "Action prob: [1.000000e+00 1.441532e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4765354e-37]\n",
      "Action prob: [1.0000000e+00 2.4765354e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3071466e-27]\n",
      "Action prob: [1.0000000e+00 2.3071466e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7399186e-35]\n",
      "Action prob: [1.0000000e+00 2.7399186e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0163057e-30]\n",
      "Action prob: [1.0000000e+00 5.0163057e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2161597e-34]\n",
      "Action prob: [1.0000000e+00 3.2161597e-34], Action: 0, state: 8\n",
      "[1.000000e+00 6.658858e-27]\n",
      "Action prob: [1.000000e+00 6.658858e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 9.6647725e-27]\n",
      "Action prob: [1.0000000e+00 9.6647725e-27], Action: 0, state: 8\n",
      "[1.000000e+00 2.279112e-26]\n",
      "Action prob: [1.000000e+00 2.279112e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9900758e-30]\n",
      "Action prob: [1.0000000e+00 2.9900758e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5268218e-28]\n",
      "Action prob: [1.0000000e+00 1.5268218e-28], Action: 0, state: 8\n",
      "[1.000000e+00 6.170714e-34]\n",
      "Action prob: [1.000000e+00 6.170714e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1763185e-34]\n",
      "Action prob: [1.0000000e+00 1.1763185e-34], Action: 0, state: 8\n",
      "[1.000000e+00 1.321058e-26]\n",
      "Action prob: [1.000000e+00 1.321058e-26], Action: 0, state: 8\n",
      "[1.000000e+00 8.459009e-28]\n",
      "Action prob: [1.000000e+00 8.459009e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7498658e-35]\n",
      "Action prob: [1.0000000e+00 2.7498658e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9585498e-27]\n",
      "Action prob: [1.0000000e+00 2.9585498e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3043603e-31]\n",
      "Action prob: [1.0000000e+00 4.3043603e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 8.3951936e-29]\n",
      "Action prob: [1.0000000e+00 8.3951936e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0288169e-27]\n",
      "Action prob: [1.0000000e+00 1.0288169e-27], Action: 0, state: 8\n",
      "[1.000000e+00 1.812739e-34]\n",
      "Action prob: [1.000000e+00 1.812739e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1082742e-34]\n",
      "Action prob: [1.0000000e+00 1.1082742e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6889694e-26]\n",
      "Action prob: [1.0000000e+00 1.6889694e-26], Action: 0, state: 8\n",
      "[1.000000e+00 8.144364e-34]\n",
      "Action prob: [1.000000e+00 8.144364e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8944069e-34]\n",
      "Action prob: [1.0000000e+00 2.8944069e-34], Action: 0, state: 8\n",
      "[1.e+00 7.e-44]\n",
      "Action prob: [1.e+00 7.e-44], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9333499e-26]\n",
      "Action prob: [1.0000000e+00 1.9333499e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6872696e-37]\n",
      "Action prob: [1.0000000e+00 2.6872696e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2945763e-27]\n",
      "Action prob: [1.0000000e+00 3.2945763e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.275109e-35]\n",
      "Action prob: [1.000000e+00 9.275109e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 7.3569047e-31]\n",
      "Action prob: [1.0000000e+00 7.3569047e-31], Action: 0, state: 8\n",
      "[1.000000e+00 1.725068e-35]\n",
      "Action prob: [1.000000e+00 1.725068e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.1352303e-28]\n",
      "Action prob: [1.0000000e+00 5.1352303e-28], Action: 0, state: 8\n",
      "[1.000e+00 1.921e-42]\n",
      "Action prob: [1.000e+00 1.921e-42], Action: 0, state: 8\n",
      "[1.0000000e+00 6.1680497e-28]\n",
      "Action prob: [1.0000000e+00 6.1680497e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7619534e-27]\n",
      "Action prob: [1.0000000e+00 1.7619534e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3558408e-35]\n",
      "Action prob: [1.0000000e+00 1.3558408e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9290393e-34]\n",
      "Action prob: [1.0000000e+00 4.9290393e-34], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -134900, loss is -0.0\n",
      "[1.0000000e+00 3.1176907e-30]\n",
      "Action prob: [1.0000000e+00 3.1176907e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 4.2776977e-30]\n",
      "Action prob: [1.0000000e+00 4.2776977e-30], Action: 0, state: 0\n",
      "[1.000000e+00 1.492972e-29]\n",
      "Action prob: [1.000000e+00 1.492972e-29], Action: 0, state: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 1.9191735e-28]\n",
      "Action prob: [1.0000000e+00 1.9191735e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 3.6503923e-29]\n",
      "Action prob: [1.0000000e+00 3.6503923e-29], Action: 0, state: 1\n",
      "[1.000000e+00 8.893166e-31]\n",
      "Action prob: [1.000000e+00 8.893166e-31], Action: 0, state: 1\n",
      "[1.000000e+00 3.831391e-29]\n",
      "Action prob: [1.000000e+00 3.831391e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 1.8680545e-29]\n",
      "Action prob: [1.0000000e+00 1.8680545e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 3.6047823e-29]\n",
      "Action prob: [1.0000000e+00 3.6047823e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 2.2168615e-31]\n",
      "Action prob: [1.0000000e+00 2.2168615e-31], Action: 0, state: 3\n",
      "[1.000000e+00 3.983469e-29]\n",
      "Action prob: [1.000000e+00 3.983469e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.2248879e-32]\n",
      "Action prob: [1.0000000e+00 1.2248879e-32], Action: 0, state: 3\n",
      "[1.0000000e+00 9.2057664e-29]\n",
      "Action prob: [1.0000000e+00 9.2057664e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.2908845e-33]\n",
      "Action prob: [1.0000000e+00 1.2908845e-33], Action: 0, state: 3\n",
      "[1.000000e+00 3.006628e-29]\n",
      "Action prob: [1.000000e+00 3.006628e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.9169848e-29]\n",
      "Action prob: [1.0000000e+00 1.9169848e-29], Action: 0, state: 3\n",
      "[1.000000e+00 6.252236e-30]\n",
      "Action prob: [1.000000e+00 6.252236e-30], Action: 0, state: 3\n",
      "[1.0e+00 2.7e-42]\n",
      "Action prob: [1.0e+00 2.7e-42], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1918425e-26]\n",
      "Action prob: [1.0000000e+00 2.1918425e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 6.1946766e-34]\n",
      "Action prob: [1.0000000e+00 6.1946766e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0765107e-27]\n",
      "Action prob: [1.0000000e+00 3.0765107e-27], Action: 0, state: 8\n",
      "[1.000000e+00 1.328347e-39]\n",
      "Action prob: [1.000000e+00 1.328347e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7467485e-27]\n",
      "Action prob: [1.0000000e+00 1.7467485e-27], Action: 0, state: 8\n",
      "[1.000000e+00 4.506637e-36]\n",
      "Action prob: [1.000000e+00 4.506637e-36], Action: 0, state: 8\n",
      "[1.000000e+00 2.571159e-34]\n",
      "Action prob: [1.000000e+00 2.571159e-34], Action: 0, state: 8\n",
      "[1.0000e+00 5.3899e-33]\n",
      "Action prob: [1.0000e+00 5.3899e-33], Action: 0, state: 8\n",
      "[1.00000e+00 6.03016e-27]\n",
      "Action prob: [1.00000e+00 6.03016e-27], Action: 0, state: 8\n",
      "[1.0000e+00 4.0834e-41]\n",
      "Action prob: [1.0000e+00 4.0834e-41], Action: 0, state: 8\n",
      "[1.000000e+00 4.249719e-39]\n",
      "Action prob: [1.000000e+00 4.249719e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2434963e-28]\n",
      "Action prob: [1.0000000e+00 1.2434963e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5747103e-37]\n",
      "Action prob: [1.0000000e+00 1.5747103e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 6.9561527e-34]\n",
      "Action prob: [1.0000000e+00 6.9561527e-34], Action: 0, state: 8\n",
      "[1.000000e+00 3.265186e-27]\n",
      "Action prob: [1.000000e+00 3.265186e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0177192e-27]\n",
      "Action prob: [1.0000000e+00 3.0177192e-27], Action: 0, state: 8\n",
      "[1.000000e+00 2.740746e-34]\n",
      "Action prob: [1.000000e+00 2.740746e-34], Action: 0, state: 8\n",
      "[1.000000e+00 2.974633e-33]\n",
      "Action prob: [1.000000e+00 2.974633e-33], Action: 0, state: 8\n",
      "[1.000000e+00 7.063179e-37]\n",
      "Action prob: [1.000000e+00 7.063179e-37], Action: 0, state: 8\n",
      "[1.000000e+00 7.124348e-26]\n",
      "Action prob: [1.000000e+00 7.124348e-26], Action: 0, state: 8\n",
      "[1.000000e+00 6.408483e-33]\n",
      "Action prob: [1.000000e+00 6.408483e-33], Action: 0, state: 8\n",
      "[1.000000e+00 1.881476e-39]\n",
      "Action prob: [1.000000e+00 1.881476e-39], Action: 0, state: 8\n",
      "[1.000000e+00 5.044195e-27]\n",
      "Action prob: [1.000000e+00 5.044195e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2345582e-36]\n",
      "Action prob: [1.0000000e+00 1.2345582e-36], Action: 0, state: 8\n",
      "[1.000000e+00 8.343821e-37]\n",
      "Action prob: [1.000000e+00 8.343821e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1312927e-35]\n",
      "Action prob: [1.0000000e+00 1.1312927e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0104798e-38]\n",
      "Action prob: [1.0000000e+00 1.0104798e-38], Action: 0, state: 8\n",
      "[1.000000e+00 1.339179e-38]\n",
      "Action prob: [1.000000e+00 1.339179e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9414037e-32]\n",
      "Action prob: [1.0000000e+00 2.9414037e-32], Action: 0, state: 8\n",
      "[1.000000e+00 5.333466e-27]\n",
      "Action prob: [1.000000e+00 5.333466e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1510246e-36]\n",
      "Action prob: [1.0000000e+00 1.1510246e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3608057e-26]\n",
      "Action prob: [1.0000000e+00 1.3608057e-26], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -91300, loss is -0.0\n",
      "[1.0000000e+00 2.6686474e-29]\n",
      "Action prob: [1.0000000e+00 2.6686474e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 2.7248135e-29]\n",
      "Action prob: [1.0000000e+00 2.7248135e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 5.7862564e-30]\n",
      "Action prob: [1.0000000e+00 5.7862564e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 8.9787945e-31]\n",
      "Action prob: [1.0000000e+00 8.9787945e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 5.6262986e-29]\n",
      "Action prob: [1.0000000e+00 5.6262986e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 4.4018848e-30]\n",
      "Action prob: [1.0000000e+00 4.4018848e-30], Action: 0, state: 2\n",
      "[1.000000e+00 9.321239e-31]\n",
      "Action prob: [1.000000e+00 9.321239e-31], Action: 0, state: 3\n",
      "[1.00000e+00 2.87419e-30]\n",
      "Action prob: [1.00000e+00 2.87419e-30], Action: 0, state: 3\n",
      "[1.000000e+00 6.132116e-33]\n",
      "Action prob: [1.000000e+00 6.132116e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9014946e-28]\n",
      "Action prob: [1.0000000e+00 1.9014946e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6119456e-26]\n",
      "Action prob: [1.0000000e+00 1.6119456e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 6.6259686e-27]\n",
      "Action prob: [1.0000000e+00 6.6259686e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1380362e-29]\n",
      "Action prob: [1.0000000e+00 3.1380362e-29], Action: 0, state: 8\n",
      "[1.000000e+00 3.822166e-36]\n",
      "Action prob: [1.000000e+00 3.822166e-36], Action: 0, state: 8\n",
      "[1.000000e+00 8.001504e-27]\n",
      "Action prob: [1.000000e+00 8.001504e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6474626e-24]\n",
      "Action prob: [1.0000000e+00 1.6474626e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6610997e-24]\n",
      "Action prob: [1.0000000e+00 1.6610997e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6329866e-26]\n",
      "Action prob: [1.0000000e+00 2.6329866e-26], Action: 0, state: 8\n",
      "[1.000000e+00 6.788069e-27]\n",
      "Action prob: [1.000000e+00 6.788069e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.7098064e-34]\n",
      "Action prob: [1.0000000e+00 3.7098064e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0382024e-30]\n",
      "Action prob: [1.0000000e+00 1.0382024e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0752258e-34]\n",
      "Action prob: [1.0000000e+00 2.0752258e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0022919e-33]\n",
      "Action prob: [1.0000000e+00 2.0022919e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5233037e-26]\n",
      "Action prob: [1.0000000e+00 1.5233037e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0861975e-31]\n",
      "Action prob: [1.0000000e+00 1.0861975e-31], Action: 0, state: 8\n",
      "[1.00000e+00 6.78318e-26]\n",
      "Action prob: [1.00000e+00 6.78318e-26], Action: 0, state: 8\n",
      "[1.000000e+00 5.433109e-32]\n",
      "Action prob: [1.000000e+00 5.433109e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6836568e-27]\n",
      "Action prob: [1.0000000e+00 2.6836568e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8769898e-33]\n",
      "Action prob: [1.0000000e+00 3.8769898e-33], Action: 0, state: 8\n",
      "[1.000000e+00 4.808361e-34]\n",
      "Action prob: [1.000000e+00 4.808361e-34], Action: 0, state: 8\n",
      "[1.000000e+00 9.241033e-34]\n",
      "Action prob: [1.000000e+00 9.241033e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6859869e-36]\n",
      "Action prob: [1.0000000e+00 1.6859869e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6332684e-33]\n",
      "Action prob: [1.0000000e+00 2.6332684e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9955261e-27]\n",
      "Action prob: [1.0000000e+00 2.9955261e-27], Action: 0, state: 8\n",
      "[1.000000e+00 1.664975e-39]\n",
      "Action prob: [1.000000e+00 1.664975e-39], Action: 0, state: 8\n",
      "[1.000000e+00 2.566749e-34]\n",
      "Action prob: [1.000000e+00 2.566749e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1727968e-32]\n",
      "Action prob: [1.0000000e+00 2.1727968e-32], Action: 0, state: 8\n",
      "[1.000000e+00 3.494791e-39]\n",
      "Action prob: [1.000000e+00 3.494791e-39], Action: 0, state: 8\n",
      "[1.000000e+00 7.238578e-35]\n",
      "Action prob: [1.000000e+00 7.238578e-35], Action: 0, state: 8\n",
      "[1.000000e+00 3.934393e-34]\n",
      "Action prob: [1.000000e+00 3.934393e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7022208e-26]\n",
      "Action prob: [1.0000000e+00 2.7022208e-26], Action: 0, state: 8\n",
      "[1.000000e+00 6.009928e-27]\n",
      "Action prob: [1.000000e+00 6.009928e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9120167e-31]\n",
      "Action prob: [1.0000000e+00 1.9120167e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1045814e-26]\n",
      "Action prob: [1.0000000e+00 1.1045814e-26], Action: 0, state: 8\n",
      "[1.000000e+00 7.809616e-36]\n",
      "Action prob: [1.000000e+00 7.809616e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2158033e-28]\n",
      "Action prob: [1.0000000e+00 1.2158033e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1938097e-27]\n",
      "Action prob: [1.0000000e+00 3.1938097e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3678218e-33]\n",
      "Action prob: [1.0000000e+00 3.3678218e-33], Action: 0, state: 8\n",
      "[1.000000e+00 6.736655e-35]\n",
      "Action prob: [1.000000e+00 6.736655e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7488248e-27]\n",
      "Action prob: [1.0000000e+00 4.7488248e-27], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0.,\n",
      "        0., -0., 0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -123600, loss is -0.0\n",
      "[1.0000000e+00 1.3629701e-29]\n",
      "Action prob: [1.0000000e+00 1.3629701e-29], Action: 0, state: 0\n",
      "[1.000000e+00 4.720356e-29]\n",
      "Action prob: [1.000000e+00 4.720356e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 4.5192225e-28]\n",
      "Action prob: [1.0000000e+00 4.5192225e-28], Action: 0, state: 1\n",
      "[1.00000000e+00 1.14378474e-29]\n",
      "Action prob: [1.00000000e+00 1.14378474e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 1.2806459e-29]\n",
      "Action prob: [1.0000000e+00 1.2806459e-29], Action: 0, state: 2\n",
      "[1.000000e+00 1.519489e-28]\n",
      "Action prob: [1.000000e+00 1.519489e-28], Action: 0, state: 2\n",
      "[1.000000e+00 2.343216e-30]\n",
      "Action prob: [1.000000e+00 2.343216e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 7.2817977e-31]\n",
      "Action prob: [1.0000000e+00 7.2817977e-31], Action: 0, state: 2\n",
      "[1.000000e+00 9.035458e-30]\n",
      "Action prob: [1.000000e+00 9.035458e-30], Action: 0, state: 3\n",
      "[1.000000e+00 3.580666e-34]\n",
      "Action prob: [1.000000e+00 3.580666e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7593371e-31]\n",
      "Action prob: [1.0000000e+00 1.7593371e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5978514e-31]\n",
      "Action prob: [1.0000000e+00 2.5978514e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 6.8615077e-28]\n",
      "Action prob: [1.0000000e+00 6.8615077e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5067747e-26]\n",
      "Action prob: [1.0000000e+00 2.5067747e-26], Action: 0, state: 8\n",
      "[1.000000e+00 2.509631e-37]\n",
      "Action prob: [1.000000e+00 2.509631e-37], Action: 0, state: 8\n",
      "[1.000000e+00 8.398565e-27]\n",
      "Action prob: [1.000000e+00 8.398565e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2211345e-33]\n",
      "Action prob: [1.0000000e+00 4.2211345e-33], Action: 0, state: 8\n",
      "[1.000000e+00 7.985714e-33]\n",
      "Action prob: [1.000000e+00 7.985714e-33], Action: 0, state: 8\n",
      "[1.000000e+00 3.707458e-34]\n",
      "Action prob: [1.000000e+00 3.707458e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6182793e-26]\n",
      "Action prob: [1.0000000e+00 1.6182793e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3371062e-28]\n",
      "Action prob: [1.0000000e+00 5.3371062e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5216786e-32]\n",
      "Action prob: [1.0000000e+00 1.5216786e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 4.4983625e-34]\n",
      "Action prob: [1.0000000e+00 4.4983625e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 5.5669294e-28]\n",
      "Action prob: [1.0000000e+00 5.5669294e-28], Action: 0, state: 8\n",
      "[1.000000e+00 8.161343e-27]\n",
      "Action prob: [1.000000e+00 8.161343e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3134156e-33]\n",
      "Action prob: [1.0000000e+00 1.3134156e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3602607e-26]\n",
      "Action prob: [1.0000000e+00 1.3602607e-26], Action: 0, state: 8\n",
      "[1.00000000e+00 1.16380435e-32]\n",
      "Action prob: [1.00000000e+00 1.16380435e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0905837e-35]\n",
      "Action prob: [1.0000000e+00 2.0905837e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9835137e-26]\n",
      "Action prob: [1.0000000e+00 1.9835137e-26], Action: 0, state: 8\n",
      "[1.00000000e+00 1.20747206e-32]\n",
      "Action prob: [1.00000000e+00 1.20747206e-32], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 6.434715e-34]\n",
      "Action prob: [1.000000e+00 6.434715e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0005286e-27]\n",
      "Action prob: [1.0000000e+00 4.0005286e-27], Action: 0, state: 8\n",
      "[1.000000e+00 4.414757e-34]\n",
      "Action prob: [1.000000e+00 4.414757e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0871452e-34]\n",
      "Action prob: [1.0000000e+00 1.0871452e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3130662e-31]\n",
      "Action prob: [1.0000000e+00 1.3130662e-31], Action: 0, state: 8\n",
      "[1.000000e+00 4.033061e-26]\n",
      "Action prob: [1.000000e+00 4.033061e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9173968e-27]\n",
      "Action prob: [1.0000000e+00 2.9173968e-27], Action: 0, state: 8\n",
      "[1.000000e+00 2.947299e-33]\n",
      "Action prob: [1.000000e+00 2.947299e-33], Action: 0, state: 8\n",
      "[1.000000e+00 3.405632e-28]\n",
      "Action prob: [1.000000e+00 3.405632e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6572612e-35]\n",
      "Action prob: [1.0000000e+00 1.6572612e-35], Action: 0, state: 8\n",
      "[1.00000e+00 4.93758e-28]\n",
      "Action prob: [1.00000e+00 4.93758e-28], Action: 0, state: 8\n",
      "[1.0000e+00 9.4372e-41]\n",
      "Action prob: [1.0000e+00 9.4372e-41], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2045421e-31]\n",
      "Action prob: [1.0000000e+00 1.2045421e-31], Action: 0, state: 8\n",
      "[1.000000e+00 4.284839e-28]\n",
      "Action prob: [1.000000e+00 4.284839e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9445807e-27]\n",
      "Action prob: [1.0000000e+00 3.9445807e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2202311e-36]\n",
      "Action prob: [1.0000000e+00 1.2202311e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0402243e-32]\n",
      "Action prob: [1.0000000e+00 4.0402243e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2609768e-28]\n",
      "Action prob: [1.0000000e+00 2.2609768e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1940591e-34]\n",
      "Action prob: [1.0000000e+00 1.1940591e-34], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -119600, loss is -0.0\n",
      "[1.0000000e+00 1.0211615e-34]\n",
      "Action prob: [1.0000000e+00 1.0211615e-34], Action: 0, state: 0\n",
      "[1.0000000e+00 4.4077847e-29]\n",
      "Action prob: [1.0000000e+00 4.4077847e-29], Action: 0, state: 0\n",
      "[1.000000e+00 9.086783e-31]\n",
      "Action prob: [1.000000e+00 9.086783e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 2.9475747e-29]\n",
      "Action prob: [1.0000000e+00 2.9475747e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 4.3452937e-30]\n",
      "Action prob: [1.0000000e+00 4.3452937e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 4.7939225e-29]\n",
      "Action prob: [1.0000000e+00 4.7939225e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 5.2323773e-29]\n",
      "Action prob: [1.0000000e+00 5.2323773e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 2.0458174e-30]\n",
      "Action prob: [1.0000000e+00 2.0458174e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.5602977e-32]\n",
      "Action prob: [1.0000000e+00 1.5602977e-32], Action: 0, state: 1\n",
      "[1.0000000e+00 1.0483634e-29]\n",
      "Action prob: [1.0000000e+00 1.0483634e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.2301471e-31]\n",
      "Action prob: [1.0000000e+00 1.2301471e-31], Action: 0, state: 2\n",
      "[1.0000000e+00 9.1921507e-29]\n",
      "Action prob: [1.0000000e+00 9.1921507e-29], Action: 0, state: 3\n",
      "[1.000000e+00 3.653223e-35]\n",
      "Action prob: [1.000000e+00 3.653223e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2908296e-34]\n",
      "Action prob: [1.0000000e+00 1.2908296e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0040947e-36]\n",
      "Action prob: [1.0000000e+00 1.0040947e-36], Action: 0, state: 8\n",
      "[1.0000e+00 9.9637e-41]\n",
      "Action prob: [1.0000e+00 9.9637e-41], Action: 0, state: 8\n",
      "[1.000000e+00 9.372172e-27]\n",
      "Action prob: [1.000000e+00 9.372172e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8927063e-27]\n",
      "Action prob: [1.0000000e+00 2.8927063e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 9.3843315e-28]\n",
      "Action prob: [1.0000000e+00 9.3843315e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3286255e-33]\n",
      "Action prob: [1.0000000e+00 2.3286255e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5823006e-33]\n",
      "Action prob: [1.0000000e+00 1.5823006e-33], Action: 0, state: 8\n",
      "[1.000000e+00 6.343411e-36]\n",
      "Action prob: [1.000000e+00 6.343411e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6053574e-36]\n",
      "Action prob: [1.0000000e+00 2.6053574e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6000352e-27]\n",
      "Action prob: [1.0000000e+00 1.6000352e-27], Action: 0, state: 8\n",
      "[1.00000e+00 6.51969e-33]\n",
      "Action prob: [1.00000e+00 6.51969e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.7148234e-32]\n",
      "Action prob: [1.0000000e+00 3.7148234e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 4.4186993e-34]\n",
      "Action prob: [1.0000000e+00 4.4186993e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1206971e-27]\n",
      "Action prob: [1.0000000e+00 2.1206971e-27], Action: 0, state: 8\n",
      "[1.000000e+00 6.388658e-27]\n",
      "Action prob: [1.000000e+00 6.388658e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7067073e-27]\n",
      "Action prob: [1.0000000e+00 2.7067073e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3161794e-32]\n",
      "Action prob: [1.0000000e+00 2.3161794e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3400457e-26]\n",
      "Action prob: [1.0000000e+00 1.3400457e-26], Action: 0, state: 8\n",
      "[1.000000e+00 3.265672e-27]\n",
      "Action prob: [1.000000e+00 3.265672e-27], Action: 0, state: 8\n",
      "[1.000000e+00 6.475422e-33]\n",
      "Action prob: [1.000000e+00 6.475422e-33], Action: 0, state: 8\n",
      "[1.000000e+00 2.614369e-35]\n",
      "Action prob: [1.000000e+00 2.614369e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0342482e-35]\n",
      "Action prob: [1.0000000e+00 3.0342482e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 4.5287105e-37]\n",
      "Action prob: [1.0000000e+00 4.5287105e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3473145e-34]\n",
      "Action prob: [1.0000000e+00 3.3473145e-34], Action: 0, state: 8\n",
      "[1.000000e+00 6.693467e-35]\n",
      "Action prob: [1.000000e+00 6.693467e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3139458e-27]\n",
      "Action prob: [1.0000000e+00 1.3139458e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 7.7767025e-37]\n",
      "Action prob: [1.0000000e+00 7.7767025e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 5.6839966e-32]\n",
      "Action prob: [1.0000000e+00 5.6839966e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5155485e-28]\n",
      "Action prob: [1.0000000e+00 3.5155485e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7107182e-33]\n",
      "Action prob: [1.0000000e+00 1.7107182e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8912594e-27]\n",
      "Action prob: [1.0000000e+00 1.8912594e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8428656e-35]\n",
      "Action prob: [1.0000000e+00 1.8428656e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3271259e-32]\n",
      "Action prob: [1.0000000e+00 2.3271259e-32], Action: 0, state: 8\n",
      "[1.000000e+00 8.132503e-27]\n",
      "Action prob: [1.000000e+00 8.132503e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7866646e-27]\n",
      "Action prob: [1.0000000e+00 1.7866646e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9229133e-33]\n",
      "Action prob: [1.0000000e+00 1.9229133e-33], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -107500, loss is -0.0\n",
      "[1.0000000e+00 4.3269704e-28]\n",
      "Action prob: [1.0000000e+00 4.3269704e-28], Action: 0, state: 0\n",
      "[1.0000000e+00 6.2214703e-31]\n",
      "Action prob: [1.0000000e+00 6.2214703e-31], Action: 0, state: 0\n",
      "[1.000000e+00 7.666104e-29]\n",
      "Action prob: [1.000000e+00 7.666104e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.3185833e-30]\n",
      "Action prob: [1.0000000e+00 1.3185833e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 5.3402374e-30]\n",
      "Action prob: [1.0000000e+00 5.3402374e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 1.2172739e-29]\n",
      "Action prob: [1.0000000e+00 1.2172739e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.8940587e-29]\n",
      "Action prob: [1.0000000e+00 1.8940587e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 5.3272968e-30]\n",
      "Action prob: [1.0000000e+00 5.3272968e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.1364211e-30]\n",
      "Action prob: [1.0000000e+00 1.1364211e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 7.5692896e-34]\n",
      "Action prob: [1.0000000e+00 7.5692896e-34], Action: 0, state: 1\n",
      "[1.0000000e+00 3.5214925e-29]\n",
      "Action prob: [1.0000000e+00 3.5214925e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 3.0575658e-29]\n",
      "Action prob: [1.0000000e+00 3.0575658e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.4154647e-30]\n",
      "Action prob: [1.0000000e+00 1.4154647e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 1.1240741e-28]\n",
      "Action prob: [1.0000000e+00 1.1240741e-28], Action: 0, state: 2\n",
      "[1.000000e+00 1.400196e-31]\n",
      "Action prob: [1.000000e+00 1.400196e-31], Action: 0, state: 2\n",
      "[1.0000000e+00 5.0717206e-30]\n",
      "Action prob: [1.0000000e+00 5.0717206e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 1.1030896e-28]\n",
      "Action prob: [1.0000000e+00 1.1030896e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 2.4614415e-34]\n",
      "Action prob: [1.0000000e+00 2.4614415e-34], Action: 0, state: 8\n",
      "[1.000000e+00 1.932443e-26]\n",
      "Action prob: [1.000000e+00 1.932443e-26], Action: 0, state: 8\n",
      "[1.000000e+00 8.425874e-27]\n",
      "Action prob: [1.000000e+00 8.425874e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0186089e-27]\n",
      "Action prob: [1.0000000e+00 1.0186089e-27], Action: 0, state: 8\n",
      "[1.000000e+00 4.835325e-27]\n",
      "Action prob: [1.000000e+00 4.835325e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0394682e-27]\n",
      "Action prob: [1.0000000e+00 1.0394682e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8833136e-32]\n",
      "Action prob: [1.0000000e+00 1.8833136e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3113774e-34]\n",
      "Action prob: [1.0000000e+00 1.3113774e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.663681e-28]\n",
      "Action prob: [1.000000e+00 7.663681e-28], Action: 0, state: 8\n",
      "[1.000000e+00 7.705634e-27]\n",
      "Action prob: [1.000000e+00 7.705634e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1700235e-31]\n",
      "Action prob: [1.0000000e+00 1.1700235e-31], Action: 0, state: 8\n",
      "[1.000000e+00 3.834909e-32]\n",
      "Action prob: [1.000000e+00 3.834909e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3648883e-34]\n",
      "Action prob: [1.0000000e+00 4.3648883e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 5.1026042e-34]\n",
      "Action prob: [1.0000000e+00 5.1026042e-34], Action: 0, state: 8\n",
      "[1.00000e+00 8.49346e-32]\n",
      "Action prob: [1.00000e+00 8.49346e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1655438e-36]\n",
      "Action prob: [1.0000000e+00 2.1655438e-36], Action: 0, state: 8\n",
      "[1.000000e+00 8.400642e-36]\n",
      "Action prob: [1.000000e+00 8.400642e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 6.4736436e-33]\n",
      "Action prob: [1.0000000e+00 6.4736436e-33], Action: 0, state: 8\n",
      "[1.000000e+00 6.392967e-29]\n",
      "Action prob: [1.000000e+00 6.392967e-29], Action: 0, state: 8\n",
      "[1.000000e+00 3.650897e-27]\n",
      "Action prob: [1.000000e+00 3.650897e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.928189e-27]\n",
      "Action prob: [1.000000e+00 7.928189e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0332284e-31]\n",
      "Action prob: [1.0000000e+00 5.0332284e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 4.8116267e-34]\n",
      "Action prob: [1.0000000e+00 4.8116267e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1066765e-26]\n",
      "Action prob: [1.0000000e+00 2.1066765e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2901903e-36]\n",
      "Action prob: [1.0000000e+00 3.2901903e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3562087e-34]\n",
      "Action prob: [1.0000000e+00 1.3562087e-34], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 3.531487e-37]\n",
      "Action prob: [1.000000e+00 3.531487e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9256846e-33]\n",
      "Action prob: [1.0000000e+00 3.9256846e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4804968e-34]\n",
      "Action prob: [1.0000000e+00 1.4804968e-34], Action: 0, state: 8\n",
      "[1.000000e+00 3.221696e-35]\n",
      "Action prob: [1.000000e+00 3.221696e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4473892e-33]\n",
      "Action prob: [1.0000000e+00 2.4473892e-33], Action: 0, state: 8\n",
      "[1.00000e+00 3.28611e-39]\n",
      "Action prob: [1.00000e+00 3.28611e-39], Action: 0, state: 8\n",
      "[1.000000e+00 9.636465e-34]\n",
      "Action prob: [1.000000e+00 9.636465e-34], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -87800, loss is -0.0\n",
      "[1.0000000e+00 7.2211074e-31]\n",
      "Action prob: [1.0000000e+00 7.2211074e-31], Action: 0, state: 0\n",
      "[1.000000e+00 5.589163e-29]\n",
      "Action prob: [1.000000e+00 5.589163e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.3159904e-30]\n",
      "Action prob: [1.0000000e+00 1.3159904e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.9383537e-29]\n",
      "Action prob: [1.0000000e+00 1.9383537e-29], Action: 0, state: 1\n",
      "[1.000000e+00 1.271213e-29]\n",
      "Action prob: [1.000000e+00 1.271213e-29], Action: 0, state: 1\n",
      "[1.000000e+00 3.377555e-29]\n",
      "Action prob: [1.000000e+00 3.377555e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 3.2414618e-32]\n",
      "Action prob: [1.0000000e+00 3.2414618e-32], Action: 0, state: 2\n",
      "[1.0000000e+00 7.8796903e-31]\n",
      "Action prob: [1.0000000e+00 7.8796903e-31], Action: 0, state: 2\n",
      "[1.0000000e+00 2.6647383e-31]\n",
      "Action prob: [1.0000000e+00 2.6647383e-31], Action: 0, state: 3\n",
      "[1.0000000e+00 2.4441505e-34]\n",
      "Action prob: [1.0000000e+00 2.4441505e-34], Action: 0, state: 3\n",
      "[1.0000000e+00 5.6237053e-28]\n",
      "Action prob: [1.0000000e+00 5.6237053e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 4.5601863e-32]\n",
      "Action prob: [1.0000000e+00 4.5601863e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2952692e-26]\n",
      "Action prob: [1.0000000e+00 1.2952692e-26], Action: 0, state: 9\n",
      "[1.000000e+00 2.789029e-27]\n",
      "Action prob: [1.000000e+00 2.789029e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.4185382e-33]\n",
      "Action prob: [1.0000000e+00 1.4185382e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 2.8053127e-34]\n",
      "Action prob: [1.0000000e+00 2.8053127e-34], Action: 0, state: 9\n",
      "[1.000000e+00 9.192717e-28]\n",
      "Action prob: [1.000000e+00 9.192717e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 6.6461916e-28]\n",
      "Action prob: [1.0000000e+00 6.6461916e-28], Action: 0, state: 9\n",
      "[1.000000e+00 5.488513e-27]\n",
      "Action prob: [1.000000e+00 5.488513e-27], Action: 0, state: 9\n",
      "[1.000000e+00 7.739294e-30]\n",
      "Action prob: [1.000000e+00 7.739294e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 7.0293488e-34]\n",
      "Action prob: [1.0000000e+00 7.0293488e-34], Action: 0, state: 9\n",
      "[1.000000e+00 9.452273e-35]\n",
      "Action prob: [1.000000e+00 9.452273e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2641587e-35]\n",
      "Action prob: [1.0000000e+00 1.2641587e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3094475e-27]\n",
      "Action prob: [1.0000000e+00 1.3094475e-27], Action: 0, state: 9\n",
      "[1.000000e+00 5.380984e-33]\n",
      "Action prob: [1.000000e+00 5.380984e-33], Action: 0, state: 9\n",
      "[1.000000e+00 9.901061e-35]\n",
      "Action prob: [1.000000e+00 9.901061e-35], Action: 0, state: 9\n",
      "[1.000000e+00 6.439353e-35]\n",
      "Action prob: [1.000000e+00 6.439353e-35], Action: 0, state: 9\n",
      "[1.00000e+00 6.54296e-33]\n",
      "Action prob: [1.00000e+00 6.54296e-33], Action: 0, state: 9\n",
      "[1.00000e+00 1.06974e-33]\n",
      "Action prob: [1.00000e+00 1.06974e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3184468e-31]\n",
      "Action prob: [1.0000000e+00 1.3184468e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 5.6473745e-28]\n",
      "Action prob: [1.0000000e+00 5.6473745e-28], Action: 0, state: 9\n",
      "[1.00000000e+00 1.61326735e-27]\n",
      "Action prob: [1.00000000e+00 1.61326735e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2023712e-30]\n",
      "Action prob: [1.0000000e+00 1.2023712e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 5.1885925e-28]\n",
      "Action prob: [1.0000000e+00 5.1885925e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 3.5581864e-26]\n",
      "Action prob: [1.0000000e+00 3.5581864e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 2.5717672e-34]\n",
      "Action prob: [1.0000000e+00 2.5717672e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 2.2961241e-30]\n",
      "Action prob: [1.0000000e+00 2.2961241e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1706828e-26]\n",
      "Action prob: [1.0000000e+00 1.1706828e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1616159e-35]\n",
      "Action prob: [1.0000000e+00 1.1616159e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 3.7516347e-33]\n",
      "Action prob: [1.0000000e+00 3.7516347e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 9.0346215e-32]\n",
      "Action prob: [1.0000000e+00 9.0346215e-32], Action: 0, state: 9\n",
      "[1.000000e+00 7.613165e-33]\n",
      "Action prob: [1.000000e+00 7.613165e-33], Action: 0, state: 9\n",
      "[1.000000e+00 5.232903e-34]\n",
      "Action prob: [1.000000e+00 5.232903e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2570963e-32]\n",
      "Action prob: [1.0000000e+00 1.2570963e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 2.6869648e-35]\n",
      "Action prob: [1.0000000e+00 2.6869648e-35], Action: 0, state: 9\n",
      "[1.00000e+00 9.05423e-37]\n",
      "Action prob: [1.00000e+00 9.05423e-37], Action: 0, state: 9\n",
      "[1.0000000e+00 1.5676838e-32]\n",
      "Action prob: [1.0000000e+00 1.5676838e-32], Action: 0, state: 9\n",
      "[1.000000e+00 6.244385e-33]\n",
      "Action prob: [1.000000e+00 6.244385e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 3.7821093e-27]\n",
      "Action prob: [1.0000000e+00 3.7821093e-27], Action: 0, state: 9\n",
      "[1.000000e+00 9.137512e-28]\n",
      "Action prob: [1.000000e+00 9.137512e-28], Action: 0, state: 9\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., -0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -34000, loss is -0.0\n",
      "[1.0000000e+00 3.7873027e-29]\n",
      "Action prob: [1.0000000e+00 3.7873027e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.4758598e-29]\n",
      "Action prob: [1.0000000e+00 1.4758598e-29], Action: 0, state: 0\n",
      "[1.000000e+00 4.686007e-33]\n",
      "Action prob: [1.000000e+00 4.686007e-33], Action: 0, state: 1\n",
      "[1.000000e+00 4.341549e-30]\n",
      "Action prob: [1.000000e+00 4.341549e-30], Action: 0, state: 1\n",
      "[1.000000e+00 5.908463e-31]\n",
      "Action prob: [1.000000e+00 5.908463e-31], Action: 0, state: 2\n",
      "[1.000000e+00 9.603645e-29]\n",
      "Action prob: [1.000000e+00 9.603645e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 2.2638247e-28]\n",
      "Action prob: [1.0000000e+00 2.2638247e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.0296875e-29]\n",
      "Action prob: [1.0000000e+00 1.0296875e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 2.1122525e-34]\n",
      "Action prob: [1.0000000e+00 2.1122525e-34], Action: 0, state: 3\n",
      "[1.0000000e+00 3.7855694e-29]\n",
      "Action prob: [1.0000000e+00 3.7855694e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.6990413e-29]\n",
      "Action prob: [1.0000000e+00 1.6990413e-29], Action: 0, state: 3\n",
      "[1.000000e+00 8.234099e-30]\n",
      "Action prob: [1.000000e+00 8.234099e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 1.3102756e-29]\n",
      "Action prob: [1.0000000e+00 1.3102756e-29], Action: 0, state: 3\n",
      "[1.00000e+00 7.80855e-27]\n",
      "Action prob: [1.00000e+00 7.80855e-27], Action: 0, state: 8\n",
      "[1.000000e+00 1.861056e-36]\n",
      "Action prob: [1.000000e+00 1.861056e-36], Action: 0, state: 8\n",
      "[1.000000e+00 9.970614e-27]\n",
      "Action prob: [1.000000e+00 9.970614e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2529503e-36]\n",
      "Action prob: [1.0000000e+00 3.2529503e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4782876e-34]\n",
      "Action prob: [1.0000000e+00 2.4782876e-34], Action: 0, state: 8\n",
      "[1.000000e+00 3.225445e-36]\n",
      "Action prob: [1.000000e+00 3.225445e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0656048e-34]\n",
      "Action prob: [1.0000000e+00 3.0656048e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5414195e-35]\n",
      "Action prob: [1.0000000e+00 3.5414195e-35], Action: 0, state: 8\n",
      "[1.000000e+00 9.867405e-32]\n",
      "Action prob: [1.000000e+00 9.867405e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9729898e-32]\n",
      "Action prob: [1.0000000e+00 2.9729898e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3681657e-27]\n",
      "Action prob: [1.0000000e+00 5.3681657e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8411012e-33]\n",
      "Action prob: [1.0000000e+00 2.8411012e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.8345834e-35]\n",
      "Action prob: [1.0000000e+00 5.8345834e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8744568e-28]\n",
      "Action prob: [1.0000000e+00 3.8744568e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8074217e-27]\n",
      "Action prob: [1.0000000e+00 1.8074217e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9690382e-32]\n",
      "Action prob: [1.0000000e+00 3.9690382e-32], Action: 0, state: 8\n",
      "[1.000000e+00 4.846993e-36]\n",
      "Action prob: [1.000000e+00 4.846993e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6884013e-35]\n",
      "Action prob: [1.0000000e+00 1.6884013e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6811974e-34]\n",
      "Action prob: [1.0000000e+00 1.6811974e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.189835e-29]\n",
      "Action prob: [1.000000e+00 7.189835e-29], Action: 0, state: 8\n",
      "[1.000000e+00 7.495557e-27]\n",
      "Action prob: [1.000000e+00 7.495557e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9133047e-27]\n",
      "Action prob: [1.0000000e+00 1.9133047e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0811717e-34]\n",
      "Action prob: [1.0000000e+00 2.0811717e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 6.1784353e-28]\n",
      "Action prob: [1.0000000e+00 6.1784353e-28], Action: 0, state: 8\n",
      "[1.000000e+00 3.265996e-27]\n",
      "Action prob: [1.000000e+00 3.265996e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5979761e-34]\n",
      "Action prob: [1.0000000e+00 2.5979761e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0018654e-26]\n",
      "Action prob: [1.0000000e+00 1.0018654e-26], Action: 0, state: 8\n",
      "[1.000000e+00 9.113253e-27]\n",
      "Action prob: [1.000000e+00 9.113253e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 9.7397445e-37]\n",
      "Action prob: [1.0000000e+00 9.7397445e-37], Action: 0, state: 8\n",
      "[1.000000e+00 5.386707e-28]\n",
      "Action prob: [1.000000e+00 5.386707e-28], Action: 0, state: 8\n",
      "[1.000000e+00 9.534457e-32]\n",
      "Action prob: [1.000000e+00 9.534457e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2756352e-34]\n",
      "Action prob: [1.0000000e+00 1.2756352e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3629718e-34]\n",
      "Action prob: [1.0000000e+00 1.3629718e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1512801e-27]\n",
      "Action prob: [1.0000000e+00 1.1512801e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 7.1627954e-27]\n",
      "Action prob: [1.0000000e+00 7.1627954e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3914529e-31]\n",
      "Action prob: [1.0000000e+00 1.3914529e-31], Action: 0, state: 8\n",
      "[1.000000e+00 5.812153e-33]\n",
      "Action prob: [1.000000e+00 5.812153e-33], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0.,\n",
      "        0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -106400, loss is -0.0\n",
      "[1.0000000e+00 1.1677724e-30]\n",
      "Action prob: [1.0000000e+00 1.1677724e-30], Action: 0, state: 0\n",
      "[1.000000e+00 7.199465e-30]\n",
      "Action prob: [1.000000e+00 7.199465e-30], Action: 0, state: 0\n",
      "[1.000000e+00 9.797394e-29]\n",
      "Action prob: [1.000000e+00 9.797394e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 2.2989036e-29]\n",
      "Action prob: [1.0000000e+00 2.2989036e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 4.2145784e-29]\n",
      "Action prob: [1.0000000e+00 4.2145784e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 3.1349221e-31]\n",
      "Action prob: [1.0000000e+00 3.1349221e-31], Action: 0, state: 2\n",
      "[1.0000000e+00 3.3733542e-31]\n",
      "Action prob: [1.0000000e+00 3.3733542e-31], Action: 0, state: 2\n",
      "[1.0000000e+00 5.0136275e-30]\n",
      "Action prob: [1.0000000e+00 5.0136275e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 2.0276234e-28]\n",
      "Action prob: [1.0000000e+00 2.0276234e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.8542909e-26]\n",
      "Action prob: [1.0000000e+00 1.8542909e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1697296e-27]\n",
      "Action prob: [1.0000000e+00 2.1697296e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4939023e-36]\n",
      "Action prob: [1.0000000e+00 3.4939023e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0293017e-37]\n",
      "Action prob: [1.0000000e+00 4.0293017e-37], Action: 0, state: 8\n",
      "[1.000000e+00 4.068094e-39]\n",
      "Action prob: [1.000000e+00 4.068094e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6028965e-34]\n",
      "Action prob: [1.0000000e+00 2.6028965e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1987592e-34]\n",
      "Action prob: [1.0000000e+00 2.1987592e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.928431e-27]\n",
      "Action prob: [1.000000e+00 7.928431e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7788636e-35]\n",
      "Action prob: [1.0000000e+00 1.7788636e-35], Action: 0, state: 8\n",
      "[1.00000e+00 2.64989e-37]\n",
      "Action prob: [1.00000e+00 2.64989e-37], Action: 0, state: 8\n",
      "[1.000000e+00 2.430462e-36]\n",
      "Action prob: [1.000000e+00 2.430462e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5542435e-29]\n",
      "Action prob: [1.0000000e+00 2.5542435e-29], Action: 0, state: 8\n",
      "[1.000000e+00 4.206406e-35]\n",
      "Action prob: [1.000000e+00 4.206406e-35], Action: 0, state: 8\n",
      "[1.000000e+00 7.122363e-34]\n",
      "Action prob: [1.000000e+00 7.122363e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3996819e-33]\n",
      "Action prob: [1.0000000e+00 1.3996819e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 6.8919165e-34]\n",
      "Action prob: [1.0000000e+00 6.8919165e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1991925e-27]\n",
      "Action prob: [1.0000000e+00 4.1991925e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6460971e-33]\n",
      "Action prob: [1.0000000e+00 2.6460971e-33], Action: 0, state: 8\n",
      "[1.00000e+00 8.00364e-40]\n",
      "Action prob: [1.00000e+00 8.00364e-40], Action: 0, state: 8\n",
      "[1.000000e+00 5.365832e-27]\n",
      "Action prob: [1.000000e+00 5.365832e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4275339e-32]\n",
      "Action prob: [1.0000000e+00 1.4275339e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5244243e-35]\n",
      "Action prob: [1.0000000e+00 1.5244243e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1365361e-26]\n",
      "Action prob: [1.0000000e+00 1.1365361e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1517335e-33]\n",
      "Action prob: [1.0000000e+00 1.1517335e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3152851e-34]\n",
      "Action prob: [1.0000000e+00 1.3152851e-34], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 1.0492495e-33]\n",
      "Action prob: [1.0000000e+00 1.0492495e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.7502114e-29]\n",
      "Action prob: [1.0000000e+00 3.7502114e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0645895e-27]\n",
      "Action prob: [1.0000000e+00 1.0645895e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4348968e-35]\n",
      "Action prob: [1.0000000e+00 1.4348968e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4840591e-34]\n",
      "Action prob: [1.0000000e+00 1.4840591e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 5.2732786e-35]\n",
      "Action prob: [1.0000000e+00 5.2732786e-35], Action: 0, state: 8\n",
      "[1.000000e+00 2.299628e-32]\n",
      "Action prob: [1.000000e+00 2.299628e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2213935e-32]\n",
      "Action prob: [1.0000000e+00 3.2213935e-32], Action: 0, state: 8\n",
      "[1.000000e+00 3.799462e-27]\n",
      "Action prob: [1.000000e+00 3.799462e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3816545e-28]\n",
      "Action prob: [1.0000000e+00 5.3816545e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6386068e-31]\n",
      "Action prob: [1.0000000e+00 1.6386068e-31], Action: 0, state: 8\n",
      "[1.000000e+00 5.666684e-37]\n",
      "Action prob: [1.000000e+00 5.666684e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0000375e-36]\n",
      "Action prob: [1.0000000e+00 4.0000375e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0583099e-26]\n",
      "Action prob: [1.0000000e+00 1.0583099e-26], Action: 0, state: 8\n",
      "[1.000e+00 2.954e-42]\n",
      "Action prob: [1.000e+00 2.954e-42], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4495655e-33]\n",
      "Action prob: [1.0000000e+00 1.4495655e-33], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        -0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -119800, loss is -0.0\n",
      "[1.0000000e+00 1.3928078e-30]\n",
      "Action prob: [1.0000000e+00 1.3928078e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 6.7731044e-31]\n",
      "Action prob: [1.0000000e+00 6.7731044e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 4.8673147e-30]\n",
      "Action prob: [1.0000000e+00 4.8673147e-30], Action: 0, state: 1\n",
      "[1.000000e+00 8.179501e-30]\n",
      "Action prob: [1.000000e+00 8.179501e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 3.1688657e-30]\n",
      "Action prob: [1.0000000e+00 3.1688657e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.4229527e-29]\n",
      "Action prob: [1.0000000e+00 1.4229527e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 4.2300366e-31]\n",
      "Action prob: [1.0000000e+00 4.2300366e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 1.0915939e-30]\n",
      "Action prob: [1.0000000e+00 1.0915939e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.4717445e-29]\n",
      "Action prob: [1.0000000e+00 1.4717445e-29], Action: 0, state: 1\n",
      "[1.000000e+00 3.391048e-28]\n",
      "Action prob: [1.000000e+00 3.391048e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 1.9459106e-29]\n",
      "Action prob: [1.0000000e+00 1.9459106e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.4679044e-28]\n",
      "Action prob: [1.0000000e+00 1.4679044e-28], Action: 0, state: 2\n",
      "[1.000000e+00 2.468472e-29]\n",
      "Action prob: [1.000000e+00 2.468472e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 2.0732203e-30]\n",
      "Action prob: [1.0000000e+00 2.0732203e-30], Action: 0, state: 2\n",
      "[1.000000e+00 4.077784e-34]\n",
      "Action prob: [1.000000e+00 4.077784e-34], Action: 0, state: 3\n",
      "[1.0000000e+00 1.6880385e-30]\n",
      "Action prob: [1.0000000e+00 1.6880385e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 1.6054407e-26]\n",
      "Action prob: [1.0000000e+00 1.6054407e-26], Action: 0, state: 8\n",
      "[1.000000e+00 7.514281e-27]\n",
      "Action prob: [1.000000e+00 7.514281e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.570661e-28]\n",
      "Action prob: [1.000000e+00 9.570661e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 6.1288607e-27]\n",
      "Action prob: [1.0000000e+00 6.1288607e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0933014e-29]\n",
      "Action prob: [1.0000000e+00 4.0933014e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5760757e-36]\n",
      "Action prob: [1.0000000e+00 3.5760757e-36], Action: 0, state: 8\n",
      "[1.000000e+00 1.046326e-36]\n",
      "Action prob: [1.000000e+00 1.046326e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1483416e-26]\n",
      "Action prob: [1.0000000e+00 4.1483416e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6471714e-32]\n",
      "Action prob: [1.0000000e+00 3.6471714e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4238512e-33]\n",
      "Action prob: [1.0000000e+00 1.4238512e-33], Action: 0, state: 8\n",
      "[1.000000e+00 7.363909e-35]\n",
      "Action prob: [1.000000e+00 7.363909e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.5039636e-35]\n",
      "Action prob: [1.0000000e+00 5.5039636e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3410923e-32]\n",
      "Action prob: [1.0000000e+00 3.3410923e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8334582e-26]\n",
      "Action prob: [1.0000000e+00 3.8334582e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5708605e-27]\n",
      "Action prob: [1.0000000e+00 1.5708605e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1370696e-34]\n",
      "Action prob: [1.0000000e+00 2.1370696e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0332236e-33]\n",
      "Action prob: [1.0000000e+00 5.0332236e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0940385e-35]\n",
      "Action prob: [1.0000000e+00 4.0940385e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4131107e-25]\n",
      "Action prob: [1.0000000e+00 1.4131107e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3916044e-27]\n",
      "Action prob: [1.0000000e+00 1.3916044e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.607981e-34]\n",
      "Action prob: [1.000000e+00 9.607981e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9122159e-34]\n",
      "Action prob: [1.0000000e+00 2.9122159e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3580103e-34]\n",
      "Action prob: [1.0000000e+00 1.3580103e-34], Action: 0, state: 8\n",
      "[1.000000e+00 5.531073e-35]\n",
      "Action prob: [1.000000e+00 5.531073e-35], Action: 0, state: 8\n",
      "[1.000000e+00 2.592152e-29]\n",
      "Action prob: [1.000000e+00 2.592152e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7217752e-34]\n",
      "Action prob: [1.0000000e+00 1.7217752e-34], Action: 0, state: 8\n",
      "[1.000000e+00 4.789521e-35]\n",
      "Action prob: [1.000000e+00 4.789521e-35], Action: 0, state: 8\n",
      "[1.000000e+00 2.932291e-35]\n",
      "Action prob: [1.000000e+00 2.932291e-35], Action: 0, state: 8\n",
      "[1.000000e+00 5.237932e-28]\n",
      "Action prob: [1.000000e+00 5.237932e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1327186e-26]\n",
      "Action prob: [1.0000000e+00 1.1327186e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6593107e-35]\n",
      "Action prob: [1.0000000e+00 1.6593107e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1615323e-34]\n",
      "Action prob: [1.0000000e+00 1.1615323e-34], Action: 0, state: 8\n",
      "[1.000000e+00 3.238835e-36]\n",
      "Action prob: [1.000000e+00 3.238835e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3723876e-34]\n",
      "Action prob: [1.0000000e+00 4.3723876e-34], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -92600, loss is -0.0\n",
      "[1.0000000e+00 1.3042316e-29]\n",
      "Action prob: [1.0000000e+00 1.3042316e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 2.0049996e-31]\n",
      "Action prob: [1.0000000e+00 2.0049996e-31], Action: 0, state: 0\n",
      "[1.000000e+00 7.736283e-30]\n",
      "Action prob: [1.000000e+00 7.736283e-30], Action: 0, state: 1\n",
      "[1.000000e+00 8.538885e-30]\n",
      "Action prob: [1.000000e+00 8.538885e-30], Action: 0, state: 1\n",
      "[1.000000e+00 4.121406e-31]\n",
      "Action prob: [1.000000e+00 4.121406e-31], Action: 0, state: 1\n",
      "[1.000000e+00 6.587022e-30]\n",
      "Action prob: [1.000000e+00 6.587022e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 8.3651714e-30]\n",
      "Action prob: [1.0000000e+00 8.3651714e-30], Action: 0, state: 1\n",
      "[1.000000e+00 1.129687e-30]\n",
      "Action prob: [1.000000e+00 1.129687e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.3176638e-29]\n",
      "Action prob: [1.0000000e+00 1.3176638e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.0214485e-29]\n",
      "Action prob: [1.0000000e+00 1.0214485e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 6.5631155e-31]\n",
      "Action prob: [1.0000000e+00 6.5631155e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 4.4473357e-31]\n",
      "Action prob: [1.0000000e+00 4.4473357e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 2.9599339e-30]\n",
      "Action prob: [1.0000000e+00 2.9599339e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 4.9945386e-30]\n",
      "Action prob: [1.0000000e+00 4.9945386e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 6.5510876e-30]\n",
      "Action prob: [1.0000000e+00 6.5510876e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 5.0298287e-32]\n",
      "Action prob: [1.0000000e+00 5.0298287e-32], Action: 0, state: 2\n",
      "[1.0000000e+00 2.5576365e-29]\n",
      "Action prob: [1.0000000e+00 2.5576365e-29], Action: 0, state: 2\n",
      "[1.000000e+00 4.957356e-29]\n",
      "Action prob: [1.000000e+00 4.957356e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 3.9044552e-29]\n",
      "Action prob: [1.0000000e+00 3.9044552e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 4.8108866e-29]\n",
      "Action prob: [1.0000000e+00 4.8108866e-29], Action: 0, state: 2\n",
      "[1.00000e+00 5.80527e-30]\n",
      "Action prob: [1.00000e+00 5.80527e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 3.1767086e-30]\n",
      "Action prob: [1.0000000e+00 3.1767086e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 7.7222066e-33]\n",
      "Action prob: [1.0000000e+00 7.7222066e-33], Action: 0, state: 3\n",
      "[1.0000000e+00 7.2479394e-29]\n",
      "Action prob: [1.0000000e+00 7.2479394e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4226292e-35]\n",
      "Action prob: [1.0000000e+00 3.4226292e-35], Action: 0, state: 8\n",
      "[1.000000e+00 3.581564e-36]\n",
      "Action prob: [1.000000e+00 3.581564e-36], Action: 0, state: 8\n",
      "[1.000000e+00 5.365402e-27]\n",
      "Action prob: [1.000000e+00 5.365402e-27], Action: 0, state: 8\n",
      "[1.00000000e+00 1.10486795e-26]\n",
      "Action prob: [1.00000000e+00 1.10486795e-26], Action: 0, state: 8\n",
      "[1.000000e+00 2.488283e-33]\n",
      "Action prob: [1.000000e+00 2.488283e-33], Action: 0, state: 8\n",
      "[1.000000e+00 4.708205e-34]\n",
      "Action prob: [1.000000e+00 4.708205e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1879572e-33]\n",
      "Action prob: [1.0000000e+00 3.1879572e-33], Action: 0, state: 8\n",
      "[1.00000e+00 6.80915e-28]\n",
      "Action prob: [1.00000e+00 6.80915e-28], Action: 0, state: 8\n",
      "[1.000e+00 1.178e-42]\n",
      "Action prob: [1.000e+00 1.178e-42], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3101617e-34]\n",
      "Action prob: [1.0000000e+00 5.3101617e-34], Action: 0, state: 8\n",
      "[1.000e+00 1.733e-42]\n",
      "Action prob: [1.000e+00 1.733e-42], Action: 0, state: 8\n",
      "[1.000000e+00 8.056727e-27]\n",
      "Action prob: [1.000000e+00 8.056727e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1259728e-34]\n",
      "Action prob: [1.0000000e+00 3.1259728e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6510998e-32]\n",
      "Action prob: [1.0000000e+00 2.6510998e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3178116e-27]\n",
      "Action prob: [1.0000000e+00 2.3178116e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7676309e-27]\n",
      "Action prob: [1.0000000e+00 2.7676309e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3792453e-28]\n",
      "Action prob: [1.0000000e+00 3.3792453e-28], Action: 0, state: 8\n",
      "[1.000000e+00 2.807885e-39]\n",
      "Action prob: [1.000000e+00 2.807885e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 6.9715554e-28]\n",
      "Action prob: [1.0000000e+00 6.9715554e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4588583e-33]\n",
      "Action prob: [1.0000000e+00 3.4588583e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0412896e-35]\n",
      "Action prob: [1.0000000e+00 1.0412896e-35], Action: 0, state: 8\n",
      "[1.000000e+00 1.525307e-37]\n",
      "Action prob: [1.000000e+00 1.525307e-37], Action: 0, state: 8\n",
      "[1.000000e+00 9.329726e-34]\n",
      "Action prob: [1.000000e+00 9.329726e-34], Action: 0, state: 8\n",
      "[1.000000e+00 4.437367e-33]\n",
      "Action prob: [1.000000e+00 4.437367e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9886746e-34]\n",
      "Action prob: [1.0000000e+00 3.9886746e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0195855e-33]\n",
      "Action prob: [1.0000000e+00 1.0195855e-33], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., -0.,\n",
      "        0., -0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -65200, loss is -0.0\n",
      "[1.0000000e+00 8.6872976e-29]\n",
      "Action prob: [1.0000000e+00 8.6872976e-29], Action: 0, state: 0\n",
      "[1.000000e+00 2.677294e-29]\n",
      "Action prob: [1.000000e+00 2.677294e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 7.7472535e-34]\n",
      "Action prob: [1.0000000e+00 7.7472535e-34], Action: 0, state: 1\n",
      "[1.0000000e+00 3.5812197e-30]\n",
      "Action prob: [1.0000000e+00 3.5812197e-30], Action: 0, state: 1\n",
      "[1.000000e+00 9.514951e-31]\n",
      "Action prob: [1.000000e+00 9.514951e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 1.1857459e-30]\n",
      "Action prob: [1.0000000e+00 1.1857459e-30], Action: 0, state: 2\n",
      "[1.000000e+00 1.587656e-35]\n",
      "Action prob: [1.000000e+00 1.587656e-35], Action: 0, state: 3\n",
      "[1.0000000e+00 1.4992534e-32]\n",
      "Action prob: [1.0000000e+00 1.4992534e-32], Action: 0, state: 3\n",
      "[1.0000000e+00 1.9936986e-29]\n",
      "Action prob: [1.0000000e+00 1.9936986e-29], Action: 0, state: 3\n",
      "[1.0000e+00 5.6841e-41]\n",
      "Action prob: [1.0000e+00 5.6841e-41], Action: 0, state: 3\n",
      "[1.0000000e+00 5.0712004e-29]\n",
      "Action prob: [1.0000000e+00 5.0712004e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 1.5191599e-34]\n",
      "Action prob: [1.0000000e+00 1.5191599e-34], Action: 0, state: 8\n",
      "[1.00000e+00 3.11197e-26]\n",
      "Action prob: [1.00000e+00 3.11197e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0901731e-33]\n",
      "Action prob: [1.0000000e+00 1.0901731e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3471937e-33]\n",
      "Action prob: [1.0000000e+00 4.3471937e-33], Action: 0, state: 8\n",
      "[1.000000e+00 8.643156e-32]\n",
      "Action prob: [1.000000e+00 8.643156e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0556924e-27]\n",
      "Action prob: [1.0000000e+00 1.0556924e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7844373e-34]\n",
      "Action prob: [1.0000000e+00 2.7844373e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6107028e-35]\n",
      "Action prob: [1.0000000e+00 1.6107028e-35], Action: 0, state: 8\n",
      "[1.0000e+00 2.1032e-41]\n",
      "Action prob: [1.0000e+00 2.1032e-41], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4627618e-28]\n",
      "Action prob: [1.0000000e+00 1.4627618e-28], Action: 0, state: 8\n",
      "[1.000000e+00 9.769789e-34]\n",
      "Action prob: [1.000000e+00 9.769789e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3011226e-31]\n",
      "Action prob: [1.0000000e+00 5.3011226e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4930017e-35]\n",
      "Action prob: [1.0000000e+00 1.4930017e-35], Action: 0, state: 8\n",
      "[1.000000e+00 2.875873e-34]\n",
      "Action prob: [1.000000e+00 2.875873e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2924104e-37]\n",
      "Action prob: [1.0000000e+00 4.2924104e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6495756e-24]\n",
      "Action prob: [1.0000000e+00 1.6495756e-24], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5496465e-33]\n",
      "Action prob: [1.0000000e+00 3.5496465e-33], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 1.2424968e-34]\n",
      "Action prob: [1.0000000e+00 1.2424968e-34], Action: 0, state: 8\n",
      "[1.000000e+00 2.992237e-27]\n",
      "Action prob: [1.000000e+00 2.992237e-27], Action: 0, state: 8\n",
      "[1.000000e+00 2.200186e-26]\n",
      "Action prob: [1.000000e+00 2.200186e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1785501e-38]\n",
      "Action prob: [1.0000000e+00 2.1785501e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0834568e-33]\n",
      "Action prob: [1.0000000e+00 1.0834568e-33], Action: 0, state: 8\n",
      "[1.000000e+00 1.638473e-34]\n",
      "Action prob: [1.000000e+00 1.638473e-34], Action: 0, state: 8\n",
      "[1.000000e+00 4.247102e-35]\n",
      "Action prob: [1.000000e+00 4.247102e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0767617e-27]\n",
      "Action prob: [1.0000000e+00 2.0767617e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5115064e-34]\n",
      "Action prob: [1.0000000e+00 1.5115064e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1873092e-27]\n",
      "Action prob: [1.0000000e+00 1.1873092e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1095577e-31]\n",
      "Action prob: [1.0000000e+00 1.1095577e-31], Action: 0, state: 8\n",
      "[1.000000e+00 8.519827e-28]\n",
      "Action prob: [1.000000e+00 8.519827e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 6.6981955e-34]\n",
      "Action prob: [1.0000000e+00 6.6981955e-34], Action: 0, state: 8\n",
      "[1.000000e+00 3.922538e-27]\n",
      "Action prob: [1.000000e+00 3.922538e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.152931e-28]\n",
      "Action prob: [1.000000e+00 9.152931e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0280977e-27]\n",
      "Action prob: [1.0000000e+00 3.0280977e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4126217e-38]\n",
      "Action prob: [1.0000000e+00 1.4126217e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5244588e-35]\n",
      "Action prob: [1.0000000e+00 2.5244588e-35], Action: 0, state: 8\n",
      "[1.0000e+00 7.0812e-41]\n",
      "Action prob: [1.0000e+00 7.0812e-41], Action: 0, state: 8\n",
      "[1.000000e+00 6.104614e-28]\n",
      "Action prob: [1.000000e+00 6.104614e-28], Action: 0, state: 8\n",
      "[1.000000e+00 5.529132e-35]\n",
      "Action prob: [1.000000e+00 5.529132e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 6.7465287e-28]\n",
      "Action prob: [1.0000000e+00 6.7465287e-28], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0.,\n",
      "        0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -113100, loss is -0.0\n",
      "[1.0000000e+00 1.3031418e-30]\n",
      "Action prob: [1.0000000e+00 1.3031418e-30], Action: 0, state: 0\n",
      "[1.000000e+00 5.892951e-32]\n",
      "Action prob: [1.000000e+00 5.892951e-32], Action: 0, state: 1\n",
      "[1.0000000e+00 1.3491024e-28]\n",
      "Action prob: [1.0000000e+00 1.3491024e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 1.1271817e-30]\n",
      "Action prob: [1.0000000e+00 1.1271817e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 2.3951866e-33]\n",
      "Action prob: [1.0000000e+00 2.3951866e-33], Action: 0, state: 2\n",
      "[1.000000e+00 9.053399e-30]\n",
      "Action prob: [1.000000e+00 9.053399e-30], Action: 0, state: 3\n",
      "[1.000000e+00 3.370804e-33]\n",
      "Action prob: [1.000000e+00 3.370804e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.4279835e-35]\n",
      "Action prob: [1.0000000e+00 5.4279835e-35], Action: 0, state: 8\n",
      "[1.00000e+00 1.83773e-40]\n",
      "Action prob: [1.00000e+00 1.83773e-40], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1520668e-33]\n",
      "Action prob: [1.0000000e+00 3.1520668e-33], Action: 0, state: 8\n",
      "[1.000000e+00 2.812825e-26]\n",
      "Action prob: [1.000000e+00 2.812825e-26], Action: 0, state: 8\n",
      "[1.000000e+00 3.159761e-32]\n",
      "Action prob: [1.000000e+00 3.159761e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 6.9271074e-33]\n",
      "Action prob: [1.0000000e+00 6.9271074e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8407523e-27]\n",
      "Action prob: [1.0000000e+00 2.8407523e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.672524e-33]\n",
      "Action prob: [1.000000e+00 7.672524e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3661901e-32]\n",
      "Action prob: [1.0000000e+00 1.3661901e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4167165e-32]\n",
      "Action prob: [1.0000000e+00 1.4167165e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4112119e-36]\n",
      "Action prob: [1.0000000e+00 1.4112119e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7057618e-27]\n",
      "Action prob: [1.0000000e+00 4.7057618e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9999638e-33]\n",
      "Action prob: [1.0000000e+00 4.9999638e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8234153e-31]\n",
      "Action prob: [1.0000000e+00 1.8234153e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2747694e-34]\n",
      "Action prob: [1.0000000e+00 1.2747694e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0056213e-34]\n",
      "Action prob: [1.0000000e+00 1.0056213e-34], Action: 0, state: 8\n",
      "[1.000000e+00 2.329877e-34]\n",
      "Action prob: [1.000000e+00 2.329877e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1128747e-27]\n",
      "Action prob: [1.0000000e+00 1.1128747e-27], Action: 0, state: 8\n",
      "[1.00000e+00 2.16233e-39]\n",
      "Action prob: [1.00000e+00 2.16233e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2568675e-27]\n",
      "Action prob: [1.0000000e+00 2.2568675e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.5510256e-33]\n",
      "Action prob: [1.0000000e+00 4.5510256e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.9104334e-28]\n",
      "Action prob: [1.0000000e+00 5.9104334e-28], Action: 0, state: 8\n",
      "[1.000000e+00 7.738998e-30]\n",
      "Action prob: [1.000000e+00 7.738998e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3788964e-27]\n",
      "Action prob: [1.0000000e+00 4.3788964e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.892945e-34]\n",
      "Action prob: [1.000000e+00 7.892945e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1009736e-33]\n",
      "Action prob: [1.0000000e+00 3.1009736e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4317628e-34]\n",
      "Action prob: [1.0000000e+00 2.4317628e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.163577e-30]\n",
      "Action prob: [1.000000e+00 7.163577e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5548034e-33]\n",
      "Action prob: [1.0000000e+00 2.5548034e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8302595e-35]\n",
      "Action prob: [1.0000000e+00 2.8302595e-35], Action: 0, state: 8\n",
      "[1.000000e+00 6.632906e-32]\n",
      "Action prob: [1.000000e+00 6.632906e-32], Action: 0, state: 8\n",
      "[1.000000e+00 7.001134e-29]\n",
      "Action prob: [1.000000e+00 7.001134e-29], Action: 0, state: 8\n",
      "[1.000000e+00 7.144052e-26]\n",
      "Action prob: [1.000000e+00 7.144052e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4200213e-26]\n",
      "Action prob: [1.0000000e+00 1.4200213e-26], Action: 0, state: 8\n",
      "[1.000000e+00 3.927422e-33]\n",
      "Action prob: [1.000000e+00 3.927422e-33], Action: 0, state: 8\n",
      "[1.000000e+00 7.894871e-27]\n",
      "Action prob: [1.000000e+00 7.894871e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3113529e-33]\n",
      "Action prob: [1.0000000e+00 1.3113529e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.6073836e-35]\n",
      "Action prob: [1.0000000e+00 5.6073836e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2529066e-33]\n",
      "Action prob: [1.0000000e+00 1.2529066e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0018636e-37]\n",
      "Action prob: [1.0000000e+00 1.0018636e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0288666e-37]\n",
      "Action prob: [1.0000000e+00 1.0288666e-37], Action: 0, state: 8\n",
      "[1.00000e+00 2.74638e-39]\n",
      "Action prob: [1.00000e+00 2.74638e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9938142e-35]\n",
      "Action prob: [1.0000000e+00 1.9938142e-35], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0.,\n",
      "        0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -131100, loss is -0.0\n",
      "[1.0000000e+00 1.4015059e-30]\n",
      "Action prob: [1.0000000e+00 1.4015059e-30], Action: 0, state: 0\n",
      "[1.000000e+00 9.182929e-30]\n",
      "Action prob: [1.000000e+00 9.182929e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 1.1807356e-30]\n",
      "Action prob: [1.0000000e+00 1.1807356e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 9.4843245e-32]\n",
      "Action prob: [1.0000000e+00 9.4843245e-32], Action: 0, state: 1\n",
      "[1.000000e+00 3.261907e-30]\n",
      "Action prob: [1.000000e+00 3.261907e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.3984618e-30]\n",
      "Action prob: [1.0000000e+00 1.3984618e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 5.8613264e-29]\n",
      "Action prob: [1.0000000e+00 5.8613264e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.1742406e-30]\n",
      "Action prob: [1.0000000e+00 1.1742406e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.1705911e-30]\n",
      "Action prob: [1.0000000e+00 1.1705911e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 4.1623953e-29]\n",
      "Action prob: [1.0000000e+00 4.1623953e-29], Action: 0, state: 2\n",
      "[1.000000e+00 2.323479e-33]\n",
      "Action prob: [1.000000e+00 2.323479e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 2.4018182e-27]\n",
      "Action prob: [1.0000000e+00 2.4018182e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 2.6406634e-32]\n",
      "Action prob: [1.0000000e+00 2.6406634e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3002237e-35]\n",
      "Action prob: [1.0000000e+00 1.3002237e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 1.6040752e-34]\n",
      "Action prob: [1.0000000e+00 1.6040752e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.9595259e-38]\n",
      "Action prob: [1.0000000e+00 1.9595259e-38], Action: 0, state: 9\n",
      "[1.0000000e+00 2.8199023e-28]\n",
      "Action prob: [1.0000000e+00 2.8199023e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 6.4637647e-28]\n",
      "Action prob: [1.0000000e+00 6.4637647e-28], Action: 0, state: 9\n",
      "[1.0000e+00 7.9866e-41]\n",
      "Action prob: [1.0000e+00 7.9866e-41], Action: 0, state: 9\n",
      "[1.0000000e+00 3.2684264e-27]\n",
      "Action prob: [1.0000000e+00 3.2684264e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 8.5962863e-35]\n",
      "Action prob: [1.0000000e+00 8.5962863e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 2.9323388e-33]\n",
      "Action prob: [1.0000000e+00 2.9323388e-33], Action: 0, state: 9\n",
      "[1.00000e+00 5.85576e-37]\n",
      "Action prob: [1.00000e+00 5.85576e-37], Action: 0, state: 9\n",
      "[1.0000000e+00 2.3343068e-27]\n",
      "Action prob: [1.0000000e+00 2.3343068e-27], Action: 0, state: 9\n",
      "[1.000000e+00 9.695121e-28]\n",
      "Action prob: [1.000000e+00 9.695121e-28], Action: 0, state: 9\n",
      "[1.000000e+00 5.066931e-35]\n",
      "Action prob: [1.000000e+00 5.066931e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 2.9781068e-26]\n",
      "Action prob: [1.0000000e+00 2.9781068e-26], Action: 0, state: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 5.260867e-33]\n",
      "Action prob: [1.000000e+00 5.260867e-33], Action: 0, state: 9\n",
      "[1.00000e+00 1.24744e-35]\n",
      "Action prob: [1.00000e+00 1.24744e-35], Action: 0, state: 9\n",
      "[1.00000e+00 2.96825e-34]\n",
      "Action prob: [1.00000e+00 2.96825e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7006757e-36]\n",
      "Action prob: [1.0000000e+00 1.7006757e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 2.2542868e-34]\n",
      "Action prob: [1.0000000e+00 2.2542868e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 5.8276225e-27]\n",
      "Action prob: [1.0000000e+00 5.8276225e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 2.7397605e-36]\n",
      "Action prob: [1.0000000e+00 2.7397605e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 1.9345952e-35]\n",
      "Action prob: [1.0000000e+00 1.9345952e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 2.2880904e-36]\n",
      "Action prob: [1.0000000e+00 2.2880904e-36], Action: 0, state: 9\n",
      "[1.0000e+00 3.0178e-27]\n",
      "Action prob: [1.0000e+00 3.0178e-27], Action: 0, state: 9\n",
      "[1.000000e+00 2.841305e-27]\n",
      "Action prob: [1.000000e+00 2.841305e-27], Action: 0, state: 9\n",
      "[1.000000e+00 4.639244e-34]\n",
      "Action prob: [1.000000e+00 4.639244e-34], Action: 0, state: 9\n",
      "[1.000000e+00 4.387206e-27]\n",
      "Action prob: [1.000000e+00 4.387206e-27], Action: 0, state: 9\n",
      "[1.000000e+00 2.228108e-27]\n",
      "Action prob: [1.000000e+00 2.228108e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.9107042e-31]\n",
      "Action prob: [1.0000000e+00 1.9107042e-31], Action: 0, state: 9\n",
      "[1.000000e+00 1.339511e-39]\n",
      "Action prob: [1.000000e+00 1.339511e-39], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2263319e-33]\n",
      "Action prob: [1.0000000e+00 1.2263319e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 3.6525504e-37]\n",
      "Action prob: [1.0000000e+00 3.6525504e-37], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0706288e-35]\n",
      "Action prob: [1.0000000e+00 1.0706288e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 1.5626974e-33]\n",
      "Action prob: [1.0000000e+00 1.5626974e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0853953e-36]\n",
      "Action prob: [1.0000000e+00 1.0853953e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 1.4212725e-27]\n",
      "Action prob: [1.0000000e+00 1.4212725e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 2.8102826e-34]\n",
      "Action prob: [1.0000000e+00 2.8102826e-34], Action: 0, state: 9\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -32900, loss is -0.0\n",
      "[1.0000000e+00 1.6268618e-29]\n",
      "Action prob: [1.0000000e+00 1.6268618e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.5078763e-29]\n",
      "Action prob: [1.0000000e+00 1.5078763e-29], Action: 0, state: 1\n",
      "[1.000000e+00 8.030664e-30]\n",
      "Action prob: [1.000000e+00 8.030664e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.2686305e-30]\n",
      "Action prob: [1.0000000e+00 1.2686305e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.1214186e-28]\n",
      "Action prob: [1.0000000e+00 1.1214186e-28], Action: 0, state: 1\n",
      "[1.000000e+00 5.942175e-35]\n",
      "Action prob: [1.000000e+00 5.942175e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 2.1605945e-27]\n",
      "Action prob: [1.0000000e+00 2.1605945e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1411364e-34]\n",
      "Action prob: [1.0000000e+00 1.1411364e-34], Action: 0, state: 9\n",
      "[1.000000e+00 8.526657e-35]\n",
      "Action prob: [1.000000e+00 8.526657e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 4.8493267e-27]\n",
      "Action prob: [1.0000000e+00 4.8493267e-27], Action: 0, state: 9\n",
      "[1.000000e+00 2.430862e-35]\n",
      "Action prob: [1.000000e+00 2.430862e-35], Action: 0, state: 9\n",
      "[1.000000e+00 7.588338e-35]\n",
      "Action prob: [1.000000e+00 7.588338e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 2.7987674e-29]\n",
      "Action prob: [1.0000000e+00 2.7987674e-29], Action: 0, state: 9\n",
      "[1.000000e+00 5.431582e-37]\n",
      "Action prob: [1.000000e+00 5.431582e-37], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3716747e-30]\n",
      "Action prob: [1.0000000e+00 1.3716747e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 6.0300706e-26]\n",
      "Action prob: [1.0000000e+00 6.0300706e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 4.3974156e-32]\n",
      "Action prob: [1.0000000e+00 4.3974156e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 4.6680892e-35]\n",
      "Action prob: [1.0000000e+00 4.6680892e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1750268e-34]\n",
      "Action prob: [1.0000000e+00 1.1750268e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 3.3899694e-31]\n",
      "Action prob: [1.0000000e+00 3.3899694e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 4.2689556e-32]\n",
      "Action prob: [1.0000000e+00 4.2689556e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1580419e-26]\n",
      "Action prob: [1.0000000e+00 1.1580419e-26], Action: 0, state: 9\n",
      "[1.000000e+00 7.639023e-34]\n",
      "Action prob: [1.000000e+00 7.639023e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 3.1259498e-26]\n",
      "Action prob: [1.0000000e+00 3.1259498e-26], Action: 0, state: 9\n",
      "[1.000000e+00 4.236944e-33]\n",
      "Action prob: [1.000000e+00 4.236944e-33], Action: 0, state: 9\n",
      "[1.000000e+00 5.951702e-28]\n",
      "Action prob: [1.000000e+00 5.951702e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 2.4278327e-34]\n",
      "Action prob: [1.0000000e+00 2.4278327e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2871221e-34]\n",
      "Action prob: [1.0000000e+00 1.2871221e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 2.6127156e-26]\n",
      "Action prob: [1.0000000e+00 2.6127156e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.5106825e-26]\n",
      "Action prob: [1.0000000e+00 1.5106825e-26], Action: 0, state: 9\n",
      "[1.000000e+00 6.896228e-27]\n",
      "Action prob: [1.000000e+00 6.896228e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 3.2545913e-27]\n",
      "Action prob: [1.0000000e+00 3.2545913e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 2.2702763e-28]\n",
      "Action prob: [1.0000000e+00 2.2702763e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7718069e-35]\n",
      "Action prob: [1.0000000e+00 1.7718069e-35], Action: 0, state: 9\n",
      "[1.00000e+00 9.26157e-27]\n",
      "Action prob: [1.00000e+00 9.26157e-27], Action: 0, state: 9\n",
      "[1.000000e+00 9.268306e-30]\n",
      "Action prob: [1.000000e+00 9.268306e-30], Action: 0, state: 9\n",
      "[1.000000e+00 5.718632e-28]\n",
      "Action prob: [1.000000e+00 5.718632e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 7.6637996e-35]\n",
      "Action prob: [1.0000000e+00 7.6637996e-35], Action: 0, state: 9\n",
      "[1.000000e+00 9.499699e-35]\n",
      "Action prob: [1.000000e+00 9.499699e-35], Action: 0, state: 9\n",
      "[1.000000e+00 5.891352e-33]\n",
      "Action prob: [1.000000e+00 5.891352e-33], Action: 0, state: 9\n",
      "[1.000000e+00 6.190067e-35]\n",
      "Action prob: [1.000000e+00 6.190067e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 3.2417023e-36]\n",
      "Action prob: [1.0000000e+00 3.2417023e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 1.4666074e-26]\n",
      "Action prob: [1.0000000e+00 1.4666074e-26], Action: 0, state: 9\n",
      "[1.000000e+00 3.279399e-30]\n",
      "Action prob: [1.000000e+00 3.279399e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 1.6886344e-26]\n",
      "Action prob: [1.0000000e+00 1.6886344e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.9476205e-27]\n",
      "Action prob: [1.0000000e+00 1.9476205e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 3.2096874e-27]\n",
      "Action prob: [1.0000000e+00 3.2096874e-27], Action: 0, state: 9\n",
      "[1.00000e+00 6.12863e-26]\n",
      "Action prob: [1.00000e+00 6.12863e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0730914e-33]\n",
      "Action prob: [1.0000000e+00 1.0730914e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 2.0650157e-26]\n",
      "Action prob: [1.0000000e+00 2.0650157e-26], Action: 0, state: 9\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -42400, loss is -0.0\n",
      "[1.0000000e+00 2.8406613e-30]\n",
      "Action prob: [1.0000000e+00 2.8406613e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 1.1378514e-32]\n",
      "Action prob: [1.0000000e+00 1.1378514e-32], Action: 0, state: 1\n",
      "[1.0000000e+00 2.0553696e-29]\n",
      "Action prob: [1.0000000e+00 2.0553696e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 3.8044144e-31]\n",
      "Action prob: [1.0000000e+00 3.8044144e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 1.2594219e-28]\n",
      "Action prob: [1.0000000e+00 1.2594219e-28], Action: 0, state: 1\n",
      "[1.000000e+00 5.702879e-29]\n",
      "Action prob: [1.000000e+00 5.702879e-29], Action: 0, state: 2\n",
      "[1.000000e+00 5.083483e-28]\n",
      "Action prob: [1.000000e+00 5.083483e-28], Action: 0, state: 2\n",
      "[1.0000000e+00 6.3560475e-31]\n",
      "Action prob: [1.0000000e+00 6.3560475e-31], Action: 0, state: 2\n",
      "[1.0000000e+00 2.7025247e-30]\n",
      "Action prob: [1.0000000e+00 2.7025247e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 4.2159387e-32]\n",
      "Action prob: [1.0000000e+00 4.2159387e-32], Action: 0, state: 3\n",
      "[1.00000e+00 5.93972e-30]\n",
      "Action prob: [1.00000e+00 5.93972e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5144087e-35]\n",
      "Action prob: [1.0000000e+00 1.5144087e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1574213e-30]\n",
      "Action prob: [1.0000000e+00 1.1574213e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0592221e-27]\n",
      "Action prob: [1.0000000e+00 1.0592221e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.688446e-32]\n",
      "Action prob: [1.000000e+00 9.688446e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0321428e-34]\n",
      "Action prob: [1.0000000e+00 1.0321428e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4446602e-35]\n",
      "Action prob: [1.0000000e+00 3.4446602e-35], Action: 0, state: 8\n",
      "[1.000000e+00 7.840583e-33]\n",
      "Action prob: [1.000000e+00 7.840583e-33], Action: 0, state: 8\n",
      "[1.000000e+00 1.835781e-33]\n",
      "Action prob: [1.000000e+00 1.835781e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 7.1455325e-31]\n",
      "Action prob: [1.0000000e+00 7.1455325e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3170525e-34]\n",
      "Action prob: [1.0000000e+00 1.3170525e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2844496e-33]\n",
      "Action prob: [1.0000000e+00 1.2844496e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2557142e-27]\n",
      "Action prob: [1.0000000e+00 2.2557142e-27], Action: 0, state: 8\n",
      "[1.00000e+00 1.89454e-32]\n",
      "Action prob: [1.00000e+00 1.89454e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 9.0189495e-33]\n",
      "Action prob: [1.0000000e+00 9.0189495e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4884993e-27]\n",
      "Action prob: [1.0000000e+00 2.4884993e-27], Action: 0, state: 8\n",
      "[1.00000e+00 9.10679e-27]\n",
      "Action prob: [1.00000e+00 9.10679e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0138433e-33]\n",
      "Action prob: [1.0000000e+00 2.0138433e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6733775e-28]\n",
      "Action prob: [1.0000000e+00 1.6733775e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5319253e-26]\n",
      "Action prob: [1.0000000e+00 2.5319253e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 7.2346747e-38]\n",
      "Action prob: [1.0000000e+00 7.2346747e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0372021e-27]\n",
      "Action prob: [1.0000000e+00 3.0372021e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7149859e-32]\n",
      "Action prob: [1.0000000e+00 1.7149859e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2320083e-36]\n",
      "Action prob: [1.0000000e+00 1.2320083e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9229197e-34]\n",
      "Action prob: [1.0000000e+00 1.9229197e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 9.3436476e-35]\n",
      "Action prob: [1.0000000e+00 9.3436476e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7616195e-27]\n",
      "Action prob: [1.0000000e+00 2.7616195e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.728889e-32]\n",
      "Action prob: [1.000000e+00 9.728889e-32], Action: 0, state: 8\n",
      "[1.000000e+00 4.063789e-28]\n",
      "Action prob: [1.000000e+00 4.063789e-28], Action: 0, state: 8\n",
      "[1.000000e+00 6.297271e-34]\n",
      "Action prob: [1.000000e+00 6.297271e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 5.4989924e-34]\n",
      "Action prob: [1.0000000e+00 5.4989924e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3798857e-26]\n",
      "Action prob: [1.0000000e+00 1.3798857e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9624257e-33]\n",
      "Action prob: [1.0000000e+00 1.9624257e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 9.5010037e-35]\n",
      "Action prob: [1.0000000e+00 9.5010037e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9070144e-34]\n",
      "Action prob: [1.0000000e+00 4.9070144e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2585441e-34]\n",
      "Action prob: [1.0000000e+00 1.2585441e-34], Action: 0, state: 8\n",
      "[1.000000e+00 6.980312e-35]\n",
      "Action prob: [1.000000e+00 6.980312e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4466095e-34]\n",
      "Action prob: [1.0000000e+00 1.4466095e-34], Action: 0, state: 8\n",
      "[1.000000e+00 8.349624e-35]\n",
      "Action prob: [1.000000e+00 8.349624e-35], Action: 0, state: 8\n",
      "[1.000000e+00 1.227768e-27]\n",
      "Action prob: [1.000000e+00 1.227768e-27], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -115700, loss is -0.0\n",
      "[1.000000e+00 8.891538e-31]\n",
      "Action prob: [1.000000e+00 8.891538e-31], Action: 0, state: 0\n",
      "[1.000000e+00 3.951763e-28]\n",
      "Action prob: [1.000000e+00 3.951763e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 7.3291734e-31]\n",
      "Action prob: [1.0000000e+00 7.3291734e-31], Action: 0, state: 2\n",
      "[1.0000000e+00 1.5742414e-30]\n",
      "Action prob: [1.0000000e+00 1.5742414e-30], Action: 0, state: 3\n",
      "[1.00000e+00 6.02675e-29]\n",
      "Action prob: [1.00000e+00 6.02675e-29], Action: 0, state: 3\n",
      "[1.000000e+00 4.132273e-29]\n",
      "Action prob: [1.000000e+00 4.132273e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 2.0115507e-30]\n",
      "Action prob: [1.0000000e+00 2.0115507e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 2.6640037e-33]\n",
      "Action prob: [1.0000000e+00 2.6640037e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9931344e-30]\n",
      "Action prob: [1.0000000e+00 2.9931344e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 6.6898046e-31]\n",
      "Action prob: [1.0000000e+00 6.6898046e-31], Action: 0, state: 8\n",
      "[1.000000e+00 5.094397e-34]\n",
      "Action prob: [1.000000e+00 5.094397e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5034122e-32]\n",
      "Action prob: [1.0000000e+00 3.5034122e-32], Action: 0, state: 8\n",
      "[1.000000e+00 2.643226e-30]\n",
      "Action prob: [1.000000e+00 2.643226e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2836745e-26]\n",
      "Action prob: [1.0000000e+00 3.2836745e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3658702e-35]\n",
      "Action prob: [1.0000000e+00 1.3658702e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0862815e-26]\n",
      "Action prob: [1.0000000e+00 5.0862815e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2584964e-26]\n",
      "Action prob: [1.0000000e+00 2.2584964e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 8.2743126e-29]\n",
      "Action prob: [1.0000000e+00 8.2743126e-29], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 1.774402e-30]\n",
      "Action prob: [1.000000e+00 1.774402e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 7.2726774e-35]\n",
      "Action prob: [1.0000000e+00 7.2726774e-35], Action: 0, state: 8\n",
      "[1.000000e+00 6.784883e-35]\n",
      "Action prob: [1.000000e+00 6.784883e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0451245e-30]\n",
      "Action prob: [1.0000000e+00 1.0451245e-30], Action: 0, state: 8\n",
      "[1.000000e+00 2.829257e-34]\n",
      "Action prob: [1.000000e+00 2.829257e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0349892e-35]\n",
      "Action prob: [1.0000000e+00 3.0349892e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 9.0976925e-27]\n",
      "Action prob: [1.0000000e+00 9.0976925e-27], Action: 0, state: 8\n",
      "[1.000000e+00 4.189097e-27]\n",
      "Action prob: [1.000000e+00 4.189097e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 6.0209427e-27]\n",
      "Action prob: [1.0000000e+00 6.0209427e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2152764e-34]\n",
      "Action prob: [1.0000000e+00 3.2152764e-34], Action: 0, state: 8\n",
      "[1.000000e+00 8.691881e-27]\n",
      "Action prob: [1.000000e+00 8.691881e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.0067692e-34]\n",
      "Action prob: [1.0000000e+00 3.0067692e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6976946e-28]\n",
      "Action prob: [1.0000000e+00 1.6976946e-28], Action: 0, state: 8\n",
      "[1.000000e+00 4.128168e-33]\n",
      "Action prob: [1.000000e+00 4.128168e-33], Action: 0, state: 8\n",
      "[1.000000e+00 3.667844e-27]\n",
      "Action prob: [1.000000e+00 3.667844e-27], Action: 0, state: 8\n",
      "[1.000000e+00 4.362105e-28]\n",
      "Action prob: [1.000000e+00 4.362105e-28], Action: 0, state: 8\n",
      "[1.00000000e+00 1.60059685e-27]\n",
      "Action prob: [1.00000000e+00 1.60059685e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3523592e-35]\n",
      "Action prob: [1.0000000e+00 1.3523592e-35], Action: 0, state: 8\n",
      "[1.000000e+00 9.554922e-39]\n",
      "Action prob: [1.000000e+00 9.554922e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2971652e-35]\n",
      "Action prob: [1.0000000e+00 3.2971652e-35], Action: 0, state: 8\n",
      "[1.000000e+00 8.456447e-31]\n",
      "Action prob: [1.000000e+00 8.456447e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9888089e-27]\n",
      "Action prob: [1.0000000e+00 1.9888089e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9777183e-27]\n",
      "Action prob: [1.0000000e+00 3.9777183e-27], Action: 0, state: 8\n",
      "[1.000000e+00 8.212561e-27]\n",
      "Action prob: [1.000000e+00 8.212561e-27], Action: 0, state: 8\n",
      "[1.000000e+00 5.455182e-33]\n",
      "Action prob: [1.000000e+00 5.455182e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4613404e-27]\n",
      "Action prob: [1.0000000e+00 1.4613404e-27], Action: 0, state: 8\n",
      "[1.000000e+00 9.366527e-34]\n",
      "Action prob: [1.000000e+00 9.366527e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8730414e-30]\n",
      "Action prob: [1.0000000e+00 1.8730414e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2531268e-26]\n",
      "Action prob: [1.0000000e+00 2.2531268e-26], Action: 0, state: 8\n",
      "[1.000000e+00 4.946838e-35]\n",
      "Action prob: [1.000000e+00 4.946838e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3416518e-26]\n",
      "Action prob: [1.0000000e+00 1.3416518e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1716024e-35]\n",
      "Action prob: [1.0000000e+00 4.1716024e-35], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0., 0., 0., -0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -128300, loss is -0.0\n",
      "[1.000000e+00 6.647656e-30]\n",
      "Action prob: [1.000000e+00 6.647656e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 7.1519686e-31]\n",
      "Action prob: [1.0000000e+00 7.1519686e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 4.5570804e-29]\n",
      "Action prob: [1.0000000e+00 4.5570804e-29], Action: 0, state: 1\n",
      "[1.00000e+00 8.43226e-30]\n",
      "Action prob: [1.00000e+00 8.43226e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 1.9843508e-29]\n",
      "Action prob: [1.0000000e+00 1.9843508e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 3.5006147e-35]\n",
      "Action prob: [1.0000000e+00 3.5006147e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.4713075e-35]\n",
      "Action prob: [1.0000000e+00 5.4713075e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7855553e-33]\n",
      "Action prob: [1.0000000e+00 1.7855553e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1087086e-28]\n",
      "Action prob: [1.0000000e+00 2.1087086e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9745155e-33]\n",
      "Action prob: [1.0000000e+00 1.9745155e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8656702e-35]\n",
      "Action prob: [1.0000000e+00 1.8656702e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 7.5531775e-31]\n",
      "Action prob: [1.0000000e+00 7.5531775e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4848947e-27]\n",
      "Action prob: [1.0000000e+00 2.4848947e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9191804e-36]\n",
      "Action prob: [1.0000000e+00 1.9191804e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8308853e-33]\n",
      "Action prob: [1.0000000e+00 1.8308853e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7907785e-35]\n",
      "Action prob: [1.0000000e+00 1.7907785e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 8.3521726e-35]\n",
      "Action prob: [1.0000000e+00 8.3521726e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1707903e-33]\n",
      "Action prob: [1.0000000e+00 1.1707903e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5330439e-27]\n",
      "Action prob: [1.0000000e+00 1.5330439e-27], Action: 0, state: 8\n",
      "[1.000000e+00 5.614404e-35]\n",
      "Action prob: [1.000000e+00 5.614404e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6666548e-27]\n",
      "Action prob: [1.0000000e+00 3.6666548e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1551993e-28]\n",
      "Action prob: [1.0000000e+00 1.1551993e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9209066e-33]\n",
      "Action prob: [1.0000000e+00 2.9209066e-33], Action: 0, state: 8\n",
      "[1.000e+00 8.436e-41]\n",
      "Action prob: [1.000e+00 8.436e-41], Action: 0, state: 8\n",
      "[1.000000e+00 2.072441e-34]\n",
      "Action prob: [1.000000e+00 2.072441e-34], Action: 0, state: 8\n",
      "[1.000000e+00 4.800276e-35]\n",
      "Action prob: [1.000000e+00 4.800276e-35], Action: 0, state: 8\n",
      "[1.00000e+00 7.54898e-29]\n",
      "Action prob: [1.00000e+00 7.54898e-29], Action: 0, state: 8\n",
      "[1.000000e+00 4.909491e-32]\n",
      "Action prob: [1.000000e+00 4.909491e-32], Action: 0, state: 8\n",
      "[1.000000e+00 7.674273e-35]\n",
      "Action prob: [1.000000e+00 7.674273e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4679471e-27]\n",
      "Action prob: [1.0000000e+00 2.4679471e-27], Action: 0, state: 8\n",
      "[1.000000e+00 4.796876e-33]\n",
      "Action prob: [1.000000e+00 4.796876e-33], Action: 0, state: 8\n",
      "[1.000000e+00 6.085171e-30]\n",
      "Action prob: [1.000000e+00 6.085171e-30], Action: 0, state: 8\n",
      "[1.000e+00 5.317e-42]\n",
      "Action prob: [1.000e+00 5.317e-42], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3481462e-33]\n",
      "Action prob: [1.0000000e+00 3.3481462e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0773445e-26]\n",
      "Action prob: [1.0000000e+00 5.0773445e-26], Action: 0, state: 8\n",
      "[1.000000e+00 4.391314e-32]\n",
      "Action prob: [1.000000e+00 4.391314e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1720415e-33]\n",
      "Action prob: [1.0000000e+00 2.1720415e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 6.8568817e-34]\n",
      "Action prob: [1.0000000e+00 6.8568817e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4382458e-34]\n",
      "Action prob: [1.0000000e+00 1.4382458e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1305617e-30]\n",
      "Action prob: [1.0000000e+00 3.1305617e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8435752e-34]\n",
      "Action prob: [1.0000000e+00 3.8435752e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 5.4955954e-34]\n",
      "Action prob: [1.0000000e+00 5.4955954e-34], Action: 0, state: 8\n",
      "[1.000000e+00 9.642968e-35]\n",
      "Action prob: [1.000000e+00 9.642968e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9793603e-33]\n",
      "Action prob: [1.0000000e+00 3.9793603e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.9137403e-26]\n",
      "Action prob: [1.0000000e+00 4.9137403e-26], Action: 0, state: 8\n",
      "[1.000000e+00 5.072622e-33]\n",
      "Action prob: [1.000000e+00 5.072622e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2974888e-35]\n",
      "Action prob: [1.0000000e+00 1.2974888e-35], Action: 0, state: 8\n",
      "[1.000000e+00 4.998892e-27]\n",
      "Action prob: [1.000000e+00 4.998892e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7085044e-27]\n",
      "Action prob: [1.0000000e+00 2.7085044e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7930115e-34]\n",
      "Action prob: [1.0000000e+00 2.7930115e-34], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0., 0., 0., 0., 0., 0., 0., -0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -134900, loss is -0.0\n",
      "[1.0000000e+00 7.7427524e-29]\n",
      "Action prob: [1.0000000e+00 7.7427524e-29], Action: 0, state: 0\n",
      "[1.000000e+00 4.125797e-30]\n",
      "Action prob: [1.000000e+00 4.125797e-30], Action: 0, state: 0\n",
      "[1.000000e+00 5.831886e-29]\n",
      "Action prob: [1.000000e+00 5.831886e-29], Action: 0, state: 0\n",
      "[1.000000e+00 2.710569e-29]\n",
      "Action prob: [1.000000e+00 2.710569e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 2.8490516e-29]\n",
      "Action prob: [1.0000000e+00 2.8490516e-29], Action: 0, state: 0\n",
      "[1.000000e+00 5.248525e-31]\n",
      "Action prob: [1.000000e+00 5.248525e-31], Action: 0, state: 0\n",
      "[1.0000000e+00 2.8068506e-29]\n",
      "Action prob: [1.0000000e+00 2.8068506e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.4219604e-28]\n",
      "Action prob: [1.0000000e+00 1.4219604e-28], Action: 0, state: 2\n",
      "[1.0000000e+00 1.1770481e-30]\n",
      "Action prob: [1.0000000e+00 1.1770481e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 1.9588707e-28]\n",
      "Action prob: [1.0000000e+00 1.9588707e-28], Action: 0, state: 2\n",
      "[1.000000e+00 6.530805e-29]\n",
      "Action prob: [1.000000e+00 6.530805e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 3.2159912e-32]\n",
      "Action prob: [1.0000000e+00 3.2159912e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2110215e-36]\n",
      "Action prob: [1.0000000e+00 1.2110215e-36], Action: 0, state: 8\n",
      "[1.000000e+00 2.327552e-32]\n",
      "Action prob: [1.000000e+00 2.327552e-32], Action: 0, state: 8\n",
      "[1.000000e+00 9.524196e-34]\n",
      "Action prob: [1.000000e+00 9.524196e-34], Action: 0, state: 8\n",
      "[1.000000e+00 6.965735e-35]\n",
      "Action prob: [1.000000e+00 6.965735e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1080436e-33]\n",
      "Action prob: [1.0000000e+00 2.1080436e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0299722e-36]\n",
      "Action prob: [1.0000000e+00 5.0299722e-36], Action: 0, state: 8\n",
      "[1.000000e+00 7.616535e-33]\n",
      "Action prob: [1.000000e+00 7.616535e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 6.5084747e-28]\n",
      "Action prob: [1.0000000e+00 6.5084747e-28], Action: 0, state: 8\n",
      "[1.000000e+00 3.607263e-34]\n",
      "Action prob: [1.000000e+00 3.607263e-34], Action: 0, state: 8\n",
      "[1.00000e+00 5.19527e-27]\n",
      "Action prob: [1.00000e+00 5.19527e-27], Action: 0, state: 8\n",
      "[1.000000e+00 8.438734e-36]\n",
      "Action prob: [1.000000e+00 8.438734e-36], Action: 0, state: 8\n",
      "[1.000000e+00 6.112517e-27]\n",
      "Action prob: [1.000000e+00 6.112517e-27], Action: 0, state: 8\n",
      "[1.000000e+00 8.497332e-36]\n",
      "Action prob: [1.000000e+00 8.497332e-36], Action: 0, state: 8\n",
      "[1.000e+00 7.451e-42]\n",
      "Action prob: [1.000e+00 7.451e-42], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0939018e-37]\n",
      "Action prob: [1.0000000e+00 2.0939018e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0497021e-25]\n",
      "Action prob: [1.0000000e+00 1.0497021e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0897775e-34]\n",
      "Action prob: [1.0000000e+00 1.0897775e-34], Action: 0, state: 8\n",
      "[1.000000e+00 1.846406e-34]\n",
      "Action prob: [1.000000e+00 1.846406e-34], Action: 0, state: 8\n",
      "[1.00000e+00 7.88542e-27]\n",
      "Action prob: [1.00000e+00 7.88542e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1073358e-27]\n",
      "Action prob: [1.0000000e+00 1.1073358e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4152618e-33]\n",
      "Action prob: [1.0000000e+00 2.4152618e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8554816e-28]\n",
      "Action prob: [1.0000000e+00 3.8554816e-28], Action: 0, state: 8\n",
      "[1.000000e+00 9.717487e-35]\n",
      "Action prob: [1.000000e+00 9.717487e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6370215e-29]\n",
      "Action prob: [1.0000000e+00 1.6370215e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5388323e-35]\n",
      "Action prob: [1.0000000e+00 1.5388323e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4708868e-34]\n",
      "Action prob: [1.0000000e+00 2.4708868e-34], Action: 0, state: 8\n",
      "[1.000000e+00 3.816779e-34]\n",
      "Action prob: [1.000000e+00 3.816779e-34], Action: 0, state: 8\n",
      "[1.000000e+00 5.002803e-27]\n",
      "Action prob: [1.000000e+00 5.002803e-27], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 3.3845234e-27]\n",
      "Action prob: [1.0000000e+00 3.3845234e-27], Action: 0, state: 8\n",
      "[1.000000e+00 4.520021e-33]\n",
      "Action prob: [1.000000e+00 4.520021e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6371882e-36]\n",
      "Action prob: [1.0000000e+00 3.6371882e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3668845e-33]\n",
      "Action prob: [1.0000000e+00 2.3668845e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2441452e-34]\n",
      "Action prob: [1.0000000e+00 2.2441452e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1691006e-27]\n",
      "Action prob: [1.0000000e+00 2.1691006e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2657066e-29]\n",
      "Action prob: [1.0000000e+00 1.2657066e-29], Action: 0, state: 8\n",
      "[1.000000e+00 9.908162e-28]\n",
      "Action prob: [1.000000e+00 9.908162e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0546695e-36]\n",
      "Action prob: [1.0000000e+00 5.0546695e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8378944e-32]\n",
      "Action prob: [1.0000000e+00 3.8378944e-32], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0., 0., 0., 0.,\n",
      "        0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -111200, loss is -0.0\n",
      "[1.0000000e+00 3.4581793e-29]\n",
      "Action prob: [1.0000000e+00 3.4581793e-29], Action: 0, state: 0\n",
      "[1.000000e+00 8.238498e-30]\n",
      "Action prob: [1.000000e+00 8.238498e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 1.3408407e-30]\n",
      "Action prob: [1.0000000e+00 1.3408407e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 1.8441432e-30]\n",
      "Action prob: [1.0000000e+00 1.8441432e-30], Action: 0, state: 0\n",
      "[1.000000e+00 2.266081e-27]\n",
      "Action prob: [1.000000e+00 2.266081e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 2.3472113e-33]\n",
      "Action prob: [1.0000000e+00 2.3472113e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3588035e-26]\n",
      "Action prob: [1.0000000e+00 1.3588035e-26], Action: 0, state: 9\n",
      "[1.000000e+00 7.756598e-34]\n",
      "Action prob: [1.000000e+00 7.756598e-34], Action: 0, state: 9\n",
      "[1.000000e+00 5.659647e-35]\n",
      "Action prob: [1.000000e+00 5.659647e-35], Action: 0, state: 9\n",
      "[1.000000e+00 4.941685e-29]\n",
      "Action prob: [1.000000e+00 4.941685e-29], Action: 0, state: 9\n",
      "[1.0000000e+00 1.5313606e-27]\n",
      "Action prob: [1.0000000e+00 1.5313606e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1166672e-36]\n",
      "Action prob: [1.0000000e+00 1.1166672e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0681291e-26]\n",
      "Action prob: [1.0000000e+00 1.0681291e-26], Action: 0, state: 9\n",
      "[1.000000e+00 5.803397e-27]\n",
      "Action prob: [1.000000e+00 5.803397e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 2.8251364e-27]\n",
      "Action prob: [1.0000000e+00 2.8251364e-27], Action: 0, state: 9\n",
      "[1.00000e+00 2.70795e-40]\n",
      "Action prob: [1.00000e+00 2.70795e-40], Action: 0, state: 9\n",
      "[1.0000000e+00 1.9184357e-34]\n",
      "Action prob: [1.0000000e+00 1.9184357e-34], Action: 0, state: 9\n",
      "[1.000000e+00 9.376681e-34]\n",
      "Action prob: [1.000000e+00 9.376681e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0408853e-26]\n",
      "Action prob: [1.0000000e+00 1.0408853e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3398358e-34]\n",
      "Action prob: [1.0000000e+00 1.3398358e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3317599e-33]\n",
      "Action prob: [1.0000000e+00 1.3317599e-33], Action: 0, state: 9\n",
      "[1.000000e+00 8.311454e-36]\n",
      "Action prob: [1.000000e+00 8.311454e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 3.3673695e-27]\n",
      "Action prob: [1.0000000e+00 3.3673695e-27], Action: 0, state: 9\n",
      "[1.000000e+00 1.293858e-32]\n",
      "Action prob: [1.000000e+00 1.293858e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0291985e-33]\n",
      "Action prob: [1.0000000e+00 1.0291985e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1815932e-35]\n",
      "Action prob: [1.0000000e+00 1.1815932e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1448437e-32]\n",
      "Action prob: [1.0000000e+00 1.1448437e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.4403713e-33]\n",
      "Action prob: [1.0000000e+00 1.4403713e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 4.1348146e-35]\n",
      "Action prob: [1.0000000e+00 4.1348146e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 4.1515033e-28]\n",
      "Action prob: [1.0000000e+00 4.1515033e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 8.5324855e-34]\n",
      "Action prob: [1.0000000e+00 8.5324855e-34], Action: 0, state: 9\n",
      "[1.000000e+00 4.015788e-27]\n",
      "Action prob: [1.000000e+00 4.015788e-27], Action: 0, state: 9\n",
      "[1.00000e+00 8.66555e-37]\n",
      "Action prob: [1.00000e+00 8.66555e-37], Action: 0, state: 9\n",
      "[1.00000e+00 4.89998e-27]\n",
      "Action prob: [1.00000e+00 4.89998e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 2.8717854e-33]\n",
      "Action prob: [1.0000000e+00 2.8717854e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.6893165e-27]\n",
      "Action prob: [1.0000000e+00 1.6893165e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 3.6762337e-35]\n",
      "Action prob: [1.0000000e+00 3.6762337e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 2.4530721e-33]\n",
      "Action prob: [1.0000000e+00 2.4530721e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.6726456e-33]\n",
      "Action prob: [1.0000000e+00 1.6726456e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 3.7580886e-36]\n",
      "Action prob: [1.0000000e+00 3.7580886e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7239776e-33]\n",
      "Action prob: [1.0000000e+00 1.7239776e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 7.5812455e-36]\n",
      "Action prob: [1.0000000e+00 7.5812455e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 2.1996097e-31]\n",
      "Action prob: [1.0000000e+00 2.1996097e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 5.6867235e-34]\n",
      "Action prob: [1.0000000e+00 5.6867235e-34], Action: 0, state: 9\n",
      "[1.000000e+00 7.390988e-26]\n",
      "Action prob: [1.000000e+00 7.390988e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 3.2164606e-30]\n",
      "Action prob: [1.0000000e+00 3.2164606e-30], Action: 0, state: 9\n",
      "[1.00000e+00 2.57332e-39]\n",
      "Action prob: [1.00000e+00 2.57332e-39], Action: 0, state: 9\n",
      "[1.00000000e+00 1.21317245e-27]\n",
      "Action prob: [1.00000000e+00 1.21317245e-27], Action: 0, state: 9\n",
      "[1.000000e+00 3.743526e-27]\n",
      "Action prob: [1.000000e+00 3.743526e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 3.2288704e-34]\n",
      "Action prob: [1.0000000e+00 3.2288704e-34], Action: 0, state: 9\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -44000, loss is -0.0\n",
      "[1.0000000e+00 1.2440698e-29]\n",
      "Action prob: [1.0000000e+00 1.2440698e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.6128974e-28]\n",
      "Action prob: [1.0000000e+00 1.6128974e-28], Action: 0, state: 1\n",
      "[1.0000000e+00 1.4641687e-28]\n",
      "Action prob: [1.0000000e+00 1.4641687e-28], Action: 0, state: 2\n",
      "[1.000000e+00 1.451445e-28]\n",
      "Action prob: [1.000000e+00 1.451445e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 7.5954045e-35]\n",
      "Action prob: [1.0000000e+00 7.5954045e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3313942e-33]\n",
      "Action prob: [1.0000000e+00 1.3313942e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8985386e-27]\n",
      "Action prob: [1.0000000e+00 2.8985386e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7594173e-34]\n",
      "Action prob: [1.0000000e+00 4.7594173e-34], Action: 0, state: 8\n",
      "[1.000000e+00 5.239192e-35]\n",
      "Action prob: [1.000000e+00 5.239192e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3434509e-28]\n",
      "Action prob: [1.0000000e+00 2.3434509e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1268392e-35]\n",
      "Action prob: [1.0000000e+00 1.1268392e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3173539e-34]\n",
      "Action prob: [1.0000000e+00 1.3173539e-34], Action: 0, state: 8\n",
      "[1.000000e+00 9.360139e-33]\n",
      "Action prob: [1.000000e+00 9.360139e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.4683844e-28]\n",
      "Action prob: [1.0000000e+00 5.4683844e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4647063e-38]\n",
      "Action prob: [1.0000000e+00 2.4647063e-38], Action: 0, state: 8\n",
      "[1.00000e+00 1.80919e-40]\n",
      "Action prob: [1.00000e+00 1.80919e-40], Action: 0, state: 8\n",
      "[1.000000e+00 8.752498e-28]\n",
      "Action prob: [1.000000e+00 8.752498e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 9.3385874e-35]\n",
      "Action prob: [1.0000000e+00 9.3385874e-35], Action: 0, state: 8\n",
      "[1.00000000e+00 1.43287435e-33]\n",
      "Action prob: [1.00000000e+00 1.43287435e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9856986e-29]\n",
      "Action prob: [1.0000000e+00 1.9856986e-29], Action: 0, state: 8\n",
      "[1.000000e+00 7.111666e-34]\n",
      "Action prob: [1.000000e+00 7.111666e-34], Action: 0, state: 8\n",
      "[1.0000e+00 7.3572e-27]\n",
      "Action prob: [1.0000e+00 7.3572e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2404509e-34]\n",
      "Action prob: [1.0000000e+00 1.2404509e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9179902e-33]\n",
      "Action prob: [1.0000000e+00 1.9179902e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0156061e-34]\n",
      "Action prob: [1.0000000e+00 1.0156061e-34], Action: 0, state: 8\n",
      "[1.000000e+00 6.949135e-31]\n",
      "Action prob: [1.000000e+00 6.949135e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 8.0770656e-35]\n",
      "Action prob: [1.0000000e+00 8.0770656e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0204487e-34]\n",
      "Action prob: [1.0000000e+00 4.0204487e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.672091e-39]\n",
      "Action prob: [1.000000e+00 7.672091e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6376962e-29]\n",
      "Action prob: [1.0000000e+00 1.6376962e-29], Action: 0, state: 8\n",
      "[1.000000e+00 2.301087e-30]\n",
      "Action prob: [1.000000e+00 2.301087e-30], Action: 0, state: 8\n",
      "[1.000000e+00 4.288046e-27]\n",
      "Action prob: [1.000000e+00 4.288046e-27], Action: 0, state: 8\n",
      "[1.000000e+00 2.011404e-31]\n",
      "Action prob: [1.000000e+00 2.011404e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5395503e-33]\n",
      "Action prob: [1.0000000e+00 1.5395503e-33], Action: 0, state: 8\n",
      "[1.00000000e+00 1.07542616e-35]\n",
      "Action prob: [1.00000000e+00 1.07542616e-35], Action: 0, state: 8\n",
      "[1.000000e+00 2.636054e-39]\n",
      "Action prob: [1.000000e+00 2.636054e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 7.0011123e-35]\n",
      "Action prob: [1.0000000e+00 7.0011123e-35], Action: 0, state: 8\n",
      "[1.000000e+00 1.091533e-27]\n",
      "Action prob: [1.000000e+00 1.091533e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2619378e-27]\n",
      "Action prob: [1.0000000e+00 1.2619378e-27], Action: 0, state: 8\n",
      "[1.000000e+00 6.527348e-35]\n",
      "Action prob: [1.000000e+00 6.527348e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5902291e-31]\n",
      "Action prob: [1.0000000e+00 1.5902291e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3813969e-34]\n",
      "Action prob: [1.0000000e+00 1.3813969e-34], Action: 0, state: 8\n",
      "[1.000000e+00 4.976846e-32]\n",
      "Action prob: [1.000000e+00 4.976846e-32], Action: 0, state: 8\n",
      "[1.000000e+00 5.810994e-35]\n",
      "Action prob: [1.000000e+00 5.810994e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8906679e-33]\n",
      "Action prob: [1.0000000e+00 2.8906679e-33], Action: 0, state: 8\n",
      "[1.000000e+00 4.938578e-28]\n",
      "Action prob: [1.000000e+00 4.938578e-28], Action: 0, state: 8\n",
      "[1.00000e+00 3.53296e-27]\n",
      "Action prob: [1.00000e+00 3.53296e-27], Action: 0, state: 8\n",
      "[1.000e+00 3.199e-40]\n",
      "Action prob: [1.000e+00 3.199e-40], Action: 0, state: 8\n",
      "[1.000000e+00 6.838356e-28]\n",
      "Action prob: [1.000000e+00 6.838356e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1187683e-33]\n",
      "Action prob: [1.0000000e+00 3.1187683e-33], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., 0., 0., 0., 0.,\n",
      "        0., -0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for this episode -138800, loss is -0.0\n",
      "[1.0000000e+00 2.7143145e-29]\n",
      "Action prob: [1.0000000e+00 2.7143145e-29], Action: 0, state: 0\n",
      "[1.000000e+00 7.766248e-27]\n",
      "Action prob: [1.000000e+00 7.766248e-27], Action: 0, state: 9\n",
      "[1.00000000e+00 1.12252915e-32]\n",
      "Action prob: [1.00000000e+00 1.12252915e-32], Action: 0, state: 9\n",
      "[1.0000000e+00 1.9669355e-35]\n",
      "Action prob: [1.0000000e+00 1.9669355e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7216758e-35]\n",
      "Action prob: [1.0000000e+00 1.7216758e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 4.1662133e-34]\n",
      "Action prob: [1.0000000e+00 4.1662133e-34], Action: 0, state: 9\n",
      "[1.000000e+00 8.058713e-30]\n",
      "Action prob: [1.000000e+00 8.058713e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 3.5630192e-35]\n",
      "Action prob: [1.0000000e+00 3.5630192e-35], Action: 0, state: 9\n",
      "[1.00000e+00 4.78923e-27]\n",
      "Action prob: [1.00000e+00 4.78923e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 3.0006864e-33]\n",
      "Action prob: [1.0000000e+00 3.0006864e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 2.3305432e-27]\n",
      "Action prob: [1.0000000e+00 2.3305432e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 3.7747437e-27]\n",
      "Action prob: [1.0000000e+00 3.7747437e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.7037684e-34]\n",
      "Action prob: [1.0000000e+00 1.7037684e-34], Action: 0, state: 9\n",
      "[1.000000e+00 6.374055e-26]\n",
      "Action prob: [1.000000e+00 6.374055e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 7.2213058e-37]\n",
      "Action prob: [1.0000000e+00 7.2213058e-37], Action: 0, state: 9\n",
      "[1.000000e+00 5.660338e-35]\n",
      "Action prob: [1.000000e+00 5.660338e-35], Action: 0, state: 9\n",
      "[1.0000e+00 9.0795e-40]\n",
      "Action prob: [1.0000e+00 9.0795e-40], Action: 0, state: 9\n",
      "[1.000000e+00 3.238333e-33]\n",
      "Action prob: [1.000000e+00 3.238333e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3153195e-35]\n",
      "Action prob: [1.0000000e+00 1.3153195e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0640888e-37]\n",
      "Action prob: [1.0000000e+00 1.0640888e-37], Action: 0, state: 9\n",
      "[1.0000000e+00 2.7302996e-27]\n",
      "Action prob: [1.0000000e+00 2.7302996e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.4598015e-36]\n",
      "Action prob: [1.0000000e+00 1.4598015e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 1.8824621e-36]\n",
      "Action prob: [1.0000000e+00 1.8824621e-36], Action: 0, state: 9\n",
      "[1.000000e+00 6.734702e-35]\n",
      "Action prob: [1.000000e+00 6.734702e-35], Action: 0, state: 9\n",
      "[1.000000e+00 3.929756e-35]\n",
      "Action prob: [1.000000e+00 3.929756e-35], Action: 0, state: 9\n",
      "[1.000000e+00 3.572764e-35]\n",
      "Action prob: [1.000000e+00 3.572764e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 2.7502317e-36]\n",
      "Action prob: [1.0000000e+00 2.7502317e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 2.8945042e-28]\n",
      "Action prob: [1.0000000e+00 2.8945042e-28], Action: 0, state: 9\n",
      "[1.0000000e+00 3.0700517e-34]\n",
      "Action prob: [1.0000000e+00 3.0700517e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0202547e-33]\n",
      "Action prob: [1.0000000e+00 1.0202547e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 2.7201738e-27]\n",
      "Action prob: [1.0000000e+00 2.7201738e-27], Action: 0, state: 9\n",
      "[1.000000e+00 4.249963e-31]\n",
      "Action prob: [1.000000e+00 4.249963e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 1.2925049e-34]\n",
      "Action prob: [1.0000000e+00 1.2925049e-34], Action: 0, state: 9\n",
      "[1.000000e+00 6.264972e-34]\n",
      "Action prob: [1.000000e+00 6.264972e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.8712868e-35]\n",
      "Action prob: [1.0000000e+00 1.8712868e-35], Action: 0, state: 9\n",
      "[1.000000e+00 8.310167e-33]\n",
      "Action prob: [1.000000e+00 8.310167e-33], Action: 0, state: 9\n",
      "[1.0000000e+00 8.2522223e-35]\n",
      "Action prob: [1.0000000e+00 8.2522223e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 5.8589507e-31]\n",
      "Action prob: [1.0000000e+00 5.8589507e-31], Action: 0, state: 9\n",
      "[1.0000000e+00 1.8715438e-35]\n",
      "Action prob: [1.0000000e+00 1.8715438e-35], Action: 0, state: 9\n",
      "[1.0000000e+00 1.6860726e-26]\n",
      "Action prob: [1.0000000e+00 1.6860726e-26], Action: 0, state: 9\n",
      "[1.0000000e+00 4.1947492e-31]\n",
      "Action prob: [1.0000000e+00 4.1947492e-31], Action: 0, state: 9\n",
      "[1.000000e+00 4.361626e-34]\n",
      "Action prob: [1.000000e+00 4.361626e-34], Action: 0, state: 9\n",
      "[1.0000000e+00 1.0993921e-37]\n",
      "Action prob: [1.0000000e+00 1.0993921e-37], Action: 0, state: 9\n",
      "[1.000000e+00 6.472473e-36]\n",
      "Action prob: [1.000000e+00 6.472473e-36], Action: 0, state: 9\n",
      "[1.000000e+00 1.308332e-30]\n",
      "Action prob: [1.000000e+00 1.308332e-30], Action: 0, state: 9\n",
      "[1.0000000e+00 3.6480266e-36]\n",
      "Action prob: [1.0000000e+00 3.6480266e-36], Action: 0, state: 9\n",
      "[1.0000000e+00 1.3702386e-27]\n",
      "Action prob: [1.0000000e+00 1.3702386e-27], Action: 0, state: 9\n",
      "[1.0000000e+00 1.1352304e-36]\n",
      "Action prob: [1.0000000e+00 1.1352304e-36], Action: 0, state: 9\n",
      "[1.000000e+00 9.462918e-27]\n",
      "Action prob: [1.000000e+00 9.462918e-27], Action: 0, state: 9\n",
      "[1.000000e+00 6.950952e-27]\n",
      "Action prob: [1.000000e+00 6.950952e-27], Action: 0, state: 9\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., -0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -50000, loss is -0.0\n",
      "[1.0000000e+00 5.9234285e-30]\n",
      "Action prob: [1.0000000e+00 5.9234285e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 9.8884845e-29]\n",
      "Action prob: [1.0000000e+00 9.8884845e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 6.3091894e-29]\n",
      "Action prob: [1.0000000e+00 6.3091894e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.2782641e-29]\n",
      "Action prob: [1.0000000e+00 1.2782641e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 6.7743224e-30]\n",
      "Action prob: [1.0000000e+00 6.7743224e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 2.2572245e-31]\n",
      "Action prob: [1.0000000e+00 2.2572245e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 4.3127142e-29]\n",
      "Action prob: [1.0000000e+00 4.3127142e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 1.1996419e-28]\n",
      "Action prob: [1.0000000e+00 1.1996419e-28], Action: 0, state: 2\n",
      "[1.0000000e+00 3.0526474e-29]\n",
      "Action prob: [1.0000000e+00 3.0526474e-29], Action: 0, state: 2\n",
      "[1.000000e+00 7.437559e-29]\n",
      "Action prob: [1.000000e+00 7.437559e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 1.7309192e-30]\n",
      "Action prob: [1.0000000e+00 1.7309192e-30], Action: 0, state: 2\n",
      "[1.00000e+00 4.45571e-30]\n",
      "Action prob: [1.00000e+00 4.45571e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 4.1893484e-29]\n",
      "Action prob: [1.0000000e+00 4.1893484e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 3.6348896e-34]\n",
      "Action prob: [1.0000000e+00 3.6348896e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.362534e-27]\n",
      "Action prob: [1.000000e+00 7.362534e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6440917e-31]\n",
      "Action prob: [1.0000000e+00 1.6440917e-31], Action: 0, state: 8\n",
      "[1.00000e+00 1.27385e-35]\n",
      "Action prob: [1.00000e+00 1.27385e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2671765e-27]\n",
      "Action prob: [1.0000000e+00 1.2671765e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9606702e-36]\n",
      "Action prob: [1.0000000e+00 2.9606702e-36], Action: 0, state: 8\n",
      "[1.000000e+00 9.757051e-34]\n",
      "Action prob: [1.000000e+00 9.757051e-34], Action: 0, state: 8\n",
      "[1.0000e+00 8.9284e-27]\n",
      "Action prob: [1.0000e+00 8.9284e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 8.8211817e-35]\n",
      "Action prob: [1.0000000e+00 8.8211817e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.6903693e-34]\n",
      "Action prob: [1.0000000e+00 5.6903693e-34], Action: 0, state: 8\n",
      "[1.000000e+00 3.319086e-27]\n",
      "Action prob: [1.000000e+00 3.319086e-27], Action: 0, state: 8\n",
      "[1.00000e+00 2.77821e-26]\n",
      "Action prob: [1.00000e+00 2.77821e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5737497e-34]\n",
      "Action prob: [1.0000000e+00 2.5737497e-34], Action: 0, state: 8\n",
      "[1.000000e+00 5.115016e-35]\n",
      "Action prob: [1.000000e+00 5.115016e-35], Action: 0, state: 8\n",
      "[1.000000e+00 3.342888e-33]\n",
      "Action prob: [1.000000e+00 3.342888e-33], Action: 0, state: 8\n",
      "[1.000000e+00 6.880591e-35]\n",
      "Action prob: [1.000000e+00 6.880591e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2066469e-26]\n",
      "Action prob: [1.0000000e+00 1.2066469e-26], Action: 0, state: 8\n",
      "[1.000000e+00 9.665212e-35]\n",
      "Action prob: [1.000000e+00 9.665212e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2551496e-34]\n",
      "Action prob: [1.0000000e+00 1.2551496e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 5.0229963e-27]\n",
      "Action prob: [1.0000000e+00 5.0229963e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5090306e-32]\n",
      "Action prob: [1.0000000e+00 1.5090306e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2296408e-35]\n",
      "Action prob: [1.0000000e+00 4.2296408e-35], Action: 0, state: 8\n",
      "[1.000000e+00 9.861109e-27]\n",
      "Action prob: [1.000000e+00 9.861109e-27], Action: 0, state: 8\n",
      "[1.000000e+00 2.779801e-33]\n",
      "Action prob: [1.000000e+00 2.779801e-33], Action: 0, state: 8\n",
      "[1.000000e+00 9.393067e-36]\n",
      "Action prob: [1.000000e+00 9.393067e-36], Action: 0, state: 8\n",
      "[1.000000e+00 6.430689e-27]\n",
      "Action prob: [1.000000e+00 6.430689e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1490498e-38]\n",
      "Action prob: [1.0000000e+00 2.1490498e-38], Action: 0, state: 8\n",
      "[1.000000e+00 8.487511e-37]\n",
      "Action prob: [1.000000e+00 8.487511e-37], Action: 0, state: 8\n",
      "[1.000000e+00 1.692543e-33]\n",
      "Action prob: [1.000000e+00 1.692543e-33], Action: 0, state: 8\n",
      "[1.0e+00 6.7e-44]\n",
      "Action prob: [1.0e+00 6.7e-44], Action: 0, state: 8\n",
      "[1.000000e+00 9.563618e-28]\n",
      "Action prob: [1.000000e+00 9.563618e-28], Action: 0, state: 8\n",
      "[1.000000e+00 3.688596e-27]\n",
      "Action prob: [1.000000e+00 3.688596e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7895072e-35]\n",
      "Action prob: [1.0000000e+00 2.7895072e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8094432e-27]\n",
      "Action prob: [1.0000000e+00 1.8094432e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1453259e-28]\n",
      "Action prob: [1.0000000e+00 2.1453259e-28], Action: 0, state: 8\n",
      "[1.000000e+00 1.773491e-27]\n",
      "Action prob: [1.000000e+00 1.773491e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8897418e-33]\n",
      "Action prob: [1.0000000e+00 2.8897418e-33], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -104400, loss is -0.0\n",
      "[1.000000e+00 8.979128e-33]\n",
      "Action prob: [1.000000e+00 8.979128e-33], Action: 0, state: 0\n",
      "[1.0000000e+00 8.1491046e-30]\n",
      "Action prob: [1.0000000e+00 8.1491046e-30], Action: 0, state: 0\n",
      "[1.00000e+00 9.63347e-30]\n",
      "Action prob: [1.00000e+00 9.63347e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 5.0255595e-29]\n",
      "Action prob: [1.0000000e+00 5.0255595e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 6.3965705e-31]\n",
      "Action prob: [1.0000000e+00 6.3965705e-31], Action: 0, state: 1\n",
      "[1.000000e+00 4.456375e-29]\n",
      "Action prob: [1.000000e+00 4.456375e-29], Action: 0, state: 1\n",
      "[1.00000e+00 6.83876e-32]\n",
      "Action prob: [1.00000e+00 6.83876e-32], Action: 0, state: 1\n",
      "[1.000000e+00 8.515204e-30]\n",
      "Action prob: [1.000000e+00 8.515204e-30], Action: 0, state: 2\n",
      "[1.000000e+00 3.029324e-26]\n",
      "Action prob: [1.000000e+00 3.029324e-26], Action: 0, state: 3\n",
      "[1.0000000e+00 2.0077835e-33]\n",
      "Action prob: [1.0000000e+00 2.0077835e-33], Action: 0, state: 3\n",
      "[1.0000000e+00 1.3230791e-28]\n",
      "Action prob: [1.0000000e+00 1.3230791e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.4374607e-35]\n",
      "Action prob: [1.0000000e+00 1.4374607e-35], Action: 0, state: 3\n",
      "[1.0000000e+00 2.1569805e-26]\n",
      "Action prob: [1.0000000e+00 2.1569805e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0225983e-37]\n",
      "Action prob: [1.0000000e+00 1.0225983e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7612474e-28]\n",
      "Action prob: [1.0000000e+00 4.7612474e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1484613e-33]\n",
      "Action prob: [1.0000000e+00 3.1484613e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0672243e-27]\n",
      "Action prob: [1.0000000e+00 1.0672243e-27], Action: 0, state: 8\n",
      "[1.000000e+00 5.260827e-33]\n",
      "Action prob: [1.000000e+00 5.260827e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.8433828e-27]\n",
      "Action prob: [1.0000000e+00 5.8433828e-27], Action: 0, state: 8\n",
      "[1.000000e+00 4.431176e-33]\n",
      "Action prob: [1.000000e+00 4.431176e-33], Action: 0, state: 8\n",
      "[1.000000e+00 9.361986e-35]\n",
      "Action prob: [1.000000e+00 9.361986e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2485464e-37]\n",
      "Action prob: [1.0000000e+00 3.2485464e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1263688e-31]\n",
      "Action prob: [1.0000000e+00 1.1263688e-31], Action: 0, state: 8\n",
      "[1.000000e+00 7.615423e-35]\n",
      "Action prob: [1.000000e+00 7.615423e-35], Action: 0, state: 8\n",
      "[1.000000e+00 6.640797e-27]\n",
      "Action prob: [1.000000e+00 6.640797e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 7.9446934e-26]\n",
      "Action prob: [1.0000000e+00 7.9446934e-26], Action: 0, state: 8\n",
      "[1.000000e+00 7.476053e-27]\n",
      "Action prob: [1.000000e+00 7.476053e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0778648e-33]\n",
      "Action prob: [1.0000000e+00 2.0778648e-33], Action: 0, state: 8\n",
      "[1.000000e+00 4.395429e-28]\n",
      "Action prob: [1.000000e+00 4.395429e-28], Action: 0, state: 8\n",
      "[1.00000e+00 5.61173e-34]\n",
      "Action prob: [1.00000e+00 5.61173e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.379488e-35]\n",
      "Action prob: [1.000000e+00 7.379488e-35], Action: 0, state: 8\n",
      "[1.000e+00 7.438e-42]\n",
      "Action prob: [1.000e+00 7.438e-42], Action: 0, state: 8\n",
      "[1.00000e+00 5.63857e-28]\n",
      "Action prob: [1.00000e+00 5.63857e-28], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 3.6499346e-28]\n",
      "Action prob: [1.0000000e+00 3.6499346e-28], Action: 0, state: 8\n",
      "[1.000000e+00 1.077444e-32]\n",
      "Action prob: [1.000000e+00 1.077444e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6467945e-34]\n",
      "Action prob: [1.0000000e+00 1.6467945e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0209955e-31]\n",
      "Action prob: [1.0000000e+00 1.0209955e-31], Action: 0, state: 8\n",
      "[1.000000e+00 6.401781e-35]\n",
      "Action prob: [1.000000e+00 6.401781e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.0428944e-36]\n",
      "Action prob: [1.0000000e+00 2.0428944e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1928042e-26]\n",
      "Action prob: [1.0000000e+00 2.1928042e-26], Action: 0, state: 8\n",
      "[1.000000e+00 7.513218e-35]\n",
      "Action prob: [1.000000e+00 7.513218e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.8244443e-27]\n",
      "Action prob: [1.0000000e+00 5.8244443e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1946739e-27]\n",
      "Action prob: [1.0000000e+00 1.1946739e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7870053e-33]\n",
      "Action prob: [1.0000000e+00 4.7870053e-33], Action: 0, state: 8\n",
      "[1.000000e+00 2.157252e-26]\n",
      "Action prob: [1.000000e+00 2.157252e-26], Action: 0, state: 8\n",
      "[1.000000e+00 4.577321e-31]\n",
      "Action prob: [1.000000e+00 4.577321e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4017058e-29]\n",
      "Action prob: [1.0000000e+00 2.4017058e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3805036e-36]\n",
      "Action prob: [1.0000000e+00 5.3805036e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3026772e-35]\n",
      "Action prob: [1.0000000e+00 4.3026772e-35], Action: 0, state: 8\n",
      "[1.000000e+00 3.869443e-39]\n",
      "Action prob: [1.000000e+00 3.869443e-39], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0.,\n",
      "        -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -108700, loss is -0.0\n",
      "[1.0000000e+00 2.9641373e-30]\n",
      "Action prob: [1.0000000e+00 2.9641373e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 2.4216855e-31]\n",
      "Action prob: [1.0000000e+00 2.4216855e-31], Action: 0, state: 1\n",
      "[1.00000e+00 7.72001e-30]\n",
      "Action prob: [1.00000e+00 7.72001e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.8714496e-29]\n",
      "Action prob: [1.0000000e+00 1.8714496e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 2.0175758e-30]\n",
      "Action prob: [1.0000000e+00 2.0175758e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 3.4700196e-29]\n",
      "Action prob: [1.0000000e+00 3.4700196e-29], Action: 0, state: 3\n",
      "[1.000000e+00 9.770363e-31]\n",
      "Action prob: [1.000000e+00 9.770363e-31], Action: 0, state: 3\n",
      "[1.00000e+00 9.09234e-29]\n",
      "Action prob: [1.00000e+00 9.09234e-29], Action: 0, state: 8\n",
      "[1.000000e+00 4.126796e-34]\n",
      "Action prob: [1.000000e+00 4.126796e-34], Action: 0, state: 8\n",
      "[1.0e+00 5.3e-44]\n",
      "Action prob: [1.0e+00 5.3e-44], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1160928e-35]\n",
      "Action prob: [1.0000000e+00 1.1160928e-35], Action: 0, state: 8\n",
      "[1.00000e+00 2.16382e-40]\n",
      "Action prob: [1.00000e+00 2.16382e-40], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6989023e-27]\n",
      "Action prob: [1.0000000e+00 2.6989023e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.5312773e-33]\n",
      "Action prob: [1.0000000e+00 4.5312773e-33], Action: 0, state: 8\n",
      "[1.000000e+00 8.001473e-27]\n",
      "Action prob: [1.000000e+00 8.001473e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 7.4539517e-28]\n",
      "Action prob: [1.0000000e+00 7.4539517e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7532787e-34]\n",
      "Action prob: [1.0000000e+00 2.7532787e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.3642496e-33]\n",
      "Action prob: [1.0000000e+00 2.3642496e-33], Action: 0, state: 8\n",
      "[1.0000e+00 1.8612e-40]\n",
      "Action prob: [1.0000e+00 1.8612e-40], Action: 0, state: 8\n",
      "[1.000000e+00 7.848743e-28]\n",
      "Action prob: [1.000000e+00 7.848743e-28], Action: 0, state: 8\n",
      "[1.00000e+00 1.00745e-32]\n",
      "Action prob: [1.00000e+00 1.00745e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5996705e-29]\n",
      "Action prob: [1.0000000e+00 3.5996705e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6608057e-27]\n",
      "Action prob: [1.0000000e+00 1.6608057e-27], Action: 0, state: 8\n",
      "[1.000000e+00 3.133109e-36]\n",
      "Action prob: [1.000000e+00 3.133109e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 7.1151614e-28]\n",
      "Action prob: [1.0000000e+00 7.1151614e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 7.2292507e-35]\n",
      "Action prob: [1.0000000e+00 7.2292507e-35], Action: 0, state: 8\n",
      "[1.000000e+00 6.822464e-35]\n",
      "Action prob: [1.000000e+00 6.822464e-35], Action: 0, state: 8\n",
      "[1.000000e+00 9.416972e-34]\n",
      "Action prob: [1.000000e+00 9.416972e-34], Action: 0, state: 8\n",
      "[1.00000e+00 6.09142e-40]\n",
      "Action prob: [1.00000e+00 6.09142e-40], Action: 0, state: 8\n",
      "[1.0000000e+00 9.5681036e-36]\n",
      "Action prob: [1.0000000e+00 9.5681036e-36], Action: 0, state: 8\n",
      "[1.0e+00 1.5e-44]\n",
      "Action prob: [1.0e+00 1.5e-44], Action: 0, state: 8\n",
      "[1.00000e+00 8.27527e-34]\n",
      "Action prob: [1.00000e+00 8.27527e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7703438e-33]\n",
      "Action prob: [1.0000000e+00 4.7703438e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3909144e-27]\n",
      "Action prob: [1.0000000e+00 1.3909144e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 6.9149328e-34]\n",
      "Action prob: [1.0000000e+00 6.9149328e-34], Action: 0, state: 8\n",
      "[1.000000e+00 9.500071e-33]\n",
      "Action prob: [1.000000e+00 9.500071e-33], Action: 0, state: 8\n",
      "[1.00000e+00 6.93268e-27]\n",
      "Action prob: [1.00000e+00 6.93268e-27], Action: 0, state: 8\n",
      "[1.000000e+00 8.001596e-27]\n",
      "Action prob: [1.000000e+00 8.001596e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0433739e-26]\n",
      "Action prob: [1.0000000e+00 1.0433739e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0990085e-33]\n",
      "Action prob: [1.0000000e+00 1.0990085e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2869855e-32]\n",
      "Action prob: [1.0000000e+00 3.2869855e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1606363e-35]\n",
      "Action prob: [1.0000000e+00 3.1606363e-35], Action: 0, state: 8\n",
      "[1.000000e+00 5.771708e-37]\n",
      "Action prob: [1.000000e+00 5.771708e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 4.2772984e-26]\n",
      "Action prob: [1.0000000e+00 4.2772984e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6202488e-27]\n",
      "Action prob: [1.0000000e+00 1.6202488e-27], Action: 0, state: 8\n",
      "[1.000000e+00 1.485318e-32]\n",
      "Action prob: [1.000000e+00 1.485318e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5674346e-34]\n",
      "Action prob: [1.0000000e+00 2.5674346e-34], Action: 0, state: 8\n",
      "[1.000000e+00 1.117713e-33]\n",
      "Action prob: [1.000000e+00 1.117713e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7049252e-27]\n",
      "Action prob: [1.0000000e+00 1.7049252e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5562072e-33]\n",
      "Action prob: [1.0000000e+00 2.5562072e-33], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -127600, loss is -0.0\n",
      "[1.0000000e+00 1.9763431e-29]\n",
      "Action prob: [1.0000000e+00 1.9763431e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 3.6343976e-30]\n",
      "Action prob: [1.0000000e+00 3.6343976e-30], Action: 0, state: 1\n",
      "[1.000000e+00 2.168082e-28]\n",
      "Action prob: [1.000000e+00 2.168082e-28], Action: 0, state: 2\n",
      "[1.0000000e+00 1.4518042e-29]\n",
      "Action prob: [1.0000000e+00 1.4518042e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 1.4967177e-30]\n",
      "Action prob: [1.0000000e+00 1.4967177e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 1.4988271e-36]\n",
      "Action prob: [1.0000000e+00 1.4988271e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 4.1513767e-28]\n",
      "Action prob: [1.0000000e+00 4.1513767e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1503659e-27]\n",
      "Action prob: [1.0000000e+00 2.1503659e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5170927e-35]\n",
      "Action prob: [1.0000000e+00 2.5170927e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9215768e-35]\n",
      "Action prob: [1.0000000e+00 1.9215768e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2192874e-27]\n",
      "Action prob: [1.0000000e+00 1.2192874e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6909683e-33]\n",
      "Action prob: [1.0000000e+00 1.6909683e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1359729e-33]\n",
      "Action prob: [1.0000000e+00 1.1359729e-33], Action: 0, state: 8\n",
      "[1.000000e+00 9.141419e-35]\n",
      "Action prob: [1.000000e+00 9.141419e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4696347e-37]\n",
      "Action prob: [1.0000000e+00 3.4696347e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2971959e-35]\n",
      "Action prob: [1.0000000e+00 2.2971959e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 3.1692082e-35]\n",
      "Action prob: [1.0000000e+00 3.1692082e-35], Action: 0, state: 8\n",
      "[1.00000000e+00 1.05825336e-26]\n",
      "Action prob: [1.00000000e+00 1.05825336e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3163964e-31]\n",
      "Action prob: [1.0000000e+00 4.3163964e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0339435e-27]\n",
      "Action prob: [1.0000000e+00 1.0339435e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9798642e-36]\n",
      "Action prob: [1.0000000e+00 2.9798642e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 4.5017364e-30]\n",
      "Action prob: [1.0000000e+00 4.5017364e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5070412e-27]\n",
      "Action prob: [1.0000000e+00 2.5070412e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4966815e-25]\n",
      "Action prob: [1.0000000e+00 1.4966815e-25], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4232256e-27]\n",
      "Action prob: [1.0000000e+00 1.4232256e-27], Action: 0, state: 8\n",
      "[1.000000e+00 5.746185e-28]\n",
      "Action prob: [1.000000e+00 5.746185e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5179962e-27]\n",
      "Action prob: [1.0000000e+00 2.5179962e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3975844e-34]\n",
      "Action prob: [1.0000000e+00 1.3975844e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.5054872e-31]\n",
      "Action prob: [1.0000000e+00 2.5054872e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0835043e-37]\n",
      "Action prob: [1.0000000e+00 1.0835043e-37], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2547295e-26]\n",
      "Action prob: [1.0000000e+00 3.2547295e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4481382e-31]\n",
      "Action prob: [1.0000000e+00 3.4481382e-31], Action: 0, state: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 2.1454262e-26]\n",
      "Action prob: [1.0000000e+00 2.1454262e-26], Action: 0, state: 8\n",
      "[1.000000e+00 3.180727e-27]\n",
      "Action prob: [1.000000e+00 3.180727e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7651094e-34]\n",
      "Action prob: [1.0000000e+00 2.7651094e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6725222e-26]\n",
      "Action prob: [1.0000000e+00 3.6725222e-26], Action: 0, state: 8\n",
      "[1.000000e+00 7.250872e-36]\n",
      "Action prob: [1.000000e+00 7.250872e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4289708e-34]\n",
      "Action prob: [1.0000000e+00 1.4289708e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.977451e-36]\n",
      "Action prob: [1.000000e+00 7.977451e-36], Action: 0, state: 8\n",
      "[1.000000e+00 7.318628e-27]\n",
      "Action prob: [1.000000e+00 7.318628e-27], Action: 0, state: 8\n",
      "[1.000000e+00 5.847218e-27]\n",
      "Action prob: [1.000000e+00 5.847218e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9772705e-38]\n",
      "Action prob: [1.0000000e+00 2.9772705e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 4.5447407e-35]\n",
      "Action prob: [1.0000000e+00 4.5447407e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 7.1336436e-35]\n",
      "Action prob: [1.0000000e+00 7.1336436e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3413656e-38]\n",
      "Action prob: [1.0000000e+00 4.3413656e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3210592e-36]\n",
      "Action prob: [1.0000000e+00 3.3210592e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3212547e-26]\n",
      "Action prob: [1.0000000e+00 1.3212547e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.5212915e-28]\n",
      "Action prob: [1.0000000e+00 4.5212915e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6981367e-26]\n",
      "Action prob: [1.0000000e+00 1.6981367e-26], Action: 0, state: 8\n",
      "[1.000000e+00 7.308387e-35]\n",
      "Action prob: [1.000000e+00 7.308387e-35], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., -0., -0., -0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -135000, loss is -0.0\n",
      "[1.0000000e+00 1.3119961e-29]\n",
      "Action prob: [1.0000000e+00 1.3119961e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 5.7826378e-30]\n",
      "Action prob: [1.0000000e+00 5.7826378e-30], Action: 0, state: 1\n",
      "[1.000000e+00 2.094821e-29]\n",
      "Action prob: [1.000000e+00 2.094821e-29], Action: 0, state: 2\n",
      "[1.000000e+00 2.560702e-29]\n",
      "Action prob: [1.000000e+00 2.560702e-29], Action: 0, state: 3\n",
      "[1.000000e+00 4.003465e-32]\n",
      "Action prob: [1.000000e+00 4.003465e-32], Action: 0, state: 3\n",
      "[1.0000000e+00 1.2846023e-32]\n",
      "Action prob: [1.0000000e+00 1.2846023e-32], Action: 0, state: 3\n",
      "[1.000000e+00 3.967827e-32]\n",
      "Action prob: [1.000000e+00 3.967827e-32], Action: 0, state: 8\n",
      "[1.000000e+00 1.980555e-36]\n",
      "Action prob: [1.000000e+00 1.980555e-36], Action: 0, state: 8\n",
      "[1.000000e+00 1.332328e-27]\n",
      "Action prob: [1.000000e+00 1.332328e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.7005918e-26]\n",
      "Action prob: [1.0000000e+00 3.7005918e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7836183e-35]\n",
      "Action prob: [1.0000000e+00 2.7836183e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7870545e-33]\n",
      "Action prob: [1.0000000e+00 1.7870545e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5471214e-33]\n",
      "Action prob: [1.0000000e+00 1.5471214e-33], Action: 0, state: 8\n",
      "[1.00000e+00 7.49226e-37]\n",
      "Action prob: [1.00000e+00 7.49226e-37], Action: 0, state: 8\n",
      "[1.00000000e+00 1.14649046e-26]\n",
      "Action prob: [1.00000000e+00 1.14649046e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2981465e-36]\n",
      "Action prob: [1.0000000e+00 1.2981465e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9092073e-27]\n",
      "Action prob: [1.0000000e+00 1.9092073e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3051123e-27]\n",
      "Action prob: [1.0000000e+00 3.3051123e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5165444e-26]\n",
      "Action prob: [1.0000000e+00 3.5165444e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9376493e-38]\n",
      "Action prob: [1.0000000e+00 2.9376493e-38], Action: 0, state: 8\n",
      "[1.000000e+00 9.669195e-35]\n",
      "Action prob: [1.000000e+00 9.669195e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.7815215e-27]\n",
      "Action prob: [1.0000000e+00 5.7815215e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8970899e-35]\n",
      "Action prob: [1.0000000e+00 1.8970899e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1544721e-36]\n",
      "Action prob: [1.0000000e+00 1.1544721e-36], Action: 0, state: 8\n",
      "[1.000000e+00 5.090821e-27]\n",
      "Action prob: [1.000000e+00 5.090821e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.8638277e-29]\n",
      "Action prob: [1.0000000e+00 3.8638277e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7578384e-34]\n",
      "Action prob: [1.0000000e+00 1.7578384e-34], Action: 0, state: 8\n",
      "[1.000000e+00 4.042022e-35]\n",
      "Action prob: [1.000000e+00 4.042022e-35], Action: 0, state: 8\n",
      "[1.000000e+00 3.838627e-39]\n",
      "Action prob: [1.000000e+00 3.838627e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6926527e-26]\n",
      "Action prob: [1.0000000e+00 3.6926527e-26], Action: 0, state: 8\n",
      "[1.00000000e+00 1.09933194e-32]\n",
      "Action prob: [1.00000000e+00 1.09933194e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9887096e-35]\n",
      "Action prob: [1.0000000e+00 1.9887096e-35], Action: 0, state: 8\n",
      "[1.000000e+00 1.648655e-34]\n",
      "Action prob: [1.000000e+00 1.648655e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9528372e-33]\n",
      "Action prob: [1.0000000e+00 1.9528372e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9997946e-34]\n",
      "Action prob: [1.0000000e+00 1.9997946e-34], Action: 0, state: 8\n",
      "[1.000000e+00 6.187752e-28]\n",
      "Action prob: [1.000000e+00 6.187752e-28], Action: 0, state: 8\n",
      "[1.000000e+00 2.468634e-35]\n",
      "Action prob: [1.000000e+00 2.468634e-35], Action: 0, state: 8\n",
      "[1.000000e+00 5.386399e-28]\n",
      "Action prob: [1.000000e+00 5.386399e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8185666e-31]\n",
      "Action prob: [1.0000000e+00 1.8185666e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 3.9731373e-35]\n",
      "Action prob: [1.0000000e+00 3.9731373e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8168021e-27]\n",
      "Action prob: [1.0000000e+00 1.8168021e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6926818e-33]\n",
      "Action prob: [1.0000000e+00 3.6926818e-33], Action: 0, state: 8\n",
      "[1.000000e+00 8.043461e-27]\n",
      "Action prob: [1.000000e+00 8.043461e-27], Action: 0, state: 8\n",
      "[1.000000e+00 7.805274e-27]\n",
      "Action prob: [1.000000e+00 7.805274e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 4.6782042e-32]\n",
      "Action prob: [1.0000000e+00 4.6782042e-32], Action: 0, state: 8\n",
      "[1.000000e+00 2.397538e-39]\n",
      "Action prob: [1.000000e+00 2.397538e-39], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2903497e-30]\n",
      "Action prob: [1.0000000e+00 1.2903497e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.9196463e-34]\n",
      "Action prob: [1.0000000e+00 2.9196463e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 7.3371425e-32]\n",
      "Action prob: [1.0000000e+00 7.3371425e-32], Action: 0, state: 8\n",
      "[1.000000e+00 5.809466e-27]\n",
      "Action prob: [1.000000e+00 5.809466e-27], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -131800, loss is -0.0\n",
      "[1.000000e+00 5.552526e-29]\n",
      "Action prob: [1.000000e+00 5.552526e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.6495462e-29]\n",
      "Action prob: [1.0000000e+00 1.6495462e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 4.3059554e-30]\n",
      "Action prob: [1.0000000e+00 4.3059554e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.0399986e-29]\n",
      "Action prob: [1.0000000e+00 1.0399986e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 3.5407127e-30]\n",
      "Action prob: [1.0000000e+00 3.5407127e-30], Action: 0, state: 1\n",
      "[1.0000000e+00 1.9368439e-31]\n",
      "Action prob: [1.0000000e+00 1.9368439e-31], Action: 0, state: 2\n",
      "[1.0000000e+00 1.4599318e-33]\n",
      "Action prob: [1.0000000e+00 1.4599318e-33], Action: 0, state: 2\n",
      "[1.0000000e+00 2.5632905e-30]\n",
      "Action prob: [1.0000000e+00 2.5632905e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 1.8636618e-30]\n",
      "Action prob: [1.0000000e+00 1.8636618e-30], Action: 0, state: 3\n",
      "[1.0000000e+00 1.0701481e-33]\n",
      "Action prob: [1.0000000e+00 1.0701481e-33], Action: 0, state: 3\n",
      "[1.0000000e+00 1.4178054e-29]\n",
      "Action prob: [1.0000000e+00 1.4178054e-29], Action: 0, state: 3\n",
      "[1.0000000e+00 2.0133851e-38]\n",
      "Action prob: [1.0000000e+00 2.0133851e-38], Action: 0, state: 3\n",
      "[1.0000000e+00 8.7899894e-32]\n",
      "Action prob: [1.0000000e+00 8.7899894e-32], Action: 0, state: 3\n",
      "[1.00000e+00 1.86912e-33]\n",
      "Action prob: [1.00000e+00 1.86912e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6940636e-30]\n",
      "Action prob: [1.0000000e+00 1.6940636e-30], Action: 0, state: 8\n",
      "[1.000000e+00 1.769973e-31]\n",
      "Action prob: [1.000000e+00 1.769973e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5591363e-26]\n",
      "Action prob: [1.0000000e+00 1.5591363e-26], Action: 0, state: 8\n",
      "[1.000000e+00 1.349947e-35]\n",
      "Action prob: [1.000000e+00 1.349947e-35], Action: 0, state: 8\n",
      "[1.00e+00 5.48e-43]\n",
      "Action prob: [1.00e+00 5.48e-43], Action: 0, state: 8\n",
      "[1.0000e+00 6.0407e-36]\n",
      "Action prob: [1.0000e+00 6.0407e-36], Action: 0, state: 8\n",
      "[1.000000e+00 3.325855e-34]\n",
      "Action prob: [1.000000e+00 3.325855e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3107269e-27]\n",
      "Action prob: [1.0000000e+00 1.3107269e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7179437e-34]\n",
      "Action prob: [1.0000000e+00 1.7179437e-34], Action: 0, state: 8\n",
      "[1.00000e+00 3.19538e-40]\n",
      "Action prob: [1.00000e+00 3.19538e-40], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6050108e-35]\n",
      "Action prob: [1.0000000e+00 2.6050108e-35], Action: 0, state: 8\n",
      "[1.000000e+00 5.115993e-27]\n",
      "Action prob: [1.000000e+00 5.115993e-27], Action: 0, state: 8\n",
      "[1.000000e+00 6.707245e-27]\n",
      "Action prob: [1.000000e+00 6.707245e-27], Action: 0, state: 8\n",
      "[1.00000e+00 6.40569e-35]\n",
      "Action prob: [1.00000e+00 6.40569e-35], Action: 0, state: 8\n",
      "[1.000000e+00 4.705385e-27]\n",
      "Action prob: [1.000000e+00 4.705385e-27], Action: 0, state: 8\n",
      "[1.000000e+00 5.147395e-26]\n",
      "Action prob: [1.000000e+00 5.147395e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0358938e-33]\n",
      "Action prob: [1.0000000e+00 4.0358938e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4317972e-34]\n",
      "Action prob: [1.0000000e+00 1.4317972e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.4614455e-33]\n",
      "Action prob: [1.0000000e+00 3.4614455e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0012739e-32]\n",
      "Action prob: [1.0000000e+00 1.0012739e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 7.8182327e-28]\n",
      "Action prob: [1.0000000e+00 7.8182327e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0194802e-26]\n",
      "Action prob: [1.0000000e+00 1.0194802e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1359856e-26]\n",
      "Action prob: [1.0000000e+00 1.1359856e-26], Action: 0, state: 8\n",
      "[1.000000e+00 9.530428e-38]\n",
      "Action prob: [1.000000e+00 9.530428e-38], Action: 0, state: 8\n",
      "[1.0000000e+00 4.0831792e-37]\n",
      "Action prob: [1.0000000e+00 4.0831792e-37], Action: 0, state: 8\n",
      "[1.000000e+00 8.260357e-33]\n",
      "Action prob: [1.000000e+00 8.260357e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.6384965e-36]\n",
      "Action prob: [1.0000000e+00 4.6384965e-36], Action: 0, state: 8\n",
      "[1.00000e+00 5.04941e-28]\n",
      "Action prob: [1.00000e+00 5.04941e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3201904e-33]\n",
      "Action prob: [1.0000000e+00 3.3201904e-33], Action: 0, state: 8\n",
      "[1.00000e+00 9.58562e-40]\n",
      "Action prob: [1.00000e+00 9.58562e-40], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3645307e-29]\n",
      "Action prob: [1.0000000e+00 1.3645307e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 4.7619223e-27]\n",
      "Action prob: [1.0000000e+00 4.7619223e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0490691e-26]\n",
      "Action prob: [1.0000000e+00 1.0490691e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 2.4885866e-33]\n",
      "Action prob: [1.0000000e+00 2.4885866e-33], Action: 0, state: 8\n",
      "[1.000000e+00 3.681265e-31]\n",
      "Action prob: [1.000000e+00 3.681265e-31], Action: 0, state: 8\n",
      "[1.000000e+00 5.639464e-39]\n",
      "Action prob: [1.000000e+00 5.639464e-39], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -105500, loss is -0.0\n",
      "[1.0000000e+00 1.1306959e-30]\n",
      "Action prob: [1.0000000e+00 1.1306959e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 3.6147722e-33]\n",
      "Action prob: [1.0000000e+00 3.6147722e-33], Action: 0, state: 0\n",
      "[1.0000000e+00 1.3080582e-29]\n",
      "Action prob: [1.0000000e+00 1.3080582e-29], Action: 0, state: 0\n",
      "[1.0000000e+00 1.1875345e-29]\n",
      "Action prob: [1.0000000e+00 1.1875345e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 3.2443705e-31]\n",
      "Action prob: [1.0000000e+00 3.2443705e-31], Action: 0, state: 1\n",
      "[1.0000000e+00 4.8221103e-30]\n",
      "Action prob: [1.0000000e+00 4.8221103e-30], Action: 0, state: 2\n",
      "[1.000000e+00 5.247026e-30]\n",
      "Action prob: [1.000000e+00 5.247026e-30], Action: 0, state: 2\n",
      "[1.000000e+00 1.447319e-30]\n",
      "Action prob: [1.000000e+00 1.447319e-30], Action: 0, state: 2\n",
      "[1.0000000e+00 1.5515335e-29]\n",
      "Action prob: [1.0000000e+00 1.5515335e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 3.8033696e-31]\n",
      "Action prob: [1.0000000e+00 3.8033696e-31], Action: 0, state: 2\n",
      "[1.0000000e+00 1.4697471e-29]\n",
      "Action prob: [1.0000000e+00 1.4697471e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 5.0364603e-29]\n",
      "Action prob: [1.0000000e+00 5.0364603e-29], Action: 0, state: 2\n",
      "[1.000000e+00 7.280638e-29]\n",
      "Action prob: [1.000000e+00 7.280638e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 1.6595564e-29]\n",
      "Action prob: [1.0000000e+00 1.6595564e-29], Action: 0, state: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 3.9603649e-28]\n",
      "Action prob: [1.0000000e+00 3.9603649e-28], Action: 0, state: 8\n",
      "[1.000000e+00 7.026239e-34]\n",
      "Action prob: [1.000000e+00 7.026239e-34], Action: 0, state: 8\n",
      "[1.000000e+00 2.651149e-33]\n",
      "Action prob: [1.000000e+00 2.651149e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5981088e-33]\n",
      "Action prob: [1.0000000e+00 1.5981088e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1833898e-33]\n",
      "Action prob: [1.0000000e+00 1.1833898e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.8475574e-32]\n",
      "Action prob: [1.0000000e+00 4.8475574e-32], Action: 0, state: 8\n",
      "[1.000000e+00 7.677443e-33]\n",
      "Action prob: [1.000000e+00 7.677443e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1462124e-33]\n",
      "Action prob: [1.0000000e+00 2.1462124e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 5.8199685e-31]\n",
      "Action prob: [1.0000000e+00 5.8199685e-31], Action: 0, state: 8\n",
      "[1.000000e+00 5.180367e-35]\n",
      "Action prob: [1.000000e+00 5.180367e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.9574062e-36]\n",
      "Action prob: [1.0000000e+00 1.9574062e-36], Action: 0, state: 8\n",
      "[1.0000000e+00 5.9009266e-28]\n",
      "Action prob: [1.0000000e+00 5.9009266e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8848822e-27]\n",
      "Action prob: [1.0000000e+00 2.8848822e-27], Action: 0, state: 8\n",
      "[1.000000e+00 8.992456e-27]\n",
      "Action prob: [1.000000e+00 8.992456e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5947399e-27]\n",
      "Action prob: [1.0000000e+00 1.5947399e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5866836e-32]\n",
      "Action prob: [1.0000000e+00 1.5866836e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1454978e-34]\n",
      "Action prob: [1.0000000e+00 1.1454978e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0716991e-28]\n",
      "Action prob: [1.0000000e+00 1.0716991e-28], Action: 0, state: 8\n",
      "[1.000000e+00 8.342028e-32]\n",
      "Action prob: [1.000000e+00 8.342028e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.4200755e-26]\n",
      "Action prob: [1.0000000e+00 1.4200755e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 5.6405567e-33]\n",
      "Action prob: [1.0000000e+00 5.6405567e-33], Action: 0, state: 8\n",
      "[1.000000e+00 3.084456e-26]\n",
      "Action prob: [1.000000e+00 3.084456e-26], Action: 0, state: 8\n",
      "[1.000000e+00 1.751159e-34]\n",
      "Action prob: [1.000000e+00 1.751159e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.383494e-33]\n",
      "Action prob: [1.000000e+00 7.383494e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 3.2319512e-34]\n",
      "Action prob: [1.0000000e+00 3.2319512e-34], Action: 0, state: 8\n",
      "[1.000000e+00 7.906926e-27]\n",
      "Action prob: [1.000000e+00 7.906926e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 5.2924855e-27]\n",
      "Action prob: [1.0000000e+00 5.2924855e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 3.5812552e-33]\n",
      "Action prob: [1.0000000e+00 3.5812552e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2191141e-29]\n",
      "Action prob: [1.0000000e+00 1.2191141e-29], Action: 0, state: 8\n",
      "[1.0000000e+00 6.3155064e-34]\n",
      "Action prob: [1.0000000e+00 6.3155064e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.6859132e-32]\n",
      "Action prob: [1.0000000e+00 2.6859132e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0773194e-27]\n",
      "Action prob: [1.0000000e+00 1.0773194e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8610372e-26]\n",
      "Action prob: [1.0000000e+00 1.8610372e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 3.6514553e-34]\n",
      "Action prob: [1.0000000e+00 3.6514553e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 2.7951582e-31]\n",
      "Action prob: [1.0000000e+00 2.7951582e-31], Action: 0, state: 8\n",
      "[1.0000000e+00 2.8682972e-30]\n",
      "Action prob: [1.0000000e+00 2.8682972e-30], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -100300, loss is -0.0\n",
      "[1.000000e+00 8.449454e-30]\n",
      "Action prob: [1.000000e+00 8.449454e-30], Action: 0, state: 0\n",
      "[1.0000000e+00 1.5637569e-28]\n",
      "Action prob: [1.0000000e+00 1.5637569e-28], Action: 0, state: 1\n",
      "[1.000000e+00 9.776221e-30]\n",
      "Action prob: [1.000000e+00 9.776221e-30], Action: 0, state: 1\n",
      "[1.000000e+00 5.317325e-31]\n",
      "Action prob: [1.000000e+00 5.317325e-31], Action: 0, state: 1\n",
      "[1.000000e+00 1.903649e-29]\n",
      "Action prob: [1.000000e+00 1.903649e-29], Action: 0, state: 1\n",
      "[1.00000000e+00 1.20193624e-29]\n",
      "Action prob: [1.00000000e+00 1.20193624e-29], Action: 0, state: 1\n",
      "[1.0000000e+00 2.2874265e-29]\n",
      "Action prob: [1.0000000e+00 2.2874265e-29], Action: 0, state: 2\n",
      "[1.0000000e+00 3.3176768e-37]\n",
      "Action prob: [1.0000000e+00 3.3176768e-37], Action: 0, state: 2\n",
      "[1.000000e+00 1.868197e-29]\n",
      "Action prob: [1.000000e+00 1.868197e-29], Action: 0, state: 3\n",
      "[1.000000e+00 8.336866e-34]\n",
      "Action prob: [1.000000e+00 8.336866e-34], Action: 0, state: 3\n",
      "[1.000000e+00 2.510509e-32]\n",
      "Action prob: [1.000000e+00 2.510509e-32], Action: 0, state: 3\n",
      "[1.0000000e+00 1.1694904e-27]\n",
      "Action prob: [1.0000000e+00 1.1694904e-27], Action: 0, state: 3\n",
      "[1.000000e+00 2.429267e-28]\n",
      "Action prob: [1.000000e+00 2.429267e-28], Action: 0, state: 3\n",
      "[1.0000000e+00 1.3329956e-32]\n",
      "Action prob: [1.0000000e+00 1.3329956e-32], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5118409e-34]\n",
      "Action prob: [1.0000000e+00 1.5118409e-34], Action: 0, state: 8\n",
      "[1.000000e+00 1.124958e-35]\n",
      "Action prob: [1.000000e+00 1.124958e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.5858827e-27]\n",
      "Action prob: [1.0000000e+00 1.5858827e-27], Action: 0, state: 8\n",
      "[1.0000000e+00 1.2228361e-28]\n",
      "Action prob: [1.0000000e+00 1.2228361e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6937662e-30]\n",
      "Action prob: [1.0000000e+00 1.6937662e-30], Action: 0, state: 8\n",
      "[1.0000000e+00 2.1387658e-34]\n",
      "Action prob: [1.0000000e+00 2.1387658e-34], Action: 0, state: 8\n",
      "[1.000000e+00 2.787954e-35]\n",
      "Action prob: [1.000000e+00 2.787954e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 6.0702276e-34]\n",
      "Action prob: [1.0000000e+00 6.0702276e-34], Action: 0, state: 8\n",
      "[1.00000000e+00 1.34034265e-33]\n",
      "Action prob: [1.00000000e+00 1.34034265e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 4.3791125e-35]\n",
      "Action prob: [1.0000000e+00 4.3791125e-35], Action: 0, state: 8\n",
      "[1.000000e+00 5.111531e-25]\n",
      "Action prob: [1.000000e+00 5.111531e-25], Action: 0, state: 8\n",
      "[1. 0.]\n",
      "Action prob: [1. 0.], Action: 0, state: 8\n",
      "[1.000000e+00 5.462619e-32]\n",
      "Action prob: [1.000000e+00 5.462619e-32], Action: 0, state: 8\n",
      "[1.000000e+00 8.502398e-34]\n",
      "Action prob: [1.000000e+00 8.502398e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.3425167e-34]\n",
      "Action prob: [1.0000000e+00 1.3425167e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7714226e-34]\n",
      "Action prob: [1.0000000e+00 1.7714226e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3525172e-33]\n",
      "Action prob: [1.0000000e+00 3.3525172e-33], Action: 0, state: 8\n",
      "[1.0000000e+00 1.0371464e-36]\n",
      "Action prob: [1.0000000e+00 1.0371464e-36], Action: 0, state: 8\n",
      "[1.000000e+00 3.237737e-35]\n",
      "Action prob: [1.000000e+00 3.237737e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 2.2562558e-35]\n",
      "Action prob: [1.0000000e+00 2.2562558e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 1.7810442e-34]\n",
      "Action prob: [1.0000000e+00 1.7810442e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 4.5286807e-35]\n",
      "Action prob: [1.0000000e+00 4.5286807e-35], Action: 0, state: 8\n",
      "[1.000000e+00 7.280505e-35]\n",
      "Action prob: [1.000000e+00 7.280505e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 5.3232056e-33]\n",
      "Action prob: [1.0000000e+00 5.3232056e-33], Action: 0, state: 8\n",
      "[1.000000e+00 6.722871e-27]\n",
      "Action prob: [1.000000e+00 6.722871e-27], Action: 0, state: 8\n",
      "[1.000000e+00 2.391534e-26]\n",
      "Action prob: [1.000000e+00 2.391534e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.1878157e-36]\n",
      "Action prob: [1.0000000e+00 1.1878157e-36], Action: 0, state: 8\n",
      "[1.000000e+00 8.139475e-37]\n",
      "Action prob: [1.000000e+00 8.139475e-37], Action: 0, state: 8\n",
      "[1.000000e+00 5.669674e-35]\n",
      "Action prob: [1.000000e+00 5.669674e-35], Action: 0, state: 8\n",
      "[1.0000000e+00 6.4125826e-28]\n",
      "Action prob: [1.0000000e+00 6.4125826e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 1.8151406e-26]\n",
      "Action prob: [1.0000000e+00 1.8151406e-26], Action: 0, state: 8\n",
      "[1.0000000e+00 1.6363867e-34]\n",
      "Action prob: [1.0000000e+00 1.6363867e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 6.7385347e-34]\n",
      "Action prob: [1.0000000e+00 6.7385347e-34], Action: 0, state: 8\n",
      "[1.0000000e+00 7.4094425e-28]\n",
      "Action prob: [1.0000000e+00 7.4094425e-28], Action: 0, state: 8\n",
      "[1.0000000e+00 3.3558038e-34]\n",
      "Action prob: [1.0000000e+00 3.3558038e-34], Action: 0, state: 8\n",
      "[1.000000e+00 8.237162e-34]\n",
      "Action prob: [1.000000e+00 8.237162e-34], Action: 0, state: 8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0., -0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0., -0., 0.,\n",
      "        -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Reward for this episode -105400, loss is -0.0\n",
      "[nan nan]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26668/954792413.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#writer = SummaryWriter(f\"runs/baseline/gamma/lr_{lr}gamma_{gamma}episode_{episodes}_mu_{mu0}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreinforce_baseline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmachine1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mrewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26668/3643016647.py\u001b[0m in \u001b[0;36mreinforce_baseline\u001b[1;34m(machine, baseline_net, policy_estimator, num_episodes, gamma, lr)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0maction_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpolicy_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#convert to numpy and get action prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#select weighted actions based on NN output prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Action prob: {action_probs}, Action: {action}, state: {machine.state}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "machine1 = Machine_env()\n",
    "print(machine1.reward_func)\n",
    "baseline = StateValueNetwork(machine1.observation_space)\n",
    "pol = policy_estimator(machine1)\n",
    "\n",
    "#Parameters\n",
    "episodes = 300\n",
    "gamma = 0.9\n",
    "lr= 0.1\n",
    "\n",
    "\n",
    "#writer = SummaryWriter(f\"runs/baseline/gamma/lr_{lr}gamma_{gamma}episode_{episodes}_mu_{mu0}\")\n",
    "writer = None\n",
    "results = reinforce_baseline(machine1,baseline,pol,episodes,gamma,lr)\n",
    "rewards = results[0]\n",
    "actions = np.array(results[1])\n",
    "states = results[2]\n",
    "\n",
    "episode = [i for i in range(episodes)]\n",
    "\n",
    "#Moving average we will use a window size of 50\n",
    "\n",
    "moving_averages = []\n",
    "window_size = 10\n",
    "\n",
    "df = pd.DataFrame(rewards,columns = ['r'])\n",
    "moving_ave = df.r.rolling(window_size,min_periods=1).mean().values\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.title(f'Average Reward vs Episodes: lr_{lr}, gamma_{gamma}')\n",
    "plt.plot(episode,rewards,label = 'Episodic Reward')\n",
    "plt.plot(episode,moving_ave,label = f'Moving Average Window {window_size}')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Rewards')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
